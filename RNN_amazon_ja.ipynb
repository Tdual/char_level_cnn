{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from tensorflow.contrib.learn import preprocessing\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from numpy.random import choice, randint\n",
    "import MeCab\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext jupyternotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_data_file = \"data/amazon_ja/pos.txt\"\n",
    "negative_data_file = \"data/amazon_ja/neg.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self):\n",
    "        mecab = MeCab.Tagger(\"-Ochasen -d /usr/local/lib/mecab/dic/mecab-ipadic-neologd/\")\n",
    "        self.parser = mecab.parse\n",
    "            \n",
    "\n",
    "    def tokenize(self, text):\n",
    "        text = text.lower()\n",
    "        l = [line.split(\"\\t\") for line in self.parser(text).split(\"\\n\")]\n",
    "        res = \" \".join([i[2] for i in l if len(i) >=4]) # has POS.)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'認める たい ない もの だ な 。 自分自身 の 若さ故の過ち という もの を 。'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tokenizer().tokenize(\"認めたくないものだな。自分自身の若さ故の過ちというものを。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_and_labels(positive_data_file, negative_data_file, level=\"char\", lang=\"En\"):\n",
    "       \n",
    "    positive_examples = list(open(positive_data_file, \"r\").readlines())\n",
    "    negative_examples = list(open(negative_data_file, \"r\").readlines())\n",
    "    if level == \"char\":\n",
    "        positive_examples = [s.replace(\" \", \"\").replace(\"\", \" \").lower() for s in positive_examples]\n",
    "        negative_examples = [s.replace(\" \", \"\").replace(\"\", \" \").lower() for s in negative_examples]\n",
    "    elif level == \"word\":\n",
    "        if lang == \"Ja\":\n",
    "            t = Tokenizer()\n",
    "            positive_examples = [t.tokenize(s) for s in positive_examples]\n",
    "            negative_examples = [t.tokenize(s) for s in negative_examples]\n",
    "        else:\n",
    "            positive_examples = [s.strip() for s in positive_examples]\n",
    "            negative_examples = [s.strip() for s in negative_examples]\n",
    "    else:\n",
    "        print(\"invaid value of 'level'. ('char' or 'word') \")\n",
    "        \n",
    "    n_pos = len(positive_examples)\n",
    "    n_neg = len(negative_examples)\n",
    "    ratio = n_pos/n_neg\n",
    "    print(\"# pos: \", n_pos)\n",
    "    print(\"# neg: \", n_neg)\n",
    "    print(\"pos/neg:\", ratio)\n",
    "    x_text = positive_examples + negative_examples\n",
    "\n",
    "    positive_labels = [[0, 1] for _ in positive_examples]\n",
    "    negative_labels = [[1, 0] for _ in negative_examples]\n",
    "    y = np.concatenate([positive_labels, negative_labels], 0)\n",
    "    \n",
    "    return x_text, y, ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# pos:  43179\n",
      "# neg:  5788\n",
      "pos/neg: 7.460089841050449\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"2e13ac45-b5ec-443f-937b-c1c857b926bb\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"2e13ac45-b5ec-443f-937b-c1c857b926bb\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify\n",
    "x_text, y, ratio = load_data_and_labels(positive_data_file, negative_data_file, level=\"word\", lang=\"Ja\")\n",
    "#x_text, y, ratio = load_data_and_labels(positive_data_file, negative_data_file, level=\"char\", lang=\"Ja\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_doc = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48967"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'crocs の 偽物 サンダル は 今や どこ に でも 売る て いる ます が 、 昔 買う た もの は けっこう 丈夫 に 出来る て いる て 長い 履ける た の です が 、 最近 の 物 は 底 が 柔らかい 、 石 など を 踏む で しまう と 足 の 裏 が 痛い し 、 すぐ に 底 が すり減る て 履ける ない なる て しまう 。 安物 買い を やめる て 、 正規 の crocs 公式 品 を 買う て みる ます た が 、 やはり 底 が 頑丈 で 履く 心地 が いい 。 底 が 柔らかい て ふにゃふにゃ の クッション性 を 求める て いる 人 に は 、 固い て 満足 出来る ない かも しれる ます ん が 、 散歩 や 買い物 に 行く 時 など サンダル を 普段 履く する 自分 にとって は この くらい しっかり する て いる ない と 履ける た もの だ は ない です 。 満足 の いく 買い物 が 出来る ます た 。'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_list = np.array([len(r)for r in x_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   length\n",
       "0     451\n",
       "1     161\n",
       "2     130\n",
       "3     273\n",
       "4     363"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(length_list, columns=[\"length\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48967.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>200.733474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>277.468464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>137.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>229.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80%</th>\n",
       "      <td>260.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>371.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>528.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13936.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             length\n",
       "count  48967.000000\n",
       "mean     200.733474\n",
       "std      277.468464\n",
       "min        4.000000\n",
       "50%      137.000000\n",
       "75%      229.000000\n",
       "80%      260.000000\n",
       "90%      371.000000\n",
       "95%      528.700000\n",
       "max    13936.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(percentiles=[0.5,0.75,0.8,0.9,0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x1c251492b0>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c2488ffd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist(bins=50,figsize=(10,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cut length to  528\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48967.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>177.694284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>128.380369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>137.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>229.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80%</th>\n",
       "      <td>260.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>371.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>528.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>528.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             length\n",
       "count  48967.000000\n",
       "mean     177.694284\n",
       "std      128.380369\n",
       "min        4.000000\n",
       "50%      137.000000\n",
       "75%      229.000000\n",
       "80%      260.000000\n",
       "90%      371.000000\n",
       "95%      528.000000\n",
       "max      528.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = int(df.quantile(0.95)[\"length\"]) #1000\n",
    "if long_doc:\n",
    "    print(\"cut length to \", max_length)\n",
    "    x_text = [x[:max_length] if len(x) > max_length else x for x in x_text]\n",
    "length_list = np.array([len(r)for r in x_text])\n",
    "df = pd.DataFrame(length_list, columns=[\"length\"])\n",
    "df.describe(percentiles=[0.5,0.75,0.8,0.9,0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x1c249cc4e0>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1083e5128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist(bins=50,figsize=(10,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-26-0ac02ce7bc00>:1: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "WARNING:tensorflow:From /Users/tdual/anaconda2/envs/py3.6/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n"
     ]
    }
   ],
   "source": [
    "vocab_processor = preprocessing.VocabularyProcessor(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/tdual/anaconda2/envs/py3.6/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"cf04c8ec-6226-4ada-b047-aabb42c23186\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"cf04c8ec-6226-4ada-b047-aabb42c23186\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify\n",
    "x = np.array(list(vocab_processor.fit_transform(x_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_percentage = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 46594\n",
      "Train/Test split: 44071/4896\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"c5fe3ea1-a06e-4b49-9699-18006bb32957\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"c5fe3ea1-a06e-4b49-9699-18006bb32957\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify\n",
    "np.random.seed(10)\n",
    "shuffle_indices = np.random.permutation(np.arange(len(y)))\n",
    "x_shuffled = x[shuffle_indices]\n",
    "y_shuffled = y[shuffle_indices]\n",
    "\n",
    "test_sample_index = -1 * int(test_percentage * float(len(y)))\n",
    "x_train, x_test = x_shuffled[:test_sample_index], x_shuffled[test_sample_index:]\n",
    "y_train, y_test = y_shuffled[:test_sample_index], y_shuffled[test_sample_index:]\n",
    "\n",
    "#del x, y, x_shuffled, y_shuffled\n",
    "\n",
    "print(\"Vocabulary Size: {:d}\".format(len(vocab_processor.vocabulary_)))\n",
    "print(\"Train/Test split: {:d}/{:d}\".format(len(y_train), len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44071, 528)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = x_train.shape[1]\n",
    "num_classes = y_train.shape[1]\n",
    "vocab_size = len(vocab_processor.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, sequence_length, num_classes, vocab_size, embedding_size,\n",
    "                 cell_type, hidden_size, l2_reg_lambda=0.0):\n",
    "\n",
    "        # Placeholders for input, output and dropout\n",
    "        self.input_text = tf.placeholder(tf.int32, shape=[None, sequence_length], name='input_text')\n",
    "        self.input_y = tf.placeholder(tf.float32, shape=[None, num_classes], name='input_y')\n",
    "        self.dropout_keep_prob = tf.placeholder(tf.float32, name='dropout_keep_prob')\n",
    "\n",
    "        l2_loss = tf.constant(0.0)\n",
    "        text_length = self._length(self.input_text)\n",
    "\n",
    "        with tf.device('/cpu:0'), tf.name_scope(\"text-embedding\"):\n",
    "            self.W_text = tf.Variable(tf.random_uniform([vocab_size, embedding_size], -1.0, 1.0), name=\"W_text\")\n",
    "            self.embedded_chars = tf.nn.embedding_lookup(self.W_text, self.input_text)\n",
    "\n",
    "\n",
    "        with tf.name_scope(\"rnn\"):\n",
    "            cell = self._get_cell(hidden_size, cell_type)\n",
    "            cell = tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob=self.dropout_keep_prob)\n",
    "            all_outputs, _ = tf.nn.dynamic_rnn(cell=cell, inputs=self.embedded_chars, sequence_length=text_length, dtype=tf.float32)\n",
    "            self.h_outputs = self.last_relevant(all_outputs, text_length)\n",
    "\n",
    "\n",
    "        with tf.name_scope(\"output\"):\n",
    "            W = tf.get_variable(\"W\", shape=[hidden_size, num_classes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b = tf.Variable(tf.constant(0.1, shape=[num_classes]), name=\"b\")\n",
    "            l2_loss += tf.nn.l2_loss(W)\n",
    "            l2_loss += tf.nn.l2_loss(b)\n",
    "            self.logits = tf.nn.xw_plus_b(self.h_outputs, W, b, name=\"logits\")\n",
    "            self.predictions = tf.argmax(self.logits, 1, name=\"predictions\")\n",
    "\n",
    "\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            losses = tf.nn.softmax_cross_entropy_with_logits(logits=self.logits, labels=self.input_y)\n",
    "            self.loss = tf.reduce_mean(losses) + l2_reg_lambda * l2_loss\n",
    "\n",
    "\n",
    "        with tf.name_scope(\"accuracy\"):\n",
    "            correct_predictions = tf.equal(self.predictions, tf.argmax(self.input_y, axis=1))\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32), name=\"accuracy\")\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_cell(hidden_size, cell_type):\n",
    "        if cell_type == \"vanilla\":\n",
    "            return tf.nn.rnn_cell.BasicRNNCell(hidden_size)\n",
    "        elif cell_type == \"lstm\":\n",
    "            return tf.nn.rnn_cell.BasicLSTMCell(hidden_size)\n",
    "        elif cell_type == \"gru\":\n",
    "            return tf.nn.rnn_cell.GRUCell(hidden_size)\n",
    "        else:\n",
    "            print(\"ERROR: '\" + cell_type + \"' is a wrong cell type !!!\")\n",
    "            return None\n",
    "\n",
    "    # Length of the sequence data\n",
    "    @staticmethod\n",
    "    def _length(seq):\n",
    "        relevant = tf.sign(tf.abs(seq))\n",
    "        length = tf.reduce_sum(relevant, reduction_indices=1)\n",
    "        length = tf.cast(length, tf.int32)\n",
    "        return length\n",
    "\n",
    "    # Extract the output of last cell of each sequence\n",
    "    # Ex) The movie is good -> length = 4\n",
    "    #     output = [ [1.314, -3.32, ..., 0.98]\n",
    "    #                [0.287, -0.50, ..., 1.55]\n",
    "    #                [2.194, -2.12, ..., 0.63]\n",
    "    #                [1.938, -1.88, ..., 1.31]\n",
    "    #                [  0.0,   0.0, ...,  0.0]\n",
    "    #                ...\n",
    "    #                [  0.0,   0.0, ...,  0.0] ]\n",
    "    #     The output we need is 4th output of cell, so extract it.\n",
    "    @staticmethod\n",
    "    def last_relevant(seq, length):\n",
    "        batch_size = tf.shape(seq)[0]\n",
    "        max_length = int(seq.get_shape()[1])\n",
    "        input_size = int(seq.get_shape()[2])\n",
    "        index = tf.range(0, batch_size) * max_length + (length - 1)\n",
    "        flat = tf.reshape(seq, [-1, input_size])\n",
    "        return tf.gather(flat, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iter(data, batch_size, num_epochs, shuffle=True):\n",
    "    data = np.array(data)\n",
    "    data_size = len(data)\n",
    "    num_batches_per_epoch = int((len(data)-1)/batch_size) + 1\n",
    "    print(\"num of epochs: \", num_epochs)\n",
    "    print(\"num of batches: \", num_batches_per_epoch)\n",
    "    print(\"num of step: \", num_batches_per_epoch*num_epochs)\n",
    "    for epoch in range(num_epochs):\n",
    "        if shuffle:\n",
    "            shuffle_indices = np.random.permutation(np.arange(data_size))\n",
    "            shuffled_data = data[shuffle_indices]\n",
    "        else:\n",
    "            shuffled_data = data\n",
    "        for batch_num in range(num_batches_per_epoch):\n",
    "            start_index = batch_num * batch_size\n",
    "            end_index = min((batch_num + 1) * batch_size, data_size)\n",
    "            yield shuffled_data[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_type=\"vanilla\"\n",
    "word2vec=None\n",
    "embedding_dim=300\n",
    "hidden_size=128\n",
    "dropout_keep_prob=0.5\n",
    "l2_reg_lambda=3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to ./runs/2018_07_11_21_08_34/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "display_every=10\n",
    "num_epochs = 200            \n",
    "evaluate_every = 20         \n",
    "num_checkpoints = 5\n",
    "learning_rate = 1e-3\n",
    "\n",
    "allow_soft_placement = True    \n",
    "log_device_placement = False  \n",
    "\n",
    "save_checkpoint = True\n",
    "\n",
    "\n",
    "#timestamp = str(int(time.time()))\n",
    "#timestamp = \"1525609926\"\n",
    "time_path = datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "prefix = \"\"\n",
    "#out_dir = os.path.abspath(os.path.join(os.path.curdir, \"runs\", timestamp, prefix))\n",
    "out_dir = os.path.join(os.path.curdir, \"runs\", time_path, prefix)\n",
    "print(\"Writing to {}\\n\".format(out_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tdual/anaconda2/envs/py3.6/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of epochs:  200\n",
      "num of batches:  689\n",
      "num of step:  137800\n",
      "2018-07-11T21:08:41.042047: step 10, loss 5.61865, acc 0.828125\n",
      "2018-07-11T21:08:44.879057: step 20, loss 4.90508, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:09:05.526318: step 20, loss 4.86884, acc 0.847631\n",
      "\n",
      "2018-07-11T21:09:10.038187: step 30, loss 4.36942, acc 0.8125\n",
      "2018-07-11T21:09:14.276855: step 40, loss 3.84761, acc 0.78125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:09:26.822194: step 40, loss 3.68801, acc 0.86009\n",
      "\n",
      "2018-07-11T21:09:30.958727: step 50, loss 3.18964, acc 0.90625\n",
      "2018-07-11T21:09:35.118260: step 60, loss 2.938, acc 0.828125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:09:47.604426: step 60, loss 2.77817, acc 0.870507\n",
      "\n",
      "2018-07-11T21:09:51.839616: step 70, loss 2.25718, acc 0.953125\n",
      "2018-07-11T21:09:55.927078: step 80, loss 2.05108, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:10:16.062352: step 80, loss 2.10435, acc 0.875\n",
      "\n",
      "2018-07-11T21:10:20.206205: step 90, loss 1.89282, acc 0.875\n",
      "2018-07-11T21:10:24.237110: step 100, loss 1.55102, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:10:35.812553: step 100, loss 1.60206, acc 0.877247\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/2018_07_11_21_08_34/checkpoints/model-100\n",
      "\n",
      "2018-07-11T21:10:41.079042: step 110, loss 1.51388, acc 0.84375\n",
      "2018-07-11T21:10:45.094614: step 120, loss 1.33471, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:10:57.684324: step 120, loss 1.22846, acc 0.879289\n",
      "\n",
      "2018-07-11T21:11:02.083728: step 130, loss 1.1021, acc 0.890625\n",
      "2018-07-11T21:11:06.272013: step 140, loss 0.971583, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:11:18.792351: step 140, loss 0.954298, acc 0.881332\n",
      "\n",
      "2018-07-11T21:11:22.971871: step 150, loss 0.872135, acc 0.875\n",
      "2018-07-11T21:11:27.031246: step 160, loss 0.802849, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:11:39.028427: step 160, loss 0.762807, acc 0.881944\n",
      "\n",
      "2018-07-11T21:11:43.326084: step 170, loss 0.671765, acc 0.90625\n",
      "2018-07-11T21:11:47.596409: step 180, loss 0.650705, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:12:00.012482: step 180, loss 0.633606, acc 0.880719\n",
      "\n",
      "2018-07-11T21:12:04.351869: step 190, loss 0.561106, acc 0.875\n",
      "2018-07-11T21:12:08.706059: step 200, loss 0.65774, acc 0.8125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:12:21.459011: step 200, loss 0.530706, acc 0.882761\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/2018_07_11_21_08_34/checkpoints/model-200\n",
      "\n",
      "2018-07-11T21:12:26.389038: step 210, loss 0.466649, acc 0.921875\n",
      "2018-07-11T21:12:30.666802: step 220, loss 0.519264, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:12:43.610014: step 220, loss 0.472683, acc 0.883374\n",
      "\n",
      "2018-07-11T21:12:48.066543: step 230, loss 0.521171, acc 0.828125\n",
      "2018-07-11T21:12:52.332229: step 240, loss 0.465836, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:13:11.047601: step 240, loss 0.430474, acc 0.887459\n",
      "\n",
      "2018-07-11T21:13:15.681229: step 250, loss 0.4129, acc 0.890625\n",
      "2018-07-11T21:13:20.012017: step 260, loss 0.463233, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:13:33.754673: step 260, loss 0.414578, acc 0.882761\n",
      "\n",
      "2018-07-11T21:13:38.428977: step 270, loss 0.341594, acc 0.9375\n",
      "2018-07-11T21:13:42.821067: step 280, loss 0.452843, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:13:56.521258: step 280, loss 0.377757, acc 0.886438\n",
      "\n",
      "2018-07-11T21:14:01.076267: step 290, loss 0.392153, acc 0.890625\n",
      "2018-07-11T21:14:05.528843: step 300, loss 0.420562, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:14:18.957431: step 300, loss 0.369597, acc 0.890114\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/2018_07_11_21_08_34/checkpoints/model-300\n",
      "\n",
      "2018-07-11T21:14:23.827979: step 310, loss 0.431632, acc 0.875\n",
      "2018-07-11T21:14:28.104964: step 320, loss 0.361742, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:14:40.319325: step 320, loss 0.355515, acc 0.886642\n",
      "\n",
      "2018-07-11T21:14:44.492171: step 330, loss 0.367429, acc 0.875\n",
      "2018-07-11T21:14:48.711337: step 340, loss 0.291316, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:15:00.836219: step 340, loss 0.355011, acc 0.89134\n",
      "\n",
      "2018-07-11T21:15:05.011851: step 350, loss 0.43936, acc 0.84375\n",
      "2018-07-11T21:15:09.173240: step 360, loss 0.193009, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:15:21.096201: step 360, loss 0.370637, acc 0.881332\n",
      "\n",
      "2018-07-11T21:15:25.289787: step 370, loss 0.319424, acc 0.921875\n",
      "2018-07-11T21:15:29.480685: step 380, loss 0.310444, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:15:41.691155: step 380, loss 0.348388, acc 0.888685\n",
      "\n",
      "2018-07-11T21:15:45.883531: step 390, loss 0.30578, acc 0.90625\n",
      "2018-07-11T21:15:50.053424: step 400, loss 0.366795, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:16:02.276501: step 400, loss 0.34127, acc 0.89277\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/2018_07_11_21_08_34/checkpoints/model-400\n",
      "\n",
      "2018-07-11T21:16:06.995851: step 410, loss 0.393591, acc 0.875\n",
      "2018-07-11T21:16:11.193713: step 420, loss 0.351102, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:16:23.505072: step 420, loss 0.355855, acc 0.886438\n",
      "\n",
      "2018-07-11T21:16:27.661529: step 430, loss 0.392125, acc 0.859375\n",
      "2018-07-11T21:16:31.842246: step 440, loss 0.376603, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:16:44.351734: step 440, loss 0.355589, acc 0.888072\n",
      "\n",
      "2018-07-11T21:16:48.589432: step 450, loss 0.437814, acc 0.859375\n",
      "2018-07-11T21:16:52.748631: step 460, loss 0.341439, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:17:04.873923: step 460, loss 0.351844, acc 0.889093\n",
      "\n",
      "2018-07-11T21:17:09.155583: step 470, loss 0.287091, acc 0.9375\n",
      "2018-07-11T21:17:13.346747: step 480, loss 0.240844, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:17:25.581230: step 480, loss 0.34091, acc 0.890523\n",
      "\n",
      "2018-07-11T21:17:29.800714: step 490, loss 0.232559, acc 0.96875\n",
      "2018-07-11T21:17:34.028080: step 500, loss 0.284991, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:17:47.058804: step 500, loss 0.356246, acc 0.872345\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/2018_07_11_21_08_34/checkpoints/model-500\n",
      "\n",
      "2018-07-11T21:17:51.937826: step 510, loss 0.43948, acc 0.84375\n",
      "2018-07-11T21:17:56.215747: step 520, loss 0.301057, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:18:09.445382: step 520, loss 0.349451, acc 0.886234\n",
      "\n",
      "2018-07-11T21:18:13.720483: step 530, loss 0.31873, acc 0.921875\n",
      "2018-07-11T21:18:18.090578: step 540, loss 0.298955, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:18:31.423289: step 540, loss 0.348339, acc 0.887051\n",
      "\n",
      "2018-07-11T21:18:35.652215: step 550, loss 0.403203, acc 0.890625\n",
      "2018-07-11T21:18:40.040827: step 560, loss 0.293892, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:18:53.380457: step 560, loss 0.34135, acc 0.889502\n",
      "\n",
      "2018-07-11T21:18:57.765001: step 570, loss 0.340789, acc 0.90625\n",
      "2018-07-11T21:19:02.055607: step 580, loss 0.288829, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:19:15.400023: step 580, loss 0.334789, acc 0.891953\n",
      "\n",
      "2018-07-11T21:19:19.737616: step 590, loss 0.383888, acc 0.890625\n",
      "2018-07-11T21:19:24.102757: step 600, loss 0.38062, acc 0.828125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:19:37.173109: step 600, loss 0.486704, acc 0.744894\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/2018_07_11_21_08_34/checkpoints/model-600\n",
      "\n",
      "2018-07-11T21:19:42.104856: step 610, loss 0.307262, acc 0.953125\n",
      "2018-07-11T21:19:46.261810: step 620, loss 0.339859, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:19:58.905262: step 620, loss 0.364203, acc 0.875817\n",
      "\n",
      "2018-07-11T21:20:03.147541: step 630, loss 0.326969, acc 0.890625\n",
      "2018-07-11T21:20:07.589526: step 640, loss 0.30215, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:20:20.700038: step 640, loss 0.339877, acc 0.893587\n",
      "\n",
      "2018-07-11T21:20:24.973762: step 650, loss 0.412542, acc 0.84375\n",
      "2018-07-11T21:20:29.222401: step 660, loss 0.478712, acc 0.796875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:20:42.287340: step 660, loss 0.334305, acc 0.895016\n",
      "\n",
      "2018-07-11T21:20:46.451721: step 670, loss 0.398753, acc 0.859375\n",
      "2018-07-11T21:20:50.680995: step 680, loss 0.273906, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:21:03.751757: step 680, loss 0.338244, acc 0.896446\n",
      "\n",
      "2018-07-11T21:21:07.928057: step 690, loss 0.215768, acc 0.953125\n",
      "2018-07-11T21:21:12.095379: step 700, loss 0.350124, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:21:25.615386: step 700, loss 0.347026, acc 0.882353\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/2018_07_11_21_08_34/checkpoints/model-700\n",
      "\n",
      "2018-07-11T21:21:30.504560: step 710, loss 0.313051, acc 0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-07-11T21:21:34.685134: step 720, loss 0.252979, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:21:47.827881: step 720, loss 0.332816, acc 0.899101\n",
      "\n",
      "2018-07-11T21:21:52.148409: step 730, loss 0.391459, acc 0.859375\n",
      "2018-07-11T21:21:56.458050: step 740, loss 0.387971, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:22:09.837454: step 740, loss 0.336011, acc 0.894812\n",
      "\n",
      "2018-07-11T21:22:14.195202: step 750, loss 0.197811, acc 0.96875\n",
      "2018-07-11T21:22:18.461633: step 760, loss 0.245561, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:22:31.525868: step 760, loss 0.326957, acc 0.902369\n",
      "\n",
      "2018-07-11T21:22:35.694958: step 770, loss 0.319789, acc 0.921875\n",
      "2018-07-11T21:22:39.968278: step 780, loss 0.377672, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:22:53.039453: step 780, loss 0.343006, acc 0.887459\n",
      "\n",
      "2018-07-11T21:22:57.287526: step 790, loss 0.321594, acc 0.90625\n",
      "2018-07-11T21:23:01.590946: step 800, loss 0.230331, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:23:15.357311: step 800, loss 0.335551, acc 0.890727\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/2018_07_11_21_08_34/checkpoints/model-800\n",
      "\n",
      "2018-07-11T21:23:20.238183: step 810, loss 0.35338, acc 0.90625\n",
      "2018-07-11T21:23:24.501987: step 820, loss 0.298816, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:23:37.546852: step 820, loss 0.336721, acc 0.895425\n",
      "\n",
      "2018-07-11T21:23:41.816326: step 830, loss 0.308888, acc 0.90625\n",
      "2018-07-11T21:23:46.079758: step 840, loss 0.36889, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:23:59.280959: step 840, loss 0.332323, acc 0.898284\n",
      "\n",
      "2018-07-11T21:24:03.535969: step 850, loss 0.242401, acc 0.953125\n",
      "2018-07-11T21:24:07.797900: step 860, loss 0.340833, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:24:20.961395: step 860, loss 0.326989, acc 0.895629\n",
      "\n",
      "2018-07-11T21:24:25.249965: step 870, loss 0.292943, acc 0.921875\n",
      "2018-07-11T21:24:29.569141: step 880, loss 0.367673, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:24:42.810852: step 880, loss 0.325829, acc 0.895833\n",
      "\n",
      "2018-07-11T21:24:47.044902: step 890, loss 0.31901, acc 0.90625\n",
      "2018-07-11T21:24:51.296708: step 900, loss 0.276904, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:25:04.240345: step 900, loss 0.334372, acc 0.898693\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/2018_07_11_21_08_34/checkpoints/model-900\n",
      "\n",
      "2018-07-11T21:25:09.115751: step 910, loss 0.32558, acc 0.90625\n",
      "2018-07-11T21:25:13.343188: step 920, loss 0.240829, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:25:26.315466: step 920, loss 0.327404, acc 0.902982\n",
      "\n",
      "2018-07-11T21:25:30.678968: step 930, loss 0.389508, acc 0.875\n",
      "2018-07-11T21:25:34.985560: step 940, loss 0.387047, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:25:48.061466: step 940, loss 0.323426, acc 0.902574\n",
      "\n",
      "2018-07-11T21:25:52.359853: step 950, loss 0.284282, acc 0.9375\n",
      "2018-07-11T21:25:56.619041: step 960, loss 0.285253, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:26:09.990502: step 960, loss 0.324193, acc 0.902369\n",
      "\n",
      "2018-07-11T21:26:14.328976: step 970, loss 0.303059, acc 0.90625\n",
      "2018-07-11T21:26:18.571994: step 980, loss 0.250499, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:26:32.164387: step 980, loss 0.325581, acc 0.895221\n",
      "\n",
      "2018-07-11T21:26:36.522011: step 990, loss 0.290045, acc 0.9375\n",
      "2018-07-11T21:26:40.824230: step 1000, loss 0.342932, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:26:54.189909: step 1000, loss 0.323399, acc 0.902778\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/2018_07_11_21_08_34/checkpoints/model-1000\n",
      "\n",
      "2018-07-11T21:26:59.019729: step 1010, loss 0.330819, acc 0.890625\n",
      "2018-07-11T21:27:03.267263: step 1020, loss 0.315523, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:27:16.560283: step 1020, loss 0.315188, acc 0.901757\n",
      "\n",
      "2018-07-11T21:27:20.815920: step 1030, loss 0.289242, acc 0.9375\n",
      "2018-07-11T21:27:25.142724: step 1040, loss 0.191667, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:27:38.233197: step 1040, loss 0.312767, acc 0.902369\n",
      "\n",
      "2018-07-11T21:27:42.516336: step 1050, loss 0.238166, acc 0.953125\n",
      "2018-07-11T21:27:46.742376: step 1060, loss 0.34558, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:27:59.940801: step 1060, loss 0.326564, acc 0.891544\n",
      "\n",
      "2018-07-11T21:28:04.261706: step 1070, loss 0.25254, acc 0.921875\n",
      "2018-07-11T21:28:08.580713: step 1080, loss 0.234683, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:28:21.554607: step 1080, loss 0.308285, acc 0.905025\n",
      "\n",
      "2018-07-11T21:28:25.854895: step 1090, loss 0.20814, acc 0.96875\n",
      "2018-07-11T21:28:30.129188: step 1100, loss 0.270902, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:28:43.131781: step 1100, loss 0.318648, acc 0.898284\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/2018_07_11_21_08_34/checkpoints/model-1100\n",
      "\n",
      "2018-07-11T21:28:48.047680: step 1110, loss 0.408723, acc 0.875\n",
      "2018-07-11T21:28:52.297507: step 1120, loss 0.379665, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:29:05.402934: step 1120, loss 0.423074, acc 0.847018\n",
      "\n",
      "2018-07-11T21:29:09.882235: step 1130, loss 0.391426, acc 0.875\n",
      "2018-07-11T21:29:14.162439: step 1140, loss 0.291957, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:29:27.273306: step 1140, loss 0.375889, acc 0.868873\n",
      "\n",
      "2018-07-11T21:29:31.523041: step 1150, loss 0.412529, acc 0.859375\n",
      "2018-07-11T21:29:35.801836: step 1160, loss 0.433309, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:29:49.126700: step 1160, loss 0.333712, acc 0.894608\n",
      "\n",
      "2018-07-11T21:29:53.439151: step 1170, loss 0.343703, acc 0.890625\n",
      "2018-07-11T21:29:57.828169: step 1180, loss 0.228683, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:30:11.235674: step 1180, loss 0.33154, acc 0.89134\n",
      "\n",
      "2018-07-11T21:30:15.456059: step 1190, loss 0.401227, acc 0.859375\n",
      "2018-07-11T21:30:19.700695: step 1200, loss 0.323286, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:30:32.863072: step 1200, loss 0.329761, acc 0.897059\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/2018_07_11_21_08_34/checkpoints/model-1200\n",
      "\n",
      "2018-07-11T21:30:37.779587: step 1210, loss 0.461997, acc 0.84375\n",
      "2018-07-11T21:30:42.028091: step 1220, loss 0.422291, acc 0.828125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:30:55.510122: step 1220, loss 0.314314, acc 0.90482\n",
      "\n",
      "2018-07-11T21:30:59.830465: step 1230, loss 0.376467, acc 0.890625\n",
      "2018-07-11T21:31:04.129446: step 1240, loss 0.236968, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:31:17.649412: step 1240, loss 0.318314, acc 0.900531\n",
      "\n",
      "2018-07-11T21:31:21.974267: step 1250, loss 0.350714, acc 0.890625\n",
      "2018-07-11T21:31:26.277219: step 1260, loss 0.314807, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:31:40.069706: step 1260, loss 0.315069, acc 0.905842\n",
      "\n",
      "2018-07-11T21:31:44.407254: step 1270, loss 0.262292, acc 0.9375\n",
      "2018-07-11T21:31:48.889098: step 1280, loss 0.326497, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:32:03.061997: step 1280, loss 0.316225, acc 0.905433\n",
      "\n",
      "2018-07-11T21:32:07.991917: step 1290, loss 0.257361, acc 0.96875\n",
      "2018-07-11T21:32:12.651113: step 1300, loss 0.327871, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:32:26.497913: step 1300, loss 0.30716, acc 0.907067\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/2018_07_11_21_08_34/checkpoints/model-1300\n",
      "\n",
      "2018-07-11T21:32:31.518318: step 1310, loss 0.30887, acc 0.90625\n",
      "2018-07-11T21:32:35.861829: step 1320, loss 0.287834, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:32:49.262756: step 1320, loss 0.302032, acc 0.906046\n",
      "\n",
      "2018-07-11T21:32:53.552910: step 1330, loss 0.191566, acc 0.96875\n",
      "2018-07-11T21:32:57.726140: step 1340, loss 0.373584, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:33:10.200738: step 1340, loss 0.320145, acc 0.905842\n",
      "\n",
      "2018-07-11T21:33:14.411959: step 1350, loss 0.355556, acc 0.90625\n",
      "2018-07-11T21:33:18.543859: step 1360, loss 0.271182, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:33:30.879653: step 1360, loss 0.31643, acc 0.905637\n",
      "\n",
      "2018-07-11T21:33:35.153475: step 1370, loss 0.380989, acc 0.859375\n",
      "2018-07-11T21:33:39.264530: step 1380, loss 0.282738, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:33:51.745704: step 1380, loss 0.311486, acc 0.908701\n",
      "\n",
      "2018-07-11T21:33:55.997183: step 1390, loss 0.207083, acc 0.9375\n",
      "2018-07-11T21:34:00.189524: step 1400, loss 0.245536, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:34:12.717291: step 1400, loss 0.310602, acc 0.902982\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/2018_07_11_21_08_34/checkpoints/model-1400\n",
      "\n",
      "2018-07-11T21:34:17.447050: step 1410, loss 0.404273, acc 0.859375\n",
      "2018-07-11T21:34:21.702070: step 1420, loss 0.237419, acc 0.984375\n",
      "\n",
      "Evaluation:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-07-11T21:34:34.902857: step 1420, loss 0.338989, acc 0.900123\n",
      "\n",
      "2018-07-11T21:34:39.362709: step 1430, loss 0.251125, acc 0.9375\n",
      "2018-07-11T21:34:43.682194: step 1440, loss 0.266492, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:34:56.637227: step 1440, loss 0.32067, acc 0.899306\n",
      "\n",
      "2018-07-11T21:35:00.636683: step 1450, loss 0.215066, acc 0.96875\n",
      "2018-07-11T21:35:04.552417: step 1460, loss 0.365276, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:35:16.039338: step 1460, loss 0.312756, acc 0.907884\n",
      "\n",
      "2018-07-11T21:35:19.966319: step 1470, loss 0.347193, acc 0.90625\n",
      "2018-07-11T21:35:23.863645: step 1480, loss 0.369113, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:35:35.205581: step 1480, loss 0.309562, acc 0.907884\n",
      "\n",
      "2018-07-11T21:35:39.158302: step 1490, loss 0.298814, acc 0.921875\n",
      "2018-07-11T21:35:43.087779: step 1500, loss 0.341663, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:35:56.161954: step 1500, loss 0.308275, acc 0.903391\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/2018_07_11_21_08_34/checkpoints/model-1500\n",
      "\n",
      "2018-07-11T21:36:00.494562: step 1510, loss 0.284159, acc 0.90625\n",
      "2018-07-11T21:36:04.434970: step 1520, loss 0.314071, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:36:16.327963: step 1520, loss 0.311199, acc 0.898284\n",
      "\n",
      "2018-07-11T21:36:20.253828: step 1530, loss 0.253961, acc 0.953125\n",
      "2018-07-11T21:36:24.158792: step 1540, loss 0.252975, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:36:35.585198: step 1540, loss 0.321108, acc 0.904208\n",
      "\n",
      "2018-07-11T21:36:39.485889: step 1550, loss 0.36548, acc 0.90625\n",
      "2018-07-11T21:36:43.391071: step 1560, loss 0.348665, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:36:55.228846: step 1560, loss 0.307683, acc 0.904616\n",
      "\n",
      "2018-07-11T21:36:59.201351: step 1570, loss 0.308368, acc 0.921875\n",
      "2018-07-11T21:37:03.078470: step 1580, loss 0.217551, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:37:14.637777: step 1580, loss 0.307362, acc 0.904208\n",
      "\n",
      "2018-07-11T21:37:18.537409: step 1590, loss 0.249912, acc 0.9375\n",
      "2018-07-11T21:37:22.399583: step 1600, loss 0.307366, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:37:34.217557: step 1600, loss 0.329138, acc 0.886234\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/2018_07_11_21_08_34/checkpoints/model-1600\n",
      "\n",
      "2018-07-11T21:37:38.784506: step 1610, loss 0.231769, acc 0.9375\n",
      "2018-07-11T21:37:42.695762: step 1620, loss 0.255402, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:37:54.531525: step 1620, loss 0.330664, acc 0.884804\n",
      "\n",
      "2018-07-11T21:37:58.431004: step 1630, loss 0.306089, acc 0.9375\n",
      "2018-07-11T21:38:02.345707: step 1640, loss 0.29235, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:38:14.395763: step 1640, loss 0.329346, acc 0.905025\n",
      "\n",
      "2018-07-11T21:38:18.290273: step 1650, loss 0.225789, acc 0.953125\n",
      "2018-07-11T21:38:22.203651: step 1660, loss 0.247235, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:38:33.685383: step 1660, loss 0.33224, acc 0.892361\n",
      "\n",
      "2018-07-11T21:38:37.633318: step 1670, loss 0.344678, acc 0.921875\n",
      "2018-07-11T21:38:41.567306: step 1680, loss 0.322728, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:38:53.464237: step 1680, loss 0.342592, acc 0.883374\n",
      "\n",
      "2018-07-11T21:38:57.402081: step 1690, loss 0.331277, acc 0.875\n",
      "2018-07-11T21:39:01.322975: step 1700, loss 0.321338, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:39:12.793891: step 1700, loss 0.310231, acc 0.907067\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/2018_07_11_21_08_34/checkpoints/model-1700\n",
      "\n",
      "2018-07-11T21:39:17.357904: step 1710, loss 0.340173, acc 0.90625\n",
      "2018-07-11T21:39:21.260300: step 1720, loss 0.251189, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:39:33.101966: step 1720, loss 0.317296, acc 0.893791\n",
      "\n",
      "2018-07-11T21:39:37.061054: step 1730, loss 0.29289, acc 0.9375\n",
      "2018-07-11T21:39:40.979410: step 1740, loss 0.345279, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:39:52.538549: step 1740, loss 0.358692, acc 0.874387\n",
      "\n",
      "2018-07-11T21:39:56.472611: step 1750, loss 0.338561, acc 0.890625\n",
      "2018-07-11T21:40:00.390299: step 1760, loss 0.44841, acc 0.828125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:40:11.954037: step 1760, loss 0.330394, acc 0.889706\n",
      "\n",
      "2018-07-11T21:40:15.800727: step 1770, loss 0.286572, acc 0.90625\n",
      "2018-07-11T21:40:19.625854: step 1780, loss 0.268521, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:40:31.395214: step 1780, loss 0.3162, acc 0.902369\n",
      "\n",
      "2018-07-11T21:40:35.356700: step 1790, loss 0.271585, acc 0.9375\n",
      "2018-07-11T21:40:39.264643: step 1800, loss 0.237486, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:40:50.833853: step 1800, loss 0.312072, acc 0.902369\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/2018_07_11_21_08_34/checkpoints/model-1800\n",
      "\n",
      "2018-07-11T21:40:55.429756: step 1810, loss 0.305643, acc 0.9375\n",
      "2018-07-11T21:40:59.303496: step 1820, loss 0.2088, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:41:11.353308: step 1820, loss 0.310449, acc 0.905433\n",
      "\n",
      "2018-07-11T21:41:15.068066: step 1830, loss 0.326518, acc 0.890625\n",
      "2018-07-11T21:41:19.014774: step 1840, loss 0.369731, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:41:30.833022: step 1840, loss 0.305828, acc 0.910539\n",
      "\n",
      "2018-07-11T21:41:34.683872: step 1850, loss 0.21618, acc 0.953125\n",
      "2018-07-11T21:41:38.609293: step 1860, loss 0.203296, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:41:50.197789: step 1860, loss 0.306931, acc 0.909722\n",
      "\n",
      "2018-07-11T21:41:54.139815: step 1870, loss 0.419525, acc 0.828125\n",
      "2018-07-11T21:41:58.032002: step 1880, loss 0.169238, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:42:09.552217: step 1880, loss 0.309347, acc 0.902574\n",
      "\n",
      "2018-07-11T21:42:13.455769: step 1890, loss 0.298961, acc 0.90625\n",
      "2018-07-11T21:42:17.380955: step 1900, loss 0.424923, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:42:29.192441: step 1900, loss 0.320823, acc 0.901757\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/2018_07_11_21_08_34/checkpoints/model-1900\n",
      "\n",
      "2018-07-11T21:42:33.637538: step 1910, loss 0.344694, acc 0.875\n",
      "2018-07-11T21:42:37.549607: step 1920, loss 0.287261, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:42:49.343574: step 1920, loss 0.323032, acc 0.899101\n",
      "\n",
      "2018-07-11T21:42:53.270529: step 1930, loss 0.334821, acc 0.890625\n",
      "2018-07-11T21:42:57.168304: step 1940, loss 0.288649, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:43:08.881748: step 1940, loss 0.314148, acc 0.902165\n",
      "\n",
      "2018-07-11T21:43:12.793347: step 1950, loss 0.37531, acc 0.890625\n",
      "2018-07-11T21:43:16.721756: step 1960, loss 0.290329, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:43:28.296128: step 1960, loss 0.309515, acc 0.904616\n",
      "\n",
      "2018-07-11T21:43:32.227388: step 1970, loss 0.350399, acc 0.875\n",
      "2018-07-11T21:43:36.131998: step 1980, loss 0.208248, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:43:47.893474: step 1980, loss 0.316506, acc 0.901961\n",
      "\n",
      "2018-07-11T21:43:51.772217: step 1990, loss 0.263992, acc 0.9375\n",
      "2018-07-11T21:43:55.666561: step 2000, loss 0.27126, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:44:07.345038: step 2000, loss 0.304895, acc 0.910131\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/2018_07_11_21_08_34/checkpoints/model-2000\n",
      "\n",
      "2018-07-11T21:44:11.824758: step 2010, loss 0.369946, acc 0.890625\n",
      "2018-07-11T21:44:15.696015: step 2020, loss 0.344279, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:44:27.923986: step 2020, loss 0.309175, acc 0.906863\n",
      "\n",
      "2018-07-11T21:44:32.216365: step 2030, loss 0.23171, acc 0.96875\n",
      "2018-07-11T21:44:36.540695: step 2040, loss 0.30265, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:44:49.472020: step 2040, loss 0.30539, acc 0.908088\n",
      "\n",
      "2018-07-11T21:44:53.871766: step 2050, loss 0.222727, acc 0.96875\n",
      "2018-07-11T21:44:58.110747: step 2060, loss 0.222411, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:45:10.397154: step 2060, loss 0.304585, acc 0.90482\n",
      "\n",
      "2018-07-11T21:45:14.601903: step 2070, loss 0.317625, acc 0.90625\n",
      "2018-07-11T21:45:18.602753: step 2080, loss 0.222224, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:45:30.564758: step 2080, loss 0.311592, acc 0.905025\n",
      "\n",
      "2018-07-11T21:45:34.564398: step 2090, loss 0.250849, acc 0.9375\n",
      "2018-07-11T21:45:38.457003: step 2100, loss 0.2522, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:45:50.812500: step 2100, loss 0.302481, acc 0.909314\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/2018_07_11_21_08_34/checkpoints/model-2100\n",
      "\n",
      "2018-07-11T21:45:55.485656: step 2110, loss 0.137988, acc 1\n",
      "2018-07-11T21:45:59.662474: step 2120, loss 0.250302, acc 0.953125\n",
      "\n",
      "Evaluation:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-07-11T21:46:12.197617: step 2120, loss 0.314037, acc 0.911152\n",
      "\n",
      "2018-07-11T21:46:16.101910: step 2130, loss 0.295989, acc 0.921875\n",
      "2018-07-11T21:46:19.903348: step 2140, loss 0.346511, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:46:31.997860: step 2140, loss 0.305904, acc 0.908497\n",
      "\n",
      "2018-07-11T21:46:36.001922: step 2150, loss 0.256937, acc 0.921875\n",
      "2018-07-11T21:46:40.306099: step 2160, loss 0.227227, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:46:52.656323: step 2160, loss 0.304317, acc 0.910335\n",
      "\n",
      "2018-07-11T21:46:56.585796: step 2170, loss 0.307945, acc 0.90625\n",
      "2018-07-11T21:47:00.542489: step 2180, loss 0.30267, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:47:12.580855: step 2180, loss 0.29727, acc 0.91442\n",
      "\n",
      "2018-07-11T21:47:16.401615: step 2190, loss 0.227013, acc 0.953125\n",
      "2018-07-11T21:47:20.333252: step 2200, loss 0.195247, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:47:36.756834: step 2200, loss 0.299007, acc 0.912173\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/2018_07_11_21_08_34/checkpoints/model-2200\n",
      "\n",
      "2018-07-11T21:47:41.259233: step 2210, loss 0.231563, acc 0.921875\n",
      "2018-07-11T21:47:45.130069: step 2220, loss 0.322367, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:47:56.665983: step 2220, loss 0.301336, acc 0.914011\n",
      "\n",
      "2018-07-11T21:48:00.602483: step 2230, loss 0.263752, acc 0.921875\n",
      "2018-07-11T21:48:04.484062: step 2240, loss 0.218376, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:48:15.964793: step 2240, loss 0.300963, acc 0.906454\n",
      "\n",
      "2018-07-11T21:48:19.842753: step 2250, loss 0.294899, acc 0.921875\n",
      "2018-07-11T21:48:23.790791: step 2260, loss 0.182549, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:48:34.982476: step 2260, loss 0.304002, acc 0.914828\n",
      "\n",
      "2018-07-11T21:48:38.920179: step 2270, loss 0.266405, acc 0.921875\n",
      "2018-07-11T21:48:42.814663: step 2280, loss 0.225034, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:48:54.690640: step 2280, loss 0.298944, acc 0.911765\n",
      "\n",
      "2018-07-11T21:48:58.653117: step 2290, loss 0.199163, acc 0.953125\n",
      "2018-07-11T21:49:02.588959: step 2300, loss 0.180505, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:49:15.052107: step 2300, loss 0.302095, acc 0.912173\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/2018_07_11_21_08_34/checkpoints/model-2300\n",
      "\n",
      "2018-07-11T21:49:19.734678: step 2310, loss 0.317703, acc 0.890625\n",
      "2018-07-11T21:49:23.731347: step 2320, loss 0.298126, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:49:35.625535: step 2320, loss 0.301616, acc 0.914624\n",
      "\n",
      "2018-07-11T21:49:39.611769: step 2330, loss 0.35582, acc 0.875\n",
      "2018-07-11T21:49:43.579058: step 2340, loss 0.18671, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:49:55.202270: step 2340, loss 0.300419, acc 0.912786\n",
      "\n",
      "2018-07-11T21:49:59.174803: step 2350, loss 0.281142, acc 0.921875\n",
      "2018-07-11T21:50:03.120144: step 2360, loss 0.17526, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:50:14.990021: step 2360, loss 0.300079, acc 0.912786\n",
      "\n",
      "2018-07-11T21:50:18.964321: step 2370, loss 0.238932, acc 0.96875\n",
      "2018-07-11T21:50:22.891633: step 2380, loss 0.193651, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:50:35.210404: step 2380, loss 0.302475, acc 0.912786\n",
      "\n",
      "2018-07-11T21:50:39.241821: step 2390, loss 0.327898, acc 0.921875\n",
      "2018-07-11T21:50:43.459199: step 2400, loss 0.294582, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:50:56.523624: step 2400, loss 0.299933, acc 0.914216\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/2018_07_11_21_08_34/checkpoints/model-2400\n",
      "\n",
      "2018-07-11T21:51:01.295269: step 2410, loss 0.284998, acc 0.9375\n",
      "2018-07-11T21:51:05.351006: step 2420, loss 0.270677, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:51:18.082109: step 2420, loss 0.302648, acc 0.915033\n",
      "\n",
      "2018-07-11T21:51:22.408734: step 2430, loss 0.248758, acc 0.9375\n",
      "2018-07-11T21:51:26.529263: step 2440, loss 0.479281, acc 0.8125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:51:38.928041: step 2440, loss 0.30102, acc 0.914828\n",
      "\n",
      "2018-07-11T21:51:42.970802: step 2450, loss 0.25185, acc 0.9375\n",
      "2018-07-11T21:51:46.973054: step 2460, loss 0.237026, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:51:58.877853: step 2460, loss 0.303546, acc 0.913194\n",
      "\n",
      "2018-07-11T21:52:02.896059: step 2470, loss 0.30732, acc 0.859375\n",
      "2018-07-11T21:52:06.914379: step 2480, loss 0.276481, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:52:18.400263: step 2480, loss 0.312065, acc 0.902165\n",
      "\n",
      "2018-07-11T21:52:22.319859: step 2490, loss 0.341404, acc 0.890625\n",
      "2018-07-11T21:52:26.227836: step 2500, loss 0.246675, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:52:38.109360: step 2500, loss 0.303414, acc 0.907884\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/2018_07_11_21_08_34/checkpoints/model-2500\n",
      "\n",
      "2018-07-11T21:52:42.655397: step 2510, loss 0.24413, acc 0.953125\n",
      "2018-07-11T21:52:46.530328: step 2520, loss 0.373662, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:52:58.101667: step 2520, loss 0.300481, acc 0.915237\n",
      "\n",
      "2018-07-11T21:53:01.999710: step 2530, loss 0.445305, acc 0.84375\n",
      "2018-07-11T21:53:05.950753: step 2540, loss 0.310813, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:53:17.590412: step 2540, loss 0.296824, acc 0.91156\n",
      "\n",
      "2018-07-11T21:53:21.796907: step 2550, loss 0.412513, acc 0.90625\n",
      "2018-07-11T21:53:26.288347: step 2560, loss 0.236452, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:53:38.995035: step 2560, loss 0.304028, acc 0.906863\n",
      "\n",
      "2018-07-11T21:53:43.428945: step 2570, loss 0.18453, acc 0.96875\n",
      "2018-07-11T21:53:47.539632: step 2580, loss 0.311347, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:54:00.054605: step 2580, loss 0.300616, acc 0.912582\n",
      "\n",
      "2018-07-11T21:54:04.404751: step 2590, loss 0.252901, acc 0.90625\n",
      "2018-07-11T21:54:08.797583: step 2600, loss 0.32916, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:54:26.605810: step 2600, loss 0.2977, acc 0.911356\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/2018_07_11_21_08_34/checkpoints/model-2600\n",
      "\n",
      "2018-07-11T21:54:31.503094: step 2610, loss 0.298503, acc 0.921875\n",
      "2018-07-11T21:54:35.778461: step 2620, loss 0.295912, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:54:47.995160: step 2620, loss 0.296501, acc 0.912173\n",
      "\n",
      "2018-07-11T21:54:52.195895: step 2630, loss 0.225444, acc 0.9375\n",
      "2018-07-11T21:54:56.323634: step 2640, loss 0.278245, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:55:08.319062: step 2640, loss 0.306431, acc 0.90625\n",
      "\n",
      "2018-07-11T21:55:12.726758: step 2650, loss 0.209176, acc 0.953125\n",
      "2018-07-11T21:55:16.912469: step 2660, loss 0.232577, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:55:29.158683: step 2660, loss 0.299209, acc 0.912786\n",
      "\n",
      "2018-07-11T21:55:33.032112: step 2670, loss 0.28075, acc 0.9375\n",
      "2018-07-11T21:55:37.166216: step 2680, loss 0.266366, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:55:48.680878: step 2680, loss 0.32908, acc 0.895016\n",
      "\n",
      "2018-07-11T21:55:52.598397: step 2690, loss 0.361618, acc 0.90625\n",
      "2018-07-11T21:55:56.507155: step 2700, loss 0.280226, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:56:07.990316: step 2700, loss 0.299811, acc 0.911152\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/2018_07_11_21_08_34/checkpoints/model-2700\n",
      "\n",
      "2018-07-11T21:56:12.615166: step 2710, loss 0.289134, acc 0.90625\n",
      "2018-07-11T21:56:16.490584: step 2720, loss 0.395757, acc 0.828125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:56:28.545307: step 2720, loss 0.335199, acc 0.884395\n",
      "\n",
      "2018-07-11T21:56:32.821423: step 2730, loss 0.279846, acc 0.890625\n",
      "2018-07-11T21:56:37.232374: step 2740, loss 0.180218, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:56:50.745576: step 2740, loss 0.315649, acc 0.905025\n",
      "\n",
      "2018-07-11T21:56:54.782980: step 2750, loss 0.243224, acc 0.9375\n",
      "2018-07-11T21:56:59.324682: step 2760, loss 0.283573, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:57:12.900012: step 2760, loss 0.309039, acc 0.910131\n",
      "\n",
      "2018-07-11T21:57:17.161621: step 2770, loss 0.273813, acc 0.921875\n",
      "2018-07-11T21:57:21.429847: step 2780, loss 0.258224, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:57:41.495804: step 2780, loss 0.30646, acc 0.906046\n",
      "\n",
      "2018-07-11T21:57:46.176404: step 2790, loss 0.300666, acc 0.90625\n",
      "2018-07-11T21:57:50.583928: step 2800, loss 0.19799, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:58:03.477473: step 2800, loss 0.3016, acc 0.911152\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/2018_07_11_21_08_34/checkpoints/model-2800\n",
      "\n",
      "2018-07-11T21:58:08.495714: step 2810, loss 0.295977, acc 0.921875\n",
      "2018-07-11T21:58:12.594736: step 2820, loss 0.177087, acc 0.953125\n",
      "\n",
      "Evaluation:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-07-11T21:58:24.962896: step 2820, loss 0.300163, acc 0.911969\n",
      "\n",
      "2018-07-11T21:58:29.285745: step 2830, loss 0.415016, acc 0.875\n",
      "2018-07-11T21:58:33.456079: step 2840, loss 0.226998, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:58:45.878216: step 2840, loss 0.319599, acc 0.89808\n",
      "\n",
      "2018-07-11T21:58:50.073977: step 2850, loss 0.233642, acc 0.9375\n",
      "2018-07-11T21:58:54.290835: step 2860, loss 0.262441, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:59:06.713378: step 2860, loss 0.320927, acc 0.911969\n",
      "\n",
      "2018-07-11T21:59:10.914876: step 2870, loss 0.264337, acc 0.9375\n",
      "2018-07-11T21:59:15.753074: step 2880, loss 0.284139, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:59:28.070337: step 2880, loss 0.29995, acc 0.91299\n",
      "\n",
      "2018-07-11T21:59:32.119868: step 2890, loss 0.200295, acc 0.96875\n",
      "2018-07-11T21:59:36.148749: step 2900, loss 0.226676, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T21:59:47.853360: step 2900, loss 0.297574, acc 0.913603\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/2018_07_11_21_08_34/checkpoints/model-2900\n",
      "\n",
      "2018-07-11T21:59:52.691028: step 2910, loss 0.292405, acc 0.921875\n",
      "2018-07-11T21:59:56.778147: step 2920, loss 0.25415, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T22:00:13.894247: step 2920, loss 0.329766, acc 0.890114\n",
      "\n",
      "2018-07-11T22:00:17.837378: step 2930, loss 0.347467, acc 0.890625\n",
      "2018-07-11T22:00:21.835130: step 2940, loss 0.175678, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T22:00:33.523232: step 2940, loss 0.314766, acc 0.908905\n",
      "\n",
      "2018-07-11T22:00:37.459326: step 2950, loss 0.226051, acc 0.953125\n",
      "2018-07-11T22:00:41.394803: step 2960, loss 0.40255, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T22:00:53.457670: step 2960, loss 0.364837, acc 0.881332\n",
      "\n",
      "2018-07-11T22:00:57.800177: step 2970, loss 0.21017, acc 0.96875\n",
      "2018-07-11T22:01:01.854555: step 2980, loss 0.389689, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T22:01:14.434893: step 2980, loss 0.330502, acc 0.894404\n",
      "\n",
      "2018-07-11T22:01:18.652213: step 2990, loss 0.341012, acc 0.890625\n",
      "2018-07-11T22:01:22.940053: step 3000, loss 0.264958, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T22:01:35.506635: step 3000, loss 0.32681, acc 0.897467\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/2018_07_11_21_08_34/checkpoints/model-3000\n",
      "\n",
      "2018-07-11T22:01:40.286169: step 3010, loss 0.200545, acc 0.96875\n",
      "2018-07-11T22:01:44.571362: step 3020, loss 0.360811, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T22:01:57.002462: step 3020, loss 0.316888, acc 0.90768\n",
      "\n",
      "2018-07-11T22:02:01.525610: step 3030, loss 0.287212, acc 0.921875\n",
      "2018-07-11T22:02:05.602228: step 3040, loss 0.25592, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T22:02:16.966603: step 3040, loss 0.307325, acc 0.911765\n",
      "\n",
      "2018-07-11T22:02:20.842398: step 3050, loss 0.214464, acc 0.96875\n",
      "2018-07-11T22:02:24.808819: step 3060, loss 0.246955, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T22:02:36.843929: step 3060, loss 0.301015, acc 0.911969\n",
      "\n",
      "2018-07-11T22:02:41.172892: step 3070, loss 0.243589, acc 0.953125\n",
      "2018-07-11T22:02:45.183807: step 3080, loss 0.250104, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T22:02:57.433775: step 3080, loss 0.30952, acc 0.909722\n",
      "\n",
      "2018-07-11T22:03:01.424888: step 3090, loss 0.262836, acc 0.90625\n",
      "2018-07-11T22:03:05.500871: step 3100, loss 0.271742, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T22:03:17.358618: step 3100, loss 0.338761, acc 0.888889\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/2018_07_11_21_08_34/checkpoints/model-3100\n",
      "\n",
      "2018-07-11T22:03:22.311947: step 3110, loss 0.32161, acc 0.859375\n",
      "2018-07-11T22:03:26.494234: step 3120, loss 0.198533, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T22:03:39.251783: step 3120, loss 0.325553, acc 0.897672\n",
      "\n",
      "2018-07-11T22:03:43.264726: step 3130, loss 0.225118, acc 0.9375\n",
      "2018-07-11T22:03:47.425937: step 3140, loss 0.215577, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T22:04:00.069010: step 3140, loss 0.302927, acc 0.908292\n",
      "\n",
      "2018-07-11T22:04:04.254881: step 3150, loss 0.338997, acc 0.90625\n",
      "2018-07-11T22:04:08.331687: step 3160, loss 0.24262, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T22:04:20.615477: step 3160, loss 0.30522, acc 0.905433\n",
      "\n",
      "2018-07-11T22:04:24.833200: step 3170, loss 0.350492, acc 0.921875\n",
      "2018-07-11T22:04:29.044806: step 3180, loss 0.2571, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T22:04:41.837988: step 3180, loss 0.299918, acc 0.912786\n",
      "\n",
      "2018-07-11T22:04:46.359998: step 3190, loss 0.167079, acc 0.96875\n",
      "2018-07-11T22:04:50.787500: step 3200, loss 0.311771, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T22:05:05.498050: step 3200, loss 0.301874, acc 0.911356\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/2018_07_11_21_08_34/checkpoints/model-3200\n",
      "\n",
      "2018-07-11T22:05:12.447022: step 3210, loss 0.188356, acc 0.984375\n",
      "2018-07-11T22:05:19.104926: step 3220, loss 0.214981, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T22:05:44.378800: step 3220, loss 0.302822, acc 0.912786\n",
      "\n",
      "2018-07-11T22:05:51.473979: step 3230, loss 0.355794, acc 0.875\n",
      "2018-07-11T22:05:58.356880: step 3240, loss 0.276689, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T22:06:20.957858: step 3240, loss 0.296949, acc 0.916667\n",
      "\n",
      "2018-07-11T22:06:25.981130: step 3250, loss 0.158631, acc 0.984375\n",
      "2018-07-11T22:06:30.722360: step 3260, loss 0.282577, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T22:06:46.435484: step 3260, loss 0.292615, acc 0.918301\n",
      "\n",
      "2018-07-11T22:06:50.613441: step 3270, loss 0.255372, acc 0.9375\n",
      "2018-07-11T22:06:55.016479: step 3280, loss 0.164491, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T22:07:07.409822: step 3280, loss 0.2965, acc 0.914624\n",
      "\n",
      "2018-07-11T22:07:11.433323: step 3290, loss 0.218849, acc 0.953125\n",
      "2018-07-11T22:07:15.374927: step 3300, loss 0.232592, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T22:07:26.890462: step 3300, loss 0.298916, acc 0.909926\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/2018_07_11_21_08_34/checkpoints/model-3300\n",
      "\n",
      "2018-07-11T22:07:31.570183: step 3310, loss 0.21883, acc 0.953125\n",
      "2018-07-11T22:07:35.641497: step 3320, loss 0.216447, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T22:07:48.411321: step 3320, loss 0.29707, acc 0.916871\n",
      "\n",
      "2018-07-11T22:07:52.696610: step 3330, loss 0.129159, acc 1\n",
      "2018-07-11T22:07:57.020189: step 3340, loss 0.195228, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T22:08:08.854778: step 3340, loss 0.298288, acc 0.918913\n",
      "\n",
      "2018-07-11T22:08:12.834790: step 3350, loss 0.267833, acc 0.9375\n",
      "2018-07-11T22:08:16.870692: step 3360, loss 0.302816, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T22:08:29.313572: step 3360, loss 0.297463, acc 0.912582\n",
      "\n",
      "2018-07-11T22:08:33.674046: step 3370, loss 0.232376, acc 0.9375\n",
      "2018-07-11T22:08:37.822120: step 3380, loss 0.13355, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T22:08:50.782464: step 3380, loss 0.296918, acc 0.915033\n",
      "\n",
      "2018-07-11T22:08:54.917708: step 3390, loss 0.286051, acc 0.921875\n",
      "2018-07-11T22:08:59.092053: step 3400, loss 0.677131, acc 0.6875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T22:09:11.399489: step 3400, loss 0.481637, acc 0.780025\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/2018_07_11_21_08_34/checkpoints/model-3400\n",
      "\n",
      "2018-07-11T22:09:16.187891: step 3410, loss 0.431431, acc 0.859375\n",
      "2018-07-11T22:09:20.405325: step 3420, loss 0.252384, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T22:09:35.689042: step 3420, loss 0.348057, acc 0.902369\n",
      "\n",
      "2018-07-11T22:09:40.741573: step 3430, loss 0.305305, acc 0.90625\n",
      "2018-07-11T22:09:45.751558: step 3440, loss 0.257261, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T22:09:59.401084: step 3440, loss 0.329253, acc 0.894199\n",
      "\n",
      "2018-07-11T22:10:03.645477: step 3450, loss 0.328783, acc 0.90625\n",
      "2018-07-11T22:10:08.035089: step 3460, loss 0.216888, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T22:10:21.535433: step 3460, loss 0.3197, acc 0.901552\n",
      "\n",
      "2018-07-11T22:10:25.877417: step 3470, loss 0.292362, acc 0.890625\n",
      "2018-07-11T22:10:29.978994: step 3480, loss 0.30092, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T22:10:42.838815: step 3480, loss 0.312996, acc 0.903391\n",
      "\n",
      "2018-07-11T22:10:47.442187: step 3490, loss 0.213186, acc 0.96875\n",
      "2018-07-11T22:10:52.168533: step 3500, loss 0.253553, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T22:11:06.622573: step 3500, loss 0.31375, acc 0.90625\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/2018_07_11_21_08_34/checkpoints/model-3500\n",
      "\n",
      "2018-07-11T22:11:11.667387: step 3510, loss 0.348272, acc 0.890625\n",
      "2018-07-11T22:11:16.027022: step 3520, loss 0.186735, acc 0.96875\n",
      "\n",
      "Evaluation:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-07-11T22:11:29.350158: step 3520, loss 0.315898, acc 0.90482\n",
      "\n",
      "2018-07-11T22:11:33.759203: step 3530, loss 0.278142, acc 0.9375\n",
      "2018-07-11T22:11:37.857080: step 3540, loss 0.224364, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T22:11:50.777784: step 3540, loss 0.306062, acc 0.908292\n",
      "\n",
      "2018-07-11T22:11:54.818397: step 3550, loss 0.178145, acc 0.953125\n",
      "2018-07-11T22:11:59.164803: step 3560, loss 0.187559, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T22:12:12.223315: step 3560, loss 0.319358, acc 0.89951\n",
      "\n",
      "2018-07-11T22:12:16.696583: step 3570, loss 0.277701, acc 0.921875\n",
      "2018-07-11T22:12:20.973429: step 3580, loss 0.365835, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T22:12:34.218804: step 3580, loss 0.321042, acc 0.894404\n",
      "\n",
      "2018-07-11T22:12:38.266064: step 3590, loss 0.313977, acc 0.890625\n",
      "2018-07-11T22:12:42.318620: step 3600, loss 0.231202, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-11T22:12:55.567745: step 3600, loss 0.31232, acc 0.906046\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/2018_07_11_21_08_34/checkpoints/model-3600\n",
      "\n",
      "2018-07-11T22:13:00.620231: step 3610, loss 0.25658, acc 0.921875\n",
      "2018-07-11T22:13:05.031704: step 3620, loss 0.209902, acc 0.953125\n",
      "\n",
      "Evaluation:\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "        session_conf = tf.ConfigProto(\n",
    "            allow_soft_placement=allow_soft_placement,\n",
    "            log_device_placement=log_device_placement)\n",
    "        \n",
    "        sess = tf.Session(config=session_conf)\n",
    "        with sess.as_default():\n",
    "            rnn = RNN(\n",
    "                sequence_length=x_train.shape[1],\n",
    "                num_classes=y_train.shape[1],\n",
    "                vocab_size=vocab_size,\n",
    "                embedding_size=embedding_dim,\n",
    "                cell_type=cell_type,\n",
    "                hidden_size=hidden_size,\n",
    "                l2_reg_lambda=l2_reg_lambda\n",
    "            )\n",
    "\n",
    "\n",
    "            global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "            train_op = tf.train.AdamOptimizer(learning_rate).minimize(rnn.loss, global_step=global_step)\n",
    "\n",
    "\n",
    "            loss_summary = tf.summary.scalar(\"loss\", rnn.loss)\n",
    "            acc_summary = tf.summary.scalar(\"accuracy\", rnn.accuracy)\n",
    "\n",
    "            train_summary_op = tf.summary.merge([loss_summary, acc_summary])\n",
    "            train_summary_dir = os.path.join(out_dir, \"summaries\", \"train\")\n",
    "            train_summary_writer = tf.summary.FileWriter(train_summary_dir, sess.graph)\n",
    "\n",
    "            test_summary_op = tf.summary.merge([loss_summary, acc_summary])\n",
    "            test_summary_dir = os.path.join(out_dir, \"summaries\", \"test\")\n",
    "            test_summary_writer = tf.summary.FileWriter(test_summary_dir, sess.graph)\n",
    "\n",
    "            checkpoint_dir = os.path.abspath(os.path.join(out_dir, \"checkpoints\"))\n",
    "            checkpoint_prefix = os.path.join(checkpoint_dir, \"model\")\n",
    "            if not os.path.exists(checkpoint_dir):\n",
    "                os.makedirs(checkpoint_dir)\n",
    "            saver = tf.train.Saver(tf.global_variables(), max_to_keep=num_checkpoints)\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            # Pre-trained word2vec\n",
    "            if word2vec:\n",
    "                # initial matrix with random uniform\n",
    "                initW = np.random.uniform(-0.25, 0.25, (len(text_vocab_processor.vocabulary_), embedding_dim))\n",
    "                # load any vectors from the word2vec\n",
    "                print(\"Load word2vec file {0}\".format(word2vec))\n",
    "                with open(word2vec, \"rb\") as f:\n",
    "                    header = f.readline()\n",
    "                    vocab_size, layer1_size = map(int, header.split())\n",
    "                    binary_len = np.dtype('float32').itemsize * layer1_size\n",
    "                    for line in range(vocab_size):\n",
    "                        word = []\n",
    "                        while True:\n",
    "                            ch = f.read(1).decode('latin-1')\n",
    "                            if ch == ' ':\n",
    "                                word = ''.join(word)\n",
    "                                break\n",
    "                            if ch != '\\n':\n",
    "                                word.append(ch)\n",
    "                        idx = text_vocab_processor.vocabulary_.get(word)\n",
    "                        if idx != 0:\n",
    "                            initW[idx] = np.fromstring(f.read(binary_len), dtype='float32')\n",
    "                        else:\n",
    "                            f.read(binary_len)\n",
    "                sess.run(rnn.W_text.assign(initW))\n",
    "                print(\"Success to load pre-trained word2vec model!\\n\")\n",
    "\n",
    "\n",
    "            batches = batch_iter(list(zip(x_train, y_train)), batch_size, num_epochs)\n",
    "\n",
    "            for batch in batches:\n",
    "                x_batch, y_batch = zip(*batch)\n",
    "                feed_dict = {\n",
    "                    rnn.input_text: x_batch,\n",
    "                    rnn.input_y: y_batch,\n",
    "                    rnn.dropout_keep_prob: dropout_keep_prob\n",
    "                }\n",
    "                _, step, summaries, loss, accuracy = sess.run(\n",
    "                    [train_op, global_step, train_summary_op, rnn.loss, rnn.accuracy], feed_dict)\n",
    "                train_summary_writer.add_summary(summaries, step)\n",
    "\n",
    "                if step % display_every == 0:\n",
    "                    time_str = datetime.datetime.now().isoformat()\n",
    "                    print(\"{}: step {}, loss {:g}, acc {:g}\".format(time_str, step, loss, accuracy))\n",
    "\n",
    "                if step % evaluate_every == 0:\n",
    "                    print(\"\\nEvaluation:\")\n",
    "                    feed_dict_test = {\n",
    "                        rnn.input_text: x_test,\n",
    "                        rnn.input_y: y_test,\n",
    "                        rnn.dropout_keep_prob: 1.0\n",
    "                    }\n",
    "                    summaries_test, loss, accuracy = sess.run([test_summary_op, rnn.loss, rnn.accuracy], feed_dict_test)\n",
    "                    test_summary_writer.add_summary(summaries_test, step)\n",
    "\n",
    "                    time_str = datetime.datetime.now().isoformat()\n",
    "                    print(\"{}: step {}, loss {:g}, acc {:g}\\n\".format(time_str, step, loss, accuracy))\n",
    "\n",
    "                if step % checkpoint_every == 0:\n",
    "                    path = saver.save(sess, checkpoint_prefix, global_step=step)\n",
    "                    print(\"Saved model checkpoint to {}\\n\".format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_py3.6)",
   "language": "python",
   "name": "conda_py3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
