{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset  \n",
    "- amazon review\n",
    "http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Books_5.json.gz\n",
    "\n",
    "- chABSA\n",
    "https://github.com/chakki-works/chABSA-dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/ShopRunner/jupyter-notify\n",
    "```\n",
    "pip install jupyternotify\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tdual/anaconda2/envs/py3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from tensorflow.contrib.learn import preprocessing\n",
    "import pickle\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "%load_ext jupyternotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN:\n",
    "\n",
    "    def __init__(\n",
    "      self, sequence_length, num_classes, vocab_size, embedding_size, filter_sizes, num_filters, l2_reg_lambda=0.0):\n",
    "\n",
    "\n",
    "        self.input_x = tf.placeholder(tf.int32, [None, sequence_length], name=\"input_x\")\n",
    "        self.input_y = tf.placeholder(tf.float32, [None, num_classes], name=\"input_y\")\n",
    "        self.dropout_keep_prob = tf.placeholder(tf.float32, name=\"dropout_keep_prob\")\n",
    "\n",
    "        l2_loss = tf.constant(0.0)\n",
    "\n",
    "\n",
    "        with tf.device('/cpu:0'), tf.name_scope(\"embedding\"):\n",
    "            self.W = tf.Variable(tf.random_uniform([vocab_size, embedding_size], -1.0, 1.0), name=\"W\")\n",
    "            self.embedded_chars = tf.nn.embedding_lookup(self.W, self.input_x)\n",
    "            self.embedded_chars_expanded = tf.expand_dims(self.embedded_chars, -1)\n",
    "\n",
    " \n",
    "        pooled_outputs = []\n",
    "        for i, filter_size in enumerate(filter_sizes):\n",
    "            with tf.name_scope(\"conv-maxpool-%s\" % filter_size):\n",
    "                filter_shape = [filter_size, embedding_size, 1, num_filters]\n",
    "                W = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.1), name=\"W\")\n",
    "                b = tf.Variable(tf.constant(0.1, shape=[num_filters]), name=\"b\")\n",
    "                conv = tf.nn.conv2d(self.embedded_chars_expanded,W,strides=[1, 1, 1, 1],padding=\"VALID\", name=\"conv\")\n",
    "                h = tf.nn.relu(tf.nn.bias_add(conv, b), name=\"relu\")\n",
    "                pooled = tf.nn.max_pool(h, ksize=[1, sequence_length - filter_size + 1, 1, 1],strides=[1, 1, 1, 1],padding='VALID',name=\"pool\")\n",
    "                pooled_outputs.append(pooled)\n",
    "\n",
    "\n",
    "        num_filters_total = num_filters * len(filter_sizes)\n",
    "        print(num_filters_total)\n",
    "        self.h_pool = tf.concat(pooled_outputs, 3)\n",
    "        self.h_pool_flat = tf.reshape(self.h_pool, [-1, num_filters_total])\n",
    "        \n",
    "\n",
    "        with tf.name_scope(\"fc-1\"):\n",
    "            W = tf.Variable(tf.truncated_normal([num_filters_total, 1024], stddev=0.1), name=\"W\")\n",
    "            b = tf.Variable(tf.constant(0.1, shape=[1024]), name=\"b\")\n",
    "            l2_loss += tf.nn.l2_loss(W)\n",
    "            l2_loss += tf.nn.l2_loss(b)\n",
    "            fc_1_output = tf.nn.relu(tf.nn.xw_plus_b(self.h_pool_flat, W, b), name=\"fc-1-out\")\n",
    "\n",
    "\n",
    "        with tf.name_scope(\"dropout-1\"):\n",
    "            drop_1 = tf.nn.dropout(fc_1_output, self.dropout_keep_prob)\n",
    "\n",
    "\n",
    "        with tf.name_scope(\"fc-2\"):\n",
    "            W = tf.Variable(tf.truncated_normal([1024,1024], stddev=0.1), name=\"W\")\n",
    "            b = tf.Variable(tf.constant(0.1, shape=[1024]), name=\"b\")\n",
    "            l2_loss += tf.nn.l2_loss(W)\n",
    "            l2_loss += tf.nn.l2_loss(b)\n",
    "            fc_2_output = tf.nn.relu(tf.nn.xw_plus_b(drop_1, W, b), name=\"fc-2-out\")\n",
    "            \n",
    "        with tf.name_scope(\"dropout-2\"):\n",
    "            drop_2 = tf.nn.dropout(fc_2_output, self.dropout_keep_prob)\n",
    "\n",
    "\n",
    "        with tf.name_scope(\"fc-3\"):\n",
    "            W = tf.Variable(tf.truncated_normal([1024, num_classes], stddev=0.1), name=\"W\")\n",
    "            b = tf.Variable(tf.constant(0.1, shape=[num_classes]), name=\"b\")\n",
    "            l2_loss += tf.nn.l2_loss(W)\n",
    "            l2_loss += tf.nn.l2_loss(b)\n",
    "            self.scores = tf.nn.xw_plus_b(drop_2, W, b, name=\"output\")\n",
    "            self.predictions = tf.argmax(self.scores, 1, name=\"predictions\")\n",
    "            \n",
    "            \n",
    "        with tf.name_scope(\"loss\"):\n",
    "            losses = tf.nn.softmax_cross_entropy_with_logits(logits=self.scores, labels=self.input_y)\n",
    "            self.loss = tf.reduce_mean(losses) + l2_reg_lambda * l2_loss\n",
    "\n",
    "\n",
    "        with tf.name_scope(\"accuracy\"):\n",
    "            correct_predictions = tf.equal(self.predictions, tf.argmax(self.input_y, 1))\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"), name=\"accuracy\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#positive_data_file = \"data/amazon/book_pos.txt\"\n",
    "#negative_data_file = \"data/amazon/book_neg.txt\"\n",
    "positive_data_file = \"data/chABSA/pos.txt\"\n",
    "negative_data_file = \"data/chABSA/neg.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_and_labels(positive_data_file, negative_data_file, level=\"char\"):\n",
    "       \n",
    "    positive_examples = list(open(positive_data_file, \"r\").readlines())\n",
    "    negative_examples = list(open(negative_data_file, \"r\").readlines())\n",
    "    if level == \"char\":\n",
    "        positive_examples = [s.replace(\" \", \"\").replace(\"\", \" \").lower() for s in positive_examples]\n",
    "        negative_examples = [s.replace(\" \", \"\").replace(\"\", \" \").lower() for s in negative_examples]\n",
    "    elif level == \"word\":\n",
    "        positive_examples = [s.strip() for s in positive_examples]\n",
    "        negative_examples = [s.strip() for s in negative_examples]\n",
    "    else:\n",
    "        print(\"invaid value of 'level'. ('char' or 'word') \")\n",
    "        \n",
    "    x_text = positive_examples + negative_examples\n",
    "\n",
    "    positive_labels = [[0, 1] for _ in positive_examples]\n",
    "    negative_labels = [[1, 0] for _ in negative_examples]\n",
    "    y = np.concatenate([positive_labels, negative_labels], 0)\n",
    "    \n",
    "    return x_text, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"9bc3c622-56ce-4416-a5bf-25c37ca21684\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"9bc3c622-56ce-4416-a5bf-25c37ca21684\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify\n",
    "x_text, y = load_data_and_labels(positive_data_file, negative_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2830"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 当 連 結 会 計 年 度 の 世 界 経 済 は 、 米 国 を 中 心 に 景 気 は 概 ね 堅 調 に 推 移 し ま し た が 、 英 国 の e u 離 脱 問 題 に よ る 影 響 の ほ か 、 中 国 を は じ め と す る 新 興 国 経 済 の 減 速 懸 念 や 米 国 新 政 権 の 政 策 動 向 の 不 確 実 性 な ど 、 景 気 の 先 行 き は 不 透 明 な 状 況 が 続 き ま し た \\n '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_list = np.array([len(r)for r in x_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   length\n",
       "0     225\n",
       "1     107\n",
       "2     131\n",
       "3     137\n",
       "4     137"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(length_list, columns=[\"length\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2830.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>162.599293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>77.631221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>107.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>149.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>201.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>805.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            length\n",
       "count  2830.000000\n",
       "mean    162.599293\n",
       "std      77.631221\n",
       "min       5.000000\n",
       "25%     107.000000\n",
       "50%     149.000000\n",
       "75%     201.000000\n",
       "max     805.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x1c214ab390>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c2137be80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist(bins=50,figsize=(10,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_text = [x[:2000] if len(x) > 2000 else x for x in x_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2830.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>162.599293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>77.631221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>107.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>149.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>201.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>805.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            length\n",
       "count  2830.000000\n",
       "mean    162.599293\n",
       "std      77.631221\n",
       "min       5.000000\n",
       "25%     107.000000\n",
       "50%     149.000000\n",
       "75%     201.000000\n",
       "max     805.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_list = np.array([len(r)for r in x_text])\n",
    "df = pd.DataFrame(length_list, columns=[\"length\"])\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x1c214c0828>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c215596a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist(bins=50,figsize=(10,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "level = \"char\" #\"word\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max document length 805\n"
     ]
    }
   ],
   "source": [
    "if level == \"word\":\n",
    "    max_document_length = max([len(x.split(\" \")) for x in x_text])\n",
    "elif level == \"char\":\n",
    "    max_document_length = max([len(x) for x in x_text])\n",
    "print(\"max document length\", max_document_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-ef6c3fae6839>:1: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "WARNING:tensorflow:From /Users/tdual/anaconda2/envs/py3.6/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n"
     ]
    }
   ],
   "source": [
    "vocab_processor = preprocessing.VocabularyProcessor(max_document_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/tdual/anaconda2/envs/py3.6/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"27983e31-c233-4f77-a70c-57a9dc10ae1e\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"27983e31-c233-4f77-a70c-57a9dc10ae1e\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify\n",
    "x = np.array(list(vocab_processor.fit_transform(x_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_percentage = 0.1#0.0010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 1517\n",
      "Train/Test split: 2547/283\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"e97953b7-bfb8-45f8-8baa-7cec4d53e83f\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"e97953b7-bfb8-45f8-8baa-7cec4d53e83f\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify\n",
    "np.random.seed(10)\n",
    "shuffle_indices = np.random.permutation(np.arange(len(y)))\n",
    "x_shuffled = x[shuffle_indices]\n",
    "y_shuffled = y[shuffle_indices]\n",
    "\n",
    "test_sample_index = -1 * int(test_percentage * float(len(y)))\n",
    "x_train, x_test = x_shuffled[:test_sample_index], x_shuffled[test_sample_index:]\n",
    "y_train, y_test = y_shuffled[:test_sample_index], y_shuffled[test_sample_index:]\n",
    "\n",
    "#del x, y, x_shuffled, y_shuffled\n",
    "\n",
    "print(\"Vocabulary Size: {:d}\".format(len(vocab_processor.vocabulary_)))\n",
    "print(\"Train/Test split: {:d}/{:d}\".format(len(y_train), len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2547, 805)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle():\n",
    "    chunk_size =  int(len(x_train)/10)\n",
    "    print(chunk_size)\n",
    "    for i in range(0, len(x_train), chunck_size):\n",
    "        print(i)\n",
    "        end = i+chunck_size\n",
    "        if end < len(x_train):\n",
    "            chunk = x_train[i:  end]\n",
    "        else:\n",
    "            chunk = x_train[i:]\n",
    "            end = len(x_train)\n",
    "        with open(\"data/x_train_{}.pkl\".format(end), \"wb\") as f:\n",
    "            pickle.dump(chunk, f, protocol = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_x_train():\n",
    "    all_size = 999000\n",
    "    chunk_size = 99900\n",
    "    x_train =[]\n",
    "    for i in range(0, all_size, chunck_size):\n",
    "        print(i)\n",
    "        end = i+chunk_size\n",
    "        if end > len(reviews):\n",
    "            end = all_size\n",
    "        with open(\"data/x_train_{}.pkl\".format(end), \"rb\") as f:\n",
    "            x_train += pickle.load(f)\n",
    "        return x_train\n",
    "#x_train = load_x_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iter(data, batch_size, num_epochs, shuffle=True):\n",
    "    data = np.array(data)\n",
    "    data_size = len(data)\n",
    "    num_batches_per_epoch = int((len(data)-1)/batch_size) + 1\n",
    "    for epoch in range(num_epochs):\n",
    "        if shuffle:\n",
    "            shuffle_indices = np.random.permutation(np.arange(data_size))\n",
    "            shuffled_data = data[shuffle_indices]\n",
    "        else:\n",
    "            shuffled_data = data\n",
    "        for batch_num in range(num_batches_per_epoch):\n",
    "            start_index = batch_num * batch_size\n",
    "            end_index = min((batch_num + 1) * batch_size, data_size)\n",
    "            yield shuffled_data[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = x_train.shape[1]\n",
    "num_classes = y_train.shape[1]\n",
    "vocab_size = len(vocab_processor.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 32     \n",
    "filter_sizes = [2,3,4,5]    \n",
    "num_filters=128               \n",
    "dropout_keep_prob=0.5 \n",
    "l2_reg_lambda=0.0       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "WARNING:tensorflow:From <ipython-input-2-4c3c4a42c727>:71: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.TextCNN at 0x1c21783828>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextCNN(sequence_length, num_classes, vocab_size, embedding_size, filter_sizes, num_filters, l2_reg_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to /Users/tdual/Workspace/char_level_cnn/runs/1526189751\n",
      "\n"
     ]
    }
   ],
   "source": [
    "timestamp = str(int(time.time()))\n",
    "#timestamp = \"1525609926\"\n",
    "prefix = \"\"\n",
    "out_dir = os.path.abspath(os.path.join(os.path.curdir, \"runs\", timestamp, prefix))\n",
    "print(\"Writing to {}\\n\".format(out_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64                  \n",
    "num_epochs=200            \n",
    "evaluate_every=20         \n",
    "num_checkpoints=5\n",
    "learning_rate = 1e-3\n",
    "\n",
    "allow_soft_placement=True    \n",
    "log_device_placement=False  \n",
    "\n",
    "save_checkpoint = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "INFO:tensorflow:Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-2/W:0/grad/hist is illegal; using conv-maxpool-2/W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-2/W:0/grad/sparsity is illegal; using conv-maxpool-2/W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-2/b:0/grad/hist is illegal; using conv-maxpool-2/b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-2/b:0/grad/sparsity is illegal; using conv-maxpool-2/b_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name fc-1/W:0/grad/hist is illegal; using fc-1/W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name fc-1/W:0/grad/sparsity is illegal; using fc-1/W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name fc-1/b:0/grad/hist is illegal; using fc-1/b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name fc-1/b:0/grad/sparsity is illegal; using fc-1/b_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name fc-2/W:0/grad/hist is illegal; using fc-2/W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name fc-2/W:0/grad/sparsity is illegal; using fc-2/W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name fc-2/b:0/grad/hist is illegal; using fc-2/b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name fc-2/b:0/grad/sparsity is illegal; using fc-2/b_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name fc-3/W:0/grad/hist is illegal; using fc-3/W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name fc-3/W:0/grad/sparsity is illegal; using fc-3/W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name fc-3/b:0/grad/hist is illegal; using fc-3/b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name fc-3/b:0/grad/sparsity is illegal; using fc-3/b_0/grad/sparsity instead.\n",
      "2018-05-13T14:35:55.181943: step 1, loss 9.43353, acc 0.53125\n",
      "2018-05-13T14:35:55.611139: step 2, loss 9.0451, acc 0.53125\n",
      "2018-05-13T14:35:56.030556: step 3, loss 13.0487, acc 0.578125\n",
      "2018-05-13T14:35:56.439608: step 4, loss 9.94254, acc 0.4375\n",
      "2018-05-13T14:35:56.826840: step 5, loss 9.08664, acc 0.53125\n",
      "2018-05-13T14:35:57.207618: step 6, loss 13.9187, acc 0.46875\n",
      "2018-05-13T14:35:57.602836: step 7, loss 10.654, acc 0.5\n",
      "2018-05-13T14:35:58.001308: step 8, loss 11.2366, acc 0.625\n",
      "2018-05-13T14:35:58.371053: step 9, loss 9.22391, acc 0.609375\n",
      "2018-05-13T14:35:58.796021: step 10, loss 7.71649, acc 0.546875\n",
      "2018-05-13T14:35:59.195192: step 11, loss 10.2412, acc 0.453125\n",
      "2018-05-13T14:35:59.610837: step 12, loss 8.65538, acc 0.46875\n",
      "2018-05-13T14:36:00.020056: step 13, loss 6.32154, acc 0.640625\n",
      "2018-05-13T14:36:00.437064: step 14, loss 8.42512, acc 0.625\n",
      "2018-05-13T14:36:00.839557: step 15, loss 11.5707, acc 0.53125\n",
      "2018-05-13T14:36:01.231122: step 16, loss 6.72554, acc 0.546875\n",
      "2018-05-13T14:36:01.651505: step 17, loss 6.72128, acc 0.578125\n",
      "2018-05-13T14:36:02.052552: step 18, loss 8.9549, acc 0.4375\n",
      "2018-05-13T14:36:02.469775: step 19, loss 7.49573, acc 0.5\n",
      "2018-05-13T14:36:02.857362: step 20, loss 5.96147, acc 0.578125\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:36:03.341649: step 20, loss 1.24467, acc 0.657244\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-20\n",
      "\n",
      "2018-05-13T14:36:04.007622: step 21, loss 7.771, acc 0.53125\n",
      "2018-05-13T14:36:04.503169: step 22, loss 8.20433, acc 0.625\n",
      "2018-05-13T14:36:04.977800: step 23, loss 5.38735, acc 0.5625\n",
      "2018-05-13T14:36:05.457534: step 24, loss 4.9087, acc 0.625\n",
      "2018-05-13T14:36:05.933826: step 25, loss 4.42076, acc 0.609375\n",
      "2018-05-13T14:36:06.466842: step 26, loss 4.90376, acc 0.578125\n",
      "2018-05-13T14:36:06.963549: step 27, loss 5.70671, acc 0.53125\n",
      "2018-05-13T14:36:07.488804: step 28, loss 4.61104, acc 0.59375\n",
      "2018-05-13T14:36:07.982385: step 29, loss 3.99205, acc 0.53125\n",
      "2018-05-13T14:36:08.480279: step 30, loss 5.41229, acc 0.5625\n",
      "2018-05-13T14:36:09.044604: step 31, loss 3.30494, acc 0.640625\n",
      "2018-05-13T14:36:09.488727: step 32, loss 6.34138, acc 0.5\n",
      "2018-05-13T14:36:09.921262: step 33, loss 5.44751, acc 0.546875\n",
      "2018-05-13T14:36:10.355043: step 34, loss 5.30408, acc 0.4375\n",
      "2018-05-13T14:36:10.789890: step 35, loss 5.0193, acc 0.5\n",
      "2018-05-13T14:36:11.210663: step 36, loss 5.19194, acc 0.5\n",
      "2018-05-13T14:36:11.666435: step 37, loss 4.42558, acc 0.5625\n",
      "2018-05-13T14:36:12.191164: step 38, loss 4.06479, acc 0.546875\n",
      "2018-05-13T14:36:12.728856: step 39, loss 3.74068, acc 0.484375\n",
      "2018-05-13T14:36:13.148817: step 40, loss 3.91119, acc 0.509804\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:36:13.719287: step 40, loss 2.3794, acc 0.625442\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-40\n",
      "\n",
      "2018-05-13T14:36:14.371340: step 41, loss 4.86428, acc 0.5\n",
      "2018-05-13T14:36:14.874355: step 42, loss 3.84102, acc 0.59375\n",
      "2018-05-13T14:36:15.475336: step 43, loss 2.93435, acc 0.5625\n",
      "2018-05-13T14:36:15.956498: step 44, loss 2.94799, acc 0.515625\n",
      "2018-05-13T14:36:16.542702: step 45, loss 3.70453, acc 0.515625\n",
      "2018-05-13T14:36:17.056411: step 46, loss 2.94102, acc 0.484375\n",
      "2018-05-13T14:36:17.612068: step 47, loss 2.15107, acc 0.625\n",
      "2018-05-13T14:36:18.024490: step 48, loss 1.9201, acc 0.703125\n",
      "2018-05-13T14:36:18.460491: step 49, loss 2.40864, acc 0.59375\n",
      "2018-05-13T14:36:19.036741: step 50, loss 2.06007, acc 0.5625\n",
      "2018-05-13T14:36:19.529892: step 51, loss 3.70122, acc 0.5625\n",
      "2018-05-13T14:36:20.053907: step 52, loss 1.68477, acc 0.625\n",
      "2018-05-13T14:36:20.584649: step 53, loss 3.07465, acc 0.5\n",
      "2018-05-13T14:36:21.066783: step 54, loss 3.25069, acc 0.390625\n",
      "2018-05-13T14:36:21.569862: step 55, loss 2.20649, acc 0.625\n",
      "2018-05-13T14:36:22.072822: step 56, loss 2.07741, acc 0.640625\n",
      "2018-05-13T14:36:22.642281: step 57, loss 3.1316, acc 0.59375\n",
      "2018-05-13T14:36:23.071705: step 58, loss 1.25375, acc 0.703125\n",
      "2018-05-13T14:36:23.605891: step 59, loss 2.11663, acc 0.59375\n",
      "2018-05-13T14:36:24.089683: step 60, loss 1.73689, acc 0.59375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:36:24.654843: step 60, loss 0.655311, acc 0.64311\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-60\n",
      "\n",
      "2018-05-13T14:36:25.312751: step 61, loss 2.02045, acc 0.515625\n",
      "2018-05-13T14:36:25.821435: step 62, loss 1.94964, acc 0.59375\n",
      "2018-05-13T14:36:26.321887: step 63, loss 2.24346, acc 0.5625\n",
      "2018-05-13T14:36:26.790514: step 64, loss 1.89643, acc 0.46875\n",
      "2018-05-13T14:36:27.287894: step 65, loss 2.22255, acc 0.53125\n",
      "2018-05-13T14:36:27.823322: step 66, loss 2.05275, acc 0.5\n",
      "2018-05-13T14:36:28.347612: step 67, loss 1.94821, acc 0.5625\n",
      "2018-05-13T14:36:28.778112: step 68, loss 2.78832, acc 0.4375\n",
      "2018-05-13T14:36:29.274020: step 69, loss 1.52087, acc 0.59375\n",
      "2018-05-13T14:36:29.803442: step 70, loss 1.37512, acc 0.546875\n",
      "2018-05-13T14:36:30.286302: step 71, loss 1.29626, acc 0.59375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-13T14:36:30.688621: step 72, loss 1.56013, acc 0.46875\n",
      "2018-05-13T14:36:31.262610: step 73, loss 1.40701, acc 0.578125\n",
      "2018-05-13T14:36:31.769976: step 74, loss 1.40695, acc 0.59375\n",
      "2018-05-13T14:36:32.294869: step 75, loss 1.27674, acc 0.546875\n",
      "2018-05-13T14:36:32.828070: step 76, loss 1.73711, acc 0.484375\n",
      "2018-05-13T14:36:33.329704: step 77, loss 1.59753, acc 0.484375\n",
      "2018-05-13T14:36:33.819303: step 78, loss 0.81099, acc 0.6875\n",
      "2018-05-13T14:36:34.295513: step 79, loss 1.02549, acc 0.609375\n",
      "2018-05-13T14:36:34.754910: step 80, loss 1.01229, acc 0.647059\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:36:35.342546: step 80, loss 0.643042, acc 0.625442\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-80\n",
      "\n",
      "2018-05-13T14:36:36.022534: step 81, loss 1.09611, acc 0.53125\n",
      "2018-05-13T14:36:36.530257: step 82, loss 0.883207, acc 0.578125\n",
      "2018-05-13T14:36:36.990646: step 83, loss 1.11955, acc 0.59375\n",
      "2018-05-13T14:36:37.483777: step 84, loss 1.04013, acc 0.6875\n",
      "2018-05-13T14:36:37.996605: step 85, loss 1.41202, acc 0.546875\n",
      "2018-05-13T14:36:38.516444: step 86, loss 1.04328, acc 0.5\n",
      "2018-05-13T14:36:39.006431: step 87, loss 0.71403, acc 0.625\n",
      "2018-05-13T14:36:39.493197: step 88, loss 1.33216, acc 0.484375\n",
      "2018-05-13T14:36:39.898668: step 89, loss 0.969202, acc 0.625\n",
      "2018-05-13T14:36:40.360149: step 90, loss 0.879675, acc 0.65625\n",
      "2018-05-13T14:36:40.812460: step 91, loss 0.941578, acc 0.640625\n",
      "2018-05-13T14:36:41.264879: step 92, loss 1.33516, acc 0.4375\n",
      "2018-05-13T14:36:41.732365: step 93, loss 1.08602, acc 0.625\n",
      "2018-05-13T14:36:42.133755: step 94, loss 1.00212, acc 0.65625\n",
      "2018-05-13T14:36:42.617563: step 95, loss 0.864309, acc 0.578125\n",
      "2018-05-13T14:36:43.070612: step 96, loss 0.916319, acc 0.53125\n",
      "2018-05-13T14:36:43.560319: step 97, loss 0.855414, acc 0.578125\n",
      "2018-05-13T14:36:43.976777: step 98, loss 0.675125, acc 0.609375\n",
      "2018-05-13T14:36:44.543919: step 99, loss 0.820659, acc 0.625\n",
      "2018-05-13T14:36:45.028695: step 100, loss 0.904032, acc 0.71875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:36:45.577391: step 100, loss 0.573453, acc 0.70318\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-100\n",
      "\n",
      "2018-05-13T14:36:46.253325: step 101, loss 0.718213, acc 0.671875\n",
      "2018-05-13T14:36:46.745470: step 102, loss 0.877779, acc 0.65625\n",
      "2018-05-13T14:36:47.231166: step 103, loss 0.796595, acc 0.65625\n",
      "2018-05-13T14:36:47.739865: step 104, loss 0.808255, acc 0.65625\n",
      "2018-05-13T14:36:48.244257: step 105, loss 0.606192, acc 0.71875\n",
      "2018-05-13T14:36:48.788255: step 106, loss 1.08687, acc 0.515625\n",
      "2018-05-13T14:36:49.292919: step 107, loss 0.919561, acc 0.6875\n",
      "2018-05-13T14:36:49.779319: step 108, loss 0.830476, acc 0.625\n",
      "2018-05-13T14:36:50.322041: step 109, loss 0.862879, acc 0.578125\n",
      "2018-05-13T14:36:50.793628: step 110, loss 0.658125, acc 0.6875\n",
      "2018-05-13T14:36:51.238385: step 111, loss 0.571763, acc 0.734375\n",
      "2018-05-13T14:36:51.740393: step 112, loss 0.660086, acc 0.71875\n",
      "2018-05-13T14:36:52.196792: step 113, loss 0.508439, acc 0.71875\n",
      "2018-05-13T14:36:52.697641: step 114, loss 0.781334, acc 0.546875\n",
      "2018-05-13T14:36:53.182236: step 115, loss 0.734271, acc 0.625\n",
      "2018-05-13T14:36:53.671928: step 116, loss 0.657056, acc 0.65625\n",
      "2018-05-13T14:36:54.159476: step 117, loss 0.702645, acc 0.625\n",
      "2018-05-13T14:36:54.651284: step 118, loss 0.683013, acc 0.703125\n",
      "2018-05-13T14:36:55.127067: step 119, loss 0.796845, acc 0.578125\n",
      "2018-05-13T14:36:55.477349: step 120, loss 0.643754, acc 0.647059\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:36:56.019632: step 120, loss 0.505147, acc 0.731449\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-120\n",
      "\n",
      "2018-05-13T14:36:56.680995: step 121, loss 0.612661, acc 0.71875\n",
      "2018-05-13T14:36:57.128755: step 122, loss 0.598685, acc 0.640625\n",
      "2018-05-13T14:36:57.638342: step 123, loss 0.660934, acc 0.734375\n",
      "2018-05-13T14:36:58.166256: step 124, loss 0.693207, acc 0.59375\n",
      "2018-05-13T14:36:58.779683: step 125, loss 0.590984, acc 0.703125\n",
      "2018-05-13T14:36:59.254035: step 126, loss 0.610666, acc 0.734375\n",
      "2018-05-13T14:36:59.780303: step 127, loss 0.477194, acc 0.796875\n",
      "2018-05-13T14:37:00.258647: step 128, loss 0.629185, acc 0.671875\n",
      "2018-05-13T14:37:00.751660: step 129, loss 0.743569, acc 0.5\n",
      "2018-05-13T14:37:01.258935: step 130, loss 0.455286, acc 0.8125\n",
      "2018-05-13T14:37:01.754349: step 131, loss 0.672321, acc 0.671875\n",
      "2018-05-13T14:37:02.234274: step 132, loss 0.657957, acc 0.6875\n",
      "2018-05-13T14:37:02.714894: step 133, loss 0.542986, acc 0.703125\n",
      "2018-05-13T14:37:03.186282: step 134, loss 0.591509, acc 0.65625\n",
      "2018-05-13T14:37:03.755840: step 135, loss 0.726874, acc 0.53125\n",
      "2018-05-13T14:37:04.222096: step 136, loss 0.571051, acc 0.703125\n",
      "2018-05-13T14:37:04.730056: step 137, loss 0.563598, acc 0.765625\n",
      "2018-05-13T14:37:05.229018: step 138, loss 0.590654, acc 0.671875\n",
      "2018-05-13T14:37:05.765760: step 139, loss 0.679955, acc 0.546875\n",
      "2018-05-13T14:37:06.252445: step 140, loss 0.634873, acc 0.671875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:37:06.810660: step 140, loss 0.458465, acc 0.784452\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-140\n",
      "\n",
      "2018-05-13T14:37:07.487307: step 141, loss 0.596588, acc 0.734375\n",
      "2018-05-13T14:37:07.962028: step 142, loss 0.516706, acc 0.71875\n",
      "2018-05-13T14:37:08.468876: step 143, loss 0.610847, acc 0.671875\n",
      "2018-05-13T14:37:08.975763: step 144, loss 0.489253, acc 0.71875\n",
      "2018-05-13T14:37:09.473662: step 145, loss 0.49197, acc 0.765625\n",
      "2018-05-13T14:37:09.928901: step 146, loss 0.558765, acc 0.703125\n",
      "2018-05-13T14:37:10.405207: step 147, loss 0.54748, acc 0.71875\n",
      "2018-05-13T14:37:10.893429: step 148, loss 0.615214, acc 0.640625\n",
      "2018-05-13T14:37:11.370419: step 149, loss 0.561249, acc 0.671875\n",
      "2018-05-13T14:37:11.874018: step 150, loss 0.663623, acc 0.640625\n",
      "2018-05-13T14:37:12.387939: step 151, loss 0.442, acc 0.8125\n",
      "2018-05-13T14:37:12.917430: step 152, loss 0.501747, acc 0.75\n",
      "2018-05-13T14:37:13.437825: step 153, loss 0.500389, acc 0.703125\n",
      "2018-05-13T14:37:13.918755: step 154, loss 0.578612, acc 0.71875\n",
      "2018-05-13T14:37:14.412767: step 155, loss 0.547343, acc 0.703125\n",
      "2018-05-13T14:37:15.046329: step 156, loss 0.487192, acc 0.75\n",
      "2018-05-13T14:37:15.639968: step 157, loss 0.546233, acc 0.6875\n",
      "2018-05-13T14:37:16.096860: step 158, loss 0.510182, acc 0.734375\n",
      "2018-05-13T14:37:16.610470: step 159, loss 0.689438, acc 0.703125\n",
      "2018-05-13T14:37:16.985610: step 160, loss 0.411214, acc 0.784314\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:37:17.494686: step 160, loss 0.403615, acc 0.823322\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-160\n",
      "\n",
      "2018-05-13T14:37:18.159654: step 161, loss 0.512843, acc 0.734375\n",
      "2018-05-13T14:37:18.662954: step 162, loss 0.39875, acc 0.8125\n",
      "2018-05-13T14:37:19.155093: step 163, loss 0.638178, acc 0.703125\n",
      "2018-05-13T14:37:19.663446: step 164, loss 0.491239, acc 0.75\n",
      "2018-05-13T14:37:20.091626: step 165, loss 0.674057, acc 0.609375\n",
      "2018-05-13T14:37:20.597057: step 166, loss 0.500789, acc 0.734375\n",
      "2018-05-13T14:37:21.055959: step 167, loss 0.45506, acc 0.734375\n",
      "2018-05-13T14:37:21.522738: step 168, loss 0.55068, acc 0.671875\n",
      "2018-05-13T14:37:22.055445: step 169, loss 0.465079, acc 0.765625\n",
      "2018-05-13T14:37:22.606780: step 170, loss 0.529282, acc 0.671875\n",
      "2018-05-13T14:37:23.107256: step 171, loss 0.414466, acc 0.796875\n",
      "2018-05-13T14:37:23.569145: step 172, loss 0.512192, acc 0.796875\n",
      "2018-05-13T14:37:24.080101: step 173, loss 0.43967, acc 0.765625\n",
      "2018-05-13T14:37:24.600808: step 174, loss 0.504605, acc 0.765625\n",
      "2018-05-13T14:37:25.074389: step 175, loss 0.52034, acc 0.6875\n",
      "2018-05-13T14:37:25.543095: step 176, loss 0.467027, acc 0.78125\n",
      "2018-05-13T14:37:25.969334: step 177, loss 0.542105, acc 0.703125\n",
      "2018-05-13T14:37:26.405641: step 178, loss 0.458784, acc 0.796875\n",
      "2018-05-13T14:37:26.866396: step 179, loss 0.416461, acc 0.75\n",
      "2018-05-13T14:37:27.302070: step 180, loss 0.480059, acc 0.765625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:37:27.742707: step 180, loss 0.385945, acc 0.833922\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-180\n",
      "\n",
      "2018-05-13T14:37:28.409100: step 181, loss 0.430046, acc 0.78125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-13T14:37:28.878146: step 182, loss 0.46464, acc 0.734375\n",
      "2018-05-13T14:37:29.350841: step 183, loss 0.435622, acc 0.78125\n",
      "2018-05-13T14:37:29.849270: step 184, loss 0.544593, acc 0.734375\n",
      "2018-05-13T14:37:30.356004: step 185, loss 0.412175, acc 0.875\n",
      "2018-05-13T14:37:30.874637: step 186, loss 0.52001, acc 0.765625\n",
      "2018-05-13T14:37:31.453548: step 187, loss 0.440029, acc 0.78125\n",
      "2018-05-13T14:37:31.974443: step 188, loss 0.612741, acc 0.671875\n",
      "2018-05-13T14:37:32.485961: step 189, loss 0.448835, acc 0.828125\n",
      "2018-05-13T14:37:32.979084: step 190, loss 0.488954, acc 0.78125\n",
      "2018-05-13T14:37:33.471455: step 191, loss 0.348694, acc 0.875\n",
      "2018-05-13T14:37:33.949905: step 192, loss 0.433376, acc 0.75\n",
      "2018-05-13T14:37:34.491770: step 193, loss 0.424301, acc 0.71875\n",
      "2018-05-13T14:37:34.989321: step 194, loss 0.398889, acc 0.765625\n",
      "2018-05-13T14:37:35.503076: step 195, loss 0.509166, acc 0.75\n",
      "2018-05-13T14:37:35.984568: step 196, loss 0.433085, acc 0.828125\n",
      "2018-05-13T14:37:36.478586: step 197, loss 0.515718, acc 0.796875\n",
      "2018-05-13T14:37:36.956802: step 198, loss 0.542117, acc 0.71875\n",
      "2018-05-13T14:37:37.470552: step 199, loss 0.461069, acc 0.796875\n",
      "2018-05-13T14:37:37.829076: step 200, loss 0.348738, acc 0.862745\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:37:38.373360: step 200, loss 0.360618, acc 0.837456\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-200\n",
      "\n",
      "2018-05-13T14:37:39.060953: step 201, loss 0.306712, acc 0.84375\n",
      "2018-05-13T14:37:39.593319: step 202, loss 0.384109, acc 0.796875\n",
      "2018-05-13T14:37:40.078066: step 203, loss 0.376365, acc 0.875\n",
      "2018-05-13T14:37:40.567661: step 204, loss 0.545176, acc 0.65625\n",
      "2018-05-13T14:37:41.054655: step 205, loss 0.383463, acc 0.859375\n",
      "2018-05-13T14:37:41.565026: step 206, loss 0.381773, acc 0.859375\n",
      "2018-05-13T14:37:41.984709: step 207, loss 0.393864, acc 0.78125\n",
      "2018-05-13T14:37:42.499508: step 208, loss 0.461714, acc 0.75\n",
      "2018-05-13T14:37:42.996783: step 209, loss 0.453103, acc 0.78125\n",
      "2018-05-13T14:37:43.488988: step 210, loss 0.376523, acc 0.828125\n",
      "2018-05-13T14:37:43.967004: step 211, loss 0.365682, acc 0.859375\n",
      "2018-05-13T14:37:44.434675: step 212, loss 0.42374, acc 0.828125\n",
      "2018-05-13T14:37:44.902604: step 213, loss 0.387669, acc 0.828125\n",
      "2018-05-13T14:37:45.394690: step 214, loss 0.473643, acc 0.828125\n",
      "2018-05-13T14:37:45.831833: step 215, loss 0.292551, acc 0.890625\n",
      "2018-05-13T14:37:46.325598: step 216, loss 0.263645, acc 0.921875\n",
      "2018-05-13T14:37:46.843775: step 217, loss 0.412744, acc 0.828125\n",
      "2018-05-13T14:37:47.319604: step 218, loss 0.41068, acc 0.78125\n",
      "2018-05-13T14:37:47.794116: step 219, loss 0.415737, acc 0.765625\n",
      "2018-05-13T14:37:48.272095: step 220, loss 0.419472, acc 0.8125\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:37:48.743838: step 220, loss 0.344085, acc 0.830389\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-220\n",
      "\n",
      "2018-05-13T14:37:49.433702: step 221, loss 0.382994, acc 0.78125\n",
      "2018-05-13T14:37:49.900085: step 222, loss 0.457236, acc 0.796875\n",
      "2018-05-13T14:37:50.411066: step 223, loss 0.437387, acc 0.765625\n",
      "2018-05-13T14:37:50.897023: step 224, loss 0.413017, acc 0.84375\n",
      "2018-05-13T14:37:51.473398: step 225, loss 0.456131, acc 0.796875\n",
      "2018-05-13T14:37:52.005486: step 226, loss 0.529331, acc 0.734375\n",
      "2018-05-13T14:37:52.485583: step 227, loss 0.31253, acc 0.875\n",
      "2018-05-13T14:37:52.947382: step 228, loss 0.383046, acc 0.828125\n",
      "2018-05-13T14:37:53.472737: step 229, loss 0.396783, acc 0.859375\n",
      "2018-05-13T14:37:53.956919: step 230, loss 0.374048, acc 0.875\n",
      "2018-05-13T14:37:54.399674: step 231, loss 0.394721, acc 0.875\n",
      "2018-05-13T14:37:54.905953: step 232, loss 0.426401, acc 0.828125\n",
      "2018-05-13T14:37:55.409081: step 233, loss 0.381367, acc 0.828125\n",
      "2018-05-13T14:37:55.857078: step 234, loss 0.402071, acc 0.796875\n",
      "2018-05-13T14:37:56.330569: step 235, loss 0.556105, acc 0.734375\n",
      "2018-05-13T14:37:56.788881: step 236, loss 0.393227, acc 0.8125\n",
      "2018-05-13T14:37:57.280631: step 237, loss 0.338959, acc 0.84375\n",
      "2018-05-13T14:37:57.771843: step 238, loss 0.404419, acc 0.859375\n",
      "2018-05-13T14:37:58.245131: step 239, loss 0.558575, acc 0.765625\n",
      "2018-05-13T14:37:58.670752: step 240, loss 0.303791, acc 0.843137\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:37:59.135326: step 240, loss 0.336034, acc 0.844523\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-240\n",
      "\n",
      "2018-05-13T14:37:59.777807: step 241, loss 0.408327, acc 0.84375\n",
      "2018-05-13T14:38:00.253637: step 242, loss 0.3241, acc 0.828125\n",
      "2018-05-13T14:38:00.730501: step 243, loss 0.314504, acc 0.859375\n",
      "2018-05-13T14:38:01.210926: step 244, loss 0.397503, acc 0.875\n",
      "2018-05-13T14:38:01.689262: step 245, loss 0.465702, acc 0.78125\n",
      "2018-05-13T14:38:02.231977: step 246, loss 0.455422, acc 0.84375\n",
      "2018-05-13T14:38:02.761228: step 247, loss 0.299699, acc 0.890625\n",
      "2018-05-13T14:38:03.252089: step 248, loss 0.330866, acc 0.828125\n",
      "2018-05-13T14:38:03.777541: step 249, loss 0.366341, acc 0.828125\n",
      "2018-05-13T14:38:04.247095: step 250, loss 0.410132, acc 0.796875\n",
      "2018-05-13T14:38:04.750813: step 251, loss 0.353594, acc 0.84375\n",
      "2018-05-13T14:38:05.193322: step 252, loss 0.471429, acc 0.8125\n",
      "2018-05-13T14:38:05.664203: step 253, loss 0.436991, acc 0.796875\n",
      "2018-05-13T14:38:06.083574: step 254, loss 0.351373, acc 0.84375\n",
      "2018-05-13T14:38:06.544807: step 255, loss 0.401715, acc 0.8125\n",
      "2018-05-13T14:38:07.018347: step 256, loss 0.420851, acc 0.8125\n",
      "2018-05-13T14:38:07.486479: step 257, loss 0.340347, acc 0.859375\n",
      "2018-05-13T14:38:07.968027: step 258, loss 0.477511, acc 0.828125\n",
      "2018-05-13T14:38:08.487974: step 259, loss 0.439748, acc 0.796875\n",
      "2018-05-13T14:38:08.957031: step 260, loss 0.277886, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:38:09.419006: step 260, loss 0.327957, acc 0.869258\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-260\n",
      "\n",
      "2018-05-13T14:38:10.125946: step 261, loss 0.382115, acc 0.84375\n",
      "2018-05-13T14:38:10.623106: step 262, loss 0.334976, acc 0.875\n",
      "2018-05-13T14:38:11.068321: step 263, loss 0.460551, acc 0.765625\n",
      "2018-05-13T14:38:11.528014: step 264, loss 0.39997, acc 0.8125\n",
      "2018-05-13T14:38:12.062758: step 265, loss 0.383513, acc 0.828125\n",
      "2018-05-13T14:38:12.509578: step 266, loss 0.373021, acc 0.796875\n",
      "2018-05-13T14:38:12.961656: step 267, loss 0.44295, acc 0.75\n",
      "2018-05-13T14:38:13.425289: step 268, loss 0.414036, acc 0.875\n",
      "2018-05-13T14:38:13.884884: step 269, loss 0.376608, acc 0.78125\n",
      "2018-05-13T14:38:14.346467: step 270, loss 0.34989, acc 0.8125\n",
      "2018-05-13T14:38:14.840187: step 271, loss 0.411971, acc 0.78125\n",
      "2018-05-13T14:38:15.333848: step 272, loss 0.380565, acc 0.859375\n",
      "2018-05-13T14:38:15.817215: step 273, loss 0.375525, acc 0.828125\n",
      "2018-05-13T14:38:16.289563: step 274, loss 0.318043, acc 0.84375\n",
      "2018-05-13T14:38:16.775792: step 275, loss 0.423141, acc 0.765625\n",
      "2018-05-13T14:38:17.245022: step 276, loss 0.411083, acc 0.78125\n",
      "2018-05-13T14:38:17.747691: step 277, loss 0.510621, acc 0.78125\n",
      "2018-05-13T14:38:18.205693: step 278, loss 0.363575, acc 0.84375\n",
      "2018-05-13T14:38:18.685613: step 279, loss 0.44599, acc 0.765625\n",
      "2018-05-13T14:38:19.089077: step 280, loss 0.312463, acc 0.862745\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:38:19.551161: step 280, loss 0.330744, acc 0.862191\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-280\n",
      "\n",
      "2018-05-13T14:38:20.230280: step 281, loss 0.48523, acc 0.78125\n",
      "2018-05-13T14:38:20.741366: step 282, loss 0.493218, acc 0.75\n",
      "2018-05-13T14:38:21.208985: step 283, loss 0.433436, acc 0.828125\n",
      "2018-05-13T14:38:21.659506: step 284, loss 0.435596, acc 0.734375\n",
      "2018-05-13T14:38:22.161973: step 285, loss 0.326037, acc 0.859375\n",
      "2018-05-13T14:38:22.694063: step 286, loss 0.355193, acc 0.90625\n",
      "2018-05-13T14:38:23.167154: step 287, loss 0.305663, acc 0.890625\n",
      "2018-05-13T14:38:23.639812: step 288, loss 0.485846, acc 0.765625\n",
      "2018-05-13T14:38:24.098646: step 289, loss 0.485919, acc 0.828125\n",
      "2018-05-13T14:38:24.622000: step 290, loss 0.436458, acc 0.765625\n",
      "2018-05-13T14:38:25.103081: step 291, loss 0.415242, acc 0.78125\n",
      "2018-05-13T14:38:25.610391: step 292, loss 0.494779, acc 0.796875\n",
      "2018-05-13T14:38:26.088858: step 293, loss 0.540181, acc 0.71875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-13T14:38:26.582099: step 294, loss 0.474366, acc 0.78125\n",
      "2018-05-13T14:38:27.068995: step 295, loss 0.275262, acc 0.859375\n",
      "2018-05-13T14:38:27.596253: step 296, loss 0.510578, acc 0.71875\n",
      "2018-05-13T14:38:28.139105: step 297, loss 0.564638, acc 0.75\n",
      "2018-05-13T14:38:28.645400: step 298, loss 0.461016, acc 0.828125\n",
      "2018-05-13T14:38:29.139843: step 299, loss 0.397684, acc 0.765625\n",
      "2018-05-13T14:38:29.653121: step 300, loss 0.36219, acc 0.828125\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:38:30.165923: step 300, loss 0.374223, acc 0.844523\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-300\n",
      "\n",
      "2018-05-13T14:38:30.854395: step 301, loss 0.504356, acc 0.796875\n",
      "2018-05-13T14:38:31.398179: step 302, loss 0.355497, acc 0.84375\n",
      "2018-05-13T14:38:31.909474: step 303, loss 0.435989, acc 0.8125\n",
      "2018-05-13T14:38:32.395707: step 304, loss 0.467738, acc 0.8125\n",
      "2018-05-13T14:38:32.797077: step 305, loss 0.464972, acc 0.75\n",
      "2018-05-13T14:38:33.195779: step 306, loss 0.312956, acc 0.859375\n",
      "2018-05-13T14:38:33.579806: step 307, loss 0.387741, acc 0.859375\n",
      "2018-05-13T14:38:33.994953: step 308, loss 0.41642, acc 0.75\n",
      "2018-05-13T14:38:34.401284: step 309, loss 0.396431, acc 0.796875\n",
      "2018-05-13T14:38:34.790083: step 310, loss 0.393414, acc 0.796875\n",
      "2018-05-13T14:38:35.154165: step 311, loss 0.37221, acc 0.78125\n",
      "2018-05-13T14:38:35.569614: step 312, loss 0.351076, acc 0.875\n",
      "2018-05-13T14:38:36.092515: step 313, loss 0.312653, acc 0.84375\n",
      "2018-05-13T14:38:36.572003: step 314, loss 0.357394, acc 0.84375\n",
      "2018-05-13T14:38:37.064750: step 315, loss 0.369781, acc 0.828125\n",
      "2018-05-13T14:38:37.580549: step 316, loss 0.331738, acc 0.84375\n",
      "2018-05-13T14:38:38.097757: step 317, loss 0.340539, acc 0.828125\n",
      "2018-05-13T14:38:38.586171: step 318, loss 0.38534, acc 0.84375\n",
      "2018-05-13T14:38:39.054638: step 319, loss 0.260595, acc 0.890625\n",
      "2018-05-13T14:38:39.452285: step 320, loss 0.287907, acc 0.882353\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:38:39.950520: step 320, loss 0.335032, acc 0.85159\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-320\n",
      "\n",
      "2018-05-13T14:38:40.497833: step 321, loss 0.437714, acc 0.8125\n",
      "2018-05-13T14:38:40.958259: step 322, loss 0.361151, acc 0.84375\n",
      "2018-05-13T14:38:41.453467: step 323, loss 0.384631, acc 0.796875\n",
      "2018-05-13T14:38:41.869450: step 324, loss 0.235909, acc 0.90625\n",
      "2018-05-13T14:38:42.272173: step 325, loss 0.340231, acc 0.875\n",
      "2018-05-13T14:38:42.634249: step 326, loss 0.377813, acc 0.828125\n",
      "2018-05-13T14:38:43.023113: step 327, loss 0.459597, acc 0.765625\n",
      "2018-05-13T14:38:43.484283: step 328, loss 0.299531, acc 0.84375\n",
      "2018-05-13T14:38:43.949293: step 329, loss 0.314331, acc 0.890625\n",
      "2018-05-13T14:38:44.461771: step 330, loss 0.409785, acc 0.828125\n",
      "2018-05-13T14:38:44.980327: step 331, loss 0.500991, acc 0.75\n",
      "2018-05-13T14:38:45.433751: step 332, loss 0.384189, acc 0.828125\n",
      "2018-05-13T14:38:45.953248: step 333, loss 0.339674, acc 0.859375\n",
      "2018-05-13T14:38:46.435409: step 334, loss 0.310302, acc 0.8125\n",
      "2018-05-13T14:38:46.871501: step 335, loss 0.276692, acc 0.875\n",
      "2018-05-13T14:38:47.336312: step 336, loss 0.404057, acc 0.78125\n",
      "2018-05-13T14:38:47.788326: step 337, loss 0.218241, acc 0.953125\n",
      "2018-05-13T14:38:48.323032: step 338, loss 0.28947, acc 0.859375\n",
      "2018-05-13T14:38:48.842581: step 339, loss 0.394169, acc 0.8125\n",
      "2018-05-13T14:38:49.292116: step 340, loss 0.255444, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:38:49.885238: step 340, loss 0.328108, acc 0.865724\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-340\n",
      "\n",
      "2018-05-13T14:38:50.534483: step 341, loss 0.281672, acc 0.859375\n",
      "2018-05-13T14:38:51.048701: step 342, loss 0.375861, acc 0.859375\n",
      "2018-05-13T14:38:51.547364: step 343, loss 0.304189, acc 0.90625\n",
      "2018-05-13T14:38:52.083003: step 344, loss 0.349229, acc 0.875\n",
      "2018-05-13T14:38:52.622693: step 345, loss 0.301305, acc 0.90625\n",
      "2018-05-13T14:38:53.126466: step 346, loss 0.387712, acc 0.84375\n",
      "2018-05-13T14:38:53.643773: step 347, loss 0.279438, acc 0.859375\n",
      "2018-05-13T14:38:54.201231: step 348, loss 0.542581, acc 0.703125\n",
      "2018-05-13T14:38:54.764160: step 349, loss 0.45462, acc 0.78125\n",
      "2018-05-13T14:38:55.276076: step 350, loss 0.300176, acc 0.859375\n",
      "2018-05-13T14:38:55.863220: step 351, loss 0.347119, acc 0.828125\n",
      "2018-05-13T14:38:56.399399: step 352, loss 0.384906, acc 0.796875\n",
      "2018-05-13T14:38:56.901370: step 353, loss 0.422389, acc 0.8125\n",
      "2018-05-13T14:38:57.315053: step 354, loss 0.375262, acc 0.84375\n",
      "2018-05-13T14:38:57.815088: step 355, loss 0.416988, acc 0.8125\n",
      "2018-05-13T14:38:58.327257: step 356, loss 0.39927, acc 0.828125\n",
      "2018-05-13T14:38:58.831930: step 357, loss 0.343111, acc 0.859375\n",
      "2018-05-13T14:38:59.354553: step 358, loss 0.269332, acc 0.859375\n",
      "2018-05-13T14:38:59.824004: step 359, loss 0.495777, acc 0.78125\n",
      "2018-05-13T14:39:00.265871: step 360, loss 0.488021, acc 0.705882\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:39:00.817121: step 360, loss 0.329185, acc 0.85159\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-360\n",
      "\n",
      "2018-05-13T14:39:01.483960: step 361, loss 0.355853, acc 0.78125\n",
      "2018-05-13T14:39:02.005735: step 362, loss 0.357495, acc 0.78125\n",
      "2018-05-13T14:39:02.493021: step 363, loss 0.440093, acc 0.734375\n",
      "2018-05-13T14:39:02.970261: step 364, loss 0.333262, acc 0.84375\n",
      "2018-05-13T14:39:03.474638: step 365, loss 0.380723, acc 0.828125\n",
      "2018-05-13T14:39:03.974726: step 366, loss 0.404168, acc 0.796875\n",
      "2018-05-13T14:39:04.485609: step 367, loss 0.311262, acc 0.890625\n",
      "2018-05-13T14:39:04.998539: step 368, loss 0.416092, acc 0.8125\n",
      "2018-05-13T14:39:05.541768: step 369, loss 0.27637, acc 0.875\n",
      "2018-05-13T14:39:06.008995: step 370, loss 0.294209, acc 0.90625\n",
      "2018-05-13T14:39:06.530862: step 371, loss 0.440466, acc 0.8125\n",
      "2018-05-13T14:39:07.028990: step 372, loss 0.320835, acc 0.859375\n",
      "2018-05-13T14:39:07.537981: step 373, loss 0.402047, acc 0.796875\n",
      "2018-05-13T14:39:08.055642: step 374, loss 0.476091, acc 0.765625\n",
      "2018-05-13T14:39:08.554278: step 375, loss 0.406214, acc 0.890625\n",
      "2018-05-13T14:39:09.075636: step 376, loss 0.333946, acc 0.796875\n",
      "2018-05-13T14:39:09.600186: step 377, loss 0.284648, acc 0.859375\n",
      "2018-05-13T14:39:10.126666: step 378, loss 0.283083, acc 0.859375\n",
      "2018-05-13T14:39:10.597720: step 379, loss 0.440915, acc 0.765625\n",
      "2018-05-13T14:39:10.996727: step 380, loss 0.370864, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:39:11.423024: step 380, loss 0.315237, acc 0.858657\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-380\n",
      "\n",
      "2018-05-13T14:39:12.157426: step 381, loss 0.397744, acc 0.796875\n",
      "2018-05-13T14:39:12.634957: step 382, loss 0.462726, acc 0.8125\n",
      "2018-05-13T14:39:13.159347: step 383, loss 0.310432, acc 0.90625\n",
      "2018-05-13T14:39:13.666492: step 384, loss 0.332151, acc 0.875\n",
      "2018-05-13T14:39:14.151978: step 385, loss 0.332621, acc 0.859375\n",
      "2018-05-13T14:39:14.650670: step 386, loss 0.402519, acc 0.796875\n",
      "2018-05-13T14:39:15.187280: step 387, loss 0.293046, acc 0.859375\n",
      "2018-05-13T14:39:15.728507: step 388, loss 0.354124, acc 0.84375\n",
      "2018-05-13T14:39:16.179998: step 389, loss 0.337482, acc 0.828125\n",
      "2018-05-13T14:39:16.693908: step 390, loss 0.446315, acc 0.796875\n",
      "2018-05-13T14:39:17.202446: step 391, loss 0.362894, acc 0.828125\n",
      "2018-05-13T14:39:17.636402: step 392, loss 0.386718, acc 0.84375\n",
      "2018-05-13T14:39:18.123301: step 393, loss 0.311825, acc 0.796875\n",
      "2018-05-13T14:39:18.602036: step 394, loss 0.311811, acc 0.828125\n",
      "2018-05-13T14:39:19.108658: step 395, loss 0.418065, acc 0.8125\n",
      "2018-05-13T14:39:19.583960: step 396, loss 0.420092, acc 0.8125\n",
      "2018-05-13T14:39:20.129670: step 397, loss 0.446932, acc 0.78125\n",
      "2018-05-13T14:39:20.644001: step 398, loss 0.240977, acc 0.90625\n",
      "2018-05-13T14:39:21.174334: step 399, loss 0.321801, acc 0.875\n",
      "2018-05-13T14:39:21.574884: step 400, loss 0.286177, acc 0.901961\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:39:22.199263: step 400, loss 0.306563, acc 0.879859\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-400\n",
      "\n",
      "2018-05-13T14:39:22.920379: step 401, loss 0.364686, acc 0.828125\n",
      "2018-05-13T14:39:23.418147: step 402, loss 0.274621, acc 0.90625\n",
      "2018-05-13T14:39:23.913170: step 403, loss 0.373867, acc 0.84375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-13T14:39:24.408362: step 404, loss 0.36273, acc 0.8125\n",
      "2018-05-13T14:39:24.863011: step 405, loss 0.292089, acc 0.875\n",
      "2018-05-13T14:39:25.358653: step 406, loss 0.370709, acc 0.8125\n",
      "2018-05-13T14:39:25.823076: step 407, loss 0.317014, acc 0.859375\n",
      "2018-05-13T14:39:26.284677: step 408, loss 0.318071, acc 0.8125\n",
      "2018-05-13T14:39:26.728436: step 409, loss 0.294767, acc 0.890625\n",
      "2018-05-13T14:39:27.203946: step 410, loss 0.292449, acc 0.90625\n",
      "2018-05-13T14:39:27.693077: step 411, loss 0.289691, acc 0.84375\n",
      "2018-05-13T14:39:28.172692: step 412, loss 0.327099, acc 0.859375\n",
      "2018-05-13T14:39:28.692822: step 413, loss 0.315276, acc 0.84375\n",
      "2018-05-13T14:39:29.157891: step 414, loss 0.328864, acc 0.8125\n",
      "2018-05-13T14:39:29.622997: step 415, loss 0.24836, acc 0.875\n",
      "2018-05-13T14:39:30.138843: step 416, loss 0.40739, acc 0.8125\n",
      "2018-05-13T14:39:30.658192: step 417, loss 0.304224, acc 0.859375\n",
      "2018-05-13T14:39:31.115094: step 418, loss 0.35638, acc 0.84375\n",
      "2018-05-13T14:39:31.584268: step 419, loss 0.35477, acc 0.84375\n",
      "2018-05-13T14:39:32.163357: step 420, loss 0.29782, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:39:32.775352: step 420, loss 0.303504, acc 0.872792\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-420\n",
      "\n",
      "2018-05-13T14:39:33.490358: step 421, loss 0.359666, acc 0.84375\n",
      "2018-05-13T14:39:33.948764: step 422, loss 0.439707, acc 0.78125\n",
      "2018-05-13T14:39:34.442046: step 423, loss 0.282307, acc 0.90625\n",
      "2018-05-13T14:39:34.831088: step 424, loss 0.2894, acc 0.859375\n",
      "2018-05-13T14:39:35.214677: step 425, loss 0.339863, acc 0.84375\n",
      "2018-05-13T14:39:35.584155: step 426, loss 0.402272, acc 0.84375\n",
      "2018-05-13T14:39:35.975263: step 427, loss 0.24627, acc 0.921875\n",
      "2018-05-13T14:39:36.362903: step 428, loss 0.276942, acc 0.859375\n",
      "2018-05-13T14:39:36.766254: step 429, loss 0.258232, acc 0.921875\n",
      "2018-05-13T14:39:37.169726: step 430, loss 0.371573, acc 0.8125\n",
      "2018-05-13T14:39:37.544689: step 431, loss 0.316182, acc 0.875\n",
      "2018-05-13T14:39:37.936049: step 432, loss 0.280003, acc 0.859375\n",
      "2018-05-13T14:39:38.334018: step 433, loss 0.512453, acc 0.765625\n",
      "2018-05-13T14:39:38.757257: step 434, loss 0.322834, acc 0.828125\n",
      "2018-05-13T14:39:39.175111: step 435, loss 0.429241, acc 0.796875\n",
      "2018-05-13T14:39:39.577177: step 436, loss 0.282584, acc 0.90625\n",
      "2018-05-13T14:39:39.977669: step 437, loss 0.271323, acc 0.890625\n",
      "2018-05-13T14:39:40.396462: step 438, loss 0.250013, acc 0.90625\n",
      "2018-05-13T14:39:40.771827: step 439, loss 0.295955, acc 0.84375\n",
      "2018-05-13T14:39:41.085805: step 440, loss 0.182542, acc 0.941176\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:39:41.608636: step 440, loss 0.275772, acc 0.886926\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-440\n",
      "\n",
      "2018-05-13T14:39:42.202831: step 441, loss 0.313092, acc 0.859375\n",
      "2018-05-13T14:39:42.614470: step 442, loss 0.374482, acc 0.84375\n",
      "2018-05-13T14:39:43.017474: step 443, loss 0.326972, acc 0.84375\n",
      "2018-05-13T14:39:43.415447: step 444, loss 0.217014, acc 0.921875\n",
      "2018-05-13T14:39:43.846375: step 445, loss 0.31515, acc 0.890625\n",
      "2018-05-13T14:39:44.350778: step 446, loss 0.271137, acc 0.90625\n",
      "2018-05-13T14:39:44.821762: step 447, loss 0.30116, acc 0.875\n",
      "2018-05-13T14:39:45.305303: step 448, loss 0.263263, acc 0.875\n",
      "2018-05-13T14:39:45.796958: step 449, loss 0.413012, acc 0.8125\n",
      "2018-05-13T14:39:46.249077: step 450, loss 0.263262, acc 0.875\n",
      "2018-05-13T14:39:46.711549: step 451, loss 0.321633, acc 0.859375\n",
      "2018-05-13T14:39:47.218213: step 452, loss 0.273803, acc 0.875\n",
      "2018-05-13T14:39:47.712269: step 453, loss 0.211365, acc 0.921875\n",
      "2018-05-13T14:39:48.205289: step 454, loss 0.245685, acc 0.875\n",
      "2018-05-13T14:39:48.698533: step 455, loss 0.32483, acc 0.875\n",
      "2018-05-13T14:39:49.169835: step 456, loss 0.32046, acc 0.859375\n",
      "2018-05-13T14:39:49.673608: step 457, loss 0.33836, acc 0.84375\n",
      "2018-05-13T14:39:50.160122: step 458, loss 0.183979, acc 0.953125\n",
      "2018-05-13T14:39:50.662057: step 459, loss 0.283229, acc 0.875\n",
      "2018-05-13T14:39:51.158244: step 460, loss 0.311022, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:39:51.741673: step 460, loss 0.28333, acc 0.876325\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-460\n",
      "\n",
      "2018-05-13T14:39:52.410647: step 461, loss 0.213137, acc 0.90625\n",
      "2018-05-13T14:39:52.866594: step 462, loss 0.254017, acc 0.890625\n",
      "2018-05-13T14:39:53.338599: step 463, loss 0.353988, acc 0.8125\n",
      "2018-05-13T14:39:53.814832: step 464, loss 0.275769, acc 0.859375\n",
      "2018-05-13T14:39:54.332858: step 465, loss 0.243292, acc 0.890625\n",
      "2018-05-13T14:39:54.742494: step 466, loss 0.362805, acc 0.875\n",
      "2018-05-13T14:39:55.203183: step 467, loss 0.20036, acc 0.9375\n",
      "2018-05-13T14:39:55.702547: step 468, loss 0.305995, acc 0.890625\n",
      "2018-05-13T14:39:56.154773: step 469, loss 0.38532, acc 0.828125\n",
      "2018-05-13T14:39:56.642777: step 470, loss 0.227202, acc 0.875\n",
      "2018-05-13T14:39:57.139625: step 471, loss 0.298197, acc 0.875\n",
      "2018-05-13T14:39:57.630085: step 472, loss 0.403724, acc 0.828125\n",
      "2018-05-13T14:39:57.984098: step 473, loss 0.326126, acc 0.84375\n",
      "2018-05-13T14:39:58.355788: step 474, loss 0.276419, acc 0.828125\n",
      "2018-05-13T14:39:58.830655: step 475, loss 0.398056, acc 0.8125\n",
      "2018-05-13T14:39:59.303463: step 476, loss 0.253134, acc 0.890625\n",
      "2018-05-13T14:39:59.736406: step 477, loss 0.295272, acc 0.875\n",
      "2018-05-13T14:40:00.193925: step 478, loss 0.231196, acc 0.890625\n",
      "2018-05-13T14:40:00.682193: step 479, loss 0.338277, acc 0.84375\n",
      "2018-05-13T14:40:01.085290: step 480, loss 0.214646, acc 0.882353\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:40:01.614405: step 480, loss 0.285327, acc 0.876325\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-480\n",
      "\n",
      "2018-05-13T14:40:02.274328: step 481, loss 0.281261, acc 0.875\n",
      "2018-05-13T14:40:02.805061: step 482, loss 0.249218, acc 0.90625\n",
      "2018-05-13T14:40:03.356836: step 483, loss 0.33506, acc 0.859375\n",
      "2018-05-13T14:40:03.851984: step 484, loss 0.206222, acc 0.921875\n",
      "2018-05-13T14:40:04.383968: step 485, loss 0.195962, acc 0.90625\n",
      "2018-05-13T14:40:04.897648: step 486, loss 0.289733, acc 0.890625\n",
      "2018-05-13T14:40:05.393564: step 487, loss 0.322122, acc 0.828125\n",
      "2018-05-13T14:40:05.822449: step 488, loss 0.159344, acc 0.9375\n",
      "2018-05-13T14:40:06.201320: step 489, loss 0.353624, acc 0.84375\n",
      "2018-05-13T14:40:06.617844: step 490, loss 0.404685, acc 0.828125\n",
      "2018-05-13T14:40:07.181722: step 491, loss 0.230131, acc 0.890625\n",
      "2018-05-13T14:40:07.683918: step 492, loss 0.195067, acc 0.921875\n",
      "2018-05-13T14:40:08.178922: step 493, loss 0.265144, acc 0.890625\n",
      "2018-05-13T14:40:08.650609: step 494, loss 0.236165, acc 0.90625\n",
      "2018-05-13T14:40:09.146703: step 495, loss 0.325211, acc 0.84375\n",
      "2018-05-13T14:40:09.638432: step 496, loss 0.289637, acc 0.8125\n",
      "2018-05-13T14:40:10.133500: step 497, loss 0.3504, acc 0.84375\n",
      "2018-05-13T14:40:10.627203: step 498, loss 0.414698, acc 0.8125\n",
      "2018-05-13T14:40:11.080570: step 499, loss 0.255007, acc 0.859375\n",
      "2018-05-13T14:40:11.565983: step 500, loss 0.280268, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:40:12.131448: step 500, loss 0.289288, acc 0.869258\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-500\n",
      "\n",
      "2018-05-13T14:40:12.781903: step 501, loss 0.260063, acc 0.890625\n",
      "2018-05-13T14:40:13.343948: step 502, loss 0.285003, acc 0.828125\n",
      "2018-05-13T14:40:13.868487: step 503, loss 0.359257, acc 0.828125\n",
      "2018-05-13T14:40:14.336219: step 504, loss 0.310265, acc 0.8125\n",
      "2018-05-13T14:40:14.815212: step 505, loss 0.309945, acc 0.84375\n",
      "2018-05-13T14:40:15.250876: step 506, loss 0.226698, acc 0.890625\n",
      "2018-05-13T14:40:15.758211: step 507, loss 0.331486, acc 0.859375\n",
      "2018-05-13T14:40:16.234600: step 508, loss 0.264023, acc 0.84375\n",
      "2018-05-13T14:40:16.727451: step 509, loss 0.192496, acc 0.90625\n",
      "2018-05-13T14:40:17.221972: step 510, loss 0.246181, acc 0.859375\n",
      "2018-05-13T14:40:17.669823: step 511, loss 0.241768, acc 0.90625\n",
      "2018-05-13T14:40:18.177542: step 512, loss 0.362472, acc 0.875\n",
      "2018-05-13T14:40:18.660339: step 513, loss 0.24216, acc 0.890625\n",
      "2018-05-13T14:40:19.121454: step 514, loss 0.403918, acc 0.796875\n",
      "2018-05-13T14:40:19.589770: step 515, loss 0.321327, acc 0.828125\n",
      "2018-05-13T14:40:20.070884: step 516, loss 0.183232, acc 0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-13T14:40:20.527402: step 517, loss 0.374907, acc 0.8125\n",
      "2018-05-13T14:40:20.991691: step 518, loss 0.313222, acc 0.8125\n",
      "2018-05-13T14:40:21.472461: step 519, loss 0.2746, acc 0.84375\n",
      "2018-05-13T14:40:21.883723: step 520, loss 0.371535, acc 0.823529\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:40:22.488881: step 520, loss 0.312041, acc 0.869258\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-520\n",
      "\n",
      "2018-05-13T14:40:23.172543: step 521, loss 0.416153, acc 0.765625\n",
      "2018-05-13T14:40:23.635725: step 522, loss 0.379172, acc 0.765625\n",
      "2018-05-13T14:40:24.085774: step 523, loss 0.265552, acc 0.875\n",
      "2018-05-13T14:40:24.558524: step 524, loss 0.265252, acc 0.828125\n",
      "2018-05-13T14:40:24.998562: step 525, loss 0.209662, acc 0.9375\n",
      "2018-05-13T14:40:25.482231: step 526, loss 0.221084, acc 0.90625\n",
      "2018-05-13T14:40:25.924843: step 527, loss 0.223581, acc 0.90625\n",
      "2018-05-13T14:40:26.358259: step 528, loss 0.338293, acc 0.859375\n",
      "2018-05-13T14:40:26.789412: step 529, loss 0.299272, acc 0.84375\n",
      "2018-05-13T14:40:27.272720: step 530, loss 0.497366, acc 0.8125\n",
      "2018-05-13T14:40:27.740928: step 531, loss 0.416977, acc 0.765625\n",
      "2018-05-13T14:40:28.211525: step 532, loss 0.468494, acc 0.765625\n",
      "2018-05-13T14:40:28.701928: step 533, loss 0.390377, acc 0.78125\n",
      "2018-05-13T14:40:29.209284: step 534, loss 0.272701, acc 0.859375\n",
      "2018-05-13T14:40:29.679006: step 535, loss 0.221994, acc 0.875\n",
      "2018-05-13T14:40:30.126965: step 536, loss 0.334443, acc 0.78125\n",
      "2018-05-13T14:40:30.604561: step 537, loss 0.338547, acc 0.84375\n",
      "2018-05-13T14:40:31.038307: step 538, loss 0.211078, acc 0.875\n",
      "2018-05-13T14:40:31.419821: step 539, loss 0.293896, acc 0.875\n",
      "2018-05-13T14:40:31.899120: step 540, loss 0.334835, acc 0.765625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:40:32.381239: step 540, loss 0.301607, acc 0.879859\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-540\n",
      "\n",
      "2018-05-13T14:40:33.033073: step 541, loss 0.306426, acc 0.828125\n",
      "2018-05-13T14:40:33.455708: step 542, loss 0.256321, acc 0.90625\n",
      "2018-05-13T14:40:33.929554: step 543, loss 0.427696, acc 0.8125\n",
      "2018-05-13T14:40:34.417568: step 544, loss 0.31467, acc 0.84375\n",
      "2018-05-13T14:40:34.886768: step 545, loss 0.383463, acc 0.796875\n",
      "2018-05-13T14:40:35.397558: step 546, loss 0.217006, acc 0.875\n",
      "2018-05-13T14:40:35.897714: step 547, loss 0.253399, acc 0.859375\n",
      "2018-05-13T14:40:36.367733: step 548, loss 0.327035, acc 0.796875\n",
      "2018-05-13T14:40:36.843287: step 549, loss 0.426743, acc 0.8125\n",
      "2018-05-13T14:40:37.275041: step 550, loss 0.237314, acc 0.84375\n",
      "2018-05-13T14:40:37.751494: step 551, loss 0.25017, acc 0.859375\n",
      "2018-05-13T14:40:38.260557: step 552, loss 0.273426, acc 0.859375\n",
      "2018-05-13T14:40:38.777595: step 553, loss 0.302139, acc 0.84375\n",
      "2018-05-13T14:40:39.293452: step 554, loss 0.282303, acc 0.828125\n",
      "2018-05-13T14:40:39.761484: step 555, loss 0.282239, acc 0.8125\n",
      "2018-05-13T14:40:40.238138: step 556, loss 0.269356, acc 0.890625\n",
      "2018-05-13T14:40:40.724207: step 557, loss 0.274287, acc 0.84375\n",
      "2018-05-13T14:40:41.258740: step 558, loss 0.408869, acc 0.875\n",
      "2018-05-13T14:40:41.743259: step 559, loss 0.303724, acc 0.828125\n",
      "2018-05-13T14:40:42.183615: step 560, loss 0.190275, acc 0.921569\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:40:42.735796: step 560, loss 0.288984, acc 0.886926\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-560\n",
      "\n",
      "2018-05-13T14:40:43.375081: step 561, loss 0.129181, acc 0.953125\n",
      "2018-05-13T14:40:43.855141: step 562, loss 0.228941, acc 0.796875\n",
      "2018-05-13T14:40:44.353359: step 563, loss 0.443716, acc 0.796875\n",
      "2018-05-13T14:40:44.814974: step 564, loss 0.411632, acc 0.828125\n",
      "2018-05-13T14:40:45.271449: step 565, loss 0.225232, acc 0.890625\n",
      "2018-05-13T14:40:45.771200: step 566, loss 0.245228, acc 0.90625\n",
      "2018-05-13T14:40:46.260630: step 567, loss 0.316445, acc 0.875\n",
      "2018-05-13T14:40:46.744809: step 568, loss 0.20026, acc 0.875\n",
      "2018-05-13T14:40:47.208225: step 569, loss 0.168077, acc 0.9375\n",
      "2018-05-13T14:40:47.741968: step 570, loss 0.218522, acc 0.921875\n",
      "2018-05-13T14:40:48.208185: step 571, loss 0.438377, acc 0.75\n",
      "2018-05-13T14:40:48.691030: step 572, loss 0.374297, acc 0.75\n",
      "2018-05-13T14:40:49.164887: step 573, loss 0.287176, acc 0.875\n",
      "2018-05-13T14:40:49.632263: step 574, loss 0.309077, acc 0.828125\n",
      "2018-05-13T14:40:50.093338: step 575, loss 0.327511, acc 0.78125\n",
      "2018-05-13T14:40:50.611049: step 576, loss 0.28841, acc 0.84375\n",
      "2018-05-13T14:40:51.085405: step 577, loss 0.452758, acc 0.71875\n",
      "2018-05-13T14:40:51.561562: step 578, loss 0.348845, acc 0.765625\n",
      "2018-05-13T14:40:52.091646: step 579, loss 0.33197, acc 0.8125\n",
      "2018-05-13T14:40:52.554634: step 580, loss 0.304497, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:40:53.040349: step 580, loss 0.295964, acc 0.872792\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-580\n",
      "\n",
      "2018-05-13T14:40:53.716034: step 581, loss 0.334577, acc 0.8125\n",
      "2018-05-13T14:40:54.167865: step 582, loss 0.31985, acc 0.765625\n",
      "2018-05-13T14:40:54.642067: step 583, loss 0.328227, acc 0.796875\n",
      "2018-05-13T14:40:55.016313: step 584, loss 0.24011, acc 0.875\n",
      "2018-05-13T14:40:55.406845: step 585, loss 0.392749, acc 0.828125\n",
      "2018-05-13T14:40:55.792344: step 586, loss 0.299987, acc 0.8125\n",
      "2018-05-13T14:40:56.186361: step 587, loss 0.355763, acc 0.765625\n",
      "2018-05-13T14:40:56.569069: step 588, loss 0.283468, acc 0.875\n",
      "2018-05-13T14:40:56.959612: step 589, loss 0.418984, acc 0.796875\n",
      "2018-05-13T14:40:57.368659: step 590, loss 0.287242, acc 0.859375\n",
      "2018-05-13T14:40:57.772720: step 591, loss 0.284623, acc 0.875\n",
      "2018-05-13T14:40:58.143224: step 592, loss 0.333833, acc 0.859375\n",
      "2018-05-13T14:40:58.527125: step 593, loss 0.268182, acc 0.890625\n",
      "2018-05-13T14:40:58.901068: step 594, loss 0.322756, acc 0.828125\n",
      "2018-05-13T14:40:59.306093: step 595, loss 0.319795, acc 0.84375\n",
      "2018-05-13T14:40:59.715136: step 596, loss 0.248666, acc 0.875\n",
      "2018-05-13T14:41:00.109920: step 597, loss 0.304252, acc 0.796875\n",
      "2018-05-13T14:41:00.474202: step 598, loss 0.266587, acc 0.8125\n",
      "2018-05-13T14:41:00.841407: step 599, loss 0.233037, acc 0.859375\n",
      "2018-05-13T14:41:01.145113: step 600, loss 0.314151, acc 0.803922\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:41:01.583150: step 600, loss 0.278907, acc 0.886926\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-600\n",
      "\n",
      "2018-05-13T14:41:02.272667: step 601, loss 0.224145, acc 0.84375\n",
      "2018-05-13T14:41:02.762251: step 602, loss 0.185085, acc 0.90625\n",
      "2018-05-13T14:41:03.260716: step 603, loss 0.435955, acc 0.765625\n",
      "2018-05-13T14:41:03.757843: step 604, loss 0.336236, acc 0.796875\n",
      "2018-05-13T14:41:04.209196: step 605, loss 0.239988, acc 0.859375\n",
      "2018-05-13T14:41:04.694769: step 606, loss 0.313036, acc 0.8125\n",
      "2018-05-13T14:41:05.166692: step 607, loss 0.259456, acc 0.84375\n",
      "2018-05-13T14:41:05.699958: step 608, loss 0.204642, acc 0.921875\n",
      "2018-05-13T14:41:06.155123: step 609, loss 0.282349, acc 0.859375\n",
      "2018-05-13T14:41:06.663971: step 610, loss 0.244293, acc 0.875\n",
      "2018-05-13T14:41:07.136324: step 611, loss 0.264179, acc 0.890625\n",
      "2018-05-13T14:41:07.606755: step 612, loss 0.312226, acc 0.796875\n",
      "2018-05-13T14:41:08.100011: step 613, loss 0.352179, acc 0.828125\n",
      "2018-05-13T14:41:08.645531: step 614, loss 0.185121, acc 0.9375\n",
      "2018-05-13T14:41:09.122306: step 615, loss 0.193294, acc 0.921875\n",
      "2018-05-13T14:41:09.611723: step 616, loss 0.206886, acc 0.921875\n",
      "2018-05-13T14:41:10.055940: step 617, loss 0.308876, acc 0.859375\n",
      "2018-05-13T14:41:10.529123: step 618, loss 0.353697, acc 0.859375\n",
      "2018-05-13T14:41:10.968882: step 619, loss 0.25237, acc 0.875\n",
      "2018-05-13T14:41:11.460483: step 620, loss 0.253659, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:41:12.015101: step 620, loss 0.391063, acc 0.858657\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-620\n",
      "\n",
      "2018-05-13T14:41:12.708366: step 621, loss 0.250116, acc 0.859375\n",
      "2018-05-13T14:41:13.183862: step 622, loss 0.299212, acc 0.84375\n",
      "2018-05-13T14:41:13.629001: step 623, loss 0.172702, acc 0.921875\n",
      "2018-05-13T14:41:14.118383: step 624, loss 0.384284, acc 0.875\n",
      "2018-05-13T14:41:14.601400: step 625, loss 0.221455, acc 0.921875\n",
      "2018-05-13T14:41:15.078349: step 626, loss 0.188374, acc 0.859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-13T14:41:15.592970: step 627, loss 0.311958, acc 0.84375\n",
      "2018-05-13T14:41:16.055951: step 628, loss 0.32339, acc 0.796875\n",
      "2018-05-13T14:41:16.583145: step 629, loss 0.26613, acc 0.8125\n",
      "2018-05-13T14:41:17.053263: step 630, loss 0.171224, acc 0.90625\n",
      "2018-05-13T14:41:17.542334: step 631, loss 0.212193, acc 0.875\n",
      "2018-05-13T14:41:18.023224: step 632, loss 0.192296, acc 0.890625\n",
      "2018-05-13T14:41:18.559340: step 633, loss 0.220793, acc 0.890625\n",
      "2018-05-13T14:41:19.061264: step 634, loss 0.135754, acc 0.921875\n",
      "2018-05-13T14:41:19.529098: step 635, loss 0.189443, acc 0.90625\n",
      "2018-05-13T14:41:20.011966: step 636, loss 0.236609, acc 0.890625\n",
      "2018-05-13T14:41:20.502499: step 637, loss 0.15001, acc 0.9375\n",
      "2018-05-13T14:41:20.992986: step 638, loss 0.154154, acc 0.96875\n",
      "2018-05-13T14:41:21.493328: step 639, loss 0.236054, acc 0.921875\n",
      "2018-05-13T14:41:21.886152: step 640, loss 0.235648, acc 0.843137\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:41:22.424368: step 640, loss 0.317614, acc 0.879859\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-640\n",
      "\n",
      "2018-05-13T14:41:23.144162: step 641, loss 0.282511, acc 0.859375\n",
      "2018-05-13T14:41:23.682909: step 642, loss 0.217747, acc 0.921875\n",
      "2018-05-13T14:41:24.186104: step 643, loss 0.173617, acc 0.90625\n",
      "2018-05-13T14:41:24.743701: step 644, loss 0.199502, acc 0.875\n",
      "2018-05-13T14:41:25.247791: step 645, loss 0.211514, acc 0.921875\n",
      "2018-05-13T14:41:25.715357: step 646, loss 0.239567, acc 0.875\n",
      "2018-05-13T14:41:26.234289: step 647, loss 0.208099, acc 0.875\n",
      "2018-05-13T14:41:26.641552: step 648, loss 0.228079, acc 0.859375\n",
      "2018-05-13T14:41:27.023934: step 649, loss 0.13803, acc 0.953125\n",
      "2018-05-13T14:41:27.427674: step 650, loss 0.161653, acc 0.9375\n",
      "2018-05-13T14:41:27.818449: step 651, loss 0.321996, acc 0.84375\n",
      "2018-05-13T14:41:28.217263: step 652, loss 0.260891, acc 0.828125\n",
      "2018-05-13T14:41:28.684161: step 653, loss 0.147223, acc 0.96875\n",
      "2018-05-13T14:41:29.166561: step 654, loss 0.21773, acc 0.890625\n",
      "2018-05-13T14:41:29.749462: step 655, loss 0.20028, acc 0.875\n",
      "2018-05-13T14:41:30.201270: step 656, loss 0.224397, acc 0.921875\n",
      "2018-05-13T14:41:30.685920: step 657, loss 0.309518, acc 0.859375\n",
      "2018-05-13T14:41:31.119501: step 658, loss 0.242448, acc 0.90625\n",
      "2018-05-13T14:41:31.512200: step 659, loss 0.192117, acc 0.90625\n",
      "2018-05-13T14:41:32.064612: step 660, loss 0.215403, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:41:32.634406: step 660, loss 0.310069, acc 0.883392\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-660\n",
      "\n",
      "2018-05-13T14:41:33.327662: step 661, loss 0.107075, acc 0.96875\n",
      "2018-05-13T14:41:33.721831: step 662, loss 0.268952, acc 0.890625\n",
      "2018-05-13T14:41:34.085733: step 663, loss 0.183643, acc 0.921875\n",
      "2018-05-13T14:41:34.458300: step 664, loss 0.246622, acc 0.859375\n",
      "2018-05-13T14:41:34.840545: step 665, loss 0.156999, acc 0.921875\n",
      "2018-05-13T14:41:35.229599: step 666, loss 0.208875, acc 0.859375\n",
      "2018-05-13T14:41:35.676760: step 667, loss 0.276372, acc 0.828125\n",
      "2018-05-13T14:41:36.068480: step 668, loss 0.17202, acc 0.953125\n",
      "2018-05-13T14:41:36.467207: step 669, loss 0.259192, acc 0.90625\n",
      "2018-05-13T14:41:36.852578: step 670, loss 0.244793, acc 0.90625\n",
      "2018-05-13T14:41:37.238783: step 671, loss 0.2908, acc 0.859375\n",
      "2018-05-13T14:41:37.627300: step 672, loss 0.329083, acc 0.828125\n",
      "2018-05-13T14:41:38.022999: step 673, loss 0.279377, acc 0.84375\n",
      "2018-05-13T14:41:38.428570: step 674, loss 0.254045, acc 0.90625\n",
      "2018-05-13T14:41:38.816052: step 675, loss 0.274129, acc 0.875\n",
      "2018-05-13T14:41:39.222063: step 676, loss 0.333617, acc 0.796875\n",
      "2018-05-13T14:41:39.636443: step 677, loss 0.254236, acc 0.890625\n",
      "2018-05-13T14:41:40.009145: step 678, loss 0.300865, acc 0.859375\n",
      "2018-05-13T14:41:40.410887: step 679, loss 0.233457, acc 0.921875\n",
      "2018-05-13T14:41:40.716077: step 680, loss 0.201964, acc 0.941176\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:41:41.163711: step 680, loss 0.322402, acc 0.85159\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-680\n",
      "\n",
      "2018-05-13T14:41:41.819394: step 681, loss 0.264569, acc 0.859375\n",
      "2018-05-13T14:41:42.338514: step 682, loss 0.190567, acc 0.921875\n",
      "2018-05-13T14:41:42.862088: step 683, loss 0.188439, acc 0.921875\n",
      "2018-05-13T14:41:43.368340: step 684, loss 0.111761, acc 0.953125\n",
      "2018-05-13T14:41:43.840131: step 685, loss 0.178411, acc 0.9375\n",
      "2018-05-13T14:41:44.356287: step 686, loss 0.10633, acc 0.9375\n",
      "2018-05-13T14:41:44.884986: step 687, loss 0.254033, acc 0.90625\n",
      "2018-05-13T14:41:45.414982: step 688, loss 0.235382, acc 0.890625\n",
      "2018-05-13T14:41:45.867081: step 689, loss 0.190773, acc 0.9375\n",
      "2018-05-13T14:41:46.347510: step 690, loss 0.367346, acc 0.859375\n",
      "2018-05-13T14:41:46.843356: step 691, loss 0.21408, acc 0.890625\n",
      "2018-05-13T14:41:47.357588: step 692, loss 0.234056, acc 0.875\n",
      "2018-05-13T14:41:47.841832: step 693, loss 0.313816, acc 0.84375\n",
      "2018-05-13T14:41:48.353185: step 694, loss 0.240392, acc 0.890625\n",
      "2018-05-13T14:41:48.865011: step 695, loss 0.169126, acc 0.921875\n",
      "2018-05-13T14:41:49.342050: step 696, loss 0.24466, acc 0.859375\n",
      "2018-05-13T14:41:49.844507: step 697, loss 0.124285, acc 0.921875\n",
      "2018-05-13T14:41:50.332358: step 698, loss 0.191472, acc 0.9375\n",
      "2018-05-13T14:41:50.827082: step 699, loss 0.23657, acc 0.90625\n",
      "2018-05-13T14:41:51.325596: step 700, loss 0.258658, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:41:51.904987: step 700, loss 0.310337, acc 0.858657\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-700\n",
      "\n",
      "2018-05-13T14:41:52.635401: step 701, loss 0.243155, acc 0.859375\n",
      "2018-05-13T14:41:53.211004: step 702, loss 0.223421, acc 0.875\n",
      "2018-05-13T14:41:53.755214: step 703, loss 0.187305, acc 0.921875\n",
      "2018-05-13T14:41:54.242426: step 704, loss 0.174576, acc 0.90625\n",
      "2018-05-13T14:41:54.725672: step 705, loss 0.179362, acc 0.875\n",
      "2018-05-13T14:41:55.182391: step 706, loss 0.182185, acc 0.90625\n",
      "2018-05-13T14:41:55.656401: step 707, loss 0.241128, acc 0.875\n",
      "2018-05-13T14:41:56.200783: step 708, loss 0.167818, acc 0.921875\n",
      "2018-05-13T14:41:56.710929: step 709, loss 0.179824, acc 0.90625\n",
      "2018-05-13T14:41:57.263815: step 710, loss 0.221593, acc 0.890625\n",
      "2018-05-13T14:41:57.762449: step 711, loss 0.138473, acc 0.921875\n",
      "2018-05-13T14:41:58.238027: step 712, loss 0.201945, acc 0.875\n",
      "2018-05-13T14:41:58.747214: step 713, loss 0.213414, acc 0.921875\n",
      "2018-05-13T14:41:59.273005: step 714, loss 0.256044, acc 0.859375\n",
      "2018-05-13T14:41:59.822431: step 715, loss 0.296468, acc 0.859375\n",
      "2018-05-13T14:42:00.320182: step 716, loss 0.193379, acc 0.890625\n",
      "2018-05-13T14:42:00.798933: step 717, loss 0.227999, acc 0.890625\n",
      "2018-05-13T14:42:01.294726: step 718, loss 0.22697, acc 0.875\n",
      "2018-05-13T14:42:01.771542: step 719, loss 0.257409, acc 0.84375\n",
      "2018-05-13T14:42:02.178577: step 720, loss 0.324712, acc 0.843137\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:42:02.669659: step 720, loss 0.323518, acc 0.886926\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-720\n",
      "\n",
      "2018-05-13T14:42:03.211250: step 721, loss 0.198813, acc 0.859375\n",
      "2018-05-13T14:42:03.604348: step 722, loss 0.194131, acc 0.890625\n",
      "2018-05-13T14:42:03.996199: step 723, loss 0.29401, acc 0.875\n",
      "2018-05-13T14:42:04.441697: step 724, loss 0.291759, acc 0.875\n",
      "2018-05-13T14:42:04.952527: step 725, loss 0.192892, acc 0.875\n",
      "2018-05-13T14:42:05.358585: step 726, loss 0.181844, acc 0.890625\n",
      "2018-05-13T14:42:05.745387: step 727, loss 0.266231, acc 0.9375\n",
      "2018-05-13T14:42:06.130024: step 728, loss 0.151224, acc 0.921875\n",
      "2018-05-13T14:42:06.623251: step 729, loss 0.243332, acc 0.890625\n",
      "2018-05-13T14:42:07.131353: step 730, loss 0.163653, acc 0.90625\n",
      "2018-05-13T14:42:07.615634: step 731, loss 0.245373, acc 0.828125\n",
      "2018-05-13T14:42:08.100880: step 732, loss 0.30457, acc 0.84375\n",
      "2018-05-13T14:42:08.597611: step 733, loss 0.295995, acc 0.84375\n",
      "2018-05-13T14:42:09.116534: step 734, loss 0.225446, acc 0.890625\n",
      "2018-05-13T14:42:09.590561: step 735, loss 0.182098, acc 0.890625\n",
      "2018-05-13T14:42:10.084308: step 736, loss 0.190999, acc 0.84375\n",
      "2018-05-13T14:42:10.580632: step 737, loss 0.256357, acc 0.875\n",
      "2018-05-13T14:42:11.051253: step 738, loss 0.16012, acc 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-13T14:42:11.555539: step 739, loss 0.224274, acc 0.90625\n",
      "2018-05-13T14:42:12.052192: step 740, loss 0.245608, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:42:12.605166: step 740, loss 0.307933, acc 0.893993\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-740\n",
      "\n",
      "2018-05-13T14:42:13.392773: step 741, loss 0.336313, acc 0.828125\n",
      "2018-05-13T14:42:13.885143: step 742, loss 0.191889, acc 0.875\n",
      "2018-05-13T14:42:14.369400: step 743, loss 0.154323, acc 0.890625\n",
      "2018-05-13T14:42:14.868175: step 744, loss 0.162895, acc 0.953125\n",
      "2018-05-13T14:42:15.332989: step 745, loss 0.187496, acc 0.890625\n",
      "2018-05-13T14:42:15.769656: step 746, loss 0.157943, acc 0.90625\n",
      "2018-05-13T14:42:16.232530: step 747, loss 0.303488, acc 0.828125\n",
      "2018-05-13T14:42:16.755959: step 748, loss 0.197255, acc 0.921875\n",
      "2018-05-13T14:42:17.233733: step 749, loss 0.164194, acc 0.90625\n",
      "2018-05-13T14:42:17.760196: step 750, loss 0.23409, acc 0.90625\n",
      "2018-05-13T14:42:18.338083: step 751, loss 0.234633, acc 0.875\n",
      "2018-05-13T14:42:18.842106: step 752, loss 0.207506, acc 0.890625\n",
      "2018-05-13T14:42:19.306200: step 753, loss 0.161612, acc 0.90625\n",
      "2018-05-13T14:42:19.874950: step 754, loss 0.272647, acc 0.875\n",
      "2018-05-13T14:42:20.381579: step 755, loss 0.129203, acc 0.921875\n",
      "2018-05-13T14:42:20.923624: step 756, loss 0.169341, acc 0.9375\n",
      "2018-05-13T14:42:21.469975: step 757, loss 0.168977, acc 0.953125\n",
      "2018-05-13T14:42:22.013626: step 758, loss 0.233721, acc 0.90625\n",
      "2018-05-13T14:42:22.571372: step 759, loss 0.286405, acc 0.796875\n",
      "2018-05-13T14:42:22.961813: step 760, loss 0.0891129, acc 0.960784\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:42:23.479384: step 760, loss 0.31103, acc 0.883392\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-760\n",
      "\n",
      "2018-05-13T14:42:24.160908: step 761, loss 0.158974, acc 0.921875\n",
      "2018-05-13T14:42:24.647821: step 762, loss 0.213889, acc 0.921875\n",
      "2018-05-13T14:42:25.181893: step 763, loss 0.175282, acc 0.921875\n",
      "2018-05-13T14:42:25.653108: step 764, loss 0.210751, acc 0.859375\n",
      "2018-05-13T14:42:26.125087: step 765, loss 0.151954, acc 0.90625\n",
      "2018-05-13T14:42:26.600149: step 766, loss 0.15048, acc 0.953125\n",
      "2018-05-13T14:42:27.111045: step 767, loss 0.162097, acc 0.890625\n",
      "2018-05-13T14:42:27.585221: step 768, loss 0.151905, acc 0.9375\n",
      "2018-05-13T14:42:28.076117: step 769, loss 0.15552, acc 0.9375\n",
      "2018-05-13T14:42:28.588848: step 770, loss 0.214667, acc 0.859375\n",
      "2018-05-13T14:42:29.071059: step 771, loss 0.140545, acc 0.9375\n",
      "2018-05-13T14:42:29.565573: step 772, loss 0.266073, acc 0.8125\n",
      "2018-05-13T14:42:30.074804: step 773, loss 0.124561, acc 0.96875\n",
      "2018-05-13T14:42:30.552609: step 774, loss 0.191453, acc 0.90625\n",
      "2018-05-13T14:42:31.028166: step 775, loss 0.251411, acc 0.828125\n",
      "2018-05-13T14:42:31.521208: step 776, loss 0.268628, acc 0.84375\n",
      "2018-05-13T14:42:32.024140: step 777, loss 0.228402, acc 0.9375\n",
      "2018-05-13T14:42:32.570992: step 778, loss 0.141122, acc 0.921875\n",
      "2018-05-13T14:42:33.064776: step 779, loss 0.145558, acc 0.921875\n",
      "2018-05-13T14:42:33.548541: step 780, loss 0.19158, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:42:34.159643: step 780, loss 0.352616, acc 0.890459\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-780\n",
      "\n",
      "2018-05-13T14:42:34.872085: step 781, loss 0.200427, acc 0.859375\n",
      "2018-05-13T14:42:35.351815: step 782, loss 0.158593, acc 0.921875\n",
      "2018-05-13T14:42:35.791727: step 783, loss 0.238017, acc 0.890625\n",
      "2018-05-13T14:42:36.261219: step 784, loss 0.200441, acc 0.890625\n",
      "2018-05-13T14:42:36.736849: step 785, loss 0.241503, acc 0.84375\n",
      "2018-05-13T14:42:37.197153: step 786, loss 0.234867, acc 0.84375\n",
      "2018-05-13T14:42:37.718754: step 787, loss 0.206245, acc 0.859375\n",
      "2018-05-13T14:42:38.208647: step 788, loss 0.20408, acc 0.9375\n",
      "2018-05-13T14:42:38.690724: step 789, loss 0.205159, acc 0.90625\n",
      "2018-05-13T14:42:39.195317: step 790, loss 0.231216, acc 0.859375\n",
      "2018-05-13T14:42:39.639161: step 791, loss 0.250985, acc 0.859375\n",
      "2018-05-13T14:42:40.033355: step 792, loss 0.204877, acc 0.90625\n",
      "2018-05-13T14:42:40.453166: step 793, loss 0.21807, acc 0.90625\n",
      "2018-05-13T14:42:40.835057: step 794, loss 0.426761, acc 0.796875\n",
      "2018-05-13T14:42:41.220865: step 795, loss 0.232873, acc 0.921875\n",
      "2018-05-13T14:42:41.618682: step 796, loss 0.25807, acc 0.859375\n",
      "2018-05-13T14:42:42.051150: step 797, loss 0.204071, acc 0.90625\n",
      "2018-05-13T14:42:42.447754: step 798, loss 0.239221, acc 0.90625\n",
      "2018-05-13T14:42:42.834286: step 799, loss 0.224985, acc 0.859375\n",
      "2018-05-13T14:42:43.142917: step 800, loss 0.113259, acc 0.941176\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:42:43.694812: step 800, loss 0.293004, acc 0.890459\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-800\n",
      "\n",
      "2018-05-13T14:42:44.401868: step 801, loss 0.197242, acc 0.90625\n",
      "2018-05-13T14:42:44.933948: step 802, loss 0.196517, acc 0.890625\n",
      "2018-05-13T14:42:45.445688: step 803, loss 0.191884, acc 0.890625\n",
      "2018-05-13T14:42:45.827341: step 804, loss 0.116809, acc 0.96875\n",
      "2018-05-13T14:42:46.216251: step 805, loss 0.144019, acc 0.953125\n",
      "2018-05-13T14:42:46.622334: step 806, loss 0.141164, acc 0.921875\n",
      "2018-05-13T14:42:47.101774: step 807, loss 0.190041, acc 0.921875\n",
      "2018-05-13T14:42:47.607266: step 808, loss 0.17195, acc 0.921875\n",
      "2018-05-13T14:42:48.062177: step 809, loss 0.13832, acc 0.96875\n",
      "2018-05-13T14:42:48.560799: step 810, loss 0.235576, acc 0.875\n",
      "2018-05-13T14:42:49.030756: step 811, loss 0.127471, acc 0.953125\n",
      "2018-05-13T14:42:49.538764: step 812, loss 0.231662, acc 0.84375\n",
      "2018-05-13T14:42:49.925866: step 813, loss 0.188647, acc 0.890625\n",
      "2018-05-13T14:42:50.312470: step 814, loss 0.142275, acc 0.9375\n",
      "2018-05-13T14:42:50.709729: step 815, loss 0.131536, acc 0.9375\n",
      "2018-05-13T14:42:51.104389: step 816, loss 0.15827, acc 0.921875\n",
      "2018-05-13T14:42:51.520427: step 817, loss 0.166018, acc 0.90625\n",
      "2018-05-13T14:42:51.938902: step 818, loss 0.248813, acc 0.921875\n",
      "2018-05-13T14:42:52.355899: step 819, loss 0.215976, acc 0.859375\n",
      "2018-05-13T14:42:52.770597: step 820, loss 0.141618, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:42:53.259110: step 820, loss 0.328301, acc 0.883392\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-820\n",
      "\n",
      "2018-05-13T14:42:53.842684: step 821, loss 0.141828, acc 0.890625\n",
      "2018-05-13T14:42:54.259451: step 822, loss 0.16888, acc 0.921875\n",
      "2018-05-13T14:42:54.663701: step 823, loss 0.142343, acc 0.921875\n",
      "2018-05-13T14:42:55.071383: step 824, loss 0.183044, acc 0.921875\n",
      "2018-05-13T14:42:55.477398: step 825, loss 0.191839, acc 0.890625\n",
      "2018-05-13T14:42:55.994247: step 826, loss 0.205248, acc 0.90625\n",
      "2018-05-13T14:42:56.499178: step 827, loss 0.172656, acc 0.890625\n",
      "2018-05-13T14:42:56.979225: step 828, loss 0.139713, acc 0.921875\n",
      "2018-05-13T14:42:57.498818: step 829, loss 0.161533, acc 0.921875\n",
      "2018-05-13T14:42:57.962086: step 830, loss 0.167058, acc 0.921875\n",
      "2018-05-13T14:42:58.422223: step 831, loss 0.274699, acc 0.84375\n",
      "2018-05-13T14:42:58.899870: step 832, loss 0.140156, acc 0.921875\n",
      "2018-05-13T14:42:59.275788: step 833, loss 0.179637, acc 0.9375\n",
      "2018-05-13T14:42:59.661036: step 834, loss 0.147967, acc 0.953125\n",
      "2018-05-13T14:43:00.045226: step 835, loss 0.194546, acc 0.890625\n",
      "2018-05-13T14:43:00.423785: step 836, loss 0.178946, acc 0.890625\n",
      "2018-05-13T14:43:00.799438: step 837, loss 0.141654, acc 0.953125\n",
      "2018-05-13T14:43:01.174274: step 838, loss 0.2357, acc 0.828125\n",
      "2018-05-13T14:43:01.544271: step 839, loss 0.178531, acc 0.9375\n",
      "2018-05-13T14:43:01.840746: step 840, loss 0.193677, acc 0.901961\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:43:02.386862: step 840, loss 0.372966, acc 0.90106\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-840\n",
      "\n",
      "2018-05-13T14:43:03.033020: step 841, loss 0.332312, acc 0.84375\n",
      "2018-05-13T14:43:03.486270: step 842, loss 0.158942, acc 0.921875\n",
      "2018-05-13T14:43:03.980929: step 843, loss 0.213918, acc 0.90625\n",
      "2018-05-13T14:43:04.437662: step 844, loss 0.205847, acc 0.875\n",
      "2018-05-13T14:43:04.875235: step 845, loss 0.184515, acc 0.921875\n",
      "2018-05-13T14:43:05.256304: step 846, loss 0.174188, acc 0.90625\n",
      "2018-05-13T14:43:05.692157: step 847, loss 0.226508, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-13T14:43:06.113456: step 848, loss 0.180961, acc 0.890625\n",
      "2018-05-13T14:43:06.550692: step 849, loss 0.183633, acc 0.890625\n",
      "2018-05-13T14:43:07.006925: step 850, loss 0.282317, acc 0.8125\n",
      "2018-05-13T14:43:07.471636: step 851, loss 0.180235, acc 0.859375\n",
      "2018-05-13T14:43:07.943211: step 852, loss 0.153836, acc 0.90625\n",
      "2018-05-13T14:43:08.414656: step 853, loss 0.18147, acc 0.90625\n",
      "2018-05-13T14:43:08.926880: step 854, loss 0.217485, acc 0.875\n",
      "2018-05-13T14:43:09.324566: step 855, loss 0.22393, acc 0.875\n",
      "2018-05-13T14:43:09.725260: step 856, loss 0.140823, acc 0.921875\n",
      "2018-05-13T14:43:10.130895: step 857, loss 0.195893, acc 0.875\n",
      "2018-05-13T14:43:10.516360: step 858, loss 0.251745, acc 0.859375\n",
      "2018-05-13T14:43:10.896553: step 859, loss 0.124446, acc 0.890625\n",
      "2018-05-13T14:43:11.280065: step 860, loss 0.136192, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:43:11.752714: step 860, loss 0.285733, acc 0.886926\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-860\n",
      "\n",
      "2018-05-13T14:43:12.389269: step 861, loss 0.191863, acc 0.890625\n",
      "2018-05-13T14:43:12.911677: step 862, loss 0.17572, acc 0.890625\n",
      "2018-05-13T14:43:13.432878: step 863, loss 0.216341, acc 0.890625\n",
      "2018-05-13T14:43:13.831555: step 864, loss 0.111967, acc 0.96875\n",
      "2018-05-13T14:43:14.332170: step 865, loss 0.143192, acc 0.90625\n",
      "2018-05-13T14:43:14.873102: step 866, loss 0.100746, acc 0.953125\n",
      "2018-05-13T14:43:15.425954: step 867, loss 0.189724, acc 0.84375\n",
      "2018-05-13T14:43:15.906773: step 868, loss 0.21287, acc 0.921875\n",
      "2018-05-13T14:43:16.406301: step 869, loss 0.280881, acc 0.859375\n",
      "2018-05-13T14:43:16.896832: step 870, loss 0.128099, acc 0.9375\n",
      "2018-05-13T14:43:17.392893: step 871, loss 0.124675, acc 0.921875\n",
      "2018-05-13T14:43:17.841336: step 872, loss 0.101527, acc 0.953125\n",
      "2018-05-13T14:43:18.321501: step 873, loss 0.232277, acc 0.90625\n",
      "2018-05-13T14:43:18.758655: step 874, loss 0.160275, acc 0.90625\n",
      "2018-05-13T14:43:19.219190: step 875, loss 0.195417, acc 0.921875\n",
      "2018-05-13T14:43:19.720068: step 876, loss 0.172463, acc 0.921875\n",
      "2018-05-13T14:43:20.197945: step 877, loss 0.135086, acc 0.9375\n",
      "2018-05-13T14:43:20.697242: step 878, loss 0.141042, acc 0.9375\n",
      "2018-05-13T14:43:21.178452: step 879, loss 0.192992, acc 0.875\n",
      "2018-05-13T14:43:21.597670: step 880, loss 0.092379, acc 0.960784\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:43:22.118728: step 880, loss 0.366798, acc 0.883392\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-880\n",
      "\n",
      "2018-05-13T14:43:22.743892: step 881, loss 0.13779, acc 0.96875\n",
      "2018-05-13T14:43:23.237419: step 882, loss 0.130206, acc 0.9375\n",
      "2018-05-13T14:43:23.754441: step 883, loss 0.186376, acc 0.921875\n",
      "2018-05-13T14:43:24.277212: step 884, loss 0.160893, acc 0.9375\n",
      "2018-05-13T14:43:24.791010: step 885, loss 0.172674, acc 0.921875\n",
      "2018-05-13T14:43:25.279157: step 886, loss 0.235684, acc 0.890625\n",
      "2018-05-13T14:43:25.709998: step 887, loss 0.171559, acc 0.890625\n",
      "2018-05-13T14:43:26.210804: step 888, loss 0.191742, acc 0.921875\n",
      "2018-05-13T14:43:26.698118: step 889, loss 0.268183, acc 0.84375\n",
      "2018-05-13T14:43:27.215621: step 890, loss 0.159148, acc 0.953125\n",
      "2018-05-13T14:43:27.747002: step 891, loss 0.16455, acc 0.9375\n",
      "2018-05-13T14:43:28.242579: step 892, loss 0.215952, acc 0.921875\n",
      "2018-05-13T14:43:28.675053: step 893, loss 0.118911, acc 0.9375\n",
      "2018-05-13T14:43:29.085714: step 894, loss 0.124927, acc 0.953125\n",
      "2018-05-13T14:43:29.470886: step 895, loss 0.205553, acc 0.90625\n",
      "2018-05-13T14:43:29.850122: step 896, loss 0.102402, acc 0.96875\n",
      "2018-05-13T14:43:30.321680: step 897, loss 0.212441, acc 0.859375\n",
      "2018-05-13T14:43:30.827928: step 898, loss 0.205116, acc 0.875\n",
      "2018-05-13T14:43:31.294325: step 899, loss 0.135967, acc 0.9375\n",
      "2018-05-13T14:43:31.776654: step 900, loss 0.152567, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:43:32.272276: step 900, loss 0.385799, acc 0.897527\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-900\n",
      "\n",
      "2018-05-13T14:43:32.898534: step 901, loss 0.101573, acc 0.96875\n",
      "2018-05-13T14:43:33.304327: step 902, loss 0.187225, acc 0.9375\n",
      "2018-05-13T14:43:33.690666: step 903, loss 0.140861, acc 0.9375\n",
      "2018-05-13T14:43:34.188382: step 904, loss 0.178621, acc 0.90625\n",
      "2018-05-13T14:43:34.558766: step 905, loss 0.295852, acc 0.875\n",
      "2018-05-13T14:43:34.929456: step 906, loss 0.126961, acc 0.953125\n",
      "2018-05-13T14:43:35.306985: step 907, loss 0.121733, acc 0.953125\n",
      "2018-05-13T14:43:35.767947: step 908, loss 0.155403, acc 0.921875\n",
      "2018-05-13T14:43:36.187532: step 909, loss 0.152695, acc 0.90625\n",
      "2018-05-13T14:43:36.581106: step 910, loss 0.104517, acc 0.984375\n",
      "2018-05-13T14:43:36.958795: step 911, loss 0.0804074, acc 0.984375\n",
      "2018-05-13T14:43:37.325973: step 912, loss 0.238321, acc 0.890625\n",
      "2018-05-13T14:43:37.718957: step 913, loss 0.253344, acc 0.828125\n",
      "2018-05-13T14:43:38.100289: step 914, loss 0.145192, acc 0.953125\n",
      "2018-05-13T14:43:38.495622: step 915, loss 0.116387, acc 0.96875\n",
      "2018-05-13T14:43:38.878718: step 916, loss 0.139705, acc 0.9375\n",
      "2018-05-13T14:43:39.272440: step 917, loss 0.182854, acc 0.953125\n",
      "2018-05-13T14:43:39.663952: step 918, loss 0.127578, acc 0.9375\n",
      "2018-05-13T14:43:40.066020: step 919, loss 0.148655, acc 0.921875\n",
      "2018-05-13T14:43:40.402583: step 920, loss 0.0861796, acc 0.980392\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:43:40.941011: step 920, loss 0.380128, acc 0.872792\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-920\n",
      "\n",
      "2018-05-13T14:43:41.589415: step 921, loss 0.197883, acc 0.859375\n",
      "2018-05-13T14:43:42.113108: step 922, loss 0.0932543, acc 0.96875\n",
      "2018-05-13T14:43:42.576082: step 923, loss 0.11178, acc 0.9375\n",
      "2018-05-13T14:43:42.995178: step 924, loss 0.0972724, acc 0.953125\n",
      "2018-05-13T14:43:43.487248: step 925, loss 0.205616, acc 0.890625\n",
      "2018-05-13T14:43:43.932679: step 926, loss 0.0859251, acc 0.953125\n",
      "2018-05-13T14:43:44.412546: step 927, loss 0.199181, acc 0.875\n",
      "2018-05-13T14:43:44.895664: step 928, loss 0.0815342, acc 0.96875\n",
      "2018-05-13T14:43:45.322196: step 929, loss 0.23562, acc 0.859375\n",
      "2018-05-13T14:43:45.804991: step 930, loss 0.148777, acc 0.890625\n",
      "2018-05-13T14:43:46.375949: step 931, loss 0.130309, acc 0.921875\n",
      "2018-05-13T14:43:46.875277: step 932, loss 0.245674, acc 0.921875\n",
      "2018-05-13T14:43:47.359154: step 933, loss 0.10284, acc 0.953125\n",
      "2018-05-13T14:43:47.859579: step 934, loss 0.122858, acc 0.9375\n",
      "2018-05-13T14:43:48.348121: step 935, loss 0.265502, acc 0.828125\n",
      "2018-05-13T14:43:48.835553: step 936, loss 0.183882, acc 0.921875\n",
      "2018-05-13T14:43:49.299128: step 937, loss 0.214281, acc 0.859375\n",
      "2018-05-13T14:43:49.737781: step 938, loss 0.0958849, acc 0.953125\n",
      "2018-05-13T14:43:50.232846: step 939, loss 0.247755, acc 0.890625\n",
      "2018-05-13T14:43:50.696251: step 940, loss 0.203508, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:43:51.220555: step 940, loss 0.329375, acc 0.886926\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-940\n",
      "\n",
      "2018-05-13T14:43:51.830048: step 941, loss 0.120734, acc 0.953125\n",
      "2018-05-13T14:43:52.307475: step 942, loss 0.268236, acc 0.84375\n",
      "2018-05-13T14:43:52.765824: step 943, loss 0.128736, acc 0.9375\n",
      "2018-05-13T14:43:53.236684: step 944, loss 0.199025, acc 0.859375\n",
      "2018-05-13T14:43:53.739265: step 945, loss 0.123424, acc 0.9375\n",
      "2018-05-13T14:43:54.218871: step 946, loss 0.225231, acc 0.84375\n",
      "2018-05-13T14:43:54.737738: step 947, loss 0.217607, acc 0.875\n",
      "2018-05-13T14:43:55.254852: step 948, loss 0.171358, acc 0.890625\n",
      "2018-05-13T14:43:55.681681: step 949, loss 0.175932, acc 0.859375\n",
      "2018-05-13T14:43:56.078261: step 950, loss 0.13702, acc 0.9375\n",
      "2018-05-13T14:43:56.476389: step 951, loss 0.271921, acc 0.90625\n",
      "2018-05-13T14:43:56.906278: step 952, loss 0.142471, acc 0.9375\n",
      "2018-05-13T14:43:57.339187: step 953, loss 0.216731, acc 0.875\n",
      "2018-05-13T14:43:57.797240: step 954, loss 0.158059, acc 0.90625\n",
      "2018-05-13T14:43:58.261820: step 955, loss 0.262374, acc 0.875\n",
      "2018-05-13T14:43:58.789519: step 956, loss 0.207148, acc 0.890625\n",
      "2018-05-13T14:43:59.274435: step 957, loss 0.136916, acc 0.9375\n",
      "2018-05-13T14:43:59.810206: step 958, loss 0.119936, acc 0.9375\n",
      "2018-05-13T14:44:00.233410: step 959, loss 0.184028, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-13T14:44:00.555045: step 960, loss 0.176656, acc 0.882353\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:44:01.077589: step 960, loss 0.366352, acc 0.897527\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-960\n",
      "\n",
      "2018-05-13T14:44:01.745113: step 961, loss 0.255164, acc 0.828125\n",
      "2018-05-13T14:44:02.290720: step 962, loss 0.145692, acc 0.890625\n",
      "2018-05-13T14:44:02.833147: step 963, loss 0.150111, acc 0.921875\n",
      "2018-05-13T14:44:03.277867: step 964, loss 0.231816, acc 0.890625\n",
      "2018-05-13T14:44:03.800739: step 965, loss 0.0856069, acc 0.96875\n",
      "2018-05-13T14:44:04.314656: step 966, loss 0.178476, acc 0.890625\n",
      "2018-05-13T14:44:04.690720: step 967, loss 0.162248, acc 0.921875\n",
      "2018-05-13T14:44:05.054338: step 968, loss 0.17525, acc 0.921875\n",
      "2018-05-13T14:44:05.429853: step 969, loss 0.121438, acc 0.921875\n",
      "2018-05-13T14:44:05.822917: step 970, loss 0.313759, acc 0.828125\n",
      "2018-05-13T14:44:06.189009: step 971, loss 0.225047, acc 0.875\n",
      "2018-05-13T14:44:06.684786: step 972, loss 0.0950773, acc 0.921875\n",
      "2018-05-13T14:44:07.177394: step 973, loss 0.183176, acc 0.90625\n",
      "2018-05-13T14:44:07.681713: step 974, loss 0.164548, acc 0.90625\n",
      "2018-05-13T14:44:08.150490: step 975, loss 0.22506, acc 0.890625\n",
      "2018-05-13T14:44:08.641918: step 976, loss 0.121013, acc 0.90625\n",
      "2018-05-13T14:44:09.125695: step 977, loss 0.13832, acc 0.953125\n",
      "2018-05-13T14:44:09.624500: step 978, loss 0.162549, acc 0.9375\n",
      "2018-05-13T14:44:09.998594: step 979, loss 0.22893, acc 0.890625\n",
      "2018-05-13T14:44:10.498632: step 980, loss 0.143404, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:44:11.050259: step 980, loss 0.322215, acc 0.879859\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-980\n",
      "\n",
      "2018-05-13T14:44:11.722559: step 981, loss 0.178212, acc 0.90625\n",
      "2018-05-13T14:44:12.200292: step 982, loss 0.282564, acc 0.8125\n",
      "2018-05-13T14:44:12.686938: step 983, loss 0.172941, acc 0.875\n",
      "2018-05-13T14:44:13.150114: step 984, loss 0.187036, acc 0.921875\n",
      "2018-05-13T14:44:13.569068: step 985, loss 0.142045, acc 0.90625\n",
      "2018-05-13T14:44:14.098384: step 986, loss 0.183998, acc 0.9375\n",
      "2018-05-13T14:44:14.648045: step 987, loss 0.172365, acc 0.890625\n",
      "2018-05-13T14:44:15.100395: step 988, loss 0.306218, acc 0.78125\n",
      "2018-05-13T14:44:15.547853: step 989, loss 0.126244, acc 0.921875\n",
      "2018-05-13T14:44:16.048663: step 990, loss 0.207461, acc 0.875\n",
      "2018-05-13T14:44:16.515393: step 991, loss 0.202791, acc 0.828125\n",
      "2018-05-13T14:44:16.907592: step 992, loss 0.203703, acc 0.890625\n",
      "2018-05-13T14:44:17.357573: step 993, loss 0.192523, acc 0.875\n",
      "2018-05-13T14:44:17.858918: step 994, loss 0.19093, acc 0.890625\n",
      "2018-05-13T14:44:18.323983: step 995, loss 0.195039, acc 0.859375\n",
      "2018-05-13T14:44:18.710552: step 996, loss 0.217704, acc 0.875\n",
      "2018-05-13T14:44:19.089419: step 997, loss 0.155262, acc 0.9375\n",
      "2018-05-13T14:44:19.510218: step 998, loss 0.154223, acc 0.859375\n",
      "2018-05-13T14:44:19.892697: step 999, loss 0.301622, acc 0.8125\n",
      "2018-05-13T14:44:20.238074: step 1000, loss 0.23158, acc 0.921569\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:44:20.745813: step 1000, loss 0.38572, acc 0.897527\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-1000\n",
      "\n",
      "2018-05-13T14:44:21.445778: step 1001, loss 0.168183, acc 0.90625\n",
      "2018-05-13T14:44:21.921613: step 1002, loss 0.206429, acc 0.890625\n",
      "2018-05-13T14:44:22.422720: step 1003, loss 0.174888, acc 0.9375\n",
      "2018-05-13T14:44:22.920610: step 1004, loss 0.237559, acc 0.859375\n",
      "2018-05-13T14:44:23.387146: step 1005, loss 0.241874, acc 0.90625\n",
      "2018-05-13T14:44:23.916601: step 1006, loss 0.24516, acc 0.90625\n",
      "2018-05-13T14:44:24.416791: step 1007, loss 0.184051, acc 0.859375\n",
      "2018-05-13T14:44:24.870754: step 1008, loss 0.176983, acc 0.890625\n",
      "2018-05-13T14:44:25.352270: step 1009, loss 0.166851, acc 0.875\n",
      "2018-05-13T14:44:25.847724: step 1010, loss 0.19636, acc 0.921875\n",
      "2018-05-13T14:44:26.308961: step 1011, loss 0.167718, acc 0.921875\n",
      "2018-05-13T14:44:26.814242: step 1012, loss 0.213408, acc 0.875\n",
      "2018-05-13T14:44:27.284338: step 1013, loss 0.138848, acc 0.921875\n",
      "2018-05-13T14:44:27.788222: step 1014, loss 0.185098, acc 0.890625\n",
      "2018-05-13T14:44:28.314193: step 1015, loss 0.203559, acc 0.890625\n",
      "2018-05-13T14:44:28.700843: step 1016, loss 0.189377, acc 0.90625\n",
      "2018-05-13T14:44:29.091824: step 1017, loss 0.176621, acc 0.9375\n",
      "2018-05-13T14:44:29.531902: step 1018, loss 0.186582, acc 0.859375\n",
      "2018-05-13T14:44:30.003349: step 1019, loss 0.102377, acc 0.96875\n",
      "2018-05-13T14:44:30.492389: step 1020, loss 0.141648, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:44:30.966897: step 1020, loss 0.349414, acc 0.897527\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-1020\n",
      "\n",
      "2018-05-13T14:44:31.674607: step 1021, loss 0.1493, acc 0.90625\n",
      "2018-05-13T14:44:32.193781: step 1022, loss 0.107177, acc 0.953125\n",
      "2018-05-13T14:44:32.726239: step 1023, loss 0.125315, acc 0.9375\n",
      "2018-05-13T14:44:33.254653: step 1024, loss 0.32372, acc 0.859375\n",
      "2018-05-13T14:44:33.803503: step 1025, loss 0.13283, acc 0.96875\n",
      "2018-05-13T14:44:34.234896: step 1026, loss 0.223653, acc 0.84375\n",
      "2018-05-13T14:44:34.738747: step 1027, loss 0.15405, acc 0.921875\n",
      "2018-05-13T14:44:35.254847: step 1028, loss 0.121124, acc 0.96875\n",
      "2018-05-13T14:44:35.750398: step 1029, loss 0.162318, acc 0.921875\n",
      "2018-05-13T14:44:36.171716: step 1030, loss 0.154111, acc 0.9375\n",
      "2018-05-13T14:44:36.637060: step 1031, loss 0.186965, acc 0.90625\n",
      "2018-05-13T14:44:37.072584: step 1032, loss 0.157308, acc 0.953125\n",
      "2018-05-13T14:44:37.598342: step 1033, loss 0.121974, acc 0.921875\n",
      "2018-05-13T14:44:38.110206: step 1034, loss 0.0983358, acc 0.96875\n",
      "2018-05-13T14:44:38.570222: step 1035, loss 0.108133, acc 0.96875\n",
      "2018-05-13T14:44:39.110000: step 1036, loss 0.0996418, acc 0.96875\n",
      "2018-05-13T14:44:39.567368: step 1037, loss 0.187682, acc 0.90625\n",
      "2018-05-13T14:44:40.024290: step 1038, loss 0.177735, acc 0.921875\n",
      "2018-05-13T14:44:40.518393: step 1039, loss 0.151548, acc 0.890625\n",
      "2018-05-13T14:44:40.906608: step 1040, loss 0.104331, acc 0.921569\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:44:41.531832: step 1040, loss 0.321616, acc 0.897527\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-1040\n",
      "\n",
      "2018-05-13T14:44:42.278430: step 1041, loss 0.132962, acc 0.921875\n",
      "2018-05-13T14:44:42.795987: step 1042, loss 0.133533, acc 0.96875\n",
      "2018-05-13T14:44:43.375540: step 1043, loss 0.121515, acc 0.953125\n",
      "2018-05-13T14:44:43.938797: step 1044, loss 0.113701, acc 0.953125\n",
      "2018-05-13T14:44:44.499208: step 1045, loss 0.141194, acc 0.9375\n",
      "2018-05-13T14:44:44.991230: step 1046, loss 0.156392, acc 0.921875\n",
      "2018-05-13T14:44:45.464700: step 1047, loss 0.198404, acc 0.875\n",
      "2018-05-13T14:44:45.942115: step 1048, loss 0.206397, acc 0.890625\n",
      "2018-05-13T14:44:46.442621: step 1049, loss 0.165889, acc 0.9375\n",
      "2018-05-13T14:44:46.816762: step 1050, loss 0.146443, acc 0.921875\n",
      "2018-05-13T14:44:47.191190: step 1051, loss 0.152213, acc 0.90625\n",
      "2018-05-13T14:44:47.569262: step 1052, loss 0.0955118, acc 0.953125\n",
      "2018-05-13T14:44:48.042429: step 1053, loss 0.0827594, acc 0.984375\n",
      "2018-05-13T14:44:48.588592: step 1054, loss 0.138539, acc 0.9375\n",
      "2018-05-13T14:44:49.075591: step 1055, loss 0.104112, acc 0.96875\n",
      "2018-05-13T14:44:49.558515: step 1056, loss 0.163487, acc 0.921875\n",
      "2018-05-13T14:44:50.050748: step 1057, loss 0.0811327, acc 0.984375\n",
      "2018-05-13T14:44:50.531764: step 1058, loss 0.0845744, acc 0.96875\n",
      "2018-05-13T14:44:51.044468: step 1059, loss 0.0941694, acc 0.984375\n",
      "2018-05-13T14:44:51.513542: step 1060, loss 0.190433, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:44:52.115108: step 1060, loss 0.356434, acc 0.904594\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-1060\n",
      "\n",
      "2018-05-13T14:44:52.801073: step 1061, loss 0.16983, acc 0.90625\n",
      "2018-05-13T14:44:53.290756: step 1062, loss 0.177909, acc 0.890625\n",
      "2018-05-13T14:44:53.742787: step 1063, loss 0.157784, acc 0.9375\n",
      "2018-05-13T14:44:54.265442: step 1064, loss 0.213215, acc 0.890625\n",
      "2018-05-13T14:44:54.766225: step 1065, loss 0.141449, acc 0.9375\n",
      "2018-05-13T14:44:55.232847: step 1066, loss 0.108919, acc 0.9375\n",
      "2018-05-13T14:44:55.729955: step 1067, loss 0.160088, acc 0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-13T14:44:56.223828: step 1068, loss 0.142588, acc 0.90625\n",
      "2018-05-13T14:44:56.727609: step 1069, loss 0.169849, acc 0.890625\n",
      "2018-05-13T14:44:57.248870: step 1070, loss 0.116933, acc 0.921875\n",
      "2018-05-13T14:44:57.750267: step 1071, loss 0.145303, acc 0.9375\n",
      "2018-05-13T14:44:58.196572: step 1072, loss 0.131546, acc 0.921875\n",
      "2018-05-13T14:44:58.656732: step 1073, loss 0.143882, acc 0.921875\n",
      "2018-05-13T14:44:59.125574: step 1074, loss 0.0998347, acc 0.953125\n",
      "2018-05-13T14:44:59.648027: step 1075, loss 0.110497, acc 0.9375\n",
      "2018-05-13T14:45:00.118077: step 1076, loss 0.119553, acc 0.953125\n",
      "2018-05-13T14:45:00.657617: step 1077, loss 0.100394, acc 0.953125\n",
      "2018-05-13T14:45:01.143438: step 1078, loss 0.212864, acc 0.90625\n",
      "2018-05-13T14:45:01.646308: step 1079, loss 0.114517, acc 0.953125\n",
      "2018-05-13T14:45:02.088182: step 1080, loss 0.0827507, acc 0.980392\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:45:02.564639: step 1080, loss 0.314242, acc 0.904594\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-1080\n",
      "\n",
      "2018-05-13T14:45:03.229691: step 1081, loss 0.149992, acc 0.953125\n",
      "2018-05-13T14:45:03.686572: step 1082, loss 0.0969139, acc 0.9375\n",
      "2018-05-13T14:45:04.171370: step 1083, loss 0.11046, acc 0.921875\n",
      "2018-05-13T14:45:04.671269: step 1084, loss 0.133657, acc 0.953125\n",
      "2018-05-13T14:45:05.176457: step 1085, loss 0.167601, acc 0.921875\n",
      "2018-05-13T14:45:05.673892: step 1086, loss 0.121665, acc 0.9375\n",
      "2018-05-13T14:45:06.166928: step 1087, loss 0.0912306, acc 0.96875\n",
      "2018-05-13T14:45:06.617146: step 1088, loss 0.264565, acc 0.890625\n",
      "2018-05-13T14:45:07.131262: step 1089, loss 0.109405, acc 0.953125\n",
      "2018-05-13T14:45:07.589325: step 1090, loss 0.125685, acc 0.9375\n",
      "2018-05-13T14:45:08.107503: step 1091, loss 0.154842, acc 0.90625\n",
      "2018-05-13T14:45:08.521300: step 1092, loss 0.276601, acc 0.84375\n",
      "2018-05-13T14:45:08.895141: step 1093, loss 0.167431, acc 0.9375\n",
      "2018-05-13T14:45:09.449302: step 1094, loss 0.0729763, acc 0.96875\n",
      "2018-05-13T14:45:09.862220: step 1095, loss 0.146969, acc 0.90625\n",
      "2018-05-13T14:45:10.246384: step 1096, loss 0.159622, acc 0.921875\n",
      "2018-05-13T14:45:10.653513: step 1097, loss 0.142455, acc 0.9375\n",
      "2018-05-13T14:45:11.058369: step 1098, loss 0.104602, acc 0.984375\n",
      "2018-05-13T14:45:11.443498: step 1099, loss 0.20219, acc 0.890625\n",
      "2018-05-13T14:45:11.818861: step 1100, loss 0.212698, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:45:12.306201: step 1100, loss 0.299871, acc 0.893993\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-1100\n",
      "\n",
      "2018-05-13T14:45:13.021255: step 1101, loss 0.140958, acc 0.9375\n",
      "2018-05-13T14:45:13.535133: step 1102, loss 0.191961, acc 0.921875\n",
      "2018-05-13T14:45:14.035793: step 1103, loss 0.173389, acc 0.921875\n",
      "2018-05-13T14:45:14.499608: step 1104, loss 0.306735, acc 0.828125\n",
      "2018-05-13T14:45:15.016456: step 1105, loss 0.0762434, acc 0.984375\n",
      "2018-05-13T14:45:15.574870: step 1106, loss 0.188015, acc 0.921875\n",
      "2018-05-13T14:45:16.073336: step 1107, loss 0.10063, acc 0.96875\n",
      "2018-05-13T14:45:16.587109: step 1108, loss 0.143109, acc 0.953125\n",
      "2018-05-13T14:45:17.046619: step 1109, loss 0.180607, acc 0.890625\n",
      "2018-05-13T14:45:17.577792: step 1110, loss 0.119159, acc 0.9375\n",
      "2018-05-13T14:45:18.121909: step 1111, loss 0.116222, acc 0.9375\n",
      "2018-05-13T14:45:18.667805: step 1112, loss 0.144529, acc 0.90625\n",
      "2018-05-13T14:45:19.126706: step 1113, loss 0.122609, acc 0.953125\n",
      "2018-05-13T14:45:19.658583: step 1114, loss 0.166292, acc 0.90625\n",
      "2018-05-13T14:45:20.169640: step 1115, loss 0.0982777, acc 0.953125\n",
      "2018-05-13T14:45:20.646539: step 1116, loss 0.132763, acc 0.953125\n",
      "2018-05-13T14:45:21.100961: step 1117, loss 0.16751, acc 0.953125\n",
      "2018-05-13T14:45:21.662221: step 1118, loss 0.248893, acc 0.890625\n",
      "2018-05-13T14:45:22.288104: step 1119, loss 0.188029, acc 0.890625\n",
      "2018-05-13T14:45:22.670690: step 1120, loss 0.0800164, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:45:23.318694: step 1120, loss 0.364193, acc 0.897527\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-1120\n",
      "\n",
      "2018-05-13T14:45:24.026234: step 1121, loss 0.10515, acc 0.921875\n",
      "2018-05-13T14:45:24.553378: step 1122, loss 0.129296, acc 0.9375\n",
      "2018-05-13T14:45:25.091221: step 1123, loss 0.150545, acc 0.90625\n",
      "2018-05-13T14:45:25.577338: step 1124, loss 0.093646, acc 0.96875\n",
      "2018-05-13T14:45:26.103181: step 1125, loss 0.184243, acc 0.890625\n",
      "2018-05-13T14:45:26.617367: step 1126, loss 0.0668136, acc 0.984375\n",
      "2018-05-13T14:45:27.161054: step 1127, loss 0.117601, acc 0.9375\n",
      "2018-05-13T14:45:27.695567: step 1128, loss 0.114097, acc 0.953125\n",
      "2018-05-13T14:45:28.226196: step 1129, loss 0.227001, acc 0.875\n",
      "2018-05-13T14:45:28.716488: step 1130, loss 0.0932712, acc 0.953125\n",
      "2018-05-13T14:45:29.198447: step 1131, loss 0.191003, acc 0.90625\n",
      "2018-05-13T14:45:29.673059: step 1132, loss 0.0655262, acc 0.984375\n",
      "2018-05-13T14:45:30.154121: step 1133, loss 0.110121, acc 0.921875\n",
      "2018-05-13T14:45:30.629882: step 1134, loss 0.141891, acc 0.953125\n",
      "2018-05-13T14:45:31.115098: step 1135, loss 0.121532, acc 0.9375\n",
      "2018-05-13T14:45:31.536239: step 1136, loss 0.143462, acc 0.921875\n",
      "2018-05-13T14:45:32.070375: step 1137, loss 0.153208, acc 0.921875\n",
      "2018-05-13T14:45:32.532426: step 1138, loss 0.157726, acc 0.9375\n",
      "2018-05-13T14:45:33.019980: step 1139, loss 0.0956452, acc 0.96875\n",
      "2018-05-13T14:45:33.565478: step 1140, loss 0.194387, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:45:34.167520: step 1140, loss 0.356377, acc 0.893993\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-1140\n",
      "\n",
      "2018-05-13T14:45:34.796137: step 1141, loss 0.117588, acc 0.9375\n",
      "2018-05-13T14:45:35.149858: step 1142, loss 0.116268, acc 0.921875\n",
      "2018-05-13T14:45:35.561040: step 1143, loss 0.107214, acc 0.921875\n",
      "2018-05-13T14:45:36.030519: step 1144, loss 0.121069, acc 0.953125\n",
      "2018-05-13T14:45:36.513666: step 1145, loss 0.127815, acc 0.921875\n",
      "2018-05-13T14:45:36.988800: step 1146, loss 0.191206, acc 0.921875\n",
      "2018-05-13T14:45:37.450843: step 1147, loss 0.15628, acc 0.9375\n",
      "2018-05-13T14:45:37.938039: step 1148, loss 0.131776, acc 0.921875\n",
      "2018-05-13T14:45:38.430814: step 1149, loss 0.115983, acc 0.9375\n",
      "2018-05-13T14:45:38.913989: step 1150, loss 0.123248, acc 0.921875\n",
      "2018-05-13T14:45:39.284100: step 1151, loss 0.150836, acc 0.921875\n",
      "2018-05-13T14:45:39.774607: step 1152, loss 0.222369, acc 0.90625\n",
      "2018-05-13T14:45:40.266962: step 1153, loss 0.158543, acc 0.921875\n",
      "2018-05-13T14:45:40.728767: step 1154, loss 0.148579, acc 0.890625\n",
      "2018-05-13T14:45:41.226309: step 1155, loss 0.246702, acc 0.859375\n",
      "2018-05-13T14:45:41.774178: step 1156, loss 0.136064, acc 0.9375\n",
      "2018-05-13T14:45:42.305769: step 1157, loss 0.193926, acc 0.875\n",
      "2018-05-13T14:45:42.825368: step 1158, loss 0.204394, acc 0.90625\n",
      "2018-05-13T14:45:43.315404: step 1159, loss 0.13426, acc 0.9375\n",
      "2018-05-13T14:45:43.702070: step 1160, loss 0.128674, acc 0.941176\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:45:44.183684: step 1160, loss 0.325405, acc 0.90106\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-1160\n",
      "\n",
      "2018-05-13T14:45:44.915319: step 1161, loss 0.178607, acc 0.890625\n",
      "2018-05-13T14:45:45.428411: step 1162, loss 0.175115, acc 0.90625\n",
      "2018-05-13T14:45:45.887096: step 1163, loss 0.201781, acc 0.90625\n",
      "2018-05-13T14:45:46.376326: step 1164, loss 0.23202, acc 0.890625\n",
      "2018-05-13T14:45:46.850408: step 1165, loss 0.0823881, acc 0.96875\n",
      "2018-05-13T14:45:47.350805: step 1166, loss 0.109894, acc 0.953125\n",
      "2018-05-13T14:45:47.867590: step 1167, loss 0.0660054, acc 0.96875\n",
      "2018-05-13T14:45:48.273724: step 1168, loss 0.140095, acc 0.890625\n",
      "2018-05-13T14:45:48.722711: step 1169, loss 0.152436, acc 0.90625\n",
      "2018-05-13T14:45:49.097117: step 1170, loss 0.146252, acc 0.921875\n",
      "2018-05-13T14:45:49.573591: step 1171, loss 0.0933124, acc 0.96875\n",
      "2018-05-13T14:45:50.114095: step 1172, loss 0.0874758, acc 0.953125\n",
      "2018-05-13T14:45:50.688857: step 1173, loss 0.143782, acc 0.90625\n",
      "2018-05-13T14:45:51.232269: step 1174, loss 0.147424, acc 0.9375\n",
      "2018-05-13T14:45:51.670327: step 1175, loss 0.105379, acc 0.9375\n",
      "2018-05-13T14:45:52.162990: step 1176, loss 0.085241, acc 0.9375\n",
      "2018-05-13T14:45:52.723562: step 1177, loss 0.118631, acc 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-13T14:45:53.236058: step 1178, loss 0.251063, acc 0.875\n",
      "2018-05-13T14:45:53.782071: step 1179, loss 0.180057, acc 0.921875\n",
      "2018-05-13T14:45:54.253319: step 1180, loss 0.0576113, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:45:54.746242: step 1180, loss 0.463618, acc 0.908127\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-1180\n",
      "\n",
      "2018-05-13T14:45:55.303298: step 1181, loss 0.101473, acc 0.96875\n",
      "2018-05-13T14:45:55.726199: step 1182, loss 0.206428, acc 0.875\n",
      "2018-05-13T14:45:56.093234: step 1183, loss 0.114116, acc 0.921875\n",
      "2018-05-13T14:45:56.484271: step 1184, loss 0.106253, acc 0.921875\n",
      "2018-05-13T14:45:56.970780: step 1185, loss 0.0842574, acc 0.953125\n",
      "2018-05-13T14:45:57.449117: step 1186, loss 0.134437, acc 0.921875\n",
      "2018-05-13T14:45:57.988028: step 1187, loss 0.0362582, acc 1\n",
      "2018-05-13T14:45:58.496871: step 1188, loss 0.0663823, acc 0.96875\n",
      "2018-05-13T14:45:58.954870: step 1189, loss 0.0917455, acc 0.9375\n",
      "2018-05-13T14:45:59.491653: step 1190, loss 0.108442, acc 0.921875\n",
      "2018-05-13T14:45:59.905960: step 1191, loss 0.200175, acc 0.921875\n",
      "2018-05-13T14:46:00.300896: step 1192, loss 0.15175, acc 0.9375\n",
      "2018-05-13T14:46:00.708161: step 1193, loss 0.113322, acc 0.9375\n",
      "2018-05-13T14:46:01.101174: step 1194, loss 0.142624, acc 0.953125\n",
      "2018-05-13T14:46:01.549572: step 1195, loss 0.1274, acc 0.9375\n",
      "2018-05-13T14:46:02.017173: step 1196, loss 0.128339, acc 0.9375\n",
      "2018-05-13T14:46:02.442840: step 1197, loss 0.161737, acc 0.9375\n",
      "2018-05-13T14:46:02.848082: step 1198, loss 0.0986501, acc 0.953125\n",
      "2018-05-13T14:46:03.243877: step 1199, loss 0.125134, acc 0.953125\n",
      "2018-05-13T14:46:03.587276: step 1200, loss 0.237346, acc 0.882353\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:46:04.099626: step 1200, loss 0.421509, acc 0.904594\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-1200\n",
      "\n",
      "2018-05-13T14:46:04.792641: step 1201, loss 0.13431, acc 0.9375\n",
      "2018-05-13T14:46:05.230716: step 1202, loss 0.115791, acc 0.921875\n",
      "2018-05-13T14:46:05.612600: step 1203, loss 0.2077, acc 0.921875\n",
      "2018-05-13T14:46:05.978029: step 1204, loss 0.161484, acc 0.9375\n",
      "2018-05-13T14:46:06.373015: step 1205, loss 0.128149, acc 0.9375\n",
      "2018-05-13T14:46:06.799851: step 1206, loss 0.122501, acc 0.96875\n",
      "2018-05-13T14:46:07.176864: step 1207, loss 0.135933, acc 0.9375\n",
      "2018-05-13T14:46:07.563912: step 1208, loss 0.0594581, acc 1\n",
      "2018-05-13T14:46:07.963227: step 1209, loss 0.141289, acc 0.953125\n",
      "2018-05-13T14:46:08.355595: step 1210, loss 0.0745224, acc 0.96875\n",
      "2018-05-13T14:46:08.881968: step 1211, loss 0.166848, acc 0.90625\n",
      "2018-05-13T14:46:09.397459: step 1212, loss 0.132134, acc 0.953125\n",
      "2018-05-13T14:46:09.901543: step 1213, loss 0.141534, acc 0.9375\n",
      "2018-05-13T14:46:10.416348: step 1214, loss 0.0943238, acc 0.96875\n",
      "2018-05-13T14:46:10.897088: step 1215, loss 0.319353, acc 0.890625\n",
      "2018-05-13T14:46:11.371166: step 1216, loss 0.387808, acc 0.890625\n",
      "2018-05-13T14:46:11.840909: step 1217, loss 0.117806, acc 0.96875\n",
      "2018-05-13T14:46:12.238139: step 1218, loss 0.170763, acc 0.90625\n",
      "2018-05-13T14:46:12.798716: step 1219, loss 0.140887, acc 0.953125\n",
      "2018-05-13T14:46:13.318506: step 1220, loss 0.145236, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:46:13.828395: step 1220, loss 0.352328, acc 0.886926\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-1220\n",
      "\n",
      "2018-05-13T14:46:14.530077: step 1221, loss 0.19297, acc 0.921875\n",
      "2018-05-13T14:46:15.027212: step 1222, loss 0.113019, acc 0.96875\n",
      "2018-05-13T14:46:15.398329: step 1223, loss 0.156463, acc 0.921875\n",
      "2018-05-13T14:46:15.861977: step 1224, loss 0.0817626, acc 0.96875\n",
      "2018-05-13T14:46:16.251844: step 1225, loss 0.195031, acc 0.9375\n",
      "2018-05-13T14:46:16.668405: step 1226, loss 0.100039, acc 0.953125\n",
      "2018-05-13T14:46:17.073467: step 1227, loss 0.173519, acc 0.921875\n",
      "2018-05-13T14:46:17.466686: step 1228, loss 0.0572051, acc 0.984375\n",
      "2018-05-13T14:46:17.853865: step 1229, loss 0.0666121, acc 0.96875\n",
      "2018-05-13T14:46:18.240484: step 1230, loss 0.13546, acc 0.9375\n",
      "2018-05-13T14:46:18.644317: step 1231, loss 0.107005, acc 0.953125\n",
      "2018-05-13T14:46:19.036411: step 1232, loss 0.166927, acc 0.90625\n",
      "2018-05-13T14:46:19.431722: step 1233, loss 0.132235, acc 0.921875\n",
      "2018-05-13T14:46:19.871098: step 1234, loss 0.0929225, acc 0.96875\n",
      "2018-05-13T14:46:20.251735: step 1235, loss 0.157431, acc 0.953125\n",
      "2018-05-13T14:46:20.742507: step 1236, loss 0.147409, acc 0.921875\n",
      "2018-05-13T14:46:21.278484: step 1237, loss 0.203308, acc 0.875\n",
      "2018-05-13T14:46:21.863210: step 1238, loss 0.0563864, acc 0.984375\n",
      "2018-05-13T14:46:22.371426: step 1239, loss 0.14479, acc 0.90625\n",
      "2018-05-13T14:46:22.742573: step 1240, loss 0.103166, acc 0.960784\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:46:23.276184: step 1240, loss 0.379392, acc 0.879859\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-1240\n",
      "\n",
      "2018-05-13T14:46:23.921445: step 1241, loss 0.143256, acc 0.921875\n",
      "2018-05-13T14:46:24.418007: step 1242, loss 0.109884, acc 0.96875\n",
      "2018-05-13T14:46:24.900376: step 1243, loss 0.0809447, acc 0.96875\n",
      "2018-05-13T14:46:25.346232: step 1244, loss 0.0865503, acc 0.96875\n",
      "2018-05-13T14:46:25.845298: step 1245, loss 0.0522069, acc 0.984375\n",
      "2018-05-13T14:46:26.362431: step 1246, loss 0.0750517, acc 0.9375\n",
      "2018-05-13T14:46:26.826473: step 1247, loss 0.0974042, acc 0.953125\n",
      "2018-05-13T14:46:27.307103: step 1248, loss 0.143065, acc 0.921875\n",
      "2018-05-13T14:46:27.803432: step 1249, loss 0.184907, acc 0.90625\n",
      "2018-05-13T14:46:28.256602: step 1250, loss 0.0686553, acc 0.953125\n",
      "2018-05-13T14:46:28.699103: step 1251, loss 0.150808, acc 0.921875\n",
      "2018-05-13T14:46:29.179110: step 1252, loss 0.233434, acc 0.890625\n",
      "2018-05-13T14:46:29.622617: step 1253, loss 0.135348, acc 0.90625\n",
      "2018-05-13T14:46:30.070884: step 1254, loss 0.026615, acc 1\n",
      "2018-05-13T14:46:30.538913: step 1255, loss 0.155069, acc 0.921875\n",
      "2018-05-13T14:46:30.999846: step 1256, loss 0.0466989, acc 0.984375\n",
      "2018-05-13T14:46:31.475161: step 1257, loss 0.166686, acc 0.890625\n",
      "2018-05-13T14:46:31.912244: step 1258, loss 0.171106, acc 0.9375\n",
      "2018-05-13T14:46:32.419895: step 1259, loss 0.19161, acc 0.875\n",
      "2018-05-13T14:46:32.959871: step 1260, loss 0.0809586, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:46:33.506384: step 1260, loss 0.358261, acc 0.890459\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-1260\n",
      "\n",
      "2018-05-13T14:46:34.205668: step 1261, loss 0.127018, acc 0.9375\n",
      "2018-05-13T14:46:34.698034: step 1262, loss 0.0667512, acc 0.953125\n",
      "2018-05-13T14:46:35.141915: step 1263, loss 0.0880372, acc 0.953125\n",
      "2018-05-13T14:46:35.598550: step 1264, loss 0.140414, acc 0.90625\n",
      "2018-05-13T14:46:35.973954: step 1265, loss 0.15382, acc 0.90625\n",
      "2018-05-13T14:46:36.346340: step 1266, loss 0.151644, acc 0.90625\n",
      "2018-05-13T14:46:36.730046: step 1267, loss 0.164635, acc 0.921875\n",
      "2018-05-13T14:46:37.099622: step 1268, loss 0.0852481, acc 0.96875\n",
      "2018-05-13T14:46:37.488321: step 1269, loss 0.103495, acc 0.953125\n",
      "2018-05-13T14:46:37.856806: step 1270, loss 0.09011, acc 0.96875\n",
      "2018-05-13T14:46:38.229817: step 1271, loss 0.104325, acc 0.9375\n",
      "2018-05-13T14:46:38.615337: step 1272, loss 0.0662419, acc 0.953125\n",
      "2018-05-13T14:46:39.000776: step 1273, loss 0.0516552, acc 1\n",
      "2018-05-13T14:46:39.378493: step 1274, loss 0.0885091, acc 0.984375\n",
      "2018-05-13T14:46:39.835262: step 1275, loss 0.0920846, acc 0.96875\n",
      "2018-05-13T14:46:40.331225: step 1276, loss 0.170976, acc 0.953125\n",
      "2018-05-13T14:46:40.789661: step 1277, loss 0.129146, acc 0.953125\n",
      "2018-05-13T14:46:41.287964: step 1278, loss 0.108361, acc 0.96875\n",
      "2018-05-13T14:46:41.808361: step 1279, loss 0.0833754, acc 0.953125\n",
      "2018-05-13T14:46:42.207076: step 1280, loss 0.20708, acc 0.901961\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:46:42.661979: step 1280, loss 0.434514, acc 0.890459\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-1280\n",
      "\n",
      "2018-05-13T14:46:43.198535: step 1281, loss 0.066606, acc 0.953125\n",
      "2018-05-13T14:46:43.575080: step 1282, loss 0.106289, acc 0.921875\n",
      "2018-05-13T14:46:43.939712: step 1283, loss 0.168683, acc 0.921875\n",
      "2018-05-13T14:46:44.445853: step 1284, loss 0.175919, acc 0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-13T14:46:44.971404: step 1285, loss 0.0843288, acc 0.9375\n",
      "2018-05-13T14:46:45.531993: step 1286, loss 0.1307, acc 0.9375\n",
      "2018-05-13T14:46:46.060790: step 1287, loss 0.150009, acc 0.90625\n",
      "2018-05-13T14:46:46.557820: step 1288, loss 0.0733695, acc 0.953125\n",
      "2018-05-13T14:46:47.078643: step 1289, loss 0.0785428, acc 0.953125\n",
      "2018-05-13T14:46:47.654389: step 1290, loss 0.0301259, acc 1\n",
      "2018-05-13T14:46:48.162497: step 1291, loss 0.148048, acc 0.921875\n",
      "2018-05-13T14:46:48.629398: step 1292, loss 0.0730828, acc 0.96875\n",
      "2018-05-13T14:46:49.128976: step 1293, loss 0.0615704, acc 0.96875\n",
      "2018-05-13T14:46:49.630977: step 1294, loss 0.0669009, acc 0.96875\n",
      "2018-05-13T14:46:50.091007: step 1295, loss 0.106032, acc 0.9375\n",
      "2018-05-13T14:46:50.575376: step 1296, loss 0.0914895, acc 0.96875\n",
      "2018-05-13T14:46:51.027922: step 1297, loss 0.0991688, acc 0.9375\n",
      "2018-05-13T14:46:51.508320: step 1298, loss 0.120176, acc 0.890625\n",
      "2018-05-13T14:46:51.993396: step 1299, loss 0.106482, acc 0.9375\n",
      "2018-05-13T14:46:52.521374: step 1300, loss 0.0720234, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:46:53.068797: step 1300, loss 0.513846, acc 0.876325\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-1300\n",
      "\n",
      "2018-05-13T14:46:53.697649: step 1301, loss 0.0533053, acc 1\n",
      "2018-05-13T14:46:54.066185: step 1302, loss 0.106, acc 0.953125\n",
      "2018-05-13T14:46:54.429688: step 1303, loss 0.0931004, acc 0.96875\n",
      "2018-05-13T14:46:54.873316: step 1304, loss 0.0540483, acc 0.984375\n",
      "2018-05-13T14:46:55.328983: step 1305, loss 0.211994, acc 0.90625\n",
      "2018-05-13T14:46:55.795341: step 1306, loss 0.132062, acc 0.921875\n",
      "2018-05-13T14:46:56.283522: step 1307, loss 0.0578781, acc 0.984375\n",
      "2018-05-13T14:46:56.756086: step 1308, loss 0.258337, acc 0.875\n",
      "2018-05-13T14:46:57.251882: step 1309, loss 0.165828, acc 0.890625\n",
      "2018-05-13T14:46:57.782471: step 1310, loss 0.146903, acc 0.953125\n",
      "2018-05-13T14:46:58.263758: step 1311, loss 0.0917992, acc 0.9375\n",
      "2018-05-13T14:46:58.775170: step 1312, loss 0.219151, acc 0.90625\n",
      "2018-05-13T14:46:59.156309: step 1313, loss 0.12621, acc 0.921875\n",
      "2018-05-13T14:46:59.549292: step 1314, loss 0.147785, acc 0.9375\n",
      "2018-05-13T14:46:59.973265: step 1315, loss 0.15151, acc 0.90625\n",
      "2018-05-13T14:47:00.433127: step 1316, loss 0.21473, acc 0.859375\n",
      "2018-05-13T14:47:00.914492: step 1317, loss 0.118116, acc 0.9375\n",
      "2018-05-13T14:47:01.384807: step 1318, loss 0.062272, acc 0.984375\n",
      "2018-05-13T14:47:01.908542: step 1319, loss 0.159333, acc 0.90625\n",
      "2018-05-13T14:47:02.369782: step 1320, loss 0.0883003, acc 0.960784\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:47:02.898328: step 1320, loss 0.43391, acc 0.904594\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-1320\n",
      "\n",
      "2018-05-13T14:47:03.626809: step 1321, loss 0.125761, acc 0.9375\n",
      "2018-05-13T14:47:04.108272: step 1322, loss 0.137783, acc 0.9375\n",
      "2018-05-13T14:47:04.603698: step 1323, loss 0.0779979, acc 0.9375\n",
      "2018-05-13T14:47:05.099880: step 1324, loss 0.22, acc 0.90625\n",
      "2018-05-13T14:47:05.594778: step 1325, loss 0.1425, acc 0.921875\n",
      "2018-05-13T14:47:06.072781: step 1326, loss 0.120109, acc 0.953125\n",
      "2018-05-13T14:47:06.490322: step 1327, loss 0.0983031, acc 0.953125\n",
      "2018-05-13T14:47:06.955656: step 1328, loss 0.0709583, acc 0.96875\n",
      "2018-05-13T14:47:07.435828: step 1329, loss 0.204675, acc 0.90625\n",
      "2018-05-13T14:47:07.982497: step 1330, loss 0.0897825, acc 0.921875\n",
      "2018-05-13T14:47:08.455614: step 1331, loss 0.0743238, acc 0.96875\n",
      "2018-05-13T14:47:08.984734: step 1332, loss 0.141775, acc 0.9375\n",
      "2018-05-13T14:47:09.439259: step 1333, loss 0.171376, acc 0.9375\n",
      "2018-05-13T14:47:09.925673: step 1334, loss 0.0882534, acc 0.953125\n",
      "2018-05-13T14:47:10.428510: step 1335, loss 0.136108, acc 0.90625\n",
      "2018-05-13T14:47:10.950525: step 1336, loss 0.11243, acc 0.953125\n",
      "2018-05-13T14:47:11.349233: step 1337, loss 0.160675, acc 0.921875\n",
      "2018-05-13T14:47:11.731639: step 1338, loss 0.0999285, acc 0.953125\n",
      "2018-05-13T14:47:12.152766: step 1339, loss 0.125895, acc 0.921875\n",
      "2018-05-13T14:47:12.541177: step 1340, loss 0.0865547, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:47:13.077466: step 1340, loss 0.380937, acc 0.908127\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-1340\n",
      "\n",
      "2018-05-13T14:47:13.742235: step 1341, loss 0.102193, acc 0.9375\n",
      "2018-05-13T14:47:14.225958: step 1342, loss 0.15964, acc 0.9375\n",
      "2018-05-13T14:47:14.697577: step 1343, loss 0.106137, acc 0.9375\n",
      "2018-05-13T14:47:15.180218: step 1344, loss 0.076982, acc 0.96875\n",
      "2018-05-13T14:47:15.620838: step 1345, loss 0.0966092, acc 0.953125\n",
      "2018-05-13T14:47:16.106493: step 1346, loss 0.154373, acc 0.953125\n",
      "2018-05-13T14:47:16.603471: step 1347, loss 0.0751158, acc 0.96875\n",
      "2018-05-13T14:47:17.061582: step 1348, loss 0.10764, acc 0.96875\n",
      "2018-05-13T14:47:17.525849: step 1349, loss 0.0775768, acc 0.96875\n",
      "2018-05-13T14:47:18.000511: step 1350, loss 0.052294, acc 0.984375\n",
      "2018-05-13T14:47:18.444267: step 1351, loss 0.121651, acc 0.9375\n",
      "2018-05-13T14:47:18.897198: step 1352, loss 0.0873093, acc 0.984375\n",
      "2018-05-13T14:47:19.351741: step 1353, loss 0.131531, acc 0.9375\n",
      "2018-05-13T14:47:19.774818: step 1354, loss 0.0767014, acc 0.984375\n",
      "2018-05-13T14:47:20.235078: step 1355, loss 0.0843069, acc 0.953125\n",
      "2018-05-13T14:47:20.719178: step 1356, loss 0.0790518, acc 0.953125\n",
      "2018-05-13T14:47:21.076210: step 1357, loss 0.172572, acc 0.90625\n",
      "2018-05-13T14:47:21.450531: step 1358, loss 0.0733234, acc 0.953125\n",
      "2018-05-13T14:47:21.921989: step 1359, loss 0.145151, acc 0.90625\n",
      "2018-05-13T14:47:22.269969: step 1360, loss 0.100786, acc 0.941176\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:47:22.784416: step 1360, loss 0.390231, acc 0.904594\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-1360\n",
      "\n",
      "2018-05-13T14:47:23.397615: step 1361, loss 0.0716233, acc 0.96875\n",
      "2018-05-13T14:47:23.859667: step 1362, loss 0.0508599, acc 0.96875\n",
      "2018-05-13T14:47:24.275741: step 1363, loss 0.106692, acc 0.9375\n",
      "2018-05-13T14:47:24.775627: step 1364, loss 0.0736704, acc 1\n",
      "2018-05-13T14:47:25.244034: step 1365, loss 0.0912785, acc 0.953125\n",
      "2018-05-13T14:47:25.700605: step 1366, loss 0.170636, acc 0.90625\n",
      "2018-05-13T14:47:26.150961: step 1367, loss 0.0747324, acc 0.953125\n",
      "2018-05-13T14:47:26.651631: step 1368, loss 0.0944414, acc 0.921875\n",
      "2018-05-13T14:47:27.073753: step 1369, loss 0.165245, acc 0.921875\n",
      "2018-05-13T14:47:27.553590: step 1370, loss 0.103366, acc 0.9375\n",
      "2018-05-13T14:47:28.018611: step 1371, loss 0.122599, acc 0.9375\n",
      "2018-05-13T14:47:28.493872: step 1372, loss 0.140549, acc 0.90625\n",
      "2018-05-13T14:47:29.002308: step 1373, loss 0.0783202, acc 0.953125\n",
      "2018-05-13T14:47:29.439869: step 1374, loss 0.0652182, acc 0.953125\n",
      "2018-05-13T14:47:29.898515: step 1375, loss 0.142162, acc 0.953125\n",
      "2018-05-13T14:47:30.257176: step 1376, loss 0.102695, acc 0.953125\n",
      "2018-05-13T14:47:30.636388: step 1377, loss 0.177937, acc 0.921875\n",
      "2018-05-13T14:47:31.009832: step 1378, loss 0.0965297, acc 0.953125\n",
      "2018-05-13T14:47:31.477559: step 1379, loss 0.0978521, acc 0.953125\n",
      "2018-05-13T14:47:31.962425: step 1380, loss 0.0570627, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:47:32.573142: step 1380, loss 0.451462, acc 0.886926\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-1380\n",
      "\n",
      "2018-05-13T14:47:33.190308: step 1381, loss 0.0791648, acc 0.953125\n",
      "2018-05-13T14:47:33.568506: step 1382, loss 0.0878633, acc 0.96875\n",
      "2018-05-13T14:47:33.954854: step 1383, loss 0.111429, acc 0.96875\n",
      "2018-05-13T14:47:34.395730: step 1384, loss 0.15522, acc 0.9375\n",
      "2018-05-13T14:47:34.804298: step 1385, loss 0.139925, acc 0.921875\n",
      "2018-05-13T14:47:35.229558: step 1386, loss 0.161654, acc 0.90625\n",
      "2018-05-13T14:47:35.614764: step 1387, loss 0.0678613, acc 0.96875\n",
      "2018-05-13T14:47:36.055128: step 1388, loss 0.107128, acc 0.9375\n",
      "2018-05-13T14:47:36.522399: step 1389, loss 0.0785225, acc 0.953125\n",
      "2018-05-13T14:47:36.928945: step 1390, loss 0.0957172, acc 0.9375\n",
      "2018-05-13T14:47:37.393064: step 1391, loss 0.0694318, acc 0.953125\n",
      "2018-05-13T14:47:37.810063: step 1392, loss 0.104873, acc 0.96875\n",
      "2018-05-13T14:47:38.275474: step 1393, loss 0.0824054, acc 0.96875\n",
      "2018-05-13T14:47:38.742643: step 1394, loss 0.138138, acc 0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-13T14:47:39.151808: step 1395, loss 0.0764228, acc 0.953125\n",
      "2018-05-13T14:47:39.594964: step 1396, loss 0.130351, acc 0.9375\n",
      "2018-05-13T14:47:40.013529: step 1397, loss 0.11788, acc 0.9375\n",
      "2018-05-13T14:47:40.469359: step 1398, loss 0.100747, acc 0.953125\n",
      "2018-05-13T14:47:40.923406: step 1399, loss 0.103009, acc 0.9375\n",
      "2018-05-13T14:47:41.262447: step 1400, loss 0.0936434, acc 0.980392\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:47:41.703406: step 1400, loss 0.412043, acc 0.908127\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-1400\n",
      "\n",
      "2018-05-13T14:47:42.339456: step 1401, loss 0.0750653, acc 0.984375\n",
      "2018-05-13T14:47:42.708025: step 1402, loss 0.111989, acc 0.96875\n",
      "2018-05-13T14:47:43.128895: step 1403, loss 0.116811, acc 0.9375\n",
      "2018-05-13T14:47:43.564387: step 1404, loss 0.102807, acc 0.96875\n",
      "2018-05-13T14:47:43.982165: step 1405, loss 0.0877224, acc 0.96875\n",
      "2018-05-13T14:47:44.412359: step 1406, loss 0.0587618, acc 0.984375\n",
      "2018-05-13T14:47:44.883601: step 1407, loss 0.0794886, acc 0.984375\n",
      "2018-05-13T14:47:45.331162: step 1408, loss 0.195703, acc 0.90625\n",
      "2018-05-13T14:47:45.781620: step 1409, loss 0.0683616, acc 0.96875\n",
      "2018-05-13T14:47:46.214051: step 1410, loss 0.137375, acc 0.90625\n",
      "2018-05-13T14:47:46.653322: step 1411, loss 0.138363, acc 0.90625\n",
      "2018-05-13T14:47:47.070493: step 1412, loss 0.104263, acc 0.96875\n",
      "2018-05-13T14:47:47.518968: step 1413, loss 0.176136, acc 0.90625\n",
      "2018-05-13T14:47:47.951609: step 1414, loss 0.0783803, acc 0.96875\n",
      "2018-05-13T14:47:48.409128: step 1415, loss 0.094182, acc 0.953125\n",
      "2018-05-13T14:47:48.892554: step 1416, loss 0.0830518, acc 0.96875\n",
      "2018-05-13T14:47:49.390878: step 1417, loss 0.0813986, acc 0.96875\n",
      "2018-05-13T14:47:49.883699: step 1418, loss 0.105372, acc 0.953125\n",
      "2018-05-13T14:47:50.287419: step 1419, loss 0.0646257, acc 0.96875\n",
      "2018-05-13T14:47:50.661458: step 1420, loss 0.0923645, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:47:51.065911: step 1420, loss 0.428862, acc 0.90106\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-1420\n",
      "\n",
      "2018-05-13T14:47:51.709464: step 1421, loss 0.055505, acc 0.96875\n",
      "2018-05-13T14:47:52.209027: step 1422, loss 0.0906942, acc 0.953125\n",
      "2018-05-13T14:47:52.674534: step 1423, loss 0.0539282, acc 0.96875\n",
      "2018-05-13T14:47:53.142854: step 1424, loss 0.0768245, acc 0.953125\n",
      "2018-05-13T14:47:53.578806: step 1425, loss 0.0813823, acc 0.9375\n",
      "2018-05-13T14:47:54.100455: step 1426, loss 0.0379581, acc 0.984375\n",
      "2018-05-13T14:47:54.496641: step 1427, loss 0.13582, acc 0.921875\n",
      "2018-05-13T14:47:54.989971: step 1428, loss 0.120813, acc 0.9375\n",
      "2018-05-13T14:47:55.519265: step 1429, loss 0.105523, acc 0.953125\n",
      "2018-05-13T14:47:56.042133: step 1430, loss 0.060547, acc 0.984375\n",
      "2018-05-13T14:47:56.437002: step 1431, loss 0.112573, acc 0.9375\n",
      "2018-05-13T14:47:56.922280: step 1432, loss 0.133068, acc 0.921875\n",
      "2018-05-13T14:47:57.437798: step 1433, loss 0.173908, acc 0.953125\n",
      "2018-05-13T14:47:57.926297: step 1434, loss 0.0854722, acc 0.96875\n",
      "2018-05-13T14:47:58.411152: step 1435, loss 0.0609042, acc 0.96875\n",
      "2018-05-13T14:47:58.905750: step 1436, loss 0.118749, acc 0.921875\n",
      "2018-05-13T14:47:59.417387: step 1437, loss 0.0733519, acc 0.953125\n",
      "2018-05-13T14:47:59.902561: step 1438, loss 0.0606254, acc 0.96875\n",
      "2018-05-13T14:48:00.380314: step 1439, loss 0.163614, acc 0.875\n",
      "2018-05-13T14:48:00.812939: step 1440, loss 0.0463568, acc 0.980392\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:48:01.385920: step 1440, loss 0.376811, acc 0.90106\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-1440\n",
      "\n",
      "2018-05-13T14:48:02.135736: step 1441, loss 0.131134, acc 0.921875\n",
      "2018-05-13T14:48:02.658398: step 1442, loss 0.146014, acc 0.875\n",
      "2018-05-13T14:48:03.165774: step 1443, loss 0.123632, acc 0.953125\n",
      "2018-05-13T14:48:03.617125: step 1444, loss 0.0939985, acc 0.953125\n",
      "2018-05-13T14:48:04.102543: step 1445, loss 0.161668, acc 0.953125\n",
      "2018-05-13T14:48:04.584329: step 1446, loss 0.0545013, acc 0.984375\n",
      "2018-05-13T14:48:04.985208: step 1447, loss 0.113639, acc 0.921875\n",
      "2018-05-13T14:48:05.445605: step 1448, loss 0.0997953, acc 0.953125\n",
      "2018-05-13T14:48:05.824237: step 1449, loss 0.0913831, acc 0.9375\n",
      "2018-05-13T14:48:06.243541: step 1450, loss 0.115725, acc 0.953125\n",
      "2018-05-13T14:48:06.648962: step 1451, loss 0.192369, acc 0.921875\n",
      "2018-05-13T14:48:07.061227: step 1452, loss 0.0772099, acc 0.96875\n",
      "2018-05-13T14:48:07.474062: step 1453, loss 0.0704347, acc 0.96875\n",
      "2018-05-13T14:48:07.862732: step 1454, loss 0.0453328, acc 0.984375\n",
      "2018-05-13T14:48:08.267700: step 1455, loss 0.132207, acc 0.90625\n",
      "2018-05-13T14:48:08.639812: step 1456, loss 0.149465, acc 0.9375\n",
      "2018-05-13T14:48:09.026662: step 1457, loss 0.108904, acc 0.953125\n",
      "2018-05-13T14:48:09.413422: step 1458, loss 0.0710718, acc 0.96875\n",
      "2018-05-13T14:48:09.777432: step 1459, loss 0.0831158, acc 0.953125\n",
      "2018-05-13T14:48:10.176051: step 1460, loss 0.103209, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:48:10.742389: step 1460, loss 0.45275, acc 0.897527\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-1460\n",
      "\n",
      "2018-05-13T14:48:11.396769: step 1461, loss 0.0560179, acc 0.984375\n",
      "2018-05-13T14:48:11.852541: step 1462, loss 0.147905, acc 0.90625\n",
      "2018-05-13T14:48:12.401629: step 1463, loss 0.0793224, acc 0.96875\n",
      "2018-05-13T14:48:12.975656: step 1464, loss 0.151945, acc 0.96875\n",
      "2018-05-13T14:48:13.450110: step 1465, loss 0.0652439, acc 0.953125\n",
      "2018-05-13T14:48:13.926013: step 1466, loss 0.0571113, acc 0.984375\n",
      "2018-05-13T14:48:14.441806: step 1467, loss 0.0623365, acc 0.96875\n",
      "2018-05-13T14:48:14.870335: step 1468, loss 0.115303, acc 0.921875\n",
      "2018-05-13T14:48:15.257817: step 1469, loss 0.123963, acc 0.9375\n",
      "2018-05-13T14:48:15.638856: step 1470, loss 0.0479925, acc 0.984375\n",
      "2018-05-13T14:48:16.053317: step 1471, loss 0.0769103, acc 0.984375\n",
      "2018-05-13T14:48:16.465314: step 1472, loss 0.118471, acc 0.9375\n",
      "2018-05-13T14:48:16.893052: step 1473, loss 0.172592, acc 0.90625\n",
      "2018-05-13T14:48:17.359653: step 1474, loss 0.164173, acc 0.90625\n",
      "2018-05-13T14:48:17.755539: step 1475, loss 0.146053, acc 0.90625\n",
      "2018-05-13T14:48:18.211926: step 1476, loss 0.0855817, acc 0.9375\n",
      "2018-05-13T14:48:18.600513: step 1477, loss 0.0926248, acc 0.96875\n",
      "2018-05-13T14:48:19.084334: step 1478, loss 0.125649, acc 0.953125\n",
      "2018-05-13T14:48:19.584940: step 1479, loss 0.0851986, acc 0.96875\n",
      "2018-05-13T14:48:19.989609: step 1480, loss 0.0532294, acc 0.980392\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:48:20.670568: step 1480, loss 0.400076, acc 0.893993\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-1480\n",
      "\n",
      "2018-05-13T14:48:21.378782: step 1481, loss 0.0733736, acc 0.96875\n",
      "2018-05-13T14:48:21.821856: step 1482, loss 0.163955, acc 0.90625\n",
      "2018-05-13T14:48:22.272936: step 1483, loss 0.017888, acc 1\n",
      "2018-05-13T14:48:22.750572: step 1484, loss 0.0891658, acc 0.96875\n",
      "2018-05-13T14:48:23.224121: step 1485, loss 0.0755496, acc 0.953125\n",
      "2018-05-13T14:48:23.654641: step 1486, loss 0.137214, acc 0.921875\n",
      "2018-05-13T14:48:24.112120: step 1487, loss 0.0962749, acc 0.953125\n",
      "2018-05-13T14:48:24.668779: step 1488, loss 0.0775595, acc 0.953125\n",
      "2018-05-13T14:48:25.119817: step 1489, loss 0.0742393, acc 0.96875\n",
      "2018-05-13T14:48:25.575799: step 1490, loss 0.11523, acc 0.9375\n",
      "2018-05-13T14:48:26.059696: step 1491, loss 0.110049, acc 0.953125\n",
      "2018-05-13T14:48:26.565473: step 1492, loss 0.0668458, acc 0.984375\n",
      "2018-05-13T14:48:27.031933: step 1493, loss 0.0910498, acc 0.953125\n",
      "2018-05-13T14:48:27.518042: step 1494, loss 0.104364, acc 0.96875\n",
      "2018-05-13T14:48:27.979862: step 1495, loss 0.176138, acc 0.9375\n",
      "2018-05-13T14:48:28.545145: step 1496, loss 0.0560909, acc 0.984375\n",
      "2018-05-13T14:48:28.931812: step 1497, loss 0.197145, acc 0.921875\n",
      "2018-05-13T14:48:29.322716: step 1498, loss 0.048354, acc 0.984375\n",
      "2018-05-13T14:48:29.735566: step 1499, loss 0.0867363, acc 0.953125\n",
      "2018-05-13T14:48:30.106828: step 1500, loss 0.22033, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:48:30.605914: step 1500, loss 0.388132, acc 0.897527\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-1500\n",
      "\n",
      "2018-05-13T14:48:31.220273: step 1501, loss 0.152808, acc 0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-13T14:48:31.769529: step 1502, loss 0.0583356, acc 1\n",
      "2018-05-13T14:48:32.300122: step 1503, loss 0.137525, acc 0.9375\n",
      "2018-05-13T14:48:32.888418: step 1504, loss 0.0781788, acc 0.96875\n",
      "2018-05-13T14:48:33.399236: step 1505, loss 0.0743335, acc 0.96875\n",
      "2018-05-13T14:48:33.875344: step 1506, loss 0.141491, acc 0.921875\n",
      "2018-05-13T14:48:34.350128: step 1507, loss 0.101222, acc 0.9375\n",
      "2018-05-13T14:48:34.829808: step 1508, loss 0.154046, acc 0.90625\n",
      "2018-05-13T14:48:35.217507: step 1509, loss 0.141141, acc 0.921875\n",
      "2018-05-13T14:48:35.657919: step 1510, loss 0.151503, acc 0.921875\n",
      "2018-05-13T14:48:36.139372: step 1511, loss 0.0719045, acc 0.96875\n",
      "2018-05-13T14:48:36.612692: step 1512, loss 0.0934121, acc 0.9375\n",
      "2018-05-13T14:48:37.144740: step 1513, loss 0.110206, acc 0.9375\n",
      "2018-05-13T14:48:37.611728: step 1514, loss 0.0844808, acc 0.96875\n",
      "2018-05-13T14:48:38.038354: step 1515, loss 0.156693, acc 0.921875\n",
      "2018-05-13T14:48:38.555024: step 1516, loss 0.0578747, acc 0.984375\n",
      "2018-05-13T14:48:39.047097: step 1517, loss 0.0785294, acc 0.96875\n",
      "2018-05-13T14:48:39.555494: step 1518, loss 0.0982006, acc 0.9375\n",
      "2018-05-13T14:48:40.070815: step 1519, loss 0.118512, acc 0.9375\n",
      "2018-05-13T14:48:40.461183: step 1520, loss 0.0397138, acc 0.980392\n",
      "\n",
      "Evaluation:\n",
      "2018-05-13T14:48:41.004923: step 1520, loss 0.515567, acc 0.890459\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1526189751/checkpoints/model-1520\n",
      "\n",
      "2018-05-13T14:48:41.714743: step 1521, loss 0.105979, acc 0.921875\n",
      "2018-05-13T14:48:42.236099: step 1522, loss 0.201087, acc 0.921875\n",
      "2018-05-13T14:48:42.772923: step 1523, loss 0.110855, acc 0.953125\n",
      "2018-05-13T14:48:43.236487: step 1524, loss 0.128776, acc 0.90625\n",
      "2018-05-13T14:48:43.761554: step 1525, loss 0.105955, acc 0.953125\n",
      "2018-05-13T14:48:44.280031: step 1526, loss 0.150034, acc 0.921875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-c2a49e0a7bc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0mcurrent_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-c2a49e0a7bc0>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(x_batch, y_batch)\u001b[0m\n\u001b[1;32m     57\u001b[0m               \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_keep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdropout_keep_prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             }\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_summary_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mtime_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misoformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    session_conf = tf.ConfigProto(\n",
    "      allow_soft_placement=allow_soft_placement,\n",
    "      log_device_placement=log_device_placement)\n",
    "    sess = tf.Session(config=session_conf)\n",
    "    \n",
    "    with sess.as_default():\n",
    "        \n",
    "        cnn = TextCNN(sequence_length, num_classes, vocab_size, embedding_size, filter_sizes, num_filters, l2_reg_lambda)\n",
    "\n",
    "\n",
    "        global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "        grads_and_vars = optimizer.compute_gradients(cnn.loss)\n",
    "        train_op = optimizer.apply_gradients(grads_and_vars, global_step=global_step)\n",
    "\n",
    "\n",
    "        grad_summaries = []\n",
    "        for g, v in grads_and_vars:\n",
    "            if g is not None:\n",
    "                grad_hist_summary = tf.summary.histogram(\"{}/grad/hist\".format(v.name), g)\n",
    "                sparsity_summary = tf.summary.scalar(\"{}/grad/sparsity\".format(v.name), tf.nn.zero_fraction(g))\n",
    "                grad_summaries.append(grad_hist_summary)\n",
    "                grad_summaries.append(sparsity_summary)\n",
    "        grad_summaries_merged = tf.summary.merge(grad_summaries)\n",
    "\n",
    "\n",
    "        loss_summary = tf.summary.scalar(\"loss\", cnn.loss)\n",
    "        acc_summary = tf.summary.scalar(\"accuracy\", cnn.accuracy)\n",
    "\n",
    "        train_summary_op = tf.summary.merge([loss_summary, acc_summary, grad_summaries_merged])\n",
    "        \n",
    "        train_summary_dir = os.path.join(out_dir, \"summaries\", \"train\")\n",
    "        train_summary_writer = tf.summary.FileWriter(train_summary_dir, sess.graph)\n",
    "\n",
    "        test_summary_op = tf.summary.merge([loss_summary, acc_summary])\n",
    "        test_summary_dir = os.path.join(out_dir, \"summaries\", \"test\")\n",
    "        test_summary_writer = tf.summary.FileWriter(test_summary_dir, sess.graph)\n",
    "\n",
    "        if save_checkpoint:\n",
    "            checkpoint_dir = os.path.abspath(os.path.join(out_dir, \"checkpoints\"))\n",
    "            checkpoint_prefix = os.path.join(checkpoint_dir, \"model\")\n",
    "            if not os.path.exists(checkpoint_dir):\n",
    "                os.makedirs(checkpoint_dir)\n",
    "            saver = tf.train.Saver(tf.global_variables(), max_to_keep=num_checkpoints)\n",
    "\n",
    "  \n",
    "        vocab_processor.save(os.path.join(out_dir, \"vocab\"))\n",
    "\n",
    "\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        def train_step(x_batch, y_batch):\n",
    "            feed_dict = {\n",
    "              cnn.input_x: x_batch,\n",
    "              cnn.input_y: y_batch,\n",
    "              cnn.dropout_keep_prob: dropout_keep_prob\n",
    "            }\n",
    "            _, step, summaries, loss, accuracy = sess.run([train_op, global_step, train_summary_op, cnn.loss, cnn.accuracy], feed_dict)\n",
    "            \n",
    "            time_str = datetime.datetime.now().isoformat()\n",
    "            print(\"{}: step {}, loss {:g}, acc {:g}\".format(time_str, step, loss, accuracy))\n",
    "            train_summary_writer.add_summary(summaries, step)\n",
    "\n",
    "        def test_step(x_batch, y_batch, writer=None):\n",
    "            feed_dict = {\n",
    "              cnn.input_x: x_batch,\n",
    "              cnn.input_y: y_batch,\n",
    "              cnn.dropout_keep_prob: 1.0\n",
    "            }\n",
    "            step, summaries, loss, accuracy = sess.run([global_step, test_summary_op, cnn.loss, cnn.accuracy], feed_dict)\n",
    "            time_str = datetime.datetime.now().isoformat()\n",
    "            print(\"{}: step {}, loss {:g}, acc {:g}\".format(time_str, step, loss, accuracy))\n",
    "            if writer:\n",
    "                writer.add_summary(summaries, step)\n",
    "\n",
    "        batches = batch_iter(list(zip(x_train, y_train)), batch_size, num_epochs)\n",
    "        for batch in batches:\n",
    "            x_batch, y_batch = zip(*batch)\n",
    "            train_step(x_batch, y_batch)\n",
    "            current_step = tf.train.global_step(sess, global_step)\n",
    "            \n",
    "            if current_step % evaluate_every == 0:\n",
    "                print(\"\\nEvaluation:\")\n",
    "                test_step(x_test, y_test, writer=test_summary_writer)\n",
    "                print(\"\")\n",
    "                \n",
    "            if save_checkpoint and current_step % evaluate_every == 0:\n",
    "                path = saver.save(sess, checkpoint_prefix, global_step=current_step)\n",
    "                print(\"Saved model checkpoint to {}\\n\".format(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "char level cnn \n",
    "- 1525408577  \n",
    "- 1526189751   good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.train.get_checkpoint_state('./runs/1526189751/checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(x):\n",
    "    with tf.Graph().as_default():\n",
    "        session_conf = tf.ConfigProto(\n",
    "          allow_soft_placement=allow_soft_placement,\n",
    "          log_device_placement=log_device_placement)\n",
    "        sess = tf.Session(config=session_conf)\n",
    "        with sess.as_default():\n",
    "            cnn = TextCNN(\n",
    "                sequence_length=x_train.shape[1],\n",
    "                num_classes=y_train.shape[1],\n",
    "                vocab_size=len(vocab_processor.vocabulary_),\n",
    "                embedding_size=embedding_dim,\n",
    "                filter_sizes=list(map(int, filter_sizes.split(\",\"))),\n",
    "                num_filters=num_filters,\n",
    "                l2_reg_lambda=l2_reg_lambda)\n",
    "\n",
    "            saver = tf.train.Saver()\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            saver.restore(sess, \"runs/1525408577/checkpoints/model-98400\")\n",
    "\n",
    "            feed_dict = {\n",
    "                  cnn.input_x: x,\n",
    "                  cnn.dropout_keep_prob: 1.0\n",
    "                }\n",
    "            feature_5, feature_2 = sess.run([cnn.f_h, cnn.scores ], feed_dict=feed_dict)\n",
    "    return feature_5, feature_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = list(open(\"data/amazon/rating_5.txt\", \"r\").readlines())\n",
    "review = [s.strip() for s in review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "x = []\n",
    "for r in review:\n",
    "    l = r.split(\":::::\")\n",
    "    y.append(float(l[0]))\n",
    "    x.append(l[1].replace(\" \", \"\").replace(\"\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_processor = preprocessing.VocabularyProcessor.restore(os.path.join(\"runs/1525408577\", \"vocab\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(list(vocab_processor.fit_transform(x)))\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_5 ,feature_2 = get_feature(x[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_5[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_5[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0\n",
    "chunk_size = 100\n",
    "for i in range(0, len(x) , chunk_size):\n",
    "    feature_5 ,feature_2 = get_feature(x[i:i+chunk_size])\n",
    "    for f, r in zip(feature_5, y[i:i+chunk_size]):\n",
    "        s  += int(np.argmax(f) == r)\n",
    "    print(s/(i+chunk_size))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(feature_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_2 [0]  #[neg, pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_py3.6)",
   "language": "python",
   "name": "conda_py3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
