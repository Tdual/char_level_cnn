{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset  \n",
    "http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Books_5.json.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/ShopRunner/jupyter-notify\n",
    "```\n",
    "pip install jupyternotify\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tdual/anaconda2/envs/py3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/tdual/anaconda2/envs/py3.6/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from tensorflow.contrib.learn import preprocessing\n",
    "import pickle\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "%load_ext jupyternotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN:\n",
    "\n",
    "    def __init__(\n",
    "      self, sequence_length, num_classes, vocab_size, embedding_size, filter_sizes, num_filters, l2_reg_lambda=0.0):\n",
    "\n",
    "\n",
    "        self.input_x = tf.placeholder(tf.int32, [None, sequence_length], name=\"input_x\")\n",
    "        self.input_y = tf.placeholder(tf.float32, [None, num_classes], name=\"input_y\")\n",
    "        self.dropout_keep_prob = tf.placeholder(tf.float32, name=\"dropout_keep_prob\")\n",
    "\n",
    "        l2_loss = tf.constant(0.0)\n",
    "\n",
    "\n",
    "        with tf.device('/cpu:0'), tf.name_scope(\"embedding\"):\n",
    "            self.W = tf.Variable(tf.random_uniform([vocab_size, embedding_size], -1.0, 1.0), name=\"W\")\n",
    "            self.embedded_chars = tf.nn.embedding_lookup(self.W, self.input_x)\n",
    "            self.embedded_chars_expanded = tf.expand_dims(self.embedded_chars, -1)\n",
    "\n",
    " \n",
    "        pooled_outputs = []\n",
    "        for i, filter_size in enumerate(filter_sizes):\n",
    "            with tf.name_scope(\"conv-maxpool-%s\" % filter_size):\n",
    "                filter_shape = [filter_size, embedding_size, 1, num_filters]\n",
    "                W = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.1), name=\"W\")\n",
    "                b = tf.Variable(tf.constant(0.1, shape=[num_filters]), name=\"b\")\n",
    "                conv = tf.nn.conv2d(self.embedded_chars_expanded,W,strides=[1, 1, 1, 1],padding=\"VALID\", name=\"conv\")\n",
    "                h = tf.nn.relu(tf.nn.bias_add(conv, b), name=\"relu\")\n",
    "                pooled = tf.nn.max_pool(h, ksize=[1, sequence_length - filter_size + 1, 1, 1],strides=[1, 1, 1, 1],padding='VALID',name=\"pool\")\n",
    "                pooled_outputs.append(pooled)\n",
    "\n",
    "\n",
    "        num_filters_total = num_filters * len(filter_sizes)\n",
    "        print(num_filters_total)\n",
    "        self.h_pool = tf.concat(pooled_outputs, 3)\n",
    "        self.h_pool_flat = tf.reshape(self.h_pool, [-1, num_filters_total])\n",
    "        \n",
    "\n",
    "        with tf.name_scope(\"dropout\"):\n",
    "            self.h_drop = tf.nn.dropout(self.h_pool_flat, self.dropout_keep_prob)\n",
    "            \n",
    "                            # add@@@@@@@@\n",
    "            features_size = 5\n",
    "            self.features = tf.Variable(tf.truncated_normal([num_filters_total, features_size], stddev=0.1))\n",
    "            # 384 * 5\n",
    "            self.f_h = tf.matmul(self.h_drop, self.features, )\n",
    "              # (None * 383) *(384 * 5) \n",
    "            #print(self.h_drop) #None * 384 \n",
    "            #print(self.f_h) # None * 5\n",
    "\n",
    "\n",
    "\n",
    "        with tf.name_scope(\"output\"):\n",
    "            W = tf.get_variable(\"W\", shape=[features_size, num_classes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "            #W = tf.get_variable(\"W\", shape=[num_filters_total, num_classes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "            \n",
    "\n",
    "            \n",
    "            b = tf.Variable(tf.constant(0.1, shape=[num_classes]), name=\"b\")\n",
    "            l2_loss += tf.nn.l2_loss(W)\n",
    "            l2_loss += tf.nn.l2_loss(b)\n",
    "            #self.scores = tf.nn.xw_plus_b(self.h_drop, W, b, name=\"scores\")\n",
    "            self.scores = tf.nn.xw_plus_b(self.f_h, W, b, name=\"scores\")\n",
    "            self.predictions = tf.argmax(self.scores, 1, name=\"predictions\")\n",
    "\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            losses = tf.nn.softmax_cross_entropy_with_logits(logits=self.scores, labels=self.input_y)\n",
    "            self.loss = tf.reduce_mean(losses) + l2_reg_lambda * l2_loss\n",
    "\n",
    "        with tf.name_scope(\"accuracy\"):\n",
    "            correct_predictions = tf.equal(self.predictions, tf.argmax(self.input_y, 1))\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "# ==================================================\n",
    "\n",
    "# Data loading params\n",
    "dev_sample_percentage = 0.0005\n",
    "\n",
    "positive_data_file = \"data/amazon/book_pos.txt\"#\"./data/rt-polarity.pos\"\n",
    "negative_data_file = \"data/amazon/book_neg.txt\"#\"./data/rt-polarity.neg\" #\"Data source for the negative data.\")\n",
    "#positive_data_file = \"data/chABSA/pos.txt\"\n",
    "#negative_data_file = \"data/chABSA/neg.txt\"\n",
    "\n",
    "# Model Hyperparameters\n",
    "embedding_dim = 128     #, \"Dimensionality of character embedding (default: 128)\")\n",
    "filter_sizes = \"3,4,5\"        #, \"Comma-separated filter sizes (default: '3,4,5')\")\n",
    "num_filters=128               #, \"Number of filters per filter size (default: 128)\")\n",
    "dropout_keep_prob=0.5 #, \"Dropout keep probability (default: 0.5)\")\n",
    "l2_reg_lambda=0.0          #, \"L2 regularization lambda (default: 0.0)\")\n",
    "\n",
    "# Training parameters\n",
    "batch_size=64                    #, \"Batch Size (default: 64)\")\n",
    "num_epochs=200              #, \"Number of training epochs (default: 200)\")\n",
    "evaluate_every=100         #, \"Evaluate model on dev set after this many steps (default: 100)\")\n",
    "num_checkpoints=5          #, \"Number of checkpoints to store (default: 5)\")\n",
    "\n",
    "# Misc Parameters\n",
    "allow_soft_placement=True    #, \"Allow device soft device placement\")\n",
    "log_device_placement=False  #, \"Log placement of ops on devices\")\n",
    "\n",
    "#FLAGS = tf.flags.FLAGS\n",
    "#FLAGS._parse_flags()\n",
    "#print(\"\\nParameters:\")\n",
    "#for attr, value in sorted(FLAGS.__flags.items()):\n",
    "#    print(\"{}={}\".format(attr.upper(), value))\n",
    "#print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_and_labels(positive_data_file, negative_data_file):\n",
    "       \n",
    "    positive_examples = list(open(positive_data_file, \"r\").readlines())\n",
    "    #positive_examples = [s.strip() for s in positive_examples]\n",
    "    positive_examples = [s.replace(\" \", \"\").replace(\"\", \" \") for s in positive_examples]\n",
    "    \n",
    "    negative_examples = list(open(negative_data_file, \"r\").readlines())\n",
    "    negative_examples = [s.replace(\" \", \"\").replace(\"\", \" \") for s in negative_examples]\n",
    "    #negative_examples = [s.strip() for s in negative_examples]\n",
    "\n",
    "    x_text = positive_examples + negative_examples\n",
    "    #x_text = [clean_str(sent) for sent in x_text]\n",
    "\n",
    "    positive_labels = [[0, 1] for _ in positive_examples]\n",
    "    negative_labels = [[1, 0] for _ in negative_examples]\n",
    "    y = np.concatenate([positive_labels, negative_labels], 0)\n",
    "    return [x_text, y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"3d776bbe-ed70-4718-a576-1e1a15254f16\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"3d776bbe-ed70-4718-a576-1e1a15254f16\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify\n",
    "x_text, y = load_data_and_labels(positive_data_file, negative_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' L o v e t h e c h a r a c t e r s . L o v e t h e l o c a t i o n ! I c a n n o t w a i t f o r t h e n e x t b o o k i n t h e s e r i e s . I w i l l c e r t a i n l y r e a d i t . \\n '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_list = np.array([len(r)for r in x_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   length\n",
       "0     187\n",
       "1     399\n",
       "2     621\n",
       "3     215\n",
       "4     225"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(length_list, columns=[\"length\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>842.351232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1119.140102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>255.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>447.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>931.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>48939.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               length\n",
       "count  1000000.000000\n",
       "mean       842.351232\n",
       "std       1119.140102\n",
       "min          3.000000\n",
       "25%        255.000000\n",
       "50%        447.000000\n",
       "75%        931.000000\n",
       "max      48939.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x1c2918d7b8>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c3a3a7518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist(bins=50,figsize=(10,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_text = [x[:1000] if len(x) > 1000 else x for x in x_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>544.814889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>315.692982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>255.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>447.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>931.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               length\n",
       "count  1000000.000000\n",
       "mean       544.814889\n",
       "std        315.692982\n",
       "min          3.000000\n",
       "25%        255.000000\n",
       "50%        447.000000\n",
       "75%        931.000000\n",
       "max       1000.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_list = np.array([len(r)for r in x_text])\n",
    "df = pd.DataFrame(length_list, columns=[\"length\"])\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x1c2ec304a8>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c2de29898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist(bins=50,figsize=(10,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_text = x_text[:20000]\n",
    "#y = y[:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = \"Ja\" #\"En\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max document length 1000\n"
     ]
    }
   ],
   "source": [
    "if lang == \"En\":\n",
    "    max_document_length = max([len(x.split(\" \")) for x in x_text])\n",
    "elif lang == \"Ja\":\n",
    "    max_document_length = max([len(x) for x in x_text])\n",
    "print(\"max document length\", max_document_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"0c15e9ec-6bcc-419c-b0fc-2da8911d5712\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"0c15e9ec-6bcc-419c-b0fc-2da8911d5712\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vocab_processor = preprocessing.VocabularyProcessor(max_document_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"87fda498-f59c-4c54-b9fc-690395d3458f\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"87fda498-f59c-4c54-b9fc-690395d3458f\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify\n",
    "x = np.array(list(vocab_processor.fit_transform(x_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 66\n",
      "Train/Dev split: 999500/500\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"4c88f79c-bc90-409f-aa49-f9a2f3bd38bd\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"4c88f79c-bc90-409f-aa49-f9a2f3bd38bd\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify\n",
    "np.random.seed(10)\n",
    "shuffle_indices = np.random.permutation(np.arange(len(y)))\n",
    "x_shuffled = x[shuffle_indices]\n",
    "y_shuffled = y[shuffle_indices]\n",
    "\n",
    "dev_sample_index = -1 * int(dev_sample_percentage * float(len(y)))\n",
    "x_train, x_dev = x_shuffled[:dev_sample_index], x_shuffled[dev_sample_index:]\n",
    "y_train, y_dev = y_shuffled[:dev_sample_index], y_shuffled[dev_sample_index:]\n",
    "\n",
    "del x, y, x_shuffled, y_shuffled\n",
    "\n",
    "print(\"Vocabulary Size: {:d}\".format(len(vocab_processor.vocabulary_)))\n",
    "print(\"Train/Dev split: {:d}/{:d}\".format(len(y_train), len(y_dev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999500, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle():\n",
    "    chunk_size =  int(len(x_train)/10)\n",
    "    print(chunk_size)\n",
    "    for i in range(0, len(x_train), chunck_size):\n",
    "        print(i)\n",
    "        end = i+chunck_size\n",
    "        if end < len(x_train):\n",
    "            chunk = x_train[i:  end]\n",
    "        else:\n",
    "            chunk = x_train[i:]\n",
    "            end = len(x_train)\n",
    "        with open(\"data/x_train_{}.pkl\".format(end), \"wb\") as f:\n",
    "            pickle.dump(chunk, f, protocol = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_x_train():\n",
    "    all_size = 999000\n",
    "    chunk_size = 99900\n",
    "    x_train =[]\n",
    "    for i in range(0, all_size, chunck_size):\n",
    "        print(i)\n",
    "        end = i+chunk_size\n",
    "        if end > len(reviews):\n",
    "            end = all_size\n",
    "        with open(\"data/x_train_{}.pkl\".format(end), \"rb\") as f:\n",
    "            x_train += pickle.load(f)\n",
    "        return x_train\n",
    "#x_train = load_x_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iter(data, batch_size, num_epochs, shuffle=True):\n",
    "    \"\"\"\n",
    "    Generates a batch iterator for a dataset.\n",
    "    \"\"\"\n",
    "    data = np.array(data)\n",
    "    data_size = len(data)\n",
    "    num_batches_per_epoch = int((len(data)-1)/batch_size) + 1\n",
    "    for epoch in range(num_epochs):\n",
    "        if shuffle:\n",
    "            shuffle_indices = np.random.permutation(np.arange(data_size))\n",
    "            shuffled_data = data[shuffle_indices]\n",
    "        else:\n",
    "            shuffled_data = data\n",
    "        for batch_num in range(num_batches_per_epoch):\n",
    "            start_index = batch_num * batch_size\n",
    "            end_index = min((batch_num + 1) * batch_size, data_size)\n",
    "            yield shuffled_data[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = x_train.shape[1]\n",
    "num_classes = y_train.shape[1]\n",
    "vocab_size = len(vocab_processor.vocabulary_)\n",
    "embedding_size = embedding_dim\n",
    "filter_sizes = list(map(int, filter_sizes.split(\",\")))\n",
    "num_filters = num_filters\n",
    "l2_reg_lambda = l2_reg_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n",
      "WARNING:tensorflow:From <ipython-input-2-693fcd34cea3>:66: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "INFO:tensorflow:Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name dropout/Variable:0/grad/hist is illegal; using dropout/Variable_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name dropout/Variable:0/grad/sparsity is illegal; using dropout/Variable_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.\n",
      "Writing to /Users/tdual/Workspace/char_level_cnn/runs/1525408577\n",
      "\n",
      "2018-05-04T13:36:20.876862: step 1, loss 3.62537, acc 0.484375\n",
      "2018-05-04T13:36:21.935839: step 2, loss 1.70292, acc 0.46875\n",
      "2018-05-04T13:36:22.896710: step 3, loss 1.86427, acc 0.421875\n",
      "2018-05-04T13:36:23.815385: step 4, loss 2.81936, acc 0.375\n",
      "2018-05-04T13:36:24.868684: step 5, loss 1.63161, acc 0.5625\n",
      "2018-05-04T13:36:26.021525: step 6, loss 1.49806, acc 0.578125\n",
      "2018-05-04T13:36:27.165684: step 7, loss 2.16274, acc 0.46875\n",
      "2018-05-04T13:36:28.156232: step 8, loss 1.59039, acc 0.53125\n",
      "2018-05-04T13:36:29.267620: step 9, loss 1.89034, acc 0.421875\n",
      "2018-05-04T13:36:30.290179: step 10, loss 1.55705, acc 0.5\n",
      "2018-05-04T13:36:31.419512: step 11, loss 1.71019, acc 0.578125\n",
      "2018-05-04T13:36:32.646688: step 12, loss 1.77076, acc 0.421875\n",
      "2018-05-04T13:36:33.779304: step 13, loss 1.60825, acc 0.578125\n",
      "2018-05-04T13:36:34.879526: step 14, loss 1.53229, acc 0.5625\n",
      "2018-05-04T13:36:35.949309: step 15, loss 1.65769, acc 0.5\n",
      "2018-05-04T13:36:37.097282: step 16, loss 1.89985, acc 0.40625\n",
      "2018-05-04T13:36:38.264466: step 17, loss 1.85888, acc 0.53125\n",
      "2018-05-04T13:36:39.393942: step 18, loss 1.40059, acc 0.5625\n",
      "2018-05-04T13:36:40.437625: step 19, loss 1.69758, acc 0.4375\n",
      "2018-05-04T13:36:41.620300: step 20, loss 1.36183, acc 0.5625\n",
      "2018-05-04T13:36:42.810887: step 21, loss 1.59209, acc 0.5\n",
      "2018-05-04T13:36:43.865417: step 22, loss 1.62639, acc 0.484375\n",
      "2018-05-04T13:36:45.076519: step 23, loss 1.54307, acc 0.453125\n",
      "2018-05-04T13:36:46.118633: step 24, loss 1.5006, acc 0.515625\n",
      "2018-05-04T13:36:47.210936: step 25, loss 1.63371, acc 0.46875\n",
      "2018-05-04T13:36:48.256950: step 26, loss 1.26038, acc 0.640625\n",
      "2018-05-04T13:36:49.386798: step 27, loss 1.44275, acc 0.4375\n",
      "2018-05-04T13:36:50.416855: step 28, loss 1.18845, acc 0.5625\n",
      "2018-05-04T13:36:51.602793: step 29, loss 1.2401, acc 0.609375\n",
      "2018-05-04T13:36:52.703452: step 30, loss 1.00024, acc 0.59375\n",
      "2018-05-04T13:36:53.762533: step 31, loss 1.87999, acc 0.40625\n",
      "2018-05-04T13:36:54.870057: step 32, loss 1.43607, acc 0.5\n",
      "2018-05-04T13:36:55.995765: step 33, loss 1.30094, acc 0.59375\n",
      "2018-05-04T13:36:57.030072: step 34, loss 1.34559, acc 0.59375\n",
      "2018-05-04T13:36:58.102478: step 35, loss 1.37413, acc 0.609375\n",
      "2018-05-04T13:36:59.208510: step 36, loss 1.44867, acc 0.59375\n",
      "2018-05-04T13:37:00.276432: step 37, loss 1.08798, acc 0.53125\n",
      "2018-05-04T13:37:01.420739: step 38, loss 1.11786, acc 0.546875\n",
      "2018-05-04T13:37:02.505373: step 39, loss 0.893731, acc 0.609375\n",
      "2018-05-04T13:37:03.758408: step 40, loss 0.972806, acc 0.65625\n",
      "2018-05-04T13:37:04.967416: step 41, loss 0.974937, acc 0.609375\n",
      "2018-05-04T13:37:06.075886: step 42, loss 0.878557, acc 0.578125\n",
      "2018-05-04T13:37:07.185470: step 43, loss 1.24153, acc 0.46875\n",
      "2018-05-04T13:37:08.214058: step 44, loss 1.1611, acc 0.5625\n",
      "2018-05-04T13:37:09.321164: step 45, loss 1.51109, acc 0.515625\n",
      "2018-05-04T13:37:10.482736: step 46, loss 1.21789, acc 0.5625\n",
      "2018-05-04T13:37:11.775169: step 47, loss 1.08502, acc 0.671875\n",
      "2018-05-04T13:37:12.769484: step 48, loss 1.16589, acc 0.640625\n",
      "2018-05-04T13:37:13.749887: step 49, loss 0.803212, acc 0.65625\n",
      "2018-05-04T13:37:14.792985: step 50, loss 1.09748, acc 0.609375\n",
      "2018-05-04T13:37:15.745521: step 51, loss 1.31024, acc 0.421875\n",
      "2018-05-04T13:37:16.762581: step 52, loss 0.988994, acc 0.640625\n",
      "2018-05-04T13:37:17.980418: step 53, loss 1.07628, acc 0.578125\n",
      "2018-05-04T13:37:18.992471: step 54, loss 1.14112, acc 0.5625\n",
      "2018-05-04T13:37:20.167683: step 55, loss 0.892021, acc 0.625\n",
      "2018-05-04T13:37:21.286046: step 56, loss 1.16419, acc 0.53125\n",
      "2018-05-04T13:37:22.346297: step 57, loss 1.00816, acc 0.5625\n",
      "2018-05-04T13:37:23.374371: step 58, loss 1.11622, acc 0.53125\n",
      "2018-05-04T13:37:24.370298: step 59, loss 0.877939, acc 0.671875\n",
      "2018-05-04T13:37:25.385197: step 60, loss 1.01066, acc 0.5625\n",
      "2018-05-04T13:37:26.377078: step 61, loss 0.926593, acc 0.625\n",
      "2018-05-04T13:37:27.397431: step 62, loss 1.0066, acc 0.546875\n",
      "2018-05-04T13:37:28.449974: step 63, loss 0.859656, acc 0.671875\n",
      "2018-05-04T13:37:29.557495: step 64, loss 0.889925, acc 0.640625\n",
      "2018-05-04T13:37:30.588038: step 65, loss 1.05617, acc 0.640625\n",
      "2018-05-04T13:37:31.675601: step 66, loss 0.849365, acc 0.640625\n",
      "2018-05-04T13:37:32.697339: step 67, loss 0.949529, acc 0.515625\n",
      "2018-05-04T13:37:33.729575: step 68, loss 1.00892, acc 0.5\n",
      "2018-05-04T13:37:34.733117: step 69, loss 1.24947, acc 0.53125\n",
      "2018-05-04T13:37:35.776394: step 70, loss 0.851947, acc 0.609375\n",
      "2018-05-04T13:37:36.952015: step 71, loss 1.26754, acc 0.46875\n",
      "2018-05-04T13:37:38.147086: step 72, loss 0.908805, acc 0.640625\n",
      "2018-05-04T13:37:39.197478: step 73, loss 0.95422, acc 0.609375\n",
      "2018-05-04T13:37:40.332081: step 74, loss 0.823327, acc 0.625\n",
      "2018-05-04T13:37:41.790223: step 75, loss 0.848349, acc 0.609375\n",
      "2018-05-04T13:37:43.006253: step 76, loss 0.886769, acc 0.640625\n",
      "2018-05-04T13:37:44.300907: step 77, loss 1.16327, acc 0.53125\n",
      "2018-05-04T13:37:45.581018: step 78, loss 0.996318, acc 0.578125\n",
      "2018-05-04T13:37:46.880671: step 79, loss 0.985704, acc 0.421875\n",
      "2018-05-04T13:37:48.099107: step 80, loss 0.896026, acc 0.6875\n",
      "2018-05-04T13:37:49.288160: step 81, loss 0.893418, acc 0.65625\n",
      "2018-05-04T13:37:50.521479: step 82, loss 0.90595, acc 0.53125\n",
      "2018-05-04T13:37:51.754646: step 83, loss 0.974587, acc 0.640625\n",
      "2018-05-04T13:37:53.000785: step 84, loss 1.01432, acc 0.59375\n",
      "2018-05-04T13:37:54.305032: step 85, loss 0.745492, acc 0.671875\n",
      "2018-05-04T13:37:55.587850: step 86, loss 1.04272, acc 0.46875\n",
      "2018-05-04T13:37:56.856549: step 87, loss 0.771887, acc 0.5625\n",
      "2018-05-04T13:37:58.085420: step 88, loss 1.19328, acc 0.53125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T13:37:59.352340: step 89, loss 0.822404, acc 0.609375\n",
      "2018-05-04T13:38:00.737802: step 90, loss 0.600726, acc 0.734375\n",
      "2018-05-04T13:38:02.183978: step 91, loss 0.667795, acc 0.734375\n",
      "2018-05-04T13:38:03.449266: step 92, loss 0.81888, acc 0.609375\n",
      "2018-05-04T13:38:04.875516: step 93, loss 0.671639, acc 0.671875\n",
      "2018-05-04T13:38:06.390742: step 94, loss 0.78696, acc 0.625\n",
      "2018-05-04T13:38:08.098449: step 95, loss 0.736296, acc 0.671875\n",
      "2018-05-04T13:38:09.760748: step 96, loss 0.865418, acc 0.65625\n",
      "2018-05-04T13:38:11.504977: step 97, loss 0.671652, acc 0.71875\n",
      "2018-05-04T13:38:13.210843: step 98, loss 0.87729, acc 0.625\n",
      "2018-05-04T13:38:14.857164: step 99, loss 0.812422, acc 0.6875\n",
      "2018-05-04T13:38:16.393501: step 100, loss 0.977846, acc 0.59375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T13:38:20.378779: step 100, loss 0.536663, acc 0.706\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-100\n",
      "\n",
      "2018-05-04T13:38:22.749729: step 101, loss 0.894264, acc 0.609375\n",
      "2018-05-04T13:38:24.937483: step 102, loss 0.735389, acc 0.609375\n",
      "2018-05-04T13:38:27.138636: step 103, loss 0.55353, acc 0.734375\n",
      "2018-05-04T13:38:29.800360: step 104, loss 0.769585, acc 0.59375\n",
      "2018-05-04T13:38:32.617446: step 105, loss 0.747263, acc 0.65625\n",
      "2018-05-04T13:38:35.271929: step 106, loss 0.598183, acc 0.71875\n",
      "2018-05-04T13:38:37.516599: step 107, loss 0.78772, acc 0.59375\n",
      "2018-05-04T13:38:40.145762: step 108, loss 0.760819, acc 0.609375\n",
      "2018-05-04T13:38:42.975828: step 109, loss 0.975491, acc 0.578125\n",
      "2018-05-04T13:38:46.262549: step 110, loss 0.871023, acc 0.5625\n",
      "2018-05-04T13:38:49.808494: step 111, loss 0.714206, acc 0.703125\n",
      "2018-05-04T13:38:53.325204: step 112, loss 0.929816, acc 0.546875\n",
      "2018-05-04T13:38:56.362842: step 113, loss 0.63257, acc 0.703125\n",
      "2018-05-04T13:38:59.547906: step 114, loss 1.04393, acc 0.53125\n",
      "2018-05-04T13:39:03.293747: step 115, loss 0.765815, acc 0.578125\n",
      "2018-05-04T13:39:07.183024: step 116, loss 0.650103, acc 0.71875\n",
      "2018-05-04T13:39:11.469812: step 117, loss 0.806444, acc 0.640625\n",
      "2018-05-04T13:39:15.801123: step 118, loss 0.66722, acc 0.609375\n",
      "2018-05-04T13:39:19.910863: step 119, loss 0.687081, acc 0.625\n",
      "2018-05-04T13:39:24.545472: step 120, loss 0.880086, acc 0.578125\n",
      "2018-05-04T13:39:28.654722: step 121, loss 0.940448, acc 0.578125\n",
      "2018-05-04T13:39:32.688319: step 122, loss 0.896073, acc 0.546875\n",
      "2018-05-04T13:39:37.134648: step 123, loss 0.928182, acc 0.5625\n",
      "2018-05-04T13:39:41.601785: step 124, loss 0.774013, acc 0.625\n",
      "2018-05-04T13:39:45.567604: step 125, loss 0.896178, acc 0.546875\n",
      "2018-05-04T13:39:49.069882: step 126, loss 0.685116, acc 0.59375\n",
      "2018-05-04T13:39:52.303248: step 127, loss 0.619856, acc 0.703125\n",
      "2018-05-04T13:39:55.257922: step 128, loss 0.555335, acc 0.75\n",
      "2018-05-04T13:39:58.043151: step 129, loss 0.643623, acc 0.71875\n",
      "2018-05-04T13:40:00.692957: step 130, loss 0.760966, acc 0.578125\n",
      "2018-05-04T13:40:03.478702: step 131, loss 0.865802, acc 0.65625\n",
      "2018-05-04T13:40:05.918474: step 132, loss 0.644835, acc 0.6875\n",
      "2018-05-04T13:40:08.227509: step 133, loss 0.621213, acc 0.765625\n",
      "2018-05-04T13:40:10.559237: step 134, loss 1.00604, acc 0.546875\n",
      "2018-05-04T13:40:12.894533: step 135, loss 0.544702, acc 0.734375\n",
      "2018-05-04T13:40:15.030229: step 136, loss 0.677899, acc 0.6875\n",
      "2018-05-04T13:40:17.049264: step 137, loss 0.611169, acc 0.703125\n",
      "2018-05-04T13:40:19.036010: step 138, loss 0.646229, acc 0.6875\n",
      "2018-05-04T13:40:21.021864: step 139, loss 0.912934, acc 0.640625\n",
      "2018-05-04T13:40:23.004458: step 140, loss 0.451394, acc 0.828125\n",
      "2018-05-04T13:40:24.855971: step 141, loss 0.468435, acc 0.75\n",
      "2018-05-04T13:40:26.731263: step 142, loss 0.82511, acc 0.609375\n",
      "2018-05-04T13:40:28.552356: step 143, loss 0.994175, acc 0.609375\n",
      "2018-05-04T13:40:30.394654: step 144, loss 0.573747, acc 0.703125\n",
      "2018-05-04T13:40:32.158057: step 145, loss 0.692178, acc 0.703125\n",
      "2018-05-04T13:40:34.025038: step 146, loss 0.665276, acc 0.65625\n",
      "2018-05-04T13:40:35.916924: step 147, loss 0.829596, acc 0.59375\n",
      "2018-05-04T13:40:37.693911: step 148, loss 0.690416, acc 0.65625\n",
      "2018-05-04T13:40:39.485292: step 149, loss 0.695479, acc 0.65625\n",
      "2018-05-04T13:40:41.475347: step 150, loss 0.683285, acc 0.71875\n",
      "2018-05-04T13:40:43.265216: step 151, loss 0.778692, acc 0.65625\n",
      "2018-05-04T13:40:44.859026: step 152, loss 0.917906, acc 0.5625\n",
      "2018-05-04T13:40:46.463888: step 153, loss 0.538517, acc 0.765625\n",
      "2018-05-04T13:40:48.024552: step 154, loss 0.752244, acc 0.59375\n",
      "2018-05-04T13:40:49.528392: step 155, loss 0.605247, acc 0.703125\n",
      "2018-05-04T13:40:51.126099: step 156, loss 0.515874, acc 0.78125\n",
      "2018-05-04T13:40:52.720927: step 157, loss 0.677754, acc 0.609375\n",
      "2018-05-04T13:40:54.244105: step 158, loss 0.625233, acc 0.6875\n",
      "2018-05-04T13:40:55.672772: step 159, loss 0.871556, acc 0.546875\n",
      "2018-05-04T13:40:57.191869: step 160, loss 0.815318, acc 0.640625\n",
      "2018-05-04T13:40:58.681118: step 161, loss 0.732134, acc 0.65625\n",
      "2018-05-04T13:41:00.159486: step 162, loss 0.693168, acc 0.59375\n",
      "2018-05-04T13:41:01.674037: step 163, loss 1.10673, acc 0.53125\n",
      "2018-05-04T13:41:03.134650: step 164, loss 0.922749, acc 0.578125\n",
      "2018-05-04T13:41:04.585369: step 165, loss 0.593692, acc 0.765625\n",
      "2018-05-04T13:41:06.020459: step 166, loss 0.732308, acc 0.65625\n",
      "2018-05-04T13:41:07.391148: step 167, loss 0.697615, acc 0.59375\n",
      "2018-05-04T13:41:08.835765: step 168, loss 0.642159, acc 0.671875\n",
      "2018-05-04T13:41:10.193533: step 169, loss 0.647439, acc 0.765625\n",
      "2018-05-04T13:41:11.712459: step 170, loss 0.895875, acc 0.609375\n",
      "2018-05-04T13:41:13.139468: step 171, loss 0.624259, acc 0.703125\n",
      "2018-05-04T13:41:14.600195: step 172, loss 0.759749, acc 0.640625\n",
      "2018-05-04T13:41:16.010592: step 173, loss 0.615025, acc 0.65625\n",
      "2018-05-04T13:41:17.428765: step 174, loss 0.686735, acc 0.625\n",
      "2018-05-04T13:41:18.913864: step 175, loss 0.918201, acc 0.5625\n",
      "2018-05-04T13:41:20.381752: step 176, loss 0.73535, acc 0.59375\n",
      "2018-05-04T13:41:21.986101: step 177, loss 0.707425, acc 0.625\n",
      "2018-05-04T13:41:23.467058: step 178, loss 0.692239, acc 0.71875\n",
      "2018-05-04T13:41:24.967663: step 179, loss 0.836548, acc 0.609375\n",
      "2018-05-04T13:41:26.462028: step 180, loss 0.662712, acc 0.65625\n",
      "2018-05-04T13:41:27.879049: step 181, loss 0.682533, acc 0.609375\n",
      "2018-05-04T13:41:29.305428: step 182, loss 0.705003, acc 0.609375\n",
      "2018-05-04T13:41:30.724331: step 183, loss 0.633235, acc 0.734375\n",
      "2018-05-04T13:41:32.229998: step 184, loss 0.679581, acc 0.640625\n",
      "2018-05-04T13:41:33.679174: step 185, loss 0.778606, acc 0.65625\n",
      "2018-05-04T13:41:35.134826: step 186, loss 0.705681, acc 0.640625\n",
      "2018-05-04T13:41:36.527189: step 187, loss 0.764398, acc 0.625\n",
      "2018-05-04T13:41:37.934447: step 188, loss 0.648971, acc 0.59375\n",
      "2018-05-04T13:41:39.384170: step 189, loss 0.776734, acc 0.65625\n",
      "2018-05-04T13:41:40.768623: step 190, loss 0.578912, acc 0.71875\n",
      "2018-05-04T13:41:42.286921: step 191, loss 0.743774, acc 0.59375\n",
      "2018-05-04T13:41:43.730041: step 192, loss 0.669608, acc 0.640625\n",
      "2018-05-04T13:41:45.198817: step 193, loss 0.590097, acc 0.71875\n",
      "2018-05-04T13:41:46.690701: step 194, loss 0.679643, acc 0.65625\n",
      "2018-05-04T13:41:48.142749: step 195, loss 0.706847, acc 0.71875\n",
      "2018-05-04T13:41:49.564301: step 196, loss 0.798155, acc 0.5625\n",
      "2018-05-04T13:41:51.039356: step 197, loss 0.600733, acc 0.703125\n",
      "2018-05-04T13:41:52.542841: step 198, loss 0.647215, acc 0.671875\n",
      "2018-05-04T13:41:53.986215: step 199, loss 0.658068, acc 0.734375\n",
      "2018-05-04T13:41:55.434232: step 200, loss 0.556502, acc 0.6875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T13:41:58.823733: step 200, loss 0.465479, acc 0.796\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-200\n",
      "\n",
      "2018-05-04T13:42:00.470136: step 201, loss 0.673321, acc 0.6875\n",
      "2018-05-04T13:42:02.099114: step 202, loss 0.735467, acc 0.625\n",
      "2018-05-04T13:42:03.685576: step 203, loss 0.778635, acc 0.59375\n",
      "2018-05-04T13:42:05.217831: step 204, loss 0.51397, acc 0.71875\n",
      "2018-05-04T13:42:06.759918: step 205, loss 0.613146, acc 0.65625\n",
      "2018-05-04T13:42:08.219798: step 206, loss 0.670481, acc 0.6875\n",
      "2018-05-04T13:42:09.622072: step 207, loss 0.837961, acc 0.65625\n",
      "2018-05-04T13:42:11.039326: step 208, loss 0.612239, acc 0.65625\n",
      "2018-05-04T13:42:12.551111: step 209, loss 0.686874, acc 0.6875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T13:42:13.982753: step 210, loss 0.602437, acc 0.71875\n",
      "2018-05-04T13:42:15.393200: step 211, loss 0.667484, acc 0.625\n",
      "2018-05-04T13:42:16.877644: step 212, loss 0.532241, acc 0.78125\n",
      "2018-05-04T13:42:18.299035: step 213, loss 0.609929, acc 0.71875\n",
      "2018-05-04T13:42:19.759016: step 214, loss 0.742268, acc 0.59375\n",
      "2018-05-04T13:42:21.262313: step 215, loss 0.731759, acc 0.65625\n",
      "2018-05-04T13:42:22.724898: step 216, loss 0.642537, acc 0.640625\n",
      "2018-05-04T13:42:24.123663: step 217, loss 0.740346, acc 0.65625\n",
      "2018-05-04T13:42:25.538916: step 218, loss 0.665386, acc 0.6875\n",
      "2018-05-04T13:42:26.993820: step 219, loss 0.499142, acc 0.8125\n",
      "2018-05-04T13:42:28.446340: step 220, loss 0.627676, acc 0.65625\n",
      "2018-05-04T13:42:29.872794: step 221, loss 0.803418, acc 0.625\n",
      "2018-05-04T13:42:31.322520: step 222, loss 0.528306, acc 0.75\n",
      "2018-05-04T13:42:32.789815: step 223, loss 0.686268, acc 0.640625\n",
      "2018-05-04T13:42:34.227061: step 224, loss 0.774166, acc 0.5625\n",
      "2018-05-04T13:42:35.653710: step 225, loss 0.470953, acc 0.8125\n",
      "2018-05-04T13:42:37.136115: step 226, loss 0.628153, acc 0.65625\n",
      "2018-05-04T13:42:38.631531: step 227, loss 0.532725, acc 0.75\n",
      "2018-05-04T13:42:40.090464: step 228, loss 0.556745, acc 0.6875\n",
      "2018-05-04T13:42:41.688907: step 229, loss 0.499461, acc 0.75\n",
      "2018-05-04T13:42:43.239487: step 230, loss 0.610629, acc 0.609375\n",
      "2018-05-04T13:42:44.667724: step 231, loss 0.566889, acc 0.703125\n",
      "2018-05-04T13:42:46.169003: step 232, loss 0.512832, acc 0.765625\n",
      "2018-05-04T13:42:47.634607: step 233, loss 0.694275, acc 0.640625\n",
      "2018-05-04T13:42:49.103254: step 234, loss 0.575327, acc 0.609375\n",
      "2018-05-04T13:42:50.534625: step 235, loss 0.719826, acc 0.65625\n",
      "2018-05-04T13:42:51.989223: step 236, loss 0.593031, acc 0.6875\n",
      "2018-05-04T13:42:53.590514: step 237, loss 0.694513, acc 0.625\n",
      "2018-05-04T13:42:55.105358: step 238, loss 0.730227, acc 0.578125\n",
      "2018-05-04T13:42:56.594484: step 239, loss 0.580801, acc 0.640625\n",
      "2018-05-04T13:42:58.102579: step 240, loss 0.577652, acc 0.71875\n",
      "2018-05-04T13:42:59.601707: step 241, loss 0.726496, acc 0.609375\n",
      "2018-05-04T13:43:01.100688: step 242, loss 0.543306, acc 0.71875\n",
      "2018-05-04T13:43:02.553689: step 243, loss 0.624252, acc 0.640625\n",
      "2018-05-04T13:43:04.167280: step 244, loss 0.571156, acc 0.71875\n",
      "2018-05-04T13:43:05.685235: step 245, loss 0.658701, acc 0.671875\n",
      "2018-05-04T13:43:07.160489: step 246, loss 0.793156, acc 0.625\n",
      "2018-05-04T13:43:08.619091: step 247, loss 0.629897, acc 0.65625\n",
      "2018-05-04T13:43:10.116440: step 248, loss 0.568739, acc 0.703125\n",
      "2018-05-04T13:43:11.561578: step 249, loss 0.642203, acc 0.640625\n",
      "2018-05-04T13:43:13.086796: step 250, loss 0.687113, acc 0.59375\n",
      "2018-05-04T13:43:14.615802: step 251, loss 0.578305, acc 0.6875\n",
      "2018-05-04T13:43:16.106937: step 252, loss 0.622905, acc 0.65625\n",
      "2018-05-04T13:43:17.661195: step 253, loss 0.494111, acc 0.75\n",
      "2018-05-04T13:43:19.211649: step 254, loss 0.800709, acc 0.609375\n",
      "2018-05-04T13:43:20.710012: step 255, loss 0.569378, acc 0.71875\n",
      "2018-05-04T13:43:22.292526: step 256, loss 0.639489, acc 0.640625\n",
      "2018-05-04T13:43:23.774526: step 257, loss 0.550302, acc 0.65625\n",
      "2018-05-04T13:43:25.257718: step 258, loss 0.629399, acc 0.640625\n",
      "2018-05-04T13:43:26.860936: step 259, loss 0.518096, acc 0.734375\n",
      "2018-05-04T13:43:28.418307: step 260, loss 0.542325, acc 0.703125\n",
      "2018-05-04T13:43:30.004157: step 261, loss 0.60898, acc 0.6875\n",
      "2018-05-04T13:43:31.542962: step 262, loss 0.60363, acc 0.703125\n",
      "2018-05-04T13:43:33.225659: step 263, loss 0.647531, acc 0.671875\n",
      "2018-05-04T13:43:34.956071: step 264, loss 0.617453, acc 0.734375\n",
      "2018-05-04T13:43:36.641747: step 265, loss 0.617317, acc 0.703125\n",
      "2018-05-04T13:43:38.296872: step 266, loss 0.513769, acc 0.765625\n",
      "2018-05-04T13:43:39.930034: step 267, loss 0.587497, acc 0.6875\n",
      "2018-05-04T13:43:41.484600: step 268, loss 0.563468, acc 0.71875\n",
      "2018-05-04T13:43:43.148386: step 269, loss 0.458468, acc 0.71875\n",
      "2018-05-04T13:43:44.722327: step 270, loss 0.564732, acc 0.71875\n",
      "2018-05-04T13:43:46.276543: step 271, loss 0.532111, acc 0.6875\n",
      "2018-05-04T13:43:47.800019: step 272, loss 0.559152, acc 0.734375\n",
      "2018-05-04T13:43:49.367401: step 273, loss 0.668615, acc 0.6875\n",
      "2018-05-04T13:43:50.919348: step 274, loss 0.496086, acc 0.75\n",
      "2018-05-04T13:43:52.428442: step 275, loss 0.485516, acc 0.75\n",
      "2018-05-04T13:43:54.034903: step 276, loss 0.550855, acc 0.71875\n",
      "2018-05-04T13:43:55.570458: step 277, loss 0.632433, acc 0.65625\n",
      "2018-05-04T13:43:57.146809: step 278, loss 0.467463, acc 0.75\n",
      "2018-05-04T13:43:58.691078: step 279, loss 0.63948, acc 0.640625\n",
      "2018-05-04T13:44:00.265318: step 280, loss 0.672161, acc 0.65625\n",
      "2018-05-04T13:44:01.745092: step 281, loss 0.579916, acc 0.671875\n",
      "2018-05-04T13:44:03.249821: step 282, loss 0.478898, acc 0.78125\n",
      "2018-05-04T13:44:04.814858: step 283, loss 0.680077, acc 0.703125\n",
      "2018-05-04T13:44:06.380804: step 284, loss 0.466279, acc 0.796875\n",
      "2018-05-04T13:44:07.954913: step 285, loss 0.739557, acc 0.59375\n",
      "2018-05-04T13:44:09.554575: step 286, loss 0.496616, acc 0.734375\n",
      "2018-05-04T13:44:11.216170: step 287, loss 0.578587, acc 0.6875\n",
      "2018-05-04T13:44:12.771583: step 288, loss 0.565852, acc 0.78125\n",
      "2018-05-04T13:44:14.361383: step 289, loss 0.713249, acc 0.609375\n",
      "2018-05-04T13:44:15.879604: step 290, loss 0.46595, acc 0.75\n",
      "2018-05-04T13:44:17.385201: step 291, loss 0.653788, acc 0.640625\n",
      "2018-05-04T13:44:18.968589: step 292, loss 0.523203, acc 0.6875\n",
      "2018-05-04T13:44:20.551771: step 293, loss 0.521318, acc 0.71875\n",
      "2018-05-04T13:44:22.348135: step 294, loss 0.476653, acc 0.78125\n",
      "2018-05-04T13:44:23.982242: step 295, loss 0.530879, acc 0.703125\n",
      "2018-05-04T13:44:25.616799: step 296, loss 0.484135, acc 0.75\n",
      "2018-05-04T13:44:27.326297: step 297, loss 0.599459, acc 0.71875\n",
      "2018-05-04T13:44:28.982123: step 298, loss 0.597844, acc 0.75\n",
      "2018-05-04T13:44:30.698139: step 299, loss 0.475053, acc 0.78125\n",
      "2018-05-04T13:44:32.904302: step 300, loss 0.497014, acc 0.75\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T13:44:36.921660: step 300, loss 0.449258, acc 0.808\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-300\n",
      "\n",
      "2018-05-04T13:44:38.710307: step 301, loss 0.652877, acc 0.671875\n",
      "2018-05-04T13:44:40.275653: step 302, loss 0.528501, acc 0.703125\n",
      "2018-05-04T13:44:42.181390: step 303, loss 0.554887, acc 0.71875\n",
      "2018-05-04T13:44:43.875297: step 304, loss 0.531721, acc 0.71875\n",
      "2018-05-04T13:44:45.639210: step 305, loss 0.643507, acc 0.640625\n",
      "2018-05-04T13:44:47.497384: step 306, loss 0.619439, acc 0.65625\n",
      "2018-05-04T13:44:49.216745: step 307, loss 0.661856, acc 0.6875\n",
      "2018-05-04T13:44:51.089314: step 308, loss 0.689304, acc 0.640625\n",
      "2018-05-04T13:44:52.814107: step 309, loss 0.568471, acc 0.78125\n",
      "2018-05-04T13:44:54.481579: step 310, loss 0.665608, acc 0.609375\n",
      "2018-05-04T13:44:56.153980: step 311, loss 0.568275, acc 0.734375\n",
      "2018-05-04T13:44:57.621687: step 312, loss 0.511743, acc 0.796875\n",
      "2018-05-04T13:44:59.053373: step 313, loss 0.499996, acc 0.75\n",
      "2018-05-04T13:45:00.409858: step 314, loss 0.632969, acc 0.671875\n",
      "2018-05-04T13:45:01.831866: step 315, loss 0.570769, acc 0.734375\n",
      "2018-05-04T13:45:03.103063: step 316, loss 0.547816, acc 0.671875\n",
      "2018-05-04T13:45:04.346088: step 317, loss 0.574058, acc 0.65625\n",
      "2018-05-04T13:45:05.556667: step 318, loss 0.571813, acc 0.75\n",
      "2018-05-04T13:45:06.797650: step 319, loss 0.504615, acc 0.765625\n",
      "2018-05-04T13:45:08.028110: step 320, loss 0.585721, acc 0.765625\n",
      "2018-05-04T13:45:09.271787: step 321, loss 0.554923, acc 0.71875\n",
      "2018-05-04T13:45:10.505066: step 322, loss 0.634332, acc 0.609375\n",
      "2018-05-04T13:45:11.808970: step 323, loss 0.632176, acc 0.625\n",
      "2018-05-04T13:45:13.047078: step 324, loss 0.474729, acc 0.796875\n",
      "2018-05-04T13:45:14.300025: step 325, loss 0.494517, acc 0.78125\n",
      "2018-05-04T13:45:15.503328: step 326, loss 0.578584, acc 0.6875\n",
      "2018-05-04T13:45:16.682967: step 327, loss 0.626342, acc 0.703125\n",
      "2018-05-04T13:45:17.905393: step 328, loss 0.618958, acc 0.671875\n",
      "2018-05-04T13:45:19.122358: step 329, loss 0.549976, acc 0.6875\n",
      "2018-05-04T13:45:20.396486: step 330, loss 0.562631, acc 0.734375\n",
      "2018-05-04T13:45:21.726218: step 331, loss 0.554154, acc 0.765625\n",
      "2018-05-04T13:45:22.962742: step 332, loss 0.524506, acc 0.734375\n",
      "2018-05-04T13:45:24.210967: step 333, loss 0.690546, acc 0.578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T13:45:25.498623: step 334, loss 0.604237, acc 0.640625\n",
      "2018-05-04T13:45:26.903967: step 335, loss 0.474487, acc 0.828125\n",
      "2018-05-04T13:45:28.362681: step 336, loss 0.547836, acc 0.734375\n",
      "2018-05-04T13:45:29.954722: step 337, loss 0.561673, acc 0.6875\n",
      "2018-05-04T13:45:31.756694: step 338, loss 0.537845, acc 0.734375\n",
      "2018-05-04T13:45:33.472241: step 339, loss 0.591282, acc 0.640625\n",
      "2018-05-04T13:45:35.031763: step 340, loss 0.488786, acc 0.765625\n",
      "2018-05-04T13:45:36.557856: step 341, loss 0.596917, acc 0.6875\n",
      "2018-05-04T13:45:38.003688: step 342, loss 0.600303, acc 0.78125\n",
      "2018-05-04T13:45:39.340626: step 343, loss 0.514963, acc 0.734375\n",
      "2018-05-04T13:45:40.747200: step 344, loss 0.553534, acc 0.671875\n",
      "2018-05-04T13:45:42.180752: step 345, loss 0.434891, acc 0.84375\n",
      "2018-05-04T13:45:43.621367: step 346, loss 0.579624, acc 0.734375\n",
      "2018-05-04T13:45:44.981580: step 347, loss 0.606427, acc 0.78125\n",
      "2018-05-04T13:45:46.337351: step 348, loss 0.599379, acc 0.671875\n",
      "2018-05-04T13:45:47.725935: step 349, loss 0.658913, acc 0.671875\n",
      "2018-05-04T13:45:49.215002: step 350, loss 0.560761, acc 0.703125\n",
      "2018-05-04T13:45:50.545941: step 351, loss 0.698403, acc 0.625\n",
      "2018-05-04T13:45:51.884763: step 352, loss 0.537635, acc 0.703125\n",
      "2018-05-04T13:45:53.088963: step 353, loss 0.526057, acc 0.765625\n",
      "2018-05-04T13:45:54.294030: step 354, loss 0.62695, acc 0.65625\n",
      "2018-05-04T13:45:55.645765: step 355, loss 0.450362, acc 0.84375\n",
      "2018-05-04T13:45:56.934936: step 356, loss 0.530744, acc 0.703125\n",
      "2018-05-04T13:45:58.281213: step 357, loss 0.59385, acc 0.65625\n",
      "2018-05-04T13:45:59.699640: step 358, loss 0.450626, acc 0.8125\n",
      "2018-05-04T13:46:01.117311: step 359, loss 0.7039, acc 0.65625\n",
      "2018-05-04T13:46:02.645153: step 360, loss 0.5916, acc 0.65625\n",
      "2018-05-04T13:46:04.330430: step 361, loss 0.529679, acc 0.71875\n",
      "2018-05-04T13:46:05.962347: step 362, loss 0.592173, acc 0.671875\n",
      "2018-05-04T13:46:07.527980: step 363, loss 0.548686, acc 0.75\n",
      "2018-05-04T13:46:09.123989: step 364, loss 0.505451, acc 0.796875\n",
      "2018-05-04T13:46:10.580027: step 365, loss 0.685001, acc 0.59375\n",
      "2018-05-04T13:46:12.175874: step 366, loss 0.496449, acc 0.75\n",
      "2018-05-04T13:46:13.659393: step 367, loss 0.393034, acc 0.828125\n",
      "2018-05-04T13:46:15.175745: step 368, loss 0.533413, acc 0.71875\n",
      "2018-05-04T13:46:16.649969: step 369, loss 0.53967, acc 0.765625\n",
      "2018-05-04T13:46:18.177093: step 370, loss 0.505958, acc 0.75\n",
      "2018-05-04T13:46:19.639024: step 371, loss 0.461093, acc 0.828125\n",
      "2018-05-04T13:46:21.149753: step 372, loss 0.464422, acc 0.765625\n",
      "2018-05-04T13:46:22.599360: step 373, loss 0.494618, acc 0.78125\n",
      "2018-05-04T13:46:24.113457: step 374, loss 0.565571, acc 0.671875\n",
      "2018-05-04T13:46:25.600394: step 375, loss 0.430136, acc 0.796875\n",
      "2018-05-04T13:46:27.099251: step 376, loss 0.577425, acc 0.734375\n",
      "2018-05-04T13:46:28.578677: step 377, loss 0.580399, acc 0.78125\n",
      "2018-05-04T13:46:30.109489: step 378, loss 0.557898, acc 0.6875\n",
      "2018-05-04T13:46:31.682924: step 379, loss 0.523885, acc 0.6875\n",
      "2018-05-04T13:46:33.221774: step 380, loss 0.556732, acc 0.71875\n",
      "2018-05-04T13:46:34.865283: step 381, loss 0.53569, acc 0.6875\n",
      "2018-05-04T13:46:36.452476: step 382, loss 0.570367, acc 0.734375\n",
      "2018-05-04T13:46:38.011101: step 383, loss 0.578007, acc 0.734375\n",
      "2018-05-04T13:46:39.641547: step 384, loss 0.52198, acc 0.671875\n",
      "2018-05-04T13:46:41.278644: step 385, loss 0.44154, acc 0.8125\n",
      "2018-05-04T13:46:42.904390: step 386, loss 0.470096, acc 0.765625\n",
      "2018-05-04T13:46:44.465287: step 387, loss 0.642461, acc 0.59375\n",
      "2018-05-04T13:46:45.958572: step 388, loss 0.507456, acc 0.75\n",
      "2018-05-04T13:46:47.423199: step 389, loss 0.535626, acc 0.75\n",
      "2018-05-04T13:46:48.913441: step 390, loss 0.547077, acc 0.65625\n",
      "2018-05-04T13:46:50.419496: step 391, loss 0.571437, acc 0.6875\n",
      "2018-05-04T13:46:52.019623: step 392, loss 0.613753, acc 0.6875\n",
      "2018-05-04T13:46:53.487714: step 393, loss 0.583212, acc 0.640625\n",
      "2018-05-04T13:46:54.982830: step 394, loss 0.488638, acc 0.765625\n",
      "2018-05-04T13:46:56.481695: step 395, loss 0.587024, acc 0.71875\n",
      "2018-05-04T13:46:57.965305: step 396, loss 0.600277, acc 0.640625\n",
      "2018-05-04T13:46:59.466767: step 397, loss 0.485705, acc 0.765625\n",
      "2018-05-04T13:47:00.964907: step 398, loss 0.417197, acc 0.8125\n",
      "2018-05-04T13:47:02.542451: step 399, loss 0.400931, acc 0.859375\n",
      "2018-05-04T13:47:04.051928: step 400, loss 0.471308, acc 0.78125\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T13:47:08.027420: step 400, loss 0.435317, acc 0.828\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-400\n",
      "\n",
      "2018-05-04T13:47:09.704396: step 401, loss 0.509099, acc 0.71875\n",
      "2018-05-04T13:47:11.150509: step 402, loss 0.452043, acc 0.75\n",
      "2018-05-04T13:47:12.794437: step 403, loss 0.621185, acc 0.65625\n",
      "2018-05-04T13:47:14.310381: step 404, loss 0.455115, acc 0.78125\n",
      "2018-05-04T13:47:15.760002: step 405, loss 0.620906, acc 0.671875\n",
      "2018-05-04T13:47:17.198794: step 406, loss 0.584927, acc 0.65625\n",
      "2018-05-04T13:47:18.582370: step 407, loss 0.6107, acc 0.75\n",
      "2018-05-04T13:47:20.052780: step 408, loss 0.549911, acc 0.75\n",
      "2018-05-04T13:47:21.478134: step 409, loss 0.662205, acc 0.609375\n",
      "2018-05-04T13:47:22.906984: step 410, loss 0.467687, acc 0.734375\n",
      "2018-05-04T13:47:24.421034: step 411, loss 0.523923, acc 0.75\n",
      "2018-05-04T13:47:25.877353: step 412, loss 0.636968, acc 0.671875\n",
      "2018-05-04T13:47:27.261259: step 413, loss 0.478281, acc 0.734375\n",
      "2018-05-04T13:47:28.628837: step 414, loss 0.578571, acc 0.765625\n",
      "2018-05-04T13:47:30.053956: step 415, loss 0.655119, acc 0.671875\n",
      "2018-05-04T13:47:31.493157: step 416, loss 0.45855, acc 0.796875\n",
      "2018-05-04T13:47:32.871451: step 417, loss 0.571552, acc 0.6875\n",
      "2018-05-04T13:47:34.301886: step 418, loss 0.511651, acc 0.75\n",
      "2018-05-04T13:47:35.762779: step 419, loss 0.369471, acc 0.859375\n",
      "2018-05-04T13:47:37.151438: step 420, loss 0.546866, acc 0.65625\n",
      "2018-05-04T13:47:38.497545: step 421, loss 0.548563, acc 0.6875\n",
      "2018-05-04T13:47:39.890706: step 422, loss 0.524516, acc 0.734375\n",
      "2018-05-04T13:47:41.258083: step 423, loss 0.432983, acc 0.859375\n",
      "2018-05-04T13:47:42.601409: step 424, loss 0.447262, acc 0.75\n",
      "2018-05-04T13:47:43.944840: step 425, loss 0.484813, acc 0.765625\n",
      "2018-05-04T13:47:45.482512: step 426, loss 0.538448, acc 0.703125\n",
      "2018-05-04T13:47:46.908894: step 427, loss 0.509197, acc 0.703125\n",
      "2018-05-04T13:47:48.328327: step 428, loss 0.594316, acc 0.703125\n",
      "2018-05-04T13:47:49.692291: step 429, loss 0.54553, acc 0.703125\n",
      "2018-05-04T13:47:51.131921: step 430, loss 0.545548, acc 0.765625\n",
      "2018-05-04T13:47:52.481328: step 431, loss 0.48181, acc 0.796875\n",
      "2018-05-04T13:47:53.899608: step 432, loss 0.532905, acc 0.703125\n",
      "2018-05-04T13:47:55.276458: step 433, loss 0.562896, acc 0.703125\n",
      "2018-05-04T13:47:56.860071: step 434, loss 0.590549, acc 0.6875\n",
      "2018-05-04T13:47:58.376236: step 435, loss 0.498479, acc 0.71875\n",
      "2018-05-04T13:47:59.858372: step 436, loss 0.54235, acc 0.78125\n",
      "2018-05-04T13:48:01.332726: step 437, loss 0.499354, acc 0.734375\n",
      "2018-05-04T13:48:02.747683: step 438, loss 0.663013, acc 0.59375\n",
      "2018-05-04T13:48:04.248507: step 439, loss 0.488762, acc 0.734375\n",
      "2018-05-04T13:48:05.668330: step 440, loss 0.624478, acc 0.703125\n",
      "2018-05-04T13:48:07.251730: step 441, loss 0.491955, acc 0.75\n",
      "2018-05-04T13:48:08.734318: step 442, loss 0.531102, acc 0.734375\n",
      "2018-05-04T13:48:10.227289: step 443, loss 0.482913, acc 0.78125\n",
      "2018-05-04T13:48:11.677114: step 444, loss 0.479296, acc 0.75\n",
      "2018-05-04T13:48:13.150249: step 445, loss 0.678403, acc 0.59375\n",
      "2018-05-04T13:48:14.698814: step 446, loss 0.485538, acc 0.796875\n",
      "2018-05-04T13:48:16.175182: step 447, loss 0.40041, acc 0.796875\n",
      "2018-05-04T13:48:17.636663: step 448, loss 0.584242, acc 0.65625\n",
      "2018-05-04T13:48:19.151921: step 449, loss 0.60005, acc 0.734375\n",
      "2018-05-04T13:48:20.545164: step 450, loss 0.576872, acc 0.703125\n",
      "2018-05-04T13:48:22.043320: step 451, loss 0.562475, acc 0.671875\n",
      "2018-05-04T13:48:23.475689: step 452, loss 0.4775, acc 0.796875\n",
      "2018-05-04T13:48:24.957025: step 453, loss 0.555696, acc 0.71875\n",
      "2018-05-04T13:48:26.450015: step 454, loss 0.500861, acc 0.765625\n",
      "2018-05-04T13:48:27.956156: step 455, loss 0.587158, acc 0.640625\n",
      "2018-05-04T13:48:29.528033: step 456, loss 0.518422, acc 0.765625\n",
      "2018-05-04T13:48:31.134220: step 457, loss 0.44962, acc 0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T13:48:32.789727: step 458, loss 0.457891, acc 0.828125\n",
      "2018-05-04T13:48:34.386482: step 459, loss 0.611198, acc 0.625\n",
      "2018-05-04T13:48:35.957660: step 460, loss 0.460599, acc 0.75\n",
      "2018-05-04T13:48:37.496965: step 461, loss 0.549339, acc 0.765625\n",
      "2018-05-04T13:48:39.033063: step 462, loss 0.68002, acc 0.578125\n",
      "2018-05-04T13:48:40.618904: step 463, loss 0.694736, acc 0.65625\n",
      "2018-05-04T13:48:42.149515: step 464, loss 0.49982, acc 0.71875\n",
      "2018-05-04T13:48:43.907486: step 465, loss 0.563683, acc 0.71875\n",
      "2018-05-04T13:48:45.541651: step 466, loss 0.535921, acc 0.75\n",
      "2018-05-04T13:48:47.062713: step 467, loss 0.500971, acc 0.765625\n",
      "2018-05-04T13:48:48.636103: step 468, loss 0.634062, acc 0.6875\n",
      "2018-05-04T13:48:50.258526: step 469, loss 0.51679, acc 0.75\n",
      "2018-05-04T13:48:51.789129: step 470, loss 0.501391, acc 0.765625\n",
      "2018-05-04T13:48:53.351214: step 471, loss 0.51774, acc 0.765625\n",
      "2018-05-04T13:48:55.023770: step 472, loss 0.394941, acc 0.875\n",
      "2018-05-04T13:48:56.629771: step 473, loss 0.527484, acc 0.75\n",
      "2018-05-04T13:48:58.185420: step 474, loss 0.475386, acc 0.75\n",
      "2018-05-04T13:48:59.731666: step 475, loss 0.598479, acc 0.671875\n",
      "2018-05-04T13:49:01.308998: step 476, loss 0.464275, acc 0.734375\n",
      "2018-05-04T13:49:02.855846: step 477, loss 0.466134, acc 0.828125\n",
      "2018-05-04T13:49:04.411181: step 478, loss 0.540923, acc 0.71875\n",
      "2018-05-04T13:49:05.951084: step 479, loss 0.503717, acc 0.71875\n",
      "2018-05-04T13:49:07.475502: step 480, loss 0.410537, acc 0.8125\n",
      "2018-05-04T13:49:08.957260: step 481, loss 0.606086, acc 0.703125\n",
      "2018-05-04T13:49:10.454469: step 482, loss 0.470061, acc 0.78125\n",
      "2018-05-04T13:49:11.894102: step 483, loss 0.529801, acc 0.703125\n",
      "2018-05-04T13:49:13.399355: step 484, loss 0.520525, acc 0.71875\n",
      "2018-05-04T13:49:14.911390: step 485, loss 0.589107, acc 0.71875\n",
      "2018-05-04T13:49:16.458669: step 486, loss 0.488464, acc 0.75\n",
      "2018-05-04T13:49:18.078072: step 487, loss 0.571024, acc 0.671875\n",
      "2018-05-04T13:49:19.551518: step 488, loss 0.485224, acc 0.765625\n",
      "2018-05-04T13:49:21.064161: step 489, loss 0.586434, acc 0.6875\n",
      "2018-05-04T13:49:22.572844: step 490, loss 0.453478, acc 0.78125\n",
      "2018-05-04T13:49:24.096827: step 491, loss 0.456333, acc 0.78125\n",
      "2018-05-04T13:49:25.565121: step 492, loss 0.481179, acc 0.765625\n",
      "2018-05-04T13:49:27.100163: step 493, loss 0.680287, acc 0.671875\n",
      "2018-05-04T13:49:28.625500: step 494, loss 0.513714, acc 0.703125\n",
      "2018-05-04T13:49:30.149338: step 495, loss 0.517847, acc 0.6875\n",
      "2018-05-04T13:49:31.599910: step 496, loss 0.533965, acc 0.640625\n",
      "2018-05-04T13:49:33.152518: step 497, loss 0.544311, acc 0.6875\n",
      "2018-05-04T13:49:34.756136: step 498, loss 0.532965, acc 0.75\n",
      "2018-05-04T13:49:36.368734: step 499, loss 0.451558, acc 0.8125\n",
      "2018-05-04T13:49:38.021721: step 500, loss 0.494656, acc 0.75\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T13:49:41.680502: step 500, loss 0.419316, acc 0.836\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-500\n",
      "\n",
      "2018-05-04T13:49:43.395823: step 501, loss 0.512485, acc 0.78125\n",
      "2018-05-04T13:49:44.909637: step 502, loss 0.485815, acc 0.765625\n",
      "2018-05-04T13:49:46.482081: step 503, loss 0.538403, acc 0.671875\n",
      "2018-05-04T13:49:48.072977: step 504, loss 0.461017, acc 0.78125\n",
      "2018-05-04T13:49:49.595073: step 505, loss 0.540602, acc 0.734375\n",
      "2018-05-04T13:49:51.119841: step 506, loss 0.63475, acc 0.734375\n",
      "2018-05-04T13:49:52.711198: step 507, loss 0.478621, acc 0.765625\n",
      "2018-05-04T13:49:54.227939: step 508, loss 0.48801, acc 0.75\n",
      "2018-05-04T13:49:55.707171: step 509, loss 0.635847, acc 0.71875\n",
      "2018-05-04T13:49:57.204397: step 510, loss 0.583076, acc 0.671875\n",
      "2018-05-04T13:49:58.691271: step 511, loss 0.524855, acc 0.71875\n",
      "2018-05-04T13:50:00.128849: step 512, loss 0.450433, acc 0.8125\n",
      "2018-05-04T13:50:01.560176: step 513, loss 0.530243, acc 0.78125\n",
      "2018-05-04T13:50:03.063525: step 514, loss 0.470885, acc 0.78125\n",
      "2018-05-04T13:50:04.481113: step 515, loss 0.593423, acc 0.609375\n",
      "2018-05-04T13:50:05.919079: step 516, loss 0.514687, acc 0.734375\n",
      "2018-05-04T13:50:07.403986: step 517, loss 0.548773, acc 0.75\n",
      "2018-05-04T13:50:08.896794: step 518, loss 0.479074, acc 0.765625\n",
      "2018-05-04T13:50:10.392405: step 519, loss 0.49158, acc 0.78125\n",
      "2018-05-04T13:50:11.858984: step 520, loss 0.480128, acc 0.734375\n",
      "2018-05-04T13:50:13.436337: step 521, loss 0.482817, acc 0.828125\n",
      "2018-05-04T13:50:14.973731: step 522, loss 0.594067, acc 0.625\n",
      "2018-05-04T13:50:16.427872: step 523, loss 0.591083, acc 0.71875\n",
      "2018-05-04T13:50:17.923818: step 524, loss 0.554821, acc 0.671875\n",
      "2018-05-04T13:50:19.410666: step 525, loss 0.577392, acc 0.71875\n",
      "2018-05-04T13:50:20.872527: step 526, loss 0.552031, acc 0.734375\n",
      "2018-05-04T13:50:22.358680: step 527, loss 0.638761, acc 0.71875\n",
      "2018-05-04T13:50:23.877989: step 528, loss 0.544572, acc 0.734375\n",
      "2018-05-04T13:50:25.311319: step 529, loss 0.495518, acc 0.796875\n",
      "2018-05-04T13:50:26.739277: step 530, loss 0.572844, acc 0.703125\n",
      "2018-05-04T13:50:28.182969: step 531, loss 0.521817, acc 0.703125\n",
      "2018-05-04T13:50:29.702782: step 532, loss 0.460652, acc 0.765625\n",
      "2018-05-04T13:50:31.177148: step 533, loss 0.424818, acc 0.796875\n",
      "2018-05-04T13:50:32.665041: step 534, loss 0.601386, acc 0.734375\n",
      "2018-05-04T13:50:34.265801: step 535, loss 0.458796, acc 0.734375\n",
      "2018-05-04T13:50:35.729213: step 536, loss 0.344798, acc 0.84375\n",
      "2018-05-04T13:50:37.193947: step 537, loss 0.426529, acc 0.8125\n",
      "2018-05-04T13:50:38.703226: step 538, loss 0.512599, acc 0.75\n",
      "2018-05-04T13:50:40.166206: step 539, loss 0.548149, acc 0.71875\n",
      "2018-05-04T13:50:41.674008: step 540, loss 0.646937, acc 0.703125\n",
      "2018-05-04T13:50:43.105964: step 541, loss 0.470172, acc 0.734375\n",
      "2018-05-04T13:50:44.669401: step 542, loss 0.452707, acc 0.796875\n",
      "2018-05-04T13:50:46.178798: step 543, loss 0.509881, acc 0.75\n",
      "2018-05-04T13:50:47.659610: step 544, loss 0.484367, acc 0.765625\n",
      "2018-05-04T13:50:49.129615: step 545, loss 0.454, acc 0.765625\n",
      "2018-05-04T13:50:50.636387: step 546, loss 0.429234, acc 0.796875\n",
      "2018-05-04T13:50:52.206468: step 547, loss 0.507607, acc 0.796875\n",
      "2018-05-04T13:50:53.710731: step 548, loss 0.638831, acc 0.671875\n",
      "2018-05-04T13:50:55.208387: step 549, loss 0.460246, acc 0.765625\n",
      "2018-05-04T13:50:56.681100: step 550, loss 0.507377, acc 0.796875\n",
      "2018-05-04T13:50:58.172613: step 551, loss 0.490512, acc 0.765625\n",
      "2018-05-04T13:50:59.663896: step 552, loss 0.470273, acc 0.765625\n",
      "2018-05-04T13:51:01.202608: step 553, loss 0.505756, acc 0.75\n",
      "2018-05-04T13:51:02.752607: step 554, loss 0.475557, acc 0.796875\n",
      "2018-05-04T13:51:04.265655: step 555, loss 0.515925, acc 0.75\n",
      "2018-05-04T13:51:05.738385: step 556, loss 0.507673, acc 0.75\n",
      "2018-05-04T13:51:07.213511: step 557, loss 0.515239, acc 0.78125\n",
      "2018-05-04T13:51:08.704329: step 558, loss 0.467551, acc 0.78125\n",
      "2018-05-04T13:51:10.226407: step 559, loss 0.466229, acc 0.765625\n",
      "2018-05-04T13:51:11.783226: step 560, loss 0.52379, acc 0.75\n",
      "2018-05-04T13:51:13.433328: step 561, loss 0.532752, acc 0.796875\n",
      "2018-05-04T13:51:14.996173: step 562, loss 0.555171, acc 0.703125\n",
      "2018-05-04T13:51:16.557853: step 563, loss 0.43495, acc 0.8125\n",
      "2018-05-04T13:51:18.150414: step 564, loss 0.517842, acc 0.765625\n",
      "2018-05-04T13:51:19.714736: step 565, loss 0.472845, acc 0.78125\n",
      "2018-05-04T13:51:21.298629: step 566, loss 0.426058, acc 0.796875\n",
      "2018-05-04T13:51:22.829338: step 567, loss 0.426832, acc 0.78125\n",
      "2018-05-04T13:51:24.407072: step 568, loss 0.597941, acc 0.734375\n",
      "2018-05-04T13:51:25.973666: step 569, loss 0.494846, acc 0.734375\n",
      "2018-05-04T13:51:27.544000: step 570, loss 0.489074, acc 0.78125\n",
      "2018-05-04T13:51:29.080318: step 571, loss 0.483337, acc 0.78125\n",
      "2018-05-04T13:51:30.610364: step 572, loss 0.415351, acc 0.765625\n",
      "2018-05-04T13:51:32.178345: step 573, loss 0.47596, acc 0.78125\n",
      "2018-05-04T13:51:33.826827: step 574, loss 0.621207, acc 0.609375\n",
      "2018-05-04T13:51:35.393097: step 575, loss 0.540461, acc 0.6875\n",
      "2018-05-04T13:51:37.038892: step 576, loss 0.446657, acc 0.796875\n",
      "2018-05-04T13:51:38.687115: step 577, loss 0.650371, acc 0.640625\n",
      "2018-05-04T13:51:40.337432: step 578, loss 0.3993, acc 0.796875\n",
      "2018-05-04T13:51:41.993493: step 579, loss 0.429181, acc 0.71875\n",
      "2018-05-04T13:51:43.727216: step 580, loss 0.546528, acc 0.78125\n",
      "2018-05-04T13:51:45.352128: step 581, loss 0.426695, acc 0.828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T13:51:47.027347: step 582, loss 0.497106, acc 0.734375\n",
      "2018-05-04T13:51:48.685258: step 583, loss 0.535879, acc 0.6875\n",
      "2018-05-04T13:51:50.270135: step 584, loss 0.48197, acc 0.796875\n",
      "2018-05-04T13:51:51.843877: step 585, loss 0.493366, acc 0.78125\n",
      "2018-05-04T13:51:53.518643: step 586, loss 0.407964, acc 0.828125\n",
      "2018-05-04T13:51:55.113882: step 587, loss 0.543662, acc 0.765625\n",
      "2018-05-04T13:51:56.682031: step 588, loss 0.531545, acc 0.734375\n",
      "2018-05-04T13:51:58.288242: step 589, loss 0.560524, acc 0.71875\n",
      "2018-05-04T13:51:59.888409: step 590, loss 0.484806, acc 0.734375\n",
      "2018-05-04T13:52:01.516286: step 591, loss 0.569534, acc 0.734375\n",
      "2018-05-04T13:52:03.245084: step 592, loss 0.507125, acc 0.765625\n",
      "2018-05-04T13:52:04.852708: step 593, loss 0.426121, acc 0.84375\n",
      "2018-05-04T13:52:06.494686: step 594, loss 0.424819, acc 0.859375\n",
      "2018-05-04T13:52:08.132927: step 595, loss 0.47866, acc 0.75\n",
      "2018-05-04T13:52:09.875410: step 596, loss 0.572902, acc 0.734375\n",
      "2018-05-04T13:52:11.642645: step 597, loss 0.375015, acc 0.828125\n",
      "2018-05-04T13:52:13.392034: step 598, loss 0.543414, acc 0.734375\n",
      "2018-05-04T13:52:15.120771: step 599, loss 0.529357, acc 0.75\n",
      "2018-05-04T13:52:16.763997: step 600, loss 0.420515, acc 0.765625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T13:52:20.610814: step 600, loss 0.398192, acc 0.84\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-600\n",
      "\n",
      "2018-05-04T13:52:22.382460: step 601, loss 0.456279, acc 0.765625\n",
      "2018-05-04T13:52:24.033212: step 602, loss 0.416924, acc 0.796875\n",
      "2018-05-04T13:52:25.621297: step 603, loss 0.399417, acc 0.828125\n",
      "2018-05-04T13:52:27.206355: step 604, loss 0.394548, acc 0.859375\n",
      "2018-05-04T13:52:28.778422: step 605, loss 0.517786, acc 0.765625\n",
      "2018-05-04T13:52:30.277851: step 606, loss 0.460811, acc 0.796875\n",
      "2018-05-04T13:52:31.843582: step 607, loss 0.514723, acc 0.75\n",
      "2018-05-04T13:52:33.475408: step 608, loss 0.39611, acc 0.859375\n",
      "2018-05-04T13:52:35.144761: step 609, loss 0.550973, acc 0.75\n",
      "2018-05-04T13:52:36.905507: step 610, loss 0.398409, acc 0.84375\n",
      "2018-05-04T13:52:38.566021: step 611, loss 0.386054, acc 0.828125\n",
      "2018-05-04T13:52:40.230876: step 612, loss 0.5641, acc 0.703125\n",
      "2018-05-04T13:52:41.873623: step 613, loss 0.471505, acc 0.734375\n",
      "2018-05-04T13:52:43.423024: step 614, loss 0.400034, acc 0.8125\n",
      "2018-05-04T13:52:44.935783: step 615, loss 0.485082, acc 0.71875\n",
      "2018-05-04T13:52:46.411825: step 616, loss 0.432847, acc 0.859375\n",
      "2018-05-04T13:52:47.909589: step 617, loss 0.491614, acc 0.765625\n",
      "2018-05-04T13:52:49.406956: step 618, loss 0.560906, acc 0.703125\n",
      "2018-05-04T13:52:50.835944: step 619, loss 0.501973, acc 0.78125\n",
      "2018-05-04T13:52:52.275340: step 620, loss 0.440788, acc 0.78125\n",
      "2018-05-04T13:52:53.746077: step 621, loss 0.530129, acc 0.71875\n",
      "2018-05-04T13:52:55.197259: step 622, loss 0.508823, acc 0.703125\n",
      "2018-05-04T13:52:56.597579: step 623, loss 0.493411, acc 0.71875\n",
      "2018-05-04T13:52:58.022117: step 624, loss 0.565694, acc 0.75\n",
      "2018-05-04T13:52:59.457769: step 625, loss 0.349867, acc 0.890625\n",
      "2018-05-04T13:53:00.900882: step 626, loss 0.447292, acc 0.765625\n",
      "2018-05-04T13:53:02.449893: step 627, loss 0.452956, acc 0.75\n",
      "2018-05-04T13:53:03.917618: step 628, loss 0.410567, acc 0.796875\n",
      "2018-05-04T13:53:05.441955: step 629, loss 0.511463, acc 0.75\n",
      "2018-05-04T13:53:06.882274: step 630, loss 0.339786, acc 0.828125\n",
      "2018-05-04T13:53:08.307737: step 631, loss 0.406693, acc 0.8125\n",
      "2018-05-04T13:53:09.737892: step 632, loss 0.466181, acc 0.75\n",
      "2018-05-04T13:53:11.163799: step 633, loss 0.412982, acc 0.828125\n",
      "2018-05-04T13:53:12.553699: step 634, loss 0.410295, acc 0.8125\n",
      "2018-05-04T13:53:13.951238: step 635, loss 0.420753, acc 0.8125\n",
      "2018-05-04T13:53:15.378874: step 636, loss 0.473005, acc 0.78125\n",
      "2018-05-04T13:53:16.790977: step 637, loss 0.469747, acc 0.75\n",
      "2018-05-04T13:53:18.244862: step 638, loss 0.53654, acc 0.75\n",
      "2018-05-04T13:53:19.680974: step 639, loss 0.522517, acc 0.71875\n",
      "2018-05-04T13:53:21.118736: step 640, loss 0.39802, acc 0.8125\n",
      "2018-05-04T13:53:22.504343: step 641, loss 0.483144, acc 0.75\n",
      "2018-05-04T13:53:23.880198: step 642, loss 0.425521, acc 0.84375\n",
      "2018-05-04T13:53:25.303630: step 643, loss 0.473623, acc 0.765625\n",
      "2018-05-04T13:53:26.682169: step 644, loss 0.576982, acc 0.71875\n",
      "2018-05-04T13:53:28.042521: step 645, loss 0.477728, acc 0.765625\n",
      "2018-05-04T13:53:29.483507: step 646, loss 0.448652, acc 0.78125\n",
      "2018-05-04T13:53:30.897942: step 647, loss 0.430369, acc 0.796875\n",
      "2018-05-04T13:53:32.325485: step 648, loss 0.457307, acc 0.75\n",
      "2018-05-04T13:53:33.719202: step 649, loss 0.595116, acc 0.71875\n",
      "2018-05-04T13:53:35.187005: step 650, loss 0.578956, acc 0.703125\n",
      "2018-05-04T13:53:36.600729: step 651, loss 0.505291, acc 0.75\n",
      "2018-05-04T13:53:38.024167: step 652, loss 0.534614, acc 0.765625\n",
      "2018-05-04T13:53:39.393449: step 653, loss 0.490514, acc 0.84375\n",
      "2018-05-04T13:53:40.792188: step 654, loss 0.502444, acc 0.734375\n",
      "2018-05-04T13:53:42.210327: step 655, loss 0.380266, acc 0.796875\n",
      "2018-05-04T13:53:43.627131: step 656, loss 0.529121, acc 0.734375\n",
      "2018-05-04T13:53:45.058156: step 657, loss 0.470556, acc 0.78125\n",
      "2018-05-04T13:53:46.464320: step 658, loss 0.411435, acc 0.8125\n",
      "2018-05-04T13:53:47.991524: step 659, loss 0.438322, acc 0.796875\n",
      "2018-05-04T13:53:49.401686: step 660, loss 0.454881, acc 0.796875\n",
      "2018-05-04T13:53:50.771896: step 661, loss 0.461203, acc 0.796875\n",
      "2018-05-04T13:53:52.160640: step 662, loss 0.524473, acc 0.71875\n",
      "2018-05-04T13:53:53.548738: step 663, loss 0.457629, acc 0.765625\n",
      "2018-05-04T13:53:55.052947: step 664, loss 0.592152, acc 0.703125\n",
      "2018-05-04T13:53:56.542531: step 665, loss 0.591768, acc 0.6875\n",
      "2018-05-04T13:53:58.015804: step 666, loss 0.470795, acc 0.78125\n",
      "2018-05-04T13:53:59.539050: step 667, loss 0.536651, acc 0.828125\n",
      "2018-05-04T13:54:01.022765: step 668, loss 0.496024, acc 0.75\n",
      "2018-05-04T13:54:02.470328: step 669, loss 0.549877, acc 0.75\n",
      "2018-05-04T13:54:03.922776: step 670, loss 0.449011, acc 0.84375\n",
      "2018-05-04T13:54:05.362410: step 671, loss 0.536367, acc 0.734375\n",
      "2018-05-04T13:54:06.760139: step 672, loss 0.581381, acc 0.734375\n",
      "2018-05-04T13:54:08.217245: step 673, loss 0.379444, acc 0.84375\n",
      "2018-05-04T13:54:09.763705: step 674, loss 0.549034, acc 0.796875\n",
      "2018-05-04T13:54:11.269856: step 675, loss 0.512213, acc 0.71875\n",
      "2018-05-04T13:54:12.865910: step 676, loss 0.453772, acc 0.78125\n",
      "2018-05-04T13:54:14.430993: step 677, loss 0.430474, acc 0.8125\n",
      "2018-05-04T13:54:15.997366: step 678, loss 0.546883, acc 0.703125\n",
      "2018-05-04T13:54:17.545284: step 679, loss 0.462415, acc 0.78125\n",
      "2018-05-04T13:54:19.197231: step 680, loss 0.447133, acc 0.828125\n",
      "2018-05-04T13:54:20.764531: step 681, loss 0.472745, acc 0.78125\n",
      "2018-05-04T13:54:22.304672: step 682, loss 0.434143, acc 0.828125\n",
      "2018-05-04T13:54:23.861201: step 683, loss 0.473206, acc 0.75\n",
      "2018-05-04T13:54:25.369981: step 684, loss 0.521483, acc 0.703125\n",
      "2018-05-04T13:54:26.886696: step 685, loss 0.515381, acc 0.78125\n",
      "2018-05-04T13:54:28.351160: step 686, loss 0.437835, acc 0.796875\n",
      "2018-05-04T13:54:29.828820: step 687, loss 0.38715, acc 0.765625\n",
      "2018-05-04T13:54:31.320038: step 688, loss 0.493241, acc 0.75\n",
      "2018-05-04T13:54:32.833837: step 689, loss 0.446935, acc 0.78125\n",
      "2018-05-04T13:54:34.517599: step 690, loss 0.346481, acc 0.875\n",
      "2018-05-04T13:54:36.090739: step 691, loss 0.502437, acc 0.734375\n",
      "2018-05-04T13:54:37.638215: step 692, loss 0.560547, acc 0.734375\n",
      "2018-05-04T13:54:39.208125: step 693, loss 0.436099, acc 0.8125\n",
      "2018-05-04T13:54:40.767278: step 694, loss 0.582293, acc 0.59375\n",
      "2018-05-04T13:54:42.326036: step 695, loss 0.461192, acc 0.796875\n",
      "2018-05-04T13:54:43.955700: step 696, loss 0.488858, acc 0.796875\n",
      "2018-05-04T13:54:45.544375: step 697, loss 0.436095, acc 0.765625\n",
      "2018-05-04T13:54:47.188880: step 698, loss 0.520758, acc 0.78125\n",
      "2018-05-04T13:54:48.740787: step 699, loss 0.469009, acc 0.828125\n",
      "2018-05-04T13:54:50.324807: step 700, loss 0.472791, acc 0.78125\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T13:54:53.842857: step 700, loss 0.384415, acc 0.852\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-700\n",
      "\n",
      "2018-05-04T13:54:55.576104: step 701, loss 0.39184, acc 0.8125\n",
      "2018-05-04T13:54:57.145625: step 702, loss 0.534367, acc 0.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T13:54:58.699716: step 703, loss 0.586014, acc 0.734375\n",
      "2018-05-04T13:55:00.267957: step 704, loss 0.571493, acc 0.765625\n",
      "2018-05-04T13:55:01.821669: step 705, loss 0.622219, acc 0.671875\n",
      "2018-05-04T13:55:03.400327: step 706, loss 0.442743, acc 0.75\n",
      "2018-05-04T13:55:04.937582: step 707, loss 0.427576, acc 0.78125\n",
      "2018-05-04T13:55:06.501384: step 708, loss 0.46785, acc 0.828125\n",
      "2018-05-04T13:55:08.056930: step 709, loss 0.607073, acc 0.734375\n",
      "2018-05-04T13:55:09.638152: step 710, loss 0.3558, acc 0.828125\n",
      "2018-05-04T13:55:11.174659: step 711, loss 0.528963, acc 0.734375\n",
      "2018-05-04T13:55:12.649258: step 712, loss 0.516998, acc 0.734375\n",
      "2018-05-04T13:55:14.167510: step 713, loss 0.382792, acc 0.828125\n",
      "2018-05-04T13:55:15.714990: step 714, loss 0.603107, acc 0.71875\n",
      "2018-05-04T13:55:17.219440: step 715, loss 0.498104, acc 0.734375\n",
      "2018-05-04T13:55:18.727458: step 716, loss 0.594664, acc 0.671875\n",
      "2018-05-04T13:55:20.180191: step 717, loss 0.428853, acc 0.8125\n",
      "2018-05-04T13:55:21.741185: step 718, loss 0.49213, acc 0.75\n",
      "2018-05-04T13:55:23.248073: step 719, loss 0.604536, acc 0.65625\n",
      "2018-05-04T13:55:24.740537: step 720, loss 0.476735, acc 0.8125\n",
      "2018-05-04T13:55:26.234585: step 721, loss 0.586842, acc 0.6875\n",
      "2018-05-04T13:55:27.715873: step 722, loss 0.434549, acc 0.78125\n",
      "2018-05-04T13:55:29.181169: step 723, loss 0.489849, acc 0.734375\n",
      "2018-05-04T13:55:30.673893: step 724, loss 0.533573, acc 0.734375\n",
      "2018-05-04T13:55:32.154527: step 725, loss 0.531545, acc 0.734375\n",
      "2018-05-04T13:55:33.744883: step 726, loss 0.452543, acc 0.84375\n",
      "2018-05-04T13:55:35.297151: step 727, loss 0.640337, acc 0.640625\n",
      "2018-05-04T13:55:36.932081: step 728, loss 0.516096, acc 0.75\n",
      "2018-05-04T13:55:38.522099: step 729, loss 0.430513, acc 0.796875\n",
      "2018-05-04T13:55:40.164004: step 730, loss 0.444349, acc 0.8125\n",
      "2018-05-04T13:55:41.676432: step 731, loss 0.423887, acc 0.828125\n",
      "2018-05-04T13:55:43.178274: step 732, loss 0.437311, acc 0.75\n",
      "2018-05-04T13:55:44.656797: step 733, loss 0.532042, acc 0.703125\n",
      "2018-05-04T13:55:46.138654: step 734, loss 0.484827, acc 0.765625\n",
      "2018-05-04T13:55:47.633485: step 735, loss 0.470032, acc 0.765625\n",
      "2018-05-04T13:55:49.118936: step 736, loss 0.513351, acc 0.78125\n",
      "2018-05-04T13:55:50.582921: step 737, loss 0.424512, acc 0.765625\n",
      "2018-05-04T13:55:52.058066: step 738, loss 0.430644, acc 0.8125\n",
      "2018-05-04T13:55:53.547554: step 739, loss 0.462748, acc 0.734375\n",
      "2018-05-04T13:55:55.045329: step 740, loss 0.486485, acc 0.75\n",
      "2018-05-04T13:55:56.545349: step 741, loss 0.451082, acc 0.828125\n",
      "2018-05-04T13:55:58.029172: step 742, loss 0.607344, acc 0.65625\n",
      "2018-05-04T13:55:59.518094: step 743, loss 0.484575, acc 0.796875\n",
      "2018-05-04T13:56:01.120239: step 744, loss 0.477046, acc 0.765625\n",
      "2018-05-04T13:56:02.590456: step 745, loss 0.556372, acc 0.765625\n",
      "2018-05-04T13:56:04.108529: step 746, loss 0.490255, acc 0.78125\n",
      "2018-05-04T13:56:05.592821: step 747, loss 0.481197, acc 0.78125\n",
      "2018-05-04T13:56:07.090099: step 748, loss 0.461109, acc 0.796875\n",
      "2018-05-04T13:56:08.587484: step 749, loss 0.434681, acc 0.8125\n",
      "2018-05-04T13:56:10.066013: step 750, loss 0.486433, acc 0.734375\n",
      "2018-05-04T13:56:11.565184: step 751, loss 0.426328, acc 0.78125\n",
      "2018-05-04T13:56:13.043411: step 752, loss 0.497073, acc 0.78125\n",
      "2018-05-04T13:56:14.492377: step 753, loss 0.372133, acc 0.90625\n",
      "2018-05-04T13:56:15.901702: step 754, loss 0.547012, acc 0.75\n",
      "2018-05-04T13:56:17.325174: step 755, loss 0.504114, acc 0.75\n",
      "2018-05-04T13:56:18.731228: step 756, loss 0.576768, acc 0.71875\n",
      "2018-05-04T13:56:20.190235: step 757, loss 0.587368, acc 0.734375\n",
      "2018-05-04T13:56:21.698184: step 758, loss 0.310973, acc 0.875\n",
      "2018-05-04T13:56:23.154799: step 759, loss 0.43296, acc 0.78125\n",
      "2018-05-04T13:56:24.723710: step 760, loss 0.422049, acc 0.875\n",
      "2018-05-04T13:56:26.218060: step 761, loss 0.42499, acc 0.828125\n",
      "2018-05-04T13:56:27.701696: step 762, loss 0.501437, acc 0.78125\n",
      "2018-05-04T13:56:29.269977: step 763, loss 0.594244, acc 0.703125\n",
      "2018-05-04T13:56:30.700982: step 764, loss 0.472291, acc 0.75\n",
      "2018-05-04T13:56:32.074850: step 765, loss 0.458243, acc 0.765625\n",
      "2018-05-04T13:56:33.485076: step 766, loss 0.487833, acc 0.765625\n",
      "2018-05-04T13:56:34.933180: step 767, loss 0.447636, acc 0.78125\n",
      "2018-05-04T13:56:36.316117: step 768, loss 0.635673, acc 0.6875\n",
      "2018-05-04T13:56:37.730396: step 769, loss 0.423153, acc 0.734375\n",
      "2018-05-04T13:56:39.190566: step 770, loss 0.509498, acc 0.703125\n",
      "2018-05-04T13:56:40.615998: step 771, loss 0.504995, acc 0.71875\n",
      "2018-05-04T13:56:41.997399: step 772, loss 0.46031, acc 0.765625\n",
      "2018-05-04T13:56:43.426547: step 773, loss 0.487361, acc 0.78125\n",
      "2018-05-04T13:56:44.935990: step 774, loss 0.348954, acc 0.859375\n",
      "2018-05-04T13:56:46.365605: step 775, loss 0.574151, acc 0.71875\n",
      "2018-05-04T13:56:47.785092: step 776, loss 0.38258, acc 0.84375\n",
      "2018-05-04T13:56:49.230466: step 777, loss 0.324975, acc 0.84375\n",
      "2018-05-04T13:56:50.754938: step 778, loss 0.438855, acc 0.84375\n",
      "2018-05-04T13:56:52.278186: step 779, loss 0.564092, acc 0.734375\n",
      "2018-05-04T13:56:53.774464: step 780, loss 0.334274, acc 0.890625\n",
      "2018-05-04T13:56:55.283227: step 781, loss 0.435319, acc 0.796875\n",
      "2018-05-04T13:56:56.757597: step 782, loss 0.449914, acc 0.75\n",
      "2018-05-04T13:56:58.253306: step 783, loss 0.570097, acc 0.734375\n",
      "2018-05-04T13:56:59.739398: step 784, loss 0.333901, acc 0.859375\n",
      "2018-05-04T13:57:01.268702: step 785, loss 0.439422, acc 0.78125\n",
      "2018-05-04T13:57:02.747420: step 786, loss 0.69269, acc 0.578125\n",
      "2018-05-04T13:57:04.267655: step 787, loss 0.45001, acc 0.765625\n",
      "2018-05-04T13:57:05.801924: step 788, loss 0.446359, acc 0.828125\n",
      "2018-05-04T13:57:07.292736: step 789, loss 0.519159, acc 0.734375\n",
      "2018-05-04T13:57:08.795540: step 790, loss 0.493753, acc 0.6875\n",
      "2018-05-04T13:57:10.271097: step 791, loss 0.439473, acc 0.84375\n",
      "2018-05-04T13:57:11.931529: step 792, loss 0.450358, acc 0.84375\n",
      "2018-05-04T13:57:13.672186: step 793, loss 0.491808, acc 0.734375\n",
      "2018-05-04T13:57:15.357766: step 794, loss 0.475584, acc 0.75\n",
      "2018-05-04T13:57:16.973230: step 795, loss 0.511379, acc 0.765625\n",
      "2018-05-04T13:57:18.548961: step 796, loss 0.363297, acc 0.84375\n",
      "2018-05-04T13:57:20.214790: step 797, loss 0.375651, acc 0.859375\n",
      "2018-05-04T13:57:21.907022: step 798, loss 0.439004, acc 0.78125\n",
      "2018-05-04T13:57:23.424421: step 799, loss 0.352419, acc 0.828125\n",
      "2018-05-04T13:57:25.068589: step 800, loss 0.410282, acc 0.828125\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T13:57:29.469061: step 800, loss 0.372985, acc 0.854\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-800\n",
      "\n",
      "2018-05-04T13:57:31.197395: step 801, loss 0.396688, acc 0.859375\n",
      "2018-05-04T13:57:32.865950: step 802, loss 0.383329, acc 0.84375\n",
      "2018-05-04T13:57:34.567320: step 803, loss 0.480151, acc 0.796875\n",
      "2018-05-04T13:57:36.181375: step 804, loss 0.6067, acc 0.640625\n",
      "2018-05-04T13:57:38.000872: step 805, loss 0.578085, acc 0.703125\n",
      "2018-05-04T13:57:39.667805: step 806, loss 0.409771, acc 0.890625\n",
      "2018-05-04T13:57:41.275706: step 807, loss 0.346124, acc 0.875\n",
      "2018-05-04T13:57:42.854844: step 808, loss 0.43811, acc 0.8125\n",
      "2018-05-04T13:57:44.494331: step 809, loss 0.508874, acc 0.734375\n",
      "2018-05-04T13:57:46.047645: step 810, loss 0.392016, acc 0.84375\n",
      "2018-05-04T13:57:47.762468: step 811, loss 0.517665, acc 0.75\n",
      "2018-05-04T13:57:49.378507: step 812, loss 0.442111, acc 0.765625\n",
      "2018-05-04T13:57:50.961348: step 813, loss 0.50287, acc 0.765625\n",
      "2018-05-04T13:57:52.569974: step 814, loss 0.49525, acc 0.71875\n",
      "2018-05-04T13:57:54.152427: step 815, loss 0.400615, acc 0.796875\n",
      "2018-05-04T13:57:55.665130: step 816, loss 0.409118, acc 0.828125\n",
      "2018-05-04T13:57:57.245694: step 817, loss 0.443232, acc 0.796875\n",
      "2018-05-04T13:57:58.669655: step 818, loss 0.437287, acc 0.8125\n",
      "2018-05-04T13:58:00.046821: step 819, loss 0.33063, acc 0.859375\n",
      "2018-05-04T13:58:01.395503: step 820, loss 0.54562, acc 0.796875\n",
      "2018-05-04T13:58:02.757969: step 821, loss 0.449813, acc 0.8125\n",
      "2018-05-04T13:58:04.078325: step 822, loss 0.442082, acc 0.796875\n",
      "2018-05-04T13:58:05.360912: step 823, loss 0.461584, acc 0.78125\n",
      "2018-05-04T13:58:06.675883: step 824, loss 0.450096, acc 0.734375\n",
      "2018-05-04T13:58:07.984492: step 825, loss 0.376806, acc 0.796875\n",
      "2018-05-04T13:58:09.367862: step 826, loss 0.582712, acc 0.65625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T13:58:10.960726: step 827, loss 0.524642, acc 0.78125\n",
      "2018-05-04T13:58:12.742752: step 828, loss 0.578015, acc 0.6875\n",
      "2018-05-04T13:58:14.345437: step 829, loss 0.435884, acc 0.796875\n",
      "2018-05-04T13:58:15.960617: step 830, loss 0.373964, acc 0.8125\n",
      "2018-05-04T13:58:17.544814: step 831, loss 0.42143, acc 0.796875\n",
      "2018-05-04T13:58:19.198579: step 832, loss 0.393866, acc 0.8125\n",
      "2018-05-04T13:58:20.764023: step 833, loss 0.446854, acc 0.828125\n",
      "2018-05-04T13:58:22.459183: step 834, loss 0.2639, acc 0.921875\n",
      "2018-05-04T13:58:24.114729: step 835, loss 0.40436, acc 0.8125\n",
      "2018-05-04T13:58:25.957404: step 836, loss 0.37946, acc 0.8125\n",
      "2018-05-04T13:58:27.657741: step 837, loss 0.447126, acc 0.828125\n",
      "2018-05-04T13:58:29.288954: step 838, loss 0.477635, acc 0.765625\n",
      "2018-05-04T13:58:31.222571: step 839, loss 0.37724, acc 0.828125\n",
      "2018-05-04T13:58:33.181896: step 840, loss 0.456709, acc 0.84375\n",
      "2018-05-04T13:58:35.202335: step 841, loss 0.411581, acc 0.78125\n",
      "2018-05-04T13:58:36.967498: step 842, loss 0.420918, acc 0.8125\n",
      "2018-05-04T13:58:38.463234: step 843, loss 0.42714, acc 0.796875\n",
      "2018-05-04T13:58:39.868498: step 844, loss 0.415455, acc 0.828125\n",
      "2018-05-04T13:58:41.290797: step 845, loss 0.624972, acc 0.59375\n",
      "2018-05-04T13:58:42.611349: step 846, loss 0.571346, acc 0.703125\n",
      "2018-05-04T13:58:43.864197: step 847, loss 0.46652, acc 0.75\n",
      "2018-05-04T13:58:45.099837: step 848, loss 0.420662, acc 0.796875\n",
      "2018-05-04T13:58:46.258213: step 849, loss 0.537977, acc 0.78125\n",
      "2018-05-04T13:58:47.428040: step 850, loss 0.382741, acc 0.828125\n",
      "2018-05-04T13:58:48.580834: step 851, loss 0.432446, acc 0.765625\n",
      "2018-05-04T13:58:49.791833: step 852, loss 0.471921, acc 0.75\n",
      "2018-05-04T13:58:50.949991: step 853, loss 0.612353, acc 0.6875\n",
      "2018-05-04T13:58:52.157466: step 854, loss 0.439199, acc 0.75\n",
      "2018-05-04T13:58:53.271183: step 855, loss 0.599183, acc 0.703125\n",
      "2018-05-04T13:58:54.427118: step 856, loss 0.56131, acc 0.75\n",
      "2018-05-04T13:58:55.596529: step 857, loss 0.394446, acc 0.796875\n",
      "2018-05-04T13:58:56.750989: step 858, loss 0.37387, acc 0.796875\n",
      "2018-05-04T13:58:57.958201: step 859, loss 0.475773, acc 0.765625\n",
      "2018-05-04T13:58:59.128960: step 860, loss 0.453803, acc 0.8125\n",
      "2018-05-04T13:59:00.363601: step 861, loss 0.491508, acc 0.734375\n",
      "2018-05-04T13:59:01.638719: step 862, loss 0.570603, acc 0.71875\n",
      "2018-05-04T13:59:02.756975: step 863, loss 0.520351, acc 0.734375\n",
      "2018-05-04T13:59:03.894454: step 864, loss 0.471013, acc 0.75\n",
      "2018-05-04T13:59:05.020185: step 865, loss 0.505233, acc 0.734375\n",
      "2018-05-04T13:59:06.196970: step 866, loss 0.443652, acc 0.8125\n",
      "2018-05-04T13:59:07.334467: step 867, loss 0.332619, acc 0.90625\n",
      "2018-05-04T13:59:08.432886: step 868, loss 0.43005, acc 0.78125\n",
      "2018-05-04T13:59:09.563872: step 869, loss 0.407277, acc 0.796875\n",
      "2018-05-04T13:59:10.697518: step 870, loss 0.489417, acc 0.796875\n",
      "2018-05-04T13:59:11.861149: step 871, loss 0.431631, acc 0.796875\n",
      "2018-05-04T13:59:12.995969: step 872, loss 0.37073, acc 0.84375\n",
      "2018-05-04T13:59:14.186648: step 873, loss 0.377326, acc 0.84375\n",
      "2018-05-04T13:59:15.389128: step 874, loss 0.52614, acc 0.78125\n",
      "2018-05-04T13:59:16.507634: step 875, loss 0.422922, acc 0.796875\n",
      "2018-05-04T13:59:17.661030: step 876, loss 0.425338, acc 0.765625\n",
      "2018-05-04T13:59:18.745698: step 877, loss 0.489844, acc 0.78125\n",
      "2018-05-04T13:59:19.962069: step 878, loss 0.664492, acc 0.71875\n",
      "2018-05-04T13:59:21.127590: step 879, loss 0.396498, acc 0.78125\n",
      "2018-05-04T13:59:22.233335: step 880, loss 0.359136, acc 0.84375\n",
      "2018-05-04T13:59:23.333335: step 881, loss 0.531229, acc 0.75\n",
      "2018-05-04T13:59:24.440347: step 882, loss 0.494171, acc 0.78125\n",
      "2018-05-04T13:59:25.538990: step 883, loss 0.489189, acc 0.8125\n",
      "2018-05-04T13:59:26.729706: step 884, loss 0.387302, acc 0.859375\n",
      "2018-05-04T13:59:27.855955: step 885, loss 0.436857, acc 0.765625\n",
      "2018-05-04T13:59:28.991809: step 886, loss 0.49167, acc 0.8125\n",
      "2018-05-04T13:59:30.167421: step 887, loss 0.341743, acc 0.84375\n",
      "2018-05-04T13:59:31.325503: step 888, loss 0.47921, acc 0.859375\n",
      "2018-05-04T13:59:32.490214: step 889, loss 0.483382, acc 0.75\n",
      "2018-05-04T13:59:33.610384: step 890, loss 0.493628, acc 0.734375\n",
      "2018-05-04T13:59:34.735823: step 891, loss 0.518322, acc 0.71875\n",
      "2018-05-04T13:59:35.890979: step 892, loss 0.496607, acc 0.71875\n",
      "2018-05-04T13:59:36.980426: step 893, loss 0.495015, acc 0.703125\n",
      "2018-05-04T13:59:38.068148: step 894, loss 0.370533, acc 0.859375\n",
      "2018-05-04T13:59:39.169444: step 895, loss 0.393275, acc 0.875\n",
      "2018-05-04T13:59:40.259683: step 896, loss 0.52038, acc 0.796875\n",
      "2018-05-04T13:59:41.449175: step 897, loss 0.321032, acc 0.84375\n",
      "2018-05-04T13:59:42.615913: step 898, loss 0.511207, acc 0.765625\n",
      "2018-05-04T13:59:43.736141: step 899, loss 0.546082, acc 0.734375\n",
      "2018-05-04T13:59:44.952042: step 900, loss 0.367108, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T13:59:47.670791: step 900, loss 0.364158, acc 0.852\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-900\n",
      "\n",
      "2018-05-04T13:59:48.904359: step 901, loss 0.495045, acc 0.78125\n",
      "2018-05-04T13:59:50.167104: step 902, loss 0.432195, acc 0.8125\n",
      "2018-05-04T13:59:51.343159: step 903, loss 0.541789, acc 0.796875\n",
      "2018-05-04T13:59:52.478434: step 904, loss 0.41384, acc 0.796875\n",
      "2018-05-04T13:59:53.654496: step 905, loss 0.461783, acc 0.734375\n",
      "2018-05-04T13:59:54.775628: step 906, loss 0.44301, acc 0.765625\n",
      "2018-05-04T13:59:55.922038: step 907, loss 0.367773, acc 0.8125\n",
      "2018-05-04T13:59:57.051106: step 908, loss 0.452899, acc 0.78125\n",
      "2018-05-04T13:59:58.181201: step 909, loss 0.390781, acc 0.859375\n",
      "2018-05-04T13:59:59.320379: step 910, loss 0.524023, acc 0.6875\n",
      "2018-05-04T14:00:00.460499: step 911, loss 0.578894, acc 0.765625\n",
      "2018-05-04T14:00:01.672953: step 912, loss 0.456922, acc 0.859375\n",
      "2018-05-04T14:00:02.810666: step 913, loss 0.408585, acc 0.8125\n",
      "2018-05-04T14:00:04.009428: step 914, loss 0.352108, acc 0.84375\n",
      "2018-05-04T14:00:05.186788: step 915, loss 0.361162, acc 0.84375\n",
      "2018-05-04T14:00:06.335155: step 916, loss 0.419416, acc 0.796875\n",
      "2018-05-04T14:00:07.504772: step 917, loss 0.484955, acc 0.765625\n",
      "2018-05-04T14:00:08.696754: step 918, loss 0.473966, acc 0.75\n",
      "2018-05-04T14:00:09.880035: step 919, loss 0.327335, acc 0.84375\n",
      "2018-05-04T14:00:11.101533: step 920, loss 0.351589, acc 0.875\n",
      "2018-05-04T14:00:12.271225: step 921, loss 0.497669, acc 0.734375\n",
      "2018-05-04T14:00:13.441223: step 922, loss 0.500974, acc 0.703125\n",
      "2018-05-04T14:00:14.576390: step 923, loss 0.412705, acc 0.796875\n",
      "2018-05-04T14:00:15.712759: step 924, loss 0.46578, acc 0.75\n",
      "2018-05-04T14:00:16.833166: step 925, loss 0.39152, acc 0.828125\n",
      "2018-05-04T14:00:17.982028: step 926, loss 0.441939, acc 0.84375\n",
      "2018-05-04T14:00:19.122010: step 927, loss 0.497548, acc 0.78125\n",
      "2018-05-04T14:00:20.276489: step 928, loss 0.405915, acc 0.859375\n",
      "2018-05-04T14:00:21.478582: step 929, loss 0.424331, acc 0.859375\n",
      "2018-05-04T14:00:22.636915: step 930, loss 0.34439, acc 0.859375\n",
      "2018-05-04T14:00:23.794356: step 931, loss 0.519424, acc 0.75\n",
      "2018-05-04T14:00:24.982335: step 932, loss 0.399898, acc 0.828125\n",
      "2018-05-04T14:00:26.127052: step 933, loss 0.56352, acc 0.765625\n",
      "2018-05-04T14:00:27.285118: step 934, loss 0.300447, acc 0.890625\n",
      "2018-05-04T14:00:28.456877: step 935, loss 0.355976, acc 0.84375\n",
      "2018-05-04T14:00:29.701764: step 936, loss 0.429191, acc 0.796875\n",
      "2018-05-04T14:00:30.906003: step 937, loss 0.559351, acc 0.71875\n",
      "2018-05-04T14:00:32.080345: step 938, loss 0.393773, acc 0.765625\n",
      "2018-05-04T14:00:33.327050: step 939, loss 0.530145, acc 0.78125\n",
      "2018-05-04T14:00:34.527383: step 940, loss 0.389956, acc 0.796875\n",
      "2018-05-04T14:00:35.702837: step 941, loss 0.380602, acc 0.828125\n",
      "2018-05-04T14:00:36.851615: step 942, loss 0.44883, acc 0.78125\n",
      "2018-05-04T14:00:37.976019: step 943, loss 0.52174, acc 0.734375\n",
      "2018-05-04T14:00:39.118932: step 944, loss 0.346149, acc 0.828125\n",
      "2018-05-04T14:00:40.332644: step 945, loss 0.434203, acc 0.828125\n",
      "2018-05-04T14:00:41.536312: step 946, loss 0.423394, acc 0.78125\n",
      "2018-05-04T14:00:42.687625: step 947, loss 0.402669, acc 0.8125\n",
      "2018-05-04T14:00:43.852264: step 948, loss 0.594763, acc 0.640625\n",
      "2018-05-04T14:00:45.021489: step 949, loss 0.524893, acc 0.734375\n",
      "2018-05-04T14:00:46.176302: step 950, loss 0.38813, acc 0.78125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T14:00:47.319617: step 951, loss 0.331463, acc 0.84375\n",
      "2018-05-04T14:00:48.489831: step 952, loss 0.352452, acc 0.8125\n",
      "2018-05-04T14:00:49.657397: step 953, loss 0.535593, acc 0.703125\n",
      "2018-05-04T14:00:50.981212: step 954, loss 0.470935, acc 0.78125\n",
      "2018-05-04T14:00:52.247841: step 955, loss 0.364547, acc 0.8125\n",
      "2018-05-04T14:00:53.499582: step 956, loss 0.394871, acc 0.78125\n",
      "2018-05-04T14:00:54.677941: step 957, loss 0.345474, acc 0.875\n",
      "2018-05-04T14:00:55.824543: step 958, loss 0.499485, acc 0.734375\n",
      "2018-05-04T14:00:56.966083: step 959, loss 0.508112, acc 0.71875\n",
      "2018-05-04T14:00:58.125159: step 960, loss 0.434401, acc 0.8125\n",
      "2018-05-04T14:00:59.299677: step 961, loss 0.411049, acc 0.828125\n",
      "2018-05-04T14:01:00.461313: step 962, loss 0.323779, acc 0.890625\n",
      "2018-05-04T14:01:01.702971: step 963, loss 0.571848, acc 0.71875\n",
      "2018-05-04T14:01:02.871302: step 964, loss 0.35411, acc 0.828125\n",
      "2018-05-04T14:01:04.038467: step 965, loss 0.50297, acc 0.796875\n",
      "2018-05-04T14:01:05.201602: step 966, loss 0.483162, acc 0.796875\n",
      "2018-05-04T14:01:06.355312: step 967, loss 0.393798, acc 0.8125\n",
      "2018-05-04T14:01:07.534492: step 968, loss 0.513397, acc 0.6875\n",
      "2018-05-04T14:01:08.683983: step 969, loss 0.47865, acc 0.765625\n",
      "2018-05-04T14:01:09.837892: step 970, loss 0.604624, acc 0.75\n",
      "2018-05-04T14:01:11.024953: step 971, loss 0.462815, acc 0.75\n",
      "2018-05-04T14:01:12.216623: step 972, loss 0.38432, acc 0.84375\n",
      "2018-05-04T14:01:13.381960: step 973, loss 0.543517, acc 0.703125\n",
      "2018-05-04T14:01:14.548646: step 974, loss 0.488538, acc 0.734375\n",
      "2018-05-04T14:01:15.703279: step 975, loss 0.407837, acc 0.828125\n",
      "2018-05-04T14:01:16.959815: step 976, loss 0.498438, acc 0.765625\n",
      "2018-05-04T14:01:18.137755: step 977, loss 0.408412, acc 0.8125\n",
      "2018-05-04T14:01:19.314913: step 978, loss 0.432258, acc 0.765625\n",
      "2018-05-04T14:01:20.513348: step 979, loss 0.485311, acc 0.8125\n",
      "2018-05-04T14:01:21.739875: step 980, loss 0.330503, acc 0.859375\n",
      "2018-05-04T14:01:22.901344: step 981, loss 0.457597, acc 0.765625\n",
      "2018-05-04T14:01:24.163615: step 982, loss 0.383482, acc 0.859375\n",
      "2018-05-04T14:01:25.391673: step 983, loss 0.516981, acc 0.78125\n",
      "2018-05-04T14:01:26.525525: step 984, loss 0.456427, acc 0.75\n",
      "2018-05-04T14:01:27.686831: step 985, loss 0.432118, acc 0.84375\n",
      "2018-05-04T14:01:28.922715: step 986, loss 0.40295, acc 0.796875\n",
      "2018-05-04T14:01:30.168281: step 987, loss 0.569397, acc 0.703125\n",
      "2018-05-04T14:01:31.409653: step 988, loss 0.460216, acc 0.828125\n",
      "2018-05-04T14:01:32.574155: step 989, loss 0.471519, acc 0.765625\n",
      "2018-05-04T14:01:33.811799: step 990, loss 0.326637, acc 0.828125\n",
      "2018-05-04T14:01:35.059305: step 991, loss 0.442904, acc 0.828125\n",
      "2018-05-04T14:01:36.303901: step 992, loss 0.400268, acc 0.859375\n",
      "2018-05-04T14:01:37.633562: step 993, loss 0.461745, acc 0.78125\n",
      "2018-05-04T14:01:38.830031: step 994, loss 0.410023, acc 0.8125\n",
      "2018-05-04T14:01:40.131658: step 995, loss 0.3215, acc 0.84375\n",
      "2018-05-04T14:01:41.439125: step 996, loss 0.485235, acc 0.734375\n",
      "2018-05-04T14:01:42.714882: step 997, loss 0.473392, acc 0.796875\n",
      "2018-05-04T14:01:43.929297: step 998, loss 0.550043, acc 0.703125\n",
      "2018-05-04T14:01:45.148041: step 999, loss 0.495265, acc 0.78125\n",
      "2018-05-04T14:01:46.352175: step 1000, loss 0.411155, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T14:01:49.081299: step 1000, loss 0.349523, acc 0.862\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-1000\n",
      "\n",
      "2018-05-04T14:01:50.463372: step 1001, loss 0.457482, acc 0.734375\n",
      "2018-05-04T14:01:51.747565: step 1002, loss 0.406456, acc 0.84375\n",
      "2018-05-04T14:01:53.013434: step 1003, loss 0.355136, acc 0.84375\n",
      "2018-05-04T14:01:54.218450: step 1004, loss 0.389355, acc 0.84375\n",
      "2018-05-04T14:01:55.502838: step 1005, loss 0.345868, acc 0.84375\n",
      "2018-05-04T14:01:56.702427: step 1006, loss 0.433026, acc 0.84375\n",
      "2018-05-04T14:01:57.935803: step 1007, loss 0.440823, acc 0.75\n",
      "2018-05-04T14:01:59.122440: step 1008, loss 0.377157, acc 0.875\n",
      "2018-05-04T14:02:00.332458: step 1009, loss 0.451606, acc 0.78125\n",
      "2018-05-04T14:02:01.582673: step 1010, loss 0.406355, acc 0.828125\n",
      "2018-05-04T14:02:02.815889: step 1011, loss 0.425008, acc 0.796875\n",
      "2018-05-04T14:02:04.063164: step 1012, loss 0.403887, acc 0.8125\n",
      "2018-05-04T14:02:05.302121: step 1013, loss 0.34464, acc 0.890625\n",
      "2018-05-04T14:02:06.545521: step 1014, loss 0.441157, acc 0.84375\n",
      "2018-05-04T14:02:07.851318: step 1015, loss 0.339405, acc 0.859375\n",
      "2018-05-04T14:02:09.155050: step 1016, loss 0.313277, acc 0.859375\n",
      "2018-05-04T14:02:10.393975: step 1017, loss 0.442086, acc 0.796875\n",
      "2018-05-04T14:02:11.676638: step 1018, loss 0.328519, acc 0.890625\n",
      "2018-05-04T14:02:12.895778: step 1019, loss 0.380818, acc 0.8125\n",
      "2018-05-04T14:02:14.105526: step 1020, loss 0.419281, acc 0.859375\n",
      "2018-05-04T14:02:15.348741: step 1021, loss 0.409548, acc 0.84375\n",
      "2018-05-04T14:02:16.557207: step 1022, loss 0.451117, acc 0.75\n",
      "2018-05-04T14:02:17.783804: step 1023, loss 0.450559, acc 0.796875\n",
      "2018-05-04T14:02:19.011479: step 1024, loss 0.402115, acc 0.8125\n",
      "2018-05-04T14:02:20.275157: step 1025, loss 0.352497, acc 0.828125\n",
      "2018-05-04T14:02:21.588859: step 1026, loss 0.651266, acc 0.71875\n",
      "2018-05-04T14:02:22.789444: step 1027, loss 0.445047, acc 0.8125\n",
      "2018-05-04T14:02:24.003181: step 1028, loss 0.345186, acc 0.859375\n",
      "2018-05-04T14:02:25.249660: step 1029, loss 0.396029, acc 0.828125\n",
      "2018-05-04T14:02:26.468847: step 1030, loss 0.375771, acc 0.765625\n",
      "2018-05-04T14:02:27.676463: step 1031, loss 0.433875, acc 0.828125\n",
      "2018-05-04T14:02:28.866788: step 1032, loss 0.383314, acc 0.84375\n",
      "2018-05-04T14:02:30.084226: step 1033, loss 0.46036, acc 0.8125\n",
      "2018-05-04T14:02:31.337880: step 1034, loss 0.557561, acc 0.75\n",
      "2018-05-04T14:02:32.543720: step 1035, loss 0.52891, acc 0.75\n",
      "2018-05-04T14:02:33.745294: step 1036, loss 0.350063, acc 0.84375\n",
      "2018-05-04T14:02:34.954294: step 1037, loss 0.505688, acc 0.78125\n",
      "2018-05-04T14:02:36.151691: step 1038, loss 0.403842, acc 0.8125\n",
      "2018-05-04T14:02:37.382440: step 1039, loss 0.389802, acc 0.78125\n",
      "2018-05-04T14:02:38.628562: step 1040, loss 0.601024, acc 0.65625\n",
      "2018-05-04T14:02:39.844432: step 1041, loss 0.363262, acc 0.828125\n",
      "2018-05-04T14:02:41.114342: step 1042, loss 0.398448, acc 0.8125\n",
      "2018-05-04T14:02:42.379534: step 1043, loss 0.459609, acc 0.796875\n",
      "2018-05-04T14:02:43.635680: step 1044, loss 0.392845, acc 0.828125\n",
      "2018-05-04T14:02:44.879820: step 1045, loss 0.439583, acc 0.765625\n",
      "2018-05-04T14:02:46.062682: step 1046, loss 0.34609, acc 0.84375\n",
      "2018-05-04T14:02:47.253196: step 1047, loss 0.512988, acc 0.765625\n",
      "2018-05-04T14:02:48.451311: step 1048, loss 0.40427, acc 0.796875\n",
      "2018-05-04T14:02:49.652449: step 1049, loss 0.363029, acc 0.890625\n",
      "2018-05-04T14:02:50.913464: step 1050, loss 0.44509, acc 0.8125\n",
      "2018-05-04T14:02:52.153682: step 1051, loss 0.297736, acc 0.890625\n",
      "2018-05-04T14:02:53.331652: step 1052, loss 0.580267, acc 0.734375\n",
      "2018-05-04T14:02:54.576320: step 1053, loss 0.405359, acc 0.796875\n",
      "2018-05-04T14:02:55.827808: step 1054, loss 0.397, acc 0.828125\n",
      "2018-05-04T14:02:57.022165: step 1055, loss 0.531028, acc 0.734375\n",
      "2018-05-04T14:02:58.239255: step 1056, loss 0.456389, acc 0.828125\n",
      "2018-05-04T14:02:59.517147: step 1057, loss 0.355998, acc 0.875\n",
      "2018-05-04T14:03:00.744138: step 1058, loss 0.439812, acc 0.828125\n",
      "2018-05-04T14:03:02.022592: step 1059, loss 0.437483, acc 0.78125\n",
      "2018-05-04T14:03:03.260732: step 1060, loss 0.425216, acc 0.859375\n",
      "2018-05-04T14:03:04.527372: step 1061, loss 0.419106, acc 0.765625\n",
      "2018-05-04T14:03:05.732910: step 1062, loss 0.442478, acc 0.796875\n",
      "2018-05-04T14:03:06.973177: step 1063, loss 0.550882, acc 0.6875\n",
      "2018-05-04T14:03:08.160089: step 1064, loss 0.405147, acc 0.84375\n",
      "2018-05-04T14:03:09.384471: step 1065, loss 0.344952, acc 0.859375\n",
      "2018-05-04T14:03:10.646895: step 1066, loss 0.413892, acc 0.8125\n",
      "2018-05-04T14:03:11.924120: step 1067, loss 0.450974, acc 0.765625\n",
      "2018-05-04T14:03:13.152182: step 1068, loss 0.379057, acc 0.828125\n",
      "2018-05-04T14:03:14.371523: step 1069, loss 0.326562, acc 0.890625\n",
      "2018-05-04T14:03:15.569458: step 1070, loss 0.466908, acc 0.8125\n",
      "2018-05-04T14:03:16.771123: step 1071, loss 0.424055, acc 0.828125\n",
      "2018-05-04T14:03:17.981788: step 1072, loss 0.377922, acc 0.78125\n",
      "2018-05-04T14:03:19.196257: step 1073, loss 0.318375, acc 0.828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T14:03:20.380593: step 1074, loss 0.43194, acc 0.828125\n",
      "2018-05-04T14:03:21.646660: step 1075, loss 0.418172, acc 0.8125\n",
      "2018-05-04T14:03:22.874319: step 1076, loss 0.382744, acc 0.875\n",
      "2018-05-04T14:03:24.107512: step 1077, loss 0.35834, acc 0.828125\n",
      "2018-05-04T14:03:25.323880: step 1078, loss 0.386823, acc 0.8125\n",
      "2018-05-04T14:03:26.533896: step 1079, loss 0.45998, acc 0.828125\n",
      "2018-05-04T14:03:27.758347: step 1080, loss 0.413992, acc 0.859375\n",
      "2018-05-04T14:03:28.930649: step 1081, loss 0.338836, acc 0.875\n",
      "2018-05-04T14:03:30.139343: step 1082, loss 0.470061, acc 0.75\n",
      "2018-05-04T14:03:31.367170: step 1083, loss 0.506234, acc 0.78125\n",
      "2018-05-04T14:03:32.528083: step 1084, loss 0.400719, acc 0.84375\n",
      "2018-05-04T14:03:33.731749: step 1085, loss 0.361035, acc 0.875\n",
      "2018-05-04T14:03:34.939077: step 1086, loss 0.433472, acc 0.84375\n",
      "2018-05-04T14:03:36.103871: step 1087, loss 0.408002, acc 0.8125\n",
      "2018-05-04T14:03:37.266097: step 1088, loss 0.345788, acc 0.84375\n",
      "2018-05-04T14:03:38.433062: step 1089, loss 0.504052, acc 0.734375\n",
      "2018-05-04T14:03:39.626385: step 1090, loss 0.415271, acc 0.828125\n",
      "2018-05-04T14:03:40.852588: step 1091, loss 0.400366, acc 0.8125\n",
      "2018-05-04T14:03:42.076094: step 1092, loss 0.451831, acc 0.78125\n",
      "2018-05-04T14:03:43.266819: step 1093, loss 0.402348, acc 0.828125\n",
      "2018-05-04T14:03:44.469000: step 1094, loss 0.475812, acc 0.828125\n",
      "2018-05-04T14:03:45.648456: step 1095, loss 0.439344, acc 0.8125\n",
      "2018-05-04T14:03:46.850269: step 1096, loss 0.490723, acc 0.828125\n",
      "2018-05-04T14:03:48.034094: step 1097, loss 0.438633, acc 0.828125\n",
      "2018-05-04T14:03:49.251558: step 1098, loss 0.487707, acc 0.75\n",
      "2018-05-04T14:03:50.387823: step 1099, loss 0.364163, acc 0.90625\n",
      "2018-05-04T14:03:51.691669: step 1100, loss 0.397242, acc 0.765625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T14:03:54.449287: step 1100, loss 0.326131, acc 0.858\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-1100\n",
      "\n",
      "2018-05-04T14:03:55.780731: step 1101, loss 0.518687, acc 0.78125\n",
      "2018-05-04T14:03:56.947989: step 1102, loss 0.575794, acc 0.6875\n",
      "2018-05-04T14:03:58.122446: step 1103, loss 0.495837, acc 0.734375\n",
      "2018-05-04T14:03:59.299172: step 1104, loss 0.432989, acc 0.765625\n",
      "2018-05-04T14:04:00.445160: step 1105, loss 0.284562, acc 0.921875\n",
      "2018-05-04T14:04:01.654306: step 1106, loss 0.398952, acc 0.828125\n",
      "2018-05-04T14:04:02.854547: step 1107, loss 0.411934, acc 0.8125\n",
      "2018-05-04T14:04:03.984659: step 1108, loss 0.36452, acc 0.828125\n",
      "2018-05-04T14:04:05.139107: step 1109, loss 0.402189, acc 0.828125\n",
      "2018-05-04T14:04:06.270670: step 1110, loss 0.388448, acc 0.828125\n",
      "2018-05-04T14:04:07.421999: step 1111, loss 0.397538, acc 0.8125\n",
      "2018-05-04T14:04:08.567715: step 1112, loss 0.387367, acc 0.859375\n",
      "2018-05-04T14:04:09.691350: step 1113, loss 0.394384, acc 0.8125\n",
      "2018-05-04T14:04:10.855592: step 1114, loss 0.36797, acc 0.84375\n",
      "2018-05-04T14:04:12.018031: step 1115, loss 0.309633, acc 0.890625\n",
      "2018-05-04T14:04:13.148350: step 1116, loss 0.414919, acc 0.8125\n",
      "2018-05-04T14:04:14.280975: step 1117, loss 0.332891, acc 0.8125\n",
      "2018-05-04T14:04:15.399749: step 1118, loss 0.395209, acc 0.796875\n",
      "2018-05-04T14:04:16.550002: step 1119, loss 0.509321, acc 0.765625\n",
      "2018-05-04T14:04:17.691533: step 1120, loss 0.430607, acc 0.859375\n",
      "2018-05-04T14:04:18.903718: step 1121, loss 0.425852, acc 0.796875\n",
      "2018-05-04T14:04:20.026809: step 1122, loss 0.384009, acc 0.828125\n",
      "2018-05-04T14:04:21.258749: step 1123, loss 0.502704, acc 0.796875\n",
      "2018-05-04T14:04:22.461741: step 1124, loss 0.304414, acc 0.875\n",
      "2018-05-04T14:04:23.653622: step 1125, loss 0.441751, acc 0.796875\n",
      "2018-05-04T14:04:24.792964: step 1126, loss 0.38156, acc 0.84375\n",
      "2018-05-04T14:04:25.935107: step 1127, loss 0.331262, acc 0.828125\n",
      "2018-05-04T14:04:27.052579: step 1128, loss 0.445909, acc 0.78125\n",
      "2018-05-04T14:04:28.178452: step 1129, loss 0.485764, acc 0.796875\n",
      "2018-05-04T14:04:29.326662: step 1130, loss 0.423913, acc 0.828125\n",
      "2018-05-04T14:04:30.471353: step 1131, loss 0.477807, acc 0.75\n",
      "2018-05-04T14:04:31.697248: step 1132, loss 0.35045, acc 0.859375\n",
      "2018-05-04T14:04:32.897606: step 1133, loss 0.368328, acc 0.84375\n",
      "2018-05-04T14:04:34.168658: step 1134, loss 0.417698, acc 0.8125\n",
      "2018-05-04T14:04:35.473289: step 1135, loss 0.341945, acc 0.875\n",
      "2018-05-04T14:04:36.764460: step 1136, loss 0.447657, acc 0.78125\n",
      "2018-05-04T14:04:37.990076: step 1137, loss 0.393722, acc 0.84375\n",
      "2018-05-04T14:04:39.156334: step 1138, loss 0.432651, acc 0.8125\n",
      "2018-05-04T14:04:40.316552: step 1139, loss 0.44402, acc 0.75\n",
      "2018-05-04T14:04:41.551184: step 1140, loss 0.403496, acc 0.796875\n",
      "2018-05-04T14:04:42.711117: step 1141, loss 0.431179, acc 0.8125\n",
      "2018-05-04T14:04:43.902340: step 1142, loss 0.341278, acc 0.875\n",
      "2018-05-04T14:04:45.060999: step 1143, loss 0.364671, acc 0.8125\n",
      "2018-05-04T14:04:46.221515: step 1144, loss 0.311033, acc 0.859375\n",
      "2018-05-04T14:04:47.346089: step 1145, loss 0.402286, acc 0.84375\n",
      "2018-05-04T14:04:48.441637: step 1146, loss 0.351339, acc 0.890625\n",
      "2018-05-04T14:04:49.580740: step 1147, loss 0.476954, acc 0.75\n",
      "2018-05-04T14:04:50.936095: step 1148, loss 0.438233, acc 0.84375\n",
      "2018-05-04T14:04:52.416388: step 1149, loss 0.347029, acc 0.859375\n",
      "2018-05-04T14:04:53.988313: step 1150, loss 0.36328, acc 0.859375\n",
      "2018-05-04T14:04:55.594381: step 1151, loss 0.537058, acc 0.765625\n",
      "2018-05-04T14:04:57.241969: step 1152, loss 0.53046, acc 0.765625\n",
      "2018-05-04T14:04:58.920572: step 1153, loss 0.325102, acc 0.859375\n",
      "2018-05-04T14:05:00.325794: step 1154, loss 0.376536, acc 0.828125\n",
      "2018-05-04T14:05:01.795992: step 1155, loss 0.288645, acc 0.890625\n",
      "2018-05-04T14:05:03.074102: step 1156, loss 0.35199, acc 0.921875\n",
      "2018-05-04T14:05:04.249685: step 1157, loss 0.384572, acc 0.8125\n",
      "2018-05-04T14:05:05.413119: step 1158, loss 0.525293, acc 0.703125\n",
      "2018-05-04T14:05:06.563019: step 1159, loss 0.498218, acc 0.671875\n",
      "2018-05-04T14:05:07.737941: step 1160, loss 0.455728, acc 0.78125\n",
      "2018-05-04T14:05:08.853197: step 1161, loss 0.211381, acc 0.921875\n",
      "2018-05-04T14:05:09.967795: step 1162, loss 0.375479, acc 0.84375\n",
      "2018-05-04T14:05:11.147990: step 1163, loss 0.398318, acc 0.796875\n",
      "2018-05-04T14:05:12.272634: step 1164, loss 0.366561, acc 0.84375\n",
      "2018-05-04T14:05:13.402560: step 1165, loss 0.470164, acc 0.78125\n",
      "2018-05-04T14:05:14.536562: step 1166, loss 0.296157, acc 0.90625\n",
      "2018-05-04T14:05:15.649053: step 1167, loss 0.349685, acc 0.84375\n",
      "2018-05-04T14:05:16.820242: step 1168, loss 0.383873, acc 0.84375\n",
      "2018-05-04T14:05:18.061508: step 1169, loss 0.400045, acc 0.875\n",
      "2018-05-04T14:05:19.205787: step 1170, loss 0.393297, acc 0.8125\n",
      "2018-05-04T14:05:20.393312: step 1171, loss 0.319205, acc 0.828125\n",
      "2018-05-04T14:05:21.646294: step 1172, loss 0.395827, acc 0.828125\n",
      "2018-05-04T14:05:22.791107: step 1173, loss 0.359277, acc 0.84375\n",
      "2018-05-04T14:05:23.970437: step 1174, loss 0.344367, acc 0.828125\n",
      "2018-05-04T14:05:25.132865: step 1175, loss 0.373418, acc 0.90625\n",
      "2018-05-04T14:05:26.289700: step 1176, loss 0.34897, acc 0.796875\n",
      "2018-05-04T14:05:27.427529: step 1177, loss 0.352506, acc 0.875\n",
      "2018-05-04T14:05:28.595238: step 1178, loss 0.43124, acc 0.828125\n",
      "2018-05-04T14:05:29.824457: step 1179, loss 0.413514, acc 0.8125\n",
      "2018-05-04T14:05:31.032088: step 1180, loss 0.41359, acc 0.8125\n",
      "2018-05-04T14:05:32.226433: step 1181, loss 0.511936, acc 0.75\n",
      "2018-05-04T14:05:33.439352: step 1182, loss 0.436403, acc 0.765625\n",
      "2018-05-04T14:05:34.706672: step 1183, loss 0.430278, acc 0.765625\n",
      "2018-05-04T14:05:35.880053: step 1184, loss 0.468994, acc 0.8125\n",
      "2018-05-04T14:05:37.012802: step 1185, loss 0.471223, acc 0.765625\n",
      "2018-05-04T14:05:38.172481: step 1186, loss 0.383128, acc 0.796875\n",
      "2018-05-04T14:05:39.431744: step 1187, loss 0.424158, acc 0.796875\n",
      "2018-05-04T14:05:40.580804: step 1188, loss 0.411649, acc 0.796875\n",
      "2018-05-04T14:05:41.794395: step 1189, loss 0.391244, acc 0.78125\n",
      "2018-05-04T14:05:43.020260: step 1190, loss 0.423312, acc 0.8125\n",
      "2018-05-04T14:05:44.199850: step 1191, loss 0.363378, acc 0.8125\n",
      "2018-05-04T14:05:45.417276: step 1192, loss 0.387185, acc 0.796875\n",
      "2018-05-04T14:05:46.635810: step 1193, loss 0.364105, acc 0.859375\n",
      "2018-05-04T14:05:47.793607: step 1194, loss 0.627023, acc 0.734375\n",
      "2018-05-04T14:05:49.039491: step 1195, loss 0.357197, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T14:05:50.249707: step 1196, loss 0.384189, acc 0.84375\n",
      "2018-05-04T14:05:51.523953: step 1197, loss 0.432496, acc 0.8125\n",
      "2018-05-04T14:05:52.668532: step 1198, loss 0.336516, acc 0.875\n",
      "2018-05-04T14:05:53.867814: step 1199, loss 0.467574, acc 0.75\n",
      "2018-05-04T14:05:55.117922: step 1200, loss 0.507768, acc 0.796875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T14:05:57.726457: step 1200, loss 0.324667, acc 0.872\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-1200\n",
      "\n",
      "2018-05-04T14:05:59.070369: step 1201, loss 0.491986, acc 0.75\n",
      "2018-05-04T14:06:00.361693: step 1202, loss 0.497889, acc 0.78125\n",
      "2018-05-04T14:06:01.678467: step 1203, loss 0.370782, acc 0.8125\n",
      "2018-05-04T14:06:02.825703: step 1204, loss 0.388794, acc 0.796875\n",
      "2018-05-04T14:06:04.066608: step 1205, loss 0.444324, acc 0.84375\n",
      "2018-05-04T14:06:05.289991: step 1206, loss 0.401263, acc 0.78125\n",
      "2018-05-04T14:06:06.441390: step 1207, loss 0.397233, acc 0.84375\n",
      "2018-05-04T14:06:07.605048: step 1208, loss 0.341154, acc 0.828125\n",
      "2018-05-04T14:06:08.827784: step 1209, loss 0.467367, acc 0.8125\n",
      "2018-05-04T14:06:09.995461: step 1210, loss 0.357579, acc 0.828125\n",
      "2018-05-04T14:06:11.269801: step 1211, loss 0.463209, acc 0.75\n",
      "2018-05-04T14:06:12.480326: step 1212, loss 0.360988, acc 0.8125\n",
      "2018-05-04T14:06:13.668184: step 1213, loss 0.436694, acc 0.8125\n",
      "2018-05-04T14:06:14.840419: step 1214, loss 0.45644, acc 0.75\n",
      "2018-05-04T14:06:16.000463: step 1215, loss 0.456827, acc 0.796875\n",
      "2018-05-04T14:06:17.184267: step 1216, loss 0.379746, acc 0.796875\n",
      "2018-05-04T14:06:18.352766: step 1217, loss 0.384517, acc 0.828125\n",
      "2018-05-04T14:06:19.574138: step 1218, loss 0.283241, acc 0.890625\n",
      "2018-05-04T14:06:20.792428: step 1219, loss 0.423723, acc 0.765625\n",
      "2018-05-04T14:06:22.024478: step 1220, loss 0.386909, acc 0.859375\n",
      "2018-05-04T14:06:23.210674: step 1221, loss 0.404033, acc 0.8125\n",
      "2018-05-04T14:06:24.413554: step 1222, loss 0.465634, acc 0.734375\n",
      "2018-05-04T14:06:25.585250: step 1223, loss 0.336116, acc 0.84375\n",
      "2018-05-04T14:06:26.768353: step 1224, loss 0.438896, acc 0.765625\n",
      "2018-05-04T14:06:27.955007: step 1225, loss 0.335713, acc 0.828125\n",
      "2018-05-04T14:06:29.070908: step 1226, loss 0.43744, acc 0.78125\n",
      "2018-05-04T14:06:30.303221: step 1227, loss 0.509157, acc 0.703125\n",
      "2018-05-04T14:06:31.616765: step 1228, loss 0.421651, acc 0.78125\n",
      "2018-05-04T14:06:32.826834: step 1229, loss 0.443161, acc 0.765625\n",
      "2018-05-04T14:06:34.057928: step 1230, loss 0.598469, acc 0.703125\n",
      "2018-05-04T14:06:35.277736: step 1231, loss 0.440261, acc 0.78125\n",
      "2018-05-04T14:06:36.479493: step 1232, loss 0.463851, acc 0.765625\n",
      "2018-05-04T14:06:37.674201: step 1233, loss 0.310362, acc 0.890625\n",
      "2018-05-04T14:06:38.916303: step 1234, loss 0.539949, acc 0.75\n",
      "2018-05-04T14:06:40.134258: step 1235, loss 0.443977, acc 0.8125\n",
      "2018-05-04T14:06:41.350890: step 1236, loss 0.340237, acc 0.828125\n",
      "2018-05-04T14:06:42.566386: step 1237, loss 0.329771, acc 0.859375\n",
      "2018-05-04T14:06:43.730700: step 1238, loss 0.383441, acc 0.84375\n",
      "2018-05-04T14:06:44.914854: step 1239, loss 0.338492, acc 0.90625\n",
      "2018-05-04T14:06:46.100596: step 1240, loss 0.421044, acc 0.875\n",
      "2018-05-04T14:06:47.288831: step 1241, loss 0.285806, acc 0.890625\n",
      "2018-05-04T14:06:48.492587: step 1242, loss 0.402001, acc 0.8125\n",
      "2018-05-04T14:06:49.694678: step 1243, loss 0.335917, acc 0.875\n",
      "2018-05-04T14:06:50.919918: step 1244, loss 0.425524, acc 0.8125\n",
      "2018-05-04T14:06:52.077557: step 1245, loss 0.391252, acc 0.84375\n",
      "2018-05-04T14:06:53.238832: step 1246, loss 0.459345, acc 0.8125\n",
      "2018-05-04T14:06:54.415150: step 1247, loss 0.374528, acc 0.796875\n",
      "2018-05-04T14:06:55.598103: step 1248, loss 0.51071, acc 0.78125\n",
      "2018-05-04T14:06:56.786003: step 1249, loss 0.378194, acc 0.859375\n",
      "2018-05-04T14:06:57.950729: step 1250, loss 0.495615, acc 0.8125\n",
      "2018-05-04T14:06:59.155026: step 1251, loss 0.450589, acc 0.84375\n",
      "2018-05-04T14:07:00.330417: step 1252, loss 0.477824, acc 0.765625\n",
      "2018-05-04T14:07:01.517776: step 1253, loss 0.600797, acc 0.703125\n",
      "2018-05-04T14:07:02.672989: step 1254, loss 0.355163, acc 0.828125\n",
      "2018-05-04T14:07:03.832124: step 1255, loss 0.417652, acc 0.8125\n",
      "2018-05-04T14:07:04.966554: step 1256, loss 0.363276, acc 0.8125\n",
      "2018-05-04T14:07:06.113310: step 1257, loss 0.51648, acc 0.78125\n",
      "2018-05-04T14:07:07.299512: step 1258, loss 0.46025, acc 0.78125\n",
      "2018-05-04T14:07:08.481188: step 1259, loss 0.375012, acc 0.84375\n",
      "2018-05-04T14:07:09.678882: step 1260, loss 0.541076, acc 0.71875\n",
      "2018-05-04T14:07:10.894823: step 1261, loss 0.47651, acc 0.75\n",
      "2018-05-04T14:07:12.091241: step 1262, loss 0.409082, acc 0.796875\n",
      "2018-05-04T14:07:13.294529: step 1263, loss 0.436287, acc 0.828125\n",
      "2018-05-04T14:07:14.470085: step 1264, loss 0.35265, acc 0.875\n",
      "2018-05-04T14:07:15.607861: step 1265, loss 0.428542, acc 0.765625\n",
      "2018-05-04T14:07:16.720134: step 1266, loss 0.392482, acc 0.828125\n",
      "2018-05-04T14:07:17.874497: step 1267, loss 0.308583, acc 0.859375\n",
      "2018-05-04T14:07:19.028766: step 1268, loss 0.344543, acc 0.875\n",
      "2018-05-04T14:07:20.161963: step 1269, loss 0.287706, acc 0.875\n",
      "2018-05-04T14:07:21.416266: step 1270, loss 0.341112, acc 0.90625\n",
      "2018-05-04T14:07:22.557454: step 1271, loss 0.343276, acc 0.859375\n",
      "2018-05-04T14:07:23.736667: step 1272, loss 0.481062, acc 0.8125\n",
      "2018-05-04T14:07:24.933187: step 1273, loss 0.493114, acc 0.71875\n",
      "2018-05-04T14:07:26.109008: step 1274, loss 0.2918, acc 0.84375\n",
      "2018-05-04T14:07:27.294523: step 1275, loss 0.369413, acc 0.859375\n",
      "2018-05-04T14:07:28.408029: step 1276, loss 0.450849, acc 0.765625\n",
      "2018-05-04T14:07:29.564901: step 1277, loss 0.392804, acc 0.8125\n",
      "2018-05-04T14:07:30.720013: step 1278, loss 0.430079, acc 0.734375\n",
      "2018-05-04T14:07:31.912137: step 1279, loss 0.372476, acc 0.8125\n",
      "2018-05-04T14:07:33.104484: step 1280, loss 0.423968, acc 0.8125\n",
      "2018-05-04T14:07:34.327405: step 1281, loss 0.416417, acc 0.8125\n",
      "2018-05-04T14:07:35.557605: step 1282, loss 0.476378, acc 0.796875\n",
      "2018-05-04T14:07:36.753918: step 1283, loss 0.411025, acc 0.796875\n",
      "2018-05-04T14:07:37.885448: step 1284, loss 0.402492, acc 0.828125\n",
      "2018-05-04T14:07:39.039799: step 1285, loss 0.448022, acc 0.796875\n",
      "2018-05-04T14:07:40.170291: step 1286, loss 0.386256, acc 0.78125\n",
      "2018-05-04T14:07:41.351581: step 1287, loss 0.41592, acc 0.828125\n",
      "2018-05-04T14:07:42.517128: step 1288, loss 0.446161, acc 0.765625\n",
      "2018-05-04T14:07:43.650184: step 1289, loss 0.416535, acc 0.84375\n",
      "2018-05-04T14:07:44.821699: step 1290, loss 0.370438, acc 0.828125\n",
      "2018-05-04T14:07:45.972223: step 1291, loss 0.325022, acc 0.875\n",
      "2018-05-04T14:07:47.093618: step 1292, loss 0.314917, acc 0.859375\n",
      "2018-05-04T14:07:48.202154: step 1293, loss 0.382959, acc 0.84375\n",
      "2018-05-04T14:07:49.344890: step 1294, loss 0.320074, acc 0.828125\n",
      "2018-05-04T14:07:50.441348: step 1295, loss 0.316589, acc 0.875\n",
      "2018-05-04T14:07:51.600898: step 1296, loss 0.401199, acc 0.75\n",
      "2018-05-04T14:07:52.661680: step 1297, loss 0.255142, acc 0.890625\n",
      "2018-05-04T14:07:53.757531: step 1298, loss 0.502058, acc 0.734375\n",
      "2018-05-04T14:07:54.872719: step 1299, loss 0.378126, acc 0.84375\n",
      "2018-05-04T14:07:55.993261: step 1300, loss 0.409981, acc 0.828125\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T14:07:58.757722: step 1300, loss 0.313169, acc 0.88\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-1300\n",
      "\n",
      "2018-05-04T14:08:00.094612: step 1301, loss 0.393125, acc 0.828125\n",
      "2018-05-04T14:08:01.348358: step 1302, loss 0.433809, acc 0.796875\n",
      "2018-05-04T14:08:02.557826: step 1303, loss 0.440628, acc 0.78125\n",
      "2018-05-04T14:08:03.723986: step 1304, loss 0.566946, acc 0.78125\n",
      "2018-05-04T14:08:04.817294: step 1305, loss 0.476163, acc 0.765625\n",
      "2018-05-04T14:08:05.910633: step 1306, loss 0.392817, acc 0.796875\n",
      "2018-05-04T14:08:06.984859: step 1307, loss 0.33392, acc 0.84375\n",
      "2018-05-04T14:08:08.071142: step 1308, loss 0.408794, acc 0.8125\n",
      "2018-05-04T14:08:09.191536: step 1309, loss 0.323821, acc 0.90625\n",
      "2018-05-04T14:08:10.323514: step 1310, loss 0.374861, acc 0.875\n",
      "2018-05-04T14:08:11.452676: step 1311, loss 0.42832, acc 0.78125\n",
      "2018-05-04T14:08:12.501792: step 1312, loss 0.364697, acc 0.859375\n",
      "2018-05-04T14:08:13.567926: step 1313, loss 0.333968, acc 0.84375\n",
      "2018-05-04T14:08:14.611361: step 1314, loss 0.296191, acc 0.84375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T14:08:15.669907: step 1315, loss 0.433822, acc 0.828125\n",
      "2018-05-04T14:08:16.822831: step 1316, loss 0.436395, acc 0.765625\n",
      "2018-05-04T14:08:17.866623: step 1317, loss 0.407367, acc 0.828125\n",
      "2018-05-04T14:08:18.926452: step 1318, loss 0.401023, acc 0.8125\n",
      "2018-05-04T14:08:19.973114: step 1319, loss 0.364628, acc 0.875\n",
      "2018-05-04T14:08:21.082998: step 1320, loss 0.338983, acc 0.859375\n",
      "2018-05-04T14:08:22.214643: step 1321, loss 0.616762, acc 0.734375\n",
      "2018-05-04T14:08:23.258141: step 1322, loss 0.40774, acc 0.8125\n",
      "2018-05-04T14:08:24.331144: step 1323, loss 0.378308, acc 0.828125\n",
      "2018-05-04T14:08:25.361382: step 1324, loss 0.352843, acc 0.8125\n",
      "2018-05-04T14:08:26.393065: step 1325, loss 0.357398, acc 0.84375\n",
      "2018-05-04T14:08:27.446956: step 1326, loss 0.321535, acc 0.859375\n",
      "2018-05-04T14:08:28.555325: step 1327, loss 0.411934, acc 0.828125\n",
      "2018-05-04T14:08:29.768408: step 1328, loss 0.490511, acc 0.8125\n",
      "2018-05-04T14:08:30.864752: step 1329, loss 0.46438, acc 0.796875\n",
      "2018-05-04T14:08:32.000598: step 1330, loss 0.358866, acc 0.875\n",
      "2018-05-04T14:08:33.050595: step 1331, loss 0.318016, acc 0.84375\n",
      "2018-05-04T14:08:34.178466: step 1332, loss 0.296783, acc 0.890625\n",
      "2018-05-04T14:08:35.215986: step 1333, loss 0.32493, acc 0.875\n",
      "2018-05-04T14:08:36.267292: step 1334, loss 0.352924, acc 0.828125\n",
      "2018-05-04T14:08:37.313267: step 1335, loss 0.279584, acc 0.890625\n",
      "2018-05-04T14:08:38.379230: step 1336, loss 0.333265, acc 0.890625\n",
      "2018-05-04T14:08:39.427883: step 1337, loss 0.470238, acc 0.75\n",
      "2018-05-04T14:08:40.470597: step 1338, loss 0.383802, acc 0.78125\n",
      "2018-05-04T14:08:41.576487: step 1339, loss 0.375172, acc 0.8125\n",
      "2018-05-04T14:08:42.607465: step 1340, loss 0.42616, acc 0.828125\n",
      "2018-05-04T14:08:43.639962: step 1341, loss 0.37056, acc 0.84375\n",
      "2018-05-04T14:08:44.707434: step 1342, loss 0.378353, acc 0.84375\n",
      "2018-05-04T14:08:45.775609: step 1343, loss 0.309031, acc 0.875\n",
      "2018-05-04T14:08:46.847035: step 1344, loss 0.339191, acc 0.875\n",
      "2018-05-04T14:08:47.927474: step 1345, loss 0.494724, acc 0.765625\n",
      "2018-05-04T14:08:49.004433: step 1346, loss 0.429433, acc 0.8125\n",
      "2018-05-04T14:08:50.161592: step 1347, loss 0.437055, acc 0.84375\n",
      "2018-05-04T14:08:51.252820: step 1348, loss 0.363632, acc 0.84375\n",
      "2018-05-04T14:08:52.290227: step 1349, loss 0.340501, acc 0.84375\n",
      "2018-05-04T14:08:53.346317: step 1350, loss 0.434965, acc 0.765625\n",
      "2018-05-04T14:08:54.403106: step 1351, loss 0.331998, acc 0.890625\n",
      "2018-05-04T14:08:55.447178: step 1352, loss 0.364243, acc 0.796875\n",
      "2018-05-04T14:08:56.538388: step 1353, loss 0.426239, acc 0.75\n",
      "2018-05-04T14:08:57.616801: step 1354, loss 0.451085, acc 0.828125\n",
      "2018-05-04T14:08:58.688340: step 1355, loss 0.383377, acc 0.8125\n",
      "2018-05-04T14:08:59.890957: step 1356, loss 0.282947, acc 0.84375\n",
      "2018-05-04T14:09:00.991363: step 1357, loss 0.322394, acc 0.875\n",
      "2018-05-04T14:09:02.083284: step 1358, loss 0.503892, acc 0.78125\n",
      "2018-05-04T14:09:03.175867: step 1359, loss 0.288174, acc 0.875\n",
      "2018-05-04T14:09:04.286753: step 1360, loss 0.500625, acc 0.765625\n",
      "2018-05-04T14:09:05.378745: step 1361, loss 0.248291, acc 0.90625\n",
      "2018-05-04T14:09:06.421264: step 1362, loss 0.376626, acc 0.859375\n",
      "2018-05-04T14:09:07.465955: step 1363, loss 0.419859, acc 0.8125\n",
      "2018-05-04T14:09:08.572171: step 1364, loss 0.40256, acc 0.796875\n",
      "2018-05-04T14:09:09.710184: step 1365, loss 0.424588, acc 0.78125\n",
      "2018-05-04T14:09:10.766967: step 1366, loss 0.374161, acc 0.8125\n",
      "2018-05-04T14:09:11.842674: step 1367, loss 0.407265, acc 0.796875\n",
      "2018-05-04T14:09:12.917979: step 1368, loss 0.436413, acc 0.78125\n",
      "2018-05-04T14:09:13.995768: step 1369, loss 0.47934, acc 0.765625\n",
      "2018-05-04T14:09:15.088323: step 1370, loss 0.32813, acc 0.890625\n",
      "2018-05-04T14:09:16.164970: step 1371, loss 0.398012, acc 0.78125\n",
      "2018-05-04T14:09:17.250188: step 1372, loss 0.498456, acc 0.75\n",
      "2018-05-04T14:09:18.347383: step 1373, loss 0.357975, acc 0.859375\n",
      "2018-05-04T14:09:19.426911: step 1374, loss 0.351836, acc 0.796875\n",
      "2018-05-04T14:09:20.537124: step 1375, loss 0.365267, acc 0.828125\n",
      "2018-05-04T14:09:21.728485: step 1376, loss 0.471937, acc 0.796875\n",
      "2018-05-04T14:09:22.792849: step 1377, loss 0.514383, acc 0.8125\n",
      "2018-05-04T14:09:23.879355: step 1378, loss 0.266101, acc 0.859375\n",
      "2018-05-04T14:09:24.951369: step 1379, loss 0.355054, acc 0.828125\n",
      "2018-05-04T14:09:26.013320: step 1380, loss 0.326254, acc 0.859375\n",
      "2018-05-04T14:09:27.106099: step 1381, loss 0.327493, acc 0.84375\n",
      "2018-05-04T14:09:28.176240: step 1382, loss 0.340827, acc 0.890625\n",
      "2018-05-04T14:09:29.317611: step 1383, loss 0.340259, acc 0.84375\n",
      "2018-05-04T14:09:30.375980: step 1384, loss 0.465757, acc 0.796875\n",
      "2018-05-04T14:09:31.522834: step 1385, loss 0.261876, acc 0.9375\n",
      "2018-05-04T14:09:32.593032: step 1386, loss 0.295722, acc 0.90625\n",
      "2018-05-04T14:09:33.673912: step 1387, loss 0.405033, acc 0.8125\n",
      "2018-05-04T14:09:34.741491: step 1388, loss 0.343342, acc 0.859375\n",
      "2018-05-04T14:09:35.887781: step 1389, loss 0.24994, acc 0.890625\n",
      "2018-05-04T14:09:36.911828: step 1390, loss 0.448803, acc 0.78125\n",
      "2018-05-04T14:09:38.039048: step 1391, loss 0.462539, acc 0.78125\n",
      "2018-05-04T14:09:39.154852: step 1392, loss 0.551835, acc 0.734375\n",
      "2018-05-04T14:09:40.254942: step 1393, loss 0.370772, acc 0.828125\n",
      "2018-05-04T14:09:41.355746: step 1394, loss 0.349034, acc 0.828125\n",
      "2018-05-04T14:09:42.395241: step 1395, loss 0.424549, acc 0.859375\n",
      "2018-05-04T14:09:43.454867: step 1396, loss 0.424422, acc 0.84375\n",
      "2018-05-04T14:09:44.595708: step 1397, loss 0.568946, acc 0.734375\n",
      "2018-05-04T14:09:45.678941: step 1398, loss 0.394568, acc 0.8125\n",
      "2018-05-04T14:09:46.807774: step 1399, loss 0.414122, acc 0.828125\n",
      "2018-05-04T14:09:47.959033: step 1400, loss 0.307723, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T14:09:50.365622: step 1400, loss 0.320333, acc 0.87\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-1400\n",
      "\n",
      "2018-05-04T14:09:51.583931: step 1401, loss 0.424767, acc 0.84375\n",
      "2018-05-04T14:09:52.702021: step 1402, loss 0.343039, acc 0.890625\n",
      "2018-05-04T14:09:53.900786: step 1403, loss 0.425685, acc 0.84375\n",
      "2018-05-04T14:09:55.043415: step 1404, loss 0.334148, acc 0.859375\n",
      "2018-05-04T14:09:56.101895: step 1405, loss 0.415631, acc 0.796875\n",
      "2018-05-04T14:09:57.218169: step 1406, loss 0.357228, acc 0.875\n",
      "2018-05-04T14:09:58.275711: step 1407, loss 0.401393, acc 0.765625\n",
      "2018-05-04T14:09:59.388333: step 1408, loss 0.377266, acc 0.84375\n",
      "2018-05-04T14:10:00.504276: step 1409, loss 0.311928, acc 0.84375\n",
      "2018-05-04T14:10:01.692902: step 1410, loss 0.38217, acc 0.8125\n",
      "2018-05-04T14:10:02.826447: step 1411, loss 0.466946, acc 0.765625\n",
      "2018-05-04T14:10:03.940595: step 1412, loss 0.42775, acc 0.78125\n",
      "2018-05-04T14:10:05.070414: step 1413, loss 0.396723, acc 0.84375\n",
      "2018-05-04T14:10:06.178089: step 1414, loss 0.306804, acc 0.828125\n",
      "2018-05-04T14:10:07.266226: step 1415, loss 0.36044, acc 0.8125\n",
      "2018-05-04T14:10:08.322805: step 1416, loss 0.405158, acc 0.8125\n",
      "2018-05-04T14:10:09.505381: step 1417, loss 0.442592, acc 0.796875\n",
      "2018-05-04T14:10:10.643085: step 1418, loss 0.409468, acc 0.8125\n",
      "2018-05-04T14:10:11.841283: step 1419, loss 0.348235, acc 0.828125\n",
      "2018-05-04T14:10:12.976125: step 1420, loss 0.365342, acc 0.859375\n",
      "2018-05-04T14:10:14.089548: step 1421, loss 0.372771, acc 0.859375\n",
      "2018-05-04T14:10:15.253427: step 1422, loss 0.313766, acc 0.875\n",
      "2018-05-04T14:10:16.368157: step 1423, loss 0.413714, acc 0.8125\n",
      "2018-05-04T14:10:17.414683: step 1424, loss 0.345852, acc 0.859375\n",
      "2018-05-04T14:10:18.524651: step 1425, loss 0.360634, acc 0.78125\n",
      "2018-05-04T14:10:19.635411: step 1426, loss 0.363446, acc 0.828125\n",
      "2018-05-04T14:10:20.715540: step 1427, loss 0.288916, acc 0.875\n",
      "2018-05-04T14:10:21.901108: step 1428, loss 0.483874, acc 0.75\n",
      "2018-05-04T14:10:23.050464: step 1429, loss 0.313405, acc 0.828125\n",
      "2018-05-04T14:10:24.197549: step 1430, loss 0.330951, acc 0.875\n",
      "2018-05-04T14:10:25.327680: step 1431, loss 0.350093, acc 0.84375\n",
      "2018-05-04T14:10:26.466845: step 1432, loss 0.406932, acc 0.828125\n",
      "2018-05-04T14:10:27.618634: step 1433, loss 0.358273, acc 0.828125\n",
      "2018-05-04T14:10:28.741198: step 1434, loss 0.336224, acc 0.859375\n",
      "2018-05-04T14:10:29.860078: step 1435, loss 0.320332, acc 0.890625\n",
      "2018-05-04T14:10:31.033247: step 1436, loss 0.416776, acc 0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T14:10:32.172961: step 1437, loss 0.366737, acc 0.8125\n",
      "2018-05-04T14:10:33.324716: step 1438, loss 0.560028, acc 0.765625\n",
      "2018-05-04T14:10:34.558543: step 1439, loss 0.4343, acc 0.78125\n",
      "2018-05-04T14:10:35.698055: step 1440, loss 0.338277, acc 0.875\n",
      "2018-05-04T14:10:36.927756: step 1441, loss 0.359787, acc 0.90625\n",
      "2018-05-04T14:10:38.111610: step 1442, loss 0.440969, acc 0.8125\n",
      "2018-05-04T14:10:39.302355: step 1443, loss 0.360864, acc 0.890625\n",
      "2018-05-04T14:10:40.473249: step 1444, loss 0.270298, acc 0.9375\n",
      "2018-05-04T14:10:41.716833: step 1445, loss 0.404849, acc 0.8125\n",
      "2018-05-04T14:10:42.833750: step 1446, loss 0.366559, acc 0.84375\n",
      "2018-05-04T14:10:44.016465: step 1447, loss 0.286816, acc 0.890625\n",
      "2018-05-04T14:10:45.149263: step 1448, loss 0.327382, acc 0.84375\n",
      "2018-05-04T14:10:46.295454: step 1449, loss 0.415982, acc 0.828125\n",
      "2018-05-04T14:10:47.445148: step 1450, loss 0.347356, acc 0.84375\n",
      "2018-05-04T14:10:48.589720: step 1451, loss 0.238329, acc 0.921875\n",
      "2018-05-04T14:10:49.746808: step 1452, loss 0.357254, acc 0.828125\n",
      "2018-05-04T14:10:50.899584: step 1453, loss 0.2936, acc 0.890625\n",
      "2018-05-04T14:10:52.043656: step 1454, loss 0.267762, acc 0.921875\n",
      "2018-05-04T14:10:53.164934: step 1455, loss 0.412893, acc 0.78125\n",
      "2018-05-04T14:10:54.294935: step 1456, loss 0.331048, acc 0.859375\n",
      "2018-05-04T14:10:55.445896: step 1457, loss 0.378798, acc 0.828125\n",
      "2018-05-04T14:10:56.576743: step 1458, loss 0.348988, acc 0.84375\n",
      "2018-05-04T14:10:57.715036: step 1459, loss 0.331651, acc 0.90625\n",
      "2018-05-04T14:10:58.866392: step 1460, loss 0.395208, acc 0.796875\n",
      "2018-05-04T14:11:00.073851: step 1461, loss 0.357904, acc 0.828125\n",
      "2018-05-04T14:11:01.265553: step 1462, loss 0.332437, acc 0.828125\n",
      "2018-05-04T14:11:02.419173: step 1463, loss 0.500728, acc 0.78125\n",
      "2018-05-04T14:11:03.572739: step 1464, loss 0.409186, acc 0.875\n",
      "2018-05-04T14:11:04.754496: step 1465, loss 0.389456, acc 0.8125\n",
      "2018-05-04T14:11:05.909922: step 1466, loss 0.34215, acc 0.875\n",
      "2018-05-04T14:11:07.009229: step 1467, loss 0.394038, acc 0.78125\n",
      "2018-05-04T14:11:08.164858: step 1468, loss 0.31005, acc 0.84375\n",
      "2018-05-04T14:11:09.252820: step 1469, loss 0.359347, acc 0.828125\n",
      "2018-05-04T14:11:10.370073: step 1470, loss 0.417482, acc 0.796875\n",
      "2018-05-04T14:11:11.584310: step 1471, loss 0.393433, acc 0.8125\n",
      "2018-05-04T14:11:12.708890: step 1472, loss 0.409362, acc 0.796875\n",
      "2018-05-04T14:11:13.877275: step 1473, loss 0.384215, acc 0.84375\n",
      "2018-05-04T14:11:15.055506: step 1474, loss 0.398581, acc 0.828125\n",
      "2018-05-04T14:11:16.187108: step 1475, loss 0.288744, acc 0.875\n",
      "2018-05-04T14:11:17.357679: step 1476, loss 0.363291, acc 0.828125\n",
      "2018-05-04T14:11:18.492513: step 1477, loss 0.40523, acc 0.8125\n",
      "2018-05-04T14:11:19.658166: step 1478, loss 0.332125, acc 0.875\n",
      "2018-05-04T14:11:20.859969: step 1479, loss 0.35956, acc 0.90625\n",
      "2018-05-04T14:11:22.048791: step 1480, loss 0.408249, acc 0.765625\n",
      "2018-05-04T14:11:23.187984: step 1481, loss 0.279076, acc 0.921875\n",
      "2018-05-04T14:11:24.327838: step 1482, loss 0.473616, acc 0.796875\n",
      "2018-05-04T14:11:25.474927: step 1483, loss 0.305233, acc 0.875\n",
      "2018-05-04T14:11:26.626064: step 1484, loss 0.370286, acc 0.84375\n",
      "2018-05-04T14:11:27.788268: step 1485, loss 0.476329, acc 0.8125\n",
      "2018-05-04T14:11:28.943393: step 1486, loss 0.278037, acc 0.875\n",
      "2018-05-04T14:11:30.081647: step 1487, loss 0.272559, acc 0.875\n",
      "2018-05-04T14:11:31.253491: step 1488, loss 0.342596, acc 0.84375\n",
      "2018-05-04T14:11:32.406727: step 1489, loss 0.452013, acc 0.765625\n",
      "2018-05-04T14:11:33.554249: step 1490, loss 0.510877, acc 0.765625\n",
      "2018-05-04T14:11:34.720420: step 1491, loss 0.351055, acc 0.84375\n",
      "2018-05-04T14:11:35.863977: step 1492, loss 0.325552, acc 0.828125\n",
      "2018-05-04T14:11:36.988525: step 1493, loss 0.490644, acc 0.78125\n",
      "2018-05-04T14:11:38.150499: step 1494, loss 0.368866, acc 0.84375\n",
      "2018-05-04T14:11:39.331137: step 1495, loss 0.405238, acc 0.828125\n",
      "2018-05-04T14:11:40.474024: step 1496, loss 0.407711, acc 0.828125\n",
      "2018-05-04T14:11:41.694587: step 1497, loss 0.371944, acc 0.828125\n",
      "2018-05-04T14:11:42.837316: step 1498, loss 0.359134, acc 0.875\n",
      "2018-05-04T14:11:43.989743: step 1499, loss 0.314551, acc 0.828125\n",
      "2018-05-04T14:11:45.164625: step 1500, loss 0.370084, acc 0.828125\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T14:11:47.633715: step 1500, loss 0.297117, acc 0.874\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-1500\n",
      "\n",
      "2018-05-04T14:11:48.887989: step 1501, loss 0.260156, acc 0.921875\n",
      "2018-05-04T14:11:50.078795: step 1502, loss 0.251079, acc 0.90625\n",
      "2018-05-04T14:11:51.323098: step 1503, loss 0.334727, acc 0.890625\n",
      "2018-05-04T14:11:52.521668: step 1504, loss 0.313253, acc 0.859375\n",
      "2018-05-04T14:11:53.709917: step 1505, loss 0.450075, acc 0.828125\n",
      "2018-05-04T14:11:54.898657: step 1506, loss 0.541497, acc 0.71875\n",
      "2018-05-04T14:11:56.049882: step 1507, loss 0.43059, acc 0.78125\n",
      "2018-05-04T14:11:57.182614: step 1508, loss 0.346763, acc 0.828125\n",
      "2018-05-04T14:11:58.328609: step 1509, loss 0.356569, acc 0.890625\n",
      "2018-05-04T14:11:59.486214: step 1510, loss 0.305486, acc 0.8125\n",
      "2018-05-04T14:12:00.632915: step 1511, loss 0.44442, acc 0.765625\n",
      "2018-05-04T14:12:01.792093: step 1512, loss 0.387961, acc 0.859375\n",
      "2018-05-04T14:12:02.940486: step 1513, loss 0.396347, acc 0.859375\n",
      "2018-05-04T14:12:04.114227: step 1514, loss 0.340266, acc 0.84375\n",
      "2018-05-04T14:12:05.272199: step 1515, loss 0.209776, acc 0.9375\n",
      "2018-05-04T14:12:06.401716: step 1516, loss 0.279065, acc 0.859375\n",
      "2018-05-04T14:12:07.539455: step 1517, loss 0.431532, acc 0.765625\n",
      "2018-05-04T14:12:08.662844: step 1518, loss 0.276132, acc 0.921875\n",
      "2018-05-04T14:12:09.817861: step 1519, loss 0.321895, acc 0.875\n",
      "2018-05-04T14:12:10.998245: step 1520, loss 0.301857, acc 0.921875\n",
      "2018-05-04T14:12:12.175505: step 1521, loss 0.394132, acc 0.8125\n",
      "2018-05-04T14:12:13.365411: step 1522, loss 0.365601, acc 0.8125\n",
      "2018-05-04T14:12:14.535345: step 1523, loss 0.4045, acc 0.796875\n",
      "2018-05-04T14:12:15.673162: step 1524, loss 0.351446, acc 0.859375\n",
      "2018-05-04T14:12:16.803966: step 1525, loss 0.393373, acc 0.8125\n",
      "2018-05-04T14:12:17.947604: step 1526, loss 0.460149, acc 0.75\n",
      "2018-05-04T14:12:19.082534: step 1527, loss 0.344898, acc 0.84375\n",
      "2018-05-04T14:12:20.248639: step 1528, loss 0.431773, acc 0.828125\n",
      "2018-05-04T14:12:21.465274: step 1529, loss 0.304209, acc 0.90625\n",
      "2018-05-04T14:12:22.627803: step 1530, loss 0.334073, acc 0.84375\n",
      "2018-05-04T14:12:23.789524: step 1531, loss 0.234536, acc 0.953125\n",
      "2018-05-04T14:12:24.980656: step 1532, loss 0.249768, acc 0.890625\n",
      "2018-05-04T14:12:26.152741: step 1533, loss 0.530365, acc 0.75\n",
      "2018-05-04T14:12:27.317419: step 1534, loss 0.451711, acc 0.796875\n",
      "2018-05-04T14:12:28.429063: step 1535, loss 0.409322, acc 0.890625\n",
      "2018-05-04T14:12:29.603989: step 1536, loss 0.445927, acc 0.8125\n",
      "2018-05-04T14:12:30.758603: step 1537, loss 0.404057, acc 0.875\n",
      "2018-05-04T14:12:31.940597: step 1538, loss 0.331539, acc 0.828125\n",
      "2018-05-04T14:12:33.090490: step 1539, loss 0.395184, acc 0.78125\n",
      "2018-05-04T14:12:34.269173: step 1540, loss 0.527789, acc 0.78125\n",
      "2018-05-04T14:12:35.419708: step 1541, loss 0.455111, acc 0.78125\n",
      "2018-05-04T14:12:36.562249: step 1542, loss 0.319734, acc 0.84375\n",
      "2018-05-04T14:12:37.695500: step 1543, loss 0.293037, acc 0.890625\n",
      "2018-05-04T14:12:38.853032: step 1544, loss 0.355706, acc 0.859375\n",
      "2018-05-04T14:12:40.009150: step 1545, loss 0.340854, acc 0.875\n",
      "2018-05-04T14:12:41.211879: step 1546, loss 0.269568, acc 0.921875\n",
      "2018-05-04T14:12:42.366871: step 1547, loss 0.279991, acc 0.90625\n",
      "2018-05-04T14:12:43.502531: step 1548, loss 0.243687, acc 0.9375\n",
      "2018-05-04T14:12:44.658110: step 1549, loss 0.386751, acc 0.828125\n",
      "2018-05-04T14:12:45.783724: step 1550, loss 0.327085, acc 0.875\n",
      "2018-05-04T14:12:46.917953: step 1551, loss 0.340298, acc 0.828125\n",
      "2018-05-04T14:12:48.049931: step 1552, loss 0.438535, acc 0.8125\n",
      "2018-05-04T14:12:49.209446: step 1553, loss 0.352636, acc 0.796875\n",
      "2018-05-04T14:12:50.338171: step 1554, loss 0.228313, acc 0.953125\n",
      "2018-05-04T14:12:51.509245: step 1555, loss 0.381847, acc 0.78125\n",
      "2018-05-04T14:12:52.637587: step 1556, loss 0.471688, acc 0.8125\n",
      "2018-05-04T14:12:53.783921: step 1557, loss 0.362759, acc 0.84375\n",
      "2018-05-04T14:12:54.982785: step 1558, loss 0.553133, acc 0.765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T14:12:56.062905: step 1559, loss 0.374546, acc 0.8125\n",
      "2018-05-04T14:12:57.175761: step 1560, loss 0.419403, acc 0.84375\n",
      "2018-05-04T14:12:58.308090: step 1561, loss 0.466079, acc 0.78125\n",
      "2018-05-04T14:12:59.422256: step 1562, loss 0.294161, acc 0.9375\n",
      "2018-05-04T14:13:00.575554: step 1563, loss 0.370665, acc 0.828125\n",
      "2018-05-04T14:13:01.753398: step 1564, loss 0.386959, acc 0.875\n",
      "2018-05-04T14:13:02.896522: step 1565, loss 0.332418, acc 0.875\n",
      "2018-05-04T14:13:04.042012: step 1566, loss 0.380156, acc 0.828125\n",
      "2018-05-04T14:13:05.216456: step 1567, loss 0.515222, acc 0.75\n",
      "2018-05-04T14:13:06.373926: step 1568, loss 0.34004, acc 0.828125\n",
      "2018-05-04T14:13:07.473859: step 1569, loss 0.2691, acc 0.875\n",
      "2018-05-04T14:13:08.605990: step 1570, loss 0.345686, acc 0.8125\n",
      "2018-05-04T14:13:09.790368: step 1571, loss 0.233291, acc 0.90625\n",
      "2018-05-04T14:13:10.942749: step 1572, loss 0.448824, acc 0.8125\n",
      "2018-05-04T14:13:12.109138: step 1573, loss 0.362864, acc 0.828125\n",
      "2018-05-04T14:13:13.295949: step 1574, loss 0.274346, acc 0.90625\n",
      "2018-05-04T14:13:14.418270: step 1575, loss 0.421732, acc 0.828125\n",
      "2018-05-04T14:13:15.561164: step 1576, loss 0.372553, acc 0.828125\n",
      "2018-05-04T14:13:16.700291: step 1577, loss 0.294144, acc 0.90625\n",
      "2018-05-04T14:13:17.862794: step 1578, loss 0.373648, acc 0.828125\n",
      "2018-05-04T14:13:19.001753: step 1579, loss 0.358899, acc 0.796875\n",
      "2018-05-04T14:13:20.149041: step 1580, loss 0.474263, acc 0.75\n",
      "2018-05-04T14:13:21.385478: step 1581, loss 0.437656, acc 0.765625\n",
      "2018-05-04T14:13:22.529179: step 1582, loss 0.41298, acc 0.8125\n",
      "2018-05-04T14:13:23.657553: step 1583, loss 0.281987, acc 0.859375\n",
      "2018-05-04T14:13:24.777780: step 1584, loss 0.369365, acc 0.828125\n",
      "2018-05-04T14:13:25.862403: step 1585, loss 0.338263, acc 0.859375\n",
      "2018-05-04T14:13:26.972095: step 1586, loss 0.349069, acc 0.84375\n",
      "2018-05-04T14:13:28.087544: step 1587, loss 0.308762, acc 0.859375\n",
      "2018-05-04T14:13:29.177733: step 1588, loss 0.424798, acc 0.8125\n",
      "2018-05-04T14:13:30.261746: step 1589, loss 0.393718, acc 0.859375\n",
      "2018-05-04T14:13:31.483220: step 1590, loss 0.385994, acc 0.859375\n",
      "2018-05-04T14:13:32.639259: step 1591, loss 0.444321, acc 0.765625\n",
      "2018-05-04T14:13:33.866785: step 1592, loss 0.315745, acc 0.890625\n",
      "2018-05-04T14:13:35.105717: step 1593, loss 0.350051, acc 0.859375\n",
      "2018-05-04T14:13:36.302182: step 1594, loss 0.328798, acc 0.84375\n",
      "2018-05-04T14:13:37.507202: step 1595, loss 0.465528, acc 0.78125\n",
      "2018-05-04T14:13:38.650169: step 1596, loss 0.456845, acc 0.734375\n",
      "2018-05-04T14:13:39.788132: step 1597, loss 0.265586, acc 0.921875\n",
      "2018-05-04T14:13:40.952297: step 1598, loss 0.441932, acc 0.796875\n",
      "2018-05-04T14:13:42.133179: step 1599, loss 0.307264, acc 0.890625\n",
      "2018-05-04T14:13:43.270125: step 1600, loss 0.381161, acc 0.796875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T14:13:45.840899: step 1600, loss 0.294906, acc 0.872\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-1600\n",
      "\n",
      "2018-05-04T14:13:47.116215: step 1601, loss 0.294859, acc 0.890625\n",
      "2018-05-04T14:13:48.255510: step 1602, loss 0.358377, acc 0.828125\n",
      "2018-05-04T14:13:49.414467: step 1603, loss 0.404268, acc 0.84375\n",
      "2018-05-04T14:13:50.580173: step 1604, loss 0.264942, acc 0.890625\n",
      "2018-05-04T14:13:51.757402: step 1605, loss 0.363307, acc 0.890625\n",
      "2018-05-04T14:13:52.874887: step 1606, loss 0.479201, acc 0.78125\n",
      "2018-05-04T14:13:54.000303: step 1607, loss 0.403069, acc 0.828125\n",
      "2018-05-04T14:13:55.128732: step 1608, loss 0.31354, acc 0.859375\n",
      "2018-05-04T14:13:56.261811: step 1609, loss 0.256022, acc 0.90625\n",
      "2018-05-04T14:13:57.400482: step 1610, loss 0.286166, acc 0.859375\n",
      "2018-05-04T14:13:58.520427: step 1611, loss 0.37098, acc 0.8125\n",
      "2018-05-04T14:13:59.600210: step 1612, loss 0.365291, acc 0.875\n",
      "2018-05-04T14:14:00.705139: step 1613, loss 0.385577, acc 0.8125\n",
      "2018-05-04T14:14:01.830832: step 1614, loss 0.383942, acc 0.796875\n",
      "2018-05-04T14:14:02.898914: step 1615, loss 0.281821, acc 0.875\n",
      "2018-05-04T14:14:04.010041: step 1616, loss 0.27905, acc 0.875\n",
      "2018-05-04T14:14:05.129463: step 1617, loss 0.420802, acc 0.8125\n",
      "2018-05-04T14:14:06.211096: step 1618, loss 0.386213, acc 0.796875\n",
      "2018-05-04T14:14:07.295527: step 1619, loss 0.326363, acc 0.828125\n",
      "2018-05-04T14:14:08.381257: step 1620, loss 0.344502, acc 0.84375\n",
      "2018-05-04T14:14:09.496941: step 1621, loss 0.306376, acc 0.84375\n",
      "2018-05-04T14:14:10.652666: step 1622, loss 0.393166, acc 0.84375\n",
      "2018-05-04T14:14:11.817669: step 1623, loss 0.269309, acc 0.90625\n",
      "2018-05-04T14:14:12.939424: step 1624, loss 0.352138, acc 0.890625\n",
      "2018-05-04T14:14:14.062386: step 1625, loss 0.458178, acc 0.78125\n",
      "2018-05-04T14:14:15.192332: step 1626, loss 0.396604, acc 0.828125\n",
      "2018-05-04T14:14:16.308017: step 1627, loss 0.392725, acc 0.828125\n",
      "2018-05-04T14:14:17.401788: step 1628, loss 0.46489, acc 0.796875\n",
      "2018-05-04T14:14:18.478940: step 1629, loss 0.31225, acc 0.875\n",
      "2018-05-04T14:14:19.573276: step 1630, loss 0.31825, acc 0.8125\n",
      "2018-05-04T14:14:20.685856: step 1631, loss 0.320058, acc 0.84375\n",
      "2018-05-04T14:14:21.796451: step 1632, loss 0.3571, acc 0.84375\n",
      "2018-05-04T14:14:22.899276: step 1633, loss 0.358085, acc 0.875\n",
      "2018-05-04T14:14:23.985675: step 1634, loss 0.322143, acc 0.859375\n",
      "2018-05-04T14:14:25.144321: step 1635, loss 0.39567, acc 0.828125\n",
      "2018-05-04T14:14:26.265799: step 1636, loss 0.325408, acc 0.890625\n",
      "2018-05-04T14:14:27.381888: step 1637, loss 0.301571, acc 0.90625\n",
      "2018-05-04T14:14:28.538517: step 1638, loss 0.198967, acc 0.953125\n",
      "2018-05-04T14:14:29.706696: step 1639, loss 0.253719, acc 0.90625\n",
      "2018-05-04T14:14:30.863036: step 1640, loss 0.403797, acc 0.78125\n",
      "2018-05-04T14:14:32.058376: step 1641, loss 0.413331, acc 0.828125\n",
      "2018-05-04T14:14:33.168570: step 1642, loss 0.392952, acc 0.8125\n",
      "2018-05-04T14:14:34.361177: step 1643, loss 0.389971, acc 0.875\n",
      "2018-05-04T14:14:35.559314: step 1644, loss 0.328008, acc 0.8125\n",
      "2018-05-04T14:14:36.712512: step 1645, loss 0.307065, acc 0.859375\n",
      "2018-05-04T14:14:37.815246: step 1646, loss 0.520202, acc 0.765625\n",
      "2018-05-04T14:14:38.922501: step 1647, loss 0.475195, acc 0.796875\n",
      "2018-05-04T14:14:40.014199: step 1648, loss 0.322772, acc 0.890625\n",
      "2018-05-04T14:14:41.150067: step 1649, loss 0.322202, acc 0.890625\n",
      "2018-05-04T14:14:42.261834: step 1650, loss 0.259327, acc 0.890625\n",
      "2018-05-04T14:14:43.371080: step 1651, loss 0.294701, acc 0.90625\n",
      "2018-05-04T14:14:44.473874: step 1652, loss 0.335211, acc 0.84375\n",
      "2018-05-04T14:14:45.601954: step 1653, loss 0.321034, acc 0.875\n",
      "2018-05-04T14:14:46.711672: step 1654, loss 0.363255, acc 0.875\n",
      "2018-05-04T14:14:47.824434: step 1655, loss 0.39617, acc 0.8125\n",
      "2018-05-04T14:14:48.953770: step 1656, loss 0.287318, acc 0.890625\n",
      "2018-05-04T14:14:50.083371: step 1657, loss 0.287206, acc 0.875\n",
      "2018-05-04T14:14:51.252004: step 1658, loss 0.374703, acc 0.859375\n",
      "2018-05-04T14:14:52.356003: step 1659, loss 0.290561, acc 0.8125\n",
      "2018-05-04T14:14:53.461156: step 1660, loss 0.307007, acc 0.890625\n",
      "2018-05-04T14:14:54.606147: step 1661, loss 0.371408, acc 0.828125\n",
      "2018-05-04T14:14:55.750168: step 1662, loss 0.423839, acc 0.78125\n",
      "2018-05-04T14:14:56.880978: step 1663, loss 0.426812, acc 0.828125\n",
      "2018-05-04T14:14:57.999905: step 1664, loss 0.378069, acc 0.84375\n",
      "2018-05-04T14:14:59.139293: step 1665, loss 0.521308, acc 0.734375\n",
      "2018-05-04T14:15:00.261532: step 1666, loss 0.404204, acc 0.8125\n",
      "2018-05-04T14:15:01.447318: step 1667, loss 0.521888, acc 0.75\n",
      "2018-05-04T14:15:02.553150: step 1668, loss 0.332642, acc 0.859375\n",
      "2018-05-04T14:15:03.679603: step 1669, loss 0.405965, acc 0.828125\n",
      "2018-05-04T14:15:04.823084: step 1670, loss 0.305008, acc 0.890625\n",
      "2018-05-04T14:15:05.951217: step 1671, loss 0.394825, acc 0.8125\n",
      "2018-05-04T14:15:07.077805: step 1672, loss 0.385217, acc 0.859375\n",
      "2018-05-04T14:15:08.171269: step 1673, loss 0.333502, acc 0.84375\n",
      "2018-05-04T14:15:09.318441: step 1674, loss 0.301878, acc 0.921875\n",
      "2018-05-04T14:15:10.432420: step 1675, loss 0.358552, acc 0.8125\n",
      "2018-05-04T14:15:11.614367: step 1676, loss 0.453804, acc 0.765625\n",
      "2018-05-04T14:15:12.748554: step 1677, loss 0.358006, acc 0.828125\n",
      "2018-05-04T14:15:13.901777: step 1678, loss 0.355398, acc 0.828125\n",
      "2018-05-04T14:15:15.094655: step 1679, loss 0.317588, acc 0.875\n",
      "2018-05-04T14:15:16.278178: step 1680, loss 0.421867, acc 0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T14:15:17.408125: step 1681, loss 0.401895, acc 0.84375\n",
      "2018-05-04T14:15:18.516443: step 1682, loss 0.352219, acc 0.84375\n",
      "2018-05-04T14:15:19.645987: step 1683, loss 0.415952, acc 0.8125\n",
      "2018-05-04T14:15:20.808130: step 1684, loss 0.299755, acc 0.828125\n",
      "2018-05-04T14:15:21.971064: step 1685, loss 0.434957, acc 0.796875\n",
      "2018-05-04T14:15:23.091745: step 1686, loss 0.475699, acc 0.765625\n",
      "2018-05-04T14:15:24.205888: step 1687, loss 0.409267, acc 0.828125\n",
      "2018-05-04T14:15:25.408538: step 1688, loss 0.266975, acc 0.90625\n",
      "2018-05-04T14:15:26.511169: step 1689, loss 0.443588, acc 0.8125\n",
      "2018-05-04T14:15:27.592007: step 1690, loss 0.468252, acc 0.765625\n",
      "2018-05-04T14:15:28.689788: step 1691, loss 0.476913, acc 0.71875\n",
      "2018-05-04T14:15:29.855228: step 1692, loss 0.326334, acc 0.875\n",
      "2018-05-04T14:15:31.057850: step 1693, loss 0.346454, acc 0.90625\n",
      "2018-05-04T14:15:32.237422: step 1694, loss 0.446283, acc 0.796875\n",
      "2018-05-04T14:15:33.311076: step 1695, loss 0.308918, acc 0.859375\n",
      "2018-05-04T14:15:34.463634: step 1696, loss 0.499238, acc 0.765625\n",
      "2018-05-04T14:15:35.552732: step 1697, loss 0.294601, acc 0.875\n",
      "2018-05-04T14:15:36.662006: step 1698, loss 0.398814, acc 0.8125\n",
      "2018-05-04T14:15:37.780935: step 1699, loss 0.491377, acc 0.78125\n",
      "2018-05-04T14:15:38.984566: step 1700, loss 0.451771, acc 0.765625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T14:15:41.752293: step 1700, loss 0.300911, acc 0.876\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-1700\n",
      "\n",
      "2018-05-04T14:15:42.989425: step 1701, loss 0.329045, acc 0.859375\n",
      "2018-05-04T14:15:44.177720: step 1702, loss 0.286297, acc 0.875\n",
      "2018-05-04T14:15:45.333252: step 1703, loss 0.298443, acc 0.859375\n",
      "2018-05-04T14:15:46.478995: step 1704, loss 0.216396, acc 0.953125\n",
      "2018-05-04T14:15:47.607159: step 1705, loss 0.309974, acc 0.859375\n",
      "2018-05-04T14:15:48.750050: step 1706, loss 0.413246, acc 0.8125\n",
      "2018-05-04T14:15:49.902768: step 1707, loss 0.329872, acc 0.859375\n",
      "2018-05-04T14:15:51.111107: step 1708, loss 0.41421, acc 0.828125\n",
      "2018-05-04T14:15:52.314935: step 1709, loss 0.385685, acc 0.8125\n",
      "2018-05-04T14:15:53.402769: step 1710, loss 0.24557, acc 0.875\n",
      "2018-05-04T14:15:54.509613: step 1711, loss 0.313543, acc 0.859375\n",
      "2018-05-04T14:15:55.638823: step 1712, loss 0.311802, acc 0.859375\n",
      "2018-05-04T14:15:56.796444: step 1713, loss 0.297725, acc 0.859375\n",
      "2018-05-04T14:15:57.886203: step 1714, loss 0.364095, acc 0.8125\n",
      "2018-05-04T14:15:58.983512: step 1715, loss 0.313975, acc 0.8125\n",
      "2018-05-04T14:16:00.166581: step 1716, loss 0.360222, acc 0.796875\n",
      "2018-05-04T14:16:01.334290: step 1717, loss 0.277291, acc 0.875\n",
      "2018-05-04T14:16:02.448641: step 1718, loss 0.551077, acc 0.6875\n",
      "2018-05-04T14:16:03.571265: step 1719, loss 0.235107, acc 0.921875\n",
      "2018-05-04T14:16:04.730530: step 1720, loss 0.259888, acc 0.890625\n",
      "2018-05-04T14:16:05.854955: step 1721, loss 0.300156, acc 0.875\n",
      "2018-05-04T14:16:06.960740: step 1722, loss 0.439085, acc 0.765625\n",
      "2018-05-04T14:16:08.102251: step 1723, loss 0.349371, acc 0.875\n",
      "2018-05-04T14:16:09.297243: step 1724, loss 0.443804, acc 0.84375\n",
      "2018-05-04T14:16:10.488013: step 1725, loss 0.383599, acc 0.828125\n",
      "2018-05-04T14:16:11.627980: step 1726, loss 0.409105, acc 0.765625\n",
      "2018-05-04T14:16:12.723479: step 1727, loss 0.463925, acc 0.796875\n",
      "2018-05-04T14:16:13.790137: step 1728, loss 0.413668, acc 0.859375\n",
      "2018-05-04T14:16:14.880813: step 1729, loss 0.336522, acc 0.828125\n",
      "2018-05-04T14:16:15.982512: step 1730, loss 0.26167, acc 0.890625\n",
      "2018-05-04T14:16:17.103116: step 1731, loss 0.364013, acc 0.828125\n",
      "2018-05-04T14:16:18.203280: step 1732, loss 0.329025, acc 0.828125\n",
      "2018-05-04T14:16:19.424296: step 1733, loss 0.394874, acc 0.828125\n",
      "2018-05-04T14:16:20.588168: step 1734, loss 0.412198, acc 0.84375\n",
      "2018-05-04T14:16:21.752058: step 1735, loss 0.339954, acc 0.890625\n",
      "2018-05-04T14:16:22.868904: step 1736, loss 0.316787, acc 0.90625\n",
      "2018-05-04T14:16:24.003890: step 1737, loss 0.289453, acc 0.890625\n",
      "2018-05-04T14:16:25.128497: step 1738, loss 0.398825, acc 0.796875\n",
      "2018-05-04T14:16:26.264860: step 1739, loss 0.310589, acc 0.8125\n",
      "2018-05-04T14:16:27.400633: step 1740, loss 0.442053, acc 0.78125\n",
      "2018-05-04T14:16:28.531646: step 1741, loss 0.349407, acc 0.828125\n",
      "2018-05-04T14:16:29.654422: step 1742, loss 0.255509, acc 0.890625\n",
      "2018-05-04T14:16:30.777484: step 1743, loss 0.421637, acc 0.796875\n",
      "2018-05-04T14:16:31.927932: step 1744, loss 0.286476, acc 0.859375\n",
      "2018-05-04T14:16:33.082518: step 1745, loss 0.392744, acc 0.859375\n",
      "2018-05-04T14:16:34.272774: step 1746, loss 0.315383, acc 0.921875\n",
      "2018-05-04T14:16:35.480835: step 1747, loss 0.437469, acc 0.828125\n",
      "2018-05-04T14:16:36.668789: step 1748, loss 0.276232, acc 0.875\n",
      "2018-05-04T14:16:37.834957: step 1749, loss 0.495969, acc 0.765625\n",
      "2018-05-04T14:16:38.941570: step 1750, loss 0.298667, acc 0.859375\n",
      "2018-05-04T14:16:40.132924: step 1751, loss 0.303293, acc 0.875\n",
      "2018-05-04T14:16:41.323510: step 1752, loss 0.431315, acc 0.734375\n",
      "2018-05-04T14:16:42.439892: step 1753, loss 0.32615, acc 0.875\n",
      "2018-05-04T14:16:43.572621: step 1754, loss 0.316414, acc 0.90625\n",
      "2018-05-04T14:16:44.706904: step 1755, loss 0.401164, acc 0.796875\n",
      "2018-05-04T14:16:45.908959: step 1756, loss 0.3612, acc 0.84375\n",
      "2018-05-04T14:16:47.002163: step 1757, loss 0.327026, acc 0.875\n",
      "2018-05-04T14:16:48.089659: step 1758, loss 0.245387, acc 0.875\n",
      "2018-05-04T14:16:49.223942: step 1759, loss 0.414197, acc 0.828125\n",
      "2018-05-04T14:16:50.335395: step 1760, loss 0.314419, acc 0.859375\n",
      "2018-05-04T14:16:51.494632: step 1761, loss 0.340434, acc 0.8125\n",
      "2018-05-04T14:16:52.602008: step 1762, loss 0.347256, acc 0.859375\n",
      "2018-05-04T14:16:53.713870: step 1763, loss 0.544257, acc 0.8125\n",
      "2018-05-04T14:16:54.880997: step 1764, loss 0.285011, acc 0.890625\n",
      "2018-05-04T14:16:56.003269: step 1765, loss 0.33799, acc 0.875\n",
      "2018-05-04T14:16:57.120896: step 1766, loss 0.364993, acc 0.828125\n",
      "2018-05-04T14:16:58.236195: step 1767, loss 0.352422, acc 0.84375\n",
      "2018-05-04T14:16:59.383498: step 1768, loss 0.277625, acc 0.890625\n",
      "2018-05-04T14:17:00.504106: step 1769, loss 0.339174, acc 0.84375\n",
      "2018-05-04T14:17:01.679496: step 1770, loss 0.341276, acc 0.859375\n",
      "2018-05-04T14:17:02.783545: step 1771, loss 0.380355, acc 0.828125\n",
      "2018-05-04T14:17:03.978139: step 1772, loss 0.320044, acc 0.828125\n",
      "2018-05-04T14:17:05.154942: step 1773, loss 0.433829, acc 0.796875\n",
      "2018-05-04T14:17:06.289589: step 1774, loss 0.387696, acc 0.84375\n",
      "2018-05-04T14:17:07.413882: step 1775, loss 0.356925, acc 0.8125\n",
      "2018-05-04T14:17:08.551352: step 1776, loss 0.325498, acc 0.84375\n",
      "2018-05-04T14:17:09.689725: step 1777, loss 0.310797, acc 0.859375\n",
      "2018-05-04T14:17:10.808708: step 1778, loss 0.352972, acc 0.8125\n",
      "2018-05-04T14:17:11.943113: step 1779, loss 0.45188, acc 0.765625\n",
      "2018-05-04T14:17:13.027998: step 1780, loss 0.228321, acc 0.90625\n",
      "2018-05-04T14:17:14.113576: step 1781, loss 0.325277, acc 0.828125\n",
      "2018-05-04T14:17:15.227001: step 1782, loss 0.247911, acc 0.90625\n",
      "2018-05-04T14:17:16.351553: step 1783, loss 0.314692, acc 0.875\n",
      "2018-05-04T14:17:17.491719: step 1784, loss 0.309404, acc 0.875\n",
      "2018-05-04T14:17:18.604285: step 1785, loss 0.425577, acc 0.796875\n",
      "2018-05-04T14:17:19.808123: step 1786, loss 0.312457, acc 0.875\n",
      "2018-05-04T14:17:21.073212: step 1787, loss 0.328762, acc 0.890625\n",
      "2018-05-04T14:17:22.280600: step 1788, loss 0.354061, acc 0.84375\n",
      "2018-05-04T14:17:23.408604: step 1789, loss 0.33437, acc 0.859375\n",
      "2018-05-04T14:17:24.552305: step 1790, loss 0.383702, acc 0.84375\n",
      "2018-05-04T14:17:25.673894: step 1791, loss 0.481687, acc 0.765625\n",
      "2018-05-04T14:17:26.790300: step 1792, loss 0.314359, acc 0.859375\n",
      "2018-05-04T14:17:27.874310: step 1793, loss 0.337576, acc 0.890625\n",
      "2018-05-04T14:17:28.944093: step 1794, loss 0.220152, acc 0.90625\n",
      "2018-05-04T14:17:30.083399: step 1795, loss 0.445447, acc 0.8125\n",
      "2018-05-04T14:17:31.222501: step 1796, loss 0.297575, acc 0.875\n",
      "2018-05-04T14:17:32.426756: step 1797, loss 0.384038, acc 0.84375\n",
      "2018-05-04T14:17:33.589972: step 1798, loss 0.420342, acc 0.8125\n",
      "2018-05-04T14:17:34.795688: step 1799, loss 0.222285, acc 0.9375\n",
      "2018-05-04T14:17:35.998484: step 1800, loss 0.299929, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T14:17:38.557843: step 1800, loss 0.284904, acc 0.882\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-1800\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T14:17:39.752391: step 1801, loss 0.326511, acc 0.875\n",
      "2018-05-04T14:17:40.906712: step 1802, loss 0.289768, acc 0.84375\n",
      "2018-05-04T14:17:42.066186: step 1803, loss 0.208667, acc 0.9375\n",
      "2018-05-04T14:17:43.245022: step 1804, loss 0.285016, acc 0.890625\n",
      "2018-05-04T14:17:44.377406: step 1805, loss 0.41174, acc 0.84375\n",
      "2018-05-04T14:17:45.556794: step 1806, loss 0.24457, acc 0.90625\n",
      "2018-05-04T14:17:46.698194: step 1807, loss 0.367187, acc 0.859375\n",
      "2018-05-04T14:17:47.856904: step 1808, loss 0.296657, acc 0.90625\n",
      "2018-05-04T14:17:48.986210: step 1809, loss 0.383023, acc 0.8125\n",
      "2018-05-04T14:17:50.122538: step 1810, loss 0.395989, acc 0.828125\n",
      "2018-05-04T14:17:51.265617: step 1811, loss 0.365238, acc 0.875\n",
      "2018-05-04T14:17:52.352028: step 1812, loss 0.298597, acc 0.875\n",
      "2018-05-04T14:17:53.436785: step 1813, loss 0.370796, acc 0.84375\n",
      "2018-05-04T14:17:54.606650: step 1814, loss 0.386061, acc 0.8125\n",
      "2018-05-04T14:17:55.722989: step 1815, loss 0.313332, acc 0.859375\n",
      "2018-05-04T14:17:56.878030: step 1816, loss 0.402382, acc 0.8125\n",
      "2018-05-04T14:17:58.048752: step 1817, loss 0.392712, acc 0.78125\n",
      "2018-05-04T14:17:59.194523: step 1818, loss 0.354161, acc 0.828125\n",
      "2018-05-04T14:18:00.378474: step 1819, loss 0.25621, acc 0.890625\n",
      "2018-05-04T14:18:01.635121: step 1820, loss 0.411288, acc 0.828125\n",
      "2018-05-04T14:18:02.748228: step 1821, loss 0.58153, acc 0.765625\n",
      "2018-05-04T14:18:03.929240: step 1822, loss 0.279325, acc 0.90625\n",
      "2018-05-04T14:18:05.073581: step 1823, loss 0.501609, acc 0.78125\n",
      "2018-05-04T14:18:06.226573: step 1824, loss 0.355787, acc 0.875\n",
      "2018-05-04T14:18:07.294440: step 1825, loss 0.334328, acc 0.84375\n",
      "2018-05-04T14:18:08.436118: step 1826, loss 0.264268, acc 0.90625\n",
      "2018-05-04T14:18:09.553147: step 1827, loss 0.347697, acc 0.859375\n",
      "2018-05-04T14:18:10.701115: step 1828, loss 0.277474, acc 0.90625\n",
      "2018-05-04T14:18:11.855545: step 1829, loss 0.287941, acc 0.875\n",
      "2018-05-04T14:18:13.022024: step 1830, loss 0.323812, acc 0.875\n",
      "2018-05-04T14:18:14.209563: step 1831, loss 0.459144, acc 0.8125\n",
      "2018-05-04T14:18:15.333385: step 1832, loss 0.326328, acc 0.859375\n",
      "2018-05-04T14:18:16.502546: step 1833, loss 0.321462, acc 0.84375\n",
      "2018-05-04T14:18:17.687270: step 1834, loss 0.426527, acc 0.796875\n",
      "2018-05-04T14:18:18.806262: step 1835, loss 0.290651, acc 0.890625\n",
      "2018-05-04T14:18:19.962164: step 1836, loss 0.348828, acc 0.84375\n",
      "2018-05-04T14:18:21.207295: step 1837, loss 0.348607, acc 0.875\n",
      "2018-05-04T14:18:22.363361: step 1838, loss 0.367924, acc 0.828125\n",
      "2018-05-04T14:18:23.503606: step 1839, loss 0.461614, acc 0.8125\n",
      "2018-05-04T14:18:24.666843: step 1840, loss 0.302728, acc 0.890625\n",
      "2018-05-04T14:18:25.804159: step 1841, loss 0.244094, acc 0.84375\n",
      "2018-05-04T14:18:26.978377: step 1842, loss 0.34087, acc 0.859375\n",
      "2018-05-04T14:18:28.120793: step 1843, loss 0.529701, acc 0.78125\n",
      "2018-05-04T14:18:29.274802: step 1844, loss 0.384832, acc 0.828125\n",
      "2018-05-04T14:18:30.431827: step 1845, loss 0.380211, acc 0.828125\n",
      "2018-05-04T14:18:31.639225: step 1846, loss 0.414032, acc 0.78125\n",
      "2018-05-04T14:18:32.786042: step 1847, loss 0.306782, acc 0.875\n",
      "2018-05-04T14:18:33.931493: step 1848, loss 0.45226, acc 0.78125\n",
      "2018-05-04T14:18:35.099501: step 1849, loss 0.320145, acc 0.859375\n",
      "2018-05-04T14:18:36.234014: step 1850, loss 0.315447, acc 0.828125\n",
      "2018-05-04T14:18:37.365672: step 1851, loss 0.296695, acc 0.875\n",
      "2018-05-04T14:18:38.520485: step 1852, loss 0.31851, acc 0.859375\n",
      "2018-05-04T14:18:39.694546: step 1853, loss 0.257801, acc 0.875\n",
      "2018-05-04T14:18:40.841110: step 1854, loss 0.346107, acc 0.859375\n",
      "2018-05-04T14:18:42.025310: step 1855, loss 0.346757, acc 0.875\n",
      "2018-05-04T14:18:43.158268: step 1856, loss 0.472343, acc 0.78125\n",
      "2018-05-04T14:18:44.337945: step 1857, loss 0.260812, acc 0.875\n",
      "2018-05-04T14:18:45.476629: step 1858, loss 0.25768, acc 0.875\n",
      "2018-05-04T14:18:46.621621: step 1859, loss 0.37746, acc 0.859375\n",
      "2018-05-04T14:18:47.759344: step 1860, loss 0.240982, acc 0.890625\n",
      "2018-05-04T14:18:48.921286: step 1861, loss 0.317305, acc 0.84375\n",
      "2018-05-04T14:18:50.086777: step 1862, loss 0.455001, acc 0.765625\n",
      "2018-05-04T14:18:51.273238: step 1863, loss 0.446352, acc 0.796875\n",
      "2018-05-04T14:18:52.381476: step 1864, loss 0.375752, acc 0.796875\n",
      "2018-05-04T14:18:53.509427: step 1865, loss 0.379779, acc 0.828125\n",
      "2018-05-04T14:18:54.653640: step 1866, loss 0.363545, acc 0.828125\n",
      "2018-05-04T14:18:55.795798: step 1867, loss 0.37383, acc 0.796875\n",
      "2018-05-04T14:18:56.964056: step 1868, loss 0.408198, acc 0.796875\n",
      "2018-05-04T14:18:58.034216: step 1869, loss 0.414437, acc 0.828125\n",
      "2018-05-04T14:18:59.181431: step 1870, loss 0.283231, acc 0.890625\n",
      "2018-05-04T14:19:00.408430: step 1871, loss 0.32774, acc 0.859375\n",
      "2018-05-04T14:19:01.634082: step 1872, loss 0.263346, acc 0.890625\n",
      "2018-05-04T14:19:02.807244: step 1873, loss 0.348223, acc 0.859375\n",
      "2018-05-04T14:19:04.024801: step 1874, loss 0.295128, acc 0.875\n",
      "2018-05-04T14:19:05.232513: step 1875, loss 0.407843, acc 0.78125\n",
      "2018-05-04T14:19:06.355264: step 1876, loss 0.223371, acc 0.953125\n",
      "2018-05-04T14:19:07.502105: step 1877, loss 0.380028, acc 0.8125\n",
      "2018-05-04T14:19:08.644681: step 1878, loss 0.454053, acc 0.78125\n",
      "2018-05-04T14:19:09.810656: step 1879, loss 0.330971, acc 0.8125\n",
      "2018-05-04T14:19:10.990237: step 1880, loss 0.248807, acc 0.875\n",
      "2018-05-04T14:19:12.154217: step 1881, loss 0.295988, acc 0.890625\n",
      "2018-05-04T14:19:13.291602: step 1882, loss 0.241005, acc 0.90625\n",
      "2018-05-04T14:19:14.450319: step 1883, loss 0.27844, acc 0.921875\n",
      "2018-05-04T14:19:15.594894: step 1884, loss 0.375315, acc 0.84375\n",
      "2018-05-04T14:19:16.750704: step 1885, loss 0.332797, acc 0.84375\n",
      "2018-05-04T14:19:17.903870: step 1886, loss 0.333552, acc 0.859375\n",
      "2018-05-04T14:19:19.073165: step 1887, loss 0.342831, acc 0.875\n",
      "2018-05-04T14:19:20.220235: step 1888, loss 0.305963, acc 0.859375\n",
      "2018-05-04T14:19:21.411492: step 1889, loss 0.383786, acc 0.78125\n",
      "2018-05-04T14:19:22.561931: step 1890, loss 0.412255, acc 0.859375\n",
      "2018-05-04T14:19:23.705413: step 1891, loss 0.379608, acc 0.84375\n",
      "2018-05-04T14:19:24.854260: step 1892, loss 0.442562, acc 0.75\n",
      "2018-05-04T14:19:26.006380: step 1893, loss 0.404157, acc 0.84375\n",
      "2018-05-04T14:19:27.082737: step 1894, loss 0.395969, acc 0.828125\n",
      "2018-05-04T14:19:28.214353: step 1895, loss 0.468226, acc 0.8125\n",
      "2018-05-04T14:19:29.374589: step 1896, loss 0.490929, acc 0.84375\n",
      "2018-05-04T14:19:30.509634: step 1897, loss 0.294076, acc 0.875\n",
      "2018-05-04T14:19:31.717557: step 1898, loss 0.285901, acc 0.859375\n",
      "2018-05-04T14:19:32.877813: step 1899, loss 0.288111, acc 0.890625\n",
      "2018-05-04T14:19:34.075558: step 1900, loss 0.512366, acc 0.703125\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T14:19:36.819743: step 1900, loss 0.289626, acc 0.876\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-1900\n",
      "\n",
      "2018-05-04T14:19:38.171483: step 1901, loss 0.284456, acc 0.890625\n",
      "2018-05-04T14:19:39.359919: step 1902, loss 0.442207, acc 0.78125\n",
      "2018-05-04T14:19:40.531874: step 1903, loss 0.545455, acc 0.78125\n",
      "2018-05-04T14:19:41.717556: step 1904, loss 0.432162, acc 0.796875\n",
      "2018-05-04T14:19:42.844738: step 1905, loss 0.390355, acc 0.859375\n",
      "2018-05-04T14:19:43.943036: step 1906, loss 0.335172, acc 0.828125\n",
      "2018-05-04T14:19:45.045445: step 1907, loss 0.345605, acc 0.84375\n",
      "2018-05-04T14:19:46.139502: step 1908, loss 0.397647, acc 0.890625\n",
      "2018-05-04T14:19:47.234562: step 1909, loss 0.347568, acc 0.828125\n",
      "2018-05-04T14:19:48.323429: step 1910, loss 0.493522, acc 0.78125\n",
      "2018-05-04T14:19:49.414986: step 1911, loss 0.315022, acc 0.84375\n",
      "2018-05-04T14:19:50.508871: step 1912, loss 0.293334, acc 0.84375\n",
      "2018-05-04T14:19:51.645601: step 1913, loss 0.424134, acc 0.8125\n",
      "2018-05-04T14:19:52.733880: step 1914, loss 0.366511, acc 0.796875\n",
      "2018-05-04T14:19:53.815085: step 1915, loss 0.214304, acc 0.90625\n",
      "2018-05-04T14:19:54.902392: step 1916, loss 0.314697, acc 0.875\n",
      "2018-05-04T14:19:56.073225: step 1917, loss 0.442309, acc 0.8125\n",
      "2018-05-04T14:19:57.168586: step 1918, loss 0.442099, acc 0.796875\n",
      "2018-05-04T14:19:58.259692: step 1919, loss 0.370184, acc 0.8125\n",
      "2018-05-04T14:19:59.365561: step 1920, loss 0.405708, acc 0.8125\n",
      "2018-05-04T14:20:00.469361: step 1921, loss 0.384445, acc 0.796875\n",
      "2018-05-04T14:20:01.634683: step 1922, loss 0.334346, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T14:20:02.713239: step 1923, loss 0.306311, acc 0.875\n",
      "2018-05-04T14:20:03.818141: step 1924, loss 0.322701, acc 0.875\n",
      "2018-05-04T14:20:04.926951: step 1925, loss 0.250097, acc 0.890625\n",
      "2018-05-04T14:20:06.046333: step 1926, loss 0.36466, acc 0.84375\n",
      "2018-05-04T14:20:07.162337: step 1927, loss 0.266522, acc 0.890625\n",
      "2018-05-04T14:20:08.286457: step 1928, loss 0.273839, acc 0.875\n",
      "2018-05-04T14:20:09.438517: step 1929, loss 0.413996, acc 0.859375\n",
      "2018-05-04T14:20:10.551428: step 1930, loss 0.400027, acc 0.78125\n",
      "2018-05-04T14:20:11.712141: step 1931, loss 0.345047, acc 0.84375\n",
      "2018-05-04T14:20:12.784942: step 1932, loss 0.240422, acc 0.921875\n",
      "2018-05-04T14:20:13.866698: step 1933, loss 0.322639, acc 0.890625\n",
      "2018-05-04T14:20:14.937706: step 1934, loss 0.267907, acc 0.921875\n",
      "2018-05-04T14:20:16.002695: step 1935, loss 0.359848, acc 0.796875\n",
      "2018-05-04T14:20:17.100235: step 1936, loss 0.302631, acc 0.828125\n",
      "2018-05-04T14:20:18.194169: step 1937, loss 0.255703, acc 0.921875\n",
      "2018-05-04T14:20:19.300059: step 1938, loss 0.320579, acc 0.890625\n",
      "2018-05-04T14:20:20.461159: step 1939, loss 0.377555, acc 0.8125\n",
      "2018-05-04T14:20:21.656133: step 1940, loss 0.362734, acc 0.828125\n",
      "2018-05-04T14:20:22.765984: step 1941, loss 0.396267, acc 0.8125\n",
      "2018-05-04T14:20:23.900953: step 1942, loss 0.314383, acc 0.890625\n",
      "2018-05-04T14:20:25.032091: step 1943, loss 0.344635, acc 0.875\n",
      "2018-05-04T14:20:26.169661: step 1944, loss 0.249882, acc 0.890625\n",
      "2018-05-04T14:20:27.264158: step 1945, loss 0.39287, acc 0.84375\n",
      "2018-05-04T14:20:28.356108: step 1946, loss 0.277, acc 0.90625\n",
      "2018-05-04T14:20:29.465386: step 1947, loss 0.218546, acc 0.953125\n",
      "2018-05-04T14:20:30.543351: step 1948, loss 0.276616, acc 0.8125\n",
      "2018-05-04T14:20:31.685000: step 1949, loss 0.337284, acc 0.875\n",
      "2018-05-04T14:20:32.758332: step 1950, loss 0.542499, acc 0.765625\n",
      "2018-05-04T14:20:33.865443: step 1951, loss 0.374797, acc 0.828125\n",
      "2018-05-04T14:20:34.971339: step 1952, loss 0.308293, acc 0.921875\n",
      "2018-05-04T14:20:36.058182: step 1953, loss 0.296503, acc 0.890625\n",
      "2018-05-04T14:20:37.178800: step 1954, loss 0.310385, acc 0.859375\n",
      "2018-05-04T14:20:38.293710: step 1955, loss 0.230217, acc 0.921875\n",
      "2018-05-04T14:20:39.431786: step 1956, loss 0.274137, acc 0.890625\n",
      "2018-05-04T14:20:40.535828: step 1957, loss 0.338748, acc 0.8125\n",
      "2018-05-04T14:20:41.774607: step 1958, loss 0.303508, acc 0.890625\n",
      "2018-05-04T14:20:42.915808: step 1959, loss 0.284852, acc 0.875\n",
      "2018-05-04T14:20:44.025953: step 1960, loss 0.338905, acc 0.875\n",
      "2018-05-04T14:20:45.161083: step 1961, loss 0.283452, acc 0.90625\n",
      "2018-05-04T14:20:46.264628: step 1962, loss 0.310444, acc 0.859375\n",
      "2018-05-04T14:20:47.362093: step 1963, loss 0.278988, acc 0.875\n",
      "2018-05-04T14:20:48.436877: step 1964, loss 0.414397, acc 0.796875\n",
      "2018-05-04T14:20:49.521961: step 1965, loss 0.319677, acc 0.828125\n",
      "2018-05-04T14:20:50.604374: step 1966, loss 0.313912, acc 0.875\n",
      "2018-05-04T14:20:51.752284: step 1967, loss 0.401622, acc 0.828125\n",
      "2018-05-04T14:20:52.951963: step 1968, loss 0.428008, acc 0.828125\n",
      "2018-05-04T14:20:54.067019: step 1969, loss 0.31399, acc 0.8125\n",
      "2018-05-04T14:20:55.223673: step 1970, loss 0.261947, acc 0.890625\n",
      "2018-05-04T14:20:56.397339: step 1971, loss 0.402844, acc 0.8125\n",
      "2018-05-04T14:20:57.516594: step 1972, loss 0.274333, acc 0.921875\n",
      "2018-05-04T14:20:58.628663: step 1973, loss 0.324758, acc 0.859375\n",
      "2018-05-04T14:20:59.811954: step 1974, loss 0.341265, acc 0.828125\n",
      "2018-05-04T14:21:00.935264: step 1975, loss 0.42512, acc 0.796875\n",
      "2018-05-04T14:21:02.058671: step 1976, loss 0.33336, acc 0.828125\n",
      "2018-05-04T14:21:03.212111: step 1977, loss 0.296865, acc 0.859375\n",
      "2018-05-04T14:21:04.312145: step 1978, loss 0.386285, acc 0.796875\n",
      "2018-05-04T14:21:05.396650: step 1979, loss 0.331784, acc 0.859375\n",
      "2018-05-04T14:21:06.526360: step 1980, loss 0.413553, acc 0.859375\n",
      "2018-05-04T14:21:07.597823: step 1981, loss 0.465863, acc 0.796875\n",
      "2018-05-04T14:21:08.719606: step 1982, loss 0.479066, acc 0.78125\n",
      "2018-05-04T14:21:09.829410: step 1983, loss 0.312612, acc 0.890625\n",
      "2018-05-04T14:21:11.049512: step 1984, loss 0.466344, acc 0.875\n",
      "2018-05-04T14:21:12.244225: step 1985, loss 0.352067, acc 0.875\n",
      "2018-05-04T14:21:13.435371: step 1986, loss 0.299554, acc 0.859375\n",
      "2018-05-04T14:21:14.541069: step 1987, loss 0.497359, acc 0.8125\n",
      "2018-05-04T14:21:15.700223: step 1988, loss 0.322308, acc 0.84375\n",
      "2018-05-04T14:21:16.771533: step 1989, loss 0.285467, acc 0.875\n",
      "2018-05-04T14:21:17.885978: step 1990, loss 0.314457, acc 0.875\n",
      "2018-05-04T14:21:18.977170: step 1991, loss 0.407145, acc 0.828125\n",
      "2018-05-04T14:21:20.072931: step 1992, loss 0.297517, acc 0.875\n",
      "2018-05-04T14:21:21.259471: step 1993, loss 0.292858, acc 0.875\n",
      "2018-05-04T14:21:22.458108: step 1994, loss 0.402381, acc 0.796875\n",
      "2018-05-04T14:21:23.583303: step 1995, loss 0.371667, acc 0.828125\n",
      "2018-05-04T14:21:24.715333: step 1996, loss 0.331196, acc 0.828125\n",
      "2018-05-04T14:21:25.870915: step 1997, loss 0.314258, acc 0.859375\n",
      "2018-05-04T14:21:26.982470: step 1998, loss 0.260051, acc 0.875\n",
      "2018-05-04T14:21:28.105344: step 1999, loss 0.280148, acc 0.890625\n",
      "2018-05-04T14:21:29.377845: step 2000, loss 0.245718, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T14:21:32.222374: step 2000, loss 0.308318, acc 0.876\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-2000\n",
      "\n",
      "2018-05-04T14:21:33.468492: step 2001, loss 0.386057, acc 0.890625\n",
      "2018-05-04T14:21:34.671623: step 2002, loss 0.34897, acc 0.84375\n",
      "2018-05-04T14:21:35.825833: step 2003, loss 0.273383, acc 0.90625\n",
      "2018-05-04T14:21:37.019389: step 2004, loss 0.266502, acc 0.890625\n",
      "2018-05-04T14:21:38.160144: step 2005, loss 0.20745, acc 0.875\n",
      "2018-05-04T14:21:39.302605: step 2006, loss 0.311172, acc 0.859375\n",
      "2018-05-04T14:21:40.467887: step 2007, loss 0.349624, acc 0.828125\n",
      "2018-05-04T14:21:41.674628: step 2008, loss 0.37792, acc 0.859375\n",
      "2018-05-04T14:21:42.798251: step 2009, loss 0.370216, acc 0.875\n",
      "2018-05-04T14:21:43.926144: step 2010, loss 0.24628, acc 0.921875\n",
      "2018-05-04T14:21:45.111943: step 2011, loss 0.368762, acc 0.859375\n",
      "2018-05-04T14:21:46.183814: step 2012, loss 0.347483, acc 0.84375\n",
      "2018-05-04T14:21:47.259144: step 2013, loss 0.278156, acc 0.859375\n",
      "2018-05-04T14:21:48.360725: step 2014, loss 0.372518, acc 0.890625\n",
      "2018-05-04T14:21:49.531324: step 2015, loss 0.293235, acc 0.8125\n",
      "2018-05-04T14:21:50.718898: step 2016, loss 0.364482, acc 0.8125\n",
      "2018-05-04T14:21:51.850637: step 2017, loss 0.317571, acc 0.90625\n",
      "2018-05-04T14:21:52.936486: step 2018, loss 0.442999, acc 0.796875\n",
      "2018-05-04T14:21:54.023494: step 2019, loss 0.482863, acc 0.765625\n",
      "2018-05-04T14:21:55.156128: step 2020, loss 0.29343, acc 0.890625\n",
      "2018-05-04T14:21:56.285924: step 2021, loss 0.207895, acc 0.90625\n",
      "2018-05-04T14:21:57.441882: step 2022, loss 0.297607, acc 0.859375\n",
      "2018-05-04T14:21:58.696609: step 2023, loss 0.390859, acc 0.8125\n",
      "2018-05-04T14:21:59.941829: step 2024, loss 0.359567, acc 0.84375\n",
      "2018-05-04T14:22:01.124011: step 2025, loss 0.324148, acc 0.890625\n",
      "2018-05-04T14:22:02.272793: step 2026, loss 0.34181, acc 0.84375\n",
      "2018-05-04T14:22:03.399913: step 2027, loss 0.430517, acc 0.734375\n",
      "2018-05-04T14:22:04.614579: step 2028, loss 0.26285, acc 0.875\n",
      "2018-05-04T14:22:05.718711: step 2029, loss 0.299409, acc 0.921875\n",
      "2018-05-04T14:22:06.876639: step 2030, loss 0.500598, acc 0.734375\n",
      "2018-05-04T14:22:08.044268: step 2031, loss 0.350027, acc 0.828125\n",
      "2018-05-04T14:22:09.170677: step 2032, loss 0.283726, acc 0.921875\n",
      "2018-05-04T14:22:10.294719: step 2033, loss 0.30038, acc 0.90625\n",
      "2018-05-04T14:22:11.503358: step 2034, loss 0.292368, acc 0.8125\n",
      "2018-05-04T14:22:12.616327: step 2035, loss 0.234445, acc 0.875\n",
      "2018-05-04T14:22:13.740723: step 2036, loss 0.315718, acc 0.859375\n",
      "2018-05-04T14:22:14.890518: step 2037, loss 0.253613, acc 0.875\n",
      "2018-05-04T14:22:16.009945: step 2038, loss 0.370248, acc 0.875\n",
      "2018-05-04T14:22:17.133231: step 2039, loss 0.273857, acc 0.875\n",
      "2018-05-04T14:22:18.252344: step 2040, loss 0.254246, acc 0.890625\n",
      "2018-05-04T14:22:19.395543: step 2041, loss 0.435965, acc 0.8125\n",
      "2018-05-04T14:22:20.543070: step 2042, loss 0.383234, acc 0.84375\n",
      "2018-05-04T14:22:21.710512: step 2043, loss 0.423252, acc 0.8125\n",
      "2018-05-04T14:22:22.842938: step 2044, loss 0.386922, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T14:22:23.982813: step 2045, loss 0.19331, acc 0.9375\n",
      "2018-05-04T14:22:25.109174: step 2046, loss 0.291218, acc 0.890625\n",
      "2018-05-04T14:22:26.227740: step 2047, loss 0.532489, acc 0.703125\n",
      "2018-05-04T14:22:27.338699: step 2048, loss 0.38472, acc 0.828125\n",
      "2018-05-04T14:22:28.420544: step 2049, loss 0.479595, acc 0.828125\n",
      "2018-05-04T14:22:29.555658: step 2050, loss 0.304748, acc 0.890625\n",
      "2018-05-04T14:22:30.633521: step 2051, loss 0.353983, acc 0.90625\n",
      "2018-05-04T14:22:31.784636: step 2052, loss 0.256888, acc 0.90625\n",
      "2018-05-04T14:22:32.938098: step 2053, loss 0.403963, acc 0.828125\n",
      "2018-05-04T14:22:34.145417: step 2054, loss 0.278657, acc 0.859375\n",
      "2018-05-04T14:22:35.405522: step 2055, loss 0.344362, acc 0.859375\n",
      "2018-05-04T14:22:36.662636: step 2056, loss 0.275632, acc 0.859375\n",
      "2018-05-04T14:22:37.833492: step 2057, loss 0.415425, acc 0.828125\n",
      "2018-05-04T14:22:38.963902: step 2058, loss 0.351495, acc 0.859375\n",
      "2018-05-04T14:22:40.082219: step 2059, loss 0.368367, acc 0.84375\n",
      "2018-05-04T14:22:41.276080: step 2060, loss 0.480409, acc 0.78125\n",
      "2018-05-04T14:22:42.401077: step 2061, loss 0.305812, acc 0.9375\n",
      "2018-05-04T14:22:43.526223: step 2062, loss 0.475039, acc 0.78125\n",
      "2018-05-04T14:22:44.641643: step 2063, loss 0.320241, acc 0.890625\n",
      "2018-05-04T14:22:45.808320: step 2064, loss 0.401105, acc 0.84375\n",
      "2018-05-04T14:22:46.920641: step 2065, loss 0.322703, acc 0.8125\n",
      "2018-05-04T14:22:48.033512: step 2066, loss 0.401657, acc 0.828125\n",
      "2018-05-04T14:22:49.168769: step 2067, loss 0.303029, acc 0.84375\n",
      "2018-05-04T14:22:50.301575: step 2068, loss 0.338414, acc 0.890625\n",
      "2018-05-04T14:22:51.487604: step 2069, loss 0.263354, acc 0.90625\n",
      "2018-05-04T14:22:52.593006: step 2070, loss 0.308358, acc 0.890625\n",
      "2018-05-04T14:22:53.714968: step 2071, loss 0.434908, acc 0.796875\n",
      "2018-05-04T14:22:54.867527: step 2072, loss 0.321673, acc 0.875\n",
      "2018-05-04T14:22:55.989209: step 2073, loss 0.372859, acc 0.84375\n",
      "2018-05-04T14:22:57.112022: step 2074, loss 0.334378, acc 0.90625\n",
      "2018-05-04T14:22:58.224920: step 2075, loss 0.335592, acc 0.84375\n",
      "2018-05-04T14:22:59.415737: step 2076, loss 0.394565, acc 0.8125\n",
      "2018-05-04T14:23:00.548747: step 2077, loss 0.401224, acc 0.8125\n",
      "2018-05-04T14:23:01.731564: step 2078, loss 0.480485, acc 0.8125\n",
      "2018-05-04T14:23:02.844107: step 2079, loss 0.391687, acc 0.890625\n",
      "2018-05-04T14:23:03.967301: step 2080, loss 0.298897, acc 0.859375\n",
      "2018-05-04T14:23:05.115382: step 2081, loss 0.4367, acc 0.828125\n",
      "2018-05-04T14:23:06.230036: step 2082, loss 0.479833, acc 0.796875\n",
      "2018-05-04T14:23:07.337344: step 2083, loss 0.491808, acc 0.796875\n",
      "2018-05-04T14:23:08.471600: step 2084, loss 0.395611, acc 0.875\n",
      "2018-05-04T14:23:09.596304: step 2085, loss 0.25293, acc 0.90625\n",
      "2018-05-04T14:23:10.717293: step 2086, loss 0.342514, acc 0.84375\n",
      "2018-05-04T14:23:11.897862: step 2087, loss 0.319704, acc 0.875\n",
      "2018-05-04T14:23:13.023930: step 2088, loss 0.386672, acc 0.828125\n",
      "2018-05-04T14:23:14.219203: step 2089, loss 0.235664, acc 0.9375\n",
      "2018-05-04T14:23:15.403744: step 2090, loss 0.299381, acc 0.875\n",
      "2018-05-04T14:23:16.479349: step 2091, loss 0.366097, acc 0.859375\n",
      "2018-05-04T14:23:17.640545: step 2092, loss 0.276937, acc 0.90625\n",
      "2018-05-04T14:23:18.794278: step 2093, loss 0.375092, acc 0.875\n",
      "2018-05-04T14:23:19.869484: step 2094, loss 0.368082, acc 0.84375\n",
      "2018-05-04T14:23:20.988969: step 2095, loss 0.349172, acc 0.84375\n",
      "2018-05-04T14:23:22.136648: step 2096, loss 0.224649, acc 0.9375\n",
      "2018-05-04T14:23:23.324615: step 2097, loss 0.353014, acc 0.828125\n",
      "2018-05-04T14:23:24.500545: step 2098, loss 0.259338, acc 0.890625\n",
      "2018-05-04T14:23:25.681557: step 2099, loss 0.321599, acc 0.890625\n",
      "2018-05-04T14:23:26.837548: step 2100, loss 0.351427, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T14:23:29.297788: step 2100, loss 0.285264, acc 0.88\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-2100\n",
      "\n",
      "2018-05-04T14:23:30.519801: step 2101, loss 0.324503, acc 0.859375\n",
      "2018-05-04T14:23:31.699724: step 2102, loss 0.397706, acc 0.84375\n",
      "2018-05-04T14:23:32.813621: step 2103, loss 0.368087, acc 0.859375\n",
      "2018-05-04T14:23:33.996072: step 2104, loss 0.346323, acc 0.859375\n",
      "2018-05-04T14:23:35.196437: step 2105, loss 0.492514, acc 0.78125\n",
      "2018-05-04T14:23:36.293001: step 2106, loss 0.268447, acc 0.890625\n",
      "2018-05-04T14:23:37.433077: step 2107, loss 0.374581, acc 0.796875\n",
      "2018-05-04T14:23:38.600654: step 2108, loss 0.31108, acc 0.875\n",
      "2018-05-04T14:23:39.727688: step 2109, loss 0.337999, acc 0.84375\n",
      "2018-05-04T14:23:40.904279: step 2110, loss 0.365475, acc 0.859375\n",
      "2018-05-04T14:23:42.069860: step 2111, loss 0.334917, acc 0.875\n",
      "2018-05-04T14:23:43.211760: step 2112, loss 0.430557, acc 0.828125\n",
      "2018-05-04T14:23:44.309073: step 2113, loss 0.319517, acc 0.859375\n",
      "2018-05-04T14:23:45.379143: step 2114, loss 0.343209, acc 0.828125\n",
      "2018-05-04T14:23:46.516300: step 2115, loss 0.303946, acc 0.875\n",
      "2018-05-04T14:23:47.658848: step 2116, loss 0.343533, acc 0.859375\n",
      "2018-05-04T14:23:48.812371: step 2117, loss 0.221689, acc 0.890625\n",
      "2018-05-04T14:23:49.968357: step 2118, loss 0.264581, acc 0.921875\n",
      "2018-05-04T14:23:51.180330: step 2119, loss 0.35114, acc 0.8125\n",
      "2018-05-04T14:23:52.340161: step 2120, loss 0.355971, acc 0.890625\n",
      "2018-05-04T14:23:53.499372: step 2121, loss 0.403404, acc 0.84375\n",
      "2018-05-04T14:23:54.641093: step 2122, loss 0.365546, acc 0.8125\n",
      "2018-05-04T14:23:55.763299: step 2123, loss 0.263976, acc 0.84375\n",
      "2018-05-04T14:23:56.891917: step 2124, loss 0.435209, acc 0.828125\n",
      "2018-05-04T14:23:57.990624: step 2125, loss 0.313948, acc 0.859375\n",
      "2018-05-04T14:23:59.085249: step 2126, loss 0.273206, acc 0.890625\n",
      "2018-05-04T14:24:00.208417: step 2127, loss 0.372784, acc 0.859375\n",
      "2018-05-04T14:24:01.403453: step 2128, loss 0.174141, acc 0.96875\n",
      "2018-05-04T14:24:02.571051: step 2129, loss 0.437861, acc 0.734375\n",
      "2018-05-04T14:24:03.725409: step 2130, loss 0.3431, acc 0.859375\n",
      "2018-05-04T14:24:04.882153: step 2131, loss 0.306461, acc 0.859375\n",
      "2018-05-04T14:24:06.028093: step 2132, loss 0.421746, acc 0.75\n",
      "2018-05-04T14:24:07.122110: step 2133, loss 0.323746, acc 0.875\n",
      "2018-05-04T14:24:08.273996: step 2134, loss 0.331048, acc 0.84375\n",
      "2018-05-04T14:24:09.418483: step 2135, loss 0.187057, acc 0.96875\n",
      "2018-05-04T14:24:10.568203: step 2136, loss 0.330262, acc 0.859375\n",
      "2018-05-04T14:24:11.773236: step 2137, loss 0.369725, acc 0.828125\n",
      "2018-05-04T14:24:12.851528: step 2138, loss 0.329263, acc 0.90625\n",
      "2018-05-04T14:24:14.016210: step 2139, loss 0.325284, acc 0.859375\n",
      "2018-05-04T14:24:15.170261: step 2140, loss 0.327583, acc 0.84375\n",
      "2018-05-04T14:24:16.304679: step 2141, loss 0.309405, acc 0.90625\n",
      "2018-05-04T14:24:17.442097: step 2142, loss 0.372288, acc 0.8125\n",
      "2018-05-04T14:24:18.574562: step 2143, loss 0.480379, acc 0.8125\n",
      "2018-05-04T14:24:19.727294: step 2144, loss 0.329814, acc 0.8125\n",
      "2018-05-04T14:24:20.916530: step 2145, loss 0.364811, acc 0.796875\n",
      "2018-05-04T14:24:22.059972: step 2146, loss 0.323533, acc 0.890625\n",
      "2018-05-04T14:24:23.193398: step 2147, loss 0.272941, acc 0.90625\n",
      "2018-05-04T14:24:24.309988: step 2148, loss 0.274686, acc 0.859375\n",
      "2018-05-04T14:24:25.454609: step 2149, loss 0.229681, acc 0.90625\n",
      "2018-05-04T14:24:26.596794: step 2150, loss 0.34223, acc 0.828125\n",
      "2018-05-04T14:24:27.716236: step 2151, loss 0.339182, acc 0.859375\n",
      "2018-05-04T14:24:28.847965: step 2152, loss 0.441395, acc 0.796875\n",
      "2018-05-04T14:24:30.020872: step 2153, loss 0.305407, acc 0.859375\n",
      "2018-05-04T14:24:31.239466: step 2154, loss 0.312197, acc 0.875\n",
      "2018-05-04T14:24:32.394232: step 2155, loss 0.289666, acc 0.90625\n",
      "2018-05-04T14:24:33.526409: step 2156, loss 0.46383, acc 0.75\n",
      "2018-05-04T14:24:34.693025: step 2157, loss 0.329321, acc 0.84375\n",
      "2018-05-04T14:24:35.851800: step 2158, loss 0.363138, acc 0.78125\n",
      "2018-05-04T14:24:36.987026: step 2159, loss 0.294981, acc 0.875\n",
      "2018-05-04T14:24:38.136923: step 2160, loss 0.388342, acc 0.8125\n",
      "2018-05-04T14:24:39.309124: step 2161, loss 0.243112, acc 0.9375\n",
      "2018-05-04T14:24:40.449447: step 2162, loss 0.30861, acc 0.859375\n",
      "2018-05-04T14:24:41.687380: step 2163, loss 0.289239, acc 0.921875\n",
      "2018-05-04T14:24:42.826708: step 2164, loss 0.371006, acc 0.796875\n",
      "2018-05-04T14:24:43.972288: step 2165, loss 0.357192, acc 0.859375\n",
      "2018-05-04T14:24:45.078665: step 2166, loss 0.287787, acc 0.828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T14:24:46.240678: step 2167, loss 0.328192, acc 0.875\n",
      "2018-05-04T14:24:47.338646: step 2168, loss 0.286234, acc 0.859375\n",
      "2018-05-04T14:24:48.456026: step 2169, loss 0.3554, acc 0.875\n",
      "2018-05-04T14:24:49.578249: step 2170, loss 0.358925, acc 0.84375\n",
      "2018-05-04T14:24:50.701743: step 2171, loss 0.367828, acc 0.8125\n",
      "2018-05-04T14:24:51.883497: step 2172, loss 0.284116, acc 0.859375\n",
      "2018-05-04T14:24:52.999336: step 2173, loss 0.231624, acc 0.953125\n",
      "2018-05-04T14:24:54.157656: step 2174, loss 0.35282, acc 0.875\n",
      "2018-05-04T14:24:55.307820: step 2175, loss 0.37022, acc 0.8125\n",
      "2018-05-04T14:24:56.459866: step 2176, loss 0.294819, acc 0.859375\n",
      "2018-05-04T14:24:57.576479: step 2177, loss 0.396549, acc 0.796875\n",
      "2018-05-04T14:24:58.780144: step 2178, loss 0.33824, acc 0.859375\n",
      "2018-05-04T14:24:59.932762: step 2179, loss 0.371723, acc 0.796875\n",
      "2018-05-04T14:25:01.118633: step 2180, loss 0.371175, acc 0.828125\n",
      "2018-05-04T14:25:02.289247: step 2181, loss 0.400175, acc 0.84375\n",
      "2018-05-04T14:25:03.441414: step 2182, loss 0.387934, acc 0.828125\n",
      "2018-05-04T14:25:04.614357: step 2183, loss 0.183382, acc 0.953125\n",
      "2018-05-04T14:25:05.767030: step 2184, loss 0.427762, acc 0.8125\n",
      "2018-05-04T14:25:06.909195: step 2185, loss 0.31871, acc 0.84375\n",
      "2018-05-04T14:25:08.047173: step 2186, loss 0.350661, acc 0.78125\n",
      "2018-05-04T14:25:09.181168: step 2187, loss 0.365394, acc 0.84375\n",
      "2018-05-04T14:25:10.347797: step 2188, loss 0.379815, acc 0.84375\n",
      "2018-05-04T14:25:11.535533: step 2189, loss 0.283403, acc 0.890625\n",
      "2018-05-04T14:25:12.665316: step 2190, loss 0.294011, acc 0.890625\n",
      "2018-05-04T14:25:13.830042: step 2191, loss 0.358678, acc 0.859375\n",
      "2018-05-04T14:25:14.994472: step 2192, loss 0.312196, acc 0.875\n",
      "2018-05-04T14:25:16.134667: step 2193, loss 0.366966, acc 0.84375\n",
      "2018-05-04T14:25:17.299498: step 2194, loss 0.303473, acc 0.875\n",
      "2018-05-04T14:25:18.408470: step 2195, loss 0.284735, acc 0.875\n",
      "2018-05-04T14:25:19.580724: step 2196, loss 0.261765, acc 0.859375\n",
      "2018-05-04T14:25:20.778593: step 2197, loss 0.270864, acc 0.90625\n",
      "2018-05-04T14:25:21.959443: step 2198, loss 0.317115, acc 0.8125\n",
      "2018-05-04T14:25:23.100792: step 2199, loss 0.423151, acc 0.828125\n",
      "2018-05-04T14:25:24.247401: step 2200, loss 0.386477, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T14:25:27.081291: step 2200, loss 0.285351, acc 0.888\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-2200\n",
      "\n",
      "2018-05-04T14:25:28.402143: step 2201, loss 0.387137, acc 0.84375\n",
      "2018-05-04T14:25:29.637281: step 2202, loss 0.260268, acc 0.921875\n",
      "2018-05-04T14:25:30.849263: step 2203, loss 0.40301, acc 0.828125\n",
      "2018-05-04T14:25:31.999501: step 2204, loss 0.350741, acc 0.796875\n",
      "2018-05-04T14:25:33.183243: step 2205, loss 0.317195, acc 0.859375\n",
      "2018-05-04T14:25:34.452776: step 2206, loss 0.383582, acc 0.859375\n",
      "2018-05-04T14:25:35.718410: step 2207, loss 0.254402, acc 0.875\n",
      "2018-05-04T14:25:36.986269: step 2208, loss 0.525885, acc 0.796875\n",
      "2018-05-04T14:25:38.169862: step 2209, loss 0.367693, acc 0.84375\n",
      "2018-05-04T14:25:39.295686: step 2210, loss 0.274166, acc 0.890625\n",
      "2018-05-04T14:25:40.424045: step 2211, loss 0.365426, acc 0.78125\n",
      "2018-05-04T14:25:41.619850: step 2212, loss 0.349528, acc 0.859375\n",
      "2018-05-04T14:25:42.841443: step 2213, loss 0.420086, acc 0.859375\n",
      "2018-05-04T14:25:44.016874: step 2214, loss 0.352266, acc 0.859375\n",
      "2018-05-04T14:25:45.210719: step 2215, loss 0.408457, acc 0.796875\n",
      "2018-05-04T14:25:46.327674: step 2216, loss 0.329725, acc 0.859375\n",
      "2018-05-04T14:25:47.472961: step 2217, loss 0.228685, acc 0.9375\n",
      "2018-05-04T14:25:48.587520: step 2218, loss 0.232062, acc 0.90625\n",
      "2018-05-04T14:25:49.779142: step 2219, loss 0.243355, acc 0.921875\n",
      "2018-05-04T14:25:50.933388: step 2220, loss 0.235666, acc 0.90625\n",
      "2018-05-04T14:25:52.156855: step 2221, loss 0.341098, acc 0.828125\n",
      "2018-05-04T14:25:53.267257: step 2222, loss 0.407975, acc 0.84375\n",
      "2018-05-04T14:25:54.368919: step 2223, loss 0.331831, acc 0.84375\n",
      "2018-05-04T14:25:55.441730: step 2224, loss 0.330432, acc 0.828125\n",
      "2018-05-04T14:25:56.553335: step 2225, loss 0.418195, acc 0.78125\n",
      "2018-05-04T14:25:57.632173: step 2226, loss 0.361902, acc 0.8125\n",
      "2018-05-04T14:25:58.769280: step 2227, loss 0.468211, acc 0.765625\n",
      "2018-05-04T14:25:59.946746: step 2228, loss 0.292534, acc 0.890625\n",
      "2018-05-04T14:26:01.154146: step 2229, loss 0.240587, acc 0.90625\n",
      "2018-05-04T14:26:02.296793: step 2230, loss 0.273321, acc 0.890625\n",
      "2018-05-04T14:26:03.417250: step 2231, loss 0.421319, acc 0.859375\n",
      "2018-05-04T14:26:04.580665: step 2232, loss 0.350833, acc 0.828125\n",
      "2018-05-04T14:26:05.771436: step 2233, loss 0.321428, acc 0.828125\n",
      "2018-05-04T14:26:06.957665: step 2234, loss 0.305816, acc 0.84375\n",
      "2018-05-04T14:26:08.079673: step 2235, loss 0.259055, acc 0.890625\n",
      "2018-05-04T14:26:09.218806: step 2236, loss 0.289266, acc 0.875\n",
      "2018-05-04T14:26:10.348987: step 2237, loss 0.216559, acc 0.9375\n",
      "2018-05-04T14:26:11.540773: step 2238, loss 0.489676, acc 0.734375\n",
      "2018-05-04T14:26:12.664306: step 2239, loss 0.288732, acc 0.875\n",
      "2018-05-04T14:26:13.779351: step 2240, loss 0.416945, acc 0.84375\n",
      "2018-05-04T14:26:14.961530: step 2241, loss 0.340434, acc 0.859375\n",
      "2018-05-04T14:26:16.136500: step 2242, loss 0.325208, acc 0.90625\n",
      "2018-05-04T14:26:17.253156: step 2243, loss 0.249236, acc 0.921875\n",
      "2018-05-04T14:26:18.386378: step 2244, loss 0.265737, acc 0.90625\n",
      "2018-05-04T14:26:19.517958: step 2245, loss 0.430601, acc 0.8125\n",
      "2018-05-04T14:26:20.620224: step 2246, loss 0.248711, acc 0.921875\n",
      "2018-05-04T14:26:21.756728: step 2247, loss 0.347417, acc 0.890625\n",
      "2018-05-04T14:26:22.852029: step 2248, loss 0.31372, acc 0.875\n",
      "2018-05-04T14:26:23.988485: step 2249, loss 0.371992, acc 0.859375\n",
      "2018-05-04T14:26:25.115422: step 2250, loss 0.290943, acc 0.875\n",
      "2018-05-04T14:26:26.225971: step 2251, loss 0.165103, acc 0.9375\n",
      "2018-05-04T14:26:27.354886: step 2252, loss 0.352404, acc 0.875\n",
      "2018-05-04T14:26:28.481969: step 2253, loss 0.322029, acc 0.859375\n",
      "2018-05-04T14:26:29.699605: step 2254, loss 0.272484, acc 0.875\n",
      "2018-05-04T14:26:30.858972: step 2255, loss 0.419298, acc 0.84375\n",
      "2018-05-04T14:26:32.015683: step 2256, loss 0.286143, acc 0.875\n",
      "2018-05-04T14:26:33.144598: step 2257, loss 0.27225, acc 0.90625\n",
      "2018-05-04T14:26:34.271315: step 2258, loss 0.362963, acc 0.796875\n",
      "2018-05-04T14:26:35.356943: step 2259, loss 0.550701, acc 0.765625\n",
      "2018-05-04T14:26:36.437280: step 2260, loss 0.404913, acc 0.796875\n",
      "2018-05-04T14:26:37.597864: step 2261, loss 0.267865, acc 0.84375\n",
      "2018-05-04T14:26:38.696582: step 2262, loss 0.372014, acc 0.78125\n",
      "2018-05-04T14:26:39.853019: step 2263, loss 0.269725, acc 0.90625\n",
      "2018-05-04T14:26:40.980374: step 2264, loss 0.346667, acc 0.875\n",
      "2018-05-04T14:26:42.269195: step 2265, loss 0.206828, acc 0.921875\n",
      "2018-05-04T14:26:43.463301: step 2266, loss 0.222966, acc 0.9375\n",
      "2018-05-04T14:26:44.754651: step 2267, loss 0.26822, acc 0.890625\n",
      "2018-05-04T14:26:45.956625: step 2268, loss 0.273321, acc 0.890625\n",
      "2018-05-04T14:26:47.147223: step 2269, loss 0.253998, acc 0.921875\n",
      "2018-05-04T14:26:48.311177: step 2270, loss 0.300778, acc 0.90625\n",
      "2018-05-04T14:26:49.496173: step 2271, loss 0.359009, acc 0.859375\n",
      "2018-05-04T14:26:50.650029: step 2272, loss 0.353502, acc 0.859375\n",
      "2018-05-04T14:26:51.869481: step 2273, loss 0.434228, acc 0.875\n",
      "2018-05-04T14:26:52.999510: step 2274, loss 0.251123, acc 0.9375\n",
      "2018-05-04T14:26:54.134258: step 2275, loss 0.312984, acc 0.875\n",
      "2018-05-04T14:26:55.276113: step 2276, loss 0.283937, acc 0.890625\n",
      "2018-05-04T14:26:56.377685: step 2277, loss 0.369222, acc 0.84375\n",
      "2018-05-04T14:26:57.477710: step 2278, loss 0.274375, acc 0.859375\n",
      "2018-05-04T14:26:58.534616: step 2279, loss 0.445318, acc 0.75\n",
      "2018-05-04T14:26:59.698058: step 2280, loss 0.192871, acc 0.953125\n",
      "2018-05-04T14:27:00.808007: step 2281, loss 0.248918, acc 0.9375\n",
      "2018-05-04T14:27:01.952570: step 2282, loss 0.342123, acc 0.828125\n",
      "2018-05-04T14:27:03.068095: step 2283, loss 0.348096, acc 0.78125\n",
      "2018-05-04T14:27:04.206000: step 2284, loss 0.338248, acc 0.84375\n",
      "2018-05-04T14:27:05.331809: step 2285, loss 0.316673, acc 0.828125\n",
      "2018-05-04T14:27:06.453775: step 2286, loss 0.332566, acc 0.84375\n",
      "2018-05-04T14:27:07.568748: step 2287, loss 0.421078, acc 0.796875\n",
      "2018-05-04T14:27:08.738488: step 2288, loss 0.313853, acc 0.859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T14:27:09.866630: step 2289, loss 0.279854, acc 0.875\n",
      "2018-05-04T14:27:11.032332: step 2290, loss 0.206921, acc 0.953125\n",
      "2018-05-04T14:27:12.164875: step 2291, loss 0.394449, acc 0.796875\n",
      "2018-05-04T14:27:13.300942: step 2292, loss 0.358772, acc 0.828125\n",
      "2018-05-04T14:27:14.468520: step 2293, loss 0.380842, acc 0.84375\n",
      "2018-05-04T14:27:15.624989: step 2294, loss 0.323741, acc 0.828125\n",
      "2018-05-04T14:27:16.776337: step 2295, loss 0.349453, acc 0.859375\n",
      "2018-05-04T14:27:17.949739: step 2296, loss 0.288147, acc 0.875\n",
      "2018-05-04T14:27:19.024685: step 2297, loss 0.399076, acc 0.828125\n",
      "2018-05-04T14:27:20.151449: step 2298, loss 0.282838, acc 0.890625\n",
      "2018-05-04T14:27:21.368662: step 2299, loss 0.324984, acc 0.84375\n",
      "2018-05-04T14:27:22.521999: step 2300, loss 0.412408, acc 0.78125\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T14:27:25.346911: step 2300, loss 0.280448, acc 0.9\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-2300\n",
      "\n",
      "2018-05-04T14:27:26.606401: step 2301, loss 0.342072, acc 0.84375\n",
      "2018-05-04T14:27:27.749930: step 2302, loss 0.293064, acc 0.875\n",
      "2018-05-04T14:27:28.956585: step 2303, loss 0.300006, acc 0.859375\n",
      "2018-05-04T14:27:30.112603: step 2304, loss 0.27241, acc 0.875\n",
      "2018-05-04T14:27:31.311827: step 2305, loss 0.393755, acc 0.828125\n",
      "2018-05-04T14:27:32.405576: step 2306, loss 0.249444, acc 0.921875\n",
      "2018-05-04T14:27:33.602465: step 2307, loss 0.28846, acc 0.890625\n",
      "2018-05-04T14:27:34.831197: step 2308, loss 0.258804, acc 0.890625\n",
      "2018-05-04T14:27:35.945249: step 2309, loss 0.37856, acc 0.84375\n",
      "2018-05-04T14:27:37.144911: step 2310, loss 0.371192, acc 0.8125\n",
      "2018-05-04T14:27:38.300608: step 2311, loss 0.331017, acc 0.859375\n",
      "2018-05-04T14:27:39.403074: step 2312, loss 0.419517, acc 0.8125\n",
      "2018-05-04T14:27:40.506693: step 2313, loss 0.272315, acc 0.9375\n",
      "2018-05-04T14:27:41.648608: step 2314, loss 0.254876, acc 0.875\n",
      "2018-05-04T14:27:42.737378: step 2315, loss 0.276731, acc 0.921875\n",
      "2018-05-04T14:27:43.818172: step 2316, loss 0.374546, acc 0.84375\n",
      "2018-05-04T14:27:44.929916: step 2317, loss 0.292507, acc 0.859375\n",
      "2018-05-04T14:27:46.161270: step 2318, loss 0.278787, acc 0.859375\n",
      "2018-05-04T14:27:47.280764: step 2319, loss 0.302075, acc 0.859375\n",
      "2018-05-04T14:27:48.408858: step 2320, loss 0.371082, acc 0.84375\n",
      "2018-05-04T14:27:49.559833: step 2321, loss 0.32777, acc 0.875\n",
      "2018-05-04T14:27:50.678906: step 2322, loss 0.4701, acc 0.8125\n",
      "2018-05-04T14:27:51.831951: step 2323, loss 0.325249, acc 0.875\n",
      "2018-05-04T14:27:52.936958: step 2324, loss 0.330153, acc 0.875\n",
      "2018-05-04T14:27:54.060439: step 2325, loss 0.261685, acc 0.921875\n",
      "2018-05-04T14:27:55.180631: step 2326, loss 0.311439, acc 0.859375\n",
      "2018-05-04T14:27:56.286985: step 2327, loss 0.229961, acc 0.890625\n",
      "2018-05-04T14:27:57.407751: step 2328, loss 0.354358, acc 0.84375\n",
      "2018-05-04T14:27:58.514519: step 2329, loss 0.293749, acc 0.890625\n",
      "2018-05-04T14:27:59.711045: step 2330, loss 0.245723, acc 0.890625\n",
      "2018-05-04T14:28:00.814490: step 2331, loss 0.229665, acc 0.9375\n",
      "2018-05-04T14:28:01.939984: step 2332, loss 0.263574, acc 0.90625\n",
      "2018-05-04T14:28:03.068959: step 2333, loss 0.235687, acc 0.921875\n",
      "2018-05-04T14:28:04.185927: step 2334, loss 0.198875, acc 0.921875\n",
      "2018-05-04T14:28:05.314680: step 2335, loss 0.267345, acc 0.890625\n",
      "2018-05-04T14:28:06.405832: step 2336, loss 0.266869, acc 0.921875\n",
      "2018-05-04T14:28:07.601617: step 2337, loss 0.379583, acc 0.84375\n",
      "2018-05-04T14:28:08.717953: step 2338, loss 0.407817, acc 0.828125\n",
      "2018-05-04T14:28:09.848793: step 2339, loss 0.474199, acc 0.78125\n",
      "2018-05-04T14:28:10.995746: step 2340, loss 0.272462, acc 0.859375\n",
      "2018-05-04T14:28:12.143996: step 2341, loss 0.24453, acc 0.859375\n",
      "2018-05-04T14:28:13.264660: step 2342, loss 0.398043, acc 0.796875\n",
      "2018-05-04T14:28:14.348915: step 2343, loss 0.357322, acc 0.859375\n",
      "2018-05-04T14:28:15.429836: step 2344, loss 0.317211, acc 0.828125\n",
      "2018-05-04T14:28:16.506581: step 2345, loss 0.294511, acc 0.84375\n",
      "2018-05-04T14:28:17.594634: step 2346, loss 0.432944, acc 0.84375\n",
      "2018-05-04T14:28:18.669084: step 2347, loss 0.282221, acc 0.890625\n",
      "2018-05-04T14:28:19.762387: step 2348, loss 0.394354, acc 0.8125\n",
      "2018-05-04T14:28:20.924099: step 2349, loss 0.26609, acc 0.875\n",
      "2018-05-04T14:28:22.125110: step 2350, loss 0.276587, acc 0.890625\n",
      "2018-05-04T14:28:23.264096: step 2351, loss 0.359905, acc 0.875\n",
      "2018-05-04T14:28:24.404004: step 2352, loss 0.367861, acc 0.796875\n",
      "2018-05-04T14:28:25.526752: step 2353, loss 0.459411, acc 0.765625\n",
      "2018-05-04T14:28:26.651000: step 2354, loss 0.226891, acc 0.875\n",
      "2018-05-04T14:28:27.762903: step 2355, loss 0.322542, acc 0.84375\n",
      "2018-05-04T14:28:28.940772: step 2356, loss 0.380601, acc 0.796875\n",
      "2018-05-04T14:28:30.015884: step 2357, loss 0.220866, acc 0.921875\n",
      "2018-05-04T14:28:31.150054: step 2358, loss 0.4347, acc 0.8125\n",
      "2018-05-04T14:28:32.235660: step 2359, loss 0.271782, acc 0.890625\n",
      "2018-05-04T14:28:33.372338: step 2360, loss 0.215076, acc 0.90625\n",
      "2018-05-04T14:28:34.550957: step 2361, loss 0.288359, acc 0.90625\n",
      "2018-05-04T14:28:35.768739: step 2362, loss 0.306089, acc 0.859375\n",
      "2018-05-04T14:28:37.027210: step 2363, loss 0.343714, acc 0.875\n",
      "2018-05-04T14:28:38.179648: step 2364, loss 0.245513, acc 0.890625\n",
      "2018-05-04T14:28:39.355146: step 2365, loss 0.271319, acc 0.859375\n",
      "2018-05-04T14:28:40.536681: step 2366, loss 0.200975, acc 0.921875\n",
      "2018-05-04T14:28:41.747817: step 2367, loss 0.337693, acc 0.90625\n",
      "2018-05-04T14:28:42.814160: step 2368, loss 0.354169, acc 0.875\n",
      "2018-05-04T14:28:43.922783: step 2369, loss 0.295292, acc 0.921875\n",
      "2018-05-04T14:28:44.985020: step 2370, loss 0.324331, acc 0.859375\n",
      "2018-05-04T14:28:46.074672: step 2371, loss 0.207098, acc 0.921875\n",
      "2018-05-04T14:28:47.144328: step 2372, loss 0.364391, acc 0.84375\n",
      "2018-05-04T14:28:48.208486: step 2373, loss 0.346576, acc 0.890625\n",
      "2018-05-04T14:28:49.300486: step 2374, loss 0.337568, acc 0.84375\n",
      "2018-05-04T14:28:50.434981: step 2375, loss 0.447215, acc 0.765625\n",
      "2018-05-04T14:28:51.593865: step 2376, loss 0.454368, acc 0.75\n",
      "2018-05-04T14:28:52.668339: step 2377, loss 0.355343, acc 0.828125\n",
      "2018-05-04T14:28:53.782174: step 2378, loss 0.308864, acc 0.90625\n",
      "2018-05-04T14:28:54.892494: step 2379, loss 0.224465, acc 0.890625\n",
      "2018-05-04T14:28:56.074488: step 2380, loss 0.274099, acc 0.859375\n",
      "2018-05-04T14:28:57.181886: step 2381, loss 0.403507, acc 0.859375\n",
      "2018-05-04T14:28:58.234785: step 2382, loss 0.237858, acc 0.890625\n",
      "2018-05-04T14:28:59.317688: step 2383, loss 0.321871, acc 0.828125\n",
      "2018-05-04T14:29:00.397537: step 2384, loss 0.4488, acc 0.8125\n",
      "2018-05-04T14:29:01.556024: step 2385, loss 0.285856, acc 0.875\n",
      "2018-05-04T14:29:02.649700: step 2386, loss 0.335753, acc 0.84375\n",
      "2018-05-04T14:29:03.854994: step 2387, loss 0.330555, acc 0.875\n",
      "2018-05-04T14:29:05.197961: step 2388, loss 0.33873, acc 0.859375\n",
      "2018-05-04T14:29:06.349639: step 2389, loss 0.393598, acc 0.875\n",
      "2018-05-04T14:29:07.415109: step 2390, loss 0.323827, acc 0.859375\n",
      "2018-05-04T14:29:08.486119: step 2391, loss 0.311179, acc 0.90625\n",
      "2018-05-04T14:29:09.556939: step 2392, loss 0.205533, acc 0.953125\n",
      "2018-05-04T14:29:10.628053: step 2393, loss 0.257142, acc 0.9375\n",
      "2018-05-04T14:29:11.818688: step 2394, loss 0.333975, acc 0.859375\n",
      "2018-05-04T14:29:12.891726: step 2395, loss 0.334481, acc 0.875\n",
      "2018-05-04T14:29:14.028614: step 2396, loss 0.454772, acc 0.765625\n",
      "2018-05-04T14:29:15.178493: step 2397, loss 0.342666, acc 0.859375\n",
      "2018-05-04T14:29:16.244519: step 2398, loss 0.343457, acc 0.875\n",
      "2018-05-04T14:29:17.318275: step 2399, loss 0.316588, acc 0.875\n",
      "2018-05-04T14:29:18.406124: step 2400, loss 0.353111, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T14:29:21.213339: step 2400, loss 0.279475, acc 0.888\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-2400\n",
      "\n",
      "2018-05-04T14:29:22.554409: step 2401, loss 0.270029, acc 0.90625\n",
      "2018-05-04T14:29:23.765970: step 2402, loss 0.34883, acc 0.84375\n",
      "2018-05-04T14:29:24.904955: step 2403, loss 0.24721, acc 0.875\n",
      "2018-05-04T14:29:25.988660: step 2404, loss 0.221707, acc 0.9375\n",
      "2018-05-04T14:29:27.073267: step 2405, loss 0.31683, acc 0.875\n",
      "2018-05-04T14:29:28.175286: step 2406, loss 0.336884, acc 0.859375\n",
      "2018-05-04T14:29:29.278549: step 2407, loss 0.302549, acc 0.859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T14:29:30.385569: step 2408, loss 0.232738, acc 0.921875\n",
      "2018-05-04T14:29:31.544399: step 2409, loss 0.365663, acc 0.828125\n",
      "2018-05-04T14:29:32.622905: step 2410, loss 0.271756, acc 0.90625\n",
      "2018-05-04T14:29:33.719822: step 2411, loss 0.318237, acc 0.84375\n",
      "2018-05-04T14:29:34.804694: step 2412, loss 0.307739, acc 0.84375\n",
      "2018-05-04T14:29:35.888327: step 2413, loss 0.42239, acc 0.828125\n",
      "2018-05-04T14:29:37.024949: step 2414, loss 0.314615, acc 0.890625\n",
      "2018-05-04T14:29:38.208679: step 2415, loss 0.352494, acc 0.890625\n",
      "2018-05-04T14:29:39.361920: step 2416, loss 0.301724, acc 0.90625\n",
      "2018-05-04T14:29:40.458950: step 2417, loss 0.345478, acc 0.84375\n",
      "2018-05-04T14:29:41.628295: step 2418, loss 0.505479, acc 0.765625\n",
      "2018-05-04T14:29:42.707908: step 2419, loss 0.356767, acc 0.859375\n",
      "2018-05-04T14:29:43.804952: step 2420, loss 0.341206, acc 0.859375\n",
      "2018-05-04T14:29:44.894385: step 2421, loss 0.310392, acc 0.859375\n",
      "2018-05-04T14:29:45.972104: step 2422, loss 0.365885, acc 0.78125\n",
      "2018-05-04T14:29:47.060920: step 2423, loss 0.315276, acc 0.84375\n",
      "2018-05-04T14:29:48.143039: step 2424, loss 0.288974, acc 0.875\n",
      "2018-05-04T14:29:49.316474: step 2425, loss 0.20941, acc 0.90625\n",
      "2018-05-04T14:29:50.388454: step 2426, loss 0.273064, acc 0.890625\n",
      "2018-05-04T14:29:51.529699: step 2427, loss 0.357624, acc 0.875\n",
      "2018-05-04T14:29:52.607974: step 2428, loss 0.382369, acc 0.828125\n",
      "2018-05-04T14:29:53.673717: step 2429, loss 0.381468, acc 0.796875\n",
      "2018-05-04T14:29:54.771372: step 2430, loss 0.474051, acc 0.796875\n",
      "2018-05-04T14:29:55.875035: step 2431, loss 0.253264, acc 0.859375\n",
      "2018-05-04T14:29:56.981668: step 2432, loss 0.331292, acc 0.859375\n",
      "2018-05-04T14:29:58.061122: step 2433, loss 0.407151, acc 0.859375\n",
      "2018-05-04T14:29:59.150187: step 2434, loss 0.243202, acc 0.90625\n",
      "2018-05-04T14:30:00.245702: step 2435, loss 0.314683, acc 0.90625\n",
      "2018-05-04T14:30:01.389894: step 2436, loss 0.30254, acc 0.890625\n",
      "2018-05-04T14:30:02.465049: step 2437, loss 0.279971, acc 0.859375\n",
      "2018-05-04T14:30:03.553937: step 2438, loss 0.418845, acc 0.796875\n",
      "2018-05-04T14:30:04.633520: step 2439, loss 0.520141, acc 0.75\n",
      "2018-05-04T14:30:05.712857: step 2440, loss 0.327997, acc 0.8125\n",
      "2018-05-04T14:30:06.780077: step 2441, loss 0.204298, acc 0.9375\n",
      "2018-05-04T14:30:07.858695: step 2442, loss 0.481925, acc 0.796875\n",
      "2018-05-04T14:30:08.935295: step 2443, loss 0.28656, acc 0.859375\n",
      "2018-05-04T14:30:10.102781: step 2444, loss 0.469176, acc 0.78125\n",
      "2018-05-04T14:30:11.244780: step 2445, loss 0.327398, acc 0.84375\n",
      "2018-05-04T14:30:12.327791: step 2446, loss 0.416962, acc 0.828125\n",
      "2018-05-04T14:30:13.422726: step 2447, loss 0.348809, acc 0.8125\n",
      "2018-05-04T14:30:14.567814: step 2448, loss 0.282801, acc 0.875\n",
      "2018-05-04T14:30:15.690000: step 2449, loss 0.287398, acc 0.859375\n",
      "2018-05-04T14:30:16.796529: step 2450, loss 0.281649, acc 0.875\n",
      "2018-05-04T14:30:17.920447: step 2451, loss 0.412861, acc 0.828125\n",
      "2018-05-04T14:30:18.998817: step 2452, loss 0.331533, acc 0.921875\n",
      "2018-05-04T14:30:20.102871: step 2453, loss 0.215378, acc 0.90625\n",
      "2018-05-04T14:30:21.281991: step 2454, loss 0.184509, acc 0.9375\n",
      "2018-05-04T14:30:22.370689: step 2455, loss 0.379303, acc 0.828125\n",
      "2018-05-04T14:30:23.457827: step 2456, loss 0.441304, acc 0.796875\n",
      "2018-05-04T14:30:24.580265: step 2457, loss 0.345242, acc 0.90625\n",
      "2018-05-04T14:30:25.653351: step 2458, loss 0.476893, acc 0.8125\n",
      "2018-05-04T14:30:26.718372: step 2459, loss 0.305408, acc 0.890625\n",
      "2018-05-04T14:30:27.790802: step 2460, loss 0.333633, acc 0.78125\n",
      "2018-05-04T14:30:28.889530: step 2461, loss 0.245811, acc 0.90625\n",
      "2018-05-04T14:30:29.990817: step 2462, loss 0.351054, acc 0.859375\n",
      "2018-05-04T14:30:31.119171: step 2463, loss 0.25991, acc 0.890625\n",
      "2018-05-04T14:30:32.289872: step 2464, loss 0.324612, acc 0.859375\n",
      "2018-05-04T14:30:33.380488: step 2465, loss 0.338927, acc 0.84375\n",
      "2018-05-04T14:30:34.522937: step 2466, loss 0.262917, acc 0.890625\n",
      "2018-05-04T14:30:35.612753: step 2467, loss 0.331472, acc 0.859375\n",
      "2018-05-04T14:30:36.689222: step 2468, loss 0.232722, acc 0.921875\n",
      "2018-05-04T14:30:37.769378: step 2469, loss 0.374426, acc 0.828125\n",
      "2018-05-04T14:30:38.839750: step 2470, loss 0.248155, acc 0.90625\n",
      "2018-05-04T14:30:40.028592: step 2471, loss 0.430913, acc 0.828125\n",
      "2018-05-04T14:30:41.160599: step 2472, loss 0.351563, acc 0.84375\n",
      "2018-05-04T14:30:42.351326: step 2473, loss 0.398799, acc 0.828125\n",
      "2018-05-04T14:30:43.450403: step 2474, loss 0.351687, acc 0.875\n",
      "2018-05-04T14:30:44.646685: step 2475, loss 0.390497, acc 0.828125\n",
      "2018-05-04T14:30:45.747540: step 2476, loss 0.297767, acc 0.890625\n",
      "2018-05-04T14:30:46.898654: step 2477, loss 0.444645, acc 0.8125\n",
      "2018-05-04T14:30:48.018206: step 2478, loss 0.301947, acc 0.859375\n",
      "2018-05-04T14:30:49.166799: step 2479, loss 0.392532, acc 0.828125\n",
      "2018-05-04T14:30:50.327031: step 2480, loss 0.217589, acc 0.890625\n",
      "2018-05-04T14:30:51.485349: step 2481, loss 0.262048, acc 0.875\n",
      "2018-05-04T14:30:52.548576: step 2482, loss 0.295104, acc 0.921875\n",
      "2018-05-04T14:30:53.644179: step 2483, loss 0.226645, acc 0.90625\n",
      "2018-05-04T14:30:54.805863: step 2484, loss 0.217905, acc 0.921875\n",
      "2018-05-04T14:30:55.899132: step 2485, loss 0.324393, acc 0.84375\n",
      "2018-05-04T14:30:56.968219: step 2486, loss 0.140618, acc 0.96875\n",
      "2018-05-04T14:30:58.071846: step 2487, loss 0.416139, acc 0.796875\n",
      "2018-05-04T14:30:59.163245: step 2488, loss 0.382988, acc 0.8125\n",
      "2018-05-04T14:31:00.239941: step 2489, loss 0.412085, acc 0.84375\n",
      "2018-05-04T14:31:01.465461: step 2490, loss 0.272083, acc 0.890625\n",
      "2018-05-04T14:31:02.646847: step 2491, loss 0.319715, acc 0.90625\n",
      "2018-05-04T14:31:03.771403: step 2492, loss 0.375866, acc 0.84375\n",
      "2018-05-04T14:31:04.950427: step 2493, loss 0.460843, acc 0.765625\n",
      "2018-05-04T14:31:06.150843: step 2494, loss 0.202894, acc 0.921875\n",
      "2018-05-04T14:31:07.280125: step 2495, loss 0.302804, acc 0.84375\n",
      "2018-05-04T14:31:08.380012: step 2496, loss 0.326166, acc 0.875\n",
      "2018-05-04T14:31:09.562480: step 2497, loss 0.187389, acc 0.9375\n",
      "2018-05-04T14:31:10.623886: step 2498, loss 0.327823, acc 0.859375\n",
      "2018-05-04T14:31:11.745450: step 2499, loss 0.425077, acc 0.828125\n",
      "2018-05-04T14:31:12.904472: step 2500, loss 0.277611, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T14:31:15.688222: step 2500, loss 0.274373, acc 0.894\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-2500\n",
      "\n",
      "2018-05-04T14:31:16.962319: step 2501, loss 0.24548, acc 0.921875\n",
      "2018-05-04T14:31:18.148724: step 2502, loss 0.340384, acc 0.84375\n",
      "2018-05-04T14:31:19.304441: step 2503, loss 0.383215, acc 0.84375\n",
      "2018-05-04T14:31:20.444427: step 2504, loss 0.232876, acc 0.90625\n",
      "2018-05-04T14:31:21.661617: step 2505, loss 0.341402, acc 0.828125\n",
      "2018-05-04T14:31:22.801216: step 2506, loss 0.42689, acc 0.796875\n",
      "2018-05-04T14:31:23.952784: step 2507, loss 0.500141, acc 0.875\n",
      "2018-05-04T14:31:25.071932: step 2508, loss 0.344463, acc 0.875\n",
      "2018-05-04T14:31:26.196125: step 2509, loss 0.324477, acc 0.828125\n",
      "2018-05-04T14:31:27.318663: step 2510, loss 0.267186, acc 0.890625\n",
      "2018-05-04T14:31:28.446636: step 2511, loss 0.52092, acc 0.78125\n",
      "2018-05-04T14:31:29.593430: step 2512, loss 0.402621, acc 0.828125\n",
      "2018-05-04T14:31:30.733806: step 2513, loss 0.311346, acc 0.84375\n",
      "2018-05-04T14:31:31.893842: step 2514, loss 0.308335, acc 0.859375\n",
      "2018-05-04T14:31:33.060032: step 2515, loss 0.225201, acc 0.875\n",
      "2018-05-04T14:31:34.260215: step 2516, loss 0.279873, acc 0.875\n",
      "2018-05-04T14:31:35.493095: step 2517, loss 0.232859, acc 0.90625\n",
      "2018-05-04T14:31:36.686135: step 2518, loss 0.303057, acc 0.828125\n",
      "2018-05-04T14:31:37.924582: step 2519, loss 0.339086, acc 0.84375\n",
      "2018-05-04T14:31:39.099310: step 2520, loss 0.336224, acc 0.8125\n",
      "2018-05-04T14:31:40.351743: step 2521, loss 0.358771, acc 0.84375\n",
      "2018-05-04T14:31:41.606524: step 2522, loss 0.320597, acc 0.859375\n",
      "2018-05-04T14:31:42.807895: step 2523, loss 0.343537, acc 0.890625\n",
      "2018-05-04T14:31:43.941010: step 2524, loss 0.346367, acc 0.875\n",
      "2018-05-04T14:31:45.065248: step 2525, loss 0.270409, acc 0.890625\n",
      "2018-05-04T14:31:46.194333: step 2526, loss 0.588189, acc 0.8125\n",
      "2018-05-04T14:31:47.324171: step 2527, loss 0.407032, acc 0.765625\n",
      "2018-05-04T14:31:48.451918: step 2528, loss 0.251777, acc 0.890625\n",
      "2018-05-04T14:31:49.608741: step 2529, loss 0.548931, acc 0.765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T14:31:50.697331: step 2530, loss 0.359865, acc 0.84375\n",
      "2018-05-04T14:31:51.824027: step 2531, loss 0.303934, acc 0.90625\n",
      "2018-05-04T14:31:52.909698: step 2532, loss 0.265035, acc 0.890625\n",
      "2018-05-04T14:31:54.017840: step 2533, loss 0.325647, acc 0.875\n",
      "2018-05-04T14:31:55.153872: step 2534, loss 0.337204, acc 0.8125\n",
      "2018-05-04T14:31:56.281558: step 2535, loss 0.2501, acc 0.921875\n",
      "2018-05-04T14:31:57.416241: step 2536, loss 0.457424, acc 0.84375\n",
      "2018-05-04T14:31:58.529991: step 2537, loss 0.31762, acc 0.875\n",
      "2018-05-04T14:31:59.656240: step 2538, loss 0.372458, acc 0.859375\n",
      "2018-05-04T14:32:00.787439: step 2539, loss 0.320442, acc 0.90625\n",
      "2018-05-04T14:32:01.953721: step 2540, loss 0.301366, acc 0.84375\n",
      "2018-05-04T14:32:03.087879: step 2541, loss 0.328533, acc 0.875\n",
      "2018-05-04T14:32:04.220381: step 2542, loss 0.338292, acc 0.8125\n",
      "2018-05-04T14:32:05.350360: step 2543, loss 0.274359, acc 0.890625\n",
      "2018-05-04T14:32:06.447148: step 2544, loss 0.419906, acc 0.828125\n",
      "2018-05-04T14:32:07.565826: step 2545, loss 0.277139, acc 0.921875\n",
      "2018-05-04T14:32:08.745357: step 2546, loss 0.444661, acc 0.765625\n",
      "2018-05-04T14:32:09.959171: step 2547, loss 0.259368, acc 0.890625\n",
      "2018-05-04T14:32:11.137250: step 2548, loss 0.275455, acc 0.90625\n",
      "2018-05-04T14:32:12.261973: step 2549, loss 0.402893, acc 0.859375\n",
      "2018-05-04T14:32:13.380873: step 2550, loss 0.289519, acc 0.890625\n",
      "2018-05-04T14:32:14.520361: step 2551, loss 0.358579, acc 0.796875\n",
      "2018-05-04T14:32:15.641231: step 2552, loss 0.33323, acc 0.828125\n",
      "2018-05-04T14:32:16.750613: step 2553, loss 0.503304, acc 0.734375\n",
      "2018-05-04T14:32:17.863216: step 2554, loss 0.265775, acc 0.9375\n",
      "2018-05-04T14:32:18.997549: step 2555, loss 0.291169, acc 0.84375\n",
      "2018-05-04T14:32:20.119970: step 2556, loss 0.341827, acc 0.828125\n",
      "2018-05-04T14:32:21.329689: step 2557, loss 0.283305, acc 0.828125\n",
      "2018-05-04T14:32:22.482675: step 2558, loss 0.260705, acc 0.90625\n",
      "2018-05-04T14:32:23.668278: step 2559, loss 0.360414, acc 0.8125\n",
      "2018-05-04T14:32:24.858588: step 2560, loss 0.31775, acc 0.84375\n",
      "2018-05-04T14:32:25.969710: step 2561, loss 0.295893, acc 0.84375\n",
      "2018-05-04T14:32:27.111398: step 2562, loss 0.372655, acc 0.8125\n",
      "2018-05-04T14:32:28.236957: step 2563, loss 0.255037, acc 0.890625\n",
      "2018-05-04T14:32:29.375369: step 2564, loss 0.37092, acc 0.859375\n",
      "2018-05-04T14:32:30.519716: step 2565, loss 0.240968, acc 0.890625\n",
      "2018-05-04T14:32:31.772851: step 2566, loss 0.234216, acc 0.890625\n",
      "2018-05-04T14:32:32.888435: step 2567, loss 0.364079, acc 0.828125\n",
      "2018-05-04T14:32:34.104691: step 2568, loss 0.361828, acc 0.859375\n",
      "2018-05-04T14:32:35.290245: step 2569, loss 0.287684, acc 0.875\n",
      "2018-05-04T14:32:36.411467: step 2570, loss 0.463102, acc 0.765625\n",
      "2018-05-04T14:32:37.534695: step 2571, loss 0.466626, acc 0.84375\n",
      "2018-05-04T14:32:38.669286: step 2572, loss 0.319222, acc 0.84375\n",
      "2018-05-04T14:32:39.820607: step 2573, loss 0.262592, acc 0.9375\n",
      "2018-05-04T14:32:40.971791: step 2574, loss 0.42764, acc 0.859375\n",
      "2018-05-04T14:32:42.135060: step 2575, loss 0.410761, acc 0.78125\n",
      "2018-05-04T14:32:43.257092: step 2576, loss 0.305244, acc 0.921875\n",
      "2018-05-04T14:32:44.386867: step 2577, loss 0.314134, acc 0.875\n",
      "2018-05-04T14:32:45.510388: step 2578, loss 0.317177, acc 0.859375\n",
      "2018-05-04T14:32:46.640226: step 2579, loss 0.359652, acc 0.859375\n",
      "2018-05-04T14:32:47.745840: step 2580, loss 0.182342, acc 0.9375\n",
      "2018-05-04T14:32:48.881336: step 2581, loss 0.280358, acc 0.890625\n",
      "2018-05-04T14:32:50.001196: step 2582, loss 0.328122, acc 0.84375\n",
      "2018-05-04T14:32:51.168419: step 2583, loss 0.340702, acc 0.84375\n",
      "2018-05-04T14:32:52.307734: step 2584, loss 0.388696, acc 0.859375\n",
      "2018-05-04T14:32:53.433927: step 2585, loss 0.356412, acc 0.859375\n",
      "2018-05-04T14:32:54.562801: step 2586, loss 0.307247, acc 0.859375\n",
      "2018-05-04T14:32:55.699801: step 2587, loss 0.333357, acc 0.875\n",
      "2018-05-04T14:32:56.871388: step 2588, loss 0.271052, acc 0.921875\n",
      "2018-05-04T14:32:58.002990: step 2589, loss 0.336826, acc 0.890625\n",
      "2018-05-04T14:32:59.132424: step 2590, loss 0.401789, acc 0.84375\n",
      "2018-05-04T14:33:00.347735: step 2591, loss 0.254197, acc 0.875\n",
      "2018-05-04T14:33:01.549840: step 2592, loss 0.21675, acc 0.921875\n",
      "2018-05-04T14:33:02.639537: step 2593, loss 0.339303, acc 0.859375\n",
      "2018-05-04T14:33:03.768041: step 2594, loss 0.198881, acc 0.90625\n",
      "2018-05-04T14:33:04.906809: step 2595, loss 0.304849, acc 0.875\n",
      "2018-05-04T14:33:06.045219: step 2596, loss 0.276525, acc 0.890625\n",
      "2018-05-04T14:33:07.163859: step 2597, loss 0.389443, acc 0.828125\n",
      "2018-05-04T14:33:08.289941: step 2598, loss 0.303239, acc 0.90625\n",
      "2018-05-04T14:33:09.489623: step 2599, loss 0.339024, acc 0.828125\n",
      "2018-05-04T14:33:10.657750: step 2600, loss 0.343218, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T14:33:13.146142: step 2600, loss 0.305788, acc 0.868\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-2600\n",
      "\n",
      "2018-05-04T14:33:14.402467: step 2601, loss 0.205558, acc 0.921875\n",
      "2018-05-04T14:33:15.599372: step 2602, loss 0.280958, acc 0.875\n",
      "2018-05-04T14:33:16.704119: step 2603, loss 0.41183, acc 0.796875\n",
      "2018-05-04T14:33:17.907600: step 2604, loss 0.352145, acc 0.859375\n",
      "2018-05-04T14:33:19.006244: step 2605, loss 0.29865, acc 0.84375\n",
      "2018-05-04T14:33:20.176140: step 2606, loss 0.283224, acc 0.859375\n",
      "2018-05-04T14:33:21.409927: step 2607, loss 0.290043, acc 0.921875\n",
      "2018-05-04T14:33:22.555460: step 2608, loss 0.309154, acc 0.828125\n",
      "2018-05-04T14:33:23.641251: step 2609, loss 0.399857, acc 0.828125\n",
      "2018-05-04T14:33:24.759240: step 2610, loss 0.32737, acc 0.84375\n",
      "2018-05-04T14:33:25.942883: step 2611, loss 0.218012, acc 0.890625\n",
      "2018-05-04T14:33:27.122867: step 2612, loss 0.376551, acc 0.875\n",
      "2018-05-04T14:33:28.234277: step 2613, loss 0.205344, acc 0.921875\n",
      "2018-05-04T14:33:29.356373: step 2614, loss 0.262152, acc 0.890625\n",
      "2018-05-04T14:33:30.474614: step 2615, loss 0.316116, acc 0.890625\n",
      "2018-05-04T14:33:31.675808: step 2616, loss 0.25191, acc 0.90625\n",
      "2018-05-04T14:33:32.865051: step 2617, loss 0.361041, acc 0.859375\n",
      "2018-05-04T14:33:34.025510: step 2618, loss 0.374904, acc 0.84375\n",
      "2018-05-04T14:33:35.181617: step 2619, loss 0.348784, acc 0.828125\n",
      "2018-05-04T14:33:36.272869: step 2620, loss 0.359553, acc 0.828125\n",
      "2018-05-04T14:33:37.363383: step 2621, loss 0.378155, acc 0.859375\n",
      "2018-05-04T14:33:38.470342: step 2622, loss 0.324453, acc 0.828125\n",
      "2018-05-04T14:33:39.617640: step 2623, loss 0.333056, acc 0.890625\n",
      "2018-05-04T14:33:40.724036: step 2624, loss 0.339526, acc 0.859375\n",
      "2018-05-04T14:33:41.890605: step 2625, loss 0.352573, acc 0.859375\n",
      "2018-05-04T14:33:43.062818: step 2626, loss 0.407122, acc 0.796875\n",
      "2018-05-04T14:33:44.185203: step 2627, loss 0.422849, acc 0.78125\n",
      "2018-05-04T14:33:45.313384: step 2628, loss 0.42325, acc 0.859375\n",
      "2018-05-04T14:33:46.441725: step 2629, loss 0.308688, acc 0.828125\n",
      "2018-05-04T14:33:47.598193: step 2630, loss 0.28019, acc 0.875\n",
      "2018-05-04T14:33:48.787357: step 2631, loss 0.330079, acc 0.859375\n",
      "2018-05-04T14:33:49.956140: step 2632, loss 0.336859, acc 0.859375\n",
      "2018-05-04T14:33:51.121716: step 2633, loss 0.390376, acc 0.828125\n",
      "2018-05-04T14:33:52.249090: step 2634, loss 0.226425, acc 0.953125\n",
      "2018-05-04T14:33:53.406953: step 2635, loss 0.365654, acc 0.796875\n",
      "2018-05-04T14:33:54.572000: step 2636, loss 0.336157, acc 0.8125\n",
      "2018-05-04T14:33:55.732157: step 2637, loss 0.333468, acc 0.890625\n",
      "2018-05-04T14:33:56.884020: step 2638, loss 0.330571, acc 0.828125\n",
      "2018-05-04T14:33:58.035800: step 2639, loss 0.215182, acc 0.921875\n",
      "2018-05-04T14:33:59.187959: step 2640, loss 0.180594, acc 0.9375\n",
      "2018-05-04T14:34:00.336617: step 2641, loss 0.372446, acc 0.8125\n",
      "2018-05-04T14:34:01.584340: step 2642, loss 0.18877, acc 0.9375\n",
      "2018-05-04T14:34:02.724870: step 2643, loss 0.407086, acc 0.8125\n",
      "2018-05-04T14:34:03.889475: step 2644, loss 0.355293, acc 0.84375\n",
      "2018-05-04T14:34:05.045266: step 2645, loss 0.282316, acc 0.875\n",
      "2018-05-04T14:34:06.202763: step 2646, loss 0.224973, acc 0.890625\n",
      "2018-05-04T14:34:07.316157: step 2647, loss 0.367592, acc 0.859375\n",
      "2018-05-04T14:34:08.464662: step 2648, loss 0.339681, acc 0.875\n",
      "2018-05-04T14:34:09.618877: step 2649, loss 0.370264, acc 0.859375\n",
      "2018-05-04T14:34:10.761760: step 2650, loss 0.37377, acc 0.828125\n",
      "2018-05-04T14:34:11.967116: step 2651, loss 0.38314, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T14:34:13.100348: step 2652, loss 0.458291, acc 0.75\n",
      "2018-05-04T14:34:14.234817: step 2653, loss 0.292367, acc 0.859375\n",
      "2018-05-04T14:34:15.361918: step 2654, loss 0.251835, acc 0.875\n",
      "2018-05-04T14:34:16.427109: step 2655, loss 0.396861, acc 0.828125\n",
      "2018-05-04T14:34:17.568031: step 2656, loss 0.358345, acc 0.859375\n",
      "2018-05-04T14:34:18.721664: step 2657, loss 0.216547, acc 0.921875\n",
      "2018-05-04T14:34:19.884035: step 2658, loss 0.273481, acc 0.890625\n",
      "2018-05-04T14:34:21.098714: step 2659, loss 0.226092, acc 0.921875\n",
      "2018-05-04T14:34:22.235241: step 2660, loss 0.374027, acc 0.90625\n",
      "2018-05-04T14:34:23.384265: step 2661, loss 0.315561, acc 0.84375\n",
      "2018-05-04T14:34:24.552692: step 2662, loss 0.245334, acc 0.859375\n",
      "2018-05-04T14:34:25.689529: step 2663, loss 0.304055, acc 0.890625\n",
      "2018-05-04T14:34:26.830583: step 2664, loss 0.180337, acc 0.921875\n",
      "2018-05-04T14:34:27.989473: step 2665, loss 0.200529, acc 0.921875\n",
      "2018-05-04T14:34:29.118116: step 2666, loss 0.277834, acc 0.859375\n",
      "2018-05-04T14:34:30.246218: step 2667, loss 0.386413, acc 0.796875\n",
      "2018-05-04T14:34:31.457030: step 2668, loss 0.388281, acc 0.8125\n",
      "2018-05-04T14:34:32.609813: step 2669, loss 0.18269, acc 0.9375\n",
      "2018-05-04T14:34:33.817882: step 2670, loss 0.408868, acc 0.859375\n",
      "2018-05-04T14:34:35.055093: step 2671, loss 0.259057, acc 0.90625\n",
      "2018-05-04T14:34:36.313411: step 2672, loss 0.344529, acc 0.84375\n",
      "2018-05-04T14:34:37.530444: step 2673, loss 0.3486, acc 0.875\n",
      "2018-05-04T14:34:38.692413: step 2674, loss 0.356445, acc 0.8125\n",
      "2018-05-04T14:34:39.910828: step 2675, loss 0.414439, acc 0.796875\n",
      "2018-05-04T14:34:41.106857: step 2676, loss 0.197208, acc 0.921875\n",
      "2018-05-04T14:34:42.286655: step 2677, loss 0.287979, acc 0.890625\n",
      "2018-05-04T14:34:43.443011: step 2678, loss 0.275737, acc 0.90625\n",
      "2018-05-04T14:34:44.596230: step 2679, loss 0.361267, acc 0.875\n",
      "2018-05-04T14:34:45.730265: step 2680, loss 0.204663, acc 0.890625\n",
      "2018-05-04T14:34:46.870842: step 2681, loss 0.250248, acc 0.890625\n",
      "2018-05-04T14:34:48.014746: step 2682, loss 0.231719, acc 0.90625\n",
      "2018-05-04T14:34:49.164875: step 2683, loss 0.302105, acc 0.84375\n",
      "2018-05-04T14:34:50.303026: step 2684, loss 0.262511, acc 0.875\n",
      "2018-05-04T14:34:51.488881: step 2685, loss 0.407449, acc 0.859375\n",
      "2018-05-04T14:34:52.648670: step 2686, loss 0.219745, acc 0.90625\n",
      "2018-05-04T14:34:53.802718: step 2687, loss 0.309072, acc 0.875\n",
      "2018-05-04T14:34:54.944752: step 2688, loss 0.391624, acc 0.875\n",
      "2018-05-04T14:34:56.087623: step 2689, loss 0.215595, acc 0.890625\n",
      "2018-05-04T14:34:57.216545: step 2690, loss 0.332346, acc 0.859375\n",
      "2018-05-04T14:34:58.341101: step 2691, loss 0.41129, acc 0.8125\n",
      "2018-05-04T14:34:59.472775: step 2692, loss 0.469031, acc 0.765625\n",
      "2018-05-04T14:35:00.595419: step 2693, loss 0.291874, acc 0.890625\n",
      "2018-05-04T14:35:01.767098: step 2694, loss 0.255881, acc 0.890625\n",
      "2018-05-04T14:35:02.903819: step 2695, loss 0.212569, acc 0.921875\n",
      "2018-05-04T14:35:04.077004: step 2696, loss 0.286739, acc 0.859375\n",
      "2018-05-04T14:35:05.278128: step 2697, loss 0.302946, acc 0.890625\n",
      "2018-05-04T14:35:06.418331: step 2698, loss 0.251567, acc 0.90625\n",
      "2018-05-04T14:35:07.574942: step 2699, loss 0.291255, acc 0.859375\n",
      "2018-05-04T14:35:08.714948: step 2700, loss 0.290488, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T14:35:11.579120: step 2700, loss 0.266969, acc 0.898\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-2700\n",
      "\n",
      "2018-05-04T14:35:12.835607: step 2701, loss 0.266536, acc 0.90625\n",
      "2018-05-04T14:35:14.028243: step 2702, loss 0.406644, acc 0.828125\n",
      "2018-05-04T14:35:15.200657: step 2703, loss 0.347106, acc 0.84375\n",
      "2018-05-04T14:35:16.336549: step 2704, loss 0.338111, acc 0.828125\n",
      "2018-05-04T14:35:17.560582: step 2705, loss 0.355484, acc 0.8125\n",
      "2018-05-04T14:35:18.692958: step 2706, loss 0.366845, acc 0.828125\n",
      "2018-05-04T14:35:19.864057: step 2707, loss 0.34083, acc 0.828125\n",
      "2018-05-04T14:35:21.043500: step 2708, loss 0.465501, acc 0.765625\n",
      "2018-05-04T14:35:22.205998: step 2709, loss 0.405553, acc 0.84375\n",
      "2018-05-04T14:35:23.343018: step 2710, loss 0.431821, acc 0.796875\n",
      "2018-05-04T14:35:24.490922: step 2711, loss 0.33192, acc 0.875\n",
      "2018-05-04T14:35:25.589875: step 2712, loss 0.31771, acc 0.84375\n",
      "2018-05-04T14:35:26.714146: step 2713, loss 0.302183, acc 0.921875\n",
      "2018-05-04T14:35:27.917642: step 2714, loss 0.311924, acc 0.890625\n",
      "2018-05-04T14:35:29.045924: step 2715, loss 0.300167, acc 0.859375\n",
      "2018-05-04T14:35:30.204164: step 2716, loss 0.503919, acc 0.796875\n",
      "2018-05-04T14:35:31.379081: step 2717, loss 0.448017, acc 0.8125\n",
      "2018-05-04T14:35:32.476464: step 2718, loss 0.402632, acc 0.796875\n",
      "2018-05-04T14:35:33.622096: step 2719, loss 0.272883, acc 0.890625\n",
      "2018-05-04T14:35:34.857370: step 2720, loss 0.350281, acc 0.90625\n",
      "2018-05-04T14:35:35.986614: step 2721, loss 0.318357, acc 0.828125\n",
      "2018-05-04T14:35:37.075711: step 2722, loss 0.261171, acc 0.90625\n",
      "2018-05-04T14:35:38.166647: step 2723, loss 0.454921, acc 0.8125\n",
      "2018-05-04T14:35:39.261701: step 2724, loss 0.37214, acc 0.84375\n",
      "2018-05-04T14:35:40.455716: step 2725, loss 0.379056, acc 0.8125\n",
      "2018-05-04T14:35:41.661957: step 2726, loss 0.28537, acc 0.890625\n",
      "2018-05-04T14:35:42.771343: step 2727, loss 0.402872, acc 0.796875\n",
      "2018-05-04T14:35:43.891982: step 2728, loss 0.339695, acc 0.859375\n",
      "2018-05-04T14:35:45.020172: step 2729, loss 0.342012, acc 0.8125\n",
      "2018-05-04T14:35:46.149532: step 2730, loss 0.292404, acc 0.859375\n",
      "2018-05-04T14:35:47.259608: step 2731, loss 0.42893, acc 0.84375\n",
      "2018-05-04T14:35:48.407629: step 2732, loss 0.245924, acc 0.90625\n",
      "2018-05-04T14:35:49.520718: step 2733, loss 0.263237, acc 0.875\n",
      "2018-05-04T14:35:50.655374: step 2734, loss 0.393551, acc 0.890625\n",
      "2018-05-04T14:35:51.834419: step 2735, loss 0.34507, acc 0.859375\n",
      "2018-05-04T14:35:52.947425: step 2736, loss 0.471039, acc 0.8125\n",
      "2018-05-04T14:35:54.039295: step 2737, loss 0.225227, acc 0.921875\n",
      "2018-05-04T14:35:55.140931: step 2738, loss 0.35706, acc 0.875\n",
      "2018-05-04T14:35:56.206213: step 2739, loss 0.297421, acc 0.90625\n",
      "2018-05-04T14:35:57.286454: step 2740, loss 0.410666, acc 0.796875\n",
      "2018-05-04T14:35:58.377487: step 2741, loss 0.278724, acc 0.875\n",
      "2018-05-04T14:35:59.577600: step 2742, loss 0.145174, acc 0.953125\n",
      "2018-05-04T14:36:00.701720: step 2743, loss 0.299259, acc 0.84375\n",
      "2018-05-04T14:36:01.884887: step 2744, loss 0.334524, acc 0.859375\n",
      "2018-05-04T14:36:02.973881: step 2745, loss 0.266396, acc 0.875\n",
      "2018-05-04T14:36:04.106704: step 2746, loss 0.380229, acc 0.8125\n",
      "2018-05-04T14:36:05.289934: step 2747, loss 0.233843, acc 0.90625\n",
      "2018-05-04T14:36:06.402645: step 2748, loss 0.313021, acc 0.890625\n",
      "2018-05-04T14:36:07.533542: step 2749, loss 0.32631, acc 0.84375\n",
      "2018-05-04T14:36:08.662006: step 2750, loss 0.323458, acc 0.859375\n",
      "2018-05-04T14:36:09.804438: step 2751, loss 0.377977, acc 0.84375\n",
      "2018-05-04T14:36:10.925881: step 2752, loss 0.302988, acc 0.859375\n",
      "2018-05-04T14:36:12.028072: step 2753, loss 0.300381, acc 0.90625\n",
      "2018-05-04T14:36:13.118897: step 2754, loss 0.244757, acc 0.859375\n",
      "2018-05-04T14:36:14.231043: step 2755, loss 0.296877, acc 0.859375\n",
      "2018-05-04T14:36:15.326370: step 2756, loss 0.31303, acc 0.859375\n",
      "2018-05-04T14:36:16.443550: step 2757, loss 0.357542, acc 0.890625\n",
      "2018-05-04T14:36:17.565470: step 2758, loss 0.33285, acc 0.828125\n",
      "2018-05-04T14:36:18.777641: step 2759, loss 0.293855, acc 0.828125\n",
      "2018-05-04T14:36:19.966610: step 2760, loss 0.397083, acc 0.78125\n",
      "2018-05-04T14:36:21.241531: step 2761, loss 0.359896, acc 0.875\n",
      "2018-05-04T14:36:22.420128: step 2762, loss 0.355376, acc 0.875\n",
      "2018-05-04T14:36:23.511820: step 2763, loss 0.361002, acc 0.890625\n",
      "2018-05-04T14:36:24.687052: step 2764, loss 0.30254, acc 0.875\n",
      "2018-05-04T14:36:25.764542: step 2765, loss 0.296506, acc 0.890625\n",
      "2018-05-04T14:36:26.850041: step 2766, loss 0.354028, acc 0.890625\n",
      "2018-05-04T14:36:27.918305: step 2767, loss 0.243913, acc 0.875\n",
      "2018-05-04T14:36:29.049361: step 2768, loss 0.318183, acc 0.828125\n",
      "2018-05-04T14:36:30.244894: step 2769, loss 0.574625, acc 0.75\n",
      "2018-05-04T14:36:31.404357: step 2770, loss 0.341582, acc 0.859375\n",
      "2018-05-04T14:36:32.568256: step 2771, loss 0.350728, acc 0.84375\n",
      "2018-05-04T14:36:33.691465: step 2772, loss 0.319719, acc 0.828125\n",
      "2018-05-04T14:36:34.818462: step 2773, loss 0.416042, acc 0.828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T14:36:35.932576: step 2774, loss 0.281736, acc 0.875\n",
      "2018-05-04T14:36:37.073038: step 2775, loss 0.299771, acc 0.921875\n",
      "2018-05-04T14:36:38.253816: step 2776, loss 0.273395, acc 0.890625\n",
      "2018-05-04T14:36:39.365192: step 2777, loss 0.432315, acc 0.828125\n",
      "2018-05-04T14:36:40.449380: step 2778, loss 0.225947, acc 0.859375\n",
      "2018-05-04T14:36:41.613247: step 2779, loss 0.299004, acc 0.875\n",
      "2018-05-04T14:36:42.694755: step 2780, loss 0.291099, acc 0.875\n",
      "2018-05-04T14:36:43.791234: step 2781, loss 0.446754, acc 0.796875\n",
      "2018-05-04T14:36:44.930968: step 2782, loss 0.244281, acc 0.90625\n",
      "2018-05-04T14:36:46.052423: step 2783, loss 0.284822, acc 0.9375\n",
      "2018-05-04T14:36:47.186893: step 2784, loss 0.17375, acc 0.9375\n",
      "2018-05-04T14:36:48.309871: step 2785, loss 0.343614, acc 0.890625\n",
      "2018-05-04T14:36:49.426875: step 2786, loss 0.278967, acc 0.90625\n",
      "2018-05-04T14:36:50.540573: step 2787, loss 0.436193, acc 0.828125\n",
      "2018-05-04T14:36:51.721431: step 2788, loss 0.291839, acc 0.875\n",
      "2018-05-04T14:36:52.909178: step 2789, loss 0.415961, acc 0.859375\n",
      "2018-05-04T14:36:54.066836: step 2790, loss 0.308957, acc 0.859375\n",
      "2018-05-04T14:36:55.228464: step 2791, loss 0.277423, acc 0.921875\n",
      "2018-05-04T14:36:56.375840: step 2792, loss 0.255678, acc 0.875\n",
      "2018-05-04T14:36:57.524432: step 2793, loss 0.471115, acc 0.796875\n",
      "2018-05-04T14:36:58.617261: step 2794, loss 0.235552, acc 0.90625\n",
      "2018-05-04T14:36:59.718874: step 2795, loss 0.297646, acc 0.828125\n",
      "2018-05-04T14:37:00.902346: step 2796, loss 0.254873, acc 0.9375\n",
      "2018-05-04T14:37:02.092549: step 2797, loss 0.271592, acc 0.875\n",
      "2018-05-04T14:37:03.187650: step 2798, loss 0.47974, acc 0.796875\n",
      "2018-05-04T14:37:04.403528: step 2799, loss 0.293026, acc 0.84375\n",
      "2018-05-04T14:37:05.488427: step 2800, loss 0.181115, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T14:37:07.903378: step 2800, loss 0.265894, acc 0.886\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-2800\n",
      "\n",
      "2018-05-04T14:37:09.207298: step 2801, loss 0.236965, acc 0.890625\n",
      "2018-05-04T14:37:10.328353: step 2802, loss 0.27303, acc 0.84375\n",
      "2018-05-04T14:37:11.533129: step 2803, loss 0.368098, acc 0.796875\n",
      "2018-05-04T14:37:12.711504: step 2804, loss 0.462172, acc 0.796875\n",
      "2018-05-04T14:37:13.858462: step 2805, loss 0.275683, acc 0.84375\n",
      "2018-05-04T14:37:15.035987: step 2806, loss 0.391037, acc 0.84375\n",
      "2018-05-04T14:37:16.111016: step 2807, loss 0.288874, acc 0.859375\n",
      "2018-05-04T14:37:17.251913: step 2808, loss 0.280227, acc 0.90625\n",
      "2018-05-04T14:37:18.328624: step 2809, loss 0.356904, acc 0.859375\n",
      "2018-05-04T14:37:19.510174: step 2810, loss 0.434516, acc 0.828125\n",
      "2018-05-04T14:37:20.608912: step 2811, loss 0.228652, acc 0.90625\n",
      "2018-05-04T14:37:21.733388: step 2812, loss 0.283325, acc 0.859375\n",
      "2018-05-04T14:37:22.809561: step 2813, loss 0.32587, acc 0.8125\n",
      "2018-05-04T14:37:23.897391: step 2814, loss 0.382859, acc 0.84375\n",
      "2018-05-04T14:37:24.988455: step 2815, loss 0.318026, acc 0.859375\n",
      "2018-05-04T14:37:26.142846: step 2816, loss 0.431406, acc 0.828125\n",
      "2018-05-04T14:37:27.267739: step 2817, loss 0.355363, acc 0.8125\n",
      "2018-05-04T14:37:28.419227: step 2818, loss 0.296876, acc 0.875\n",
      "2018-05-04T14:37:29.565086: step 2819, loss 0.240939, acc 0.859375\n",
      "2018-05-04T14:37:30.725690: step 2820, loss 0.233971, acc 0.90625\n",
      "2018-05-04T14:37:31.906455: step 2821, loss 0.362272, acc 0.84375\n",
      "2018-05-04T14:37:33.076376: step 2822, loss 0.344232, acc 0.890625\n",
      "2018-05-04T14:37:34.296331: step 2823, loss 0.50405, acc 0.78125\n",
      "2018-05-04T14:37:35.533859: step 2824, loss 0.289743, acc 0.90625\n",
      "2018-05-04T14:37:36.755602: step 2825, loss 0.479783, acc 0.71875\n",
      "2018-05-04T14:37:37.918309: step 2826, loss 0.210688, acc 0.9375\n",
      "2018-05-04T14:37:39.018844: step 2827, loss 0.319075, acc 0.890625\n",
      "2018-05-04T14:37:40.091857: step 2828, loss 0.262455, acc 0.84375\n",
      "2018-05-04T14:37:41.238213: step 2829, loss 0.23118, acc 0.921875\n",
      "2018-05-04T14:37:42.421759: step 2830, loss 0.417311, acc 0.84375\n",
      "2018-05-04T14:37:43.614861: step 2831, loss 0.195884, acc 0.9375\n",
      "2018-05-04T14:37:44.795504: step 2832, loss 0.288954, acc 0.859375\n",
      "2018-05-04T14:37:45.937344: step 2833, loss 0.305901, acc 0.90625\n",
      "2018-05-04T14:37:47.084758: step 2834, loss 0.342821, acc 0.828125\n",
      "2018-05-04T14:37:48.240138: step 2835, loss 0.275184, acc 0.875\n",
      "2018-05-04T14:37:49.409462: step 2836, loss 0.291901, acc 0.921875\n",
      "2018-05-04T14:37:50.533617: step 2837, loss 0.226057, acc 0.921875\n",
      "2018-05-04T14:37:51.717011: step 2838, loss 0.257234, acc 0.921875\n",
      "2018-05-04T14:37:52.827600: step 2839, loss 0.329323, acc 0.875\n",
      "2018-05-04T14:37:53.937450: step 2840, loss 0.392729, acc 0.875\n",
      "2018-05-04T14:37:54.991559: step 2841, loss 0.357233, acc 0.828125\n",
      "2018-05-04T14:37:56.138664: step 2842, loss 0.304434, acc 0.859375\n",
      "2018-05-04T14:37:57.269879: step 2843, loss 0.351139, acc 0.84375\n",
      "2018-05-04T14:37:58.363326: step 2844, loss 0.319633, acc 0.90625\n",
      "2018-05-04T14:37:59.513127: step 2845, loss 0.289349, acc 0.90625\n",
      "2018-05-04T14:38:00.667168: step 2846, loss 0.273478, acc 0.890625\n",
      "2018-05-04T14:38:01.872012: step 2847, loss 0.22276, acc 0.9375\n",
      "2018-05-04T14:38:03.028934: step 2848, loss 0.282875, acc 0.90625\n",
      "2018-05-04T14:38:04.187032: step 2849, loss 0.289409, acc 0.875\n",
      "2018-05-04T14:38:05.337716: step 2850, loss 0.324238, acc 0.828125\n",
      "2018-05-04T14:38:06.475308: step 2851, loss 0.423187, acc 0.84375\n",
      "2018-05-04T14:38:07.635326: step 2852, loss 0.325175, acc 0.828125\n",
      "2018-05-04T14:38:08.797433: step 2853, loss 0.271363, acc 0.84375\n",
      "2018-05-04T14:38:09.950167: step 2854, loss 0.344393, acc 0.84375\n",
      "2018-05-04T14:38:11.128581: step 2855, loss 0.216651, acc 0.90625\n",
      "2018-05-04T14:38:12.258084: step 2856, loss 0.357463, acc 0.890625\n",
      "2018-05-04T14:38:13.377712: step 2857, loss 0.256507, acc 0.875\n",
      "2018-05-04T14:38:14.452050: step 2858, loss 0.373046, acc 0.859375\n",
      "2018-05-04T14:38:15.578644: step 2859, loss 0.254686, acc 0.890625\n",
      "2018-05-04T14:38:16.644038: step 2860, loss 0.41916, acc 0.8125\n",
      "2018-05-04T14:38:17.789483: step 2861, loss 0.432655, acc 0.78125\n",
      "2018-05-04T14:38:18.950378: step 2862, loss 0.34936, acc 0.859375\n",
      "2018-05-04T14:38:20.113299: step 2863, loss 0.52806, acc 0.765625\n",
      "2018-05-04T14:38:21.312647: step 2864, loss 0.247838, acc 0.921875\n",
      "2018-05-04T14:38:22.493467: step 2865, loss 0.236912, acc 0.890625\n",
      "2018-05-04T14:38:23.649456: step 2866, loss 0.196883, acc 0.90625\n",
      "2018-05-04T14:38:24.796102: step 2867, loss 0.332008, acc 0.78125\n",
      "2018-05-04T14:38:25.933137: step 2868, loss 0.57934, acc 0.84375\n",
      "2018-05-04T14:38:27.066305: step 2869, loss 0.357247, acc 0.796875\n",
      "2018-05-04T14:38:28.218027: step 2870, loss 0.257954, acc 0.875\n",
      "2018-05-04T14:38:29.387579: step 2871, loss 0.242728, acc 0.921875\n",
      "2018-05-04T14:38:30.517955: step 2872, loss 0.334316, acc 0.875\n",
      "2018-05-04T14:38:31.734408: step 2873, loss 0.255992, acc 0.875\n",
      "2018-05-04T14:38:32.889698: step 2874, loss 0.309082, acc 0.890625\n",
      "2018-05-04T14:38:34.052230: step 2875, loss 0.247257, acc 0.9375\n",
      "2018-05-04T14:38:35.225519: step 2876, loss 0.358697, acc 0.890625\n",
      "2018-05-04T14:38:36.299944: step 2877, loss 0.3726, acc 0.875\n",
      "2018-05-04T14:38:37.439415: step 2878, loss 0.456741, acc 0.765625\n",
      "2018-05-04T14:38:38.580449: step 2879, loss 0.323786, acc 0.828125\n",
      "2018-05-04T14:38:39.754272: step 2880, loss 0.348575, acc 0.890625\n",
      "2018-05-04T14:38:40.964101: step 2881, loss 0.279382, acc 0.90625\n",
      "2018-05-04T14:38:42.133854: step 2882, loss 0.352625, acc 0.875\n",
      "2018-05-04T14:38:43.271363: step 2883, loss 0.282056, acc 0.90625\n",
      "2018-05-04T14:38:44.371324: step 2884, loss 0.258534, acc 0.875\n",
      "2018-05-04T14:38:45.539545: step 2885, loss 0.318957, acc 0.84375\n",
      "2018-05-04T14:38:46.674981: step 2886, loss 0.33723, acc 0.875\n",
      "2018-05-04T14:38:47.816500: step 2887, loss 0.367331, acc 0.84375\n",
      "2018-05-04T14:38:48.957199: step 2888, loss 0.322983, acc 0.859375\n",
      "2018-05-04T14:38:50.111419: step 2889, loss 0.306185, acc 0.84375\n",
      "2018-05-04T14:38:51.305194: step 2890, loss 0.299199, acc 0.859375\n",
      "2018-05-04T14:38:52.438434: step 2891, loss 0.267845, acc 0.90625\n",
      "2018-05-04T14:38:53.594478: step 2892, loss 0.235344, acc 0.90625\n",
      "2018-05-04T14:38:54.754115: step 2893, loss 0.341761, acc 0.8125\n",
      "2018-05-04T14:38:55.873867: step 2894, loss 0.294884, acc 0.84375\n",
      "2018-05-04T14:38:57.017036: step 2895, loss 0.351901, acc 0.859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T14:38:58.111793: step 2896, loss 0.25324, acc 0.890625\n",
      "2018-05-04T14:38:59.225978: step 2897, loss 0.27003, acc 0.9375\n",
      "2018-05-04T14:39:00.359018: step 2898, loss 0.359748, acc 0.890625\n",
      "2018-05-04T14:39:01.553085: step 2899, loss 0.293922, acc 0.90625\n",
      "2018-05-04T14:39:02.702735: step 2900, loss 0.188905, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T14:39:05.444406: step 2900, loss 0.28569, acc 0.878\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-2900\n",
      "\n",
      "2018-05-04T14:39:06.726586: step 2901, loss 0.243517, acc 0.90625\n",
      "2018-05-04T14:39:07.947315: step 2902, loss 0.28232, acc 0.90625\n",
      "2018-05-04T14:39:09.040171: step 2903, loss 0.337759, acc 0.859375\n",
      "2018-05-04T14:39:10.226454: step 2904, loss 0.188033, acc 0.921875\n",
      "2018-05-04T14:39:11.384840: step 2905, loss 0.31147, acc 0.921875\n",
      "2018-05-04T14:39:12.474910: step 2906, loss 0.29678, acc 0.859375\n",
      "2018-05-04T14:39:13.615691: step 2907, loss 0.406241, acc 0.828125\n",
      "2018-05-04T14:39:14.735572: step 2908, loss 0.278897, acc 0.90625\n",
      "2018-05-04T14:39:15.887335: step 2909, loss 0.383406, acc 0.78125\n",
      "2018-05-04T14:39:17.007109: step 2910, loss 0.32549, acc 0.890625\n",
      "2018-05-04T14:39:18.142542: step 2911, loss 0.227429, acc 0.890625\n",
      "2018-05-04T14:39:19.302775: step 2912, loss 0.265972, acc 0.875\n",
      "2018-05-04T14:39:20.476226: step 2913, loss 0.272961, acc 0.859375\n",
      "2018-05-04T14:39:21.628085: step 2914, loss 0.343559, acc 0.828125\n",
      "2018-05-04T14:39:22.717383: step 2915, loss 0.371616, acc 0.890625\n",
      "2018-05-04T14:39:23.831566: step 2916, loss 0.384775, acc 0.828125\n",
      "2018-05-04T14:39:24.934265: step 2917, loss 0.320825, acc 0.890625\n",
      "2018-05-04T14:39:26.037254: step 2918, loss 0.249347, acc 0.90625\n",
      "2018-05-04T14:39:27.142415: step 2919, loss 0.426307, acc 0.828125\n",
      "2018-05-04T14:39:28.221146: step 2920, loss 0.290743, acc 0.875\n",
      "2018-05-04T14:39:29.346589: step 2921, loss 0.378547, acc 0.828125\n",
      "2018-05-04T14:39:30.440036: step 2922, loss 0.32319, acc 0.859375\n",
      "2018-05-04T14:39:31.627395: step 2923, loss 0.297395, acc 0.875\n",
      "2018-05-04T14:39:32.838601: step 2924, loss 0.250465, acc 0.859375\n",
      "2018-05-04T14:39:33.970690: step 2925, loss 0.24248, acc 0.90625\n",
      "2018-05-04T14:39:35.112262: step 2926, loss 0.260402, acc 0.875\n",
      "2018-05-04T14:39:36.254618: step 2927, loss 0.256288, acc 0.84375\n",
      "2018-05-04T14:39:37.381766: step 2928, loss 0.339582, acc 0.765625\n",
      "2018-05-04T14:39:38.502597: step 2929, loss 0.477645, acc 0.78125\n",
      "2018-05-04T14:39:39.614880: step 2930, loss 0.313865, acc 0.859375\n",
      "2018-05-04T14:39:40.778670: step 2931, loss 0.414853, acc 0.828125\n",
      "2018-05-04T14:39:41.928801: step 2932, loss 0.426302, acc 0.796875\n",
      "2018-05-04T14:39:43.072282: step 2933, loss 0.40422, acc 0.78125\n",
      "2018-05-04T14:39:44.189538: step 2934, loss 0.20997, acc 0.921875\n",
      "2018-05-04T14:39:45.327018: step 2935, loss 0.268335, acc 0.921875\n",
      "2018-05-04T14:39:46.437800: step 2936, loss 0.341364, acc 0.8125\n",
      "2018-05-04T14:39:47.539421: step 2937, loss 0.371275, acc 0.859375\n",
      "2018-05-04T14:39:48.685569: step 2938, loss 0.261512, acc 0.890625\n",
      "2018-05-04T14:39:49.809720: step 2939, loss 0.3561, acc 0.84375\n",
      "2018-05-04T14:39:50.950074: step 2940, loss 0.3643, acc 0.875\n",
      "2018-05-04T14:39:52.155055: step 2941, loss 0.344318, acc 0.875\n",
      "2018-05-04T14:39:53.277405: step 2942, loss 0.359921, acc 0.84375\n",
      "2018-05-04T14:39:54.409647: step 2943, loss 0.398505, acc 0.84375\n",
      "2018-05-04T14:39:55.541153: step 2944, loss 0.364396, acc 0.84375\n",
      "2018-05-04T14:39:56.665409: step 2945, loss 0.45887, acc 0.796875\n",
      "2018-05-04T14:39:57.849481: step 2946, loss 0.310592, acc 0.859375\n",
      "2018-05-04T14:39:58.949302: step 2947, loss 0.402445, acc 0.875\n",
      "2018-05-04T14:40:00.104999: step 2948, loss 0.348252, acc 0.8125\n",
      "2018-05-04T14:40:01.239429: step 2949, loss 0.259018, acc 0.90625\n",
      "2018-05-04T14:40:02.367952: step 2950, loss 0.219378, acc 0.921875\n",
      "2018-05-04T14:40:03.477559: step 2951, loss 0.306633, acc 0.90625\n",
      "2018-05-04T14:40:04.656814: step 2952, loss 0.423217, acc 0.828125\n",
      "2018-05-04T14:40:05.871218: step 2953, loss 0.275908, acc 0.875\n",
      "2018-05-04T14:40:06.996840: step 2954, loss 0.376616, acc 0.84375\n",
      "2018-05-04T14:40:08.118440: step 2955, loss 0.278708, acc 0.859375\n",
      "2018-05-04T14:40:09.246289: step 2956, loss 0.235019, acc 0.9375\n",
      "2018-05-04T14:40:10.382233: step 2957, loss 0.246498, acc 0.9375\n",
      "2018-05-04T14:40:11.581570: step 2958, loss 0.369886, acc 0.84375\n",
      "2018-05-04T14:40:12.708748: step 2959, loss 0.256332, acc 0.890625\n",
      "2018-05-04T14:40:13.832439: step 2960, loss 0.3428, acc 0.84375\n",
      "2018-05-04T14:40:14.970426: step 2961, loss 0.256855, acc 0.921875\n",
      "2018-05-04T14:40:16.066697: step 2962, loss 0.301526, acc 0.890625\n",
      "2018-05-04T14:40:17.213072: step 2963, loss 0.261636, acc 0.890625\n",
      "2018-05-04T14:40:18.428044: step 2964, loss 0.3361, acc 0.84375\n",
      "2018-05-04T14:40:19.557473: step 2965, loss 0.252532, acc 0.875\n",
      "2018-05-04T14:40:20.765916: step 2966, loss 0.431845, acc 0.78125\n",
      "2018-05-04T14:40:21.928531: step 2967, loss 0.271114, acc 0.875\n",
      "2018-05-04T14:40:23.047972: step 2968, loss 0.393429, acc 0.828125\n",
      "2018-05-04T14:40:24.180027: step 2969, loss 0.260937, acc 0.90625\n",
      "2018-05-04T14:40:25.316864: step 2970, loss 0.255592, acc 0.921875\n",
      "2018-05-04T14:40:26.444428: step 2971, loss 0.377092, acc 0.828125\n",
      "2018-05-04T14:40:27.548243: step 2972, loss 0.217032, acc 0.921875\n",
      "2018-05-04T14:40:28.678034: step 2973, loss 0.368839, acc 0.84375\n",
      "2018-05-04T14:40:29.813844: step 2974, loss 0.274064, acc 0.90625\n",
      "2018-05-04T14:40:30.987217: step 2975, loss 0.233518, acc 0.90625\n",
      "2018-05-04T14:40:32.127141: step 2976, loss 0.321786, acc 0.859375\n",
      "2018-05-04T14:40:33.294921: step 2977, loss 0.393509, acc 0.828125\n",
      "2018-05-04T14:40:34.520365: step 2978, loss 0.351874, acc 0.875\n",
      "2018-05-04T14:40:35.737241: step 2979, loss 0.271382, acc 0.890625\n",
      "2018-05-04T14:40:36.977417: step 2980, loss 0.250538, acc 0.90625\n",
      "2018-05-04T14:40:38.146360: step 2981, loss 0.389662, acc 0.828125\n",
      "2018-05-04T14:40:39.311139: step 2982, loss 0.442054, acc 0.84375\n",
      "2018-05-04T14:40:40.432719: step 2983, loss 0.48629, acc 0.71875\n",
      "2018-05-04T14:40:41.623159: step 2984, loss 0.318857, acc 0.84375\n",
      "2018-05-04T14:40:42.760554: step 2985, loss 0.348487, acc 0.84375\n",
      "2018-05-04T14:40:43.894286: step 2986, loss 0.273084, acc 0.890625\n",
      "2018-05-04T14:40:45.029768: step 2987, loss 0.281289, acc 0.859375\n",
      "2018-05-04T14:40:46.152585: step 2988, loss 0.433111, acc 0.828125\n",
      "2018-05-04T14:40:47.222601: step 2989, loss 0.359088, acc 0.796875\n",
      "2018-05-04T14:40:48.328676: step 2990, loss 0.225425, acc 0.890625\n",
      "2018-05-04T14:40:49.448496: step 2991, loss 0.311388, acc 0.875\n",
      "2018-05-04T14:40:50.531660: step 2992, loss 0.321948, acc 0.875\n",
      "2018-05-04T14:40:51.668534: step 2993, loss 0.369801, acc 0.78125\n",
      "2018-05-04T14:40:52.747467: step 2994, loss 0.368427, acc 0.875\n",
      "2018-05-04T14:40:53.836366: step 2995, loss 0.273121, acc 0.875\n",
      "2018-05-04T14:40:54.944254: step 2996, loss 0.297605, acc 0.890625\n",
      "2018-05-04T14:40:56.069169: step 2997, loss 0.42343, acc 0.859375\n",
      "2018-05-04T14:40:57.253250: step 2998, loss 0.290726, acc 0.875\n",
      "2018-05-04T14:40:58.373128: step 2999, loss 0.316553, acc 0.859375\n",
      "2018-05-04T14:40:59.516669: step 3000, loss 0.32564, acc 0.828125\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T14:41:02.391366: step 3000, loss 0.270041, acc 0.886\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-3000\n",
      "\n",
      "2018-05-04T14:41:03.622111: step 3001, loss 0.414862, acc 0.875\n",
      "2018-05-04T14:41:04.805409: step 3002, loss 0.247348, acc 0.921875\n",
      "2018-05-04T14:41:05.899376: step 3003, loss 0.210388, acc 0.921875\n",
      "2018-05-04T14:41:06.987288: step 3004, loss 0.22648, acc 0.921875\n",
      "2018-05-04T14:41:08.097194: step 3005, loss 0.4902, acc 0.8125\n",
      "2018-05-04T14:41:09.291761: step 3006, loss 0.421994, acc 0.71875\n",
      "2018-05-04T14:41:10.429367: step 3007, loss 0.326342, acc 0.875\n",
      "2018-05-04T14:41:11.600601: step 3008, loss 0.41667, acc 0.78125\n",
      "2018-05-04T14:41:12.700181: step 3009, loss 0.254217, acc 0.875\n",
      "2018-05-04T14:41:13.796548: step 3010, loss 0.33382, acc 0.859375\n",
      "2018-05-04T14:41:14.902113: step 3011, loss 0.304323, acc 0.90625\n",
      "2018-05-04T14:41:16.040383: step 3012, loss 0.336137, acc 0.890625\n",
      "2018-05-04T14:41:17.216039: step 3013, loss 0.404125, acc 0.8125\n",
      "2018-05-04T14:41:18.322113: step 3014, loss 0.292225, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T14:41:19.453543: step 3015, loss 0.354213, acc 0.828125\n",
      "2018-05-04T14:41:20.574358: step 3016, loss 0.321559, acc 0.859375\n",
      "2018-05-04T14:41:21.703042: step 3017, loss 0.318149, acc 0.875\n",
      "2018-05-04T14:41:22.800319: step 3018, loss 0.243688, acc 0.921875\n",
      "2018-05-04T14:41:23.889979: step 3019, loss 0.250813, acc 0.890625\n",
      "2018-05-04T14:41:24.992561: step 3020, loss 0.245821, acc 0.90625\n",
      "2018-05-04T14:41:26.161867: step 3021, loss 0.255738, acc 0.890625\n",
      "2018-05-04T14:41:27.305037: step 3022, loss 0.275646, acc 0.90625\n",
      "2018-05-04T14:41:28.415019: step 3023, loss 0.513654, acc 0.796875\n",
      "2018-05-04T14:41:29.555640: step 3024, loss 0.398371, acc 0.828125\n",
      "2018-05-04T14:41:30.737635: step 3025, loss 0.377265, acc 0.828125\n",
      "2018-05-04T14:41:31.940331: step 3026, loss 0.454608, acc 0.8125\n",
      "2018-05-04T14:41:33.030048: step 3027, loss 0.479537, acc 0.765625\n",
      "2018-05-04T14:41:34.128349: step 3028, loss 0.261494, acc 0.859375\n",
      "2018-05-04T14:41:35.232848: step 3029, loss 0.347046, acc 0.828125\n",
      "2018-05-04T14:41:36.328042: step 3030, loss 0.388279, acc 0.828125\n",
      "2018-05-04T14:41:37.436956: step 3031, loss 0.25769, acc 0.9375\n",
      "2018-05-04T14:41:38.565807: step 3032, loss 0.376622, acc 0.828125\n",
      "2018-05-04T14:41:39.760637: step 3033, loss 0.289785, acc 0.890625\n",
      "2018-05-04T14:41:40.960813: step 3034, loss 0.367988, acc 0.796875\n",
      "2018-05-04T14:41:42.108703: step 3035, loss 0.284936, acc 0.90625\n",
      "2018-05-04T14:41:43.213845: step 3036, loss 0.203009, acc 0.9375\n",
      "2018-05-04T14:41:44.322220: step 3037, loss 0.328808, acc 0.890625\n",
      "2018-05-04T14:41:45.471150: step 3038, loss 0.330796, acc 0.84375\n",
      "2018-05-04T14:41:46.590494: step 3039, loss 0.44339, acc 0.8125\n",
      "2018-05-04T14:41:47.684726: step 3040, loss 0.264461, acc 0.90625\n",
      "2018-05-04T14:41:48.782095: step 3041, loss 0.331676, acc 0.84375\n",
      "2018-05-04T14:41:49.869093: step 3042, loss 0.309668, acc 0.84375\n",
      "2018-05-04T14:41:51.068003: step 3043, loss 0.309079, acc 0.875\n",
      "2018-05-04T14:41:52.178665: step 3044, loss 0.315251, acc 0.90625\n",
      "2018-05-04T14:41:53.254997: step 3045, loss 0.295523, acc 0.859375\n",
      "2018-05-04T14:41:54.382961: step 3046, loss 0.343481, acc 0.875\n",
      "2018-05-04T14:41:55.513999: step 3047, loss 0.365325, acc 0.796875\n",
      "2018-05-04T14:41:56.625916: step 3048, loss 0.226089, acc 0.9375\n",
      "2018-05-04T14:41:57.780684: step 3049, loss 0.289563, acc 0.90625\n",
      "2018-05-04T14:41:58.927604: step 3050, loss 0.455457, acc 0.78125\n",
      "2018-05-04T14:42:00.075298: step 3051, loss 0.25089, acc 0.90625\n",
      "2018-05-04T14:42:01.260678: step 3052, loss 0.415689, acc 0.84375\n",
      "2018-05-04T14:42:02.395787: step 3053, loss 0.2893, acc 0.875\n",
      "2018-05-04T14:42:03.520750: step 3054, loss 0.264391, acc 0.859375\n",
      "2018-05-04T14:42:04.722632: step 3055, loss 0.22596, acc 0.9375\n",
      "2018-05-04T14:42:05.918263: step 3056, loss 0.216379, acc 0.890625\n",
      "2018-05-04T14:42:07.090981: step 3057, loss 0.314606, acc 0.8125\n",
      "2018-05-04T14:42:08.168722: step 3058, loss 0.299261, acc 0.921875\n",
      "2018-05-04T14:42:09.247593: step 3059, loss 0.437351, acc 0.796875\n",
      "2018-05-04T14:42:10.371393: step 3060, loss 0.294524, acc 0.90625\n",
      "2018-05-04T14:42:11.541921: step 3061, loss 0.304076, acc 0.875\n",
      "2018-05-04T14:42:12.642413: step 3062, loss 0.404944, acc 0.8125\n",
      "2018-05-04T14:42:13.774959: step 3063, loss 0.494146, acc 0.78125\n",
      "2018-05-04T14:42:14.910830: step 3064, loss 0.370751, acc 0.8125\n",
      "2018-05-04T14:42:16.032759: step 3065, loss 0.364053, acc 0.84375\n",
      "2018-05-04T14:42:17.163354: step 3066, loss 0.226835, acc 0.890625\n",
      "2018-05-04T14:42:18.286219: step 3067, loss 0.32954, acc 0.84375\n",
      "2018-05-04T14:42:19.418973: step 3068, loss 0.377231, acc 0.859375\n",
      "2018-05-04T14:42:20.548161: step 3069, loss 0.323698, acc 0.859375\n",
      "2018-05-04T14:42:21.755933: step 3070, loss 0.342798, acc 0.859375\n",
      "2018-05-04T14:42:22.889681: step 3071, loss 0.451853, acc 0.8125\n",
      "2018-05-04T14:42:24.024046: step 3072, loss 0.310422, acc 0.859375\n",
      "2018-05-04T14:42:25.213168: step 3073, loss 0.361001, acc 0.859375\n",
      "2018-05-04T14:42:26.350208: step 3074, loss 0.343667, acc 0.875\n",
      "2018-05-04T14:42:27.470503: step 3075, loss 0.414542, acc 0.75\n",
      "2018-05-04T14:42:28.616245: step 3076, loss 0.245481, acc 0.921875\n",
      "2018-05-04T14:42:29.816751: step 3077, loss 0.363265, acc 0.78125\n",
      "2018-05-04T14:42:30.993984: step 3078, loss 0.41422, acc 0.828125\n",
      "2018-05-04T14:42:32.128208: step 3079, loss 0.385482, acc 0.796875\n",
      "2018-05-04T14:42:33.256226: step 3080, loss 0.328688, acc 0.890625\n",
      "2018-05-04T14:42:34.397427: step 3081, loss 0.196956, acc 0.96875\n",
      "2018-05-04T14:42:35.525179: step 3082, loss 0.24921, acc 0.875\n",
      "2018-05-04T14:42:36.633355: step 3083, loss 0.230148, acc 0.921875\n",
      "2018-05-04T14:42:37.750513: step 3084, loss 0.271516, acc 0.90625\n",
      "2018-05-04T14:42:38.873127: step 3085, loss 0.213452, acc 0.890625\n",
      "2018-05-04T14:42:40.035187: step 3086, loss 0.272559, acc 0.859375\n",
      "2018-05-04T14:42:41.203721: step 3087, loss 0.238606, acc 0.953125\n",
      "2018-05-04T14:42:42.339627: step 3088, loss 0.215745, acc 0.90625\n",
      "2018-05-04T14:42:43.471729: step 3089, loss 0.216642, acc 0.90625\n",
      "2018-05-04T14:42:44.620450: step 3090, loss 0.386088, acc 0.8125\n",
      "2018-05-04T14:42:45.748947: step 3091, loss 0.458001, acc 0.796875\n",
      "2018-05-04T14:42:46.876029: step 3092, loss 0.414552, acc 0.828125\n",
      "2018-05-04T14:42:47.972512: step 3093, loss 0.338464, acc 0.859375\n",
      "2018-05-04T14:42:49.102049: step 3094, loss 0.315188, acc 0.875\n",
      "2018-05-04T14:42:50.280857: step 3095, loss 0.28409, acc 0.859375\n",
      "2018-05-04T14:42:51.521248: step 3096, loss 0.325889, acc 0.8125\n",
      "2018-05-04T14:42:52.598728: step 3097, loss 0.327389, acc 0.890625\n",
      "2018-05-04T14:42:53.667944: step 3098, loss 0.344095, acc 0.8125\n",
      "2018-05-04T14:42:54.843161: step 3099, loss 0.155103, acc 0.953125\n",
      "2018-05-04T14:42:55.938328: step 3100, loss 0.251804, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T14:42:58.858690: step 3100, loss 0.254525, acc 0.902\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-3100\n",
      "\n",
      "2018-05-04T14:43:00.180281: step 3101, loss 0.367563, acc 0.796875\n",
      "2018-05-04T14:43:01.423121: step 3102, loss 0.411983, acc 0.765625\n",
      "2018-05-04T14:43:02.581424: step 3103, loss 0.378491, acc 0.828125\n",
      "2018-05-04T14:43:03.742401: step 3104, loss 0.272744, acc 0.875\n",
      "2018-05-04T14:43:04.869263: step 3105, loss 0.404386, acc 0.78125\n",
      "2018-05-04T14:43:06.076958: step 3106, loss 0.261931, acc 0.890625\n",
      "2018-05-04T14:43:07.227362: step 3107, loss 0.312436, acc 0.859375\n",
      "2018-05-04T14:43:08.351485: step 3108, loss 0.289724, acc 0.90625\n",
      "2018-05-04T14:43:09.588668: step 3109, loss 0.302378, acc 0.859375\n",
      "2018-05-04T14:43:10.748887: step 3110, loss 0.314146, acc 0.84375\n",
      "2018-05-04T14:43:11.919240: step 3111, loss 0.278356, acc 0.875\n",
      "2018-05-04T14:43:13.059622: step 3112, loss 0.447957, acc 0.859375\n",
      "2018-05-04T14:43:14.188840: step 3113, loss 0.352188, acc 0.84375\n",
      "2018-05-04T14:43:15.332560: step 3114, loss 0.143891, acc 0.96875\n",
      "2018-05-04T14:43:16.422721: step 3115, loss 0.211528, acc 0.921875\n",
      "2018-05-04T14:43:17.531556: step 3116, loss 0.460672, acc 0.78125\n",
      "2018-05-04T14:43:18.687789: step 3117, loss 0.342204, acc 0.796875\n",
      "2018-05-04T14:43:19.817284: step 3118, loss 0.408783, acc 0.828125\n",
      "2018-05-04T14:43:20.965538: step 3119, loss 0.314707, acc 0.859375\n",
      "2018-05-04T14:43:22.153140: step 3120, loss 0.331395, acc 0.890625\n",
      "2018-05-04T14:43:23.323725: step 3121, loss 0.302164, acc 0.890625\n",
      "2018-05-04T14:43:24.541157: step 3122, loss 0.261264, acc 0.890625\n",
      "2018-05-04T14:43:25.629646: step 3123, loss 0.257411, acc 0.90625\n",
      "2018-05-04T14:43:26.810626: step 3124, loss 0.340997, acc 0.875\n",
      "2018-05-04T14:43:27.974885: step 3125, loss 0.355119, acc 0.875\n",
      "2018-05-04T14:43:29.146261: step 3126, loss 0.348932, acc 0.875\n",
      "2018-05-04T14:43:30.268961: step 3127, loss 0.461475, acc 0.8125\n",
      "2018-05-04T14:43:31.472965: step 3128, loss 0.213351, acc 0.921875\n",
      "2018-05-04T14:43:32.616517: step 3129, loss 0.307802, acc 0.859375\n",
      "2018-05-04T14:43:33.818513: step 3130, loss 0.214075, acc 0.953125\n",
      "2018-05-04T14:43:35.039285: step 3131, loss 0.355736, acc 0.859375\n",
      "2018-05-04T14:43:36.286032: step 3132, loss 0.417489, acc 0.84375\n",
      "2018-05-04T14:43:37.529607: step 3133, loss 0.329511, acc 0.84375\n",
      "2018-05-04T14:43:38.779703: step 3134, loss 0.379192, acc 0.859375\n",
      "2018-05-04T14:43:40.024026: step 3135, loss 0.236198, acc 0.9375\n",
      "2018-05-04T14:43:41.235692: step 3136, loss 0.335854, acc 0.84375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T14:43:42.376586: step 3137, loss 0.264673, acc 0.90625\n",
      "2018-05-04T14:43:43.503127: step 3138, loss 0.208966, acc 0.890625\n",
      "2018-05-04T14:43:44.660205: step 3139, loss 0.375368, acc 0.8125\n",
      "2018-05-04T14:43:45.791786: step 3140, loss 0.365133, acc 0.875\n",
      "2018-05-04T14:43:46.935138: step 3141, loss 0.301771, acc 0.890625\n",
      "2018-05-04T14:43:48.121240: step 3142, loss 0.238107, acc 0.90625\n",
      "2018-05-04T14:43:49.206658: step 3143, loss 0.363427, acc 0.859375\n",
      "2018-05-04T14:43:50.364544: step 3144, loss 0.459171, acc 0.796875\n",
      "2018-05-04T14:43:51.551262: step 3145, loss 0.231486, acc 0.90625\n",
      "2018-05-04T14:43:52.651715: step 3146, loss 0.375092, acc 0.875\n",
      "2018-05-04T14:43:53.807699: step 3147, loss 0.408282, acc 0.8125\n",
      "2018-05-04T14:43:54.947936: step 3148, loss 0.287267, acc 0.90625\n",
      "2018-05-04T14:43:56.057338: step 3149, loss 0.332985, acc 0.859375\n",
      "2018-05-04T14:43:57.188571: step 3150, loss 0.370877, acc 0.828125\n",
      "2018-05-04T14:43:58.326292: step 3151, loss 0.227732, acc 0.890625\n",
      "2018-05-04T14:43:59.492708: step 3152, loss 0.309334, acc 0.84375\n",
      "2018-05-04T14:44:00.617655: step 3153, loss 0.285856, acc 0.859375\n",
      "2018-05-04T14:44:01.792921: step 3154, loss 0.255233, acc 0.875\n",
      "2018-05-04T14:44:02.955480: step 3155, loss 0.258851, acc 0.90625\n",
      "2018-05-04T14:44:04.099227: step 3156, loss 0.216872, acc 0.890625\n",
      "2018-05-04T14:44:05.312387: step 3157, loss 0.293741, acc 0.84375\n",
      "2018-05-04T14:44:06.445129: step 3158, loss 0.369417, acc 0.8125\n",
      "2018-05-04T14:44:07.528283: step 3159, loss 0.308818, acc 0.90625\n",
      "2018-05-04T14:44:08.601207: step 3160, loss 0.239679, acc 0.921875\n",
      "2018-05-04T14:44:09.694375: step 3161, loss 0.214643, acc 0.953125\n",
      "2018-05-04T14:44:10.816811: step 3162, loss 0.330001, acc 0.828125\n",
      "2018-05-04T14:44:11.947799: step 3163, loss 0.217826, acc 0.921875\n",
      "2018-05-04T14:44:13.062972: step 3164, loss 0.363376, acc 0.84375\n",
      "2018-05-04T14:44:14.189710: step 3165, loss 0.26218, acc 0.875\n",
      "2018-05-04T14:44:15.355769: step 3166, loss 0.249743, acc 0.921875\n",
      "2018-05-04T14:44:16.466729: step 3167, loss 0.276741, acc 0.921875\n",
      "2018-05-04T14:44:17.589045: step 3168, loss 0.328285, acc 0.90625\n",
      "2018-05-04T14:44:18.792159: step 3169, loss 0.438742, acc 0.828125\n",
      "2018-05-04T14:44:19.968660: step 3170, loss 0.400955, acc 0.84375\n",
      "2018-05-04T14:44:21.125737: step 3171, loss 0.319892, acc 0.859375\n",
      "2018-05-04T14:44:22.247336: step 3172, loss 0.341725, acc 0.828125\n",
      "2018-05-04T14:44:23.322656: step 3173, loss 0.340448, acc 0.890625\n",
      "2018-05-04T14:44:24.432369: step 3174, loss 0.204526, acc 0.9375\n",
      "2018-05-04T14:44:25.535387: step 3175, loss 0.577381, acc 0.71875\n",
      "2018-05-04T14:44:26.659658: step 3176, loss 0.243644, acc 0.890625\n",
      "2018-05-04T14:44:27.772424: step 3177, loss 0.310071, acc 0.890625\n",
      "2018-05-04T14:44:28.886581: step 3178, loss 0.344636, acc 0.90625\n",
      "2018-05-04T14:44:30.024706: step 3179, loss 0.297659, acc 0.828125\n",
      "2018-05-04T14:44:31.226506: step 3180, loss 0.251951, acc 0.890625\n",
      "2018-05-04T14:44:32.363446: step 3181, loss 0.333546, acc 0.875\n",
      "2018-05-04T14:44:33.498176: step 3182, loss 0.268195, acc 0.90625\n",
      "2018-05-04T14:44:34.726536: step 3183, loss 0.308026, acc 0.84375\n",
      "2018-05-04T14:44:35.855708: step 3184, loss 0.229499, acc 0.921875\n",
      "2018-05-04T14:44:36.978123: step 3185, loss 0.24442, acc 0.890625\n",
      "2018-05-04T14:44:38.055887: step 3186, loss 0.304382, acc 0.859375\n",
      "2018-05-04T14:44:39.152228: step 3187, loss 0.438573, acc 0.828125\n",
      "2018-05-04T14:44:40.319821: step 3188, loss 0.392104, acc 0.828125\n",
      "2018-05-04T14:44:41.463060: step 3189, loss 0.210664, acc 0.875\n",
      "2018-05-04T14:44:42.534619: step 3190, loss 0.327569, acc 0.84375\n",
      "2018-05-04T14:44:43.621787: step 3191, loss 0.313559, acc 0.890625\n",
      "2018-05-04T14:44:44.746231: step 3192, loss 0.286977, acc 0.90625\n",
      "2018-05-04T14:44:45.870073: step 3193, loss 0.343033, acc 0.84375\n",
      "2018-05-04T14:44:46.989502: step 3194, loss 0.361838, acc 0.875\n",
      "2018-05-04T14:44:48.095243: step 3195, loss 0.395071, acc 0.8125\n",
      "2018-05-04T14:44:49.270859: step 3196, loss 0.267672, acc 0.90625\n",
      "2018-05-04T14:44:50.467773: step 3197, loss 0.316642, acc 0.8125\n",
      "2018-05-04T14:44:51.661194: step 3198, loss 0.266353, acc 0.921875\n",
      "2018-05-04T14:44:52.770635: step 3199, loss 0.372376, acc 0.875\n",
      "2018-05-04T14:44:53.900635: step 3200, loss 0.341725, acc 0.828125\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T14:44:56.702513: step 3200, loss 0.265339, acc 0.892\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-3200\n",
      "\n",
      "2018-05-04T14:44:57.918545: step 3201, loss 0.306394, acc 0.875\n",
      "2018-05-04T14:44:59.076327: step 3202, loss 0.195739, acc 0.921875\n",
      "2018-05-04T14:45:00.230351: step 3203, loss 0.417023, acc 0.859375\n",
      "2018-05-04T14:45:01.382241: step 3204, loss 0.301317, acc 0.875\n",
      "2018-05-04T14:45:02.479014: step 3205, loss 0.337741, acc 0.875\n",
      "2018-05-04T14:45:03.622272: step 3206, loss 0.484808, acc 0.75\n",
      "2018-05-04T14:45:04.808344: step 3207, loss 0.219867, acc 0.90625\n",
      "2018-05-04T14:45:05.965030: step 3208, loss 0.304543, acc 0.875\n",
      "2018-05-04T14:45:07.157617: step 3209, loss 0.402803, acc 0.84375\n",
      "2018-05-04T14:45:08.243607: step 3210, loss 0.26016, acc 0.921875\n",
      "2018-05-04T14:45:09.355658: step 3211, loss 0.517979, acc 0.8125\n",
      "2018-05-04T14:45:10.448613: step 3212, loss 0.311228, acc 0.828125\n",
      "2018-05-04T14:45:11.636346: step 3213, loss 0.213078, acc 0.921875\n",
      "2018-05-04T14:45:12.720798: step 3214, loss 0.457419, acc 0.765625\n",
      "2018-05-04T14:45:13.805035: step 3215, loss 0.34683, acc 0.8125\n",
      "2018-05-04T14:45:14.924384: step 3216, loss 0.522664, acc 0.71875\n",
      "2018-05-04T14:45:16.156872: step 3217, loss 0.262281, acc 0.90625\n",
      "2018-05-04T14:45:17.310000: step 3218, loss 0.382506, acc 0.859375\n",
      "2018-05-04T14:45:18.435933: step 3219, loss 0.264005, acc 0.921875\n",
      "2018-05-04T14:45:19.567274: step 3220, loss 0.28218, acc 0.890625\n",
      "2018-05-04T14:45:20.752713: step 3221, loss 0.315202, acc 0.90625\n",
      "2018-05-04T14:45:21.940701: step 3222, loss 0.380847, acc 0.796875\n",
      "2018-05-04T14:45:23.067565: step 3223, loss 0.362182, acc 0.796875\n",
      "2018-05-04T14:45:24.162289: step 3224, loss 0.320187, acc 0.859375\n",
      "2018-05-04T14:45:25.250387: step 3225, loss 0.250633, acc 0.890625\n",
      "2018-05-04T14:45:26.338155: step 3226, loss 0.306384, acc 0.859375\n",
      "2018-05-04T14:45:27.429578: step 3227, loss 0.257921, acc 0.890625\n",
      "2018-05-04T14:45:28.530199: step 3228, loss 0.312714, acc 0.859375\n",
      "2018-05-04T14:45:29.640266: step 3229, loss 0.311949, acc 0.859375\n",
      "2018-05-04T14:45:30.787397: step 3230, loss 0.33248, acc 0.8125\n",
      "2018-05-04T14:45:31.946785: step 3231, loss 0.377173, acc 0.765625\n",
      "2018-05-04T14:45:33.075261: step 3232, loss 0.298082, acc 0.859375\n",
      "2018-05-04T14:45:34.226490: step 3233, loss 0.20869, acc 0.890625\n",
      "2018-05-04T14:45:35.434284: step 3234, loss 0.234544, acc 0.890625\n",
      "2018-05-04T14:45:36.560258: step 3235, loss 0.234163, acc 0.90625\n",
      "2018-05-04T14:45:37.704257: step 3236, loss 0.374249, acc 0.8125\n",
      "2018-05-04T14:45:38.850633: step 3237, loss 0.335524, acc 0.890625\n",
      "2018-05-04T14:45:40.052069: step 3238, loss 0.266474, acc 0.859375\n",
      "2018-05-04T14:45:41.233577: step 3239, loss 0.249589, acc 0.875\n",
      "2018-05-04T14:45:42.420267: step 3240, loss 0.321133, acc 0.84375\n",
      "2018-05-04T14:45:43.565187: step 3241, loss 0.232757, acc 0.890625\n",
      "2018-05-04T14:45:44.688362: step 3242, loss 0.273516, acc 0.90625\n",
      "2018-05-04T14:45:45.791195: step 3243, loss 0.320926, acc 0.875\n",
      "2018-05-04T14:45:46.896528: step 3244, loss 0.280648, acc 0.890625\n",
      "2018-05-04T14:45:47.975801: step 3245, loss 0.255791, acc 0.859375\n",
      "2018-05-04T14:45:49.074716: step 3246, loss 0.378974, acc 0.859375\n",
      "2018-05-04T14:45:50.202300: step 3247, loss 0.369346, acc 0.828125\n",
      "2018-05-04T14:45:51.411793: step 3248, loss 0.304285, acc 0.84375\n",
      "2018-05-04T14:45:52.526771: step 3249, loss 0.427359, acc 0.84375\n",
      "2018-05-04T14:45:53.658907: step 3250, loss 0.379961, acc 0.859375\n",
      "2018-05-04T14:45:54.885054: step 3251, loss 0.193513, acc 0.9375\n",
      "2018-05-04T14:45:56.017927: step 3252, loss 0.340911, acc 0.859375\n",
      "2018-05-04T14:45:57.158291: step 3253, loss 0.21661, acc 0.90625\n",
      "2018-05-04T14:45:58.291316: step 3254, loss 0.350237, acc 0.8125\n",
      "2018-05-04T14:45:59.441075: step 3255, loss 0.250385, acc 0.875\n",
      "2018-05-04T14:46:00.552109: step 3256, loss 0.401619, acc 0.875\n",
      "2018-05-04T14:46:01.736242: step 3257, loss 0.281929, acc 0.90625\n",
      "2018-05-04T14:46:02.880141: step 3258, loss 0.284309, acc 0.859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T14:46:03.999771: step 3259, loss 0.265135, acc 0.859375\n",
      "2018-05-04T14:46:05.207716: step 3260, loss 0.230294, acc 0.890625\n",
      "2018-05-04T14:46:06.322100: step 3261, loss 0.313128, acc 0.921875\n",
      "2018-05-04T14:46:07.498529: step 3262, loss 0.239453, acc 0.890625\n",
      "2018-05-04T14:46:08.603369: step 3263, loss 0.218179, acc 0.90625\n",
      "2018-05-04T14:46:09.744444: step 3264, loss 0.451267, acc 0.828125\n",
      "2018-05-04T14:46:10.915292: step 3265, loss 0.18368, acc 0.921875\n",
      "2018-05-04T14:46:12.073448: step 3266, loss 0.412911, acc 0.8125\n",
      "2018-05-04T14:46:13.181976: step 3267, loss 0.183944, acc 0.9375\n",
      "2018-05-04T14:46:14.324181: step 3268, loss 0.367458, acc 0.875\n",
      "2018-05-04T14:46:15.425003: step 3269, loss 0.306875, acc 0.84375\n",
      "2018-05-04T14:46:16.549853: step 3270, loss 0.291886, acc 0.859375\n",
      "2018-05-04T14:46:17.693484: step 3271, loss 0.260273, acc 0.875\n",
      "2018-05-04T14:46:18.804355: step 3272, loss 0.36044, acc 0.8125\n",
      "2018-05-04T14:46:20.019597: step 3273, loss 0.323617, acc 0.890625\n",
      "2018-05-04T14:46:21.262972: step 3274, loss 0.267655, acc 0.859375\n",
      "2018-05-04T14:46:22.456817: step 3275, loss 0.359086, acc 0.875\n",
      "2018-05-04T14:46:23.545682: step 3276, loss 0.203461, acc 0.90625\n",
      "2018-05-04T14:46:24.637387: step 3277, loss 0.339203, acc 0.84375\n",
      "2018-05-04T14:46:25.715569: step 3278, loss 0.274116, acc 0.84375\n",
      "2018-05-04T14:46:26.902871: step 3279, loss 0.239549, acc 0.921875\n",
      "2018-05-04T14:46:28.030144: step 3280, loss 0.205712, acc 0.9375\n",
      "2018-05-04T14:46:29.155867: step 3281, loss 0.368353, acc 0.828125\n",
      "2018-05-04T14:46:30.274631: step 3282, loss 0.324438, acc 0.84375\n",
      "2018-05-04T14:46:31.449683: step 3283, loss 0.404867, acc 0.8125\n",
      "2018-05-04T14:46:32.590173: step 3284, loss 0.360404, acc 0.828125\n",
      "2018-05-04T14:46:33.842955: step 3285, loss 0.43173, acc 0.828125\n",
      "2018-05-04T14:46:35.090727: step 3286, loss 0.222439, acc 0.921875\n",
      "2018-05-04T14:46:36.321027: step 3287, loss 0.446584, acc 0.796875\n",
      "2018-05-04T14:46:37.563932: step 3288, loss 0.326899, acc 0.859375\n",
      "2018-05-04T14:46:38.752860: step 3289, loss 0.441378, acc 0.8125\n",
      "2018-05-04T14:46:39.930910: step 3290, loss 0.361455, acc 0.765625\n",
      "2018-05-04T14:46:41.142125: step 3291, loss 0.37698, acc 0.78125\n",
      "2018-05-04T14:46:42.320938: step 3292, loss 0.283529, acc 0.828125\n",
      "2018-05-04T14:46:43.472951: step 3293, loss 0.427506, acc 0.796875\n",
      "2018-05-04T14:46:44.656658: step 3294, loss 0.400546, acc 0.890625\n",
      "2018-05-04T14:46:45.773343: step 3295, loss 0.443844, acc 0.8125\n",
      "2018-05-04T14:46:46.894348: step 3296, loss 0.389633, acc 0.8125\n",
      "2018-05-04T14:46:48.017587: step 3297, loss 0.386987, acc 0.796875\n",
      "2018-05-04T14:46:49.131906: step 3298, loss 0.328739, acc 0.859375\n",
      "2018-05-04T14:46:50.249351: step 3299, loss 0.313274, acc 0.890625\n",
      "2018-05-04T14:46:51.419301: step 3300, loss 0.245895, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T14:46:54.165902: step 3300, loss 0.272934, acc 0.894\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-3300\n",
      "\n",
      "2018-05-04T14:46:55.540903: step 3301, loss 0.345057, acc 0.890625\n",
      "2018-05-04T14:46:56.760071: step 3302, loss 0.257472, acc 0.890625\n",
      "2018-05-04T14:46:58.026656: step 3303, loss 0.307762, acc 0.84375\n",
      "2018-05-04T14:46:59.172626: step 3304, loss 0.297908, acc 0.84375\n",
      "2018-05-04T14:47:00.310159: step 3305, loss 0.305982, acc 0.875\n",
      "2018-05-04T14:47:01.538221: step 3306, loss 0.306067, acc 0.875\n",
      "2018-05-04T14:47:02.672458: step 3307, loss 0.238305, acc 0.9375\n",
      "2018-05-04T14:47:03.820312: step 3308, loss 0.35258, acc 0.859375\n",
      "2018-05-04T14:47:04.981603: step 3309, loss 0.278091, acc 0.890625\n",
      "2018-05-04T14:47:06.135096: step 3310, loss 0.314975, acc 0.890625\n",
      "2018-05-04T14:47:07.264174: step 3311, loss 0.373348, acc 0.828125\n",
      "2018-05-04T14:47:08.410180: step 3312, loss 0.27841, acc 0.875\n",
      "2018-05-04T14:47:09.615482: step 3313, loss 0.401971, acc 0.859375\n",
      "2018-05-04T14:47:10.722702: step 3314, loss 0.271513, acc 0.890625\n",
      "2018-05-04T14:47:11.866069: step 3315, loss 0.253375, acc 0.953125\n",
      "2018-05-04T14:47:12.952281: step 3316, loss 0.299729, acc 0.875\n",
      "2018-05-04T14:47:14.069934: step 3317, loss 0.502407, acc 0.734375\n",
      "2018-05-04T14:47:15.198427: step 3318, loss 0.335478, acc 0.828125\n",
      "2018-05-04T14:47:16.307897: step 3319, loss 0.216943, acc 0.953125\n",
      "2018-05-04T14:47:17.446324: step 3320, loss 0.281853, acc 0.875\n",
      "2018-05-04T14:47:18.591233: step 3321, loss 0.303804, acc 0.875\n",
      "2018-05-04T14:47:19.813715: step 3322, loss 0.301422, acc 0.90625\n",
      "2018-05-04T14:47:21.005597: step 3323, loss 0.205694, acc 0.9375\n",
      "2018-05-04T14:47:22.161678: step 3324, loss 0.282136, acc 0.890625\n",
      "2018-05-04T14:47:23.283489: step 3325, loss 0.361824, acc 0.84375\n",
      "2018-05-04T14:47:24.422605: step 3326, loss 0.334469, acc 0.84375\n",
      "2018-05-04T14:47:25.566725: step 3327, loss 0.492933, acc 0.75\n",
      "2018-05-04T14:47:26.702301: step 3328, loss 0.423637, acc 0.875\n",
      "2018-05-04T14:47:27.838803: step 3329, loss 0.320227, acc 0.859375\n",
      "2018-05-04T14:47:28.982906: step 3330, loss 0.448961, acc 0.828125\n",
      "2018-05-04T14:47:30.117363: step 3331, loss 0.342967, acc 0.84375\n",
      "2018-05-04T14:47:31.302151: step 3332, loss 0.238328, acc 0.921875\n",
      "2018-05-04T14:47:32.442959: step 3333, loss 0.264026, acc 0.890625\n",
      "2018-05-04T14:47:33.590400: step 3334, loss 0.275204, acc 0.875\n",
      "2018-05-04T14:47:34.822302: step 3335, loss 0.33846, acc 0.828125\n",
      "2018-05-04T14:47:35.947249: step 3336, loss 0.219918, acc 0.90625\n",
      "2018-05-04T14:47:37.154059: step 3337, loss 0.304304, acc 0.875\n",
      "2018-05-04T14:47:38.339387: step 3338, loss 0.298182, acc 0.90625\n",
      "2018-05-04T14:47:39.441368: step 3339, loss 0.288358, acc 0.90625\n",
      "2018-05-04T14:47:40.526385: step 3340, loss 0.295383, acc 0.90625\n",
      "2018-05-04T14:47:41.760149: step 3341, loss 0.332497, acc 0.890625\n",
      "2018-05-04T14:47:42.867032: step 3342, loss 0.359062, acc 0.828125\n",
      "2018-05-04T14:47:43.943157: step 3343, loss 0.516804, acc 0.828125\n",
      "2018-05-04T14:47:45.055250: step 3344, loss 0.280493, acc 0.875\n",
      "2018-05-04T14:47:46.188038: step 3345, loss 0.180909, acc 0.9375\n",
      "2018-05-04T14:47:47.315792: step 3346, loss 0.314055, acc 0.875\n",
      "2018-05-04T14:47:48.450314: step 3347, loss 0.400987, acc 0.828125\n",
      "2018-05-04T14:47:49.579595: step 3348, loss 0.268843, acc 0.890625\n",
      "2018-05-04T14:47:50.730607: step 3349, loss 0.35454, acc 0.796875\n",
      "2018-05-04T14:47:51.898162: step 3350, loss 0.381248, acc 0.84375\n",
      "2018-05-04T14:47:53.033632: step 3351, loss 0.237716, acc 0.875\n",
      "2018-05-04T14:47:54.146691: step 3352, loss 0.264278, acc 0.890625\n",
      "2018-05-04T14:47:55.278099: step 3353, loss 0.501207, acc 0.78125\n",
      "2018-05-04T14:47:56.392590: step 3354, loss 0.21676, acc 0.90625\n",
      "2018-05-04T14:47:57.523069: step 3355, loss 0.338579, acc 0.890625\n",
      "2018-05-04T14:47:58.652753: step 3356, loss 0.247668, acc 0.890625\n",
      "2018-05-04T14:47:59.840774: step 3357, loss 0.222758, acc 0.921875\n",
      "2018-05-04T14:48:00.966410: step 3358, loss 0.307047, acc 0.921875\n",
      "2018-05-04T14:48:02.072184: step 3359, loss 0.275966, acc 0.921875\n",
      "2018-05-04T14:48:03.166966: step 3360, loss 0.41452, acc 0.78125\n",
      "2018-05-04T14:48:04.290170: step 3361, loss 0.249843, acc 0.890625\n",
      "2018-05-04T14:48:05.389762: step 3362, loss 0.308497, acc 0.84375\n",
      "2018-05-04T14:48:06.516742: step 3363, loss 0.265214, acc 0.90625\n",
      "2018-05-04T14:48:07.653929: step 3364, loss 0.407786, acc 0.8125\n",
      "2018-05-04T14:48:08.821239: step 3365, loss 0.253622, acc 0.921875\n",
      "2018-05-04T14:48:09.942123: step 3366, loss 0.235408, acc 0.90625\n",
      "2018-05-04T14:48:11.103709: step 3367, loss 0.37823, acc 0.90625\n",
      "2018-05-04T14:48:12.236761: step 3368, loss 0.270977, acc 0.890625\n",
      "2018-05-04T14:48:13.359292: step 3369, loss 0.292533, acc 0.859375\n",
      "2018-05-04T14:48:14.487343: step 3370, loss 0.293285, acc 0.859375\n",
      "2018-05-04T14:48:15.598791: step 3371, loss 0.233539, acc 0.90625\n",
      "2018-05-04T14:48:16.694994: step 3372, loss 0.306144, acc 0.875\n",
      "2018-05-04T14:48:17.774445: step 3373, loss 0.318133, acc 0.859375\n",
      "2018-05-04T14:48:18.868779: step 3374, loss 0.186033, acc 0.953125\n",
      "2018-05-04T14:48:19.950317: step 3375, loss 0.458922, acc 0.8125\n",
      "2018-05-04T14:48:21.112274: step 3376, loss 0.16076, acc 0.9375\n",
      "2018-05-04T14:48:22.227860: step 3377, loss 0.206719, acc 0.890625\n",
      "2018-05-04T14:48:23.350567: step 3378, loss 0.396841, acc 0.828125\n",
      "2018-05-04T14:48:24.538020: step 3379, loss 0.523731, acc 0.765625\n",
      "2018-05-04T14:48:25.660221: step 3380, loss 0.383981, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T14:48:26.775364: step 3381, loss 0.2981, acc 0.875\n",
      "2018-05-04T14:48:27.897504: step 3382, loss 0.27569, acc 0.875\n",
      "2018-05-04T14:48:29.021809: step 3383, loss 0.480394, acc 0.828125\n",
      "2018-05-04T14:48:30.154586: step 3384, loss 0.288207, acc 0.875\n",
      "2018-05-04T14:48:31.263516: step 3385, loss 0.255806, acc 0.953125\n",
      "2018-05-04T14:48:32.363529: step 3386, loss 0.366005, acc 0.859375\n",
      "2018-05-04T14:48:33.447606: step 3387, loss 0.442862, acc 0.796875\n",
      "2018-05-04T14:48:34.564540: step 3388, loss 0.295813, acc 0.859375\n",
      "2018-05-04T14:48:35.669845: step 3389, loss 0.287209, acc 0.890625\n",
      "2018-05-04T14:48:36.791558: step 3390, loss 0.296589, acc 0.890625\n",
      "2018-05-04T14:48:37.916565: step 3391, loss 0.36914, acc 0.890625\n",
      "2018-05-04T14:48:39.037962: step 3392, loss 0.243221, acc 0.84375\n",
      "2018-05-04T14:48:40.163700: step 3393, loss 0.316014, acc 0.859375\n",
      "2018-05-04T14:48:41.343486: step 3394, loss 0.270537, acc 0.90625\n",
      "2018-05-04T14:48:42.525062: step 3395, loss 0.413249, acc 0.828125\n",
      "2018-05-04T14:48:43.622791: step 3396, loss 0.242972, acc 0.875\n",
      "2018-05-04T14:48:44.730522: step 3397, loss 0.213068, acc 0.90625\n",
      "2018-05-04T14:48:45.873294: step 3398, loss 0.288389, acc 0.890625\n",
      "2018-05-04T14:48:46.963047: step 3399, loss 0.302433, acc 0.875\n",
      "2018-05-04T14:48:48.034359: step 3400, loss 0.377348, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T14:48:50.456161: step 3400, loss 0.284883, acc 0.884\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-3400\n",
      "\n",
      "2018-05-04T14:48:51.714121: step 3401, loss 0.237467, acc 0.90625\n",
      "2018-05-04T14:48:52.811476: step 3402, loss 0.23959, acc 0.90625\n",
      "2018-05-04T14:48:53.894056: step 3403, loss 0.273449, acc 0.90625\n",
      "2018-05-04T14:48:54.992131: step 3404, loss 0.339653, acc 0.84375\n",
      "2018-05-04T14:48:56.191306: step 3405, loss 0.22385, acc 0.90625\n",
      "2018-05-04T14:48:57.311549: step 3406, loss 0.340528, acc 0.890625\n",
      "2018-05-04T14:48:58.467313: step 3407, loss 0.350387, acc 0.859375\n",
      "2018-05-04T14:48:59.543500: step 3408, loss 0.328998, acc 0.828125\n",
      "2018-05-04T14:49:00.705564: step 3409, loss 0.369759, acc 0.875\n",
      "2018-05-04T14:49:01.906935: step 3410, loss 0.315474, acc 0.890625\n",
      "2018-05-04T14:49:02.981619: step 3411, loss 0.330527, acc 0.875\n",
      "2018-05-04T14:49:04.142672: step 3412, loss 0.305037, acc 0.890625\n",
      "2018-05-04T14:49:05.257645: step 3413, loss 0.302254, acc 0.859375\n",
      "2018-05-04T14:49:06.320925: step 3414, loss 0.272197, acc 0.90625\n",
      "2018-05-04T14:49:07.401090: step 3415, loss 0.365686, acc 0.8125\n",
      "2018-05-04T14:49:08.520375: step 3416, loss 0.368405, acc 0.828125\n",
      "2018-05-04T14:49:09.655935: step 3417, loss 0.33263, acc 0.859375\n",
      "2018-05-04T14:49:10.744839: step 3418, loss 0.2869, acc 0.859375\n",
      "2018-05-04T14:49:11.954251: step 3419, loss 0.229254, acc 0.921875\n",
      "2018-05-04T14:49:13.135973: step 3420, loss 0.544606, acc 0.8125\n",
      "2018-05-04T14:49:14.320213: step 3421, loss 0.343921, acc 0.875\n",
      "2018-05-04T14:49:15.502047: step 3422, loss 0.204566, acc 0.9375\n",
      "2018-05-04T14:49:16.615289: step 3423, loss 0.296528, acc 0.890625\n",
      "2018-05-04T14:49:17.722768: step 3424, loss 0.205984, acc 0.953125\n",
      "2018-05-04T14:49:18.809993: step 3425, loss 0.322305, acc 0.859375\n",
      "2018-05-04T14:49:19.901932: step 3426, loss 0.34887, acc 0.859375\n",
      "2018-05-04T14:49:21.051212: step 3427, loss 0.382042, acc 0.828125\n",
      "2018-05-04T14:49:22.226867: step 3428, loss 0.230501, acc 0.875\n",
      "2018-05-04T14:49:23.315109: step 3429, loss 0.295888, acc 0.921875\n",
      "2018-05-04T14:49:24.479057: step 3430, loss 0.348228, acc 0.890625\n",
      "2018-05-04T14:49:25.564295: step 3431, loss 0.246977, acc 0.921875\n",
      "2018-05-04T14:49:26.708324: step 3432, loss 0.333335, acc 0.859375\n",
      "2018-05-04T14:49:27.861901: step 3433, loss 0.343276, acc 0.890625\n",
      "2018-05-04T14:49:28.947796: step 3434, loss 0.397214, acc 0.796875\n",
      "2018-05-04T14:49:30.110011: step 3435, loss 0.297547, acc 0.875\n",
      "2018-05-04T14:49:31.307188: step 3436, loss 0.287578, acc 0.921875\n",
      "2018-05-04T14:49:32.391972: step 3437, loss 0.248934, acc 0.890625\n",
      "2018-05-04T14:49:33.582462: step 3438, loss 0.345273, acc 0.84375\n",
      "2018-05-04T14:49:34.794288: step 3439, loss 0.452311, acc 0.78125\n",
      "2018-05-04T14:49:35.999363: step 3440, loss 0.309008, acc 0.890625\n",
      "2018-05-04T14:49:37.203386: step 3441, loss 0.301502, acc 0.875\n",
      "2018-05-04T14:49:38.437070: step 3442, loss 0.350658, acc 0.84375\n",
      "2018-05-04T14:49:39.623579: step 3443, loss 0.327971, acc 0.828125\n",
      "2018-05-04T14:49:40.841920: step 3444, loss 0.245836, acc 0.921875\n",
      "2018-05-04T14:49:42.071470: step 3445, loss 0.338589, acc 0.828125\n",
      "2018-05-04T14:49:43.212608: step 3446, loss 0.255506, acc 0.9375\n",
      "2018-05-04T14:49:44.322945: step 3447, loss 0.288411, acc 0.921875\n",
      "2018-05-04T14:49:45.494227: step 3448, loss 0.368292, acc 0.8125\n",
      "2018-05-04T14:49:46.636011: step 3449, loss 0.199094, acc 0.9375\n",
      "2018-05-04T14:49:47.760043: step 3450, loss 0.381971, acc 0.796875\n",
      "2018-05-04T14:49:48.933649: step 3451, loss 0.40042, acc 0.84375\n",
      "2018-05-04T14:49:50.084763: step 3452, loss 0.209495, acc 0.890625\n",
      "2018-05-04T14:49:51.290996: step 3453, loss 0.190704, acc 0.90625\n",
      "2018-05-04T14:49:52.437395: step 3454, loss 0.288688, acc 0.859375\n",
      "2018-05-04T14:49:53.552218: step 3455, loss 0.306651, acc 0.859375\n",
      "2018-05-04T14:49:54.709084: step 3456, loss 0.227483, acc 0.90625\n",
      "2018-05-04T14:49:55.857649: step 3457, loss 0.340065, acc 0.828125\n",
      "2018-05-04T14:49:56.991324: step 3458, loss 0.302686, acc 0.859375\n",
      "2018-05-04T14:49:58.134709: step 3459, loss 0.265033, acc 0.921875\n",
      "2018-05-04T14:49:59.277903: step 3460, loss 0.260812, acc 0.875\n",
      "2018-05-04T14:50:00.410880: step 3461, loss 0.310975, acc 0.875\n",
      "2018-05-04T14:50:01.620918: step 3462, loss 0.282936, acc 0.890625\n",
      "2018-05-04T14:50:02.759377: step 3463, loss 0.423109, acc 0.78125\n",
      "2018-05-04T14:50:03.920638: step 3464, loss 0.273664, acc 0.875\n",
      "2018-05-04T14:50:05.088909: step 3465, loss 0.447855, acc 0.78125\n",
      "2018-05-04T14:50:06.242796: step 3466, loss 0.527881, acc 0.71875\n",
      "2018-05-04T14:50:07.388213: step 3467, loss 0.321903, acc 0.84375\n",
      "2018-05-04T14:50:08.504637: step 3468, loss 0.348584, acc 0.828125\n",
      "2018-05-04T14:50:09.642501: step 3469, loss 0.229777, acc 0.890625\n",
      "2018-05-04T14:50:10.806772: step 3470, loss 0.329688, acc 0.890625\n",
      "2018-05-04T14:50:11.990626: step 3471, loss 0.252522, acc 0.875\n",
      "2018-05-04T14:50:13.143256: step 3472, loss 0.251054, acc 0.953125\n",
      "2018-05-04T14:50:14.294160: step 3473, loss 0.205018, acc 0.9375\n",
      "2018-05-04T14:50:15.395329: step 3474, loss 0.170946, acc 0.921875\n",
      "2018-05-04T14:50:16.528092: step 3475, loss 0.234231, acc 0.890625\n",
      "2018-05-04T14:50:17.656837: step 3476, loss 0.197642, acc 0.890625\n",
      "2018-05-04T14:50:18.794054: step 3477, loss 0.328369, acc 0.859375\n",
      "2018-05-04T14:50:19.940264: step 3478, loss 0.438484, acc 0.84375\n",
      "2018-05-04T14:50:21.109872: step 3479, loss 0.38965, acc 0.875\n",
      "2018-05-04T14:50:22.274305: step 3480, loss 0.267155, acc 0.890625\n",
      "2018-05-04T14:50:23.338523: step 3481, loss 0.280328, acc 0.84375\n",
      "2018-05-04T14:50:24.492647: step 3482, loss 0.329758, acc 0.84375\n",
      "2018-05-04T14:50:25.592072: step 3483, loss 0.311672, acc 0.890625\n",
      "2018-05-04T14:50:26.739910: step 3484, loss 0.323526, acc 0.84375\n",
      "2018-05-04T14:50:27.886894: step 3485, loss 0.30597, acc 0.84375\n",
      "2018-05-04T14:50:29.052274: step 3486, loss 0.436634, acc 0.78125\n",
      "2018-05-04T14:50:30.198007: step 3487, loss 0.302289, acc 0.84375\n",
      "2018-05-04T14:50:31.373402: step 3488, loss 0.251654, acc 0.890625\n",
      "2018-05-04T14:50:32.536451: step 3489, loss 0.276797, acc 0.875\n",
      "2018-05-04T14:50:33.667956: step 3490, loss 0.335443, acc 0.859375\n",
      "2018-05-04T14:50:34.826308: step 3491, loss 0.335068, acc 0.828125\n",
      "2018-05-04T14:50:35.931403: step 3492, loss 0.460585, acc 0.84375\n",
      "2018-05-04T14:50:37.050533: step 3493, loss 0.281102, acc 0.90625\n",
      "2018-05-04T14:50:38.211567: step 3494, loss 0.304346, acc 0.859375\n",
      "2018-05-04T14:50:39.383997: step 3495, loss 0.231667, acc 0.890625\n",
      "2018-05-04T14:50:40.525103: step 3496, loss 0.364605, acc 0.84375\n",
      "2018-05-04T14:50:41.751818: step 3497, loss 0.296889, acc 0.84375\n",
      "2018-05-04T14:50:42.862045: step 3498, loss 0.482877, acc 0.765625\n",
      "2018-05-04T14:50:43.956357: step 3499, loss 0.455319, acc 0.765625\n",
      "2018-05-04T14:50:45.063108: step 3500, loss 0.448227, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T14:50:47.585808: step 3500, loss 0.271848, acc 0.888\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-3500\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T14:50:48.865692: step 3501, loss 0.300076, acc 0.921875\n",
      "2018-05-04T14:50:50.065141: step 3502, loss 0.242278, acc 0.921875\n",
      "2018-05-04T14:50:51.280625: step 3503, loss 0.305238, acc 0.84375\n",
      "2018-05-04T14:50:52.397864: step 3504, loss 0.303536, acc 0.859375\n",
      "2018-05-04T14:50:53.534902: step 3505, loss 0.294472, acc 0.859375\n",
      "2018-05-04T14:50:54.676241: step 3506, loss 0.327886, acc 0.84375\n",
      "2018-05-04T14:50:55.797748: step 3507, loss 0.255485, acc 0.875\n",
      "2018-05-04T14:50:56.940789: step 3508, loss 0.484244, acc 0.75\n",
      "2018-05-04T14:50:58.037545: step 3509, loss 0.398232, acc 0.78125\n",
      "2018-05-04T14:50:59.146957: step 3510, loss 0.43669, acc 0.828125\n",
      "2018-05-04T14:51:00.238654: step 3511, loss 0.356581, acc 0.84375\n",
      "2018-05-04T14:51:01.392152: step 3512, loss 0.392947, acc 0.84375\n",
      "2018-05-04T14:51:02.488407: step 3513, loss 0.22178, acc 0.953125\n",
      "2018-05-04T14:51:03.705014: step 3514, loss 0.327122, acc 0.828125\n",
      "2018-05-04T14:51:04.918612: step 3515, loss 0.272876, acc 0.875\n",
      "2018-05-04T14:51:05.996946: step 3516, loss 0.19141, acc 0.90625\n",
      "2018-05-04T14:51:07.116901: step 3517, loss 0.317401, acc 0.890625\n",
      "2018-05-04T14:51:08.226830: step 3518, loss 0.353104, acc 0.859375\n",
      "2018-05-04T14:51:09.337267: step 3519, loss 0.313313, acc 0.890625\n",
      "2018-05-04T14:51:10.444721: step 3520, loss 0.403294, acc 0.859375\n",
      "2018-05-04T14:51:11.638365: step 3521, loss 0.333691, acc 0.890625\n",
      "2018-05-04T14:51:12.762265: step 3522, loss 0.243494, acc 0.90625\n",
      "2018-05-04T14:51:13.986232: step 3523, loss 0.362646, acc 0.890625\n",
      "2018-05-04T14:51:15.185307: step 3524, loss 0.313964, acc 0.84375\n",
      "2018-05-04T14:51:16.291822: step 3525, loss 0.274979, acc 0.890625\n",
      "2018-05-04T14:51:17.392490: step 3526, loss 0.314093, acc 0.84375\n",
      "2018-05-04T14:51:18.501726: step 3527, loss 0.268939, acc 0.859375\n",
      "2018-05-04T14:51:19.644865: step 3528, loss 0.240544, acc 0.890625\n",
      "2018-05-04T14:51:20.803005: step 3529, loss 0.322147, acc 0.875\n",
      "2018-05-04T14:51:21.950865: step 3530, loss 0.305078, acc 0.84375\n",
      "2018-05-04T14:51:23.099112: step 3531, loss 0.289963, acc 0.875\n",
      "2018-05-04T14:51:24.219526: step 3532, loss 0.317256, acc 0.84375\n",
      "2018-05-04T14:51:25.400971: step 3533, loss 0.365713, acc 0.859375\n",
      "2018-05-04T14:51:26.526605: step 3534, loss 0.293053, acc 0.890625\n",
      "2018-05-04T14:51:27.645415: step 3535, loss 0.376492, acc 0.859375\n",
      "2018-05-04T14:51:28.794651: step 3536, loss 0.359354, acc 0.84375\n",
      "2018-05-04T14:51:29.898426: step 3537, loss 0.360985, acc 0.84375\n",
      "2018-05-04T14:51:31.045978: step 3538, loss 0.234528, acc 0.90625\n",
      "2018-05-04T14:51:32.147768: step 3539, loss 0.35258, acc 0.84375\n",
      "2018-05-04T14:51:33.221903: step 3540, loss 0.463792, acc 0.75\n",
      "2018-05-04T14:51:34.358743: step 3541, loss 0.215431, acc 0.90625\n",
      "2018-05-04T14:51:35.483797: step 3542, loss 0.305505, acc 0.890625\n",
      "2018-05-04T14:51:36.611694: step 3543, loss 0.215826, acc 0.90625\n",
      "2018-05-04T14:51:37.780876: step 3544, loss 0.374668, acc 0.84375\n",
      "2018-05-04T14:51:38.935493: step 3545, loss 0.347389, acc 0.859375\n",
      "2018-05-04T14:51:40.047790: step 3546, loss 0.204366, acc 0.9375\n",
      "2018-05-04T14:51:41.230372: step 3547, loss 0.299367, acc 0.84375\n",
      "2018-05-04T14:51:42.377609: step 3548, loss 0.332053, acc 0.828125\n",
      "2018-05-04T14:51:43.491633: step 3549, loss 0.33374, acc 0.890625\n",
      "2018-05-04T14:51:44.628141: step 3550, loss 0.228673, acc 0.921875\n",
      "2018-05-04T14:51:45.770358: step 3551, loss 0.324458, acc 0.859375\n",
      "2018-05-04T14:51:46.899927: step 3552, loss 0.596426, acc 0.796875\n",
      "2018-05-04T14:51:48.014991: step 3553, loss 0.307672, acc 0.828125\n",
      "2018-05-04T14:51:49.158803: step 3554, loss 0.394913, acc 0.84375\n",
      "2018-05-04T14:51:50.282945: step 3555, loss 0.340066, acc 0.875\n",
      "2018-05-04T14:51:51.478951: step 3556, loss 0.351585, acc 0.875\n",
      "2018-05-04T14:51:52.588467: step 3557, loss 0.367051, acc 0.84375\n",
      "2018-05-04T14:51:53.764993: step 3558, loss 0.384674, acc 0.8125\n",
      "2018-05-04T14:51:54.856749: step 3559, loss 0.296899, acc 0.84375\n",
      "2018-05-04T14:51:55.958715: step 3560, loss 0.301067, acc 0.90625\n",
      "2018-05-04T14:51:57.042467: step 3561, loss 0.300642, acc 0.875\n",
      "2018-05-04T14:51:58.128197: step 3562, loss 0.320838, acc 0.875\n",
      "2018-05-04T14:51:59.243663: step 3563, loss 0.287955, acc 0.84375\n",
      "2018-05-04T14:52:00.379574: step 3564, loss 0.477451, acc 0.796875\n",
      "2018-05-04T14:52:01.583306: step 3565, loss 0.364294, acc 0.890625\n",
      "2018-05-04T14:52:02.701642: step 3566, loss 0.238655, acc 0.9375\n",
      "2018-05-04T14:52:03.818293: step 3567, loss 0.279243, acc 0.875\n",
      "2018-05-04T14:52:04.977704: step 3568, loss 0.257868, acc 0.921875\n",
      "2018-05-04T14:52:06.185253: step 3569, loss 0.376347, acc 0.8125\n",
      "2018-05-04T14:52:07.313270: step 3570, loss 0.446824, acc 0.734375\n",
      "2018-05-04T14:52:08.464518: step 3571, loss 0.302171, acc 0.90625\n",
      "2018-05-04T14:52:09.625102: step 3572, loss 0.327598, acc 0.859375\n",
      "2018-05-04T14:52:10.761072: step 3573, loss 0.241069, acc 0.921875\n",
      "2018-05-04T14:52:11.918785: step 3574, loss 0.244348, acc 0.890625\n",
      "2018-05-04T14:52:13.039087: step 3575, loss 0.300721, acc 0.90625\n",
      "2018-05-04T14:52:14.153214: step 3576, loss 0.270243, acc 0.875\n",
      "2018-05-04T14:52:15.347982: step 3577, loss 0.373166, acc 0.8125\n",
      "2018-05-04T14:52:16.442763: step 3578, loss 0.32673, acc 0.875\n",
      "2018-05-04T14:52:17.567856: step 3579, loss 0.215737, acc 0.90625\n",
      "2018-05-04T14:52:18.695585: step 3580, loss 0.324835, acc 0.859375\n",
      "2018-05-04T14:52:19.832273: step 3581, loss 0.37922, acc 0.859375\n",
      "2018-05-04T14:52:21.003340: step 3582, loss 0.250103, acc 0.921875\n",
      "2018-05-04T14:52:22.208391: step 3583, loss 0.39796, acc 0.875\n",
      "2018-05-04T14:52:23.289205: step 3584, loss 0.246341, acc 0.890625\n",
      "2018-05-04T14:52:24.448984: step 3585, loss 0.305564, acc 0.859375\n",
      "2018-05-04T14:52:25.517935: step 3586, loss 0.30436, acc 0.890625\n",
      "2018-05-04T14:52:26.613638: step 3587, loss 0.264045, acc 0.890625\n",
      "2018-05-04T14:52:27.701143: step 3588, loss 0.237973, acc 0.921875\n",
      "2018-05-04T14:52:28.785935: step 3589, loss 0.364464, acc 0.796875\n",
      "2018-05-04T14:52:29.890481: step 3590, loss 0.333815, acc 0.859375\n",
      "2018-05-04T14:52:31.086840: step 3591, loss 0.403488, acc 0.859375\n",
      "2018-05-04T14:52:32.283923: step 3592, loss 0.405654, acc 0.84375\n",
      "2018-05-04T14:52:33.529149: step 3593, loss 0.251133, acc 0.875\n",
      "2018-05-04T14:52:34.830853: step 3594, loss 0.411408, acc 0.84375\n",
      "2018-05-04T14:52:36.042788: step 3595, loss 0.243489, acc 0.921875\n",
      "2018-05-04T14:52:37.272355: step 3596, loss 0.321002, acc 0.84375\n",
      "2018-05-04T14:52:38.405662: step 3597, loss 0.264158, acc 0.90625\n",
      "2018-05-04T14:52:39.505111: step 3598, loss 0.307207, acc 0.84375\n",
      "2018-05-04T14:52:40.611229: step 3599, loss 0.26739, acc 0.90625\n",
      "2018-05-04T14:52:41.816898: step 3600, loss 0.252391, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T14:52:44.858075: step 3600, loss 0.260162, acc 0.902\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-3600\n",
      "\n",
      "2018-05-04T14:52:46.135909: step 3601, loss 0.281733, acc 0.875\n",
      "2018-05-04T14:52:47.310879: step 3602, loss 0.355859, acc 0.875\n",
      "2018-05-04T14:52:48.480769: step 3603, loss 0.250252, acc 0.890625\n",
      "2018-05-04T14:52:49.655863: step 3604, loss 0.295716, acc 0.875\n",
      "2018-05-04T14:52:50.907577: step 3605, loss 0.378628, acc 0.84375\n",
      "2018-05-04T14:52:52.109907: step 3606, loss 0.267508, acc 0.890625\n",
      "2018-05-04T14:52:53.273717: step 3607, loss 0.419497, acc 0.8125\n",
      "2018-05-04T14:52:54.378092: step 3608, loss 0.35264, acc 0.875\n",
      "2018-05-04T14:52:55.462386: step 3609, loss 0.334119, acc 0.828125\n",
      "2018-05-04T14:52:56.565581: step 3610, loss 0.206406, acc 0.921875\n",
      "2018-05-04T14:52:57.663833: step 3611, loss 0.252816, acc 0.890625\n",
      "2018-05-04T14:52:58.764841: step 3612, loss 0.317115, acc 0.84375\n",
      "2018-05-04T14:52:59.894561: step 3613, loss 0.37306, acc 0.875\n",
      "2018-05-04T14:53:01.037581: step 3614, loss 0.400598, acc 0.796875\n",
      "2018-05-04T14:53:02.144420: step 3615, loss 0.205788, acc 0.875\n",
      "2018-05-04T14:53:03.230371: step 3616, loss 0.264217, acc 0.90625\n",
      "2018-05-04T14:53:04.348966: step 3617, loss 0.336963, acc 0.859375\n",
      "2018-05-04T14:53:05.469960: step 3618, loss 0.329459, acc 0.859375\n",
      "2018-05-04T14:53:06.608593: step 3619, loss 0.322408, acc 0.875\n",
      "2018-05-04T14:53:07.735847: step 3620, loss 0.219629, acc 0.90625\n",
      "2018-05-04T14:53:08.830532: step 3621, loss 0.404899, acc 0.8125\n",
      "2018-05-04T14:53:09.966020: step 3622, loss 0.424329, acc 0.796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T14:53:11.154201: step 3623, loss 0.270084, acc 0.890625\n",
      "2018-05-04T14:53:12.294698: step 3624, loss 0.363579, acc 0.8125\n",
      "2018-05-04T14:53:13.392867: step 3625, loss 0.337294, acc 0.875\n",
      "2018-05-04T14:53:14.583543: step 3626, loss 0.213525, acc 0.9375\n",
      "2018-05-04T14:53:15.669771: step 3627, loss 0.174021, acc 0.9375\n",
      "2018-05-04T14:53:16.838217: step 3628, loss 0.316485, acc 0.890625\n",
      "2018-05-04T14:53:17.935370: step 3629, loss 0.287625, acc 0.875\n",
      "2018-05-04T14:53:19.016633: step 3630, loss 0.409648, acc 0.828125\n",
      "2018-05-04T14:53:20.129296: step 3631, loss 0.222499, acc 0.90625\n",
      "2018-05-04T14:53:21.293336: step 3632, loss 0.308455, acc 0.84375\n",
      "2018-05-04T14:53:22.471076: step 3633, loss 0.257414, acc 0.921875\n",
      "2018-05-04T14:53:23.550667: step 3634, loss 0.28571, acc 0.84375\n",
      "2018-05-04T14:53:24.667589: step 3635, loss 0.361109, acc 0.84375\n",
      "2018-05-04T14:53:25.787047: step 3636, loss 0.213188, acc 0.953125\n",
      "2018-05-04T14:53:26.891403: step 3637, loss 0.270336, acc 0.859375\n",
      "2018-05-04T14:53:28.050097: step 3638, loss 0.321515, acc 0.875\n",
      "2018-05-04T14:53:29.156118: step 3639, loss 0.32941, acc 0.84375\n",
      "2018-05-04T14:53:30.239230: step 3640, loss 0.300983, acc 0.859375\n",
      "2018-05-04T14:53:31.394989: step 3641, loss 0.338251, acc 0.8125\n",
      "2018-05-04T14:53:32.589597: step 3642, loss 0.321763, acc 0.859375\n",
      "2018-05-04T14:53:33.744010: step 3643, loss 0.407949, acc 0.828125\n",
      "2018-05-04T14:53:34.869524: step 3644, loss 0.286259, acc 0.84375\n",
      "2018-05-04T14:53:35.996450: step 3645, loss 0.256372, acc 0.90625\n",
      "2018-05-04T14:53:37.194459: step 3646, loss 0.41843, acc 0.765625\n",
      "2018-05-04T14:53:38.411492: step 3647, loss 0.329036, acc 0.875\n",
      "2018-05-04T14:53:39.541318: step 3648, loss 0.32982, acc 0.796875\n",
      "2018-05-04T14:53:40.627158: step 3649, loss 0.406414, acc 0.796875\n",
      "2018-05-04T14:53:41.760909: step 3650, loss 0.271116, acc 0.890625\n",
      "2018-05-04T14:53:42.927233: step 3651, loss 0.566865, acc 0.828125\n",
      "2018-05-04T14:53:44.002772: step 3652, loss 0.302877, acc 0.875\n",
      "2018-05-04T14:53:45.114201: step 3653, loss 0.218157, acc 0.9375\n",
      "2018-05-04T14:53:46.211111: step 3654, loss 0.27553, acc 0.890625\n",
      "2018-05-04T14:53:47.407020: step 3655, loss 0.484684, acc 0.78125\n",
      "2018-05-04T14:53:48.538038: step 3656, loss 0.293931, acc 0.890625\n",
      "2018-05-04T14:53:49.667100: step 3657, loss 0.273843, acc 0.90625\n",
      "2018-05-04T14:53:50.889257: step 3658, loss 0.551873, acc 0.8125\n",
      "2018-05-04T14:53:52.111978: step 3659, loss 0.269845, acc 0.890625\n",
      "2018-05-04T14:53:53.224286: step 3660, loss 0.296871, acc 0.84375\n",
      "2018-05-04T14:53:54.323270: step 3661, loss 0.299465, acc 0.859375\n",
      "2018-05-04T14:53:55.406807: step 3662, loss 0.2774, acc 0.890625\n",
      "2018-05-04T14:53:56.490101: step 3663, loss 0.198917, acc 0.921875\n",
      "2018-05-04T14:53:57.654918: step 3664, loss 0.3258, acc 0.84375\n",
      "2018-05-04T14:53:58.738297: step 3665, loss 0.407749, acc 0.828125\n",
      "2018-05-04T14:53:59.850484: step 3666, loss 0.205574, acc 0.921875\n",
      "2018-05-04T14:54:01.014512: step 3667, loss 0.245527, acc 0.90625\n",
      "2018-05-04T14:54:02.161932: step 3668, loss 0.295884, acc 0.90625\n",
      "2018-05-04T14:54:03.341914: step 3669, loss 0.320434, acc 0.90625\n",
      "2018-05-04T14:54:04.482586: step 3670, loss 0.321551, acc 0.84375\n",
      "2018-05-04T14:54:05.619404: step 3671, loss 0.37912, acc 0.828125\n",
      "2018-05-04T14:54:06.813129: step 3672, loss 0.278816, acc 0.890625\n",
      "2018-05-04T14:54:07.931084: step 3673, loss 0.280032, acc 0.921875\n",
      "2018-05-04T14:54:09.038865: step 3674, loss 0.296186, acc 0.875\n",
      "2018-05-04T14:54:10.175966: step 3675, loss 0.50844, acc 0.78125\n",
      "2018-05-04T14:54:11.364000: step 3676, loss 0.279317, acc 0.890625\n",
      "2018-05-04T14:54:12.549285: step 3677, loss 0.353608, acc 0.828125\n",
      "2018-05-04T14:54:13.686642: step 3678, loss 0.314274, acc 0.84375\n",
      "2018-05-04T14:54:14.814484: step 3679, loss 0.290765, acc 0.875\n",
      "2018-05-04T14:54:15.981863: step 3680, loss 0.209865, acc 0.9375\n",
      "2018-05-04T14:54:17.146682: step 3681, loss 0.32572, acc 0.859375\n",
      "2018-05-04T14:54:18.286381: step 3682, loss 0.423333, acc 0.859375\n",
      "2018-05-04T14:54:19.375983: step 3683, loss 0.47774, acc 0.78125\n",
      "2018-05-04T14:54:20.476934: step 3684, loss 0.299125, acc 0.875\n",
      "2018-05-04T14:54:21.662255: step 3685, loss 0.315714, acc 0.890625\n",
      "2018-05-04T14:54:22.762045: step 3686, loss 0.528512, acc 0.796875\n",
      "2018-05-04T14:54:23.876985: step 3687, loss 0.303657, acc 0.875\n",
      "2018-05-04T14:54:25.010949: step 3688, loss 0.198875, acc 0.921875\n",
      "2018-05-04T14:54:26.131775: step 3689, loss 0.341627, acc 0.859375\n",
      "2018-05-04T14:54:27.328430: step 3690, loss 0.411879, acc 0.84375\n",
      "2018-05-04T14:54:28.431437: step 3691, loss 0.398536, acc 0.875\n",
      "2018-05-04T14:54:29.568354: step 3692, loss 0.279937, acc 0.875\n",
      "2018-05-04T14:54:30.702974: step 3693, loss 0.378035, acc 0.8125\n",
      "2018-05-04T14:54:31.866672: step 3694, loss 0.255798, acc 0.859375\n",
      "2018-05-04T14:54:32.965020: step 3695, loss 0.246894, acc 0.890625\n",
      "2018-05-04T14:54:34.102835: step 3696, loss 0.235197, acc 0.875\n",
      "2018-05-04T14:54:35.236856: step 3697, loss 0.22399, acc 0.921875\n",
      "2018-05-04T14:54:36.354405: step 3698, loss 0.38607, acc 0.84375\n",
      "2018-05-04T14:54:37.479084: step 3699, loss 0.459649, acc 0.796875\n",
      "2018-05-04T14:54:38.610269: step 3700, loss 0.342371, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T14:54:41.535579: step 3700, loss 0.282296, acc 0.882\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-3700\n",
      "\n",
      "2018-05-04T14:54:42.787273: step 3701, loss 0.275821, acc 0.890625\n",
      "2018-05-04T14:54:43.949072: step 3702, loss 0.249021, acc 0.9375\n",
      "2018-05-04T14:54:45.205999: step 3703, loss 0.264546, acc 0.921875\n",
      "2018-05-04T14:54:46.308452: step 3704, loss 0.322527, acc 0.859375\n",
      "2018-05-04T14:54:47.396156: step 3705, loss 0.398401, acc 0.84375\n",
      "2018-05-04T14:54:48.491316: step 3706, loss 0.363399, acc 0.875\n",
      "2018-05-04T14:54:49.674131: step 3707, loss 0.349842, acc 0.8125\n",
      "2018-05-04T14:54:50.810975: step 3708, loss 0.336625, acc 0.859375\n",
      "2018-05-04T14:54:51.940478: step 3709, loss 0.284488, acc 0.90625\n",
      "2018-05-04T14:54:53.030320: step 3710, loss 0.378689, acc 0.828125\n",
      "2018-05-04T14:54:54.224917: step 3711, loss 0.363353, acc 0.78125\n",
      "2018-05-04T14:54:55.374617: step 3712, loss 0.249369, acc 0.890625\n",
      "2018-05-04T14:54:56.476611: step 3713, loss 0.371399, acc 0.828125\n",
      "2018-05-04T14:54:57.569182: step 3714, loss 0.435932, acc 0.828125\n",
      "2018-05-04T14:54:58.670642: step 3715, loss 0.361204, acc 0.84375\n",
      "2018-05-04T14:54:59.757887: step 3716, loss 0.366404, acc 0.90625\n",
      "2018-05-04T14:55:00.940070: step 3717, loss 0.410354, acc 0.828125\n",
      "2018-05-04T14:55:02.083873: step 3718, loss 0.197975, acc 0.9375\n",
      "2018-05-04T14:55:03.204058: step 3719, loss 0.297148, acc 0.859375\n",
      "2018-05-04T14:55:04.349793: step 3720, loss 0.341432, acc 0.84375\n",
      "2018-05-04T14:55:05.511357: step 3721, loss 0.247197, acc 0.921875\n",
      "2018-05-04T14:55:06.642614: step 3722, loss 0.302965, acc 0.890625\n",
      "2018-05-04T14:55:07.772781: step 3723, loss 0.318624, acc 0.9375\n",
      "2018-05-04T14:55:08.894985: step 3724, loss 0.361558, acc 0.828125\n",
      "2018-05-04T14:55:10.074454: step 3725, loss 0.308765, acc 0.90625\n",
      "2018-05-04T14:55:11.274573: step 3726, loss 0.236765, acc 0.90625\n",
      "2018-05-04T14:55:12.479523: step 3727, loss 0.277656, acc 0.921875\n",
      "2018-05-04T14:55:13.610935: step 3728, loss 0.331574, acc 0.875\n",
      "2018-05-04T14:55:14.787865: step 3729, loss 0.185837, acc 0.90625\n",
      "2018-05-04T14:55:15.882940: step 3730, loss 0.366658, acc 0.8125\n",
      "2018-05-04T14:55:17.063419: step 3731, loss 0.176255, acc 0.921875\n",
      "2018-05-04T14:55:18.147705: step 3732, loss 0.296879, acc 0.890625\n",
      "2018-05-04T14:55:19.285893: step 3733, loss 0.216316, acc 0.9375\n",
      "2018-05-04T14:55:20.392829: step 3734, loss 0.324466, acc 0.875\n",
      "2018-05-04T14:55:21.580808: step 3735, loss 0.19747, acc 0.921875\n",
      "2018-05-04T14:55:22.754441: step 3736, loss 0.292587, acc 0.90625\n",
      "2018-05-04T14:55:23.967609: step 3737, loss 0.233632, acc 0.890625\n",
      "2018-05-04T14:55:25.163843: step 3738, loss 0.290925, acc 0.875\n",
      "2018-05-04T14:55:26.298792: step 3739, loss 0.323327, acc 0.828125\n",
      "2018-05-04T14:55:27.444108: step 3740, loss 0.404152, acc 0.875\n",
      "2018-05-04T14:55:28.569631: step 3741, loss 0.262885, acc 0.859375\n",
      "2018-05-04T14:55:29.694020: step 3742, loss 0.32407, acc 0.90625\n",
      "2018-05-04T14:55:30.813628: step 3743, loss 0.350859, acc 0.84375\n",
      "2018-05-04T14:55:31.979505: step 3744, loss 0.309145, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T14:55:33.154377: step 3745, loss 0.333672, acc 0.875\n",
      "2018-05-04T14:55:34.368825: step 3746, loss 0.34278, acc 0.875\n",
      "2018-05-04T14:55:35.600031: step 3747, loss 0.312911, acc 0.890625\n",
      "2018-05-04T14:55:36.855252: step 3748, loss 0.190509, acc 0.9375\n",
      "2018-05-04T14:55:38.088867: step 3749, loss 0.315283, acc 0.875\n",
      "2018-05-04T14:55:39.242916: step 3750, loss 0.333599, acc 0.84375\n",
      "2018-05-04T14:55:40.410883: step 3751, loss 0.340164, acc 0.859375\n",
      "2018-05-04T14:55:41.654319: step 3752, loss 0.282823, acc 0.875\n",
      "2018-05-04T14:55:42.821027: step 3753, loss 0.287978, acc 0.890625\n",
      "2018-05-04T14:55:43.965721: step 3754, loss 0.180881, acc 0.9375\n",
      "2018-05-04T14:55:45.099822: step 3755, loss 0.329066, acc 0.84375\n",
      "2018-05-04T14:55:46.207101: step 3756, loss 0.232237, acc 0.90625\n",
      "2018-05-04T14:55:47.325814: step 3757, loss 0.273178, acc 0.90625\n",
      "2018-05-04T14:55:48.447751: step 3758, loss 0.217209, acc 0.9375\n",
      "2018-05-04T14:55:49.579263: step 3759, loss 0.500887, acc 0.828125\n",
      "2018-05-04T14:55:50.723451: step 3760, loss 0.322434, acc 0.84375\n",
      "2018-05-04T14:55:51.897860: step 3761, loss 0.352958, acc 0.875\n",
      "2018-05-04T14:55:53.089783: step 3762, loss 0.343779, acc 0.84375\n",
      "2018-05-04T14:55:54.225607: step 3763, loss 0.301024, acc 0.90625\n",
      "2018-05-04T14:55:55.381094: step 3764, loss 0.315382, acc 0.890625\n",
      "2018-05-04T14:55:56.494213: step 3765, loss 0.364877, acc 0.78125\n",
      "2018-05-04T14:55:57.639908: step 3766, loss 0.376703, acc 0.84375\n",
      "2018-05-04T14:55:58.777693: step 3767, loss 0.315145, acc 0.84375\n",
      "2018-05-04T14:55:59.917858: step 3768, loss 0.285792, acc 0.84375\n",
      "2018-05-04T14:56:01.086402: step 3769, loss 0.2876, acc 0.859375\n",
      "2018-05-04T14:56:02.221914: step 3770, loss 0.243087, acc 0.890625\n",
      "2018-05-04T14:56:03.358565: step 3771, loss 0.387841, acc 0.859375\n",
      "2018-05-04T14:56:04.546788: step 3772, loss 0.332566, acc 0.84375\n",
      "2018-05-04T14:56:05.709091: step 3773, loss 0.342039, acc 0.8125\n",
      "2018-05-04T14:56:06.860464: step 3774, loss 0.356385, acc 0.890625\n",
      "2018-05-04T14:56:08.026469: step 3775, loss 0.280936, acc 0.9375\n",
      "2018-05-04T14:56:09.203446: step 3776, loss 0.341116, acc 0.859375\n",
      "2018-05-04T14:56:10.373372: step 3777, loss 0.284775, acc 0.890625\n",
      "2018-05-04T14:56:11.565730: step 3778, loss 0.232447, acc 0.90625\n",
      "2018-05-04T14:56:12.672808: step 3779, loss 0.344154, acc 0.84375\n",
      "2018-05-04T14:56:13.784074: step 3780, loss 0.362442, acc 0.84375\n",
      "2018-05-04T14:56:14.976008: step 3781, loss 0.279004, acc 0.921875\n",
      "2018-05-04T14:56:16.145971: step 3782, loss 0.333746, acc 0.890625\n",
      "2018-05-04T14:56:17.269789: step 3783, loss 0.381777, acc 0.828125\n",
      "2018-05-04T14:56:18.389427: step 3784, loss 0.36948, acc 0.90625\n",
      "2018-05-04T14:56:19.521053: step 3785, loss 0.281341, acc 0.875\n",
      "2018-05-04T14:56:20.666540: step 3786, loss 0.325278, acc 0.90625\n",
      "2018-05-04T14:56:21.879461: step 3787, loss 0.194013, acc 0.953125\n",
      "2018-05-04T14:56:22.986159: step 3788, loss 0.318663, acc 0.828125\n",
      "2018-05-04T14:56:24.099616: step 3789, loss 0.271981, acc 0.875\n",
      "2018-05-04T14:56:25.230656: step 3790, loss 0.370891, acc 0.828125\n",
      "2018-05-04T14:56:26.354942: step 3791, loss 0.21742, acc 0.921875\n",
      "2018-05-04T14:56:27.471771: step 3792, loss 0.187306, acc 0.921875\n",
      "2018-05-04T14:56:28.588052: step 3793, loss 0.275158, acc 0.90625\n",
      "2018-05-04T14:56:29.744035: step 3794, loss 0.328054, acc 0.875\n",
      "2018-05-04T14:56:30.882636: step 3795, loss 0.25544, acc 0.921875\n",
      "2018-05-04T14:56:32.067083: step 3796, loss 0.296983, acc 0.875\n",
      "2018-05-04T14:56:33.270600: step 3797, loss 0.417291, acc 0.84375\n",
      "2018-05-04T14:56:34.528417: step 3798, loss 0.30426, acc 0.890625\n",
      "2018-05-04T14:56:35.648294: step 3799, loss 0.258997, acc 0.890625\n",
      "2018-05-04T14:56:36.772409: step 3800, loss 0.257944, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T14:56:39.526638: step 3800, loss 0.269873, acc 0.896\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-3800\n",
      "\n",
      "2018-05-04T14:56:40.798385: step 3801, loss 0.307847, acc 0.875\n",
      "2018-05-04T14:56:42.054616: step 3802, loss 0.318728, acc 0.859375\n",
      "2018-05-04T14:56:43.227445: step 3803, loss 0.324481, acc 0.859375\n",
      "2018-05-04T14:56:44.392707: step 3804, loss 0.284243, acc 0.890625\n",
      "2018-05-04T14:56:45.549506: step 3805, loss 0.283001, acc 0.890625\n",
      "2018-05-04T14:56:46.690645: step 3806, loss 0.304578, acc 0.84375\n",
      "2018-05-04T14:56:47.819922: step 3807, loss 0.196417, acc 0.890625\n",
      "2018-05-04T14:56:48.940499: step 3808, loss 0.314262, acc 0.84375\n",
      "2018-05-04T14:56:50.070141: step 3809, loss 0.237861, acc 0.9375\n",
      "2018-05-04T14:56:51.352628: step 3810, loss 0.230158, acc 0.890625\n",
      "2018-05-04T14:56:52.468740: step 3811, loss 0.146985, acc 0.96875\n",
      "2018-05-04T14:56:53.612807: step 3812, loss 0.229111, acc 0.9375\n",
      "2018-05-04T14:56:54.796815: step 3813, loss 0.198988, acc 0.890625\n",
      "2018-05-04T14:56:55.892255: step 3814, loss 0.2601, acc 0.890625\n",
      "2018-05-04T14:56:57.038714: step 3815, loss 0.26192, acc 0.859375\n",
      "2018-05-04T14:56:58.146736: step 3816, loss 0.365387, acc 0.828125\n",
      "2018-05-04T14:56:59.275545: step 3817, loss 0.325399, acc 0.84375\n",
      "2018-05-04T14:57:00.375719: step 3818, loss 0.261527, acc 0.859375\n",
      "2018-05-04T14:57:01.548946: step 3819, loss 0.276161, acc 0.890625\n",
      "2018-05-04T14:57:02.640812: step 3820, loss 0.471922, acc 0.796875\n",
      "2018-05-04T14:57:03.769172: step 3821, loss 0.302013, acc 0.90625\n",
      "2018-05-04T14:57:04.896975: step 3822, loss 0.277884, acc 0.875\n",
      "2018-05-04T14:57:06.076907: step 3823, loss 0.251519, acc 0.890625\n",
      "2018-05-04T14:57:07.208477: step 3824, loss 0.199318, acc 0.90625\n",
      "2018-05-04T14:57:08.346557: step 3825, loss 0.25033, acc 0.921875\n",
      "2018-05-04T14:57:09.487639: step 3826, loss 0.307252, acc 0.875\n",
      "2018-05-04T14:57:10.607351: step 3827, loss 0.259097, acc 0.859375\n",
      "2018-05-04T14:57:11.798321: step 3828, loss 0.232363, acc 0.90625\n",
      "2018-05-04T14:57:12.972719: step 3829, loss 0.379475, acc 0.859375\n",
      "2018-05-04T14:57:14.070281: step 3830, loss 0.531402, acc 0.765625\n",
      "2018-05-04T14:57:15.241455: step 3831, loss 0.201116, acc 0.921875\n",
      "2018-05-04T14:57:16.375345: step 3832, loss 0.259592, acc 0.90625\n",
      "2018-05-04T14:57:17.489295: step 3833, loss 0.2525, acc 0.875\n",
      "2018-05-04T14:57:18.589741: step 3834, loss 0.547978, acc 0.78125\n",
      "2018-05-04T14:57:19.767530: step 3835, loss 0.466606, acc 0.78125\n",
      "2018-05-04T14:57:20.996992: step 3836, loss 0.346381, acc 0.84375\n",
      "2018-05-04T14:57:22.192137: step 3837, loss 0.286093, acc 0.875\n",
      "2018-05-04T14:57:23.315392: step 3838, loss 0.316537, acc 0.859375\n",
      "2018-05-04T14:57:24.429026: step 3839, loss 0.2129, acc 0.90625\n",
      "2018-05-04T14:57:25.529789: step 3840, loss 0.154961, acc 0.953125\n",
      "2018-05-04T14:57:26.620194: step 3841, loss 0.307901, acc 0.875\n",
      "2018-05-04T14:57:27.709679: step 3842, loss 0.29608, acc 0.859375\n",
      "2018-05-04T14:57:28.796682: step 3843, loss 0.274299, acc 0.890625\n",
      "2018-05-04T14:57:29.912986: step 3844, loss 0.333651, acc 0.890625\n",
      "2018-05-04T14:57:31.191062: step 3845, loss 0.314115, acc 0.859375\n",
      "2018-05-04T14:57:32.401339: step 3846, loss 0.269058, acc 0.90625\n",
      "2018-05-04T14:57:33.539953: step 3847, loss 0.393316, acc 0.84375\n",
      "2018-05-04T14:57:34.680028: step 3848, loss 0.232412, acc 0.921875\n",
      "2018-05-04T14:57:35.816364: step 3849, loss 0.223259, acc 0.890625\n",
      "2018-05-04T14:57:36.978282: step 3850, loss 0.156299, acc 0.9375\n",
      "2018-05-04T14:57:38.180530: step 3851, loss 0.213728, acc 0.9375\n",
      "2018-05-04T14:57:39.262024: step 3852, loss 0.224576, acc 0.90625\n",
      "2018-05-04T14:57:40.340671: step 3853, loss 0.217866, acc 0.890625\n",
      "2018-05-04T14:57:41.538468: step 3854, loss 0.394538, acc 0.84375\n",
      "2018-05-04T14:57:42.627583: step 3855, loss 0.273248, acc 0.90625\n",
      "2018-05-04T14:57:43.714777: step 3856, loss 0.193854, acc 0.953125\n",
      "2018-05-04T14:57:44.837314: step 3857, loss 0.285916, acc 0.890625\n",
      "2018-05-04T14:57:45.957900: step 3858, loss 0.253655, acc 0.890625\n",
      "2018-05-04T14:57:47.088714: step 3859, loss 0.365724, acc 0.796875\n",
      "2018-05-04T14:57:48.196978: step 3860, loss 0.278548, acc 0.84375\n",
      "2018-05-04T14:57:49.335988: step 3861, loss 0.279442, acc 0.921875\n",
      "2018-05-04T14:57:50.456596: step 3862, loss 0.277144, acc 0.921875\n",
      "2018-05-04T14:57:51.656543: step 3863, loss 0.244724, acc 0.9375\n",
      "2018-05-04T14:57:52.799691: step 3864, loss 0.338565, acc 0.859375\n",
      "2018-05-04T14:57:53.930804: step 3865, loss 0.298791, acc 0.953125\n",
      "2018-05-04T14:57:55.076131: step 3866, loss 0.336062, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T14:57:56.204676: step 3867, loss 0.41455, acc 0.84375\n",
      "2018-05-04T14:57:57.317975: step 3868, loss 0.263527, acc 0.90625\n",
      "2018-05-04T14:57:58.438086: step 3869, loss 0.180273, acc 0.9375\n",
      "2018-05-04T14:57:59.576950: step 3870, loss 0.316622, acc 0.859375\n",
      "2018-05-04T14:58:00.704789: step 3871, loss 0.263684, acc 0.90625\n",
      "2018-05-04T14:58:01.892743: step 3872, loss 0.180161, acc 0.9375\n",
      "2018-05-04T14:58:03.014832: step 3873, loss 0.29167, acc 0.875\n",
      "2018-05-04T14:58:04.151877: step 3874, loss 0.336389, acc 0.859375\n",
      "2018-05-04T14:58:05.270535: step 3875, loss 0.292746, acc 0.90625\n",
      "2018-05-04T14:58:06.404936: step 3876, loss 0.250057, acc 0.890625\n",
      "2018-05-04T14:58:07.538809: step 3877, loss 0.311755, acc 0.890625\n",
      "2018-05-04T14:58:08.671786: step 3878, loss 0.324177, acc 0.859375\n",
      "2018-05-04T14:58:09.852857: step 3879, loss 0.358996, acc 0.875\n",
      "2018-05-04T14:58:11.031321: step 3880, loss 0.4241, acc 0.859375\n",
      "2018-05-04T14:58:12.222800: step 3881, loss 0.292007, acc 0.875\n",
      "2018-05-04T14:58:13.298944: step 3882, loss 0.242145, acc 0.921875\n",
      "2018-05-04T14:58:14.408476: step 3883, loss 0.342768, acc 0.84375\n",
      "2018-05-04T14:58:15.486966: step 3884, loss 0.391701, acc 0.84375\n",
      "2018-05-04T14:58:16.594893: step 3885, loss 0.313006, acc 0.859375\n",
      "2018-05-04T14:58:17.701084: step 3886, loss 0.33718, acc 0.890625\n",
      "2018-05-04T14:58:18.816160: step 3887, loss 0.291712, acc 0.890625\n",
      "2018-05-04T14:58:19.935368: step 3888, loss 0.265919, acc 0.9375\n",
      "2018-05-04T14:58:21.134061: step 3889, loss 0.277581, acc 0.84375\n",
      "2018-05-04T14:58:22.284783: step 3890, loss 0.377984, acc 0.828125\n",
      "2018-05-04T14:58:23.480947: step 3891, loss 0.240896, acc 0.953125\n",
      "2018-05-04T14:58:24.599542: step 3892, loss 0.157975, acc 0.921875\n",
      "2018-05-04T14:58:25.715804: step 3893, loss 0.21355, acc 0.921875\n",
      "2018-05-04T14:58:26.828514: step 3894, loss 0.176855, acc 0.9375\n",
      "2018-05-04T14:58:27.951976: step 3895, loss 0.136166, acc 0.984375\n",
      "2018-05-04T14:58:29.138110: step 3896, loss 0.245577, acc 0.9375\n",
      "2018-05-04T14:58:30.297955: step 3897, loss 0.339526, acc 0.84375\n",
      "2018-05-04T14:58:31.506143: step 3898, loss 0.279528, acc 0.890625\n",
      "2018-05-04T14:58:32.594018: step 3899, loss 0.375289, acc 0.859375\n",
      "2018-05-04T14:58:33.737962: step 3900, loss 0.200266, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T14:58:36.684194: step 3900, loss 0.252718, acc 0.906\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-3900\n",
      "\n",
      "2018-05-04T14:58:37.962817: step 3901, loss 0.300379, acc 0.828125\n",
      "2018-05-04T14:58:39.120642: step 3902, loss 0.308777, acc 0.859375\n",
      "2018-05-04T14:58:40.344152: step 3903, loss 0.234508, acc 0.890625\n",
      "2018-05-04T14:58:41.626029: step 3904, loss 0.209042, acc 0.9375\n",
      "2018-05-04T14:58:42.793156: step 3905, loss 0.296786, acc 0.84375\n",
      "2018-05-04T14:58:43.944266: step 3906, loss 0.248424, acc 0.921875\n",
      "2018-05-04T14:58:45.073993: step 3907, loss 0.318689, acc 0.84375\n",
      "2018-05-04T14:58:46.210856: step 3908, loss 0.175629, acc 0.9375\n",
      "2018-05-04T14:58:47.319205: step 3909, loss 0.196965, acc 0.921875\n",
      "2018-05-04T14:58:48.430747: step 3910, loss 0.288032, acc 0.921875\n",
      "2018-05-04T14:58:49.495871: step 3911, loss 0.329841, acc 0.875\n",
      "2018-05-04T14:58:50.586688: step 3912, loss 0.310292, acc 0.890625\n",
      "2018-05-04T14:58:51.727051: step 3913, loss 0.279952, acc 0.8125\n",
      "2018-05-04T14:58:52.902538: step 3914, loss 0.34159, acc 0.859375\n",
      "2018-05-04T14:58:53.998581: step 3915, loss 0.225501, acc 0.890625\n",
      "2018-05-04T14:58:55.091267: step 3916, loss 0.281742, acc 0.84375\n",
      "2018-05-04T14:58:56.177304: step 3917, loss 0.424495, acc 0.796875\n",
      "2018-05-04T14:58:57.266865: step 3918, loss 0.410805, acc 0.8125\n",
      "2018-05-04T14:58:58.338601: step 3919, loss 0.412766, acc 0.8125\n",
      "2018-05-04T14:58:59.436310: step 3920, loss 0.41409, acc 0.796875\n",
      "2018-05-04T14:59:00.531906: step 3921, loss 0.409895, acc 0.8125\n",
      "2018-05-04T14:59:01.729279: step 3922, loss 0.273093, acc 0.90625\n",
      "2018-05-04T14:59:02.848981: step 3923, loss 0.22724, acc 0.90625\n",
      "2018-05-04T14:59:03.968213: step 3924, loss 0.297895, acc 0.84375\n",
      "2018-05-04T14:59:05.170739: step 3925, loss 0.322172, acc 0.890625\n",
      "2018-05-04T14:59:06.288725: step 3926, loss 0.21771, acc 0.953125\n",
      "2018-05-04T14:59:07.459057: step 3927, loss 0.223883, acc 0.90625\n",
      "2018-05-04T14:59:08.558515: step 3928, loss 0.287165, acc 0.890625\n",
      "2018-05-04T14:59:09.730928: step 3929, loss 0.222257, acc 0.90625\n",
      "2018-05-04T14:59:10.851301: step 3930, loss 0.21863, acc 0.921875\n",
      "2018-05-04T14:59:11.968000: step 3931, loss 0.304987, acc 0.890625\n",
      "2018-05-04T14:59:13.048476: step 3932, loss 0.527522, acc 0.734375\n",
      "2018-05-04T14:59:14.132960: step 3933, loss 0.317691, acc 0.828125\n",
      "2018-05-04T14:59:15.321799: step 3934, loss 0.438362, acc 0.859375\n",
      "2018-05-04T14:59:16.450311: step 3935, loss 0.298733, acc 0.859375\n",
      "2018-05-04T14:59:17.628481: step 3936, loss 0.389371, acc 0.890625\n",
      "2018-05-04T14:59:18.819937: step 3937, loss 0.183428, acc 0.9375\n",
      "2018-05-04T14:59:19.974557: step 3938, loss 0.362089, acc 0.84375\n",
      "2018-05-04T14:59:21.152161: step 3939, loss 0.323928, acc 0.84375\n",
      "2018-05-04T14:59:22.251463: step 3940, loss 0.430603, acc 0.84375\n",
      "2018-05-04T14:59:23.344308: step 3941, loss 0.369925, acc 0.890625\n",
      "2018-05-04T14:59:24.468293: step 3942, loss 0.265204, acc 0.890625\n",
      "2018-05-04T14:59:25.636951: step 3943, loss 0.386442, acc 0.8125\n",
      "2018-05-04T14:59:26.842369: step 3944, loss 0.573424, acc 0.828125\n",
      "2018-05-04T14:59:27.984174: step 3945, loss 0.319357, acc 0.90625\n",
      "2018-05-04T14:59:29.134022: step 3946, loss 0.305291, acc 0.890625\n",
      "2018-05-04T14:59:30.271683: step 3947, loss 0.451907, acc 0.828125\n",
      "2018-05-04T14:59:31.437383: step 3948, loss 0.263093, acc 0.875\n",
      "2018-05-04T14:59:32.529129: step 3949, loss 0.349862, acc 0.828125\n",
      "2018-05-04T14:59:33.625804: step 3950, loss 0.514916, acc 0.796875\n",
      "2018-05-04T14:59:34.824907: step 3951, loss 0.346907, acc 0.8125\n",
      "2018-05-04T14:59:35.920525: step 3952, loss 0.154092, acc 0.96875\n",
      "2018-05-04T14:59:37.046444: step 3953, loss 0.32402, acc 0.90625\n",
      "2018-05-04T14:59:38.175507: step 3954, loss 0.282266, acc 0.84375\n",
      "2018-05-04T14:59:39.307465: step 3955, loss 0.302086, acc 0.890625\n",
      "2018-05-04T14:59:40.443689: step 3956, loss 0.205655, acc 0.9375\n",
      "2018-05-04T14:59:41.659990: step 3957, loss 0.340113, acc 0.84375\n",
      "2018-05-04T14:59:42.874637: step 3958, loss 0.315723, acc 0.828125\n",
      "2018-05-04T14:59:43.983280: step 3959, loss 0.322996, acc 0.890625\n",
      "2018-05-04T14:59:45.123819: step 3960, loss 0.303867, acc 0.90625\n",
      "2018-05-04T14:59:46.250116: step 3961, loss 0.317174, acc 0.890625\n",
      "2018-05-04T14:59:47.376232: step 3962, loss 0.319428, acc 0.859375\n",
      "2018-05-04T14:59:48.512919: step 3963, loss 0.269923, acc 0.890625\n",
      "2018-05-04T14:59:49.724266: step 3964, loss 0.396453, acc 0.828125\n",
      "2018-05-04T14:59:50.884234: step 3965, loss 0.460273, acc 0.875\n",
      "2018-05-04T14:59:52.025864: step 3966, loss 0.308313, acc 0.890625\n",
      "2018-05-04T14:59:53.151631: step 3967, loss 0.500109, acc 0.796875\n",
      "2018-05-04T14:59:54.282990: step 3968, loss 0.295139, acc 0.921875\n",
      "2018-05-04T14:59:55.408188: step 3969, loss 0.356844, acc 0.84375\n",
      "2018-05-04T14:59:56.547070: step 3970, loss 0.391788, acc 0.828125\n",
      "2018-05-04T14:59:57.678294: step 3971, loss 0.238644, acc 0.953125\n",
      "2018-05-04T14:59:58.801944: step 3972, loss 0.349939, acc 0.875\n",
      "2018-05-04T14:59:59.927809: step 3973, loss 0.177902, acc 0.953125\n",
      "2018-05-04T15:00:01.096329: step 3974, loss 0.31416, acc 0.875\n",
      "2018-05-04T15:00:02.281364: step 3975, loss 0.260058, acc 0.90625\n",
      "2018-05-04T15:00:03.380888: step 3976, loss 0.275494, acc 0.90625\n",
      "2018-05-04T15:00:04.522910: step 3977, loss 0.241855, acc 0.921875\n",
      "2018-05-04T15:00:05.602648: step 3978, loss 0.282087, acc 0.875\n",
      "2018-05-04T15:00:06.680293: step 3979, loss 0.353984, acc 0.84375\n",
      "2018-05-04T15:00:07.763445: step 3980, loss 0.385031, acc 0.796875\n",
      "2018-05-04T15:00:08.858964: step 3981, loss 0.384135, acc 0.8125\n",
      "2018-05-04T15:00:10.061074: step 3982, loss 0.407087, acc 0.859375\n",
      "2018-05-04T15:00:11.238182: step 3983, loss 0.1573, acc 0.9375\n",
      "2018-05-04T15:00:12.409979: step 3984, loss 0.322953, acc 0.84375\n",
      "2018-05-04T15:00:13.535587: step 3985, loss 0.372028, acc 0.828125\n",
      "2018-05-04T15:00:14.650910: step 3986, loss 0.240817, acc 0.90625\n",
      "2018-05-04T15:00:15.853377: step 3987, loss 0.231642, acc 0.90625\n",
      "2018-05-04T15:00:16.985189: step 3988, loss 0.269757, acc 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T15:00:18.112870: step 3989, loss 0.350779, acc 0.8125\n",
      "2018-05-04T15:00:19.182711: step 3990, loss 0.384549, acc 0.84375\n",
      "2018-05-04T15:00:20.267227: step 3991, loss 0.344049, acc 0.828125\n",
      "2018-05-04T15:00:21.464840: step 3992, loss 0.268032, acc 0.9375\n",
      "2018-05-04T15:00:22.562364: step 3993, loss 0.439852, acc 0.828125\n",
      "2018-05-04T15:00:23.694337: step 3994, loss 0.192752, acc 0.9375\n",
      "2018-05-04T15:00:24.814058: step 3995, loss 0.380552, acc 0.875\n",
      "2018-05-04T15:00:25.937639: step 3996, loss 0.355005, acc 0.828125\n",
      "2018-05-04T15:00:27.047569: step 3997, loss 0.236987, acc 0.90625\n",
      "2018-05-04T15:00:28.163934: step 3998, loss 0.325878, acc 0.859375\n",
      "2018-05-04T15:00:29.298485: step 3999, loss 0.288553, acc 0.828125\n",
      "2018-05-04T15:00:30.433455: step 4000, loss 0.279869, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T15:00:33.005356: step 4000, loss 0.257104, acc 0.894\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-4000\n",
      "\n",
      "2018-05-04T15:00:34.237583: step 4001, loss 0.311358, acc 0.84375\n",
      "2018-05-04T15:00:35.351147: step 4002, loss 0.419534, acc 0.828125\n",
      "2018-05-04T15:00:36.428006: step 4003, loss 0.251706, acc 0.890625\n",
      "2018-05-04T15:00:37.506518: step 4004, loss 0.244737, acc 0.9375\n",
      "2018-05-04T15:00:38.596135: step 4005, loss 0.340488, acc 0.890625\n",
      "2018-05-04T15:00:39.694927: step 4006, loss 0.289314, acc 0.890625\n",
      "2018-05-04T15:00:40.827684: step 4007, loss 0.312967, acc 0.859375\n",
      "2018-05-04T15:00:42.004604: step 4008, loss 0.441753, acc 0.828125\n",
      "2018-05-04T15:00:43.094327: step 4009, loss 0.340843, acc 0.890625\n",
      "2018-05-04T15:00:44.220892: step 4010, loss 0.253822, acc 0.890625\n",
      "2018-05-04T15:00:45.353554: step 4011, loss 0.285436, acc 0.859375\n",
      "2018-05-04T15:00:46.467694: step 4012, loss 0.504437, acc 0.765625\n",
      "2018-05-04T15:00:47.641359: step 4013, loss 0.243136, acc 0.9375\n",
      "2018-05-04T15:00:48.831953: step 4014, loss 0.348899, acc 0.84375\n",
      "2018-05-04T15:00:50.007866: step 4015, loss 0.310067, acc 0.828125\n",
      "2018-05-04T15:00:51.132106: step 4016, loss 0.348909, acc 0.859375\n",
      "2018-05-04T15:00:52.227496: step 4017, loss 0.29819, acc 0.875\n",
      "2018-05-04T15:00:53.288685: step 4018, loss 0.329237, acc 0.84375\n",
      "2018-05-04T15:00:54.446767: step 4019, loss 0.469758, acc 0.796875\n",
      "2018-05-04T15:00:55.531306: step 4020, loss 0.353779, acc 0.8125\n",
      "2018-05-04T15:00:56.601067: step 4021, loss 0.266088, acc 0.859375\n",
      "2018-05-04T15:00:57.712589: step 4022, loss 0.358718, acc 0.890625\n",
      "2018-05-04T15:00:58.932885: step 4023, loss 0.192727, acc 0.9375\n",
      "2018-05-04T15:01:00.126143: step 4024, loss 0.216842, acc 0.921875\n",
      "2018-05-04T15:01:01.360598: step 4025, loss 0.278905, acc 0.875\n",
      "2018-05-04T15:01:02.504551: step 4026, loss 0.335331, acc 0.859375\n",
      "2018-05-04T15:01:03.573789: step 4027, loss 0.323623, acc 0.828125\n",
      "2018-05-04T15:01:04.730539: step 4028, loss 0.374392, acc 0.8125\n",
      "2018-05-04T15:01:05.833900: step 4029, loss 0.209465, acc 0.921875\n",
      "2018-05-04T15:01:06.926592: step 4030, loss 0.284898, acc 0.859375\n",
      "2018-05-04T15:01:08.083959: step 4031, loss 0.257717, acc 0.890625\n",
      "2018-05-04T15:01:09.172724: step 4032, loss 0.28441, acc 0.890625\n",
      "2018-05-04T15:01:10.317269: step 4033, loss 0.261819, acc 0.90625\n",
      "2018-05-04T15:01:11.540447: step 4034, loss 0.300185, acc 0.921875\n",
      "2018-05-04T15:01:12.677056: step 4035, loss 0.311509, acc 0.890625\n",
      "2018-05-04T15:01:13.791944: step 4036, loss 0.241182, acc 0.890625\n",
      "2018-05-04T15:01:14.917215: step 4037, loss 0.324239, acc 0.859375\n",
      "2018-05-04T15:01:16.088805: step 4038, loss 0.281523, acc 0.90625\n",
      "2018-05-04T15:01:17.274187: step 4039, loss 0.267745, acc 0.875\n",
      "2018-05-04T15:01:18.465732: step 4040, loss 0.339127, acc 0.84375\n",
      "2018-05-04T15:01:19.642373: step 4041, loss 0.143401, acc 0.9375\n",
      "2018-05-04T15:01:20.826000: step 4042, loss 0.38104, acc 0.859375\n",
      "2018-05-04T15:01:22.014542: step 4043, loss 0.367939, acc 0.828125\n",
      "2018-05-04T15:01:23.079401: step 4044, loss 0.267761, acc 0.875\n",
      "2018-05-04T15:01:24.240110: step 4045, loss 0.376086, acc 0.78125\n",
      "2018-05-04T15:01:25.380633: step 4046, loss 0.337853, acc 0.859375\n",
      "2018-05-04T15:01:26.468632: step 4047, loss 0.349974, acc 0.859375\n",
      "2018-05-04T15:01:27.623074: step 4048, loss 0.242143, acc 0.90625\n",
      "2018-05-04T15:01:28.792646: step 4049, loss 0.310861, acc 0.890625\n",
      "2018-05-04T15:01:29.942360: step 4050, loss 0.227773, acc 0.9375\n",
      "2018-05-04T15:01:31.125051: step 4051, loss 0.218241, acc 0.90625\n",
      "2018-05-04T15:01:32.290109: step 4052, loss 0.273196, acc 0.90625\n",
      "2018-05-04T15:01:33.515739: step 4053, loss 0.362861, acc 0.84375\n",
      "2018-05-04T15:01:34.759354: step 4054, loss 0.349918, acc 0.84375\n",
      "2018-05-04T15:01:36.013862: step 4055, loss 0.281908, acc 0.890625\n",
      "2018-05-04T15:01:37.330349: step 4056, loss 0.256482, acc 0.875\n",
      "2018-05-04T15:01:38.540667: step 4057, loss 0.314691, acc 0.84375\n",
      "2018-05-04T15:01:39.722227: step 4058, loss 0.308643, acc 0.890625\n",
      "2018-05-04T15:01:40.926716: step 4059, loss 0.313669, acc 0.890625\n",
      "2018-05-04T15:01:42.123644: step 4060, loss 0.37401, acc 0.84375\n",
      "2018-05-04T15:01:43.274278: step 4061, loss 0.468261, acc 0.796875\n",
      "2018-05-04T15:01:44.419790: step 4062, loss 0.256088, acc 0.90625\n",
      "2018-05-04T15:01:45.596845: step 4063, loss 0.296795, acc 0.875\n",
      "2018-05-04T15:01:46.682192: step 4064, loss 0.181829, acc 0.9375\n",
      "2018-05-04T15:01:47.822495: step 4065, loss 0.265413, acc 0.90625\n",
      "2018-05-04T15:01:48.960663: step 4066, loss 0.2397, acc 0.90625\n",
      "2018-05-04T15:01:50.089248: step 4067, loss 0.45721, acc 0.8125\n",
      "2018-05-04T15:01:51.300179: step 4068, loss 0.327681, acc 0.828125\n",
      "2018-05-04T15:01:52.446385: step 4069, loss 0.349005, acc 0.8125\n",
      "2018-05-04T15:01:53.578921: step 4070, loss 0.394793, acc 0.84375\n",
      "2018-05-04T15:01:54.751030: step 4071, loss 0.204983, acc 0.90625\n",
      "2018-05-04T15:01:55.908011: step 4072, loss 0.364065, acc 0.8125\n",
      "2018-05-04T15:01:57.013566: step 4073, loss 0.298821, acc 0.875\n",
      "2018-05-04T15:01:58.161909: step 4074, loss 0.234419, acc 0.921875\n",
      "2018-05-04T15:01:59.343937: step 4075, loss 0.280477, acc 0.921875\n",
      "2018-05-04T15:02:00.493979: step 4076, loss 0.396682, acc 0.828125\n",
      "2018-05-04T15:02:01.645870: step 4077, loss 0.270351, acc 0.859375\n",
      "2018-05-04T15:02:02.796089: step 4078, loss 0.298312, acc 0.84375\n",
      "2018-05-04T15:02:03.969589: step 4079, loss 0.314917, acc 0.90625\n",
      "2018-05-04T15:02:05.127893: step 4080, loss 0.317624, acc 0.84375\n",
      "2018-05-04T15:02:06.264470: step 4081, loss 0.170178, acc 0.9375\n",
      "2018-05-04T15:02:07.413372: step 4082, loss 0.336854, acc 0.84375\n",
      "2018-05-04T15:02:08.542123: step 4083, loss 0.214004, acc 0.890625\n",
      "2018-05-04T15:02:09.687595: step 4084, loss 0.458543, acc 0.859375\n",
      "2018-05-04T15:02:10.872348: step 4085, loss 0.278207, acc 0.875\n",
      "2018-05-04T15:02:12.045279: step 4086, loss 0.300163, acc 0.859375\n",
      "2018-05-04T15:02:13.202674: step 4087, loss 0.30349, acc 0.875\n",
      "2018-05-04T15:02:14.352293: step 4088, loss 0.263777, acc 0.875\n",
      "2018-05-04T15:02:15.506761: step 4089, loss 0.334493, acc 0.84375\n",
      "2018-05-04T15:02:16.609926: step 4090, loss 0.376479, acc 0.8125\n",
      "2018-05-04T15:02:17.714273: step 4091, loss 0.246488, acc 0.90625\n",
      "2018-05-04T15:02:18.829369: step 4092, loss 0.211119, acc 0.921875\n",
      "2018-05-04T15:02:19.990505: step 4093, loss 0.167053, acc 0.953125\n",
      "2018-05-04T15:02:21.185274: step 4094, loss 0.39379, acc 0.828125\n",
      "2018-05-04T15:02:22.369394: step 4095, loss 0.323081, acc 0.90625\n",
      "2018-05-04T15:02:23.551947: step 4096, loss 0.373629, acc 0.84375\n",
      "2018-05-04T15:02:24.748821: step 4097, loss 0.487568, acc 0.796875\n",
      "2018-05-04T15:02:25.913736: step 4098, loss 0.284325, acc 0.875\n",
      "2018-05-04T15:02:27.044655: step 4099, loss 0.31608, acc 0.875\n",
      "2018-05-04T15:02:28.177698: step 4100, loss 0.353147, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T15:02:30.828085: step 4100, loss 0.258298, acc 0.902\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-4100\n",
      "\n",
      "2018-05-04T15:02:32.062851: step 4101, loss 0.334722, acc 0.859375\n",
      "2018-05-04T15:02:33.248041: step 4102, loss 0.278644, acc 0.890625\n",
      "2018-05-04T15:02:34.450735: step 4103, loss 0.371425, acc 0.859375\n",
      "2018-05-04T15:02:35.611093: step 4104, loss 0.483173, acc 0.828125\n",
      "2018-05-04T15:02:36.768720: step 4105, loss 0.309424, acc 0.859375\n",
      "2018-05-04T15:02:37.905057: step 4106, loss 0.238116, acc 0.9375\n",
      "2018-05-04T15:02:39.096502: step 4107, loss 0.216614, acc 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T15:02:40.229345: step 4108, loss 0.325811, acc 0.84375\n",
      "2018-05-04T15:02:41.436395: step 4109, loss 0.444479, acc 0.796875\n",
      "2018-05-04T15:02:42.581170: step 4110, loss 0.249248, acc 0.875\n",
      "2018-05-04T15:02:43.714813: step 4111, loss 0.233163, acc 0.921875\n",
      "2018-05-04T15:02:44.897443: step 4112, loss 0.356833, acc 0.859375\n",
      "2018-05-04T15:02:45.980771: step 4113, loss 0.298693, acc 0.890625\n",
      "2018-05-04T15:02:47.153583: step 4114, loss 0.225199, acc 0.90625\n",
      "2018-05-04T15:02:48.325078: step 4115, loss 0.282592, acc 0.875\n",
      "2018-05-04T15:02:49.426167: step 4116, loss 0.328007, acc 0.875\n",
      "2018-05-04T15:02:50.515438: step 4117, loss 0.256509, acc 0.921875\n",
      "2018-05-04T15:02:51.654383: step 4118, loss 0.351605, acc 0.828125\n",
      "2018-05-04T15:02:52.828635: step 4119, loss 0.377924, acc 0.828125\n",
      "2018-05-04T15:02:53.923824: step 4120, loss 0.259873, acc 0.84375\n",
      "2018-05-04T15:02:55.019040: step 4121, loss 0.193662, acc 0.953125\n",
      "2018-05-04T15:02:56.121236: step 4122, loss 0.29548, acc 0.859375\n",
      "2018-05-04T15:02:57.224589: step 4123, loss 0.361242, acc 0.828125\n",
      "2018-05-04T15:02:58.405736: step 4124, loss 0.317894, acc 0.890625\n",
      "2018-05-04T15:02:59.540153: step 4125, loss 0.260814, acc 0.859375\n",
      "2018-05-04T15:03:00.677208: step 4126, loss 0.393549, acc 0.796875\n",
      "2018-05-04T15:03:01.847962: step 4127, loss 0.269187, acc 0.890625\n",
      "2018-05-04T15:03:02.961300: step 4128, loss 0.273109, acc 0.90625\n",
      "2018-05-04T15:03:04.119042: step 4129, loss 0.359405, acc 0.859375\n",
      "2018-05-04T15:03:05.265713: step 4130, loss 0.354735, acc 0.796875\n",
      "2018-05-04T15:03:06.404149: step 4131, loss 0.267953, acc 0.84375\n",
      "2018-05-04T15:03:07.517569: step 4132, loss 0.22491, acc 0.90625\n",
      "2018-05-04T15:03:08.583239: step 4133, loss 0.30941, acc 0.84375\n",
      "2018-05-04T15:03:09.697919: step 4134, loss 0.270925, acc 0.875\n",
      "2018-05-04T15:03:10.789040: step 4135, loss 0.375953, acc 0.90625\n",
      "2018-05-04T15:03:11.921216: step 4136, loss 0.273293, acc 0.90625\n",
      "2018-05-04T15:03:13.121782: step 4137, loss 0.28049, acc 0.9375\n",
      "2018-05-04T15:03:14.248299: step 4138, loss 0.312804, acc 0.859375\n",
      "2018-05-04T15:03:15.363133: step 4139, loss 0.435221, acc 0.859375\n",
      "2018-05-04T15:03:16.492321: step 4140, loss 0.285278, acc 0.84375\n",
      "2018-05-04T15:03:17.637552: step 4141, loss 0.206792, acc 0.90625\n",
      "2018-05-04T15:03:18.769555: step 4142, loss 0.320044, acc 0.875\n",
      "2018-05-04T15:03:19.924704: step 4143, loss 0.387999, acc 0.796875\n",
      "2018-05-04T15:03:21.091700: step 4144, loss 0.218469, acc 0.921875\n",
      "2018-05-04T15:03:22.212951: step 4145, loss 0.279675, acc 0.890625\n",
      "2018-05-04T15:03:23.310553: step 4146, loss 0.207063, acc 0.9375\n",
      "2018-05-04T15:03:24.425599: step 4147, loss 0.242613, acc 0.921875\n",
      "2018-05-04T15:03:25.530222: step 4148, loss 0.237448, acc 0.921875\n",
      "2018-05-04T15:03:26.662652: step 4149, loss 0.224804, acc 0.921875\n",
      "2018-05-04T15:03:27.790375: step 4150, loss 0.356018, acc 0.875\n",
      "2018-05-04T15:03:28.935099: step 4151, loss 0.263171, acc 0.890625\n",
      "2018-05-04T15:03:30.091948: step 4152, loss 0.26173, acc 0.90625\n",
      "2018-05-04T15:03:31.276639: step 4153, loss 0.234136, acc 0.921875\n",
      "2018-05-04T15:03:32.411708: step 4154, loss 0.417771, acc 0.828125\n",
      "2018-05-04T15:03:33.555671: step 4155, loss 0.211076, acc 0.921875\n",
      "2018-05-04T15:03:34.702607: step 4156, loss 0.473224, acc 0.828125\n",
      "2018-05-04T15:03:35.796347: step 4157, loss 0.334973, acc 0.84375\n",
      "2018-05-04T15:03:36.879259: step 4158, loss 0.249558, acc 0.875\n",
      "2018-05-04T15:03:38.044931: step 4159, loss 0.50903, acc 0.765625\n",
      "2018-05-04T15:03:39.144738: step 4160, loss 0.242863, acc 0.90625\n",
      "2018-05-04T15:03:40.255835: step 4161, loss 0.373752, acc 0.90625\n",
      "2018-05-04T15:03:41.463061: step 4162, loss 0.29298, acc 0.828125\n",
      "2018-05-04T15:03:42.587107: step 4163, loss 0.290268, acc 0.90625\n",
      "2018-05-04T15:03:43.731448: step 4164, loss 0.291845, acc 0.890625\n",
      "2018-05-04T15:03:44.873798: step 4165, loss 0.365865, acc 0.828125\n",
      "2018-05-04T15:03:45.994450: step 4166, loss 0.42499, acc 0.8125\n",
      "2018-05-04T15:03:47.119631: step 4167, loss 0.310434, acc 0.859375\n",
      "2018-05-04T15:03:48.206930: step 4168, loss 0.231973, acc 0.875\n",
      "2018-05-04T15:03:49.295669: step 4169, loss 0.292921, acc 0.921875\n",
      "2018-05-04T15:03:50.398884: step 4170, loss 0.238367, acc 0.890625\n",
      "2018-05-04T15:03:51.565132: step 4171, loss 0.242061, acc 0.921875\n",
      "2018-05-04T15:03:52.650097: step 4172, loss 0.274495, acc 0.875\n",
      "2018-05-04T15:03:53.721498: step 4173, loss 0.367118, acc 0.8125\n",
      "2018-05-04T15:03:54.824052: step 4174, loss 0.411334, acc 0.84375\n",
      "2018-05-04T15:03:55.925562: step 4175, loss 0.250098, acc 0.90625\n",
      "2018-05-04T15:03:57.060433: step 4176, loss 0.383299, acc 0.84375\n",
      "2018-05-04T15:03:58.199960: step 4177, loss 0.421252, acc 0.828125\n",
      "2018-05-04T15:03:59.351191: step 4178, loss 0.347071, acc 0.84375\n",
      "2018-05-04T15:04:00.554587: step 4179, loss 0.255284, acc 0.890625\n",
      "2018-05-04T15:04:01.746138: step 4180, loss 0.238396, acc 0.890625\n",
      "2018-05-04T15:04:02.814463: step 4181, loss 0.364216, acc 0.875\n",
      "2018-05-04T15:04:03.905884: step 4182, loss 0.275117, acc 0.921875\n",
      "2018-05-04T15:04:05.038867: step 4183, loss 0.241376, acc 0.9375\n",
      "2018-05-04T15:04:06.128549: step 4184, loss 0.284243, acc 0.890625\n",
      "2018-05-04T15:04:07.211017: step 4185, loss 0.250407, acc 0.875\n",
      "2018-05-04T15:04:08.339537: step 4186, loss 0.251057, acc 0.90625\n",
      "2018-05-04T15:04:09.486684: step 4187, loss 0.447533, acc 0.765625\n",
      "2018-05-04T15:04:10.612612: step 4188, loss 0.263475, acc 0.90625\n",
      "2018-05-04T15:04:11.790268: step 4189, loss 0.295772, acc 0.84375\n",
      "2018-05-04T15:04:12.960785: step 4190, loss 0.281909, acc 0.890625\n",
      "2018-05-04T15:04:14.088756: step 4191, loss 0.37907, acc 0.859375\n",
      "2018-05-04T15:04:15.278165: step 4192, loss 0.232334, acc 0.90625\n",
      "2018-05-04T15:04:16.352755: step 4193, loss 0.384343, acc 0.8125\n",
      "2018-05-04T15:04:17.435980: step 4194, loss 0.216132, acc 0.875\n",
      "2018-05-04T15:04:18.523942: step 4195, loss 0.386197, acc 0.890625\n",
      "2018-05-04T15:04:19.623661: step 4196, loss 0.259546, acc 0.921875\n",
      "2018-05-04T15:04:20.813484: step 4197, loss 0.248841, acc 0.90625\n",
      "2018-05-04T15:04:22.022692: step 4198, loss 0.138915, acc 0.953125\n",
      "2018-05-04T15:04:23.099990: step 4199, loss 0.28302, acc 0.890625\n",
      "2018-05-04T15:04:24.251762: step 4200, loss 0.435771, acc 0.8125\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T15:04:26.717423: step 4200, loss 0.319934, acc 0.876\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-4200\n",
      "\n",
      "2018-05-04T15:04:27.932682: step 4201, loss 0.315, acc 0.828125\n",
      "2018-05-04T15:04:29.069325: step 4202, loss 0.255635, acc 0.90625\n",
      "2018-05-04T15:04:30.196522: step 4203, loss 0.336003, acc 0.890625\n",
      "2018-05-04T15:04:31.411318: step 4204, loss 0.21703, acc 0.921875\n",
      "2018-05-04T15:04:32.582470: step 4205, loss 0.449522, acc 0.8125\n",
      "2018-05-04T15:04:33.729552: step 4206, loss 0.260033, acc 0.859375\n",
      "2018-05-04T15:04:34.881114: step 4207, loss 0.198559, acc 0.890625\n",
      "2018-05-04T15:04:36.051973: step 4208, loss 0.277424, acc 0.875\n",
      "2018-05-04T15:04:37.227250: step 4209, loss 0.321971, acc 0.875\n",
      "2018-05-04T15:04:38.387782: step 4210, loss 0.311671, acc 0.859375\n",
      "2018-05-04T15:04:39.512180: step 4211, loss 0.435935, acc 0.796875\n",
      "2018-05-04T15:04:40.708964: step 4212, loss 0.272598, acc 0.90625\n",
      "2018-05-04T15:04:41.954490: step 4213, loss 0.455754, acc 0.8125\n",
      "2018-05-04T15:04:43.145265: step 4214, loss 0.22409, acc 0.90625\n",
      "2018-05-04T15:04:44.321196: step 4215, loss 0.300206, acc 0.84375\n",
      "2018-05-04T15:04:45.464592: step 4216, loss 0.291124, acc 0.90625\n",
      "2018-05-04T15:04:46.611083: step 4217, loss 0.254035, acc 0.875\n",
      "2018-05-04T15:04:47.680286: step 4218, loss 0.384813, acc 0.859375\n",
      "2018-05-04T15:04:48.764930: step 4219, loss 0.279764, acc 0.890625\n",
      "2018-05-04T15:04:49.858931: step 4220, loss 0.336638, acc 0.84375\n",
      "2018-05-04T15:04:51.054185: step 4221, loss 0.409392, acc 0.84375\n",
      "2018-05-04T15:04:52.172181: step 4222, loss 0.294154, acc 0.921875\n",
      "2018-05-04T15:04:53.365321: step 4223, loss 0.286415, acc 0.875\n",
      "2018-05-04T15:04:54.490894: step 4224, loss 0.368382, acc 0.84375\n",
      "2018-05-04T15:04:55.611740: step 4225, loss 0.39131, acc 0.859375\n",
      "2018-05-04T15:04:56.799811: step 4226, loss 0.32373, acc 0.859375\n",
      "2018-05-04T15:04:57.912529: step 4227, loss 0.507363, acc 0.75\n",
      "2018-05-04T15:04:59.049168: step 4228, loss 0.353805, acc 0.828125\n",
      "2018-05-04T15:05:00.256674: step 4229, loss 0.239219, acc 0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T15:05:01.465994: step 4230, loss 0.406944, acc 0.8125\n",
      "2018-05-04T15:05:02.620306: step 4231, loss 0.259834, acc 0.90625\n",
      "2018-05-04T15:05:03.780799: step 4232, loss 0.255087, acc 0.921875\n",
      "2018-05-04T15:05:04.937751: step 4233, loss 0.284763, acc 0.828125\n",
      "2018-05-04T15:05:05.998476: step 4234, loss 0.312424, acc 0.859375\n",
      "2018-05-04T15:05:07.089042: step 4235, loss 0.465315, acc 0.78125\n",
      "2018-05-04T15:05:08.267132: step 4236, loss 0.385742, acc 0.890625\n",
      "2018-05-04T15:05:09.474765: step 4237, loss 0.214934, acc 0.90625\n",
      "2018-05-04T15:05:10.670261: step 4238, loss 0.290492, acc 0.90625\n",
      "2018-05-04T15:05:11.900967: step 4239, loss 0.319629, acc 0.859375\n",
      "2018-05-04T15:05:13.018988: step 4240, loss 0.197084, acc 0.9375\n",
      "2018-05-04T15:05:14.211252: step 4241, loss 0.242462, acc 0.875\n",
      "2018-05-04T15:05:15.378877: step 4242, loss 0.336499, acc 0.875\n",
      "2018-05-04T15:05:16.562080: step 4243, loss 0.332241, acc 0.875\n",
      "2018-05-04T15:05:17.759669: step 4244, loss 0.232146, acc 0.953125\n",
      "2018-05-04T15:05:18.957173: step 4245, loss 0.353877, acc 0.84375\n",
      "2018-05-04T15:05:20.159881: step 4246, loss 0.273817, acc 0.890625\n",
      "2018-05-04T15:05:21.431353: step 4247, loss 0.417957, acc 0.828125\n",
      "2018-05-04T15:05:22.541209: step 4248, loss 0.337243, acc 0.859375\n",
      "2018-05-04T15:05:23.735112: step 4249, loss 0.28882, acc 0.875\n",
      "2018-05-04T15:05:24.930060: step 4250, loss 0.318691, acc 0.859375\n",
      "2018-05-04T15:05:26.100915: step 4251, loss 0.380388, acc 0.8125\n",
      "2018-05-04T15:05:27.275577: step 4252, loss 0.327634, acc 0.859375\n",
      "2018-05-04T15:05:28.471285: step 4253, loss 0.306483, acc 0.875\n",
      "2018-05-04T15:05:29.649292: step 4254, loss 0.251476, acc 0.890625\n",
      "2018-05-04T15:05:30.864485: step 4255, loss 0.267711, acc 0.859375\n",
      "2018-05-04T15:05:32.085876: step 4256, loss 0.29378, acc 0.875\n",
      "2018-05-04T15:05:33.205890: step 4257, loss 0.255743, acc 0.875\n",
      "2018-05-04T15:05:34.394951: step 4258, loss 0.308566, acc 0.875\n",
      "2018-05-04T15:05:35.581312: step 4259, loss 0.207105, acc 0.921875\n",
      "2018-05-04T15:05:36.743588: step 4260, loss 0.34798, acc 0.859375\n",
      "2018-05-04T15:05:37.941312: step 4261, loss 0.237426, acc 0.90625\n",
      "2018-05-04T15:05:39.117998: step 4262, loss 0.315818, acc 0.828125\n",
      "2018-05-04T15:05:40.302580: step 4263, loss 0.347707, acc 0.859375\n",
      "2018-05-04T15:05:41.556067: step 4264, loss 0.380161, acc 0.84375\n",
      "2018-05-04T15:05:42.737286: step 4265, loss 0.391369, acc 0.828125\n",
      "2018-05-04T15:05:43.922516: step 4266, loss 0.336132, acc 0.828125\n",
      "2018-05-04T15:05:45.123155: step 4267, loss 0.204763, acc 0.90625\n",
      "2018-05-04T15:05:46.318019: step 4268, loss 0.316736, acc 0.875\n",
      "2018-05-04T15:05:47.439688: step 4269, loss 0.244804, acc 0.921875\n",
      "2018-05-04T15:05:48.613319: step 4270, loss 0.276212, acc 0.90625\n",
      "2018-05-04T15:05:49.733604: step 4271, loss 0.203349, acc 0.921875\n",
      "2018-05-04T15:05:50.955516: step 4272, loss 0.252898, acc 0.859375\n",
      "2018-05-04T15:05:52.175886: step 4273, loss 0.335956, acc 0.875\n",
      "2018-05-04T15:05:53.359405: step 4274, loss 0.251179, acc 0.921875\n",
      "2018-05-04T15:05:54.520390: step 4275, loss 0.268943, acc 0.875\n",
      "2018-05-04T15:05:55.705440: step 4276, loss 0.192732, acc 0.9375\n",
      "2018-05-04T15:05:56.892521: step 4277, loss 0.303128, acc 0.875\n",
      "2018-05-04T15:05:58.070469: step 4278, loss 0.188685, acc 0.953125\n",
      "2018-05-04T15:05:59.218063: step 4279, loss 0.340901, acc 0.828125\n",
      "2018-05-04T15:06:00.384867: step 4280, loss 0.408521, acc 0.8125\n",
      "2018-05-04T15:06:01.606297: step 4281, loss 0.348264, acc 0.890625\n",
      "2018-05-04T15:06:02.748379: step 4282, loss 0.328606, acc 0.875\n",
      "2018-05-04T15:06:03.873944: step 4283, loss 0.266357, acc 0.90625\n",
      "2018-05-04T15:06:05.056497: step 4284, loss 0.2603, acc 0.90625\n",
      "2018-05-04T15:06:06.231462: step 4285, loss 0.441834, acc 0.859375\n",
      "2018-05-04T15:06:07.411975: step 4286, loss 0.356658, acc 0.859375\n",
      "2018-05-04T15:06:08.599109: step 4287, loss 0.359385, acc 0.8125\n",
      "2018-05-04T15:06:09.790183: step 4288, loss 0.378329, acc 0.828125\n",
      "2018-05-04T15:06:10.970175: step 4289, loss 0.27827, acc 0.890625\n",
      "2018-05-04T15:06:12.185201: step 4290, loss 0.354092, acc 0.828125\n",
      "2018-05-04T15:06:13.349857: step 4291, loss 0.358632, acc 0.859375\n",
      "2018-05-04T15:06:14.516116: step 4292, loss 0.264897, acc 0.875\n",
      "2018-05-04T15:06:15.654387: step 4293, loss 0.31651, acc 0.84375\n",
      "2018-05-04T15:06:16.778960: step 4294, loss 0.50763, acc 0.734375\n",
      "2018-05-04T15:06:17.926797: step 4295, loss 0.202296, acc 0.90625\n",
      "2018-05-04T15:06:19.070571: step 4296, loss 0.346475, acc 0.796875\n",
      "2018-05-04T15:06:20.215233: step 4297, loss 0.332062, acc 0.90625\n",
      "2018-05-04T15:06:21.427114: step 4298, loss 0.298175, acc 0.875\n",
      "2018-05-04T15:06:22.605971: step 4299, loss 0.29111, acc 0.90625\n",
      "2018-05-04T15:06:23.764110: step 4300, loss 0.320698, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T15:06:26.903145: step 4300, loss 0.252743, acc 0.908\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-4300\n",
      "\n",
      "2018-05-04T15:06:28.227562: step 4301, loss 0.300164, acc 0.859375\n",
      "2018-05-04T15:06:29.448004: step 4302, loss 0.347766, acc 0.8125\n",
      "2018-05-04T15:06:30.662806: step 4303, loss 0.417262, acc 0.828125\n",
      "2018-05-04T15:06:31.994828: step 4304, loss 0.299441, acc 0.84375\n",
      "2018-05-04T15:06:33.154556: step 4305, loss 0.401577, acc 0.796875\n",
      "2018-05-04T15:06:34.365728: step 4306, loss 0.406136, acc 0.75\n",
      "2018-05-04T15:06:35.447850: step 4307, loss 0.355378, acc 0.859375\n",
      "2018-05-04T15:06:36.544317: step 4308, loss 0.194844, acc 0.890625\n",
      "2018-05-04T15:06:37.654694: step 4309, loss 0.283446, acc 0.84375\n",
      "2018-05-04T15:06:38.745445: step 4310, loss 0.293412, acc 0.90625\n",
      "2018-05-04T15:06:39.871433: step 4311, loss 0.371239, acc 0.84375\n",
      "2018-05-04T15:06:41.084981: step 4312, loss 0.3281, acc 0.875\n",
      "2018-05-04T15:06:42.259861: step 4313, loss 0.33394, acc 0.859375\n",
      "2018-05-04T15:06:43.354868: step 4314, loss 0.234419, acc 0.921875\n",
      "2018-05-04T15:06:44.485926: step 4315, loss 0.229742, acc 0.90625\n",
      "2018-05-04T15:06:45.627412: step 4316, loss 0.295289, acc 0.859375\n",
      "2018-05-04T15:06:46.819245: step 4317, loss 0.29723, acc 0.875\n",
      "2018-05-04T15:06:47.936095: step 4318, loss 0.292813, acc 0.90625\n",
      "2018-05-04T15:06:49.004763: step 4319, loss 0.277525, acc 0.890625\n",
      "2018-05-04T15:06:50.105548: step 4320, loss 0.321432, acc 0.84375\n",
      "2018-05-04T15:06:51.252584: step 4321, loss 0.5025, acc 0.828125\n",
      "2018-05-04T15:06:52.332371: step 4322, loss 0.287611, acc 0.890625\n",
      "2018-05-04T15:06:53.417450: step 4323, loss 0.32157, acc 0.859375\n",
      "2018-05-04T15:06:54.623783: step 4324, loss 0.326193, acc 0.875\n",
      "2018-05-04T15:06:55.837734: step 4325, loss 0.474676, acc 0.84375\n",
      "2018-05-04T15:06:56.933487: step 4326, loss 0.331302, acc 0.84375\n",
      "2018-05-04T15:06:58.019944: step 4327, loss 0.237568, acc 0.921875\n",
      "2018-05-04T15:06:59.113553: step 4328, loss 0.34845, acc 0.828125\n",
      "2018-05-04T15:07:00.251841: step 4329, loss 0.248046, acc 0.921875\n",
      "2018-05-04T15:07:01.410107: step 4330, loss 0.284606, acc 0.875\n",
      "2018-05-04T15:07:02.485981: step 4331, loss 0.389722, acc 0.859375\n",
      "2018-05-04T15:07:03.576370: step 4332, loss 0.289197, acc 0.84375\n",
      "2018-05-04T15:07:04.744064: step 4333, loss 0.252916, acc 0.890625\n",
      "2018-05-04T15:07:05.883967: step 4334, loss 0.301272, acc 0.875\n",
      "2018-05-04T15:07:06.969065: step 4335, loss 0.240154, acc 0.890625\n",
      "2018-05-04T15:07:08.056494: step 4336, loss 0.310348, acc 0.9375\n",
      "2018-05-04T15:07:09.152687: step 4337, loss 0.321436, acc 0.890625\n",
      "2018-05-04T15:07:10.333079: step 4338, loss 0.326801, acc 0.859375\n",
      "2018-05-04T15:07:11.549642: step 4339, loss 0.346104, acc 0.84375\n",
      "2018-05-04T15:07:12.657054: step 4340, loss 0.330664, acc 0.890625\n",
      "2018-05-04T15:07:13.864033: step 4341, loss 0.298499, acc 0.875\n",
      "2018-05-04T15:07:14.990154: step 4342, loss 0.315469, acc 0.9375\n",
      "2018-05-04T15:07:16.116543: step 4343, loss 0.531579, acc 0.703125\n",
      "2018-05-04T15:07:17.220907: step 4344, loss 0.239733, acc 0.9375\n",
      "2018-05-04T15:07:18.317241: step 4345, loss 0.409249, acc 0.859375\n",
      "2018-05-04T15:07:19.441646: step 4346, loss 0.22824, acc 0.90625\n",
      "2018-05-04T15:07:20.593863: step 4347, loss 0.260727, acc 0.890625\n",
      "2018-05-04T15:07:21.776379: step 4348, loss 0.478321, acc 0.71875\n",
      "2018-05-04T15:07:22.875378: step 4349, loss 0.185988, acc 0.9375\n",
      "2018-05-04T15:07:23.957958: step 4350, loss 0.320447, acc 0.890625\n",
      "2018-05-04T15:07:25.052414: step 4351, loss 0.356217, acc 0.859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T15:07:26.124642: step 4352, loss 0.476511, acc 0.78125\n",
      "2018-05-04T15:07:27.194139: step 4353, loss 0.344518, acc 0.84375\n",
      "2018-05-04T15:07:28.291291: step 4354, loss 0.224103, acc 0.921875\n",
      "2018-05-04T15:07:29.435627: step 4355, loss 0.296144, acc 0.875\n",
      "2018-05-04T15:07:30.574767: step 4356, loss 0.446231, acc 0.8125\n",
      "2018-05-04T15:07:31.749797: step 4357, loss 0.189454, acc 0.921875\n",
      "2018-05-04T15:07:32.886509: step 4358, loss 0.290611, acc 0.90625\n",
      "2018-05-04T15:07:34.093028: step 4359, loss 0.313733, acc 0.90625\n",
      "2018-05-04T15:07:35.362575: step 4360, loss 0.273772, acc 0.859375\n",
      "2018-05-04T15:07:36.574958: step 4361, loss 0.20931, acc 0.90625\n",
      "2018-05-04T15:07:37.812824: step 4362, loss 0.243877, acc 0.859375\n",
      "2018-05-04T15:07:39.026382: step 4363, loss 0.311495, acc 0.90625\n",
      "2018-05-04T15:07:40.201427: step 4364, loss 0.234731, acc 0.9375\n",
      "2018-05-04T15:07:41.353946: step 4365, loss 0.405509, acc 0.859375\n",
      "2018-05-04T15:07:42.426787: step 4366, loss 0.227758, acc 0.90625\n",
      "2018-05-04T15:07:43.490449: step 4367, loss 0.273113, acc 0.875\n",
      "2018-05-04T15:07:44.573373: step 4368, loss 0.351048, acc 0.84375\n",
      "2018-05-04T15:07:45.679041: step 4369, loss 0.324405, acc 0.8125\n",
      "2018-05-04T15:07:46.748527: step 4370, loss 0.274516, acc 0.875\n",
      "2018-05-04T15:07:47.839242: step 4371, loss 0.222071, acc 0.90625\n",
      "2018-05-04T15:07:49.001431: step 4372, loss 0.335591, acc 0.84375\n",
      "2018-05-04T15:07:50.122792: step 4373, loss 0.363535, acc 0.859375\n",
      "2018-05-04T15:07:51.307534: step 4374, loss 0.354329, acc 0.84375\n",
      "2018-05-04T15:07:52.435742: step 4375, loss 0.292476, acc 0.875\n",
      "2018-05-04T15:07:53.556055: step 4376, loss 0.328284, acc 0.875\n",
      "2018-05-04T15:07:54.696511: step 4377, loss 0.252244, acc 0.890625\n",
      "2018-05-04T15:07:55.816380: step 4378, loss 0.44215, acc 0.796875\n",
      "2018-05-04T15:07:56.943140: step 4379, loss 0.384802, acc 0.90625\n",
      "2018-05-04T15:07:58.021409: step 4380, loss 0.337668, acc 0.78125\n",
      "2018-05-04T15:07:59.113306: step 4381, loss 0.181622, acc 0.921875\n",
      "2018-05-04T15:08:00.227350: step 4382, loss 0.237256, acc 0.90625\n",
      "2018-05-04T15:08:01.358212: step 4383, loss 0.370531, acc 0.828125\n",
      "2018-05-04T15:08:02.446403: step 4384, loss 0.365653, acc 0.796875\n",
      "2018-05-04T15:08:03.554553: step 4385, loss 0.390435, acc 0.859375\n",
      "2018-05-04T15:08:04.758223: step 4386, loss 0.248252, acc 0.9375\n",
      "2018-05-04T15:08:05.888629: step 4387, loss 0.292758, acc 0.859375\n",
      "2018-05-04T15:08:07.021730: step 4388, loss 0.241905, acc 0.875\n",
      "2018-05-04T15:08:08.147712: step 4389, loss 0.361513, acc 0.875\n",
      "2018-05-04T15:08:09.280943: step 4390, loss 0.200111, acc 0.921875\n",
      "2018-05-04T15:08:10.444467: step 4391, loss 0.357051, acc 0.875\n",
      "2018-05-04T15:08:11.649768: step 4392, loss 0.325721, acc 0.890625\n",
      "2018-05-04T15:08:12.743902: step 4393, loss 0.226407, acc 0.9375\n",
      "2018-05-04T15:08:13.871689: step 4394, loss 0.24283, acc 0.90625\n",
      "2018-05-04T15:08:14.999643: step 4395, loss 0.250882, acc 0.921875\n",
      "2018-05-04T15:08:16.112142: step 4396, loss 0.251636, acc 0.859375\n",
      "2018-05-04T15:08:17.228570: step 4397, loss 0.279459, acc 0.890625\n",
      "2018-05-04T15:08:18.327533: step 4398, loss 0.385651, acc 0.84375\n",
      "2018-05-04T15:08:19.453271: step 4399, loss 0.302492, acc 0.859375\n",
      "2018-05-04T15:08:20.655481: step 4400, loss 0.333291, acc 0.828125\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T15:08:23.142915: step 4400, loss 0.274455, acc 0.892\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-4400\n",
      "\n",
      "2018-05-04T15:08:24.358083: step 4401, loss 0.177683, acc 0.9375\n",
      "2018-05-04T15:08:25.467844: step 4402, loss 0.28583, acc 0.90625\n",
      "2018-05-04T15:08:26.569596: step 4403, loss 0.300773, acc 0.890625\n",
      "2018-05-04T15:08:27.694923: step 4404, loss 0.376048, acc 0.859375\n",
      "2018-05-04T15:08:28.824716: step 4405, loss 0.287229, acc 0.875\n",
      "2018-05-04T15:08:29.950544: step 4406, loss 0.296285, acc 0.90625\n",
      "2018-05-04T15:08:31.099425: step 4407, loss 0.358231, acc 0.8125\n",
      "2018-05-04T15:08:32.256909: step 4408, loss 0.386708, acc 0.859375\n",
      "2018-05-04T15:08:33.379565: step 4409, loss 0.455972, acc 0.859375\n",
      "2018-05-04T15:08:34.585344: step 4410, loss 0.346302, acc 0.84375\n",
      "2018-05-04T15:08:35.704663: step 4411, loss 0.502258, acc 0.796875\n",
      "2018-05-04T15:08:36.827864: step 4412, loss 0.280863, acc 0.875\n",
      "2018-05-04T15:08:37.947987: step 4413, loss 0.584838, acc 0.703125\n",
      "2018-05-04T15:08:39.118462: step 4414, loss 0.337587, acc 0.875\n",
      "2018-05-04T15:08:40.279647: step 4415, loss 0.187362, acc 0.9375\n",
      "2018-05-04T15:08:41.497364: step 4416, loss 0.398254, acc 0.84375\n",
      "2018-05-04T15:08:42.649899: step 4417, loss 0.338659, acc 0.859375\n",
      "2018-05-04T15:08:43.725023: step 4418, loss 0.295894, acc 0.84375\n",
      "2018-05-04T15:08:44.810375: step 4419, loss 0.332254, acc 0.890625\n",
      "2018-05-04T15:08:45.877920: step 4420, loss 0.321208, acc 0.84375\n",
      "2018-05-04T15:08:47.048510: step 4421, loss 0.295732, acc 0.875\n",
      "2018-05-04T15:08:48.155235: step 4422, loss 0.391116, acc 0.828125\n",
      "2018-05-04T15:08:49.281125: step 4423, loss 0.323222, acc 0.859375\n",
      "2018-05-04T15:08:50.387994: step 4424, loss 0.351142, acc 0.859375\n",
      "2018-05-04T15:08:51.669355: step 4425, loss 0.28435, acc 0.890625\n",
      "2018-05-04T15:08:52.857815: step 4426, loss 0.334503, acc 0.890625\n",
      "2018-05-04T15:08:54.049220: step 4427, loss 0.34103, acc 0.859375\n",
      "2018-05-04T15:08:55.209769: step 4428, loss 0.32176, acc 0.828125\n",
      "2018-05-04T15:08:56.338031: step 4429, loss 0.241987, acc 0.90625\n",
      "2018-05-04T15:08:57.496130: step 4430, loss 0.27861, acc 0.875\n",
      "2018-05-04T15:08:58.656800: step 4431, loss 0.284437, acc 0.890625\n",
      "2018-05-04T15:08:59.808454: step 4432, loss 0.360921, acc 0.875\n",
      "2018-05-04T15:09:01.003260: step 4433, loss 0.349443, acc 0.859375\n",
      "2018-05-04T15:09:02.188758: step 4434, loss 0.309859, acc 0.875\n",
      "2018-05-04T15:09:03.313859: step 4435, loss 0.247767, acc 0.890625\n",
      "2018-05-04T15:09:04.474588: step 4436, loss 0.368879, acc 0.921875\n",
      "2018-05-04T15:09:05.595485: step 4437, loss 0.245451, acc 0.921875\n",
      "2018-05-04T15:09:06.728105: step 4438, loss 0.288542, acc 0.90625\n",
      "2018-05-04T15:09:07.887207: step 4439, loss 0.279575, acc 0.875\n",
      "2018-05-04T15:09:09.027933: step 4440, loss 0.218545, acc 0.921875\n",
      "2018-05-04T15:09:10.173243: step 4441, loss 0.312243, acc 0.84375\n",
      "2018-05-04T15:09:11.333994: step 4442, loss 0.345757, acc 0.859375\n",
      "2018-05-04T15:09:12.505116: step 4443, loss 0.20419, acc 0.90625\n",
      "2018-05-04T15:09:13.663846: step 4444, loss 0.264465, acc 0.90625\n",
      "2018-05-04T15:09:14.847493: step 4445, loss 0.29578, acc 0.90625\n",
      "2018-05-04T15:09:16.024047: step 4446, loss 0.315158, acc 0.84375\n",
      "2018-05-04T15:09:17.204673: step 4447, loss 0.279189, acc 0.890625\n",
      "2018-05-04T15:09:18.342006: step 4448, loss 0.31779, acc 0.90625\n",
      "2018-05-04T15:09:19.437185: step 4449, loss 0.426256, acc 0.796875\n",
      "2018-05-04T15:09:20.596719: step 4450, loss 0.397605, acc 0.890625\n",
      "2018-05-04T15:09:21.811901: step 4451, loss 0.244012, acc 0.921875\n",
      "2018-05-04T15:09:22.898749: step 4452, loss 0.417767, acc 0.8125\n",
      "2018-05-04T15:09:24.012787: step 4453, loss 0.279835, acc 0.90625\n",
      "2018-05-04T15:09:25.143826: step 4454, loss 0.501673, acc 0.8125\n",
      "2018-05-04T15:09:26.298661: step 4455, loss 0.24465, acc 0.90625\n",
      "2018-05-04T15:09:27.458852: step 4456, loss 0.166798, acc 0.96875\n",
      "2018-05-04T15:09:28.642483: step 4457, loss 0.261377, acc 0.890625\n",
      "2018-05-04T15:09:29.868768: step 4458, loss 0.239595, acc 0.875\n",
      "2018-05-04T15:09:31.110075: step 4459, loss 0.153635, acc 0.953125\n",
      "2018-05-04T15:09:32.293207: step 4460, loss 0.372242, acc 0.859375\n",
      "2018-05-04T15:09:33.446582: step 4461, loss 0.320442, acc 0.859375\n",
      "2018-05-04T15:09:34.613138: step 4462, loss 0.336882, acc 0.890625\n",
      "2018-05-04T15:09:35.757875: step 4463, loss 0.301889, acc 0.890625\n",
      "2018-05-04T15:09:36.921420: step 4464, loss 0.321087, acc 0.859375\n",
      "2018-05-04T15:09:38.087354: step 4465, loss 0.295207, acc 0.890625\n",
      "2018-05-04T15:09:39.245530: step 4466, loss 0.183788, acc 0.9375\n",
      "2018-05-04T15:09:40.377094: step 4467, loss 0.241962, acc 0.890625\n",
      "2018-05-04T15:09:41.601941: step 4468, loss 0.239576, acc 0.921875\n",
      "2018-05-04T15:09:42.751665: step 4469, loss 0.370534, acc 0.859375\n",
      "2018-05-04T15:09:43.914602: step 4470, loss 0.363363, acc 0.765625\n",
      "2018-05-04T15:09:45.064663: step 4471, loss 0.313019, acc 0.859375\n",
      "2018-05-04T15:09:46.234428: step 4472, loss 0.238572, acc 0.890625\n",
      "2018-05-04T15:09:47.389415: step 4473, loss 0.247903, acc 0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T15:09:48.538395: step 4474, loss 0.324578, acc 0.84375\n",
      "2018-05-04T15:09:49.700263: step 4475, loss 0.405392, acc 0.8125\n",
      "2018-05-04T15:09:50.845203: step 4476, loss 0.401017, acc 0.8125\n",
      "2018-05-04T15:09:52.034678: step 4477, loss 0.338328, acc 0.859375\n",
      "2018-05-04T15:09:53.173067: step 4478, loss 0.277261, acc 0.890625\n",
      "2018-05-04T15:09:54.312295: step 4479, loss 0.465089, acc 0.828125\n",
      "2018-05-04T15:09:55.449074: step 4480, loss 0.230823, acc 0.90625\n",
      "2018-05-04T15:09:56.594263: step 4481, loss 0.268799, acc 0.890625\n",
      "2018-05-04T15:09:57.758547: step 4482, loss 0.294639, acc 0.890625\n",
      "2018-05-04T15:09:58.895249: step 4483, loss 0.344333, acc 0.84375\n",
      "2018-05-04T15:10:00.027656: step 4484, loss 0.235255, acc 0.921875\n",
      "2018-05-04T15:10:01.232724: step 4485, loss 0.288654, acc 0.84375\n",
      "2018-05-04T15:10:02.408028: step 4486, loss 0.327063, acc 0.828125\n",
      "2018-05-04T15:10:03.564687: step 4487, loss 0.381784, acc 0.84375\n",
      "2018-05-04T15:10:04.695778: step 4488, loss 0.218869, acc 0.921875\n",
      "2018-05-04T15:10:05.841397: step 4489, loss 0.368667, acc 0.84375\n",
      "2018-05-04T15:10:06.962346: step 4490, loss 0.272751, acc 0.859375\n",
      "2018-05-04T15:10:08.073933: step 4491, loss 0.231484, acc 0.890625\n",
      "2018-05-04T15:10:09.177042: step 4492, loss 0.266522, acc 0.875\n",
      "2018-05-04T15:10:10.378006: step 4493, loss 0.300974, acc 0.859375\n",
      "2018-05-04T15:10:11.641095: step 4494, loss 0.250372, acc 0.921875\n",
      "2018-05-04T15:10:12.813655: step 4495, loss 0.253259, acc 0.90625\n",
      "2018-05-04T15:10:13.984063: step 4496, loss 0.229967, acc 0.890625\n",
      "2018-05-04T15:10:15.142539: step 4497, loss 0.27302, acc 0.859375\n",
      "2018-05-04T15:10:16.276956: step 4498, loss 0.295046, acc 0.84375\n",
      "2018-05-04T15:10:17.422983: step 4499, loss 0.295502, acc 0.875\n",
      "2018-05-04T15:10:18.537210: step 4500, loss 0.286577, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T15:10:21.057249: step 4500, loss 0.252363, acc 0.906\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-4500\n",
      "\n",
      "2018-05-04T15:10:22.316082: step 4501, loss 0.234476, acc 0.90625\n",
      "2018-05-04T15:10:23.520148: step 4502, loss 0.248552, acc 0.9375\n",
      "2018-05-04T15:10:24.720339: step 4503, loss 0.33108, acc 0.859375\n",
      "2018-05-04T15:10:25.862766: step 4504, loss 0.349109, acc 0.8125\n",
      "2018-05-04T15:10:27.011896: step 4505, loss 0.325767, acc 0.875\n",
      "2018-05-04T15:10:28.163266: step 4506, loss 0.324428, acc 0.875\n",
      "2018-05-04T15:10:29.324333: step 4507, loss 0.193609, acc 0.9375\n",
      "2018-05-04T15:10:30.473757: step 4508, loss 0.323017, acc 0.875\n",
      "2018-05-04T15:10:31.663964: step 4509, loss 0.290403, acc 0.890625\n",
      "2018-05-04T15:10:32.839624: step 4510, loss 0.300677, acc 0.890625\n",
      "2018-05-04T15:10:34.083683: step 4511, loss 0.234787, acc 0.921875\n",
      "2018-05-04T15:10:35.308018: step 4512, loss 0.363957, acc 0.796875\n",
      "2018-05-04T15:10:36.525676: step 4513, loss 0.186003, acc 0.953125\n",
      "2018-05-04T15:10:37.705680: step 4514, loss 0.21957, acc 0.90625\n",
      "2018-05-04T15:10:38.866115: step 4515, loss 0.315836, acc 0.890625\n",
      "2018-05-04T15:10:40.026854: step 4516, loss 0.251925, acc 0.90625\n",
      "2018-05-04T15:10:41.256857: step 4517, loss 0.37321, acc 0.890625\n",
      "2018-05-04T15:10:42.409494: step 4518, loss 0.409635, acc 0.828125\n",
      "2018-05-04T15:10:43.551378: step 4519, loss 0.265107, acc 0.875\n",
      "2018-05-04T15:10:44.717959: step 4520, loss 0.301004, acc 0.859375\n",
      "2018-05-04T15:10:45.872601: step 4521, loss 0.253402, acc 0.890625\n",
      "2018-05-04T15:10:47.019273: step 4522, loss 0.317832, acc 0.890625\n",
      "2018-05-04T15:10:48.174071: step 4523, loss 0.379904, acc 0.796875\n",
      "2018-05-04T15:10:49.371469: step 4524, loss 0.259983, acc 0.921875\n",
      "2018-05-04T15:10:50.529905: step 4525, loss 0.410592, acc 0.78125\n",
      "2018-05-04T15:10:51.741869: step 4526, loss 0.333159, acc 0.84375\n",
      "2018-05-04T15:10:52.894029: step 4527, loss 0.325543, acc 0.8125\n",
      "2018-05-04T15:10:54.035429: step 4528, loss 0.282911, acc 0.9375\n",
      "2018-05-04T15:10:55.189020: step 4529, loss 0.255464, acc 0.875\n",
      "2018-05-04T15:10:56.341391: step 4530, loss 0.252332, acc 0.90625\n",
      "2018-05-04T15:10:57.471961: step 4531, loss 0.319975, acc 0.859375\n",
      "2018-05-04T15:10:58.619491: step 4532, loss 0.20872, acc 0.90625\n",
      "2018-05-04T15:10:59.768789: step 4533, loss 0.275961, acc 0.84375\n",
      "2018-05-04T15:11:00.936845: step 4534, loss 0.274452, acc 0.90625\n",
      "2018-05-04T15:11:02.115282: step 4535, loss 0.379533, acc 0.828125\n",
      "2018-05-04T15:11:03.254835: step 4536, loss 0.280211, acc 0.90625\n",
      "2018-05-04T15:11:04.416070: step 4537, loss 0.324246, acc 0.875\n",
      "2018-05-04T15:11:05.546487: step 4538, loss 0.364731, acc 0.8125\n",
      "2018-05-04T15:11:06.693111: step 4539, loss 0.352905, acc 0.90625\n",
      "2018-05-04T15:11:07.821948: step 4540, loss 0.335639, acc 0.890625\n",
      "2018-05-04T15:11:08.980367: step 4541, loss 0.355229, acc 0.8125\n",
      "2018-05-04T15:11:10.117145: step 4542, loss 0.575533, acc 0.734375\n",
      "2018-05-04T15:11:11.325147: step 4543, loss 0.334813, acc 0.890625\n",
      "2018-05-04T15:11:12.515268: step 4544, loss 0.372826, acc 0.828125\n",
      "2018-05-04T15:11:13.715619: step 4545, loss 0.255995, acc 0.890625\n",
      "2018-05-04T15:11:14.914892: step 4546, loss 0.30903, acc 0.828125\n",
      "2018-05-04T15:11:16.091989: step 4547, loss 0.253822, acc 0.890625\n",
      "2018-05-04T15:11:17.279543: step 4548, loss 0.397651, acc 0.796875\n",
      "2018-05-04T15:11:18.411118: step 4549, loss 0.321195, acc 0.890625\n",
      "2018-05-04T15:11:19.585869: step 4550, loss 0.219724, acc 0.90625\n",
      "2018-05-04T15:11:20.789025: step 4551, loss 0.294232, acc 0.859375\n",
      "2018-05-04T15:11:21.943631: step 4552, loss 0.374059, acc 0.890625\n",
      "2018-05-04T15:11:23.093073: step 4553, loss 0.330244, acc 0.875\n",
      "2018-05-04T15:11:24.213064: step 4554, loss 0.334569, acc 0.84375\n",
      "2018-05-04T15:11:25.366267: step 4555, loss 0.267625, acc 0.890625\n",
      "2018-05-04T15:11:26.506800: step 4556, loss 0.342726, acc 0.84375\n",
      "2018-05-04T15:11:27.636605: step 4557, loss 0.289358, acc 0.8125\n",
      "2018-05-04T15:11:28.742170: step 4558, loss 0.296248, acc 0.859375\n",
      "2018-05-04T15:11:29.897323: step 4559, loss 0.264347, acc 0.875\n",
      "2018-05-04T15:11:31.126990: step 4560, loss 0.382139, acc 0.8125\n",
      "2018-05-04T15:11:32.338479: step 4561, loss 0.331303, acc 0.875\n",
      "2018-05-04T15:11:33.507799: step 4562, loss 0.261928, acc 0.890625\n",
      "2018-05-04T15:11:34.689223: step 4563, loss 0.267703, acc 0.90625\n",
      "2018-05-04T15:11:35.866694: step 4564, loss 0.399914, acc 0.8125\n",
      "2018-05-04T15:11:37.050923: step 4565, loss 0.212172, acc 0.890625\n",
      "2018-05-04T15:11:38.223461: step 4566, loss 0.382529, acc 0.859375\n",
      "2018-05-04T15:11:39.383046: step 4567, loss 0.228437, acc 0.9375\n",
      "2018-05-04T15:11:40.463740: step 4568, loss 0.285603, acc 0.859375\n",
      "2018-05-04T15:11:41.664234: step 4569, loss 0.262567, acc 0.875\n",
      "2018-05-04T15:11:42.806780: step 4570, loss 0.424756, acc 0.84375\n",
      "2018-05-04T15:11:43.969489: step 4571, loss 0.38611, acc 0.8125\n",
      "2018-05-04T15:11:45.173069: step 4572, loss 0.338305, acc 0.875\n",
      "2018-05-04T15:11:46.344657: step 4573, loss 0.285266, acc 0.90625\n",
      "2018-05-04T15:11:47.508542: step 4574, loss 0.500857, acc 0.84375\n",
      "2018-05-04T15:11:48.658965: step 4575, loss 0.293082, acc 0.859375\n",
      "2018-05-04T15:11:49.809288: step 4576, loss 0.234548, acc 0.90625\n",
      "2018-05-04T15:11:50.982649: step 4577, loss 0.319144, acc 0.828125\n",
      "2018-05-04T15:11:52.160838: step 4578, loss 0.316679, acc 0.859375\n",
      "2018-05-04T15:11:53.272860: step 4579, loss 0.336295, acc 0.828125\n",
      "2018-05-04T15:11:54.427535: step 4580, loss 0.264595, acc 0.859375\n",
      "2018-05-04T15:11:55.556543: step 4581, loss 0.275228, acc 0.859375\n",
      "2018-05-04T15:11:56.716508: step 4582, loss 0.246088, acc 0.9375\n",
      "2018-05-04T15:11:57.871688: step 4583, loss 0.209447, acc 0.921875\n",
      "2018-05-04T15:11:59.037440: step 4584, loss 0.321595, acc 0.875\n",
      "2018-05-04T15:12:00.181232: step 4585, loss 0.269193, acc 0.875\n",
      "2018-05-04T15:12:01.378695: step 4586, loss 0.177715, acc 0.953125\n",
      "2018-05-04T15:12:02.501853: step 4587, loss 0.325873, acc 0.859375\n",
      "2018-05-04T15:12:03.659307: step 4588, loss 0.338608, acc 0.84375\n",
      "2018-05-04T15:12:04.797453: step 4589, loss 0.2812, acc 0.859375\n",
      "2018-05-04T15:12:05.909419: step 4590, loss 0.357619, acc 0.90625\n",
      "2018-05-04T15:12:07.052427: step 4591, loss 0.320906, acc 0.90625\n",
      "2018-05-04T15:12:08.201369: step 4592, loss 0.327325, acc 0.875\n",
      "2018-05-04T15:12:09.371772: step 4593, loss 0.303659, acc 0.84375\n",
      "2018-05-04T15:12:10.513731: step 4594, loss 0.228511, acc 0.890625\n",
      "2018-05-04T15:12:11.728955: step 4595, loss 0.293488, acc 0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T15:12:12.872244: step 4596, loss 0.371742, acc 0.828125\n",
      "2018-05-04T15:12:14.020304: step 4597, loss 0.233121, acc 0.875\n",
      "2018-05-04T15:12:15.148881: step 4598, loss 0.249837, acc 0.90625\n",
      "2018-05-04T15:12:16.286166: step 4599, loss 0.32217, acc 0.875\n",
      "2018-05-04T15:12:17.398098: step 4600, loss 0.254086, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T15:12:20.412358: step 4600, loss 0.25488, acc 0.904\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-4600\n",
      "\n",
      "2018-05-04T15:12:21.708563: step 4601, loss 0.206883, acc 0.890625\n",
      "2018-05-04T15:12:22.923183: step 4602, loss 0.188825, acc 0.9375\n",
      "2018-05-04T15:12:24.106512: step 4603, loss 0.201354, acc 0.921875\n",
      "2018-05-04T15:12:25.309751: step 4604, loss 0.409404, acc 0.828125\n",
      "2018-05-04T15:12:26.561899: step 4605, loss 0.291605, acc 0.90625\n",
      "2018-05-04T15:12:27.747436: step 4606, loss 0.290533, acc 0.890625\n",
      "2018-05-04T15:12:28.909739: step 4607, loss 0.260286, acc 0.890625\n",
      "2018-05-04T15:12:30.112829: step 4608, loss 0.231914, acc 0.890625\n",
      "2018-05-04T15:12:31.310891: step 4609, loss 0.227741, acc 0.90625\n",
      "2018-05-04T15:12:32.419143: step 4610, loss 0.194006, acc 0.953125\n",
      "2018-05-04T15:12:33.516542: step 4611, loss 0.409731, acc 0.84375\n",
      "2018-05-04T15:12:34.685956: step 4612, loss 0.34211, acc 0.859375\n",
      "2018-05-04T15:12:35.782293: step 4613, loss 0.287145, acc 0.859375\n",
      "2018-05-04T15:12:36.954093: step 4614, loss 0.205921, acc 0.9375\n",
      "2018-05-04T15:12:38.060243: step 4615, loss 0.311966, acc 0.84375\n",
      "2018-05-04T15:12:39.151826: step 4616, loss 0.353352, acc 0.890625\n",
      "2018-05-04T15:12:40.250493: step 4617, loss 0.273176, acc 0.875\n",
      "2018-05-04T15:12:41.417122: step 4618, loss 0.210341, acc 0.90625\n",
      "2018-05-04T15:12:42.512560: step 4619, loss 0.180767, acc 0.953125\n",
      "2018-05-04T15:12:43.615697: step 4620, loss 0.331262, acc 0.890625\n",
      "2018-05-04T15:12:44.802624: step 4621, loss 0.262665, acc 0.859375\n",
      "2018-05-04T15:12:45.935799: step 4622, loss 0.407934, acc 0.828125\n",
      "2018-05-04T15:12:47.069425: step 4623, loss 0.483987, acc 0.796875\n",
      "2018-05-04T15:12:48.196469: step 4624, loss 0.318441, acc 0.84375\n",
      "2018-05-04T15:12:49.395222: step 4625, loss 0.344265, acc 0.828125\n",
      "2018-05-04T15:12:50.524717: step 4626, loss 0.286316, acc 0.875\n",
      "2018-05-04T15:12:51.755338: step 4627, loss 0.245911, acc 0.90625\n",
      "2018-05-04T15:12:52.870023: step 4628, loss 0.209524, acc 0.890625\n",
      "2018-05-04T15:12:54.008545: step 4629, loss 0.291755, acc 0.890625\n",
      "2018-05-04T15:12:55.137584: step 4630, loss 0.288018, acc 0.90625\n",
      "2018-05-04T15:12:56.277445: step 4631, loss 0.287438, acc 0.859375\n",
      "2018-05-04T15:12:57.421076: step 4632, loss 0.362137, acc 0.8125\n",
      "2018-05-04T15:12:58.537689: step 4633, loss 0.256724, acc 0.921875\n",
      "2018-05-04T15:12:59.683934: step 4634, loss 0.363833, acc 0.796875\n",
      "2018-05-04T15:13:00.797636: step 4635, loss 0.182517, acc 0.9375\n",
      "2018-05-04T15:13:01.914539: step 4636, loss 0.427283, acc 0.796875\n",
      "2018-05-04T15:13:02.990167: step 4637, loss 0.441557, acc 0.84375\n",
      "2018-05-04T15:13:04.121070: step 4638, loss 0.224614, acc 0.890625\n",
      "2018-05-04T15:13:05.336357: step 4639, loss 0.247339, acc 0.890625\n",
      "2018-05-04T15:13:06.453313: step 4640, loss 0.202403, acc 0.921875\n",
      "2018-05-04T15:13:07.573444: step 4641, loss 0.372142, acc 0.828125\n",
      "2018-05-04T15:13:08.771265: step 4642, loss 0.190831, acc 0.96875\n",
      "2018-05-04T15:13:09.948578: step 4643, loss 0.224704, acc 0.921875\n",
      "2018-05-04T15:13:11.069031: step 4644, loss 0.273045, acc 0.890625\n",
      "2018-05-04T15:13:12.177045: step 4645, loss 0.273359, acc 0.890625\n",
      "2018-05-04T15:13:13.249505: step 4646, loss 0.314765, acc 0.890625\n",
      "2018-05-04T15:13:14.361898: step 4647, loss 0.291144, acc 0.890625\n",
      "2018-05-04T15:13:15.498408: step 4648, loss 0.247659, acc 0.921875\n",
      "2018-05-04T15:13:16.637493: step 4649, loss 0.415952, acc 0.8125\n",
      "2018-05-04T15:13:17.792927: step 4650, loss 0.19249, acc 0.90625\n",
      "2018-05-04T15:13:18.911873: step 4651, loss 0.40936, acc 0.796875\n",
      "2018-05-04T15:13:20.041075: step 4652, loss 0.42813, acc 0.859375\n",
      "2018-05-04T15:13:21.246890: step 4653, loss 0.187283, acc 0.921875\n",
      "2018-05-04T15:13:22.364673: step 4654, loss 0.276783, acc 0.875\n",
      "2018-05-04T15:13:23.515080: step 4655, loss 0.408059, acc 0.875\n",
      "2018-05-04T15:13:24.638370: step 4656, loss 0.255941, acc 0.890625\n",
      "2018-05-04T15:13:25.761528: step 4657, loss 0.266098, acc 0.90625\n",
      "2018-05-04T15:13:26.859825: step 4658, loss 0.253651, acc 0.90625\n",
      "2018-05-04T15:13:27.972579: step 4659, loss 0.23678, acc 0.921875\n",
      "2018-05-04T15:13:29.106490: step 4660, loss 0.260991, acc 0.90625\n",
      "2018-05-04T15:13:30.231382: step 4661, loss 0.337005, acc 0.828125\n",
      "2018-05-04T15:13:31.399541: step 4662, loss 0.261328, acc 0.859375\n",
      "2018-05-04T15:13:32.514954: step 4663, loss 0.166228, acc 0.953125\n",
      "2018-05-04T15:13:33.717128: step 4664, loss 0.407927, acc 0.859375\n",
      "2018-05-04T15:13:34.921846: step 4665, loss 0.381617, acc 0.8125\n",
      "2018-05-04T15:13:36.120862: step 4666, loss 0.289746, acc 0.890625\n",
      "2018-05-04T15:13:37.391002: step 4667, loss 0.283694, acc 0.84375\n",
      "2018-05-04T15:13:38.605929: step 4668, loss 0.208743, acc 0.9375\n",
      "2018-05-04T15:13:39.797571: step 4669, loss 0.346269, acc 0.859375\n",
      "2018-05-04T15:13:40.976396: step 4670, loss 0.517855, acc 0.765625\n",
      "2018-05-04T15:13:42.140296: step 4671, loss 0.271158, acc 0.84375\n",
      "2018-05-04T15:13:43.305495: step 4672, loss 0.254339, acc 0.890625\n",
      "2018-05-04T15:13:44.441861: step 4673, loss 0.322862, acc 0.859375\n",
      "2018-05-04T15:13:45.586638: step 4674, loss 0.241658, acc 0.890625\n",
      "2018-05-04T15:13:46.716164: step 4675, loss 0.413515, acc 0.8125\n",
      "2018-05-04T15:13:47.856351: step 4676, loss 0.225501, acc 0.921875\n",
      "2018-05-04T15:13:49.013296: step 4677, loss 0.364739, acc 0.84375\n",
      "2018-05-04T15:13:50.138090: step 4678, loss 0.313291, acc 0.875\n",
      "2018-05-04T15:13:51.281761: step 4679, loss 0.173523, acc 0.9375\n",
      "2018-05-04T15:13:52.352145: step 4680, loss 0.462688, acc 0.8125\n",
      "2018-05-04T15:13:53.435028: step 4681, loss 0.212724, acc 0.890625\n",
      "2018-05-04T15:13:54.538971: step 4682, loss 0.261587, acc 0.890625\n",
      "2018-05-04T15:13:55.657738: step 4683, loss 0.235646, acc 0.921875\n",
      "2018-05-04T15:13:56.787049: step 4684, loss 0.29544, acc 0.90625\n",
      "2018-05-04T15:13:57.913889: step 4685, loss 0.254972, acc 0.890625\n",
      "2018-05-04T15:13:59.044211: step 4686, loss 0.329248, acc 0.859375\n",
      "2018-05-04T15:14:00.193844: step 4687, loss 0.229522, acc 0.921875\n",
      "2018-05-04T15:14:01.426651: step 4688, loss 0.212194, acc 0.9375\n",
      "2018-05-04T15:14:02.619390: step 4689, loss 0.257505, acc 0.90625\n",
      "2018-05-04T15:14:03.711474: step 4690, loss 0.299202, acc 0.890625\n",
      "2018-05-04T15:14:04.898033: step 4691, loss 0.307845, acc 0.890625\n",
      "2018-05-04T15:14:05.973659: step 4692, loss 0.372163, acc 0.875\n",
      "2018-05-04T15:14:07.059153: step 4693, loss 0.26004, acc 0.90625\n",
      "2018-05-04T15:14:08.149153: step 4694, loss 0.271619, acc 0.875\n",
      "2018-05-04T15:14:09.238180: step 4695, loss 0.307298, acc 0.890625\n",
      "2018-05-04T15:14:10.319218: step 4696, loss 0.365025, acc 0.84375\n",
      "2018-05-04T15:14:11.494881: step 4697, loss 0.232259, acc 0.90625\n",
      "2018-05-04T15:14:12.584551: step 4698, loss 0.185294, acc 0.9375\n",
      "2018-05-04T15:14:13.720065: step 4699, loss 0.234817, acc 0.90625\n",
      "2018-05-04T15:14:14.942743: step 4700, loss 0.349708, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T15:14:17.409776: step 4700, loss 0.257572, acc 0.894\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-4700\n",
      "\n",
      "2018-05-04T15:14:18.730846: step 4701, loss 0.18888, acc 0.921875\n",
      "2018-05-04T15:14:19.935750: step 4702, loss 0.265273, acc 0.890625\n",
      "2018-05-04T15:14:21.123699: step 4703, loss 0.35276, acc 0.84375\n",
      "2018-05-04T15:14:22.343115: step 4704, loss 0.235231, acc 0.890625\n",
      "2018-05-04T15:14:23.454465: step 4705, loss 0.309974, acc 0.859375\n",
      "2018-05-04T15:14:24.604363: step 4706, loss 0.236011, acc 0.875\n",
      "2018-05-04T15:14:25.730565: step 4707, loss 0.387344, acc 0.859375\n",
      "2018-05-04T15:14:26.851872: step 4708, loss 0.322978, acc 0.859375\n",
      "2018-05-04T15:14:28.025479: step 4709, loss 0.273654, acc 0.875\n",
      "2018-05-04T15:14:29.108642: step 4710, loss 0.250952, acc 0.9375\n",
      "2018-05-04T15:14:30.180179: step 4711, loss 0.322523, acc 0.890625\n",
      "2018-05-04T15:14:31.325995: step 4712, loss 0.27636, acc 0.890625\n",
      "2018-05-04T15:14:32.510335: step 4713, loss 0.170188, acc 0.9375\n",
      "2018-05-04T15:14:33.697283: step 4714, loss 0.386688, acc 0.84375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T15:14:34.828278: step 4715, loss 0.317494, acc 0.859375\n",
      "2018-05-04T15:14:36.005685: step 4716, loss 0.406882, acc 0.84375\n",
      "2018-05-04T15:14:37.119676: step 4717, loss 0.26236, acc 0.921875\n",
      "2018-05-04T15:14:38.215470: step 4718, loss 0.245725, acc 0.90625\n",
      "2018-05-04T15:14:39.361219: step 4719, loss 0.290615, acc 0.875\n",
      "2018-05-04T15:14:40.476020: step 4720, loss 0.225272, acc 0.921875\n",
      "2018-05-04T15:14:41.668676: step 4721, loss 0.204114, acc 0.9375\n",
      "2018-05-04T15:14:42.777586: step 4722, loss 0.343854, acc 0.828125\n",
      "2018-05-04T15:14:43.895860: step 4723, loss 0.285576, acc 0.859375\n",
      "2018-05-04T15:14:45.042531: step 4724, loss 0.184222, acc 0.9375\n",
      "2018-05-04T15:14:46.232104: step 4725, loss 0.200297, acc 0.890625\n",
      "2018-05-04T15:14:47.347178: step 4726, loss 0.247724, acc 0.90625\n",
      "2018-05-04T15:14:48.518371: step 4727, loss 0.333282, acc 0.859375\n",
      "2018-05-04T15:14:49.675835: step 4728, loss 0.240427, acc 0.921875\n",
      "2018-05-04T15:14:50.755418: step 4729, loss 0.30145, acc 0.875\n",
      "2018-05-04T15:14:51.876144: step 4730, loss 0.383325, acc 0.78125\n",
      "2018-05-04T15:14:53.028430: step 4731, loss 0.237511, acc 0.921875\n",
      "2018-05-04T15:14:54.100108: step 4732, loss 0.213383, acc 0.890625\n",
      "2018-05-04T15:14:55.195739: step 4733, loss 0.376041, acc 0.875\n",
      "2018-05-04T15:14:56.321720: step 4734, loss 0.241432, acc 0.890625\n",
      "2018-05-04T15:14:57.507277: step 4735, loss 0.224533, acc 0.921875\n",
      "2018-05-04T15:14:58.657830: step 4736, loss 0.277483, acc 0.90625\n",
      "2018-05-04T15:14:59.797915: step 4737, loss 0.212405, acc 0.90625\n",
      "2018-05-04T15:15:00.956701: step 4738, loss 0.353501, acc 0.875\n",
      "2018-05-04T15:15:02.077394: step 4739, loss 0.271019, acc 0.890625\n",
      "2018-05-04T15:15:03.192887: step 4740, loss 0.244769, acc 0.859375\n",
      "2018-05-04T15:15:04.426075: step 4741, loss 0.282766, acc 0.859375\n",
      "2018-05-04T15:15:05.548907: step 4742, loss 0.291327, acc 0.90625\n",
      "2018-05-04T15:15:06.720141: step 4743, loss 0.26471, acc 0.90625\n",
      "2018-05-04T15:15:07.846688: step 4744, loss 0.224568, acc 0.9375\n",
      "2018-05-04T15:15:08.969429: step 4745, loss 0.205024, acc 0.90625\n",
      "2018-05-04T15:15:10.139529: step 4746, loss 0.300655, acc 0.828125\n",
      "2018-05-04T15:15:11.350811: step 4747, loss 0.272446, acc 0.890625\n",
      "2018-05-04T15:15:12.486053: step 4748, loss 0.229357, acc 0.9375\n",
      "2018-05-04T15:15:13.617502: step 4749, loss 0.327089, acc 0.890625\n",
      "2018-05-04T15:15:14.781141: step 4750, loss 0.362651, acc 0.875\n",
      "2018-05-04T15:15:15.934274: step 4751, loss 0.226224, acc 0.90625\n",
      "2018-05-04T15:15:17.094419: step 4752, loss 0.291915, acc 0.859375\n",
      "2018-05-04T15:15:18.218135: step 4753, loss 0.270488, acc 0.90625\n",
      "2018-05-04T15:15:19.380113: step 4754, loss 0.289648, acc 0.875\n",
      "2018-05-04T15:15:20.541802: step 4755, loss 0.456546, acc 0.828125\n",
      "2018-05-04T15:15:21.716097: step 4756, loss 0.235568, acc 0.890625\n",
      "2018-05-04T15:15:22.875557: step 4757, loss 0.311247, acc 0.90625\n",
      "2018-05-04T15:15:24.048508: step 4758, loss 0.194392, acc 0.921875\n",
      "2018-05-04T15:15:25.204167: step 4759, loss 0.324961, acc 0.84375\n",
      "2018-05-04T15:15:26.277732: step 4760, loss 0.181856, acc 0.921875\n",
      "2018-05-04T15:15:27.434013: step 4761, loss 0.279454, acc 0.90625\n",
      "2018-05-04T15:15:28.575171: step 4762, loss 0.442235, acc 0.859375\n",
      "2018-05-04T15:15:29.732313: step 4763, loss 0.228036, acc 0.921875\n",
      "2018-05-04T15:15:30.925568: step 4764, loss 0.439287, acc 0.84375\n",
      "2018-05-04T15:15:32.114206: step 4765, loss 0.180847, acc 0.921875\n",
      "2018-05-04T15:15:33.265945: step 4766, loss 0.470229, acc 0.8125\n",
      "2018-05-04T15:15:34.448165: step 4767, loss 0.32447, acc 0.859375\n",
      "2018-05-04T15:15:35.608961: step 4768, loss 0.363601, acc 0.78125\n",
      "2018-05-04T15:15:36.769337: step 4769, loss 0.379541, acc 0.859375\n",
      "2018-05-04T15:15:37.923596: step 4770, loss 0.273912, acc 0.875\n",
      "2018-05-04T15:15:39.086044: step 4771, loss 0.386344, acc 0.859375\n",
      "2018-05-04T15:15:40.246471: step 4772, loss 0.291453, acc 0.859375\n",
      "2018-05-04T15:15:41.429005: step 4773, loss 0.228731, acc 0.890625\n",
      "2018-05-04T15:15:42.597732: step 4774, loss 0.245894, acc 0.859375\n",
      "2018-05-04T15:15:43.762942: step 4775, loss 0.180531, acc 0.984375\n",
      "2018-05-04T15:15:44.900241: step 4776, loss 0.361056, acc 0.8125\n",
      "2018-05-04T15:15:46.052403: step 4777, loss 0.270974, acc 0.875\n",
      "2018-05-04T15:15:47.191028: step 4778, loss 0.254068, acc 0.921875\n",
      "2018-05-04T15:15:48.306606: step 4779, loss 0.312187, acc 0.875\n",
      "2018-05-04T15:15:49.478281: step 4780, loss 0.216173, acc 0.96875\n",
      "2018-05-04T15:15:50.604230: step 4781, loss 0.305768, acc 0.84375\n",
      "2018-05-04T15:15:51.807443: step 4782, loss 0.338027, acc 0.875\n",
      "2018-05-04T15:15:52.951083: step 4783, loss 0.371319, acc 0.859375\n",
      "2018-05-04T15:15:54.041001: step 4784, loss 0.328328, acc 0.859375\n",
      "2018-05-04T15:15:55.204066: step 4785, loss 0.348288, acc 0.859375\n",
      "2018-05-04T15:15:56.283423: step 4786, loss 0.293435, acc 0.875\n",
      "2018-05-04T15:15:57.419563: step 4787, loss 0.305693, acc 0.875\n",
      "2018-05-04T15:15:58.561609: step 4788, loss 0.278443, acc 0.859375\n",
      "2018-05-04T15:15:59.728801: step 4789, loss 0.327567, acc 0.890625\n",
      "2018-05-04T15:16:00.905425: step 4790, loss 0.226041, acc 0.921875\n",
      "2018-05-04T15:16:02.077966: step 4791, loss 0.317287, acc 0.890625\n",
      "2018-05-04T15:16:03.257780: step 4792, loss 0.239012, acc 0.90625\n",
      "2018-05-04T15:16:04.444789: step 4793, loss 0.327504, acc 0.875\n",
      "2018-05-04T15:16:05.627179: step 4794, loss 0.354834, acc 0.875\n",
      "2018-05-04T15:16:06.758445: step 4795, loss 0.115948, acc 0.984375\n",
      "2018-05-04T15:16:07.895898: step 4796, loss 0.181191, acc 0.921875\n",
      "2018-05-04T15:16:09.044813: step 4797, loss 0.294883, acc 0.859375\n",
      "2018-05-04T15:16:10.217984: step 4798, loss 0.280618, acc 0.875\n",
      "2018-05-04T15:16:11.444207: step 4799, loss 0.174281, acc 0.984375\n",
      "2018-05-04T15:16:12.562105: step 4800, loss 0.37709, acc 0.796875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T15:16:15.198093: step 4800, loss 0.242956, acc 0.91\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-4800\n",
      "\n",
      "2018-05-04T15:16:16.475421: step 4801, loss 0.249665, acc 0.875\n",
      "2018-05-04T15:16:17.652166: step 4802, loss 0.272139, acc 0.890625\n",
      "2018-05-04T15:16:18.832964: step 4803, loss 0.227408, acc 0.90625\n",
      "2018-05-04T15:16:20.094958: step 4804, loss 0.22674, acc 0.875\n",
      "2018-05-04T15:16:21.356152: step 4805, loss 0.236336, acc 0.90625\n",
      "2018-05-04T15:16:22.511456: step 4806, loss 0.242415, acc 0.953125\n",
      "2018-05-04T15:16:23.657163: step 4807, loss 0.405923, acc 0.828125\n",
      "2018-05-04T15:16:24.775859: step 4808, loss 0.290043, acc 0.875\n",
      "2018-05-04T15:16:25.902386: step 4809, loss 0.297626, acc 0.90625\n",
      "2018-05-04T15:16:27.094151: step 4810, loss 0.283399, acc 0.921875\n",
      "2018-05-04T15:16:28.244811: step 4811, loss 0.254897, acc 0.90625\n",
      "2018-05-04T15:16:29.405174: step 4812, loss 0.190153, acc 0.921875\n",
      "2018-05-04T15:16:30.495054: step 4813, loss 0.297967, acc 0.875\n",
      "2018-05-04T15:16:31.645082: step 4814, loss 0.152861, acc 0.9375\n",
      "2018-05-04T15:16:32.838570: step 4815, loss 0.40361, acc 0.828125\n",
      "2018-05-04T15:16:34.015456: step 4816, loss 0.395345, acc 0.875\n",
      "2018-05-04T15:16:35.276486: step 4817, loss 0.317132, acc 0.875\n",
      "2018-05-04T15:16:36.461594: step 4818, loss 0.31142, acc 0.859375\n",
      "2018-05-04T15:16:37.633298: step 4819, loss 0.302782, acc 0.859375\n",
      "2018-05-04T15:16:38.769652: step 4820, loss 0.271851, acc 0.875\n",
      "2018-05-04T15:16:39.946708: step 4821, loss 0.221079, acc 0.90625\n",
      "2018-05-04T15:16:41.132812: step 4822, loss 0.345813, acc 0.828125\n",
      "2018-05-04T15:16:42.344606: step 4823, loss 0.302372, acc 0.875\n",
      "2018-05-04T15:16:43.480172: step 4824, loss 0.387893, acc 0.890625\n",
      "2018-05-04T15:16:44.685056: step 4825, loss 0.398917, acc 0.8125\n",
      "2018-05-04T15:16:45.796496: step 4826, loss 0.201041, acc 0.921875\n",
      "2018-05-04T15:16:46.870635: step 4827, loss 0.365225, acc 0.875\n",
      "2018-05-04T15:16:47.961256: step 4828, loss 0.232022, acc 0.890625\n",
      "2018-05-04T15:16:49.085944: step 4829, loss 0.288053, acc 0.875\n",
      "2018-05-04T15:16:50.196735: step 4830, loss 0.213979, acc 0.921875\n",
      "2018-05-04T15:16:51.338090: step 4831, loss 0.373546, acc 0.890625\n",
      "2018-05-04T15:16:52.516464: step 4832, loss 0.300883, acc 0.84375\n",
      "2018-05-04T15:16:53.634722: step 4833, loss 0.435492, acc 0.8125\n",
      "2018-05-04T15:16:54.788233: step 4834, loss 0.154814, acc 0.9375\n",
      "2018-05-04T15:16:55.896717: step 4835, loss 0.362408, acc 0.8125\n",
      "2018-05-04T15:16:57.012127: step 4836, loss 0.309318, acc 0.84375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T15:16:58.124870: step 4837, loss 0.387302, acc 0.84375\n",
      "2018-05-04T15:16:59.349505: step 4838, loss 0.455106, acc 0.828125\n",
      "2018-05-04T15:17:00.545103: step 4839, loss 0.386651, acc 0.84375\n",
      "2018-05-04T15:17:01.776018: step 4840, loss 0.199962, acc 0.90625\n",
      "2018-05-04T15:17:02.878557: step 4841, loss 0.276549, acc 0.921875\n",
      "2018-05-04T15:17:03.997747: step 4842, loss 0.23471, acc 0.90625\n",
      "2018-05-04T15:17:05.115879: step 4843, loss 0.417187, acc 0.8125\n",
      "2018-05-04T15:17:06.204571: step 4844, loss 0.407981, acc 0.8125\n",
      "2018-05-04T15:17:07.325806: step 4845, loss 0.353906, acc 0.859375\n",
      "2018-05-04T15:17:08.460240: step 4846, loss 0.235921, acc 0.859375\n",
      "2018-05-04T15:17:09.596025: step 4847, loss 0.247444, acc 0.90625\n",
      "2018-05-04T15:17:10.742820: step 4848, loss 0.422692, acc 0.8125\n",
      "2018-05-04T15:17:11.905601: step 4849, loss 0.308761, acc 0.875\n",
      "2018-05-04T15:17:13.008857: step 4850, loss 0.288003, acc 0.84375\n",
      "2018-05-04T15:17:14.141146: step 4851, loss 0.295752, acc 0.890625\n",
      "2018-05-04T15:17:15.301034: step 4852, loss 0.282175, acc 0.84375\n",
      "2018-05-04T15:17:16.411247: step 4853, loss 0.283656, acc 0.84375\n",
      "2018-05-04T15:17:17.569630: step 4854, loss 0.198807, acc 0.921875\n",
      "2018-05-04T15:17:18.696133: step 4855, loss 0.434181, acc 0.78125\n",
      "2018-05-04T15:17:19.844106: step 4856, loss 0.485423, acc 0.765625\n",
      "2018-05-04T15:17:21.011359: step 4857, loss 0.3408, acc 0.796875\n",
      "2018-05-04T15:17:22.198046: step 4858, loss 0.431391, acc 0.859375\n",
      "2018-05-04T15:17:23.368169: step 4859, loss 0.300017, acc 0.90625\n",
      "2018-05-04T15:17:24.545599: step 4860, loss 0.358526, acc 0.859375\n",
      "2018-05-04T15:17:25.734353: step 4861, loss 0.198421, acc 0.921875\n",
      "2018-05-04T15:17:26.910507: step 4862, loss 0.398544, acc 0.8125\n",
      "2018-05-04T15:17:28.027857: step 4863, loss 0.268672, acc 0.90625\n",
      "2018-05-04T15:17:29.171541: step 4864, loss 0.367806, acc 0.84375\n",
      "2018-05-04T15:17:30.300225: step 4865, loss 0.428019, acc 0.875\n",
      "2018-05-04T15:17:31.510421: step 4866, loss 0.22065, acc 0.921875\n",
      "2018-05-04T15:17:32.631635: step 4867, loss 0.28452, acc 0.890625\n",
      "2018-05-04T15:17:33.822339: step 4868, loss 0.348472, acc 0.859375\n",
      "2018-05-04T15:17:34.973571: step 4869, loss 0.304081, acc 0.859375\n",
      "2018-05-04T15:17:36.095504: step 4870, loss 0.388367, acc 0.796875\n",
      "2018-05-04T15:17:37.297718: step 4871, loss 0.197994, acc 0.90625\n",
      "2018-05-04T15:17:38.501621: step 4872, loss 0.307075, acc 0.875\n",
      "2018-05-04T15:17:39.659995: step 4873, loss 0.193989, acc 0.9375\n",
      "2018-05-04T15:17:40.928851: step 4874, loss 0.276441, acc 0.921875\n",
      "2018-05-04T15:17:42.171451: step 4875, loss 0.385361, acc 0.8125\n",
      "2018-05-04T15:17:43.284469: step 4876, loss 0.286804, acc 0.90625\n",
      "2018-05-04T15:17:44.427908: step 4877, loss 0.33316, acc 0.875\n",
      "2018-05-04T15:17:45.536447: step 4878, loss 0.243502, acc 0.9375\n",
      "2018-05-04T15:17:46.719454: step 4879, loss 0.290466, acc 0.90625\n",
      "2018-05-04T15:17:47.829317: step 4880, loss 0.311425, acc 0.859375\n",
      "2018-05-04T15:17:48.952995: step 4881, loss 0.290778, acc 0.84375\n",
      "2018-05-04T15:17:50.084780: step 4882, loss 0.200591, acc 0.9375\n",
      "2018-05-04T15:17:51.264101: step 4883, loss 0.352737, acc 0.859375\n",
      "2018-05-04T15:17:52.407113: step 4884, loss 0.293551, acc 0.875\n",
      "2018-05-04T15:17:53.581452: step 4885, loss 0.379198, acc 0.828125\n",
      "2018-05-04T15:17:54.743015: step 4886, loss 0.243216, acc 0.890625\n",
      "2018-05-04T15:17:55.907547: step 4887, loss 0.297917, acc 0.859375\n",
      "2018-05-04T15:17:57.055046: step 4888, loss 0.313765, acc 0.890625\n",
      "2018-05-04T15:17:58.215978: step 4889, loss 0.377868, acc 0.90625\n",
      "2018-05-04T15:17:59.391582: step 4890, loss 0.250089, acc 0.9375\n",
      "2018-05-04T15:18:00.533365: step 4891, loss 0.418777, acc 0.828125\n",
      "2018-05-04T15:18:01.799567: step 4892, loss 0.350831, acc 0.875\n",
      "2018-05-04T15:18:02.932535: step 4893, loss 0.385101, acc 0.84375\n",
      "2018-05-04T15:18:04.081623: step 4894, loss 0.301153, acc 0.859375\n",
      "2018-05-04T15:18:05.188052: step 4895, loss 0.359908, acc 0.875\n",
      "2018-05-04T15:18:06.305780: step 4896, loss 0.292702, acc 0.890625\n",
      "2018-05-04T15:18:07.488394: step 4897, loss 0.301395, acc 0.90625\n",
      "2018-05-04T15:18:08.598118: step 4898, loss 0.227364, acc 0.875\n",
      "2018-05-04T15:18:09.738746: step 4899, loss 0.368477, acc 0.8125\n",
      "2018-05-04T15:18:10.876473: step 4900, loss 0.241563, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T15:18:13.634682: step 4900, loss 0.256221, acc 0.898\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-4900\n",
      "\n",
      "2018-05-04T15:18:15.027791: step 4901, loss 0.369157, acc 0.859375\n",
      "2018-05-04T15:18:16.245295: step 4902, loss 0.36335, acc 0.875\n",
      "2018-05-04T15:18:17.464636: step 4903, loss 0.313562, acc 0.90625\n",
      "2018-05-04T15:18:18.599505: step 4904, loss 0.253339, acc 0.90625\n",
      "2018-05-04T15:18:19.739514: step 4905, loss 0.251655, acc 0.890625\n",
      "2018-05-04T15:18:20.932397: step 4906, loss 0.231147, acc 0.921875\n",
      "2018-05-04T15:18:22.116695: step 4907, loss 0.350011, acc 0.875\n",
      "2018-05-04T15:18:23.316925: step 4908, loss 0.224043, acc 0.9375\n",
      "2018-05-04T15:18:24.452218: step 4909, loss 0.373118, acc 0.796875\n",
      "2018-05-04T15:18:25.570743: step 4910, loss 0.316691, acc 0.8125\n",
      "2018-05-04T15:18:26.710813: step 4911, loss 0.231362, acc 0.921875\n",
      "2018-05-04T15:18:27.839244: step 4912, loss 0.275342, acc 0.875\n",
      "2018-05-04T15:18:28.963919: step 4913, loss 0.217851, acc 0.90625\n",
      "2018-05-04T15:18:30.086351: step 4914, loss 0.307032, acc 0.875\n",
      "2018-05-04T15:18:31.281807: step 4915, loss 0.470223, acc 0.8125\n",
      "2018-05-04T15:18:32.394990: step 4916, loss 0.20017, acc 0.890625\n",
      "2018-05-04T15:18:33.536095: step 4917, loss 0.265593, acc 0.90625\n",
      "2018-05-04T15:18:34.685630: step 4918, loss 0.377009, acc 0.84375\n",
      "2018-05-04T15:18:35.814727: step 4919, loss 0.30095, acc 0.828125\n",
      "2018-05-04T15:18:36.943031: step 4920, loss 0.245169, acc 0.90625\n",
      "2018-05-04T15:18:38.058889: step 4921, loss 0.2825, acc 0.859375\n",
      "2018-05-04T15:18:39.193519: step 4922, loss 0.257351, acc 0.90625\n",
      "2018-05-04T15:18:40.414535: step 4923, loss 0.215595, acc 0.9375\n",
      "2018-05-04T15:18:41.606091: step 4924, loss 0.236565, acc 0.921875\n",
      "2018-05-04T15:18:42.737078: step 4925, loss 0.341368, acc 0.828125\n",
      "2018-05-04T15:18:43.856906: step 4926, loss 0.33158, acc 0.828125\n",
      "2018-05-04T15:18:45.039509: step 4927, loss 0.261691, acc 0.890625\n",
      "2018-05-04T15:18:46.171408: step 4928, loss 0.29333, acc 0.890625\n",
      "2018-05-04T15:18:47.292688: step 4929, loss 0.250491, acc 0.859375\n",
      "2018-05-04T15:18:48.428616: step 4930, loss 0.248361, acc 0.90625\n",
      "2018-05-04T15:18:49.571364: step 4931, loss 0.35448, acc 0.84375\n",
      "2018-05-04T15:18:50.716303: step 4932, loss 0.342926, acc 0.875\n",
      "2018-05-04T15:18:51.880829: step 4933, loss 0.225078, acc 0.90625\n",
      "2018-05-04T15:18:53.025496: step 4934, loss 0.319136, acc 0.796875\n",
      "2018-05-04T15:18:54.203505: step 4935, loss 0.227091, acc 0.921875\n",
      "2018-05-04T15:18:55.391898: step 4936, loss 0.327386, acc 0.828125\n",
      "2018-05-04T15:18:56.544814: step 4937, loss 0.284265, acc 0.90625\n",
      "2018-05-04T15:18:57.654740: step 4938, loss 0.396014, acc 0.84375\n",
      "2018-05-04T15:18:58.774173: step 4939, loss 0.331626, acc 0.875\n",
      "2018-05-04T15:18:59.904492: step 4940, loss 0.407591, acc 0.84375\n",
      "2018-05-04T15:19:01.090512: step 4941, loss 0.448814, acc 0.8125\n",
      "2018-05-04T15:19:02.223249: step 4942, loss 0.306003, acc 0.890625\n",
      "2018-05-04T15:19:03.340974: step 4943, loss 0.277969, acc 0.90625\n",
      "2018-05-04T15:19:04.488060: step 4944, loss 0.203252, acc 0.921875\n",
      "2018-05-04T15:19:05.635833: step 4945, loss 0.380172, acc 0.8125\n",
      "2018-05-04T15:19:06.756390: step 4946, loss 0.245878, acc 0.875\n",
      "2018-05-04T15:19:07.888350: step 4947, loss 0.370976, acc 0.8125\n",
      "2018-05-04T15:19:09.015950: step 4948, loss 0.423904, acc 0.859375\n",
      "2018-05-04T15:19:10.160871: step 4949, loss 0.353937, acc 0.828125\n",
      "2018-05-04T15:19:11.405027: step 4950, loss 0.289324, acc 0.890625\n",
      "2018-05-04T15:19:12.640282: step 4951, loss 0.18649, acc 0.953125\n",
      "2018-05-04T15:19:13.801890: step 4952, loss 0.25052, acc 0.921875\n",
      "2018-05-04T15:19:14.979997: step 4953, loss 0.366184, acc 0.8125\n",
      "2018-05-04T15:19:16.169348: step 4954, loss 0.39935, acc 0.8125\n",
      "2018-05-04T15:19:17.300389: step 4955, loss 0.267729, acc 0.90625\n",
      "2018-05-04T15:19:18.472792: step 4956, loss 0.227328, acc 0.890625\n",
      "2018-05-04T15:19:19.680770: step 4957, loss 0.408224, acc 0.859375\n",
      "2018-05-04T15:19:20.863466: step 4958, loss 0.337662, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T15:19:22.013037: step 4959, loss 0.40635, acc 0.796875\n",
      "2018-05-04T15:19:23.138045: step 4960, loss 0.371967, acc 0.875\n",
      "2018-05-04T15:19:24.276854: step 4961, loss 0.247181, acc 0.9375\n",
      "2018-05-04T15:19:25.391496: step 4962, loss 0.322201, acc 0.859375\n",
      "2018-05-04T15:19:26.547971: step 4963, loss 0.279553, acc 0.875\n",
      "2018-05-04T15:19:27.704811: step 4964, loss 0.31168, acc 0.859375\n",
      "2018-05-04T15:19:28.865284: step 4965, loss 0.467738, acc 0.828125\n",
      "2018-05-04T15:19:30.033998: step 4966, loss 0.283384, acc 0.859375\n",
      "2018-05-04T15:19:31.257979: step 4967, loss 0.33593, acc 0.859375\n",
      "2018-05-04T15:19:32.426612: step 4968, loss 0.310614, acc 0.9375\n",
      "2018-05-04T15:19:33.665099: step 4969, loss 0.328524, acc 0.890625\n",
      "2018-05-04T15:19:34.922055: step 4970, loss 0.416223, acc 0.84375\n",
      "2018-05-04T15:19:36.147441: step 4971, loss 0.172962, acc 0.96875\n",
      "2018-05-04T15:19:37.408902: step 4972, loss 0.397531, acc 0.8125\n",
      "2018-05-04T15:19:38.557959: step 4973, loss 0.44426, acc 0.8125\n",
      "2018-05-04T15:19:39.727917: step 4974, loss 0.416063, acc 0.8125\n",
      "2018-05-04T15:19:40.910349: step 4975, loss 0.227759, acc 0.921875\n",
      "2018-05-04T15:19:42.112706: step 4976, loss 0.31315, acc 0.859375\n",
      "2018-05-04T15:19:43.248769: step 4977, loss 0.433281, acc 0.84375\n",
      "2018-05-04T15:19:44.424551: step 4978, loss 0.326645, acc 0.84375\n",
      "2018-05-04T15:19:45.555705: step 4979, loss 0.345462, acc 0.84375\n",
      "2018-05-04T15:19:46.686082: step 4980, loss 0.398366, acc 0.84375\n",
      "2018-05-04T15:19:47.807010: step 4981, loss 0.227314, acc 0.90625\n",
      "2018-05-04T15:19:48.937679: step 4982, loss 0.321314, acc 0.828125\n",
      "2018-05-04T15:19:50.060283: step 4983, loss 0.384366, acc 0.828125\n",
      "2018-05-04T15:19:51.230683: step 4984, loss 0.258081, acc 0.9375\n",
      "2018-05-04T15:19:52.364518: step 4985, loss 0.399463, acc 0.828125\n",
      "2018-05-04T15:19:53.486701: step 4986, loss 0.341011, acc 0.84375\n",
      "2018-05-04T15:19:54.685120: step 4987, loss 0.415655, acc 0.828125\n",
      "2018-05-04T15:19:55.795869: step 4988, loss 0.21639, acc 0.921875\n",
      "2018-05-04T15:19:56.908656: step 4989, loss 0.301173, acc 0.90625\n",
      "2018-05-04T15:19:58.033025: step 4990, loss 0.223652, acc 0.921875\n",
      "2018-05-04T15:19:59.183236: step 4991, loss 0.319461, acc 0.890625\n",
      "2018-05-04T15:20:00.314203: step 4992, loss 0.268612, acc 0.859375\n",
      "2018-05-04T15:20:01.527616: step 4993, loss 0.250803, acc 0.921875\n",
      "2018-05-04T15:20:02.643370: step 4994, loss 0.190531, acc 0.921875\n",
      "2018-05-04T15:20:03.771374: step 4995, loss 0.284103, acc 0.875\n",
      "2018-05-04T15:20:04.918416: step 4996, loss 0.320948, acc 0.875\n",
      "2018-05-04T15:20:06.078795: step 4997, loss 0.248621, acc 0.9375\n",
      "2018-05-04T15:20:07.250271: step 4998, loss 0.296566, acc 0.859375\n",
      "2018-05-04T15:20:08.392444: step 4999, loss 0.298098, acc 0.890625\n",
      "2018-05-04T15:20:09.527618: step 5000, loss 0.393292, acc 0.828125\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T15:20:12.299635: step 5000, loss 0.260111, acc 0.902\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-5000\n",
      "\n",
      "2018-05-04T15:20:13.644424: step 5001, loss 0.326742, acc 0.828125\n",
      "2018-05-04T15:20:14.889494: step 5002, loss 0.355095, acc 0.875\n",
      "2018-05-04T15:20:16.031463: step 5003, loss 0.353936, acc 0.875\n",
      "2018-05-04T15:20:17.124235: step 5004, loss 0.340493, acc 0.859375\n",
      "2018-05-04T15:20:18.289304: step 5005, loss 0.203485, acc 0.9375\n",
      "2018-05-04T15:20:19.442247: step 5006, loss 0.203782, acc 0.921875\n",
      "2018-05-04T15:20:20.573893: step 5007, loss 0.252258, acc 0.890625\n",
      "2018-05-04T15:20:21.709289: step 5008, loss 0.343626, acc 0.796875\n",
      "2018-05-04T15:20:22.809204: step 5009, loss 0.369667, acc 0.859375\n",
      "2018-05-04T15:20:23.910785: step 5010, loss 0.309025, acc 0.859375\n",
      "2018-05-04T15:20:25.071240: step 5011, loss 0.312164, acc 0.84375\n",
      "2018-05-04T15:20:26.175521: step 5012, loss 0.322673, acc 0.828125\n",
      "2018-05-04T15:20:27.260796: step 5013, loss 0.334214, acc 0.921875\n",
      "2018-05-04T15:20:28.349926: step 5014, loss 0.301007, acc 0.875\n",
      "2018-05-04T15:20:29.481371: step 5015, loss 0.357514, acc 0.84375\n",
      "2018-05-04T15:20:30.597469: step 5016, loss 0.330657, acc 0.875\n",
      "2018-05-04T15:20:31.734587: step 5017, loss 0.256784, acc 0.828125\n",
      "2018-05-04T15:20:32.872012: step 5018, loss 0.212995, acc 0.9375\n",
      "2018-05-04T15:20:33.989895: step 5019, loss 0.322007, acc 0.84375\n",
      "2018-05-04T15:20:35.121724: step 5020, loss 0.286303, acc 0.890625\n",
      "2018-05-04T15:20:36.255553: step 5021, loss 0.373878, acc 0.828125\n",
      "2018-05-04T15:20:37.381526: step 5022, loss 0.237823, acc 0.90625\n",
      "2018-05-04T15:20:38.482334: step 5023, loss 0.361573, acc 0.8125\n",
      "2018-05-04T15:20:39.588266: step 5024, loss 0.283455, acc 0.90625\n",
      "2018-05-04T15:20:40.779417: step 5025, loss 0.226764, acc 0.9375\n",
      "2018-05-04T15:20:41.924627: step 5026, loss 0.364433, acc 0.84375\n",
      "2018-05-04T15:20:43.003751: step 5027, loss 0.282757, acc 0.875\n",
      "2018-05-04T15:20:44.103707: step 5028, loss 0.331822, acc 0.859375\n",
      "2018-05-04T15:20:45.202692: step 5029, loss 0.315904, acc 0.859375\n",
      "2018-05-04T15:20:46.280837: step 5030, loss 0.457434, acc 0.84375\n",
      "2018-05-04T15:20:47.383579: step 5031, loss 0.325391, acc 0.90625\n",
      "2018-05-04T15:20:48.483711: step 5032, loss 0.359471, acc 0.859375\n",
      "2018-05-04T15:20:49.669451: step 5033, loss 0.316667, acc 0.859375\n",
      "2018-05-04T15:20:50.788107: step 5034, loss 0.243003, acc 0.90625\n",
      "2018-05-04T15:20:51.927466: step 5035, loss 0.367221, acc 0.84375\n",
      "2018-05-04T15:20:53.055873: step 5036, loss 0.427075, acc 0.859375\n",
      "2018-05-04T15:20:54.257935: step 5037, loss 0.227854, acc 0.890625\n",
      "2018-05-04T15:20:55.455497: step 5038, loss 0.243675, acc 0.921875\n",
      "2018-05-04T15:20:56.558194: step 5039, loss 0.252032, acc 0.953125\n",
      "2018-05-04T15:20:57.722593: step 5040, loss 0.404925, acc 0.890625\n",
      "2018-05-04T15:20:58.832650: step 5041, loss 0.274592, acc 0.890625\n",
      "2018-05-04T15:20:59.915203: step 5042, loss 0.362195, acc 0.8125\n",
      "2018-05-04T15:21:01.058386: step 5043, loss 0.289989, acc 0.84375\n",
      "2018-05-04T15:21:02.166740: step 5044, loss 0.280407, acc 0.890625\n",
      "2018-05-04T15:21:03.290234: step 5045, loss 0.27422, acc 0.875\n",
      "2018-05-04T15:21:04.428585: step 5046, loss 0.29324, acc 0.890625\n",
      "2018-05-04T15:21:05.561436: step 5047, loss 0.25554, acc 0.890625\n",
      "2018-05-04T15:21:06.666868: step 5048, loss 0.240054, acc 0.84375\n",
      "2018-05-04T15:21:07.875391: step 5049, loss 0.344109, acc 0.84375\n",
      "2018-05-04T15:21:09.004789: step 5050, loss 0.339672, acc 0.859375\n",
      "2018-05-04T15:21:10.164082: step 5051, loss 0.247057, acc 0.921875\n",
      "2018-05-04T15:21:11.320603: step 5052, loss 0.426626, acc 0.78125\n",
      "2018-05-04T15:21:12.419252: step 5053, loss 0.388487, acc 0.859375\n",
      "2018-05-04T15:21:13.525309: step 5054, loss 0.371715, acc 0.84375\n",
      "2018-05-04T15:21:14.613565: step 5055, loss 0.317729, acc 0.875\n",
      "2018-05-04T15:21:15.704493: step 5056, loss 0.321974, acc 0.859375\n",
      "2018-05-04T15:21:16.831760: step 5057, loss 0.313457, acc 0.890625\n",
      "2018-05-04T15:21:17.980812: step 5058, loss 0.428443, acc 0.828125\n",
      "2018-05-04T15:21:19.115301: step 5059, loss 0.28729, acc 0.875\n",
      "2018-05-04T15:21:20.259394: step 5060, loss 0.320634, acc 0.796875\n",
      "2018-05-04T15:21:21.457046: step 5061, loss 0.35406, acc 0.875\n",
      "2018-05-04T15:21:22.571590: step 5062, loss 0.252003, acc 0.921875\n",
      "2018-05-04T15:21:23.680786: step 5063, loss 0.367903, acc 0.8125\n",
      "2018-05-04T15:21:24.838255: step 5064, loss 0.322376, acc 0.890625\n",
      "2018-05-04T15:21:25.971006: step 5065, loss 0.234735, acc 0.875\n",
      "2018-05-04T15:21:27.099181: step 5066, loss 0.408252, acc 0.828125\n",
      "2018-05-04T15:21:28.226426: step 5067, loss 0.261334, acc 0.875\n",
      "2018-05-04T15:21:29.386916: step 5068, loss 0.350808, acc 0.859375\n",
      "2018-05-04T15:21:30.480694: step 5069, loss 0.336714, acc 0.859375\n",
      "2018-05-04T15:21:31.656369: step 5070, loss 0.360108, acc 0.828125\n",
      "2018-05-04T15:21:32.748790: step 5071, loss 0.294806, acc 0.84375\n",
      "2018-05-04T15:21:33.848383: step 5072, loss 0.318351, acc 0.859375\n",
      "2018-05-04T15:21:34.975160: step 5073, loss 0.271134, acc 0.875\n",
      "2018-05-04T15:21:36.097948: step 5074, loss 0.31164, acc 0.890625\n",
      "2018-05-04T15:21:37.254496: step 5075, loss 0.304756, acc 0.90625\n",
      "2018-05-04T15:21:38.376983: step 5076, loss 0.279869, acc 0.921875\n",
      "2018-05-04T15:21:39.505083: step 5077, loss 0.322063, acc 0.90625\n",
      "2018-05-04T15:21:40.688044: step 5078, loss 0.220449, acc 0.90625\n",
      "2018-05-04T15:21:41.954361: step 5079, loss 0.293093, acc 0.84375\n",
      "2018-05-04T15:21:43.075131: step 5080, loss 0.320221, acc 0.859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T15:21:44.202406: step 5081, loss 0.29012, acc 0.875\n",
      "2018-05-04T15:21:45.339271: step 5082, loss 0.346583, acc 0.890625\n",
      "2018-05-04T15:21:46.471520: step 5083, loss 0.248528, acc 0.90625\n",
      "2018-05-04T15:21:47.676230: step 5084, loss 0.364897, acc 0.859375\n",
      "2018-05-04T15:21:48.829109: step 5085, loss 0.285433, acc 0.859375\n",
      "2018-05-04T15:21:50.024312: step 5086, loss 0.395366, acc 0.796875\n",
      "2018-05-04T15:21:51.197290: step 5087, loss 0.224725, acc 0.890625\n",
      "2018-05-04T15:21:52.309278: step 5088, loss 0.39512, acc 0.84375\n",
      "2018-05-04T15:21:53.439502: step 5089, loss 0.353197, acc 0.84375\n",
      "2018-05-04T15:21:54.573112: step 5090, loss 0.253804, acc 0.890625\n",
      "2018-05-04T15:21:55.760796: step 5091, loss 0.49404, acc 0.78125\n",
      "2018-05-04T15:21:56.884543: step 5092, loss 0.252111, acc 0.875\n",
      "2018-05-04T15:21:58.019130: step 5093, loss 0.21378, acc 0.921875\n",
      "2018-05-04T15:21:59.204839: step 5094, loss 0.452289, acc 0.828125\n",
      "2018-05-04T15:22:00.404746: step 5095, loss 0.229252, acc 0.890625\n",
      "2018-05-04T15:22:01.603612: step 5096, loss 0.300405, acc 0.875\n",
      "2018-05-04T15:22:02.804152: step 5097, loss 0.245703, acc 0.890625\n",
      "2018-05-04T15:22:03.945866: step 5098, loss 0.267388, acc 0.890625\n",
      "2018-05-04T15:22:05.069679: step 5099, loss 0.212316, acc 0.9375\n",
      "2018-05-04T15:22:06.194999: step 5100, loss 0.360673, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T15:22:08.689605: step 5100, loss 0.257737, acc 0.908\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-5100\n",
      "\n",
      "2018-05-04T15:22:09.883882: step 5101, loss 0.340159, acc 0.890625\n",
      "2018-05-04T15:22:11.113887: step 5102, loss 0.373025, acc 0.8125\n",
      "2018-05-04T15:22:12.315429: step 5103, loss 0.329313, acc 0.84375\n",
      "2018-05-04T15:22:13.432602: step 5104, loss 0.22713, acc 0.90625\n",
      "2018-05-04T15:22:14.552676: step 5105, loss 0.248343, acc 0.90625\n",
      "2018-05-04T15:22:15.672750: step 5106, loss 0.29994, acc 0.9375\n",
      "2018-05-04T15:22:16.791870: step 5107, loss 0.36698, acc 0.90625\n",
      "2018-05-04T15:22:17.906732: step 5108, loss 0.315277, acc 0.828125\n",
      "2018-05-04T15:22:19.132888: step 5109, loss 0.401085, acc 0.75\n",
      "2018-05-04T15:22:20.288208: step 5110, loss 0.365458, acc 0.84375\n",
      "2018-05-04T15:22:21.535843: step 5111, loss 0.369932, acc 0.890625\n",
      "2018-05-04T15:22:22.686011: step 5112, loss 0.338685, acc 0.828125\n",
      "2018-05-04T15:22:23.852634: step 5113, loss 0.26016, acc 0.90625\n",
      "2018-05-04T15:22:25.106975: step 5114, loss 0.220699, acc 0.90625\n",
      "2018-05-04T15:22:26.296320: step 5115, loss 0.415476, acc 0.828125\n",
      "2018-05-04T15:22:27.487197: step 5116, loss 0.309478, acc 0.890625\n",
      "2018-05-04T15:22:28.600663: step 5117, loss 0.310287, acc 0.890625\n",
      "2018-05-04T15:22:29.791817: step 5118, loss 0.322456, acc 0.890625\n",
      "2018-05-04T15:22:31.038657: step 5119, loss 0.28946, acc 0.90625\n",
      "2018-05-04T15:22:32.245294: step 5120, loss 0.326887, acc 0.84375\n",
      "2018-05-04T15:22:33.432659: step 5121, loss 0.205483, acc 0.921875\n",
      "2018-05-04T15:22:34.647385: step 5122, loss 0.282122, acc 0.890625\n",
      "2018-05-04T15:22:35.829221: step 5123, loss 0.208914, acc 0.9375\n",
      "2018-05-04T15:22:37.033382: step 5124, loss 0.374084, acc 0.796875\n",
      "2018-05-04T15:22:38.239265: step 5125, loss 0.183256, acc 0.921875\n",
      "2018-05-04T15:22:39.392554: step 5126, loss 0.300423, acc 0.875\n",
      "2018-05-04T15:22:40.624063: step 5127, loss 0.211968, acc 0.90625\n",
      "2018-05-04T15:22:41.921195: step 5128, loss 0.240438, acc 0.875\n",
      "2018-05-04T15:22:43.118983: step 5129, loss 0.30026, acc 0.859375\n",
      "2018-05-04T15:22:44.243600: step 5130, loss 0.402876, acc 0.84375\n",
      "2018-05-04T15:22:45.351472: step 5131, loss 0.29707, acc 0.890625\n",
      "2018-05-04T15:22:46.462494: step 5132, loss 0.254762, acc 0.875\n",
      "2018-05-04T15:22:47.575330: step 5133, loss 0.265208, acc 0.84375\n",
      "2018-05-04T15:22:48.761637: step 5134, loss 0.353541, acc 0.796875\n",
      "2018-05-04T15:22:49.959028: step 5135, loss 0.337529, acc 0.890625\n",
      "2018-05-04T15:22:51.120273: step 5136, loss 0.210796, acc 0.921875\n",
      "2018-05-04T15:22:52.316162: step 5137, loss 0.330849, acc 0.8125\n",
      "2018-05-04T15:22:53.550298: step 5138, loss 0.406193, acc 0.796875\n",
      "2018-05-04T15:22:54.793969: step 5139, loss 0.215182, acc 0.90625\n",
      "2018-05-04T15:22:55.989110: step 5140, loss 0.394974, acc 0.828125\n",
      "2018-05-04T15:22:57.101085: step 5141, loss 0.303275, acc 0.84375\n",
      "2018-05-04T15:22:58.283961: step 5142, loss 0.255292, acc 0.859375\n",
      "2018-05-04T15:22:59.494763: step 5143, loss 0.285049, acc 0.921875\n",
      "2018-05-04T15:23:00.670831: step 5144, loss 0.370221, acc 0.890625\n",
      "2018-05-04T15:23:01.907435: step 5145, loss 0.210248, acc 0.9375\n",
      "2018-05-04T15:23:03.090623: step 5146, loss 0.442252, acc 0.84375\n",
      "2018-05-04T15:23:04.297032: step 5147, loss 0.402975, acc 0.84375\n",
      "2018-05-04T15:23:05.488108: step 5148, loss 0.394198, acc 0.796875\n",
      "2018-05-04T15:23:06.691759: step 5149, loss 0.317556, acc 0.890625\n",
      "2018-05-04T15:23:07.885298: step 5150, loss 0.344563, acc 0.890625\n",
      "2018-05-04T15:23:09.043121: step 5151, loss 0.253658, acc 0.921875\n",
      "2018-05-04T15:23:10.247722: step 5152, loss 0.346314, acc 0.875\n",
      "2018-05-04T15:23:11.496806: step 5153, loss 0.273189, acc 0.890625\n",
      "2018-05-04T15:23:12.676550: step 5154, loss 0.32761, acc 0.84375\n",
      "2018-05-04T15:23:13.863278: step 5155, loss 0.199238, acc 0.90625\n",
      "2018-05-04T15:23:14.999367: step 5156, loss 0.338416, acc 0.875\n",
      "2018-05-04T15:23:16.178297: step 5157, loss 0.274672, acc 0.875\n",
      "2018-05-04T15:23:17.378914: step 5158, loss 0.286999, acc 0.875\n",
      "2018-05-04T15:23:18.564322: step 5159, loss 0.366031, acc 0.828125\n",
      "2018-05-04T15:23:19.779953: step 5160, loss 0.295848, acc 0.890625\n",
      "2018-05-04T15:23:21.012464: step 5161, loss 0.264009, acc 0.921875\n",
      "2018-05-04T15:23:22.236100: step 5162, loss 0.283434, acc 0.84375\n",
      "2018-05-04T15:23:23.416524: step 5163, loss 0.192306, acc 0.953125\n",
      "2018-05-04T15:23:24.604332: step 5164, loss 0.392411, acc 0.875\n",
      "2018-05-04T15:23:25.728650: step 5165, loss 0.267022, acc 0.90625\n",
      "2018-05-04T15:23:26.869189: step 5166, loss 0.257837, acc 0.90625\n",
      "2018-05-04T15:23:28.035023: step 5167, loss 0.311993, acc 0.875\n",
      "2018-05-04T15:23:29.189848: step 5168, loss 0.26344, acc 0.859375\n",
      "2018-05-04T15:23:30.326710: step 5169, loss 0.293793, acc 0.84375\n",
      "2018-05-04T15:23:31.476093: step 5170, loss 0.264795, acc 0.875\n",
      "2018-05-04T15:23:32.648687: step 5171, loss 0.347814, acc 0.859375\n",
      "2018-05-04T15:23:33.855226: step 5172, loss 0.267324, acc 0.890625\n",
      "2018-05-04T15:23:35.057915: step 5173, loss 0.303952, acc 0.859375\n",
      "2018-05-04T15:23:36.244690: step 5174, loss 0.271377, acc 0.84375\n",
      "2018-05-04T15:23:37.429029: step 5175, loss 0.294617, acc 0.859375\n",
      "2018-05-04T15:23:38.635944: step 5176, loss 0.399439, acc 0.828125\n",
      "2018-05-04T15:23:39.805022: step 5177, loss 0.266083, acc 0.890625\n",
      "2018-05-04T15:23:41.049146: step 5178, loss 0.311804, acc 0.875\n",
      "2018-05-04T15:23:42.234032: step 5179, loss 0.258583, acc 0.890625\n",
      "2018-05-04T15:23:43.415531: step 5180, loss 0.181837, acc 0.921875\n",
      "2018-05-04T15:23:44.587768: step 5181, loss 0.382706, acc 0.90625\n",
      "2018-05-04T15:23:45.742611: step 5182, loss 0.322149, acc 0.875\n",
      "2018-05-04T15:23:46.906706: step 5183, loss 0.260864, acc 0.921875\n",
      "2018-05-04T15:23:48.077437: step 5184, loss 0.48314, acc 0.8125\n",
      "2018-05-04T15:23:49.253065: step 5185, loss 0.407463, acc 0.78125\n",
      "2018-05-04T15:23:50.416659: step 5186, loss 0.465144, acc 0.796875\n",
      "2018-05-04T15:23:51.623008: step 5187, loss 0.262082, acc 0.90625\n",
      "2018-05-04T15:23:52.774431: step 5188, loss 0.298972, acc 0.859375\n",
      "2018-05-04T15:23:53.930521: step 5189, loss 0.3444, acc 0.90625\n",
      "2018-05-04T15:23:55.081957: step 5190, loss 0.482725, acc 0.828125\n",
      "2018-05-04T15:23:56.267372: step 5191, loss 0.363132, acc 0.890625\n",
      "2018-05-04T15:23:57.446694: step 5192, loss 0.273862, acc 0.875\n",
      "2018-05-04T15:23:58.633422: step 5193, loss 0.347242, acc 0.84375\n",
      "2018-05-04T15:23:59.808007: step 5194, loss 0.307581, acc 0.890625\n",
      "2018-05-04T15:24:01.023543: step 5195, loss 0.126353, acc 0.96875\n",
      "2018-05-04T15:24:02.194380: step 5196, loss 0.303755, acc 0.90625\n",
      "2018-05-04T15:24:03.306914: step 5197, loss 0.342768, acc 0.84375\n",
      "2018-05-04T15:24:04.454925: step 5198, loss 0.30885, acc 0.84375\n",
      "2018-05-04T15:24:05.617910: step 5199, loss 0.272941, acc 0.875\n",
      "2018-05-04T15:24:06.789892: step 5200, loss 0.239228, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T15:24:09.752794: step 5200, loss 0.263818, acc 0.898\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-5200\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T15:24:11.078382: step 5201, loss 0.304577, acc 0.90625\n",
      "2018-05-04T15:24:12.278224: step 5202, loss 0.241975, acc 0.890625\n",
      "2018-05-04T15:24:13.444501: step 5203, loss 0.426325, acc 0.890625\n",
      "2018-05-04T15:24:14.711052: step 5204, loss 0.264017, acc 0.90625\n",
      "2018-05-04T15:24:16.031239: step 5205, loss 0.420497, acc 0.84375\n",
      "2018-05-04T15:24:17.194604: step 5206, loss 0.331525, acc 0.890625\n",
      "2018-05-04T15:24:18.357549: step 5207, loss 0.34714, acc 0.859375\n",
      "2018-05-04T15:24:19.501190: step 5208, loss 0.38404, acc 0.8125\n",
      "2018-05-04T15:24:20.667317: step 5209, loss 0.404642, acc 0.78125\n",
      "2018-05-04T15:24:21.860175: step 5210, loss 0.212401, acc 0.9375\n",
      "2018-05-04T15:24:22.984896: step 5211, loss 0.365308, acc 0.890625\n",
      "2018-05-04T15:24:24.134584: step 5212, loss 0.3753, acc 0.828125\n",
      "2018-05-04T15:24:25.258328: step 5213, loss 0.29832, acc 0.875\n",
      "2018-05-04T15:24:26.406658: step 5214, loss 0.246798, acc 0.859375\n",
      "2018-05-04T15:24:27.527365: step 5215, loss 0.242891, acc 0.921875\n",
      "2018-05-04T15:24:28.731281: step 5216, loss 0.276352, acc 0.890625\n",
      "2018-05-04T15:24:29.891148: step 5217, loss 0.391735, acc 0.828125\n",
      "2018-05-04T15:24:31.052738: step 5218, loss 0.282285, acc 0.90625\n",
      "2018-05-04T15:24:32.128597: step 5219, loss 0.298337, acc 0.875\n",
      "2018-05-04T15:24:33.236896: step 5220, loss 0.280818, acc 0.890625\n",
      "2018-05-04T15:24:34.404740: step 5221, loss 0.378991, acc 0.8125\n",
      "2018-05-04T15:24:35.518630: step 5222, loss 0.271005, acc 0.859375\n",
      "2018-05-04T15:24:36.655692: step 5223, loss 0.391801, acc 0.84375\n",
      "2018-05-04T15:24:37.777357: step 5224, loss 0.305361, acc 0.890625\n",
      "2018-05-04T15:24:38.912612: step 5225, loss 0.282402, acc 0.859375\n",
      "2018-05-04T15:24:40.052137: step 5226, loss 0.2822, acc 0.90625\n",
      "2018-05-04T15:24:41.235576: step 5227, loss 0.19492, acc 0.9375\n",
      "2018-05-04T15:24:42.377352: step 5228, loss 0.308605, acc 0.90625\n",
      "2018-05-04T15:24:43.558296: step 5229, loss 0.273868, acc 0.859375\n",
      "2018-05-04T15:24:44.711792: step 5230, loss 0.442104, acc 0.828125\n",
      "2018-05-04T15:24:45.868584: step 5231, loss 0.284375, acc 0.875\n",
      "2018-05-04T15:24:47.049426: step 5232, loss 0.246787, acc 0.90625\n",
      "2018-05-04T15:24:48.165147: step 5233, loss 0.264255, acc 0.859375\n",
      "2018-05-04T15:24:49.293294: step 5234, loss 0.190496, acc 0.90625\n",
      "2018-05-04T15:24:50.498069: step 5235, loss 0.427186, acc 0.84375\n",
      "2018-05-04T15:24:51.694497: step 5236, loss 0.149106, acc 0.96875\n",
      "2018-05-04T15:24:52.801488: step 5237, loss 0.299852, acc 0.84375\n",
      "2018-05-04T15:24:54.035114: step 5238, loss 0.195268, acc 0.921875\n",
      "2018-05-04T15:24:55.144725: step 5239, loss 0.304544, acc 0.84375\n",
      "2018-05-04T15:24:56.357199: step 5240, loss 0.178488, acc 0.921875\n",
      "2018-05-04T15:24:57.469524: step 5241, loss 0.255948, acc 0.921875\n",
      "2018-05-04T15:24:58.592597: step 5242, loss 0.265168, acc 0.875\n",
      "2018-05-04T15:24:59.755422: step 5243, loss 0.334723, acc 0.8125\n",
      "2018-05-04T15:25:00.910840: step 5244, loss 0.251466, acc 0.9375\n",
      "2018-05-04T15:25:02.058129: step 5245, loss 0.284537, acc 0.90625\n",
      "2018-05-04T15:25:03.194595: step 5246, loss 0.300815, acc 0.90625\n",
      "2018-05-04T15:25:04.347816: step 5247, loss 0.362193, acc 0.890625\n",
      "2018-05-04T15:25:05.486863: step 5248, loss 0.458378, acc 0.828125\n",
      "2018-05-04T15:25:06.602161: step 5249, loss 0.475753, acc 0.828125\n",
      "2018-05-04T15:25:07.783819: step 5250, loss 0.335791, acc 0.796875\n",
      "2018-05-04T15:25:08.967128: step 5251, loss 0.237077, acc 0.921875\n",
      "2018-05-04T15:25:10.142377: step 5252, loss 0.449532, acc 0.796875\n",
      "2018-05-04T15:25:11.354558: step 5253, loss 0.306892, acc 0.875\n",
      "2018-05-04T15:25:12.518473: step 5254, loss 0.297344, acc 0.875\n",
      "2018-05-04T15:25:13.692110: step 5255, loss 0.472219, acc 0.84375\n",
      "2018-05-04T15:25:14.874248: step 5256, loss 0.264373, acc 0.90625\n",
      "2018-05-04T15:25:15.999155: step 5257, loss 0.167954, acc 0.9375\n",
      "2018-05-04T15:25:17.225405: step 5258, loss 0.279298, acc 0.875\n",
      "2018-05-04T15:25:18.421530: step 5259, loss 0.368491, acc 0.84375\n",
      "2018-05-04T15:25:19.677831: step 5260, loss 0.25273, acc 0.921875\n",
      "2018-05-04T15:25:20.845170: step 5261, loss 0.36144, acc 0.875\n",
      "2018-05-04T15:25:22.001288: step 5262, loss 0.341464, acc 0.859375\n",
      "2018-05-04T15:25:23.114486: step 5263, loss 0.257837, acc 0.890625\n",
      "2018-05-04T15:25:24.238471: step 5264, loss 0.263708, acc 0.875\n",
      "2018-05-04T15:25:25.395867: step 5265, loss 0.275985, acc 0.828125\n",
      "2018-05-04T15:25:26.503348: step 5266, loss 0.389132, acc 0.8125\n",
      "2018-05-04T15:25:27.645043: step 5267, loss 0.342135, acc 0.828125\n",
      "2018-05-04T15:25:28.771866: step 5268, loss 0.203438, acc 0.890625\n",
      "2018-05-04T15:25:29.918461: step 5269, loss 0.316198, acc 0.828125\n",
      "2018-05-04T15:25:31.118103: step 5270, loss 0.370838, acc 0.84375\n",
      "2018-05-04T15:25:32.286789: step 5271, loss 0.315966, acc 0.859375\n",
      "2018-05-04T15:25:33.518071: step 5272, loss 0.286994, acc 0.84375\n",
      "2018-05-04T15:25:34.781935: step 5273, loss 0.287613, acc 0.828125\n",
      "2018-05-04T15:25:36.047003: step 5274, loss 0.266892, acc 0.890625\n",
      "2018-05-04T15:25:37.303476: step 5275, loss 0.433472, acc 0.84375\n",
      "2018-05-04T15:25:38.560818: step 5276, loss 0.269513, acc 0.890625\n",
      "2018-05-04T15:25:39.720253: step 5277, loss 0.238085, acc 0.90625\n",
      "2018-05-04T15:25:40.941005: step 5278, loss 0.243179, acc 0.9375\n",
      "2018-05-04T15:25:42.168028: step 5279, loss 0.350454, acc 0.890625\n",
      "2018-05-04T15:25:43.368471: step 5280, loss 0.291311, acc 0.875\n",
      "2018-05-04T15:25:44.496456: step 5281, loss 0.325664, acc 0.890625\n",
      "2018-05-04T15:25:45.624056: step 5282, loss 0.398937, acc 0.84375\n",
      "2018-05-04T15:25:46.740841: step 5283, loss 0.322366, acc 0.890625\n",
      "2018-05-04T15:25:47.874555: step 5284, loss 0.26072, acc 0.875\n",
      "2018-05-04T15:25:49.025310: step 5285, loss 0.278724, acc 0.875\n",
      "2018-05-04T15:25:50.139673: step 5286, loss 0.327119, acc 0.875\n",
      "2018-05-04T15:25:51.363520: step 5287, loss 0.275726, acc 0.875\n",
      "2018-05-04T15:25:52.566501: step 5288, loss 0.347157, acc 0.890625\n",
      "2018-05-04T15:25:53.681832: step 5289, loss 0.233298, acc 0.890625\n",
      "2018-05-04T15:25:54.831755: step 5290, loss 0.291003, acc 0.84375\n",
      "2018-05-04T15:25:55.949606: step 5291, loss 0.231437, acc 0.890625\n",
      "2018-05-04T15:25:57.071317: step 5292, loss 0.221531, acc 0.9375\n",
      "2018-05-04T15:25:58.184591: step 5293, loss 0.286795, acc 0.859375\n",
      "2018-05-04T15:25:59.345879: step 5294, loss 0.227985, acc 0.9375\n",
      "2018-05-04T15:26:00.456188: step 5295, loss 0.256981, acc 0.875\n",
      "2018-05-04T15:26:01.657892: step 5296, loss 0.296109, acc 0.890625\n",
      "2018-05-04T15:26:02.859377: step 5297, loss 0.288334, acc 0.859375\n",
      "2018-05-04T15:26:03.982121: step 5298, loss 0.272062, acc 0.875\n",
      "2018-05-04T15:26:05.193660: step 5299, loss 0.37513, acc 0.859375\n",
      "2018-05-04T15:26:06.303316: step 5300, loss 0.22751, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T15:26:08.904887: step 5300, loss 0.258849, acc 0.906\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-5300\n",
      "\n",
      "2018-05-04T15:26:10.191523: step 5301, loss 0.240721, acc 0.890625\n",
      "2018-05-04T15:26:11.438528: step 5302, loss 0.217887, acc 0.90625\n",
      "2018-05-04T15:26:12.699849: step 5303, loss 0.202481, acc 0.921875\n",
      "2018-05-04T15:26:13.894207: step 5304, loss 0.342217, acc 0.84375\n",
      "2018-05-04T15:26:15.106989: step 5305, loss 0.389601, acc 0.828125\n",
      "2018-05-04T15:26:16.341726: step 5306, loss 0.300264, acc 0.875\n",
      "2018-05-04T15:26:17.464988: step 5307, loss 0.272847, acc 0.890625\n",
      "2018-05-04T15:26:18.602504: step 5308, loss 0.365297, acc 0.875\n",
      "2018-05-04T15:26:19.750643: step 5309, loss 0.249443, acc 0.890625\n",
      "2018-05-04T15:26:20.964991: step 5310, loss 0.354719, acc 0.875\n",
      "2018-05-04T15:26:22.112126: step 5311, loss 0.316491, acc 0.828125\n",
      "2018-05-04T15:26:23.255550: step 5312, loss 0.369685, acc 0.828125\n",
      "2018-05-04T15:26:24.417062: step 5313, loss 0.563363, acc 0.75\n",
      "2018-05-04T15:26:25.551515: step 5314, loss 0.349153, acc 0.859375\n",
      "2018-05-04T15:26:26.674469: step 5315, loss 0.139625, acc 0.96875\n",
      "2018-05-04T15:26:27.886803: step 5316, loss 0.238906, acc 0.9375\n",
      "2018-05-04T15:26:28.983178: step 5317, loss 0.51967, acc 0.765625\n",
      "2018-05-04T15:26:30.116716: step 5318, loss 0.416831, acc 0.859375\n",
      "2018-05-04T15:26:31.278677: step 5319, loss 0.261037, acc 0.875\n",
      "2018-05-04T15:26:32.371822: step 5320, loss 0.220801, acc 0.9375\n",
      "2018-05-04T15:26:33.509733: step 5321, loss 0.18548, acc 0.953125\n",
      "2018-05-04T15:26:34.656602: step 5322, loss 0.26996, acc 0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T15:26:35.780052: step 5323, loss 0.446678, acc 0.8125\n",
      "2018-05-04T15:26:36.922485: step 5324, loss 0.318431, acc 0.859375\n",
      "2018-05-04T15:26:38.043339: step 5325, loss 0.545757, acc 0.765625\n",
      "2018-05-04T15:26:39.173264: step 5326, loss 0.251949, acc 0.890625\n",
      "2018-05-04T15:26:40.309958: step 5327, loss 0.267681, acc 0.890625\n",
      "2018-05-04T15:26:41.546948: step 5328, loss 0.306539, acc 0.875\n",
      "2018-05-04T15:26:42.723460: step 5329, loss 0.210603, acc 0.921875\n",
      "2018-05-04T15:26:43.933109: step 5330, loss 0.264087, acc 0.953125\n",
      "2018-05-04T15:26:45.223030: step 5331, loss 0.304246, acc 0.90625\n",
      "2018-05-04T15:26:46.480678: step 5332, loss 0.332151, acc 0.8125\n",
      "2018-05-04T15:26:47.745248: step 5333, loss 0.478523, acc 0.78125\n",
      "2018-05-04T15:26:48.897992: step 5334, loss 0.275109, acc 0.875\n",
      "2018-05-04T15:26:50.068122: step 5335, loss 0.368955, acc 0.875\n",
      "2018-05-04T15:26:51.267842: step 5336, loss 0.329317, acc 0.828125\n",
      "2018-05-04T15:26:52.404319: step 5337, loss 0.296427, acc 0.921875\n",
      "2018-05-04T15:26:53.623923: step 5338, loss 0.314853, acc 0.90625\n",
      "2018-05-04T15:26:54.900128: step 5339, loss 0.247103, acc 0.921875\n",
      "2018-05-04T15:26:56.082918: step 5340, loss 0.229735, acc 0.921875\n",
      "2018-05-04T15:26:57.168747: step 5341, loss 0.337639, acc 0.828125\n",
      "2018-05-04T15:26:58.256125: step 5342, loss 0.385218, acc 0.828125\n",
      "2018-05-04T15:26:59.361292: step 5343, loss 0.456276, acc 0.78125\n",
      "2018-05-04T15:27:00.492073: step 5344, loss 0.352569, acc 0.875\n",
      "2018-05-04T15:27:01.662229: step 5345, loss 0.354848, acc 0.796875\n",
      "2018-05-04T15:27:02.734189: step 5346, loss 0.230946, acc 0.90625\n",
      "2018-05-04T15:27:03.863427: step 5347, loss 0.242929, acc 0.9375\n",
      "2018-05-04T15:27:05.039553: step 5348, loss 0.204405, acc 0.9375\n",
      "2018-05-04T15:27:06.183534: step 5349, loss 0.24522, acc 0.890625\n",
      "2018-05-04T15:27:07.319728: step 5350, loss 0.247956, acc 0.859375\n",
      "2018-05-04T15:27:08.432086: step 5351, loss 0.300643, acc 0.859375\n",
      "2018-05-04T15:27:09.527507: step 5352, loss 0.342166, acc 0.875\n",
      "2018-05-04T15:27:10.628692: step 5353, loss 0.210657, acc 0.953125\n",
      "2018-05-04T15:27:11.764200: step 5354, loss 0.265013, acc 0.875\n",
      "2018-05-04T15:27:12.858734: step 5355, loss 0.243782, acc 0.90625\n",
      "2018-05-04T15:27:13.947469: step 5356, loss 0.169984, acc 0.96875\n",
      "2018-05-04T15:27:15.041416: step 5357, loss 0.144025, acc 0.984375\n",
      "2018-05-04T15:27:16.160142: step 5358, loss 0.294911, acc 0.90625\n",
      "2018-05-04T15:27:17.311285: step 5359, loss 0.26894, acc 0.90625\n",
      "2018-05-04T15:27:18.423474: step 5360, loss 0.272969, acc 0.890625\n",
      "2018-05-04T15:27:19.574573: step 5361, loss 0.184808, acc 0.9375\n",
      "2018-05-04T15:27:20.715401: step 5362, loss 0.284506, acc 0.875\n",
      "2018-05-04T15:27:21.875521: step 5363, loss 0.362766, acc 0.859375\n",
      "2018-05-04T15:27:22.986886: step 5364, loss 0.227509, acc 0.9375\n",
      "2018-05-04T15:27:24.118932: step 5365, loss 0.329572, acc 0.875\n",
      "2018-05-04T15:27:25.258730: step 5366, loss 0.397481, acc 0.828125\n",
      "2018-05-04T15:27:26.380711: step 5367, loss 0.263779, acc 0.890625\n",
      "2018-05-04T15:27:27.496704: step 5368, loss 0.26435, acc 0.859375\n",
      "2018-05-04T15:27:28.627693: step 5369, loss 0.233578, acc 0.890625\n",
      "2018-05-04T15:27:29.757542: step 5370, loss 0.279572, acc 0.859375\n",
      "2018-05-04T15:27:30.903144: step 5371, loss 0.177701, acc 0.953125\n",
      "2018-05-04T15:27:32.055543: step 5372, loss 0.213823, acc 0.921875\n",
      "2018-05-04T15:27:33.171386: step 5373, loss 0.264538, acc 0.875\n",
      "2018-05-04T15:27:34.304664: step 5374, loss 0.299142, acc 0.890625\n",
      "2018-05-04T15:27:35.418409: step 5375, loss 0.245544, acc 0.90625\n",
      "2018-05-04T15:27:36.547800: step 5376, loss 0.139299, acc 0.9375\n",
      "2018-05-04T15:27:37.663472: step 5377, loss 0.269098, acc 0.921875\n",
      "2018-05-04T15:27:38.771699: step 5378, loss 0.271772, acc 0.84375\n",
      "2018-05-04T15:27:39.890806: step 5379, loss 0.205043, acc 0.875\n",
      "2018-05-04T15:27:41.056207: step 5380, loss 0.254322, acc 0.890625\n",
      "2018-05-04T15:27:42.206519: step 5381, loss 0.23136, acc 0.9375\n",
      "2018-05-04T15:27:43.374396: step 5382, loss 0.258511, acc 0.890625\n",
      "2018-05-04T15:27:44.484334: step 5383, loss 0.289948, acc 0.875\n",
      "2018-05-04T15:27:45.639185: step 5384, loss 0.293101, acc 0.890625\n",
      "2018-05-04T15:27:46.734958: step 5385, loss 0.339357, acc 0.859375\n",
      "2018-05-04T15:27:47.867964: step 5386, loss 0.223979, acc 0.90625\n",
      "2018-05-04T15:27:49.016965: step 5387, loss 0.297376, acc 0.875\n",
      "2018-05-04T15:27:50.125137: step 5388, loss 0.237041, acc 0.9375\n",
      "2018-05-04T15:27:51.299813: step 5389, loss 0.324206, acc 0.859375\n",
      "2018-05-04T15:27:52.435940: step 5390, loss 0.13913, acc 0.96875\n",
      "2018-05-04T15:27:53.555934: step 5391, loss 0.24038, acc 0.890625\n",
      "2018-05-04T15:27:54.740096: step 5392, loss 0.294863, acc 0.84375\n",
      "2018-05-04T15:27:55.894796: step 5393, loss 0.321831, acc 0.859375\n",
      "2018-05-04T15:27:57.066532: step 5394, loss 0.333905, acc 0.875\n",
      "2018-05-04T15:27:58.271998: step 5395, loss 0.254949, acc 0.90625\n",
      "2018-05-04T15:27:59.419146: step 5396, loss 0.397115, acc 0.84375\n",
      "2018-05-04T15:28:00.604573: step 5397, loss 0.333037, acc 0.828125\n",
      "2018-05-04T15:28:01.817964: step 5398, loss 0.216065, acc 0.890625\n",
      "2018-05-04T15:28:02.941617: step 5399, loss 0.270877, acc 0.890625\n",
      "2018-05-04T15:28:04.074249: step 5400, loss 0.358217, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T15:28:06.807612: step 5400, loss 0.243329, acc 0.904\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-5400\n",
      "\n",
      "2018-05-04T15:28:08.053536: step 5401, loss 0.239865, acc 0.921875\n",
      "2018-05-04T15:28:09.243083: step 5402, loss 0.315536, acc 0.875\n",
      "2018-05-04T15:28:10.466864: step 5403, loss 0.334848, acc 0.859375\n",
      "2018-05-04T15:28:11.782660: step 5404, loss 0.279705, acc 0.890625\n",
      "2018-05-04T15:28:12.973475: step 5405, loss 0.365512, acc 0.84375\n",
      "2018-05-04T15:28:14.182739: step 5406, loss 0.340287, acc 0.78125\n",
      "2018-05-04T15:28:15.376023: step 5407, loss 0.301356, acc 0.875\n",
      "2018-05-04T15:28:16.552032: step 5408, loss 0.479862, acc 0.8125\n",
      "2018-05-04T15:28:17.696644: step 5409, loss 0.249341, acc 0.890625\n",
      "2018-05-04T15:28:18.840479: step 5410, loss 0.375193, acc 0.921875\n",
      "2018-05-04T15:28:19.961567: step 5411, loss 0.479267, acc 0.859375\n",
      "2018-05-04T15:28:21.242086: step 5412, loss 0.362886, acc 0.859375\n",
      "2018-05-04T15:28:22.362520: step 5413, loss 0.225911, acc 0.9375\n",
      "2018-05-04T15:28:23.503342: step 5414, loss 0.226496, acc 0.9375\n",
      "2018-05-04T15:28:24.651541: step 5415, loss 0.261716, acc 0.890625\n",
      "2018-05-04T15:28:25.809044: step 5416, loss 0.18183, acc 0.953125\n",
      "2018-05-04T15:28:26.951016: step 5417, loss 0.593991, acc 0.75\n",
      "2018-05-04T15:28:28.143124: step 5418, loss 0.255421, acc 0.890625\n",
      "2018-05-04T15:28:29.333342: step 5419, loss 0.382347, acc 0.78125\n",
      "2018-05-04T15:28:30.519786: step 5420, loss 0.265227, acc 0.90625\n",
      "2018-05-04T15:28:31.725702: step 5421, loss 0.3611, acc 0.859375\n",
      "2018-05-04T15:28:32.918482: step 5422, loss 0.351028, acc 0.859375\n",
      "2018-05-04T15:28:34.133805: step 5423, loss 0.380603, acc 0.84375\n",
      "2018-05-04T15:28:35.372498: step 5424, loss 0.208468, acc 0.90625\n",
      "2018-05-04T15:28:36.694474: step 5425, loss 0.147133, acc 0.96875\n",
      "2018-05-04T15:28:37.904742: step 5426, loss 0.231467, acc 0.921875\n",
      "2018-05-04T15:28:39.085381: step 5427, loss 0.394775, acc 0.84375\n",
      "2018-05-04T15:28:40.256486: step 5428, loss 0.250793, acc 0.90625\n",
      "2018-05-04T15:28:41.497762: step 5429, loss 0.297294, acc 0.859375\n",
      "2018-05-04T15:28:42.662237: step 5430, loss 0.379252, acc 0.859375\n",
      "2018-05-04T15:28:43.832374: step 5431, loss 0.388444, acc 0.8125\n",
      "2018-05-04T15:28:44.973791: step 5432, loss 0.403945, acc 0.890625\n",
      "2018-05-04T15:28:46.124774: step 5433, loss 0.513592, acc 0.78125\n",
      "2018-05-04T15:28:47.283803: step 5434, loss 0.270229, acc 0.875\n",
      "2018-05-04T15:28:48.438245: step 5435, loss 0.361228, acc 0.84375\n",
      "2018-05-04T15:28:49.580191: step 5436, loss 0.185019, acc 0.9375\n",
      "2018-05-04T15:28:50.737906: step 5437, loss 0.38319, acc 0.8125\n",
      "2018-05-04T15:28:51.916911: step 5438, loss 0.416161, acc 0.859375\n",
      "2018-05-04T15:28:53.037142: step 5439, loss 0.432813, acc 0.8125\n",
      "2018-05-04T15:28:54.188566: step 5440, loss 0.182021, acc 0.96875\n",
      "2018-05-04T15:28:55.326577: step 5441, loss 0.278123, acc 0.859375\n",
      "2018-05-04T15:28:56.472267: step 5442, loss 0.174821, acc 0.921875\n",
      "2018-05-04T15:28:57.605755: step 5443, loss 0.252291, acc 0.875\n",
      "2018-05-04T15:28:58.748682: step 5444, loss 0.342387, acc 0.859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T15:29:00.004064: step 5445, loss 0.334263, acc 0.875\n",
      "2018-05-04T15:29:01.273620: step 5446, loss 0.271671, acc 0.859375\n",
      "2018-05-04T15:29:02.500575: step 5447, loss 0.310562, acc 0.859375\n",
      "2018-05-04T15:29:03.635611: step 5448, loss 0.227436, acc 0.890625\n",
      "2018-05-04T15:29:04.803968: step 5449, loss 0.368005, acc 0.828125\n",
      "2018-05-04T15:29:05.930626: step 5450, loss 0.290628, acc 0.859375\n",
      "2018-05-04T15:29:07.051385: step 5451, loss 0.369883, acc 0.84375\n",
      "2018-05-04T15:29:08.179791: step 5452, loss 0.263484, acc 0.890625\n",
      "2018-05-04T15:29:09.310603: step 5453, loss 0.236935, acc 0.90625\n",
      "2018-05-04T15:29:10.490698: step 5454, loss 0.326817, acc 0.84375\n",
      "2018-05-04T15:29:11.701144: step 5455, loss 0.235445, acc 0.90625\n",
      "2018-05-04T15:29:12.827724: step 5456, loss 0.205863, acc 0.921875\n",
      "2018-05-04T15:29:14.066770: step 5457, loss 0.341889, acc 0.890625\n",
      "2018-05-04T15:29:15.268289: step 5458, loss 0.438437, acc 0.875\n",
      "2018-05-04T15:29:16.401902: step 5459, loss 0.334442, acc 0.84375\n",
      "2018-05-04T15:29:17.543807: step 5460, loss 0.368873, acc 0.859375\n",
      "2018-05-04T15:29:18.671164: step 5461, loss 0.305992, acc 0.875\n",
      "2018-05-04T15:29:19.832977: step 5462, loss 0.312137, acc 0.875\n",
      "2018-05-04T15:29:21.066718: step 5463, loss 0.335657, acc 0.8125\n",
      "2018-05-04T15:29:22.252941: step 5464, loss 0.391687, acc 0.8125\n",
      "2018-05-04T15:29:23.426317: step 5465, loss 0.280162, acc 0.859375\n",
      "2018-05-04T15:29:24.619084: step 5466, loss 0.308335, acc 0.890625\n",
      "2018-05-04T15:29:25.788249: step 5467, loss 0.268963, acc 0.890625\n",
      "2018-05-04T15:29:26.942032: step 5468, loss 0.212676, acc 0.9375\n",
      "2018-05-04T15:29:28.062933: step 5469, loss 0.305219, acc 0.859375\n",
      "2018-05-04T15:29:29.202863: step 5470, loss 0.280196, acc 0.875\n",
      "2018-05-04T15:29:30.332144: step 5471, loss 0.400768, acc 0.78125\n",
      "2018-05-04T15:29:31.572141: step 5472, loss 0.562954, acc 0.75\n",
      "2018-05-04T15:29:32.674976: step 5473, loss 0.26175, acc 0.875\n",
      "2018-05-04T15:29:33.809180: step 5474, loss 0.407786, acc 0.875\n",
      "2018-05-04T15:29:34.958134: step 5475, loss 0.246281, acc 0.921875\n",
      "2018-05-04T15:29:36.076245: step 5476, loss 0.392562, acc 0.875\n",
      "2018-05-04T15:29:37.204649: step 5477, loss 0.367752, acc 0.796875\n",
      "2018-05-04T15:29:38.364803: step 5478, loss 0.256909, acc 0.890625\n",
      "2018-05-04T15:29:39.508763: step 5479, loss 0.240624, acc 0.921875\n",
      "2018-05-04T15:29:40.625244: step 5480, loss 0.303038, acc 0.890625\n",
      "2018-05-04T15:29:41.790735: step 5481, loss 0.228429, acc 0.90625\n",
      "2018-05-04T15:29:42.917163: step 5482, loss 0.217059, acc 0.90625\n",
      "2018-05-04T15:29:44.036998: step 5483, loss 0.363693, acc 0.875\n",
      "2018-05-04T15:29:45.243198: step 5484, loss 0.465956, acc 0.765625\n",
      "2018-05-04T15:29:46.387228: step 5485, loss 0.287338, acc 0.890625\n",
      "2018-05-04T15:29:47.516595: step 5486, loss 0.206896, acc 0.921875\n",
      "2018-05-04T15:29:48.652414: step 5487, loss 0.267132, acc 0.828125\n",
      "2018-05-04T15:29:49.781340: step 5488, loss 0.363939, acc 0.859375\n",
      "2018-05-04T15:29:50.935974: step 5489, loss 0.437356, acc 0.765625\n",
      "2018-05-04T15:29:52.092963: step 5490, loss 0.263823, acc 0.890625\n",
      "2018-05-04T15:29:53.184193: step 5491, loss 0.354709, acc 0.828125\n",
      "2018-05-04T15:29:54.333447: step 5492, loss 0.308454, acc 0.84375\n",
      "2018-05-04T15:29:55.434032: step 5493, loss 0.302734, acc 0.84375\n",
      "2018-05-04T15:29:56.553467: step 5494, loss 0.283892, acc 0.890625\n",
      "2018-05-04T15:29:57.682644: step 5495, loss 0.455066, acc 0.8125\n",
      "2018-05-04T15:29:58.823502: step 5496, loss 0.261324, acc 0.890625\n",
      "2018-05-04T15:29:59.974740: step 5497, loss 0.389458, acc 0.78125\n",
      "2018-05-04T15:30:01.145341: step 5498, loss 0.333457, acc 0.859375\n",
      "2018-05-04T15:30:02.338030: step 5499, loss 0.416804, acc 0.828125\n",
      "2018-05-04T15:30:03.457407: step 5500, loss 0.197751, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T15:30:06.011926: step 5500, loss 0.274302, acc 0.894\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-5500\n",
      "\n",
      "2018-05-04T15:30:07.215368: step 5501, loss 0.192534, acc 0.9375\n",
      "2018-05-04T15:30:08.326886: step 5502, loss 0.251651, acc 0.859375\n",
      "2018-05-04T15:30:09.459585: step 5503, loss 0.370977, acc 0.828125\n",
      "2018-05-04T15:30:10.591370: step 5504, loss 0.302715, acc 0.84375\n",
      "2018-05-04T15:30:11.784240: step 5505, loss 0.393162, acc 0.875\n",
      "2018-05-04T15:30:12.940377: step 5506, loss 0.351534, acc 0.875\n",
      "2018-05-04T15:30:14.129232: step 5507, loss 0.231161, acc 0.890625\n",
      "2018-05-04T15:30:15.275078: step 5508, loss 0.279767, acc 0.890625\n",
      "2018-05-04T15:30:16.419451: step 5509, loss 0.276341, acc 0.9375\n",
      "2018-05-04T15:30:17.573072: step 5510, loss 0.332827, acc 0.84375\n",
      "2018-05-04T15:30:18.743278: step 5511, loss 0.235136, acc 0.90625\n",
      "2018-05-04T15:30:19.948892: step 5512, loss 0.212631, acc 0.9375\n",
      "2018-05-04T15:30:21.175224: step 5513, loss 0.162596, acc 0.953125\n",
      "2018-05-04T15:30:22.456783: step 5514, loss 0.311201, acc 0.890625\n",
      "2018-05-04T15:30:23.620352: step 5515, loss 0.257415, acc 0.921875\n",
      "2018-05-04T15:30:24.852555: step 5516, loss 0.265861, acc 0.890625\n",
      "2018-05-04T15:30:25.974421: step 5517, loss 0.328218, acc 0.875\n",
      "2018-05-04T15:30:27.090695: step 5518, loss 0.372583, acc 0.875\n",
      "2018-05-04T15:30:28.204539: step 5519, loss 0.364875, acc 0.875\n",
      "2018-05-04T15:30:29.369823: step 5520, loss 0.186938, acc 0.953125\n",
      "2018-05-04T15:30:30.536342: step 5521, loss 0.237684, acc 0.890625\n",
      "2018-05-04T15:30:31.824216: step 5522, loss 0.336966, acc 0.84375\n",
      "2018-05-04T15:30:32.988224: step 5523, loss 0.326085, acc 0.8125\n",
      "2018-05-04T15:30:34.245123: step 5524, loss 0.311557, acc 0.875\n",
      "2018-05-04T15:30:35.462890: step 5525, loss 0.185105, acc 0.921875\n",
      "2018-05-04T15:30:36.622057: step 5526, loss 0.412739, acc 0.859375\n",
      "2018-05-04T15:30:37.774762: step 5527, loss 0.263762, acc 0.890625\n",
      "2018-05-04T15:30:39.006497: step 5528, loss 0.248959, acc 0.921875\n",
      "2018-05-04T15:30:40.237631: step 5529, loss 0.243638, acc 0.90625\n",
      "2018-05-04T15:30:41.504121: step 5530, loss 0.321964, acc 0.890625\n",
      "2018-05-04T15:30:42.728562: step 5531, loss 0.362153, acc 0.84375\n",
      "2018-05-04T15:30:43.995527: step 5532, loss 0.259514, acc 0.921875\n",
      "2018-05-04T15:30:45.279543: step 5533, loss 0.320105, acc 0.875\n",
      "2018-05-04T15:30:46.541889: step 5534, loss 0.306919, acc 0.875\n",
      "2018-05-04T15:30:47.809319: step 5535, loss 0.34615, acc 0.84375\n",
      "2018-05-04T15:30:49.091224: step 5536, loss 0.284743, acc 0.859375\n",
      "2018-05-04T15:30:50.344880: step 5537, loss 0.297745, acc 0.859375\n",
      "2018-05-04T15:30:51.712389: step 5538, loss 0.158458, acc 0.953125\n",
      "2018-05-04T15:30:53.041237: step 5539, loss 0.225693, acc 0.9375\n",
      "2018-05-04T15:30:54.305339: step 5540, loss 0.346614, acc 0.921875\n",
      "2018-05-04T15:30:55.563752: step 5541, loss 0.29184, acc 0.890625\n",
      "2018-05-04T15:30:56.888860: step 5542, loss 0.272572, acc 0.859375\n",
      "2018-05-04T15:30:58.201751: step 5543, loss 0.310477, acc 0.90625\n",
      "2018-05-04T15:30:59.541806: step 5544, loss 0.402013, acc 0.8125\n",
      "2018-05-04T15:31:00.906140: step 5545, loss 0.303493, acc 0.921875\n",
      "2018-05-04T15:31:02.292056: step 5546, loss 0.261345, acc 0.90625\n",
      "2018-05-04T15:31:03.644067: step 5547, loss 0.342652, acc 0.890625\n",
      "2018-05-04T15:31:05.088057: step 5548, loss 0.207894, acc 0.9375\n",
      "2018-05-04T15:31:06.469533: step 5549, loss 0.215669, acc 0.90625\n",
      "2018-05-04T15:31:07.887909: step 5550, loss 0.319472, acc 0.875\n",
      "2018-05-04T15:31:09.272518: step 5551, loss 0.332756, acc 0.859375\n",
      "2018-05-04T15:31:10.656759: step 5552, loss 0.257123, acc 0.921875\n",
      "2018-05-04T15:31:12.097123: step 5553, loss 0.233989, acc 0.890625\n",
      "2018-05-04T15:31:13.470164: step 5554, loss 0.261962, acc 0.921875\n",
      "2018-05-04T15:31:14.838838: step 5555, loss 0.203338, acc 0.953125\n",
      "2018-05-04T15:31:16.163395: step 5556, loss 0.22681, acc 0.875\n",
      "2018-05-04T15:31:17.527935: step 5557, loss 0.35631, acc 0.875\n",
      "2018-05-04T15:31:18.876945: step 5558, loss 0.331894, acc 0.890625\n",
      "2018-05-04T15:31:20.207881: step 5559, loss 0.231913, acc 0.90625\n",
      "2018-05-04T15:31:21.755605: step 5560, loss 0.365674, acc 0.796875\n",
      "2018-05-04T15:31:23.155047: step 5561, loss 0.388214, acc 0.828125\n",
      "2018-05-04T15:31:24.514378: step 5562, loss 0.273074, acc 0.890625\n",
      "2018-05-04T15:31:25.888966: step 5563, loss 0.251871, acc 0.890625\n",
      "2018-05-04T15:31:27.202119: step 5564, loss 0.241904, acc 0.890625\n",
      "2018-05-04T15:31:28.484318: step 5565, loss 0.219942, acc 0.90625\n",
      "2018-05-04T15:31:29.817931: step 5566, loss 0.416956, acc 0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T15:31:31.196117: step 5567, loss 0.540755, acc 0.78125\n",
      "2018-05-04T15:31:32.548106: step 5568, loss 0.196267, acc 0.921875\n",
      "2018-05-04T15:31:33.941299: step 5569, loss 0.332166, acc 0.859375\n",
      "2018-05-04T15:31:35.321324: step 5570, loss 0.411127, acc 0.84375\n",
      "2018-05-04T15:31:36.750670: step 5571, loss 0.188747, acc 0.9375\n",
      "2018-05-04T15:31:38.143076: step 5572, loss 0.22455, acc 0.90625\n",
      "2018-05-04T15:31:39.400668: step 5573, loss 0.239725, acc 0.875\n",
      "2018-05-04T15:31:40.657982: step 5574, loss 0.429993, acc 0.8125\n",
      "2018-05-04T15:31:42.003523: step 5575, loss 0.193927, acc 0.890625\n",
      "2018-05-04T15:31:43.296667: step 5576, loss 0.308819, acc 0.84375\n",
      "2018-05-04T15:31:44.515382: step 5577, loss 0.33947, acc 0.859375\n",
      "2018-05-04T15:31:45.755037: step 5578, loss 0.298669, acc 0.84375\n",
      "2018-05-04T15:31:46.988502: step 5579, loss 0.213777, acc 0.90625\n",
      "2018-05-04T15:31:48.198233: step 5580, loss 0.376257, acc 0.828125\n",
      "2018-05-04T15:31:49.415737: step 5581, loss 0.231026, acc 0.890625\n",
      "2018-05-04T15:31:50.548447: step 5582, loss 0.352661, acc 0.8125\n",
      "2018-05-04T15:31:51.774351: step 5583, loss 0.286805, acc 0.859375\n",
      "2018-05-04T15:31:52.964785: step 5584, loss 0.218376, acc 0.875\n",
      "2018-05-04T15:31:54.147687: step 5585, loss 0.382755, acc 0.84375\n",
      "2018-05-04T15:31:55.339831: step 5586, loss 0.302787, acc 0.90625\n",
      "2018-05-04T15:31:56.487160: step 5587, loss 0.498683, acc 0.828125\n",
      "2018-05-04T15:31:57.674982: step 5588, loss 0.259396, acc 0.875\n",
      "2018-05-04T15:31:58.847624: step 5589, loss 0.240008, acc 0.90625\n",
      "2018-05-04T15:32:00.003461: step 5590, loss 0.381333, acc 0.90625\n",
      "2018-05-04T15:32:01.159975: step 5591, loss 0.426273, acc 0.828125\n",
      "2018-05-04T15:32:02.333047: step 5592, loss 0.248467, acc 0.859375\n",
      "2018-05-04T15:32:03.450604: step 5593, loss 0.25841, acc 0.90625\n",
      "2018-05-04T15:32:04.620035: step 5594, loss 0.2497, acc 0.90625\n",
      "2018-05-04T15:32:05.779014: step 5595, loss 0.327526, acc 0.84375\n",
      "2018-05-04T15:32:06.911170: step 5596, loss 0.294672, acc 0.84375\n",
      "2018-05-04T15:32:08.040238: step 5597, loss 0.42833, acc 0.796875\n",
      "2018-05-04T15:32:09.141918: step 5598, loss 0.292191, acc 0.9375\n",
      "2018-05-04T15:32:10.268199: step 5599, loss 0.300681, acc 0.875\n",
      "2018-05-04T15:32:11.429488: step 5600, loss 0.273418, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T15:32:14.124100: step 5600, loss 0.243125, acc 0.904\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-5600\n",
      "\n",
      "2018-05-04T15:32:15.347378: step 5601, loss 0.296771, acc 0.859375\n",
      "2018-05-04T15:32:16.535476: step 5602, loss 0.261737, acc 0.90625\n",
      "2018-05-04T15:32:17.658052: step 5603, loss 0.288756, acc 0.90625\n",
      "2018-05-04T15:32:18.786239: step 5604, loss 0.295445, acc 0.890625\n",
      "2018-05-04T15:32:19.971112: step 5605, loss 0.225102, acc 0.890625\n",
      "2018-05-04T15:32:21.115446: step 5606, loss 0.30957, acc 0.84375\n",
      "2018-05-04T15:32:22.193197: step 5607, loss 0.253691, acc 0.890625\n",
      "2018-05-04T15:32:23.272419: step 5608, loss 0.274061, acc 0.890625\n",
      "2018-05-04T15:32:24.367033: step 5609, loss 0.274264, acc 0.921875\n",
      "2018-05-04T15:32:25.434495: step 5610, loss 0.350098, acc 0.859375\n",
      "2018-05-04T15:32:26.467509: step 5611, loss 0.189463, acc 0.9375\n",
      "2018-05-04T15:32:27.494270: step 5612, loss 0.256398, acc 0.9375\n",
      "2018-05-04T15:32:28.531704: step 5613, loss 0.21446, acc 0.921875\n",
      "2018-05-04T15:32:29.641873: step 5614, loss 0.17146, acc 0.921875\n",
      "2018-05-04T15:32:30.688092: step 5615, loss 0.30223, acc 0.875\n",
      "2018-05-04T15:32:31.760314: step 5616, loss 0.341768, acc 0.859375\n",
      "2018-05-04T15:32:32.812694: step 5617, loss 0.31361, acc 0.859375\n",
      "2018-05-04T15:32:33.860123: step 5618, loss 0.310792, acc 0.890625\n",
      "2018-05-04T15:32:34.919375: step 5619, loss 0.274542, acc 0.890625\n",
      "2018-05-04T15:32:36.171910: step 5620, loss 0.383636, acc 0.875\n",
      "2018-05-04T15:32:37.261337: step 5621, loss 0.304141, acc 0.875\n",
      "2018-05-04T15:32:38.418522: step 5622, loss 0.169979, acc 0.9375\n",
      "2018-05-04T15:32:39.555074: step 5623, loss 0.458564, acc 0.71875\n",
      "2018-05-04T15:32:40.923780: step 5624, loss 0.242052, acc 0.875\n",
      "2018-05-04T15:32:42.348534: step 5625, loss 0.228561, acc 0.890625\n",
      "2018-05-04T15:32:43.677257: step 5626, loss 0.188867, acc 0.953125\n",
      "2018-05-04T15:32:45.058744: step 5627, loss 0.193657, acc 0.921875\n",
      "2018-05-04T15:32:46.413597: step 5628, loss 0.369985, acc 0.875\n",
      "2018-05-04T15:32:47.670202: step 5629, loss 0.229177, acc 0.953125\n",
      "2018-05-04T15:32:49.102549: step 5630, loss 0.2974, acc 0.875\n",
      "2018-05-04T15:32:50.500489: step 5631, loss 0.232548, acc 0.90625\n",
      "2018-05-04T15:32:51.962500: step 5632, loss 0.267358, acc 0.828125\n",
      "2018-05-04T15:32:53.163515: step 5633, loss 0.339341, acc 0.875\n",
      "2018-05-04T15:32:54.386987: step 5634, loss 0.266506, acc 0.90625\n",
      "2018-05-04T15:32:55.590058: step 5635, loss 0.291241, acc 0.84375\n",
      "2018-05-04T15:32:56.791199: step 5636, loss 0.305808, acc 0.84375\n",
      "2018-05-04T15:32:57.945189: step 5637, loss 0.208708, acc 0.90625\n",
      "2018-05-04T15:32:59.088568: step 5638, loss 0.24376, acc 0.890625\n",
      "2018-05-04T15:33:00.263709: step 5639, loss 0.218213, acc 0.890625\n",
      "2018-05-04T15:33:01.621636: step 5640, loss 0.399997, acc 0.828125\n",
      "2018-05-04T15:33:02.900834: step 5641, loss 0.350138, acc 0.84375\n",
      "2018-05-04T15:33:04.117789: step 5642, loss 0.303291, acc 0.875\n",
      "2018-05-04T15:33:05.351587: step 5643, loss 0.349217, acc 0.84375\n",
      "2018-05-04T15:33:06.466055: step 5644, loss 0.309359, acc 0.796875\n",
      "2018-05-04T15:33:07.652053: step 5645, loss 0.206894, acc 0.921875\n",
      "2018-05-04T15:33:08.882178: step 5646, loss 0.355018, acc 0.875\n",
      "2018-05-04T15:33:10.069039: step 5647, loss 0.415679, acc 0.8125\n",
      "2018-05-04T15:33:11.203662: step 5648, loss 0.33876, acc 0.859375\n",
      "2018-05-04T15:33:12.353837: step 5649, loss 0.22721, acc 0.953125\n",
      "2018-05-04T15:33:13.510709: step 5650, loss 0.2354, acc 0.890625\n",
      "2018-05-04T15:33:14.762844: step 5651, loss 0.484605, acc 0.84375\n",
      "2018-05-04T15:33:15.832795: step 5652, loss 0.230698, acc 0.90625\n",
      "2018-05-04T15:33:16.949194: step 5653, loss 0.318383, acc 0.875\n",
      "2018-05-04T15:33:18.032000: step 5654, loss 0.219659, acc 0.875\n",
      "2018-05-04T15:33:19.139802: step 5655, loss 0.378345, acc 0.859375\n",
      "2018-05-04T15:33:20.210606: step 5656, loss 0.303329, acc 0.890625\n",
      "2018-05-04T15:33:21.338706: step 5657, loss 0.229887, acc 0.921875\n",
      "2018-05-04T15:33:22.489311: step 5658, loss 0.201103, acc 0.921875\n",
      "2018-05-04T15:33:23.620770: step 5659, loss 0.323724, acc 0.875\n",
      "2018-05-04T15:33:24.634732: step 5660, loss 0.324612, acc 0.890625\n",
      "2018-05-04T15:33:25.636498: step 5661, loss 0.203783, acc 0.90625\n",
      "2018-05-04T15:33:26.651892: step 5662, loss 0.245492, acc 0.875\n",
      "2018-05-04T15:33:27.718470: step 5663, loss 0.283699, acc 0.90625\n",
      "2018-05-04T15:33:28.802297: step 5664, loss 0.216523, acc 0.921875\n",
      "2018-05-04T15:33:29.987660: step 5665, loss 0.361927, acc 0.828125\n",
      "2018-05-04T15:33:31.314796: step 5666, loss 0.266931, acc 0.921875\n",
      "2018-05-04T15:33:32.599490: step 5667, loss 0.372841, acc 0.84375\n",
      "2018-05-04T15:33:33.719786: step 5668, loss 0.417756, acc 0.84375\n",
      "2018-05-04T15:33:34.895530: step 5669, loss 0.306976, acc 0.859375\n",
      "2018-05-04T15:33:36.212487: step 5670, loss 0.194153, acc 0.96875\n",
      "2018-05-04T15:33:37.434734: step 5671, loss 0.207752, acc 0.921875\n",
      "2018-05-04T15:33:38.587752: step 5672, loss 0.34433, acc 0.84375\n",
      "2018-05-04T15:33:39.634647: step 5673, loss 0.275314, acc 0.890625\n",
      "2018-05-04T15:33:40.787444: step 5674, loss 0.433446, acc 0.859375\n",
      "2018-05-04T15:33:41.933236: step 5675, loss 0.323411, acc 0.8125\n",
      "2018-05-04T15:33:42.997662: step 5676, loss 0.221171, acc 0.921875\n",
      "2018-05-04T15:33:44.071882: step 5677, loss 0.231059, acc 0.921875\n",
      "2018-05-04T15:33:45.201660: step 5678, loss 0.260338, acc 0.875\n",
      "2018-05-04T15:33:46.239613: step 5679, loss 0.60309, acc 0.703125\n",
      "2018-05-04T15:33:47.444419: step 5680, loss 0.274018, acc 0.890625\n",
      "2018-05-04T15:33:48.655024: step 5681, loss 0.296637, acc 0.9375\n",
      "2018-05-04T15:33:49.875272: step 5682, loss 0.26657, acc 0.875\n",
      "2018-05-04T15:33:51.200466: step 5683, loss 0.456464, acc 0.8125\n",
      "2018-05-04T15:33:52.458120: step 5684, loss 0.297442, acc 0.84375\n",
      "2018-05-04T15:33:53.684683: step 5685, loss 0.35893, acc 0.859375\n",
      "2018-05-04T15:33:54.895436: step 5686, loss 0.349482, acc 0.859375\n",
      "2018-05-04T15:33:56.148477: step 5687, loss 0.224027, acc 0.9375\n",
      "2018-05-04T15:33:57.301319: step 5688, loss 0.281187, acc 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T15:33:58.416955: step 5689, loss 0.283127, acc 0.859375\n",
      "2018-05-04T15:33:59.533855: step 5690, loss 0.226228, acc 0.90625\n",
      "2018-05-04T15:34:00.687225: step 5691, loss 0.41939, acc 0.8125\n",
      "2018-05-04T15:34:01.871303: step 5692, loss 0.278303, acc 0.859375\n",
      "2018-05-04T15:34:02.963630: step 5693, loss 0.215893, acc 0.890625\n",
      "2018-05-04T15:34:04.063805: step 5694, loss 0.326243, acc 0.875\n",
      "2018-05-04T15:34:05.150017: step 5695, loss 0.220908, acc 0.9375\n",
      "2018-05-04T15:34:06.351449: step 5696, loss 0.220186, acc 0.90625\n",
      "2018-05-04T15:34:07.537323: step 5697, loss 0.310677, acc 0.921875\n",
      "2018-05-04T15:34:08.730004: step 5698, loss 0.173914, acc 0.953125\n",
      "2018-05-04T15:34:10.061390: step 5699, loss 0.35975, acc 0.859375\n",
      "2018-05-04T15:34:11.396825: step 5700, loss 0.314736, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T15:34:15.047803: step 5700, loss 0.28786, acc 0.878\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-5700\n",
      "\n",
      "2018-05-04T15:34:16.414702: step 5701, loss 0.211023, acc 0.9375\n",
      "2018-05-04T15:34:17.655886: step 5702, loss 0.15556, acc 0.921875\n",
      "2018-05-04T15:34:18.915801: step 5703, loss 0.202665, acc 0.875\n",
      "2018-05-04T15:34:20.092610: step 5704, loss 0.247445, acc 0.890625\n",
      "2018-05-04T15:34:21.567052: step 5705, loss 0.258201, acc 0.9375\n",
      "2018-05-04T15:34:22.888434: step 5706, loss 0.358034, acc 0.875\n",
      "2018-05-04T15:34:24.040950: step 5707, loss 0.227371, acc 0.90625\n",
      "2018-05-04T15:34:25.189404: step 5708, loss 0.514787, acc 0.8125\n",
      "2018-05-04T15:34:26.375379: step 5709, loss 0.231074, acc 0.875\n",
      "2018-05-04T15:34:27.592707: step 5710, loss 0.265644, acc 0.890625\n",
      "2018-05-04T15:34:28.829268: step 5711, loss 0.295304, acc 0.859375\n",
      "2018-05-04T15:34:30.160193: step 5712, loss 0.279111, acc 0.90625\n",
      "2018-05-04T15:34:31.499982: step 5713, loss 0.303642, acc 0.875\n",
      "2018-05-04T15:34:32.863190: step 5714, loss 0.367912, acc 0.859375\n",
      "2018-05-04T15:34:34.229467: step 5715, loss 0.221095, acc 0.9375\n",
      "2018-05-04T15:34:35.506763: step 5716, loss 0.255707, acc 0.921875\n",
      "2018-05-04T15:34:36.743793: step 5717, loss 0.311362, acc 0.875\n",
      "2018-05-04T15:34:37.991368: step 5718, loss 0.311045, acc 0.859375\n",
      "2018-05-04T15:34:39.208349: step 5719, loss 0.2613, acc 0.9375\n",
      "2018-05-04T15:34:40.443848: step 5720, loss 0.279515, acc 0.875\n",
      "2018-05-04T15:34:41.691984: step 5721, loss 0.268243, acc 0.875\n",
      "2018-05-04T15:34:42.795896: step 5722, loss 0.327241, acc 0.90625\n",
      "2018-05-04T15:34:43.987011: step 5723, loss 0.268962, acc 0.890625\n",
      "2018-05-04T15:34:45.204625: step 5724, loss 0.329629, acc 0.859375\n",
      "2018-05-04T15:34:46.396342: step 5725, loss 0.309371, acc 0.921875\n",
      "2018-05-04T15:34:47.666147: step 5726, loss 0.209684, acc 0.921875\n",
      "2018-05-04T15:34:49.017269: step 5727, loss 0.281036, acc 0.890625\n",
      "2018-05-04T15:34:50.317781: step 5728, loss 0.187817, acc 0.9375\n",
      "2018-05-04T15:34:51.632401: step 5729, loss 0.233522, acc 0.90625\n",
      "2018-05-04T15:34:52.880927: step 5730, loss 0.266053, acc 0.890625\n",
      "2018-05-04T15:34:54.344128: step 5731, loss 0.345281, acc 0.875\n",
      "2018-05-04T15:34:55.788137: step 5732, loss 0.421876, acc 0.84375\n",
      "2018-05-04T15:34:57.386277: step 5733, loss 0.246724, acc 0.90625\n",
      "2018-05-04T15:34:58.872247: step 5734, loss 0.275382, acc 0.875\n",
      "2018-05-04T15:35:00.328718: step 5735, loss 0.31166, acc 0.859375\n",
      "2018-05-04T15:35:02.010893: step 5736, loss 0.216594, acc 0.921875\n",
      "2018-05-04T15:35:03.516727: step 5737, loss 0.400803, acc 0.765625\n",
      "2018-05-04T15:35:05.036722: step 5738, loss 0.334261, acc 0.875\n",
      "2018-05-04T15:35:06.546263: step 5739, loss 0.341736, acc 0.8125\n",
      "2018-05-04T15:35:07.925502: step 5740, loss 0.502816, acc 0.84375\n",
      "2018-05-04T15:35:09.269652: step 5741, loss 0.388762, acc 0.84375\n",
      "2018-05-04T15:35:10.917087: step 5742, loss 0.221435, acc 0.921875\n",
      "2018-05-04T15:35:12.566713: step 5743, loss 0.320275, acc 0.875\n",
      "2018-05-04T15:35:14.146476: step 5744, loss 0.237667, acc 0.9375\n",
      "2018-05-04T15:35:15.545953: step 5745, loss 0.289312, acc 0.890625\n",
      "2018-05-04T15:35:16.893281: step 5746, loss 0.209538, acc 0.90625\n",
      "2018-05-04T15:35:18.283067: step 5747, loss 0.259142, acc 0.84375\n",
      "2018-05-04T15:35:19.665607: step 5748, loss 0.370993, acc 0.828125\n",
      "2018-05-04T15:35:21.139090: step 5749, loss 0.333435, acc 0.859375\n",
      "2018-05-04T15:35:22.624816: step 5750, loss 0.335859, acc 0.828125\n",
      "2018-05-04T15:35:24.158247: step 5751, loss 0.383136, acc 0.859375\n",
      "2018-05-04T15:35:25.574680: step 5752, loss 0.441129, acc 0.78125\n",
      "2018-05-04T15:35:27.118071: step 5753, loss 0.28217, acc 0.859375\n",
      "2018-05-04T15:35:28.769801: step 5754, loss 0.206304, acc 0.921875\n",
      "2018-05-04T15:35:30.325620: step 5755, loss 0.24101, acc 0.890625\n",
      "2018-05-04T15:35:32.005710: step 5756, loss 0.192647, acc 0.9375\n",
      "2018-05-04T15:35:33.459055: step 5757, loss 0.249774, acc 0.890625\n",
      "2018-05-04T15:35:34.855315: step 5758, loss 0.216166, acc 0.859375\n",
      "2018-05-04T15:35:36.201576: step 5759, loss 0.263741, acc 0.859375\n",
      "2018-05-04T15:35:37.576467: step 5760, loss 0.199098, acc 0.953125\n",
      "2018-05-04T15:35:39.029225: step 5761, loss 0.426431, acc 0.828125\n",
      "2018-05-04T15:35:40.370590: step 5762, loss 0.306344, acc 0.859375\n",
      "2018-05-04T15:35:41.909659: step 5763, loss 0.253271, acc 0.890625\n",
      "2018-05-04T15:35:43.281715: step 5764, loss 0.417251, acc 0.765625\n",
      "2018-05-04T15:35:44.588428: step 5765, loss 0.45034, acc 0.78125\n",
      "2018-05-04T15:35:45.818616: step 5766, loss 0.305089, acc 0.84375\n",
      "2018-05-04T15:35:47.082562: step 5767, loss 0.279146, acc 0.90625\n",
      "2018-05-04T15:35:48.419494: step 5768, loss 0.428536, acc 0.796875\n",
      "2018-05-04T15:35:49.895683: step 5769, loss 0.306212, acc 0.90625\n",
      "2018-05-04T15:35:51.471294: step 5770, loss 0.319591, acc 0.84375\n",
      "2018-05-04T15:35:53.100325: step 5771, loss 0.192585, acc 0.9375\n",
      "2018-05-04T15:35:54.740218: step 5772, loss 0.362815, acc 0.828125\n",
      "2018-05-04T15:35:56.421212: step 5773, loss 0.341623, acc 0.796875\n",
      "2018-05-04T15:35:57.995307: step 5774, loss 0.301236, acc 0.890625\n",
      "2018-05-04T15:35:59.639069: step 5775, loss 0.321893, acc 0.875\n",
      "2018-05-04T15:36:01.247913: step 5776, loss 0.286444, acc 0.859375\n",
      "2018-05-04T15:36:02.898361: step 5777, loss 0.192077, acc 0.9375\n",
      "2018-05-04T15:36:04.467228: step 5778, loss 0.250675, acc 0.9375\n",
      "2018-05-04T15:36:06.053815: step 5779, loss 0.201237, acc 0.953125\n",
      "2018-05-04T15:36:07.574475: step 5780, loss 0.295347, acc 0.875\n",
      "2018-05-04T15:36:09.185048: step 5781, loss 0.214511, acc 0.90625\n",
      "2018-05-04T15:36:10.675067: step 5782, loss 0.24153, acc 0.90625\n",
      "2018-05-04T15:36:12.227996: step 5783, loss 0.324107, acc 0.8125\n",
      "2018-05-04T15:36:13.751591: step 5784, loss 0.220596, acc 0.890625\n",
      "2018-05-04T15:36:15.276913: step 5785, loss 0.439388, acc 0.796875\n",
      "2018-05-04T15:36:16.790078: step 5786, loss 0.334654, acc 0.828125\n",
      "2018-05-04T15:36:18.237389: step 5787, loss 0.338986, acc 0.859375\n",
      "2018-05-04T15:36:19.624732: step 5788, loss 0.267335, acc 0.890625\n",
      "2018-05-04T15:36:21.092657: step 5789, loss 0.297143, acc 0.890625\n",
      "2018-05-04T15:36:22.524129: step 5790, loss 0.263497, acc 0.921875\n",
      "2018-05-04T15:36:23.990009: step 5791, loss 0.335067, acc 0.859375\n",
      "2018-05-04T15:36:25.459095: step 5792, loss 0.320375, acc 0.84375\n",
      "2018-05-04T15:36:26.939126: step 5793, loss 0.289796, acc 0.875\n",
      "2018-05-04T15:36:28.309484: step 5794, loss 0.333791, acc 0.875\n",
      "2018-05-04T15:36:29.699153: step 5795, loss 0.392274, acc 0.8125\n",
      "2018-05-04T15:36:31.109358: step 5796, loss 0.290994, acc 0.875\n",
      "2018-05-04T15:36:32.445458: step 5797, loss 0.154204, acc 0.984375\n",
      "2018-05-04T15:36:33.764720: step 5798, loss 0.205296, acc 0.921875\n",
      "2018-05-04T15:36:35.033839: step 5799, loss 0.349171, acc 0.828125\n",
      "2018-05-04T15:36:36.360809: step 5800, loss 0.233938, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T15:36:39.637776: step 5800, loss 0.286708, acc 0.886\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-5800\n",
      "\n",
      "2018-05-04T15:36:41.042262: step 5801, loss 0.391148, acc 0.875\n",
      "2018-05-04T15:36:42.362632: step 5802, loss 0.183752, acc 0.953125\n",
      "2018-05-04T15:36:43.655312: step 5803, loss 0.363107, acc 0.875\n",
      "2018-05-04T15:36:44.967475: step 5804, loss 0.186401, acc 0.953125\n",
      "2018-05-04T15:36:46.283933: step 5805, loss 0.285835, acc 0.90625\n",
      "2018-05-04T15:36:47.590106: step 5806, loss 0.294083, acc 0.890625\n",
      "2018-05-04T15:36:48.968724: step 5807, loss 0.191741, acc 0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T15:36:50.306247: step 5808, loss 0.235692, acc 0.890625\n",
      "2018-05-04T15:36:51.651453: step 5809, loss 0.33119, acc 0.890625\n",
      "2018-05-04T15:36:52.920444: step 5810, loss 0.239017, acc 0.875\n",
      "2018-05-04T15:36:54.201909: step 5811, loss 0.227749, acc 0.890625\n",
      "2018-05-04T15:36:55.434759: step 5812, loss 0.364768, acc 0.796875\n",
      "2018-05-04T15:36:56.693009: step 5813, loss 0.308704, acc 0.8125\n",
      "2018-05-04T15:36:58.013662: step 5814, loss 0.218773, acc 0.9375\n",
      "2018-05-04T15:36:59.281723: step 5815, loss 0.203181, acc 0.90625\n",
      "2018-05-04T15:37:00.513721: step 5816, loss 0.289933, acc 0.890625\n",
      "2018-05-04T15:37:01.855093: step 5817, loss 0.372733, acc 0.828125\n",
      "2018-05-04T15:37:03.111268: step 5818, loss 0.246213, acc 0.859375\n",
      "2018-05-04T15:37:04.312372: step 5819, loss 0.205174, acc 0.890625\n",
      "2018-05-04T15:37:05.524256: step 5820, loss 0.323795, acc 0.90625\n",
      "2018-05-04T15:37:06.711508: step 5821, loss 0.351085, acc 0.765625\n",
      "2018-05-04T15:37:07.924047: step 5822, loss 0.311017, acc 0.890625\n",
      "2018-05-04T15:37:09.097660: step 5823, loss 0.249543, acc 0.90625\n",
      "2018-05-04T15:37:10.280054: step 5824, loss 0.313803, acc 0.859375\n",
      "2018-05-04T15:37:11.531349: step 5825, loss 0.308797, acc 0.875\n",
      "2018-05-04T15:37:12.706686: step 5826, loss 0.41452, acc 0.828125\n",
      "2018-05-04T15:37:13.940473: step 5827, loss 0.185614, acc 0.90625\n",
      "2018-05-04T15:37:15.088253: step 5828, loss 0.346537, acc 0.84375\n",
      "2018-05-04T15:37:16.223571: step 5829, loss 0.323712, acc 0.875\n",
      "2018-05-04T15:37:17.419060: step 5830, loss 0.449127, acc 0.796875\n",
      "2018-05-04T15:37:18.576625: step 5831, loss 0.341172, acc 0.84375\n",
      "2018-05-04T15:37:19.724822: step 5832, loss 0.367178, acc 0.875\n",
      "2018-05-04T15:37:20.859280: step 5833, loss 0.237705, acc 0.9375\n",
      "2018-05-04T15:37:22.039180: step 5834, loss 0.268851, acc 0.859375\n",
      "2018-05-04T15:37:23.224306: step 5835, loss 0.395339, acc 0.796875\n",
      "2018-05-04T15:37:24.491091: step 5836, loss 0.317606, acc 0.859375\n",
      "2018-05-04T15:37:25.657866: step 5837, loss 0.404089, acc 0.875\n",
      "2018-05-04T15:37:26.804347: step 5838, loss 0.242713, acc 0.953125\n",
      "2018-05-04T15:37:27.998562: step 5839, loss 0.564584, acc 0.78125\n",
      "2018-05-04T15:37:29.170959: step 5840, loss 0.37813, acc 0.8125\n",
      "2018-05-04T15:37:30.349503: step 5841, loss 0.281255, acc 0.859375\n",
      "2018-05-04T15:37:31.603859: step 5842, loss 0.190503, acc 0.9375\n",
      "2018-05-04T15:37:32.828991: step 5843, loss 0.259345, acc 0.84375\n",
      "2018-05-04T15:37:34.124386: step 5844, loss 0.255127, acc 0.890625\n",
      "2018-05-04T15:37:35.396702: step 5845, loss 0.218131, acc 0.921875\n",
      "2018-05-04T15:37:36.639243: step 5846, loss 0.227268, acc 0.890625\n",
      "2018-05-04T15:37:37.905740: step 5847, loss 0.410767, acc 0.796875\n",
      "2018-05-04T15:37:39.161010: step 5848, loss 0.354237, acc 0.859375\n",
      "2018-05-04T15:37:40.349952: step 5849, loss 0.238292, acc 0.953125\n",
      "2018-05-04T15:37:41.599962: step 5850, loss 0.329195, acc 0.8125\n",
      "2018-05-04T15:37:42.739972: step 5851, loss 0.348429, acc 0.84375\n",
      "2018-05-04T15:37:43.865599: step 5852, loss 0.252095, acc 0.921875\n",
      "2018-05-04T15:37:44.988971: step 5853, loss 0.151025, acc 0.953125\n",
      "2018-05-04T15:37:46.135418: step 5854, loss 0.177745, acc 0.90625\n",
      "2018-05-04T15:37:47.339141: step 5855, loss 0.23436, acc 0.875\n",
      "2018-05-04T15:37:48.552133: step 5856, loss 0.388075, acc 0.828125\n",
      "2018-05-04T15:37:49.745222: step 5857, loss 0.235069, acc 0.921875\n",
      "2018-05-04T15:37:50.923505: step 5858, loss 0.274776, acc 0.890625\n",
      "2018-05-04T15:37:52.148799: step 5859, loss 0.27572, acc 0.890625\n",
      "2018-05-04T15:37:53.312923: step 5860, loss 0.29678, acc 0.84375\n",
      "2018-05-04T15:37:54.502589: step 5861, loss 0.366054, acc 0.859375\n",
      "2018-05-04T15:37:55.671493: step 5862, loss 0.220005, acc 0.90625\n",
      "2018-05-04T15:37:56.864172: step 5863, loss 0.280579, acc 0.90625\n",
      "2018-05-04T15:37:58.050349: step 5864, loss 0.304332, acc 0.875\n",
      "2018-05-04T15:37:59.313725: step 5865, loss 0.211301, acc 0.953125\n",
      "2018-05-04T15:38:00.532511: step 5866, loss 0.395755, acc 0.796875\n",
      "2018-05-04T15:38:01.804253: step 5867, loss 0.25267, acc 0.890625\n",
      "2018-05-04T15:38:03.041837: step 5868, loss 0.295507, acc 0.90625\n",
      "2018-05-04T15:38:04.310135: step 5869, loss 0.285517, acc 0.875\n",
      "2018-05-04T15:38:05.535372: step 5870, loss 0.290377, acc 0.875\n",
      "2018-05-04T15:38:06.832696: step 5871, loss 0.214795, acc 0.9375\n",
      "2018-05-04T15:38:08.176590: step 5872, loss 0.154822, acc 0.953125\n",
      "2018-05-04T15:38:09.395858: step 5873, loss 0.282773, acc 0.875\n",
      "2018-05-04T15:38:10.615834: step 5874, loss 0.316026, acc 0.859375\n",
      "2018-05-04T15:38:11.825237: step 5875, loss 0.308017, acc 0.921875\n",
      "2018-05-04T15:38:13.099958: step 5876, loss 0.275226, acc 0.875\n",
      "2018-05-04T15:38:14.356941: step 5877, loss 0.189941, acc 0.90625\n",
      "2018-05-04T15:38:15.604665: step 5878, loss 0.369436, acc 0.84375\n",
      "2018-05-04T15:38:16.888297: step 5879, loss 0.274034, acc 0.890625\n",
      "2018-05-04T15:38:18.226057: step 5880, loss 0.296335, acc 0.875\n",
      "2018-05-04T15:38:19.624331: step 5881, loss 0.292312, acc 0.890625\n",
      "2018-05-04T15:38:20.932523: step 5882, loss 0.302486, acc 0.890625\n",
      "2018-05-04T15:38:22.366538: step 5883, loss 0.222313, acc 0.921875\n",
      "2018-05-04T15:38:23.884741: step 5884, loss 0.217119, acc 0.875\n",
      "2018-05-04T15:38:25.259832: step 5885, loss 0.312178, acc 0.859375\n",
      "2018-05-04T15:38:26.634519: step 5886, loss 0.295687, acc 0.859375\n",
      "2018-05-04T15:38:28.106063: step 5887, loss 0.318318, acc 0.890625\n",
      "2018-05-04T15:38:29.570002: step 5888, loss 0.233919, acc 0.921875\n",
      "2018-05-04T15:38:31.031919: step 5889, loss 0.227852, acc 0.890625\n",
      "2018-05-04T15:38:32.594140: step 5890, loss 0.330567, acc 0.890625\n",
      "2018-05-04T15:38:34.077739: step 5891, loss 0.236203, acc 0.890625\n",
      "2018-05-04T15:38:35.529562: step 5892, loss 0.166834, acc 0.953125\n",
      "2018-05-04T15:38:37.037271: step 5893, loss 0.190023, acc 0.921875\n",
      "2018-05-04T15:38:38.638032: step 5894, loss 0.156122, acc 0.953125\n",
      "2018-05-04T15:38:40.198956: step 5895, loss 0.371251, acc 0.828125\n",
      "2018-05-04T15:38:41.868895: step 5896, loss 0.322935, acc 0.859375\n",
      "2018-05-04T15:38:43.473236: step 5897, loss 0.269774, acc 0.890625\n",
      "2018-05-04T15:38:45.043698: step 5898, loss 0.268919, acc 0.890625\n",
      "2018-05-04T15:38:46.716183: step 5899, loss 0.283207, acc 0.890625\n",
      "2018-05-04T15:38:48.401707: step 5900, loss 0.320472, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T15:38:52.954184: step 5900, loss 0.290589, acc 0.896\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-5900\n",
      "\n",
      "2018-05-04T15:38:54.949555: step 5901, loss 0.442794, acc 0.8125\n",
      "2018-05-04T15:38:56.776107: step 5902, loss 0.27381, acc 0.890625\n",
      "2018-05-04T15:38:58.665894: step 5903, loss 0.331578, acc 0.90625\n",
      "2018-05-04T15:39:00.659575: step 5904, loss 0.147879, acc 0.96875\n",
      "2018-05-04T15:39:02.818212: step 5905, loss 0.222565, acc 0.90625\n",
      "2018-05-04T15:39:04.978989: step 5906, loss 0.402461, acc 0.84375\n",
      "2018-05-04T15:39:07.009126: step 5907, loss 0.300819, acc 0.890625\n",
      "2018-05-04T15:39:09.036036: step 5908, loss 0.415716, acc 0.84375\n",
      "2018-05-04T15:39:11.157191: step 5909, loss 0.239939, acc 0.90625\n",
      "2018-05-04T15:39:13.270475: step 5910, loss 0.427749, acc 0.8125\n",
      "2018-05-04T15:39:15.522855: step 5911, loss 0.458195, acc 0.828125\n",
      "2018-05-04T15:39:17.864105: step 5912, loss 0.318977, acc 0.859375\n",
      "2018-05-04T15:39:20.227269: step 5913, loss 0.281619, acc 0.90625\n",
      "2018-05-04T15:39:22.543404: step 5914, loss 0.348309, acc 0.84375\n",
      "2018-05-04T15:39:25.264891: step 5915, loss 0.194334, acc 0.921875\n",
      "2018-05-04T15:39:27.748991: step 5916, loss 0.363882, acc 0.890625\n",
      "2018-05-04T15:39:30.082955: step 5917, loss 0.198301, acc 0.921875\n",
      "2018-05-04T15:39:32.506792: step 5918, loss 0.234987, acc 0.921875\n",
      "2018-05-04T15:39:35.203217: step 5919, loss 0.264979, acc 0.9375\n",
      "2018-05-04T15:39:37.746315: step 5920, loss 0.353942, acc 0.828125\n",
      "2018-05-04T15:39:40.597365: step 5921, loss 0.352396, acc 0.84375\n",
      "2018-05-04T15:39:43.635576: step 5922, loss 0.243111, acc 0.921875\n",
      "2018-05-04T15:39:45.853766: step 5923, loss 0.207539, acc 0.9375\n",
      "2018-05-04T15:39:47.615095: step 5924, loss 0.37948, acc 0.859375\n",
      "2018-05-04T15:39:49.284596: step 5925, loss 0.175386, acc 0.953125\n",
      "2018-05-04T15:39:50.804123: step 5926, loss 0.292776, acc 0.84375\n",
      "2018-05-04T15:39:52.277179: step 5927, loss 0.318738, acc 0.890625\n",
      "2018-05-04T15:39:53.676143: step 5928, loss 0.273903, acc 0.90625\n",
      "2018-05-04T15:39:55.061509: step 5929, loss 0.320218, acc 0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T15:39:56.469034: step 5930, loss 0.358565, acc 0.90625\n",
      "2018-05-04T15:39:57.952550: step 5931, loss 0.212612, acc 0.90625\n",
      "2018-05-04T15:39:59.349485: step 5932, loss 0.282268, acc 0.90625\n",
      "2018-05-04T15:40:00.756216: step 5933, loss 0.156151, acc 0.921875\n",
      "2018-05-04T15:40:02.151476: step 5934, loss 0.240329, acc 0.890625\n",
      "2018-05-04T15:40:03.594365: step 5935, loss 0.342455, acc 0.890625\n",
      "2018-05-04T15:40:05.023650: step 5936, loss 0.296061, acc 0.828125\n",
      "2018-05-04T15:40:06.334899: step 5937, loss 0.31605, acc 0.84375\n",
      "2018-05-04T15:40:07.733937: step 5938, loss 0.378255, acc 0.8125\n",
      "2018-05-04T15:40:09.074194: step 5939, loss 0.563056, acc 0.78125\n",
      "2018-05-04T15:40:10.419013: step 5940, loss 0.287541, acc 0.875\n",
      "2018-05-04T15:40:11.754085: step 5941, loss 0.330368, acc 0.859375\n",
      "2018-05-04T15:40:13.168586: step 5942, loss 0.299701, acc 0.875\n",
      "2018-05-04T15:40:14.503406: step 5943, loss 0.333014, acc 0.84375\n",
      "2018-05-04T15:40:15.831270: step 5944, loss 0.365052, acc 0.875\n",
      "2018-05-04T15:40:17.205295: step 5945, loss 0.133548, acc 0.96875\n",
      "2018-05-04T15:40:18.609091: step 5946, loss 0.229031, acc 0.90625\n",
      "2018-05-04T15:40:20.011349: step 5947, loss 0.164478, acc 0.953125\n",
      "2018-05-04T15:40:21.426322: step 5948, loss 0.251901, acc 0.90625\n",
      "2018-05-04T15:40:22.886943: step 5949, loss 0.457859, acc 0.828125\n",
      "2018-05-04T15:40:24.362579: step 5950, loss 0.433897, acc 0.8125\n",
      "2018-05-04T15:40:25.870147: step 5951, loss 0.261318, acc 0.90625\n",
      "2018-05-04T15:40:27.374248: step 5952, loss 0.393468, acc 0.84375\n",
      "2018-05-04T15:40:29.003928: step 5953, loss 0.2915, acc 0.875\n",
      "2018-05-04T15:40:30.540213: step 5954, loss 0.391983, acc 0.875\n",
      "2018-05-04T15:40:32.144655: step 5955, loss 0.248724, acc 0.875\n",
      "2018-05-04T15:40:33.838392: step 5956, loss 0.218696, acc 0.921875\n",
      "2018-05-04T15:40:35.716388: step 5957, loss 0.143118, acc 0.984375\n",
      "2018-05-04T15:40:37.456710: step 5958, loss 0.234298, acc 0.890625\n",
      "2018-05-04T15:40:39.254507: step 5959, loss 0.396595, acc 0.84375\n",
      "2018-05-04T15:40:41.110045: step 5960, loss 0.295922, acc 0.8125\n",
      "2018-05-04T15:40:42.881373: step 5961, loss 0.297721, acc 0.90625\n",
      "2018-05-04T15:40:44.622093: step 5962, loss 0.326569, acc 0.859375\n",
      "2018-05-04T15:40:46.489420: step 5963, loss 0.45613, acc 0.78125\n",
      "2018-05-04T15:40:48.322353: step 5964, loss 0.413935, acc 0.8125\n",
      "2018-05-04T15:40:50.168897: step 5965, loss 0.179358, acc 0.921875\n",
      "2018-05-04T15:40:52.075525: step 5966, loss 0.197545, acc 0.9375\n",
      "2018-05-04T15:40:54.153143: step 5967, loss 0.358152, acc 0.828125\n",
      "2018-05-04T15:40:56.179134: step 5968, loss 0.364231, acc 0.859375\n",
      "2018-05-04T15:40:58.202439: step 5969, loss 0.245168, acc 0.90625\n",
      "2018-05-04T15:41:00.225438: step 5970, loss 0.234126, acc 0.90625\n",
      "2018-05-04T15:41:02.253510: step 5971, loss 0.22097, acc 0.90625\n",
      "2018-05-04T15:41:04.423609: step 5972, loss 0.298559, acc 0.90625\n",
      "2018-05-04T15:41:06.517538: step 5973, loss 0.259017, acc 0.921875\n",
      "2018-05-04T15:41:08.564184: step 5974, loss 0.224605, acc 0.921875\n",
      "2018-05-04T15:41:10.614049: step 5975, loss 0.254834, acc 0.875\n",
      "2018-05-04T15:41:12.687659: step 5976, loss 0.325614, acc 0.890625\n",
      "2018-05-04T15:41:14.761893: step 5977, loss 0.211739, acc 0.921875\n",
      "2018-05-04T15:41:16.791532: step 5978, loss 0.254352, acc 0.90625\n",
      "2018-05-04T15:41:18.769511: step 5979, loss 0.296584, acc 0.890625\n",
      "2018-05-04T15:41:20.613639: step 5980, loss 0.342518, acc 0.875\n",
      "2018-05-04T15:41:22.460005: step 5981, loss 0.327802, acc 0.8125\n",
      "2018-05-04T15:41:24.429621: step 5982, loss 0.294083, acc 0.921875\n",
      "2018-05-04T15:41:26.273071: step 5983, loss 0.337527, acc 0.84375\n",
      "2018-05-04T15:41:28.109106: step 5984, loss 0.26578, acc 0.890625\n",
      "2018-05-04T15:41:29.958428: step 5985, loss 0.341085, acc 0.890625\n",
      "2018-05-04T15:41:31.793864: step 5986, loss 0.31532, acc 0.84375\n",
      "2018-05-04T15:41:33.666924: step 5987, loss 0.417705, acc 0.78125\n",
      "2018-05-04T15:41:35.563000: step 5988, loss 0.375841, acc 0.84375\n",
      "2018-05-04T15:41:37.370307: step 5989, loss 0.282361, acc 0.890625\n",
      "2018-05-04T15:41:39.081850: step 5990, loss 0.14718, acc 0.96875\n",
      "2018-05-04T15:41:40.819992: step 5991, loss 0.525096, acc 0.78125\n",
      "2018-05-04T15:41:42.614202: step 5992, loss 0.239384, acc 0.875\n",
      "2018-05-04T15:41:44.328662: step 5993, loss 0.303592, acc 0.890625\n",
      "2018-05-04T15:41:46.022588: step 5994, loss 0.195763, acc 0.90625\n",
      "2018-05-04T15:41:47.748218: step 5995, loss 0.246336, acc 0.875\n",
      "2018-05-04T15:41:49.554130: step 5996, loss 0.323524, acc 0.84375\n",
      "2018-05-04T15:41:51.295521: step 5997, loss 0.336136, acc 0.859375\n",
      "2018-05-04T15:41:52.875098: step 5998, loss 0.296746, acc 0.890625\n",
      "2018-05-04T15:41:54.328139: step 5999, loss 0.286851, acc 0.90625\n",
      "2018-05-04T15:41:55.751288: step 6000, loss 0.281774, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T15:41:59.261539: step 6000, loss 0.243637, acc 0.916\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-6000\n",
      "\n",
      "2018-05-04T15:42:00.610854: step 6001, loss 0.322841, acc 0.8125\n",
      "2018-05-04T15:42:01.897486: step 6002, loss 0.275299, acc 0.875\n",
      "2018-05-04T15:42:03.167573: step 6003, loss 0.276132, acc 0.84375\n",
      "2018-05-04T15:42:04.397395: step 6004, loss 0.246713, acc 0.859375\n",
      "2018-05-04T15:42:05.530041: step 6005, loss 0.315123, acc 0.875\n",
      "2018-05-04T15:42:06.636030: step 6006, loss 0.241271, acc 0.90625\n",
      "2018-05-04T15:42:07.758288: step 6007, loss 0.346224, acc 0.828125\n",
      "2018-05-04T15:42:08.836938: step 6008, loss 0.335917, acc 0.90625\n",
      "2018-05-04T15:42:09.877255: step 6009, loss 0.333544, acc 0.859375\n",
      "2018-05-04T15:42:10.878257: step 6010, loss 0.245897, acc 0.890625\n",
      "2018-05-04T15:42:11.902597: step 6011, loss 0.20142, acc 0.921875\n",
      "2018-05-04T15:42:12.956865: step 6012, loss 0.422457, acc 0.796875\n",
      "2018-05-04T15:42:13.979936: step 6013, loss 0.390088, acc 0.84375\n",
      "2018-05-04T15:42:15.006963: step 6014, loss 0.287849, acc 0.859375\n",
      "2018-05-04T15:42:16.013784: step 6015, loss 0.262632, acc 0.921875\n",
      "2018-05-04T15:42:17.013030: step 6016, loss 0.315061, acc 0.84375\n",
      "2018-05-04T15:42:18.044249: step 6017, loss 0.299519, acc 0.859375\n",
      "2018-05-04T15:42:19.027202: step 6018, loss 0.173892, acc 0.96875\n",
      "2018-05-04T15:42:20.066283: step 6019, loss 0.365697, acc 0.828125\n",
      "2018-05-04T15:42:21.007208: step 6020, loss 0.223158, acc 0.9375\n",
      "2018-05-04T15:42:21.927358: step 6021, loss 0.215251, acc 0.890625\n",
      "2018-05-04T15:42:23.007004: step 6022, loss 0.24723, acc 0.859375\n",
      "2018-05-04T15:42:23.923084: step 6023, loss 0.261291, acc 0.84375\n",
      "2018-05-04T15:42:24.901086: step 6024, loss 0.241048, acc 0.90625\n",
      "2018-05-04T15:42:25.807968: step 6025, loss 0.225061, acc 0.921875\n",
      "2018-05-04T15:42:26.824413: step 6026, loss 0.378321, acc 0.8125\n",
      "2018-05-04T15:42:27.753029: step 6027, loss 0.266929, acc 0.875\n",
      "2018-05-04T15:42:28.776203: step 6028, loss 0.238345, acc 0.875\n",
      "2018-05-04T15:42:29.712049: step 6029, loss 0.293978, acc 0.875\n",
      "2018-05-04T15:42:30.662559: step 6030, loss 0.310018, acc 0.828125\n",
      "2018-05-04T15:42:31.647321: step 6031, loss 0.252919, acc 0.890625\n",
      "2018-05-04T15:42:32.595170: step 6032, loss 0.253732, acc 0.890625\n",
      "2018-05-04T15:42:33.600717: step 6033, loss 0.210244, acc 0.921875\n",
      "2018-05-04T15:42:34.690470: step 6034, loss 0.29051, acc 0.875\n",
      "2018-05-04T15:42:35.651356: step 6035, loss 0.22237, acc 0.9375\n",
      "2018-05-04T15:42:36.586972: step 6036, loss 0.345438, acc 0.828125\n",
      "2018-05-04T15:42:37.498970: step 6037, loss 0.433911, acc 0.84375\n",
      "2018-05-04T15:42:38.454928: step 6038, loss 0.29047, acc 0.890625\n",
      "2018-05-04T15:42:39.494724: step 6039, loss 0.223128, acc 0.890625\n",
      "2018-05-04T15:42:40.424413: step 6040, loss 0.322473, acc 0.859375\n",
      "2018-05-04T15:42:41.410029: step 6041, loss 0.410636, acc 0.84375\n",
      "2018-05-04T15:42:42.334026: step 6042, loss 0.169655, acc 0.953125\n",
      "2018-05-04T15:42:43.251682: step 6043, loss 0.401187, acc 0.8125\n",
      "2018-05-04T15:42:44.173707: step 6044, loss 0.414907, acc 0.828125\n",
      "2018-05-04T15:42:45.101595: step 6045, loss 0.237511, acc 0.890625\n",
      "2018-05-04T15:42:46.033530: step 6046, loss 0.220925, acc 0.921875\n",
      "2018-05-04T15:42:46.971232: step 6047, loss 0.327718, acc 0.875\n",
      "2018-05-04T15:42:47.899744: step 6048, loss 0.316781, acc 0.796875\n",
      "2018-05-04T15:42:48.814732: step 6049, loss 0.338585, acc 0.84375\n",
      "2018-05-04T15:42:49.761184: step 6050, loss 0.313954, acc 0.921875\n",
      "2018-05-04T15:42:50.688793: step 6051, loss 0.334567, acc 0.859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T15:42:51.612791: step 6052, loss 0.321825, acc 0.890625\n",
      "2018-05-04T15:42:52.648968: step 6053, loss 0.314506, acc 0.828125\n",
      "2018-05-04T15:42:53.587928: step 6054, loss 0.339644, acc 0.84375\n",
      "2018-05-04T15:42:54.505203: step 6055, loss 0.273057, acc 0.90625\n",
      "2018-05-04T15:42:55.421028: step 6056, loss 0.353084, acc 0.84375\n",
      "2018-05-04T15:42:56.335081: step 6057, loss 0.279581, acc 0.859375\n",
      "2018-05-04T15:42:57.258315: step 6058, loss 0.355211, acc 0.890625\n",
      "2018-05-04T15:42:58.179702: step 6059, loss 0.350884, acc 0.890625\n",
      "2018-05-04T15:42:59.100366: step 6060, loss 0.240988, acc 0.890625\n",
      "2018-05-04T15:43:00.035430: step 6061, loss 0.305878, acc 0.890625\n",
      "2018-05-04T15:43:00.972879: step 6062, loss 0.331898, acc 0.890625\n",
      "2018-05-04T15:43:01.905968: step 6063, loss 0.218983, acc 0.921875\n",
      "2018-05-04T15:43:02.947853: step 6064, loss 0.197828, acc 0.921875\n",
      "2018-05-04T15:43:03.938619: step 6065, loss 0.580606, acc 0.75\n",
      "2018-05-04T15:43:04.849341: step 6066, loss 0.367072, acc 0.875\n",
      "2018-05-04T15:43:05.844453: step 6067, loss 0.252872, acc 0.875\n",
      "2018-05-04T15:43:06.769671: step 6068, loss 0.443758, acc 0.828125\n",
      "2018-05-04T15:43:07.700084: step 6069, loss 0.239246, acc 0.890625\n",
      "2018-05-04T15:43:08.631229: step 6070, loss 0.31785, acc 0.859375\n",
      "2018-05-04T15:43:09.576096: step 6071, loss 0.414133, acc 0.828125\n",
      "2018-05-04T15:43:10.511651: step 6072, loss 0.36977, acc 0.796875\n",
      "2018-05-04T15:43:11.458304: step 6073, loss 0.331967, acc 0.890625\n",
      "2018-05-04T15:43:12.442484: step 6074, loss 0.404896, acc 0.78125\n",
      "2018-05-04T15:43:13.363328: step 6075, loss 0.223355, acc 0.921875\n",
      "2018-05-04T15:43:14.296438: step 6076, loss 0.34346, acc 0.890625\n",
      "2018-05-04T15:43:15.316236: step 6077, loss 0.393683, acc 0.828125\n",
      "2018-05-04T15:43:16.230910: step 6078, loss 0.293336, acc 0.875\n",
      "2018-05-04T15:43:17.173009: step 6079, loss 0.331398, acc 0.875\n",
      "2018-05-04T15:43:18.112306: step 6080, loss 0.39481, acc 0.859375\n",
      "2018-05-04T15:43:19.034794: step 6081, loss 0.296066, acc 0.84375\n",
      "2018-05-04T15:43:19.945885: step 6082, loss 0.457453, acc 0.828125\n",
      "2018-05-04T15:43:20.867872: step 6083, loss 0.282347, acc 0.890625\n",
      "2018-05-04T15:43:21.798222: step 6084, loss 0.203284, acc 0.921875\n",
      "2018-05-04T15:43:22.742132: step 6085, loss 0.306419, acc 0.890625\n",
      "2018-05-04T15:43:23.692468: step 6086, loss 0.263703, acc 0.875\n",
      "2018-05-04T15:43:24.634859: step 6087, loss 0.324642, acc 0.890625\n",
      "2018-05-04T15:43:25.602154: step 6088, loss 0.316507, acc 0.890625\n",
      "2018-05-04T15:43:26.530838: step 6089, loss 0.255702, acc 0.9375\n",
      "2018-05-04T15:43:27.449655: step 6090, loss 0.324319, acc 0.828125\n",
      "2018-05-04T15:43:28.365383: step 6091, loss 0.280979, acc 0.90625\n",
      "2018-05-04T15:43:29.297247: step 6092, loss 0.263461, acc 0.90625\n",
      "2018-05-04T15:43:30.238926: step 6093, loss 0.214997, acc 0.921875\n",
      "2018-05-04T15:43:31.163198: step 6094, loss 0.314741, acc 0.90625\n",
      "2018-05-04T15:43:32.098923: step 6095, loss 0.384921, acc 0.84375\n",
      "2018-05-04T15:43:33.077757: step 6096, loss 0.200641, acc 0.9375\n",
      "2018-05-04T15:43:34.122446: step 6097, loss 0.345467, acc 0.84375\n",
      "2018-05-04T15:43:35.098987: step 6098, loss 0.272678, acc 0.828125\n",
      "2018-05-04T15:43:36.092921: step 6099, loss 0.269327, acc 0.875\n",
      "2018-05-04T15:43:37.089724: step 6100, loss 0.381031, acc 0.8125\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T15:43:39.177601: step 6100, loss 0.252861, acc 0.908\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-6100\n",
      "\n",
      "2018-05-04T15:43:40.206707: step 6101, loss 0.375893, acc 0.875\n",
      "2018-05-04T15:43:41.137062: step 6102, loss 0.263815, acc 0.859375\n",
      "2018-05-04T15:43:42.130067: step 6103, loss 0.309289, acc 0.875\n",
      "2018-05-04T15:43:43.062985: step 6104, loss 0.278957, acc 0.90625\n",
      "2018-05-04T15:43:44.060641: step 6105, loss 0.404407, acc 0.78125\n",
      "2018-05-04T15:43:45.011815: step 6106, loss 0.322684, acc 0.84375\n",
      "2018-05-04T15:43:45.955825: step 6107, loss 0.277229, acc 0.875\n",
      "2018-05-04T15:43:46.896156: step 6108, loss 0.3167, acc 0.890625\n",
      "2018-05-04T15:43:47.908588: step 6109, loss 0.268703, acc 0.90625\n",
      "2018-05-04T15:43:48.842578: step 6110, loss 0.317055, acc 0.84375\n",
      "2018-05-04T15:43:49.762592: step 6111, loss 0.221037, acc 0.9375\n",
      "2018-05-04T15:43:50.689374: step 6112, loss 0.379034, acc 0.859375\n",
      "2018-05-04T15:43:51.644629: step 6113, loss 0.246908, acc 0.921875\n",
      "2018-05-04T15:43:52.582340: step 6114, loss 0.336271, acc 0.859375\n",
      "2018-05-04T15:43:53.505749: step 6115, loss 0.279993, acc 0.859375\n",
      "2018-05-04T15:43:54.506729: step 6116, loss 0.22974, acc 0.921875\n",
      "2018-05-04T15:43:55.433491: step 6117, loss 0.234258, acc 0.921875\n",
      "2018-05-04T15:43:56.384635: step 6118, loss 0.228762, acc 0.90625\n",
      "2018-05-04T15:43:57.336699: step 6119, loss 0.373137, acc 0.859375\n",
      "2018-05-04T15:43:58.352124: step 6120, loss 0.318385, acc 0.828125\n",
      "2018-05-04T15:43:59.393439: step 6121, loss 0.200098, acc 0.9375\n",
      "2018-05-04T15:44:00.338523: step 6122, loss 0.405232, acc 0.890625\n",
      "2018-05-04T15:44:01.406743: step 6123, loss 0.196045, acc 0.9375\n",
      "2018-05-04T15:44:02.434660: step 6124, loss 0.401, acc 0.828125\n",
      "2018-05-04T15:44:03.349650: step 6125, loss 0.294659, acc 0.953125\n",
      "2018-05-04T15:44:04.335674: step 6126, loss 0.380958, acc 0.8125\n",
      "2018-05-04T15:44:05.260731: step 6127, loss 0.389325, acc 0.859375\n",
      "2018-05-04T15:44:06.200881: step 6128, loss 0.27194, acc 0.84375\n",
      "2018-05-04T15:44:07.167152: step 6129, loss 0.289236, acc 0.9375\n",
      "2018-05-04T15:44:08.122054: step 6130, loss 0.348181, acc 0.859375\n",
      "2018-05-04T15:44:09.066168: step 6131, loss 0.246621, acc 0.890625\n",
      "2018-05-04T15:44:10.019762: step 6132, loss 0.388951, acc 0.84375\n",
      "2018-05-04T15:44:10.994012: step 6133, loss 0.206634, acc 0.921875\n",
      "2018-05-04T15:44:12.021664: step 6134, loss 0.3122, acc 0.875\n",
      "2018-05-04T15:44:12.974662: step 6135, loss 0.232814, acc 0.90625\n",
      "2018-05-04T15:44:13.960013: step 6136, loss 0.193558, acc 0.90625\n",
      "2018-05-04T15:44:14.950169: step 6137, loss 0.198061, acc 0.921875\n",
      "2018-05-04T15:44:15.944108: step 6138, loss 0.311483, acc 0.859375\n",
      "2018-05-04T15:44:16.940532: step 6139, loss 0.144485, acc 0.953125\n",
      "2018-05-04T15:44:17.916101: step 6140, loss 0.273749, acc 0.875\n",
      "2018-05-04T15:44:18.873040: step 6141, loss 0.213735, acc 0.9375\n",
      "2018-05-04T15:44:19.887019: step 6142, loss 0.295264, acc 0.84375\n",
      "2018-05-04T15:44:20.921722: step 6143, loss 0.167936, acc 0.9375\n",
      "2018-05-04T15:44:21.868994: step 6144, loss 0.276358, acc 0.90625\n",
      "2018-05-04T15:44:22.987860: step 6145, loss 0.383648, acc 0.8125\n",
      "2018-05-04T15:44:24.026244: step 6146, loss 0.367848, acc 0.875\n",
      "2018-05-04T15:44:25.003654: step 6147, loss 0.24993, acc 0.90625\n",
      "2018-05-04T15:44:26.064052: step 6148, loss 0.214811, acc 0.921875\n",
      "2018-05-04T15:44:27.111321: step 6149, loss 0.234107, acc 0.875\n",
      "2018-05-04T15:44:28.160673: step 6150, loss 0.245062, acc 0.890625\n",
      "2018-05-04T15:44:29.183444: step 6151, loss 0.346343, acc 0.84375\n",
      "2018-05-04T15:44:30.150416: step 6152, loss 0.267844, acc 0.890625\n",
      "2018-05-04T15:44:31.211453: step 6153, loss 0.232872, acc 0.890625\n",
      "2018-05-04T15:44:32.197094: step 6154, loss 0.312529, acc 0.84375\n",
      "2018-05-04T15:44:33.225637: step 6155, loss 0.223644, acc 0.9375\n",
      "2018-05-04T15:44:34.262623: step 6156, loss 0.256113, acc 0.875\n",
      "2018-05-04T15:44:35.310588: step 6157, loss 0.366836, acc 0.8125\n",
      "2018-05-04T15:44:36.380670: step 6158, loss 0.276088, acc 0.921875\n",
      "2018-05-04T15:44:37.395298: step 6159, loss 0.514485, acc 0.75\n",
      "2018-05-04T15:44:38.485000: step 6160, loss 0.336513, acc 0.890625\n",
      "2018-05-04T15:44:39.537813: step 6161, loss 0.215948, acc 0.890625\n",
      "2018-05-04T15:44:40.611201: step 6162, loss 0.166862, acc 0.9375\n",
      "2018-05-04T15:44:41.669944: step 6163, loss 0.324705, acc 0.84375\n",
      "2018-05-04T15:44:42.774702: step 6164, loss 0.278052, acc 0.890625\n",
      "2018-05-04T15:44:43.874967: step 6165, loss 0.272423, acc 0.875\n",
      "2018-05-04T15:44:44.937294: step 6166, loss 0.190053, acc 0.9375\n",
      "2018-05-04T15:44:45.994967: step 6167, loss 0.260693, acc 0.90625\n",
      "2018-05-04T15:44:46.983506: step 6168, loss 0.489365, acc 0.75\n",
      "2018-05-04T15:44:48.025107: step 6169, loss 0.313238, acc 0.875\n",
      "2018-05-04T15:44:49.039636: step 6170, loss 0.300779, acc 0.84375\n",
      "2018-05-04T15:44:50.130602: step 6171, loss 0.320935, acc 0.828125\n",
      "2018-05-04T15:44:51.227600: step 6172, loss 0.386402, acc 0.828125\n",
      "2018-05-04T15:44:52.253947: step 6173, loss 0.286846, acc 0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T15:44:53.318215: step 6174, loss 0.28858, acc 0.90625\n",
      "2018-05-04T15:44:54.406586: step 6175, loss 0.336568, acc 0.90625\n",
      "2018-05-04T15:44:55.500152: step 6176, loss 0.480623, acc 0.765625\n",
      "2018-05-04T15:44:56.594865: step 6177, loss 0.284265, acc 0.890625\n",
      "2018-05-04T15:44:57.660075: step 6178, loss 0.319329, acc 0.875\n",
      "2018-05-04T15:44:58.674766: step 6179, loss 0.473146, acc 0.828125\n",
      "2018-05-04T15:44:59.745589: step 6180, loss 0.182525, acc 0.921875\n",
      "2018-05-04T15:45:00.816487: step 6181, loss 0.307041, acc 0.828125\n",
      "2018-05-04T15:45:01.879610: step 6182, loss 0.252449, acc 0.90625\n",
      "2018-05-04T15:45:02.965573: step 6183, loss 0.268258, acc 0.890625\n",
      "2018-05-04T15:45:04.087969: step 6184, loss 0.273743, acc 0.84375\n",
      "2018-05-04T15:45:05.149767: step 6185, loss 0.240765, acc 0.859375\n",
      "2018-05-04T15:45:06.243683: step 6186, loss 0.150278, acc 0.953125\n",
      "2018-05-04T15:45:07.319175: step 6187, loss 0.276364, acc 0.890625\n",
      "2018-05-04T15:45:08.404015: step 6188, loss 0.287148, acc 0.84375\n",
      "2018-05-04T15:45:09.478286: step 6189, loss 0.192918, acc 0.90625\n",
      "2018-05-04T15:45:10.557176: step 6190, loss 0.170772, acc 0.9375\n",
      "2018-05-04T15:45:11.628348: step 6191, loss 0.221381, acc 0.921875\n",
      "2018-05-04T15:45:12.703503: step 6192, loss 0.335822, acc 0.828125\n",
      "2018-05-04T15:45:13.813858: step 6193, loss 0.268786, acc 0.875\n",
      "2018-05-04T15:45:14.901071: step 6194, loss 0.360086, acc 0.875\n",
      "2018-05-04T15:45:15.997443: step 6195, loss 0.249582, acc 0.859375\n",
      "2018-05-04T15:45:17.104050: step 6196, loss 0.161165, acc 0.953125\n",
      "2018-05-04T15:45:18.191090: step 6197, loss 0.411032, acc 0.828125\n",
      "2018-05-04T15:45:19.295063: step 6198, loss 0.342587, acc 0.84375\n",
      "2018-05-04T15:45:20.378580: step 6199, loss 0.378114, acc 0.796875\n",
      "2018-05-04T15:45:21.499232: step 6200, loss 0.227895, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T15:45:24.230607: step 6200, loss 0.257732, acc 0.91\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-6200\n",
      "\n",
      "2018-05-04T15:45:25.405797: step 6201, loss 0.259438, acc 0.921875\n",
      "2018-05-04T15:45:26.511790: step 6202, loss 0.285309, acc 0.90625\n",
      "2018-05-04T15:45:27.624487: step 6203, loss 0.2583, acc 0.890625\n",
      "2018-05-04T15:45:28.741646: step 6204, loss 0.312959, acc 0.90625\n",
      "2018-05-04T15:45:29.851303: step 6205, loss 0.156122, acc 0.953125\n",
      "2018-05-04T15:45:30.981119: step 6206, loss 0.455743, acc 0.765625\n",
      "2018-05-04T15:45:32.078419: step 6207, loss 0.212488, acc 0.9375\n",
      "2018-05-04T15:45:33.154895: step 6208, loss 0.178964, acc 0.921875\n",
      "2018-05-04T15:45:34.245318: step 6209, loss 0.264083, acc 0.875\n",
      "2018-05-04T15:45:35.322846: step 6210, loss 0.356386, acc 0.875\n",
      "2018-05-04T15:45:36.442930: step 6211, loss 0.500141, acc 0.8125\n",
      "2018-05-04T15:45:37.530894: step 6212, loss 0.185372, acc 0.90625\n",
      "2018-05-04T15:45:38.600983: step 6213, loss 0.32355, acc 0.890625\n",
      "2018-05-04T15:45:39.679946: step 6214, loss 0.384568, acc 0.90625\n",
      "2018-05-04T15:45:40.749359: step 6215, loss 0.362327, acc 0.859375\n",
      "2018-05-04T15:45:41.803544: step 6216, loss 0.261022, acc 0.875\n",
      "2018-05-04T15:45:42.842950: step 6217, loss 0.290755, acc 0.875\n",
      "2018-05-04T15:45:43.894180: step 6218, loss 0.248688, acc 0.890625\n",
      "2018-05-04T15:45:45.028128: step 6219, loss 0.337125, acc 0.859375\n",
      "2018-05-04T15:45:46.188965: step 6220, loss 0.198154, acc 0.921875\n",
      "2018-05-04T15:45:47.244383: step 6221, loss 0.224129, acc 0.921875\n",
      "2018-05-04T15:45:48.275097: step 6222, loss 0.261715, acc 0.90625\n",
      "2018-05-04T15:45:49.363488: step 6223, loss 0.234906, acc 0.90625\n",
      "2018-05-04T15:45:50.409888: step 6224, loss 0.282679, acc 0.859375\n",
      "2018-05-04T15:45:51.551838: step 6225, loss 0.200323, acc 0.9375\n",
      "2018-05-04T15:45:52.683592: step 6226, loss 0.384448, acc 0.84375\n",
      "2018-05-04T15:45:53.723350: step 6227, loss 0.337937, acc 0.8125\n",
      "2018-05-04T15:45:54.760836: step 6228, loss 0.309783, acc 0.859375\n",
      "2018-05-04T15:45:55.912986: step 6229, loss 0.340989, acc 0.9375\n",
      "2018-05-04T15:45:56.975599: step 6230, loss 0.426853, acc 0.8125\n",
      "2018-05-04T15:45:58.102029: step 6231, loss 0.270141, acc 0.890625\n",
      "2018-05-04T15:45:59.127927: step 6232, loss 0.294615, acc 0.859375\n",
      "2018-05-04T15:46:00.153518: step 6233, loss 0.309344, acc 0.875\n",
      "2018-05-04T15:46:01.236702: step 6234, loss 0.312413, acc 0.859375\n",
      "2018-05-04T15:46:02.256543: step 6235, loss 0.255871, acc 0.921875\n",
      "2018-05-04T15:46:03.333224: step 6236, loss 0.310128, acc 0.875\n",
      "2018-05-04T15:46:04.392015: step 6237, loss 0.260407, acc 0.875\n",
      "2018-05-04T15:46:05.458714: step 6238, loss 0.283953, acc 0.84375\n",
      "2018-05-04T15:46:06.517626: step 6239, loss 0.350341, acc 0.875\n",
      "2018-05-04T15:46:07.577909: step 6240, loss 0.334225, acc 0.859375\n",
      "2018-05-04T15:46:08.635851: step 6241, loss 0.26423, acc 0.875\n",
      "2018-05-04T15:46:09.689132: step 6242, loss 0.332557, acc 0.8125\n",
      "2018-05-04T15:46:10.744638: step 6243, loss 0.255007, acc 0.890625\n",
      "2018-05-04T15:46:11.766552: step 6244, loss 0.431162, acc 0.8125\n",
      "2018-05-04T15:46:12.823948: step 6245, loss 0.289081, acc 0.84375\n",
      "2018-05-04T15:46:13.948724: step 6246, loss 0.315366, acc 0.859375\n",
      "2018-05-04T15:46:15.020371: step 6247, loss 0.337594, acc 0.84375\n",
      "2018-05-04T15:46:16.070617: step 6248, loss 0.412107, acc 0.84375\n",
      "2018-05-04T15:46:17.149823: step 6249, loss 0.249845, acc 0.90625\n",
      "2018-05-04T15:46:18.233029: step 6250, loss 0.315538, acc 0.875\n",
      "2018-05-04T15:46:19.279107: step 6251, loss 0.253768, acc 0.921875\n",
      "2018-05-04T15:46:20.285221: step 6252, loss 0.312851, acc 0.859375\n",
      "2018-05-04T15:46:21.375413: step 6253, loss 0.267574, acc 0.828125\n",
      "2018-05-04T15:46:22.405153: step 6254, loss 0.428462, acc 0.78125\n",
      "2018-05-04T15:46:23.472506: step 6255, loss 0.334903, acc 0.84375\n",
      "2018-05-04T15:46:24.540802: step 6256, loss 0.296707, acc 0.828125\n",
      "2018-05-04T15:46:25.627439: step 6257, loss 0.227477, acc 0.9375\n",
      "2018-05-04T15:46:26.736668: step 6258, loss 0.371055, acc 0.78125\n",
      "2018-05-04T15:46:27.832488: step 6259, loss 0.281426, acc 0.875\n",
      "2018-05-04T15:46:28.871495: step 6260, loss 0.227299, acc 0.921875\n",
      "2018-05-04T15:46:29.970013: step 6261, loss 0.29433, acc 0.90625\n",
      "2018-05-04T15:46:31.011305: step 6262, loss 0.219433, acc 0.953125\n",
      "2018-05-04T15:46:32.066624: step 6263, loss 0.334065, acc 0.84375\n",
      "2018-05-04T15:46:33.152901: step 6264, loss 0.277724, acc 0.875\n",
      "2018-05-04T15:46:34.266633: step 6265, loss 0.298906, acc 0.875\n",
      "2018-05-04T15:46:35.433666: step 6266, loss 0.266753, acc 0.875\n",
      "2018-05-04T15:46:36.564821: step 6267, loss 0.292515, acc 0.921875\n",
      "2018-05-04T15:46:37.687405: step 6268, loss 0.360292, acc 0.859375\n",
      "2018-05-04T15:46:38.741404: step 6269, loss 0.232007, acc 0.890625\n",
      "2018-05-04T15:46:39.796873: step 6270, loss 0.256144, acc 0.921875\n",
      "2018-05-04T15:46:40.864145: step 6271, loss 0.342502, acc 0.84375\n",
      "2018-05-04T15:46:41.958743: step 6272, loss 0.306151, acc 0.875\n",
      "2018-05-04T15:46:42.992864: step 6273, loss 0.256245, acc 0.921875\n",
      "2018-05-04T15:46:43.996539: step 6274, loss 0.226373, acc 0.9375\n",
      "2018-05-04T15:46:45.023112: step 6275, loss 0.292809, acc 0.875\n",
      "2018-05-04T15:46:46.073183: step 6276, loss 0.285148, acc 0.859375\n",
      "2018-05-04T15:46:47.096163: step 6277, loss 0.303858, acc 0.828125\n",
      "2018-05-04T15:46:48.134758: step 6278, loss 0.317075, acc 0.9375\n",
      "2018-05-04T15:46:49.165824: step 6279, loss 0.247347, acc 0.859375\n",
      "2018-05-04T15:46:50.198869: step 6280, loss 0.412776, acc 0.796875\n",
      "2018-05-04T15:46:51.217586: step 6281, loss 0.34152, acc 0.875\n",
      "2018-05-04T15:46:52.238030: step 6282, loss 0.317275, acc 0.859375\n",
      "2018-05-04T15:46:53.255553: step 6283, loss 0.208061, acc 0.921875\n",
      "2018-05-04T15:46:54.307456: step 6284, loss 0.297336, acc 0.890625\n",
      "2018-05-04T15:46:55.366422: step 6285, loss 0.371846, acc 0.859375\n",
      "2018-05-04T15:46:56.381376: step 6286, loss 0.252082, acc 0.890625\n",
      "2018-05-04T15:46:57.426489: step 6287, loss 0.141356, acc 0.984375\n",
      "2018-05-04T15:46:58.477524: step 6288, loss 0.26582, acc 0.84375\n",
      "2018-05-04T15:46:59.534898: step 6289, loss 0.384029, acc 0.828125\n",
      "2018-05-04T15:47:00.638425: step 6290, loss 0.340879, acc 0.78125\n",
      "2018-05-04T15:47:01.651605: step 6291, loss 0.320593, acc 0.859375\n",
      "2018-05-04T15:47:02.678834: step 6292, loss 0.351049, acc 0.859375\n",
      "2018-05-04T15:47:03.752782: step 6293, loss 0.282604, acc 0.90625\n",
      "2018-05-04T15:47:04.762693: step 6294, loss 0.274078, acc 0.890625\n",
      "2018-05-04T15:47:05.782088: step 6295, loss 0.371697, acc 0.84375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T15:47:06.795156: step 6296, loss 0.305613, acc 0.890625\n",
      "2018-05-04T15:47:07.851369: step 6297, loss 0.202174, acc 0.9375\n",
      "2018-05-04T15:47:08.877652: step 6298, loss 0.208868, acc 0.90625\n",
      "2018-05-04T15:47:09.890287: step 6299, loss 0.298636, acc 0.875\n",
      "2018-05-04T15:47:10.910086: step 6300, loss 0.358257, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T15:47:13.140137: step 6300, loss 0.265267, acc 0.904\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-6300\n",
      "\n",
      "2018-05-04T15:47:14.232840: step 6301, loss 0.319198, acc 0.859375\n",
      "2018-05-04T15:47:15.369262: step 6302, loss 0.254071, acc 0.90625\n",
      "2018-05-04T15:47:16.382899: step 6303, loss 0.372145, acc 0.8125\n",
      "2018-05-04T15:47:17.528135: step 6304, loss 0.302309, acc 0.875\n",
      "2018-05-04T15:47:18.569023: step 6305, loss 0.248616, acc 0.90625\n",
      "2018-05-04T15:47:19.579577: step 6306, loss 0.2598, acc 0.84375\n",
      "2018-05-04T15:47:20.585933: step 6307, loss 0.22289, acc 0.921875\n",
      "2018-05-04T15:47:21.730112: step 6308, loss 0.25466, acc 0.921875\n",
      "2018-05-04T15:47:22.750395: step 6309, loss 0.508734, acc 0.796875\n",
      "2018-05-04T15:47:23.768740: step 6310, loss 0.241358, acc 0.890625\n",
      "2018-05-04T15:47:24.793605: step 6311, loss 0.266304, acc 0.921875\n",
      "2018-05-04T15:47:25.824158: step 6312, loss 0.272027, acc 0.890625\n",
      "2018-05-04T15:47:26.839434: step 6313, loss 0.257739, acc 0.875\n",
      "2018-05-04T15:47:27.861256: step 6314, loss 0.286815, acc 0.890625\n",
      "2018-05-04T15:47:28.868818: step 6315, loss 0.342559, acc 0.875\n",
      "2018-05-04T15:47:29.887481: step 6316, loss 0.34846, acc 0.90625\n",
      "2018-05-04T15:47:30.906307: step 6317, loss 0.360964, acc 0.859375\n",
      "2018-05-04T15:47:31.914131: step 6318, loss 0.248347, acc 0.921875\n",
      "2018-05-04T15:47:32.931359: step 6319, loss 0.444879, acc 0.8125\n",
      "2018-05-04T15:47:33.964884: step 6320, loss 0.262679, acc 0.890625\n",
      "2018-05-04T15:47:34.995327: step 6321, loss 0.3537, acc 0.859375\n",
      "2018-05-04T15:47:36.003922: step 6322, loss 0.242001, acc 0.875\n",
      "2018-05-04T15:47:37.021631: step 6323, loss 0.333699, acc 0.875\n",
      "2018-05-04T15:47:38.034211: step 6324, loss 0.276654, acc 0.875\n",
      "2018-05-04T15:47:39.055375: step 6325, loss 0.301802, acc 0.875\n",
      "2018-05-04T15:47:40.122022: step 6326, loss 0.312588, acc 0.875\n",
      "2018-05-04T15:47:41.123313: step 6327, loss 0.237019, acc 0.90625\n",
      "2018-05-04T15:47:42.195960: step 6328, loss 0.382928, acc 0.8125\n",
      "2018-05-04T15:47:43.293569: step 6329, loss 0.214682, acc 0.9375\n",
      "2018-05-04T15:47:44.280872: step 6330, loss 0.371455, acc 0.8125\n",
      "2018-05-04T15:47:45.269861: step 6331, loss 0.329528, acc 0.875\n",
      "2018-05-04T15:47:46.326105: step 6332, loss 0.382127, acc 0.8125\n",
      "2018-05-04T15:47:47.325384: step 6333, loss 0.274292, acc 0.890625\n",
      "2018-05-04T15:47:48.352146: step 6334, loss 0.37038, acc 0.828125\n",
      "2018-05-04T15:47:49.359000: step 6335, loss 0.245117, acc 0.890625\n",
      "2018-05-04T15:47:50.373313: step 6336, loss 0.260893, acc 0.90625\n",
      "2018-05-04T15:47:51.390089: step 6337, loss 0.261058, acc 0.90625\n",
      "2018-05-04T15:47:52.483884: step 6338, loss 0.290377, acc 0.875\n",
      "2018-05-04T15:47:53.469132: step 6339, loss 0.27827, acc 0.84375\n",
      "2018-05-04T15:47:54.455544: step 6340, loss 0.278095, acc 0.875\n",
      "2018-05-04T15:47:55.444327: step 6341, loss 0.274661, acc 0.859375\n",
      "2018-05-04T15:47:56.430039: step 6342, loss 0.280234, acc 0.875\n",
      "2018-05-04T15:47:57.420579: step 6343, loss 0.42475, acc 0.859375\n",
      "2018-05-04T15:47:58.440046: step 6344, loss 0.362279, acc 0.875\n",
      "2018-05-04T15:47:59.491403: step 6345, loss 0.319167, acc 0.890625\n",
      "2018-05-04T15:48:00.542474: step 6346, loss 0.340916, acc 0.875\n",
      "2018-05-04T15:48:01.589070: step 6347, loss 0.371835, acc 0.84375\n",
      "2018-05-04T15:48:02.652571: step 6348, loss 0.397529, acc 0.875\n",
      "2018-05-04T15:48:03.678126: step 6349, loss 0.399272, acc 0.859375\n",
      "2018-05-04T15:48:04.755092: step 6350, loss 0.206984, acc 0.90625\n",
      "2018-05-04T15:48:05.826878: step 6351, loss 0.281929, acc 0.921875\n",
      "2018-05-04T15:48:06.860478: step 6352, loss 0.152626, acc 0.953125\n",
      "2018-05-04T15:48:07.892280: step 6353, loss 0.260099, acc 0.875\n",
      "2018-05-04T15:48:08.854648: step 6354, loss 0.325814, acc 0.828125\n",
      "2018-05-04T15:48:09.818558: step 6355, loss 0.302065, acc 0.875\n",
      "2018-05-04T15:48:10.799444: step 6356, loss 0.313355, acc 0.84375\n",
      "2018-05-04T15:48:11.812369: step 6357, loss 0.378715, acc 0.8125\n",
      "2018-05-04T15:48:12.790902: step 6358, loss 0.396957, acc 0.859375\n",
      "2018-05-04T15:48:13.813102: step 6359, loss 0.320823, acc 0.90625\n",
      "2018-05-04T15:48:14.864118: step 6360, loss 0.225916, acc 0.890625\n",
      "2018-05-04T15:48:15.912250: step 6361, loss 0.30013, acc 0.890625\n",
      "2018-05-04T15:48:16.977502: step 6362, loss 0.1792, acc 0.9375\n",
      "2018-05-04T15:48:18.010934: step 6363, loss 0.230177, acc 0.890625\n",
      "2018-05-04T15:48:19.069580: step 6364, loss 0.363881, acc 0.828125\n",
      "2018-05-04T15:48:20.044984: step 6365, loss 0.181413, acc 0.9375\n",
      "2018-05-04T15:48:21.080284: step 6366, loss 0.247073, acc 0.890625\n",
      "2018-05-04T15:48:22.037920: step 6367, loss 0.266124, acc 0.890625\n",
      "2018-05-04T15:48:23.015336: step 6368, loss 0.268146, acc 0.90625\n",
      "2018-05-04T15:48:24.024252: step 6369, loss 0.251786, acc 0.921875\n",
      "2018-05-04T15:48:25.109501: step 6370, loss 0.279822, acc 0.90625\n",
      "2018-05-04T15:48:26.195354: step 6371, loss 0.16504, acc 0.921875\n",
      "2018-05-04T15:48:27.163009: step 6372, loss 0.276736, acc 0.921875\n",
      "2018-05-04T15:48:28.217125: step 6373, loss 0.326673, acc 0.875\n",
      "2018-05-04T15:48:29.257733: step 6374, loss 0.37263, acc 0.84375\n",
      "2018-05-04T15:48:30.301207: step 6375, loss 0.303896, acc 0.875\n",
      "2018-05-04T15:48:31.362432: step 6376, loss 0.257512, acc 0.859375\n",
      "2018-05-04T15:48:32.407138: step 6377, loss 0.288469, acc 0.921875\n",
      "2018-05-04T15:48:33.434325: step 6378, loss 0.310641, acc 0.890625\n",
      "2018-05-04T15:48:34.468107: step 6379, loss 0.396589, acc 0.84375\n",
      "2018-05-04T15:48:35.453447: step 6380, loss 0.382747, acc 0.796875\n",
      "2018-05-04T15:48:36.465775: step 6381, loss 0.254318, acc 0.921875\n",
      "2018-05-04T15:48:37.501711: step 6382, loss 0.29445, acc 0.921875\n",
      "2018-05-04T15:48:38.522574: step 6383, loss 0.330499, acc 0.84375\n",
      "2018-05-04T15:48:39.472277: step 6384, loss 0.165456, acc 0.9375\n",
      "2018-05-04T15:48:40.531486: step 6385, loss 0.215025, acc 0.9375\n",
      "2018-05-04T15:48:41.573541: step 6386, loss 0.279159, acc 0.875\n",
      "2018-05-04T15:48:42.590643: step 6387, loss 0.227545, acc 0.953125\n",
      "2018-05-04T15:48:43.641096: step 6388, loss 0.194468, acc 0.921875\n",
      "2018-05-04T15:48:44.660713: step 6389, loss 0.257767, acc 0.859375\n",
      "2018-05-04T15:48:45.700952: step 6390, loss 0.305097, acc 0.890625\n",
      "2018-05-04T15:48:46.726934: step 6391, loss 0.328789, acc 0.890625\n",
      "2018-05-04T15:48:47.744120: step 6392, loss 0.300667, acc 0.890625\n",
      "2018-05-04T15:48:48.732494: step 6393, loss 0.347314, acc 0.828125\n",
      "2018-05-04T15:48:49.750588: step 6394, loss 0.328693, acc 0.875\n",
      "2018-05-04T15:48:50.815605: step 6395, loss 0.297952, acc 0.875\n",
      "2018-05-04T15:48:51.915064: step 6396, loss 0.289484, acc 0.875\n",
      "2018-05-04T15:48:52.968243: step 6397, loss 0.298253, acc 0.890625\n",
      "2018-05-04T15:48:53.928408: step 6398, loss 0.288036, acc 0.890625\n",
      "2018-05-04T15:48:54.949435: step 6399, loss 0.225859, acc 0.890625\n",
      "2018-05-04T15:48:55.962124: step 6400, loss 0.158055, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T15:48:58.627076: step 6400, loss 0.243004, acc 0.91\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-6400\n",
      "\n",
      "2018-05-04T15:48:59.737800: step 6401, loss 0.303712, acc 0.84375\n",
      "2018-05-04T15:49:00.853438: step 6402, loss 0.307694, acc 0.890625\n",
      "2018-05-04T15:49:01.894350: step 6403, loss 0.191694, acc 0.953125\n",
      "2018-05-04T15:49:03.015555: step 6404, loss 0.300624, acc 0.921875\n",
      "2018-05-04T15:49:04.101828: step 6405, loss 0.503217, acc 0.796875\n",
      "2018-05-04T15:49:05.137202: step 6406, loss 0.248499, acc 0.921875\n",
      "2018-05-04T15:49:06.187293: step 6407, loss 0.271682, acc 0.890625\n",
      "2018-05-04T15:49:07.296536: step 6408, loss 0.236529, acc 0.890625\n",
      "2018-05-04T15:49:08.323394: step 6409, loss 0.16315, acc 0.953125\n",
      "2018-05-04T15:49:09.352971: step 6410, loss 0.302583, acc 0.875\n",
      "2018-05-04T15:49:10.399496: step 6411, loss 0.313338, acc 0.84375\n",
      "2018-05-04T15:49:11.394801: step 6412, loss 0.2987, acc 0.84375\n",
      "2018-05-04T15:49:12.407963: step 6413, loss 0.358009, acc 0.84375\n",
      "2018-05-04T15:49:13.500635: step 6414, loss 0.400333, acc 0.828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T15:49:14.595983: step 6415, loss 0.366996, acc 0.84375\n",
      "2018-05-04T15:49:15.614188: step 6416, loss 0.294512, acc 0.859375\n",
      "2018-05-04T15:49:16.628241: step 6417, loss 0.219733, acc 0.890625\n",
      "2018-05-04T15:49:17.649874: step 6418, loss 0.199836, acc 0.921875\n",
      "2018-05-04T15:49:18.637635: step 6419, loss 0.422318, acc 0.828125\n",
      "2018-05-04T15:49:19.647060: step 6420, loss 0.378784, acc 0.84375\n",
      "2018-05-04T15:49:20.754959: step 6421, loss 0.188962, acc 0.90625\n",
      "2018-05-04T15:49:21.759311: step 6422, loss 0.27697, acc 0.890625\n",
      "2018-05-04T15:49:22.767223: step 6423, loss 0.330996, acc 0.8125\n",
      "2018-05-04T15:49:23.742040: step 6424, loss 0.408009, acc 0.875\n",
      "2018-05-04T15:49:24.734878: step 6425, loss 0.283986, acc 0.890625\n",
      "2018-05-04T15:49:25.751273: step 6426, loss 0.316114, acc 0.890625\n",
      "2018-05-04T15:49:26.752158: step 6427, loss 0.180867, acc 0.9375\n",
      "2018-05-04T15:49:27.791216: step 6428, loss 0.424101, acc 0.828125\n",
      "2018-05-04T15:49:28.802440: step 6429, loss 0.291477, acc 0.84375\n",
      "2018-05-04T15:49:29.844948: step 6430, loss 0.397934, acc 0.84375\n",
      "2018-05-04T15:49:30.877253: step 6431, loss 0.280174, acc 0.921875\n",
      "2018-05-04T15:49:31.873683: step 6432, loss 0.300801, acc 0.875\n",
      "2018-05-04T15:49:32.901676: step 6433, loss 0.286419, acc 0.859375\n",
      "2018-05-04T15:49:34.016082: step 6434, loss 0.271088, acc 0.84375\n",
      "2018-05-04T15:49:35.095510: step 6435, loss 0.223479, acc 0.921875\n",
      "2018-05-04T15:49:36.175463: step 6436, loss 0.494908, acc 0.796875\n",
      "2018-05-04T15:49:37.246007: step 6437, loss 0.362578, acc 0.875\n",
      "2018-05-04T15:49:38.292239: step 6438, loss 0.324446, acc 0.84375\n",
      "2018-05-04T15:49:39.304806: step 6439, loss 0.407908, acc 0.859375\n",
      "2018-05-04T15:49:40.326057: step 6440, loss 0.255572, acc 0.90625\n",
      "2018-05-04T15:49:41.381327: step 6441, loss 0.326477, acc 0.859375\n",
      "2018-05-04T15:49:42.372964: step 6442, loss 0.147351, acc 0.921875\n",
      "2018-05-04T15:49:43.372828: step 6443, loss 0.278368, acc 0.875\n",
      "2018-05-04T15:49:44.388496: step 6444, loss 0.288278, acc 0.875\n",
      "2018-05-04T15:49:45.392172: step 6445, loss 0.42459, acc 0.796875\n",
      "2018-05-04T15:49:46.405467: step 6446, loss 0.548536, acc 0.8125\n",
      "2018-05-04T15:49:47.419944: step 6447, loss 0.218696, acc 0.90625\n",
      "2018-05-04T15:49:48.437356: step 6448, loss 0.368225, acc 0.84375\n",
      "2018-05-04T15:49:49.446677: step 6449, loss 0.210463, acc 0.90625\n",
      "2018-05-04T15:49:50.451014: step 6450, loss 0.293862, acc 0.875\n",
      "2018-05-04T15:49:51.466553: step 6451, loss 0.243184, acc 0.921875\n",
      "2018-05-04T15:49:52.591231: step 6452, loss 0.318571, acc 0.875\n",
      "2018-05-04T15:49:53.607199: step 6453, loss 0.240318, acc 0.90625\n",
      "2018-05-04T15:49:54.620273: step 6454, loss 0.228215, acc 0.890625\n",
      "2018-05-04T15:49:55.625631: step 6455, loss 0.29686, acc 0.84375\n",
      "2018-05-04T15:49:56.649621: step 6456, loss 0.241238, acc 0.921875\n",
      "2018-05-04T15:49:57.738201: step 6457, loss 0.312389, acc 0.875\n",
      "2018-05-04T15:49:58.732300: step 6458, loss 0.180226, acc 0.9375\n",
      "2018-05-04T15:49:59.834463: step 6459, loss 0.318133, acc 0.890625\n",
      "2018-05-04T15:50:00.863720: step 6460, loss 0.325166, acc 0.890625\n",
      "2018-05-04T15:50:01.888696: step 6461, loss 0.289959, acc 0.84375\n",
      "2018-05-04T15:50:02.882785: step 6462, loss 0.300174, acc 0.875\n",
      "2018-05-04T15:50:03.895449: step 6463, loss 0.293658, acc 0.859375\n",
      "2018-05-04T15:50:04.886264: step 6464, loss 0.261891, acc 0.921875\n",
      "2018-05-04T15:50:05.884454: step 6465, loss 0.276449, acc 0.875\n",
      "2018-05-04T15:50:06.901811: step 6466, loss 0.445987, acc 0.78125\n",
      "2018-05-04T15:50:07.900584: step 6467, loss 0.336294, acc 0.890625\n",
      "2018-05-04T15:50:08.985174: step 6468, loss 0.355272, acc 0.875\n",
      "2018-05-04T15:50:09.960297: step 6469, loss 0.268263, acc 0.84375\n",
      "2018-05-04T15:50:10.958625: step 6470, loss 0.303478, acc 0.859375\n",
      "2018-05-04T15:50:11.937459: step 6471, loss 0.333364, acc 0.84375\n",
      "2018-05-04T15:50:12.914195: step 6472, loss 0.258725, acc 0.875\n",
      "2018-05-04T15:50:13.916540: step 6473, loss 0.268596, acc 0.890625\n",
      "2018-05-04T15:50:14.924049: step 6474, loss 0.289107, acc 0.890625\n",
      "2018-05-04T15:50:15.944283: step 6475, loss 0.312743, acc 0.875\n",
      "2018-05-04T15:50:16.978222: step 6476, loss 0.222172, acc 0.890625\n",
      "2018-05-04T15:50:17.975957: step 6477, loss 0.302099, acc 0.890625\n",
      "2018-05-04T15:50:18.968706: step 6478, loss 0.347992, acc 0.859375\n",
      "2018-05-04T15:50:19.956921: step 6479, loss 0.348591, acc 0.859375\n",
      "2018-05-04T15:50:20.954888: step 6480, loss 0.22433, acc 0.921875\n",
      "2018-05-04T15:50:22.072306: step 6481, loss 0.367421, acc 0.828125\n",
      "2018-05-04T15:50:23.091926: step 6482, loss 0.281655, acc 0.859375\n",
      "2018-05-04T15:50:24.075105: step 6483, loss 0.259133, acc 0.875\n",
      "2018-05-04T15:50:25.072563: step 6484, loss 0.406603, acc 0.828125\n",
      "2018-05-04T15:50:26.057499: step 6485, loss 0.402152, acc 0.828125\n",
      "2018-05-04T15:50:27.051107: step 6486, loss 0.243247, acc 0.890625\n",
      "2018-05-04T15:50:28.047447: step 6487, loss 0.254981, acc 0.921875\n",
      "2018-05-04T15:50:29.052543: step 6488, loss 0.349403, acc 0.8125\n",
      "2018-05-04T15:50:30.046978: step 6489, loss 0.259742, acc 0.921875\n",
      "2018-05-04T15:50:31.058763: step 6490, loss 0.297188, acc 0.859375\n",
      "2018-05-04T15:50:32.055385: step 6491, loss 0.556768, acc 0.765625\n",
      "2018-05-04T15:50:33.067847: step 6492, loss 0.403097, acc 0.8125\n",
      "2018-05-04T15:50:34.069789: step 6493, loss 0.305341, acc 0.875\n",
      "2018-05-04T15:50:35.106010: step 6494, loss 0.186909, acc 0.90625\n",
      "2018-05-04T15:50:36.143345: step 6495, loss 0.456962, acc 0.765625\n",
      "2018-05-04T15:50:37.222117: step 6496, loss 0.326368, acc 0.890625\n",
      "2018-05-04T15:50:38.187860: step 6497, loss 0.309888, acc 0.890625\n",
      "2018-05-04T15:50:39.198034: step 6498, loss 0.382567, acc 0.875\n",
      "2018-05-04T15:50:40.202818: step 6499, loss 0.288203, acc 0.875\n",
      "2018-05-04T15:50:41.195082: step 6500, loss 0.459693, acc 0.828125\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T15:50:43.451650: step 6500, loss 0.298668, acc 0.884\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-6500\n",
      "\n",
      "2018-05-04T15:50:44.544015: step 6501, loss 0.472292, acc 0.828125\n",
      "2018-05-04T15:50:45.563404: step 6502, loss 0.293213, acc 0.890625\n",
      "2018-05-04T15:50:46.614109: step 6503, loss 0.258052, acc 0.90625\n",
      "2018-05-04T15:50:47.589319: step 6504, loss 0.195933, acc 0.921875\n",
      "2018-05-04T15:50:48.578287: step 6505, loss 0.306191, acc 0.875\n",
      "2018-05-04T15:50:49.564135: step 6506, loss 0.204233, acc 0.9375\n",
      "2018-05-04T15:50:50.554893: step 6507, loss 0.34686, acc 0.78125\n",
      "2018-05-04T15:50:51.600322: step 6508, loss 0.352272, acc 0.8125\n",
      "2018-05-04T15:50:52.643592: step 6509, loss 0.322427, acc 0.84375\n",
      "2018-05-04T15:50:53.637696: step 6510, loss 0.301916, acc 0.84375\n",
      "2018-05-04T15:50:54.678190: step 6511, loss 0.281157, acc 0.890625\n",
      "2018-05-04T15:50:55.728457: step 6512, loss 0.345879, acc 0.796875\n",
      "2018-05-04T15:50:56.741710: step 6513, loss 0.267405, acc 0.90625\n",
      "2018-05-04T15:50:57.769789: step 6514, loss 0.402168, acc 0.796875\n",
      "2018-05-04T15:50:58.786700: step 6515, loss 0.373973, acc 0.875\n",
      "2018-05-04T15:50:59.772605: step 6516, loss 0.450649, acc 0.78125\n",
      "2018-05-04T15:51:00.759275: step 6517, loss 0.271036, acc 0.875\n",
      "2018-05-04T15:51:01.754404: step 6518, loss 0.281626, acc 0.84375\n",
      "2018-05-04T15:51:02.746912: step 6519, loss 0.47553, acc 0.828125\n",
      "2018-05-04T15:51:03.823279: step 6520, loss 0.272183, acc 0.84375\n",
      "2018-05-04T15:51:04.865830: step 6521, loss 0.272642, acc 0.875\n",
      "2018-05-04T15:51:05.855358: step 6522, loss 0.258487, acc 0.921875\n",
      "2018-05-04T15:51:06.847186: step 6523, loss 0.351777, acc 0.875\n",
      "2018-05-04T15:51:07.845584: step 6524, loss 0.249676, acc 0.9375\n",
      "2018-05-04T15:51:08.863761: step 6525, loss 0.410438, acc 0.828125\n",
      "2018-05-04T15:51:09.943883: step 6526, loss 0.319538, acc 0.859375\n",
      "2018-05-04T15:51:11.019459: step 6527, loss 0.278501, acc 0.90625\n",
      "2018-05-04T15:51:12.010124: step 6528, loss 0.197371, acc 0.921875\n",
      "2018-05-04T15:51:13.078655: step 6529, loss 0.179304, acc 0.953125\n",
      "2018-05-04T15:51:14.088318: step 6530, loss 0.314566, acc 0.875\n",
      "2018-05-04T15:51:15.091806: step 6531, loss 0.357627, acc 0.828125\n",
      "2018-05-04T15:51:16.043835: step 6532, loss 0.257705, acc 0.90625\n",
      "2018-05-04T15:51:17.015458: step 6533, loss 0.30162, acc 0.84375\n",
      "2018-05-04T15:51:18.066538: step 6534, loss 0.24546, acc 0.90625\n",
      "2018-05-04T15:51:19.155065: step 6535, loss 0.272932, acc 0.875\n",
      "2018-05-04T15:51:20.142861: step 6536, loss 0.394655, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T15:51:21.124615: step 6537, loss 0.217225, acc 0.90625\n",
      "2018-05-04T15:51:22.180407: step 6538, loss 0.383537, acc 0.8125\n",
      "2018-05-04T15:51:23.286920: step 6539, loss 0.312357, acc 0.890625\n",
      "2018-05-04T15:51:24.274197: step 6540, loss 0.445236, acc 0.828125\n",
      "2018-05-04T15:51:25.277404: step 6541, loss 0.274703, acc 0.859375\n",
      "2018-05-04T15:51:26.300848: step 6542, loss 0.217307, acc 0.921875\n",
      "2018-05-04T15:51:27.278020: step 6543, loss 0.236537, acc 0.875\n",
      "2018-05-04T15:51:28.309968: step 6544, loss 0.238824, acc 0.921875\n",
      "2018-05-04T15:51:29.353292: step 6545, loss 0.287425, acc 0.890625\n",
      "2018-05-04T15:51:30.306920: step 6546, loss 0.2408, acc 0.9375\n",
      "2018-05-04T15:51:31.275145: step 6547, loss 0.256357, acc 0.9375\n",
      "2018-05-04T15:51:32.238552: step 6548, loss 0.294418, acc 0.84375\n",
      "2018-05-04T15:51:33.296773: step 6549, loss 0.226714, acc 0.9375\n",
      "2018-05-04T15:51:34.293699: step 6550, loss 0.300776, acc 0.875\n",
      "2018-05-04T15:51:35.348213: step 6551, loss 0.281647, acc 0.859375\n",
      "2018-05-04T15:51:36.301659: step 6552, loss 0.320996, acc 0.84375\n",
      "2018-05-04T15:51:37.282234: step 6553, loss 0.274614, acc 0.859375\n",
      "2018-05-04T15:51:38.296613: step 6554, loss 0.487332, acc 0.796875\n",
      "2018-05-04T15:51:39.265033: step 6555, loss 0.338621, acc 0.84375\n",
      "2018-05-04T15:51:40.220432: step 6556, loss 0.291264, acc 0.875\n",
      "2018-05-04T15:51:41.294336: step 6557, loss 0.300583, acc 0.90625\n",
      "2018-05-04T15:51:42.339042: step 6558, loss 0.42993, acc 0.8125\n",
      "2018-05-04T15:51:43.418516: step 6559, loss 0.28954, acc 0.890625\n",
      "2018-05-04T15:51:44.474725: step 6560, loss 0.450637, acc 0.875\n",
      "2018-05-04T15:51:45.502719: step 6561, loss 0.292592, acc 0.859375\n",
      "2018-05-04T15:51:46.524739: step 6562, loss 0.269706, acc 0.90625\n",
      "2018-05-04T15:51:47.549378: step 6563, loss 0.183359, acc 0.953125\n",
      "2018-05-04T15:51:48.565939: step 6564, loss 0.450781, acc 0.8125\n",
      "2018-05-04T15:51:49.569210: step 6565, loss 0.299086, acc 0.90625\n",
      "2018-05-04T15:51:50.592179: step 6566, loss 0.184344, acc 0.9375\n",
      "2018-05-04T15:51:51.654560: step 6567, loss 0.266296, acc 0.890625\n",
      "2018-05-04T15:51:52.666937: step 6568, loss 0.322923, acc 0.84375\n",
      "2018-05-04T15:51:53.615639: step 6569, loss 0.290894, acc 0.90625\n",
      "2018-05-04T15:51:54.637143: step 6570, loss 0.196918, acc 0.921875\n",
      "2018-05-04T15:51:55.561709: step 6571, loss 0.333962, acc 0.875\n",
      "2018-05-04T15:51:56.607168: step 6572, loss 0.313201, acc 0.890625\n",
      "2018-05-04T15:51:57.549143: step 6573, loss 0.285979, acc 0.859375\n",
      "2018-05-04T15:51:58.593145: step 6574, loss 0.289517, acc 0.875\n",
      "2018-05-04T15:51:59.618658: step 6575, loss 0.243156, acc 0.890625\n",
      "2018-05-04T15:52:00.630136: step 6576, loss 0.282198, acc 0.890625\n",
      "2018-05-04T15:52:01.640965: step 6577, loss 0.376556, acc 0.890625\n",
      "2018-05-04T15:52:02.580086: step 6578, loss 0.313926, acc 0.875\n",
      "2018-05-04T15:52:03.599921: step 6579, loss 0.358343, acc 0.796875\n",
      "2018-05-04T15:52:04.648057: step 6580, loss 0.26677, acc 0.890625\n",
      "2018-05-04T15:52:05.675378: step 6581, loss 0.32664, acc 0.828125\n",
      "2018-05-04T15:52:06.686795: step 6582, loss 0.260119, acc 0.890625\n",
      "2018-05-04T15:52:07.626842: step 6583, loss 0.265836, acc 0.890625\n",
      "2018-05-04T15:52:08.669013: step 6584, loss 0.200543, acc 0.921875\n",
      "2018-05-04T15:52:09.691559: step 6585, loss 0.268007, acc 0.890625\n",
      "2018-05-04T15:52:10.689589: step 6586, loss 0.371407, acc 0.84375\n",
      "2018-05-04T15:52:11.707999: step 6587, loss 0.274415, acc 0.859375\n",
      "2018-05-04T15:52:12.732168: step 6588, loss 0.213804, acc 0.890625\n",
      "2018-05-04T15:52:13.767982: step 6589, loss 0.324601, acc 0.875\n",
      "2018-05-04T15:52:14.705137: step 6590, loss 0.293874, acc 0.90625\n",
      "2018-05-04T15:52:15.739452: step 6591, loss 0.349262, acc 0.828125\n",
      "2018-05-04T15:52:16.746278: step 6592, loss 0.345991, acc 0.828125\n",
      "2018-05-04T15:52:17.778357: step 6593, loss 0.265695, acc 0.875\n",
      "2018-05-04T15:52:18.708838: step 6594, loss 0.306123, acc 0.90625\n",
      "2018-05-04T15:52:19.748208: step 6595, loss 0.274343, acc 0.875\n",
      "2018-05-04T15:52:20.760476: step 6596, loss 0.288746, acc 0.890625\n",
      "2018-05-04T15:52:21.800890: step 6597, loss 0.344124, acc 0.859375\n",
      "2018-05-04T15:52:22.832523: step 6598, loss 0.176325, acc 0.9375\n",
      "2018-05-04T15:52:23.856384: step 6599, loss 0.239849, acc 0.921875\n",
      "2018-05-04T15:52:24.835165: step 6600, loss 0.22514, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T15:52:27.000990: step 6600, loss 0.265807, acc 0.906\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-6600\n",
      "\n",
      "2018-05-04T15:52:28.103394: step 6601, loss 0.302149, acc 0.875\n",
      "2018-05-04T15:52:29.197200: step 6602, loss 0.283894, acc 0.890625\n",
      "2018-05-04T15:52:30.212403: step 6603, loss 0.206344, acc 0.921875\n",
      "2018-05-04T15:52:31.249129: step 6604, loss 0.225758, acc 0.921875\n",
      "2018-05-04T15:52:32.268488: step 6605, loss 0.381347, acc 0.828125\n",
      "2018-05-04T15:52:33.268873: step 6606, loss 0.266926, acc 0.859375\n",
      "2018-05-04T15:52:34.380627: step 6607, loss 0.216532, acc 0.90625\n",
      "2018-05-04T15:52:35.436781: step 6608, loss 0.349056, acc 0.8125\n",
      "2018-05-04T15:52:36.542579: step 6609, loss 0.347598, acc 0.828125\n",
      "2018-05-04T15:52:37.581070: step 6610, loss 0.493718, acc 0.78125\n",
      "2018-05-04T15:52:38.606910: step 6611, loss 0.343136, acc 0.859375\n",
      "2018-05-04T15:52:39.629320: step 6612, loss 0.310673, acc 0.859375\n",
      "2018-05-04T15:52:40.657837: step 6613, loss 0.260105, acc 0.859375\n",
      "2018-05-04T15:52:41.616406: step 6614, loss 0.24272, acc 0.921875\n",
      "2018-05-04T15:52:42.676151: step 6615, loss 0.319492, acc 0.875\n",
      "2018-05-04T15:52:43.706612: step 6616, loss 0.176884, acc 0.921875\n",
      "2018-05-04T15:52:44.748751: step 6617, loss 0.285768, acc 0.875\n",
      "2018-05-04T15:52:45.842390: step 6618, loss 0.291949, acc 0.859375\n",
      "2018-05-04T15:52:46.901051: step 6619, loss 0.240131, acc 0.90625\n",
      "2018-05-04T15:52:47.942721: step 6620, loss 0.46355, acc 0.828125\n",
      "2018-05-04T15:52:48.979777: step 6621, loss 0.238716, acc 0.90625\n",
      "2018-05-04T15:52:49.981565: step 6622, loss 0.357687, acc 0.8125\n",
      "2018-05-04T15:52:51.005985: step 6623, loss 0.159345, acc 0.9375\n",
      "2018-05-04T15:52:52.020158: step 6624, loss 0.30673, acc 0.859375\n",
      "2018-05-04T15:52:53.061467: step 6625, loss 0.172614, acc 0.9375\n",
      "2018-05-04T15:52:54.089185: step 6626, loss 0.18499, acc 0.9375\n",
      "2018-05-04T15:52:55.130367: step 6627, loss 0.393112, acc 0.875\n",
      "2018-05-04T15:52:56.166980: step 6628, loss 0.228433, acc 0.90625\n",
      "2018-05-04T15:52:57.211779: step 6629, loss 0.585396, acc 0.765625\n",
      "2018-05-04T15:52:58.219362: step 6630, loss 0.228444, acc 0.9375\n",
      "2018-05-04T15:52:59.278489: step 6631, loss 0.170985, acc 0.953125\n",
      "2018-05-04T15:53:00.337893: step 6632, loss 0.232597, acc 0.875\n",
      "2018-05-04T15:53:01.404966: step 6633, loss 0.403141, acc 0.859375\n",
      "2018-05-04T15:53:02.429041: step 6634, loss 0.262163, acc 0.875\n",
      "2018-05-04T15:53:03.465310: step 6635, loss 0.220844, acc 0.875\n",
      "2018-05-04T15:53:04.519724: step 6636, loss 0.341693, acc 0.890625\n",
      "2018-05-04T15:53:05.545461: step 6637, loss 0.289358, acc 0.859375\n",
      "2018-05-04T15:53:06.592710: step 6638, loss 0.266527, acc 0.890625\n",
      "2018-05-04T15:53:07.642820: step 6639, loss 0.268823, acc 0.890625\n",
      "2018-05-04T15:53:08.716461: step 6640, loss 0.484935, acc 0.765625\n",
      "2018-05-04T15:53:09.835434: step 6641, loss 0.397633, acc 0.84375\n",
      "2018-05-04T15:53:10.886792: step 6642, loss 0.22778, acc 0.890625\n",
      "2018-05-04T15:53:11.937660: step 6643, loss 0.199458, acc 0.90625\n",
      "2018-05-04T15:53:13.003996: step 6644, loss 0.454292, acc 0.828125\n",
      "2018-05-04T15:53:14.067071: step 6645, loss 0.364192, acc 0.890625\n",
      "2018-05-04T15:53:15.120614: step 6646, loss 0.247966, acc 0.921875\n",
      "2018-05-04T15:53:16.182957: step 6647, loss 0.351094, acc 0.875\n",
      "2018-05-04T15:53:17.275550: step 6648, loss 0.384226, acc 0.84375\n",
      "2018-05-04T15:53:18.301815: step 6649, loss 0.33917, acc 0.796875\n",
      "2018-05-04T15:53:19.364414: step 6650, loss 0.354296, acc 0.8125\n",
      "2018-05-04T15:53:20.431621: step 6651, loss 0.161081, acc 0.9375\n",
      "2018-05-04T15:53:21.502648: step 6652, loss 0.178143, acc 0.96875\n",
      "2018-05-04T15:53:22.549469: step 6653, loss 0.341958, acc 0.828125\n",
      "2018-05-04T15:53:23.614616: step 6654, loss 0.42951, acc 0.8125\n",
      "2018-05-04T15:53:24.695503: step 6655, loss 0.373197, acc 0.859375\n",
      "2018-05-04T15:53:25.753609: step 6656, loss 0.301566, acc 0.875\n",
      "2018-05-04T15:53:26.820893: step 6657, loss 0.348777, acc 0.859375\n",
      "2018-05-04T15:53:27.859200: step 6658, loss 0.351344, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T15:53:28.931183: step 6659, loss 0.408907, acc 0.828125\n",
      "2018-05-04T15:53:30.020900: step 6660, loss 0.337432, acc 0.875\n",
      "2018-05-04T15:53:31.123125: step 6661, loss 0.285412, acc 0.890625\n",
      "2018-05-04T15:53:32.202032: step 6662, loss 0.250339, acc 0.890625\n",
      "2018-05-04T15:53:33.265914: step 6663, loss 0.307419, acc 0.84375\n",
      "2018-05-04T15:53:34.348923: step 6664, loss 0.388447, acc 0.796875\n",
      "2018-05-04T15:53:35.408929: step 6665, loss 0.186408, acc 0.96875\n",
      "2018-05-04T15:53:36.449000: step 6666, loss 0.201804, acc 0.90625\n",
      "2018-05-04T15:53:37.504333: step 6667, loss 0.404789, acc 0.828125\n",
      "2018-05-04T15:53:38.568413: step 6668, loss 0.335488, acc 0.90625\n",
      "2018-05-04T15:53:39.638115: step 6669, loss 0.486324, acc 0.859375\n",
      "2018-05-04T15:53:40.711041: step 6670, loss 0.199293, acc 0.9375\n",
      "2018-05-04T15:53:41.775208: step 6671, loss 0.251243, acc 0.890625\n",
      "2018-05-04T15:53:42.859687: step 6672, loss 0.327653, acc 0.828125\n",
      "2018-05-04T15:53:43.935921: step 6673, loss 0.274445, acc 0.875\n",
      "2018-05-04T15:53:44.992065: step 6674, loss 0.290476, acc 0.859375\n",
      "2018-05-04T15:53:46.065750: step 6675, loss 0.220368, acc 0.90625\n",
      "2018-05-04T15:53:47.108615: step 6676, loss 0.252737, acc 0.890625\n",
      "2018-05-04T15:53:48.155409: step 6677, loss 0.367759, acc 0.859375\n",
      "2018-05-04T15:53:49.225777: step 6678, loss 0.284943, acc 0.890625\n",
      "2018-05-04T15:53:50.310481: step 6679, loss 0.346158, acc 0.875\n",
      "2018-05-04T15:53:51.477260: step 6680, loss 0.41498, acc 0.8125\n",
      "2018-05-04T15:53:52.568843: step 6681, loss 0.183539, acc 0.953125\n",
      "2018-05-04T15:53:53.641721: step 6682, loss 0.390658, acc 0.84375\n",
      "2018-05-04T15:53:54.733907: step 6683, loss 0.229701, acc 0.890625\n",
      "2018-05-04T15:53:55.811170: step 6684, loss 0.407126, acc 0.8125\n",
      "2018-05-04T15:53:56.881305: step 6685, loss 0.305366, acc 0.84375\n",
      "2018-05-04T15:53:57.906350: step 6686, loss 0.316124, acc 0.84375\n",
      "2018-05-04T15:53:58.977624: step 6687, loss 0.239376, acc 0.890625\n",
      "2018-05-04T15:54:00.049965: step 6688, loss 0.375027, acc 0.828125\n",
      "2018-05-04T15:54:01.119644: step 6689, loss 0.264271, acc 0.890625\n",
      "2018-05-04T15:54:02.172652: step 6690, loss 0.246907, acc 0.921875\n",
      "2018-05-04T15:54:03.237967: step 6691, loss 0.294902, acc 0.875\n",
      "2018-05-04T15:54:04.343977: step 6692, loss 0.464722, acc 0.796875\n",
      "2018-05-04T15:54:05.426088: step 6693, loss 0.254851, acc 0.90625\n",
      "2018-05-04T15:54:06.476739: step 6694, loss 0.286648, acc 0.890625\n",
      "2018-05-04T15:54:07.563360: step 6695, loss 0.350907, acc 0.859375\n",
      "2018-05-04T15:54:08.642915: step 6696, loss 0.259021, acc 0.875\n",
      "2018-05-04T15:54:09.703536: step 6697, loss 0.401273, acc 0.828125\n",
      "2018-05-04T15:54:10.761123: step 6698, loss 0.351349, acc 0.84375\n",
      "2018-05-04T15:54:11.852023: step 6699, loss 0.126357, acc 0.984375\n",
      "2018-05-04T15:54:12.931629: step 6700, loss 0.189157, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T15:54:15.575623: step 6700, loss 0.292619, acc 0.886\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-6700\n",
      "\n",
      "2018-05-04T15:54:16.696913: step 6701, loss 0.415573, acc 0.765625\n",
      "2018-05-04T15:54:17.779503: step 6702, loss 0.584697, acc 0.796875\n",
      "2018-05-04T15:54:18.847856: step 6703, loss 0.393651, acc 0.859375\n",
      "2018-05-04T15:54:19.957494: step 6704, loss 0.316284, acc 0.84375\n",
      "2018-05-04T15:54:21.089476: step 6705, loss 0.266313, acc 0.90625\n",
      "2018-05-04T15:54:22.172182: step 6706, loss 0.361454, acc 0.859375\n",
      "2018-05-04T15:54:23.307694: step 6707, loss 0.344787, acc 0.859375\n",
      "2018-05-04T15:54:24.373892: step 6708, loss 0.23166, acc 0.90625\n",
      "2018-05-04T15:54:25.512013: step 6709, loss 0.372065, acc 0.84375\n",
      "2018-05-04T15:54:26.547753: step 6710, loss 0.275568, acc 0.90625\n",
      "2018-05-04T15:54:27.561841: step 6711, loss 0.264887, acc 0.90625\n",
      "2018-05-04T15:54:28.587465: step 6712, loss 0.41412, acc 0.78125\n",
      "2018-05-04T15:54:29.603284: step 6713, loss 0.316796, acc 0.875\n",
      "2018-05-04T15:54:30.654837: step 6714, loss 0.380017, acc 0.84375\n",
      "2018-05-04T15:54:31.710743: step 6715, loss 0.312325, acc 0.84375\n",
      "2018-05-04T15:54:32.813544: step 6716, loss 0.228291, acc 0.9375\n",
      "2018-05-04T15:54:33.926556: step 6717, loss 0.327248, acc 0.90625\n",
      "2018-05-04T15:54:34.976033: step 6718, loss 0.489606, acc 0.8125\n",
      "2018-05-04T15:54:35.981630: step 6719, loss 0.186847, acc 0.953125\n",
      "2018-05-04T15:54:37.025975: step 6720, loss 0.330727, acc 0.859375\n",
      "2018-05-04T15:54:38.060007: step 6721, loss 0.259072, acc 0.9375\n",
      "2018-05-04T15:54:39.152268: step 6722, loss 0.267088, acc 0.890625\n",
      "2018-05-04T15:54:40.154250: step 6723, loss 0.288017, acc 0.859375\n",
      "2018-05-04T15:54:41.177175: step 6724, loss 0.376595, acc 0.890625\n",
      "2018-05-04T15:54:42.174071: step 6725, loss 0.314531, acc 0.890625\n",
      "2018-05-04T15:54:43.222759: step 6726, loss 0.245782, acc 0.90625\n",
      "2018-05-04T15:54:44.280741: step 6727, loss 0.247779, acc 0.890625\n",
      "2018-05-04T15:54:45.311097: step 6728, loss 0.229117, acc 0.90625\n",
      "2018-05-04T15:54:46.324652: step 6729, loss 0.31644, acc 0.875\n",
      "2018-05-04T15:54:47.354295: step 6730, loss 0.158065, acc 0.953125\n",
      "2018-05-04T15:54:48.385678: step 6731, loss 0.261723, acc 0.890625\n",
      "2018-05-04T15:54:49.435878: step 6732, loss 0.199538, acc 0.921875\n",
      "2018-05-04T15:54:50.472019: step 6733, loss 0.270774, acc 0.90625\n",
      "2018-05-04T15:54:51.501908: step 6734, loss 0.238338, acc 0.90625\n",
      "2018-05-04T15:54:52.541708: step 6735, loss 0.248132, acc 0.90625\n",
      "2018-05-04T15:54:53.649252: step 6736, loss 0.223697, acc 0.921875\n",
      "2018-05-04T15:54:54.670773: step 6737, loss 0.479991, acc 0.78125\n",
      "2018-05-04T15:54:55.701143: step 6738, loss 0.299772, acc 0.875\n",
      "2018-05-04T15:54:56.724421: step 6739, loss 0.267524, acc 0.90625\n",
      "2018-05-04T15:54:57.775027: step 6740, loss 0.161059, acc 0.953125\n",
      "2018-05-04T15:54:58.807700: step 6741, loss 0.333018, acc 0.859375\n",
      "2018-05-04T15:54:59.904989: step 6742, loss 0.324502, acc 0.84375\n",
      "2018-05-04T15:55:00.930717: step 6743, loss 0.345051, acc 0.84375\n",
      "2018-05-04T15:55:01.995558: step 6744, loss 0.496866, acc 0.859375\n",
      "2018-05-04T15:55:03.029520: step 6745, loss 0.256429, acc 0.875\n",
      "2018-05-04T15:55:04.102699: step 6746, loss 0.26405, acc 0.90625\n",
      "2018-05-04T15:55:05.151375: step 6747, loss 0.229095, acc 0.90625\n",
      "2018-05-04T15:55:06.173003: step 6748, loss 0.196812, acc 0.921875\n",
      "2018-05-04T15:55:07.200902: step 6749, loss 0.194873, acc 0.9375\n",
      "2018-05-04T15:55:08.237883: step 6750, loss 0.230275, acc 0.953125\n",
      "2018-05-04T15:55:09.282929: step 6751, loss 0.244832, acc 0.859375\n",
      "2018-05-04T15:55:10.313642: step 6752, loss 0.26633, acc 0.90625\n",
      "2018-05-04T15:55:11.346212: step 6753, loss 0.181322, acc 0.953125\n",
      "2018-05-04T15:55:12.363184: step 6754, loss 0.250515, acc 0.9375\n",
      "2018-05-04T15:55:13.401114: step 6755, loss 0.287306, acc 0.890625\n",
      "2018-05-04T15:55:14.444253: step 6756, loss 0.323532, acc 0.859375\n",
      "2018-05-04T15:55:15.461328: step 6757, loss 0.282134, acc 0.890625\n",
      "2018-05-04T15:55:16.487614: step 6758, loss 0.302191, acc 0.859375\n",
      "2018-05-04T15:55:17.566085: step 6759, loss 0.153345, acc 0.921875\n",
      "2018-05-04T15:55:18.676742: step 6760, loss 0.231036, acc 0.90625\n",
      "2018-05-04T15:55:19.723406: step 6761, loss 0.313213, acc 0.90625\n",
      "2018-05-04T15:55:20.782901: step 6762, loss 0.344363, acc 0.890625\n",
      "2018-05-04T15:55:21.838760: step 6763, loss 0.225432, acc 0.90625\n",
      "2018-05-04T15:55:22.853776: step 6764, loss 0.157728, acc 0.9375\n",
      "2018-05-04T15:55:23.890656: step 6765, loss 0.353627, acc 0.875\n",
      "2018-05-04T15:55:24.934223: step 6766, loss 0.211459, acc 0.9375\n",
      "2018-05-04T15:55:25.970595: step 6767, loss 0.161615, acc 0.9375\n",
      "2018-05-04T15:55:26.990176: step 6768, loss 0.16444, acc 0.953125\n",
      "2018-05-04T15:55:28.026244: step 6769, loss 0.300607, acc 0.875\n",
      "2018-05-04T15:55:29.044666: step 6770, loss 0.466049, acc 0.828125\n",
      "2018-05-04T15:55:30.128196: step 6771, loss 0.256691, acc 0.859375\n",
      "2018-05-04T15:55:31.252395: step 6772, loss 0.4421, acc 0.828125\n",
      "2018-05-04T15:55:32.284860: step 6773, loss 0.269529, acc 0.921875\n",
      "2018-05-04T15:55:33.417536: step 6774, loss 0.316191, acc 0.859375\n",
      "2018-05-04T15:55:34.499932: step 6775, loss 0.303046, acc 0.859375\n",
      "2018-05-04T15:55:35.602433: step 6776, loss 0.262694, acc 0.890625\n",
      "2018-05-04T15:55:36.725089: step 6777, loss 0.285652, acc 0.890625\n",
      "2018-05-04T15:55:37.822855: step 6778, loss 0.313655, acc 0.84375\n",
      "2018-05-04T15:55:38.873940: step 6779, loss 0.403408, acc 0.828125\n",
      "2018-05-04T15:55:39.931295: step 6780, loss 0.334857, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T15:55:41.010405: step 6781, loss 0.188644, acc 0.921875\n",
      "2018-05-04T15:55:42.089713: step 6782, loss 0.270365, acc 0.890625\n",
      "2018-05-04T15:55:43.100754: step 6783, loss 0.283435, acc 0.890625\n",
      "2018-05-04T15:55:44.125975: step 6784, loss 0.26714, acc 0.859375\n",
      "2018-05-04T15:55:45.165442: step 6785, loss 0.317586, acc 0.890625\n",
      "2018-05-04T15:55:46.192699: step 6786, loss 0.193434, acc 0.9375\n",
      "2018-05-04T15:55:47.221517: step 6787, loss 0.273476, acc 0.90625\n",
      "2018-05-04T15:55:48.238789: step 6788, loss 0.373554, acc 0.796875\n",
      "2018-05-04T15:55:49.276014: step 6789, loss 0.305394, acc 0.8125\n",
      "2018-05-04T15:55:50.288514: step 6790, loss 0.296482, acc 0.890625\n",
      "2018-05-04T15:55:51.316888: step 6791, loss 0.292544, acc 0.875\n",
      "2018-05-04T15:55:52.353462: step 6792, loss 0.393798, acc 0.859375\n",
      "2018-05-04T15:55:53.379683: step 6793, loss 0.230938, acc 0.921875\n",
      "2018-05-04T15:55:54.403893: step 6794, loss 0.311231, acc 0.890625\n",
      "2018-05-04T15:55:55.410311: step 6795, loss 0.405475, acc 0.8125\n",
      "2018-05-04T15:55:56.427527: step 6796, loss 0.294312, acc 0.875\n",
      "2018-05-04T15:55:57.438163: step 6797, loss 0.193278, acc 0.921875\n",
      "2018-05-04T15:55:58.463547: step 6798, loss 0.51121, acc 0.8125\n",
      "2018-05-04T15:55:59.541636: step 6799, loss 0.267291, acc 0.890625\n",
      "2018-05-04T15:56:00.519482: step 6800, loss 0.279254, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T15:56:02.812264: step 6800, loss 0.251103, acc 0.91\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-6800\n",
      "\n",
      "2018-05-04T15:56:04.020333: step 6801, loss 0.230437, acc 0.875\n",
      "2018-05-04T15:56:05.103683: step 6802, loss 0.275263, acc 0.859375\n",
      "2018-05-04T15:56:06.164035: step 6803, loss 0.226778, acc 0.890625\n",
      "2018-05-04T15:56:07.150571: step 6804, loss 0.232286, acc 0.921875\n",
      "2018-05-04T15:56:08.133829: step 6805, loss 0.229595, acc 0.90625\n",
      "2018-05-04T15:56:09.133125: step 6806, loss 0.22463, acc 0.90625\n",
      "2018-05-04T15:56:10.113128: step 6807, loss 0.257484, acc 0.90625\n",
      "2018-05-04T15:56:11.142157: step 6808, loss 0.212827, acc 0.921875\n",
      "2018-05-04T15:56:12.208581: step 6809, loss 0.367477, acc 0.84375\n",
      "2018-05-04T15:56:13.229778: step 6810, loss 0.406028, acc 0.796875\n",
      "2018-05-04T15:56:14.246866: step 6811, loss 0.278013, acc 0.875\n",
      "2018-05-04T15:56:15.334744: step 6812, loss 0.220967, acc 0.890625\n",
      "2018-05-04T15:56:16.361887: step 6813, loss 0.235844, acc 0.921875\n",
      "2018-05-04T15:56:17.342164: step 6814, loss 0.394327, acc 0.859375\n",
      "2018-05-04T15:56:18.316113: step 6815, loss 0.222538, acc 0.921875\n",
      "2018-05-04T15:56:19.296807: step 6816, loss 0.342475, acc 0.859375\n",
      "2018-05-04T15:56:20.372956: step 6817, loss 0.248063, acc 0.875\n",
      "2018-05-04T15:56:21.393708: step 6818, loss 0.275634, acc 0.890625\n",
      "2018-05-04T15:56:22.416430: step 6819, loss 0.198006, acc 0.921875\n",
      "2018-05-04T15:56:23.409645: step 6820, loss 0.233921, acc 0.921875\n",
      "2018-05-04T15:56:24.404793: step 6821, loss 0.381347, acc 0.8125\n",
      "2018-05-04T15:56:25.474953: step 6822, loss 0.204167, acc 0.90625\n",
      "2018-05-04T15:56:26.471910: step 6823, loss 0.28783, acc 0.890625\n",
      "2018-05-04T15:56:27.464872: step 6824, loss 0.233274, acc 0.921875\n",
      "2018-05-04T15:56:28.459047: step 6825, loss 0.228678, acc 0.9375\n",
      "2018-05-04T15:56:29.465418: step 6826, loss 0.271148, acc 0.875\n",
      "2018-05-04T15:56:30.443479: step 6827, loss 0.304854, acc 0.875\n",
      "2018-05-04T15:56:31.497843: step 6828, loss 0.265121, acc 0.90625\n",
      "2018-05-04T15:56:32.590619: step 6829, loss 0.277329, acc 0.921875\n",
      "2018-05-04T15:56:33.579731: step 6830, loss 0.296129, acc 0.875\n",
      "2018-05-04T15:56:34.583454: step 6831, loss 0.272149, acc 0.859375\n",
      "2018-05-04T15:56:35.589837: step 6832, loss 0.380098, acc 0.8125\n",
      "2018-05-04T15:56:36.608069: step 6833, loss 0.178416, acc 0.90625\n",
      "2018-05-04T15:56:37.686544: step 6834, loss 0.263031, acc 0.875\n",
      "2018-05-04T15:56:38.659388: step 6835, loss 0.263597, acc 0.890625\n",
      "2018-05-04T15:56:39.659696: step 6836, loss 0.24249, acc 0.9375\n",
      "2018-05-04T15:56:40.650871: step 6837, loss 0.414754, acc 0.859375\n",
      "2018-05-04T15:56:41.629929: step 6838, loss 0.178732, acc 0.921875\n",
      "2018-05-04T15:56:42.610772: step 6839, loss 0.416861, acc 0.84375\n",
      "2018-05-04T15:56:43.600535: step 6840, loss 0.307555, acc 0.84375\n",
      "2018-05-04T15:56:44.584614: step 6841, loss 0.312965, acc 0.8125\n",
      "2018-05-04T15:56:45.573376: step 6842, loss 0.297209, acc 0.859375\n",
      "2018-05-04T15:56:46.550087: step 6843, loss 0.219313, acc 0.90625\n",
      "2018-05-04T15:56:47.630540: step 6844, loss 0.227518, acc 0.890625\n",
      "2018-05-04T15:56:48.697381: step 6845, loss 0.26726, acc 0.890625\n",
      "2018-05-04T15:56:49.751581: step 6846, loss 0.245722, acc 0.921875\n",
      "2018-05-04T15:56:50.788186: step 6847, loss 0.339753, acc 0.859375\n",
      "2018-05-04T15:56:51.844855: step 6848, loss 0.427381, acc 0.828125\n",
      "2018-05-04T15:56:52.907845: step 6849, loss 0.315632, acc 0.859375\n",
      "2018-05-04T15:56:53.860338: step 6850, loss 0.274409, acc 0.890625\n",
      "2018-05-04T15:56:54.898057: step 6851, loss 0.306036, acc 0.875\n",
      "2018-05-04T15:56:55.921554: step 6852, loss 0.313736, acc 0.875\n",
      "2018-05-04T15:56:56.884674: step 6853, loss 0.229819, acc 0.921875\n",
      "2018-05-04T15:56:57.856969: step 6854, loss 0.295426, acc 0.890625\n",
      "2018-05-04T15:56:58.888581: step 6855, loss 0.248041, acc 0.90625\n",
      "2018-05-04T15:56:59.871099: step 6856, loss 0.217182, acc 0.90625\n",
      "2018-05-04T15:57:00.836508: step 6857, loss 0.339865, acc 0.84375\n",
      "2018-05-04T15:57:01.873353: step 6858, loss 0.323222, acc 0.859375\n",
      "2018-05-04T15:57:02.841568: step 6859, loss 0.306671, acc 0.859375\n",
      "2018-05-04T15:57:03.813795: step 6860, loss 0.292759, acc 0.84375\n",
      "2018-05-04T15:57:04.758601: step 6861, loss 0.26599, acc 0.90625\n",
      "2018-05-04T15:57:05.787358: step 6862, loss 0.243115, acc 0.90625\n",
      "2018-05-04T15:57:06.818487: step 6863, loss 0.289774, acc 0.890625\n",
      "2018-05-04T15:57:07.871463: step 6864, loss 0.284586, acc 0.875\n",
      "2018-05-04T15:57:08.902862: step 6865, loss 0.282275, acc 0.875\n",
      "2018-05-04T15:57:09.920600: step 6866, loss 0.416798, acc 0.84375\n",
      "2018-05-04T15:57:10.888956: step 6867, loss 0.237254, acc 0.875\n",
      "2018-05-04T15:57:11.837816: step 6868, loss 0.278975, acc 0.859375\n",
      "2018-05-04T15:57:12.843503: step 6869, loss 0.289538, acc 0.90625\n",
      "2018-05-04T15:57:13.897520: step 6870, loss 0.258965, acc 0.890625\n",
      "2018-05-04T15:57:14.942257: step 6871, loss 0.236977, acc 0.875\n",
      "2018-05-04T15:57:15.891157: step 6872, loss 0.286304, acc 0.890625\n",
      "2018-05-04T15:57:16.930932: step 6873, loss 0.405489, acc 0.890625\n",
      "2018-05-04T15:57:17.964569: step 6874, loss 0.339906, acc 0.8125\n",
      "2018-05-04T15:57:18.998721: step 6875, loss 0.263641, acc 0.890625\n",
      "2018-05-04T15:57:20.027728: step 6876, loss 0.335148, acc 0.828125\n",
      "2018-05-04T15:57:20.958367: step 6877, loss 0.274914, acc 0.828125\n",
      "2018-05-04T15:57:21.929804: step 6878, loss 0.244472, acc 0.890625\n",
      "2018-05-04T15:57:22.986926: step 6879, loss 0.368126, acc 0.828125\n",
      "2018-05-04T15:57:24.031792: step 6880, loss 0.259697, acc 0.875\n",
      "2018-05-04T15:57:25.058744: step 6881, loss 0.223329, acc 0.90625\n",
      "2018-05-04T15:57:26.119906: step 6882, loss 0.495127, acc 0.8125\n",
      "2018-05-04T15:57:27.141227: step 6883, loss 0.250306, acc 0.890625\n",
      "2018-05-04T15:57:28.134497: step 6884, loss 0.247209, acc 0.875\n",
      "2018-05-04T15:57:29.153885: step 6885, loss 0.243978, acc 0.90625\n",
      "2018-05-04T15:57:30.135384: step 6886, loss 0.37913, acc 0.84375\n",
      "2018-05-04T15:57:31.086072: step 6887, loss 0.342862, acc 0.859375\n",
      "2018-05-04T15:57:32.130968: step 6888, loss 0.436813, acc 0.796875\n",
      "2018-05-04T15:57:33.171246: step 6889, loss 0.467146, acc 0.828125\n",
      "2018-05-04T15:57:34.220175: step 6890, loss 0.493102, acc 0.84375\n",
      "2018-05-04T15:57:35.271211: step 6891, loss 0.212762, acc 0.9375\n",
      "2018-05-04T15:57:36.280860: step 6892, loss 0.250984, acc 0.890625\n",
      "2018-05-04T15:57:37.331473: step 6893, loss 0.374635, acc 0.84375\n",
      "2018-05-04T15:57:38.367877: step 6894, loss 0.300278, acc 0.875\n",
      "2018-05-04T15:57:39.379586: step 6895, loss 0.323577, acc 0.921875\n",
      "2018-05-04T15:57:40.423087: step 6896, loss 0.330907, acc 0.90625\n",
      "2018-05-04T15:57:41.469707: step 6897, loss 0.305588, acc 0.84375\n",
      "2018-05-04T15:57:42.476456: step 6898, loss 0.213786, acc 0.953125\n",
      "2018-05-04T15:57:43.504183: step 6899, loss 0.280278, acc 0.890625\n",
      "2018-05-04T15:57:44.528040: step 6900, loss 0.330882, acc 0.828125\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T15:57:47.316520: step 6900, loss 0.247013, acc 0.904\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-6900\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T15:57:48.378300: step 6901, loss 0.210218, acc 0.90625\n",
      "2018-05-04T15:57:49.386817: step 6902, loss 0.258407, acc 0.84375\n",
      "2018-05-04T15:57:50.422352: step 6903, loss 0.292004, acc 0.859375\n",
      "2018-05-04T15:57:51.476633: step 6904, loss 0.285638, acc 0.921875\n",
      "2018-05-04T15:57:52.525689: step 6905, loss 0.281212, acc 0.875\n",
      "2018-05-04T15:57:53.574452: step 6906, loss 0.558478, acc 0.78125\n",
      "2018-05-04T15:57:54.684191: step 6907, loss 0.252289, acc 0.890625\n",
      "2018-05-04T15:57:55.757887: step 6908, loss 0.249513, acc 0.90625\n",
      "2018-05-04T15:57:56.746634: step 6909, loss 0.285795, acc 0.890625\n",
      "2018-05-04T15:57:57.761363: step 6910, loss 0.387278, acc 0.859375\n",
      "2018-05-04T15:57:58.761401: step 6911, loss 0.348806, acc 0.875\n",
      "2018-05-04T15:57:59.759254: step 6912, loss 0.313031, acc 0.875\n",
      "2018-05-04T15:58:00.751484: step 6913, loss 0.199992, acc 0.9375\n",
      "2018-05-04T15:58:01.758637: step 6914, loss 0.234445, acc 0.9375\n",
      "2018-05-04T15:58:02.771999: step 6915, loss 0.307877, acc 0.890625\n",
      "2018-05-04T15:58:03.769263: step 6916, loss 0.314916, acc 0.875\n",
      "2018-05-04T15:58:04.859082: step 6917, loss 0.187295, acc 0.921875\n",
      "2018-05-04T15:58:05.874482: step 6918, loss 0.351983, acc 0.875\n",
      "2018-05-04T15:58:06.847922: step 6919, loss 0.349826, acc 0.828125\n",
      "2018-05-04T15:58:07.874016: step 6920, loss 0.410699, acc 0.8125\n",
      "2018-05-04T15:58:08.842660: step 6921, loss 0.269256, acc 0.90625\n",
      "2018-05-04T15:58:09.819646: step 6922, loss 0.350453, acc 0.84375\n",
      "2018-05-04T15:58:10.790729: step 6923, loss 0.233794, acc 0.921875\n",
      "2018-05-04T15:58:11.768759: step 6924, loss 0.342656, acc 0.859375\n",
      "2018-05-04T15:58:12.792465: step 6925, loss 0.2614, acc 0.90625\n",
      "2018-05-04T15:58:13.804904: step 6926, loss 0.283101, acc 0.90625\n",
      "2018-05-04T15:58:14.801163: step 6927, loss 0.245218, acc 0.875\n",
      "2018-05-04T15:58:15.835573: step 6928, loss 0.287379, acc 0.84375\n",
      "2018-05-04T15:58:16.830850: step 6929, loss 0.280056, acc 0.875\n",
      "2018-05-04T15:58:17.823148: step 6930, loss 0.20926, acc 0.90625\n",
      "2018-05-04T15:58:18.826092: step 6931, loss 0.285087, acc 0.921875\n",
      "2018-05-04T15:58:19.811520: step 6932, loss 0.29152, acc 0.875\n",
      "2018-05-04T15:58:20.817902: step 6933, loss 0.21597, acc 0.9375\n",
      "2018-05-04T15:58:21.832823: step 6934, loss 0.262864, acc 0.90625\n",
      "2018-05-04T15:58:22.817866: step 6935, loss 0.391578, acc 0.828125\n",
      "2018-05-04T15:58:23.812843: step 6936, loss 0.240497, acc 0.921875\n",
      "2018-05-04T15:58:24.877140: step 6937, loss 0.239076, acc 0.90625\n",
      "2018-05-04T15:58:25.866908: step 6938, loss 0.243482, acc 0.953125\n",
      "2018-05-04T15:58:26.825170: step 6939, loss 0.38395, acc 0.84375\n",
      "2018-05-04T15:58:27.801061: step 6940, loss 0.197801, acc 0.90625\n",
      "2018-05-04T15:58:28.778629: step 6941, loss 0.219127, acc 0.875\n",
      "2018-05-04T15:58:29.786893: step 6942, loss 0.249035, acc 0.90625\n",
      "2018-05-04T15:58:30.793855: step 6943, loss 0.281551, acc 0.9375\n",
      "2018-05-04T15:58:31.847813: step 6944, loss 0.253473, acc 0.875\n",
      "2018-05-04T15:58:32.924225: step 6945, loss 0.265648, acc 0.890625\n",
      "2018-05-04T15:58:33.980229: step 6946, loss 0.192274, acc 0.921875\n",
      "2018-05-04T15:58:35.033742: step 6947, loss 0.367088, acc 0.890625\n",
      "2018-05-04T15:58:36.076535: step 6948, loss 0.345236, acc 0.8125\n",
      "2018-05-04T15:58:37.131790: step 6949, loss 0.237475, acc 0.90625\n",
      "2018-05-04T15:58:38.132966: step 6950, loss 0.316956, acc 0.859375\n",
      "2018-05-04T15:58:39.240703: step 6951, loss 0.240124, acc 0.890625\n",
      "2018-05-04T15:58:40.279584: step 6952, loss 0.210328, acc 0.9375\n",
      "2018-05-04T15:58:41.340970: step 6953, loss 0.251529, acc 0.921875\n",
      "2018-05-04T15:58:42.325539: step 6954, loss 0.222402, acc 0.90625\n",
      "2018-05-04T15:58:43.273428: step 6955, loss 0.326267, acc 0.921875\n",
      "2018-05-04T15:58:44.267910: step 6956, loss 0.300557, acc 0.90625\n",
      "2018-05-04T15:58:45.283393: step 6957, loss 0.157254, acc 0.9375\n",
      "2018-05-04T15:58:46.323678: step 6958, loss 0.29529, acc 0.90625\n",
      "2018-05-04T15:58:47.305105: step 6959, loss 0.202583, acc 0.90625\n",
      "2018-05-04T15:58:48.316566: step 6960, loss 0.217004, acc 0.953125\n",
      "2018-05-04T15:58:49.305952: step 6961, loss 0.25332, acc 0.90625\n",
      "2018-05-04T15:58:50.286979: step 6962, loss 0.412171, acc 0.78125\n",
      "2018-05-04T15:58:51.278738: step 6963, loss 0.31138, acc 0.859375\n",
      "2018-05-04T15:58:52.284723: step 6964, loss 0.260379, acc 0.859375\n",
      "2018-05-04T15:58:53.346091: step 6965, loss 0.365223, acc 0.875\n",
      "2018-05-04T15:58:54.311512: step 6966, loss 0.441324, acc 0.84375\n",
      "2018-05-04T15:58:55.279098: step 6967, loss 0.183076, acc 0.921875\n",
      "2018-05-04T15:58:56.286022: step 6968, loss 0.347951, acc 0.84375\n",
      "2018-05-04T15:58:57.281329: step 6969, loss 0.230275, acc 0.9375\n",
      "2018-05-04T15:58:58.281755: step 6970, loss 0.314481, acc 0.90625\n",
      "2018-05-04T15:58:59.286383: step 6971, loss 0.322539, acc 0.84375\n",
      "2018-05-04T15:59:00.282860: step 6972, loss 0.197418, acc 0.921875\n",
      "2018-05-04T15:59:01.287143: step 6973, loss 0.384588, acc 0.875\n",
      "2018-05-04T15:59:02.361865: step 6974, loss 0.365398, acc 0.84375\n",
      "2018-05-04T15:59:03.330049: step 6975, loss 0.349792, acc 0.875\n",
      "2018-05-04T15:59:04.307729: step 6976, loss 0.282337, acc 0.859375\n",
      "2018-05-04T15:59:05.318739: step 6977, loss 0.25842, acc 0.859375\n",
      "2018-05-04T15:59:06.280828: step 6978, loss 0.274711, acc 0.890625\n",
      "2018-05-04T15:59:07.273233: step 6979, loss 0.408826, acc 0.796875\n",
      "2018-05-04T15:59:08.285722: step 6980, loss 0.276293, acc 0.890625\n",
      "2018-05-04T15:59:09.309785: step 6981, loss 0.444663, acc 0.828125\n",
      "2018-05-04T15:59:10.312332: step 6982, loss 0.304456, acc 0.828125\n",
      "2018-05-04T15:59:11.336112: step 6983, loss 0.363848, acc 0.859375\n",
      "2018-05-04T15:59:12.345170: step 6984, loss 0.328091, acc 0.90625\n",
      "2018-05-04T15:59:13.383668: step 6985, loss 0.469114, acc 0.828125\n",
      "2018-05-04T15:59:14.376143: step 6986, loss 0.293493, acc 0.875\n",
      "2018-05-04T15:59:15.348880: step 6987, loss 0.211473, acc 0.9375\n",
      "2018-05-04T15:59:16.392295: step 6988, loss 0.237773, acc 0.921875\n",
      "2018-05-04T15:59:17.431183: step 6989, loss 0.20241, acc 0.921875\n",
      "2018-05-04T15:59:18.434137: step 6990, loss 0.359495, acc 0.875\n",
      "2018-05-04T15:59:19.427768: step 6991, loss 0.2433, acc 0.90625\n",
      "2018-05-04T15:59:20.492240: step 6992, loss 0.183182, acc 0.9375\n",
      "2018-05-04T15:59:21.484651: step 6993, loss 0.273458, acc 0.875\n",
      "2018-05-04T15:59:22.484335: step 6994, loss 0.313918, acc 0.875\n",
      "2018-05-04T15:59:23.517737: step 6995, loss 0.287849, acc 0.90625\n",
      "2018-05-04T15:59:24.527812: step 6996, loss 0.22118, acc 0.9375\n",
      "2018-05-04T15:59:25.542955: step 6997, loss 0.361658, acc 0.84375\n",
      "2018-05-04T15:59:26.545497: step 6998, loss 0.319437, acc 0.84375\n",
      "2018-05-04T15:59:27.548930: step 6999, loss 0.272216, acc 0.90625\n",
      "2018-05-04T15:59:28.645769: step 7000, loss 0.216605, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T15:59:30.979778: step 7000, loss 0.247304, acc 0.906\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-7000\n",
      "\n",
      "2018-05-04T15:59:32.162475: step 7001, loss 0.374107, acc 0.890625\n",
      "2018-05-04T15:59:33.187513: step 7002, loss 0.288378, acc 0.875\n",
      "2018-05-04T15:59:34.260341: step 7003, loss 0.293137, acc 0.859375\n",
      "2018-05-04T15:59:35.262507: step 7004, loss 0.24302, acc 0.890625\n",
      "2018-05-04T15:59:36.253163: step 7005, loss 0.296412, acc 0.921875\n",
      "2018-05-04T15:59:37.240306: step 7006, loss 0.324288, acc 0.828125\n",
      "2018-05-04T15:59:38.231952: step 7007, loss 0.345321, acc 0.84375\n",
      "2018-05-04T15:59:39.261744: step 7008, loss 0.260385, acc 0.875\n",
      "2018-05-04T15:59:40.307753: step 7009, loss 0.208225, acc 0.890625\n",
      "2018-05-04T15:59:41.416970: step 7010, loss 0.214465, acc 0.90625\n",
      "2018-05-04T15:59:42.437973: step 7011, loss 0.218133, acc 0.9375\n",
      "2018-05-04T15:59:43.456854: step 7012, loss 0.268596, acc 0.875\n",
      "2018-05-04T15:59:44.492615: step 7013, loss 0.365411, acc 0.84375\n",
      "2018-05-04T15:59:45.602670: step 7014, loss 0.436408, acc 0.796875\n",
      "2018-05-04T15:59:46.633316: step 7015, loss 0.158699, acc 0.9375\n",
      "2018-05-04T15:59:47.642939: step 7016, loss 0.197925, acc 0.921875\n",
      "2018-05-04T15:59:48.648343: step 7017, loss 0.412004, acc 0.84375\n",
      "2018-05-04T15:59:49.707595: step 7018, loss 0.193275, acc 0.953125\n",
      "2018-05-04T15:59:50.712482: step 7019, loss 0.238339, acc 0.953125\n",
      "2018-05-04T15:59:51.707819: step 7020, loss 0.317962, acc 0.828125\n",
      "2018-05-04T15:59:52.797063: step 7021, loss 0.217283, acc 0.96875\n",
      "2018-05-04T15:59:53.811745: step 7022, loss 0.333437, acc 0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T15:59:54.885459: step 7023, loss 0.276511, acc 0.84375\n",
      "2018-05-04T15:59:55.887170: step 7024, loss 0.289977, acc 0.859375\n",
      "2018-05-04T15:59:56.964049: step 7025, loss 0.433397, acc 0.875\n",
      "2018-05-04T15:59:57.979559: step 7026, loss 0.297912, acc 0.84375\n",
      "2018-05-04T15:59:58.994949: step 7027, loss 0.314171, acc 0.859375\n",
      "2018-05-04T16:00:00.091913: step 7028, loss 0.218602, acc 0.921875\n",
      "2018-05-04T16:00:01.120032: step 7029, loss 0.140216, acc 0.984375\n",
      "2018-05-04T16:00:02.125848: step 7030, loss 0.355335, acc 0.890625\n",
      "2018-05-04T16:00:03.137784: step 7031, loss 0.296068, acc 0.890625\n",
      "2018-05-04T16:00:04.225528: step 7032, loss 0.250098, acc 0.84375\n",
      "2018-05-04T16:00:05.255773: step 7033, loss 0.307644, acc 0.875\n",
      "2018-05-04T16:00:06.296359: step 7034, loss 0.184782, acc 0.90625\n",
      "2018-05-04T16:00:07.313116: step 7035, loss 0.421138, acc 0.734375\n",
      "2018-05-04T16:00:08.386521: step 7036, loss 0.300664, acc 0.875\n",
      "2018-05-04T16:00:09.448924: step 7037, loss 0.256386, acc 0.90625\n",
      "2018-05-04T16:00:10.443088: step 7038, loss 0.375118, acc 0.859375\n",
      "2018-05-04T16:00:11.443622: step 7039, loss 0.246033, acc 0.890625\n",
      "2018-05-04T16:00:12.488531: step 7040, loss 0.337357, acc 0.859375\n",
      "2018-05-04T16:00:13.505972: step 7041, loss 0.221632, acc 0.90625\n",
      "2018-05-04T16:00:14.530102: step 7042, loss 0.262542, acc 0.890625\n",
      "2018-05-04T16:00:15.604923: step 7043, loss 0.306338, acc 0.84375\n",
      "2018-05-04T16:00:16.611937: step 7044, loss 0.300379, acc 0.875\n",
      "2018-05-04T16:00:17.708625: step 7045, loss 0.273678, acc 0.890625\n",
      "2018-05-04T16:00:18.757154: step 7046, loss 0.301409, acc 0.875\n",
      "2018-05-04T16:00:19.857856: step 7047, loss 0.29848, acc 0.890625\n",
      "2018-05-04T16:00:20.875709: step 7048, loss 0.263991, acc 0.921875\n",
      "2018-05-04T16:00:21.968948: step 7049, loss 0.496768, acc 0.828125\n",
      "2018-05-04T16:00:22.971453: step 7050, loss 0.421754, acc 0.859375\n",
      "2018-05-04T16:00:23.978244: step 7051, loss 0.406523, acc 0.84375\n",
      "2018-05-04T16:00:25.076033: step 7052, loss 0.345305, acc 0.859375\n",
      "2018-05-04T16:00:26.149091: step 7053, loss 0.283271, acc 0.84375\n",
      "2018-05-04T16:00:27.211482: step 7054, loss 0.1582, acc 0.953125\n",
      "2018-05-04T16:00:28.189581: step 7055, loss 0.34959, acc 0.828125\n",
      "2018-05-04T16:00:29.174472: step 7056, loss 0.250438, acc 0.859375\n",
      "2018-05-04T16:00:30.242187: step 7057, loss 0.336204, acc 0.859375\n",
      "2018-05-04T16:00:31.322040: step 7058, loss 0.365409, acc 0.84375\n",
      "2018-05-04T16:00:32.344469: step 7059, loss 0.245104, acc 0.890625\n",
      "2018-05-04T16:00:33.403037: step 7060, loss 0.457773, acc 0.8125\n",
      "2018-05-04T16:00:34.417376: step 7061, loss 0.292462, acc 0.90625\n",
      "2018-05-04T16:00:35.491290: step 7062, loss 0.21553, acc 0.921875\n",
      "2018-05-04T16:00:36.609583: step 7063, loss 0.239543, acc 0.90625\n",
      "2018-05-04T16:00:37.623326: step 7064, loss 0.260395, acc 0.9375\n",
      "2018-05-04T16:00:38.714368: step 7065, loss 0.39603, acc 0.796875\n",
      "2018-05-04T16:00:39.722743: step 7066, loss 0.361766, acc 0.828125\n",
      "2018-05-04T16:00:40.821605: step 7067, loss 0.273392, acc 0.90625\n",
      "2018-05-04T16:00:41.916549: step 7068, loss 0.242299, acc 0.9375\n",
      "2018-05-04T16:00:42.989779: step 7069, loss 0.238366, acc 0.921875\n",
      "2018-05-04T16:00:44.051984: step 7070, loss 0.280715, acc 0.875\n",
      "2018-05-04T16:00:45.077128: step 7071, loss 0.259791, acc 0.921875\n",
      "2018-05-04T16:00:46.132013: step 7072, loss 0.23716, acc 0.90625\n",
      "2018-05-04T16:00:47.127108: step 7073, loss 0.232704, acc 0.875\n",
      "2018-05-04T16:00:48.168926: step 7074, loss 0.348157, acc 0.84375\n",
      "2018-05-04T16:00:49.144933: step 7075, loss 0.302237, acc 0.875\n",
      "2018-05-04T16:00:50.210825: step 7076, loss 0.370146, acc 0.796875\n",
      "2018-05-04T16:00:51.275170: step 7077, loss 0.338619, acc 0.859375\n",
      "2018-05-04T16:00:52.297876: step 7078, loss 0.293181, acc 0.84375\n",
      "2018-05-04T16:00:53.381340: step 7079, loss 0.349532, acc 0.875\n",
      "2018-05-04T16:00:54.438591: step 7080, loss 0.334998, acc 0.828125\n",
      "2018-05-04T16:00:55.501196: step 7081, loss 0.255533, acc 0.828125\n",
      "2018-05-04T16:00:56.532267: step 7082, loss 0.334903, acc 0.859375\n",
      "2018-05-04T16:00:57.548199: step 7083, loss 0.274683, acc 0.875\n",
      "2018-05-04T16:00:58.518675: step 7084, loss 0.332225, acc 0.828125\n",
      "2018-05-04T16:00:59.594579: step 7085, loss 0.271399, acc 0.921875\n",
      "2018-05-04T16:01:00.625172: step 7086, loss 0.415898, acc 0.828125\n",
      "2018-05-04T16:01:01.682729: step 7087, loss 0.261607, acc 0.859375\n",
      "2018-05-04T16:01:02.749874: step 7088, loss 0.338734, acc 0.859375\n",
      "2018-05-04T16:01:03.832331: step 7089, loss 0.31788, acc 0.8125\n",
      "2018-05-04T16:01:04.844347: step 7090, loss 0.356691, acc 0.84375\n",
      "2018-05-04T16:01:05.904389: step 7091, loss 0.258213, acc 0.90625\n",
      "2018-05-04T16:01:06.955052: step 7092, loss 0.335749, acc 0.859375\n",
      "2018-05-04T16:01:07.948715: step 7093, loss 0.238644, acc 0.875\n",
      "2018-05-04T16:01:09.018849: step 7094, loss 0.257179, acc 0.921875\n",
      "2018-05-04T16:01:09.974318: step 7095, loss 0.28258, acc 0.890625\n",
      "2018-05-04T16:01:11.050491: step 7096, loss 0.36798, acc 0.796875\n",
      "2018-05-04T16:01:12.089815: step 7097, loss 0.295443, acc 0.875\n",
      "2018-05-04T16:01:13.113745: step 7098, loss 0.319963, acc 0.875\n",
      "2018-05-04T16:01:14.206545: step 7099, loss 0.363189, acc 0.796875\n",
      "2018-05-04T16:01:15.257305: step 7100, loss 0.243554, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T16:01:17.782484: step 7100, loss 0.255613, acc 0.918\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-7100\n",
      "\n",
      "2018-05-04T16:01:18.893794: step 7101, loss 0.214172, acc 0.921875\n",
      "2018-05-04T16:01:19.951168: step 7102, loss 0.210877, acc 0.890625\n",
      "2018-05-04T16:01:21.109595: step 7103, loss 0.177775, acc 0.9375\n",
      "2018-05-04T16:01:22.187507: step 7104, loss 0.284213, acc 0.875\n",
      "2018-05-04T16:01:23.278366: step 7105, loss 0.222358, acc 0.921875\n",
      "2018-05-04T16:01:24.337184: step 7106, loss 0.212395, acc 0.90625\n",
      "2018-05-04T16:01:25.340917: step 7107, loss 0.335505, acc 0.84375\n",
      "2018-05-04T16:01:26.364950: step 7108, loss 0.33711, acc 0.90625\n",
      "2018-05-04T16:01:27.396424: step 7109, loss 0.365702, acc 0.84375\n",
      "2018-05-04T16:01:28.421135: step 7110, loss 0.162161, acc 0.953125\n",
      "2018-05-04T16:01:29.452068: step 7111, loss 0.298126, acc 0.875\n",
      "2018-05-04T16:01:30.471398: step 7112, loss 0.246564, acc 0.890625\n",
      "2018-05-04T16:01:31.492885: step 7113, loss 0.272269, acc 0.921875\n",
      "2018-05-04T16:01:32.507590: step 7114, loss 0.259499, acc 0.90625\n",
      "2018-05-04T16:01:33.628468: step 7115, loss 0.233277, acc 0.90625\n",
      "2018-05-04T16:01:34.714382: step 7116, loss 0.239202, acc 0.875\n",
      "2018-05-04T16:01:35.809874: step 7117, loss 0.206487, acc 0.90625\n",
      "2018-05-04T16:01:36.897413: step 7118, loss 0.224633, acc 0.9375\n",
      "2018-05-04T16:01:37.949174: step 7119, loss 0.27508, acc 0.875\n",
      "2018-05-04T16:01:38.978668: step 7120, loss 0.341308, acc 0.890625\n",
      "2018-05-04T16:01:40.028834: step 7121, loss 0.272985, acc 0.90625\n",
      "2018-05-04T16:01:41.116157: step 7122, loss 0.376139, acc 0.84375\n",
      "2018-05-04T16:01:42.220084: step 7123, loss 0.192338, acc 0.9375\n",
      "2018-05-04T16:01:43.259066: step 7124, loss 0.277178, acc 0.90625\n",
      "2018-05-04T16:01:44.352868: step 7125, loss 0.219446, acc 0.890625\n",
      "2018-05-04T16:01:45.400860: step 7126, loss 0.221821, acc 0.90625\n",
      "2018-05-04T16:01:46.404483: step 7127, loss 0.2506, acc 0.90625\n",
      "2018-05-04T16:01:47.463750: step 7128, loss 0.287539, acc 0.84375\n",
      "2018-05-04T16:01:48.464170: step 7129, loss 0.284222, acc 0.875\n",
      "2018-05-04T16:01:49.468723: step 7130, loss 0.243094, acc 0.890625\n",
      "2018-05-04T16:01:50.460110: step 7131, loss 0.27775, acc 0.84375\n",
      "2018-05-04T16:01:51.534429: step 7132, loss 0.363888, acc 0.859375\n",
      "2018-05-04T16:01:52.549476: step 7133, loss 0.427309, acc 0.84375\n",
      "2018-05-04T16:01:53.598244: step 7134, loss 0.315844, acc 0.859375\n",
      "2018-05-04T16:01:54.630744: step 7135, loss 0.206704, acc 0.9375\n",
      "2018-05-04T16:01:55.670793: step 7136, loss 0.31902, acc 0.890625\n",
      "2018-05-04T16:01:56.692022: step 7137, loss 0.381147, acc 0.796875\n",
      "2018-05-04T16:01:57.697584: step 7138, loss 0.2767, acc 0.828125\n",
      "2018-05-04T16:01:58.696750: step 7139, loss 0.413801, acc 0.84375\n",
      "2018-05-04T16:01:59.709208: step 7140, loss 0.36724, acc 0.859375\n",
      "2018-05-04T16:02:00.712429: step 7141, loss 0.268417, acc 0.875\n",
      "2018-05-04T16:02:01.741781: step 7142, loss 0.204412, acc 0.890625\n",
      "2018-05-04T16:02:02.754259: step 7143, loss 0.394398, acc 0.875\n",
      "2018-05-04T16:02:03.784112: step 7144, loss 0.282548, acc 0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T16:02:04.791836: step 7145, loss 0.271406, acc 0.84375\n",
      "2018-05-04T16:02:05.833875: step 7146, loss 0.314026, acc 0.8125\n",
      "2018-05-04T16:02:06.928871: step 7147, loss 0.241249, acc 0.921875\n",
      "2018-05-04T16:02:07.944333: step 7148, loss 0.361423, acc 0.859375\n",
      "2018-05-04T16:02:08.942632: step 7149, loss 0.239688, acc 0.90625\n",
      "2018-05-04T16:02:10.001864: step 7150, loss 0.270206, acc 0.921875\n",
      "2018-05-04T16:02:11.033804: step 7151, loss 0.383194, acc 0.875\n",
      "2018-05-04T16:02:12.092724: step 7152, loss 0.292714, acc 0.875\n",
      "2018-05-04T16:02:13.133029: step 7153, loss 0.339758, acc 0.84375\n",
      "2018-05-04T16:02:14.168209: step 7154, loss 0.230409, acc 0.921875\n",
      "2018-05-04T16:02:15.192911: step 7155, loss 0.218631, acc 0.921875\n",
      "2018-05-04T16:02:16.256640: step 7156, loss 0.186703, acc 0.875\n",
      "2018-05-04T16:02:17.304380: step 7157, loss 0.39804, acc 0.875\n",
      "2018-05-04T16:02:18.337733: step 7158, loss 0.266484, acc 0.890625\n",
      "2018-05-04T16:02:19.361305: step 7159, loss 0.257321, acc 0.90625\n",
      "2018-05-04T16:02:20.392366: step 7160, loss 0.301911, acc 0.875\n",
      "2018-05-04T16:02:21.437417: step 7161, loss 0.219938, acc 0.9375\n",
      "2018-05-04T16:02:22.456470: step 7162, loss 0.300869, acc 0.890625\n",
      "2018-05-04T16:02:23.467455: step 7163, loss 0.200023, acc 0.90625\n",
      "2018-05-04T16:02:24.483127: step 7164, loss 0.340709, acc 0.84375\n",
      "2018-05-04T16:02:25.485586: step 7165, loss 0.230978, acc 0.921875\n",
      "2018-05-04T16:02:26.576005: step 7166, loss 0.137438, acc 0.96875\n",
      "2018-05-04T16:02:27.607833: step 7167, loss 0.185548, acc 0.9375\n",
      "2018-05-04T16:02:28.649798: step 7168, loss 0.232668, acc 0.921875\n",
      "2018-05-04T16:02:29.722149: step 7169, loss 0.354149, acc 0.84375\n",
      "2018-05-04T16:02:30.769703: step 7170, loss 0.295279, acc 0.875\n",
      "2018-05-04T16:02:31.810735: step 7171, loss 0.286007, acc 0.875\n",
      "2018-05-04T16:02:32.833794: step 7172, loss 0.291994, acc 0.859375\n",
      "2018-05-04T16:02:33.861275: step 7173, loss 0.287688, acc 0.84375\n",
      "2018-05-04T16:02:34.875603: step 7174, loss 0.334955, acc 0.890625\n",
      "2018-05-04T16:02:35.913723: step 7175, loss 0.214302, acc 0.921875\n",
      "2018-05-04T16:02:36.936626: step 7176, loss 0.264651, acc 0.90625\n",
      "2018-05-04T16:02:37.971445: step 7177, loss 0.181842, acc 0.921875\n",
      "2018-05-04T16:02:39.001493: step 7178, loss 0.32693, acc 0.890625\n",
      "2018-05-04T16:02:40.009967: step 7179, loss 0.339669, acc 0.828125\n",
      "2018-05-04T16:02:41.045352: step 7180, loss 0.317525, acc 0.90625\n",
      "2018-05-04T16:02:42.075013: step 7181, loss 0.198387, acc 0.921875\n",
      "2018-05-04T16:02:43.054042: step 7182, loss 0.224158, acc 0.90625\n",
      "2018-05-04T16:02:44.061698: step 7183, loss 0.304029, acc 0.859375\n",
      "2018-05-04T16:02:45.095758: step 7184, loss 0.353915, acc 0.8125\n",
      "2018-05-04T16:02:46.121833: step 7185, loss 0.207643, acc 0.875\n",
      "2018-05-04T16:02:47.169507: step 7186, loss 0.266112, acc 0.921875\n",
      "2018-05-04T16:02:48.183732: step 7187, loss 0.19744, acc 0.953125\n",
      "2018-05-04T16:02:49.210042: step 7188, loss 0.219956, acc 0.9375\n",
      "2018-05-04T16:02:50.292170: step 7189, loss 0.193301, acc 0.90625\n",
      "2018-05-04T16:02:51.308676: step 7190, loss 0.302532, acc 0.875\n",
      "2018-05-04T16:02:52.390050: step 7191, loss 0.228663, acc 0.90625\n",
      "2018-05-04T16:02:53.396990: step 7192, loss 0.528693, acc 0.828125\n",
      "2018-05-04T16:02:54.433280: step 7193, loss 0.472712, acc 0.78125\n",
      "2018-05-04T16:02:55.466068: step 7194, loss 0.311957, acc 0.890625\n",
      "2018-05-04T16:02:56.490966: step 7195, loss 0.196488, acc 0.921875\n",
      "2018-05-04T16:02:57.500437: step 7196, loss 0.141705, acc 0.96875\n",
      "2018-05-04T16:02:58.509036: step 7197, loss 0.200011, acc 0.953125\n",
      "2018-05-04T16:02:59.541334: step 7198, loss 0.189617, acc 0.90625\n",
      "2018-05-04T16:03:00.574363: step 7199, loss 0.376615, acc 0.84375\n",
      "2018-05-04T16:03:01.575757: step 7200, loss 0.364188, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T16:03:03.864537: step 7200, loss 0.319667, acc 0.882\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-7200\n",
      "\n",
      "2018-05-04T16:03:04.971101: step 7201, loss 0.483552, acc 0.828125\n",
      "2018-05-04T16:03:05.986284: step 7202, loss 0.356224, acc 0.828125\n",
      "2018-05-04T16:03:07.006257: step 7203, loss 0.33901, acc 0.890625\n",
      "2018-05-04T16:03:08.000650: step 7204, loss 0.321689, acc 0.828125\n",
      "2018-05-04T16:03:08.982570: step 7205, loss 0.276041, acc 0.921875\n",
      "2018-05-04T16:03:09.991616: step 7206, loss 0.162583, acc 0.890625\n",
      "2018-05-04T16:03:10.992530: step 7207, loss 0.27945, acc 0.859375\n",
      "2018-05-04T16:03:11.967576: step 7208, loss 0.229629, acc 0.875\n",
      "2018-05-04T16:03:12.994277: step 7209, loss 0.352196, acc 0.859375\n",
      "2018-05-04T16:03:14.019112: step 7210, loss 0.458806, acc 0.78125\n",
      "2018-05-04T16:03:15.043368: step 7211, loss 0.420035, acc 0.84375\n",
      "2018-05-04T16:03:16.063232: step 7212, loss 0.192874, acc 0.96875\n",
      "2018-05-04T16:03:17.064486: step 7213, loss 0.257833, acc 0.890625\n",
      "2018-05-04T16:03:18.075905: step 7214, loss 0.194095, acc 0.90625\n",
      "2018-05-04T16:03:19.072887: step 7215, loss 0.336676, acc 0.828125\n",
      "2018-05-04T16:03:20.050504: step 7216, loss 0.338295, acc 0.890625\n",
      "2018-05-04T16:03:21.042855: step 7217, loss 0.452823, acc 0.8125\n",
      "2018-05-04T16:03:22.037907: step 7218, loss 0.258937, acc 0.890625\n",
      "2018-05-04T16:03:23.020890: step 7219, loss 0.363967, acc 0.875\n",
      "2018-05-04T16:03:24.041622: step 7220, loss 0.275696, acc 0.90625\n",
      "2018-05-04T16:03:25.110194: step 7221, loss 0.249411, acc 0.890625\n",
      "2018-05-04T16:03:26.099302: step 7222, loss 0.224651, acc 0.921875\n",
      "2018-05-04T16:03:27.108252: step 7223, loss 0.238041, acc 0.921875\n",
      "2018-05-04T16:03:28.092418: step 7224, loss 0.40196, acc 0.84375\n",
      "2018-05-04T16:03:29.159061: step 7225, loss 0.376869, acc 0.84375\n",
      "2018-05-04T16:03:30.151275: step 7226, loss 0.168209, acc 0.984375\n",
      "2018-05-04T16:03:31.190890: step 7227, loss 0.23424, acc 0.90625\n",
      "2018-05-04T16:03:32.219278: step 7228, loss 0.330993, acc 0.859375\n",
      "2018-05-04T16:03:33.232742: step 7229, loss 0.308225, acc 0.890625\n",
      "2018-05-04T16:03:34.261965: step 7230, loss 0.211471, acc 0.875\n",
      "2018-05-04T16:03:35.219109: step 7231, loss 0.213578, acc 0.90625\n",
      "2018-05-04T16:03:36.187593: step 7232, loss 0.196791, acc 0.921875\n",
      "2018-05-04T16:03:37.181707: step 7233, loss 0.305089, acc 0.859375\n",
      "2018-05-04T16:03:38.166349: step 7234, loss 0.235139, acc 0.90625\n",
      "2018-05-04T16:03:39.214087: step 7235, loss 0.268566, acc 0.875\n",
      "2018-05-04T16:03:40.191498: step 7236, loss 0.205178, acc 0.90625\n",
      "2018-05-04T16:03:41.164504: step 7237, loss 0.245525, acc 0.890625\n",
      "2018-05-04T16:03:42.211922: step 7238, loss 0.310996, acc 0.875\n",
      "2018-05-04T16:03:43.158419: step 7239, loss 0.291493, acc 0.875\n",
      "2018-05-04T16:03:44.136262: step 7240, loss 0.308191, acc 0.90625\n",
      "2018-05-04T16:03:45.092066: step 7241, loss 0.345369, acc 0.859375\n",
      "2018-05-04T16:03:46.123201: step 7242, loss 0.269888, acc 0.84375\n",
      "2018-05-04T16:03:47.192496: step 7243, loss 0.251007, acc 0.859375\n",
      "2018-05-04T16:03:48.164486: step 7244, loss 0.144076, acc 0.96875\n",
      "2018-05-04T16:03:49.217026: step 7245, loss 0.38055, acc 0.84375\n",
      "2018-05-04T16:03:50.275786: step 7246, loss 0.266003, acc 0.875\n",
      "2018-05-04T16:03:51.239875: step 7247, loss 0.250265, acc 0.859375\n",
      "2018-05-04T16:03:52.212969: step 7248, loss 0.225196, acc 0.9375\n",
      "2018-05-04T16:03:53.157070: step 7249, loss 0.332607, acc 0.859375\n",
      "2018-05-04T16:03:54.181224: step 7250, loss 0.213062, acc 0.921875\n",
      "2018-05-04T16:03:55.229160: step 7251, loss 0.30746, acc 0.859375\n",
      "2018-05-04T16:03:56.281076: step 7252, loss 0.215888, acc 0.90625\n",
      "2018-05-04T16:03:57.299532: step 7253, loss 0.285637, acc 0.890625\n",
      "2018-05-04T16:03:58.286487: step 7254, loss 0.327105, acc 0.84375\n",
      "2018-05-04T16:03:59.240605: step 7255, loss 0.364027, acc 0.890625\n",
      "2018-05-04T16:04:00.229843: step 7256, loss 0.277703, acc 0.90625\n",
      "2018-05-04T16:04:01.224349: step 7257, loss 0.31915, acc 0.84375\n",
      "2018-05-04T16:04:02.169593: step 7258, loss 0.280275, acc 0.875\n",
      "2018-05-04T16:04:03.187508: step 7259, loss 0.322943, acc 0.84375\n",
      "2018-05-04T16:04:04.215467: step 7260, loss 0.259067, acc 0.890625\n",
      "2018-05-04T16:04:05.266739: step 7261, loss 0.251916, acc 0.890625\n",
      "2018-05-04T16:04:06.287517: step 7262, loss 0.273858, acc 0.90625\n",
      "2018-05-04T16:04:07.313954: step 7263, loss 0.304336, acc 0.890625\n",
      "2018-05-04T16:04:08.262684: step 7264, loss 0.317957, acc 0.890625\n",
      "2018-05-04T16:04:09.186110: step 7265, loss 0.167002, acc 0.96875\n",
      "2018-05-04T16:04:10.146216: step 7266, loss 0.18765, acc 0.953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T16:04:11.257081: step 7267, loss 0.292123, acc 0.859375\n",
      "2018-05-04T16:04:12.328028: step 7268, loss 0.332081, acc 0.84375\n",
      "2018-05-04T16:04:13.414284: step 7269, loss 0.179576, acc 0.953125\n",
      "2018-05-04T16:04:14.455224: step 7270, loss 0.223397, acc 0.875\n",
      "2018-05-04T16:04:15.483457: step 7271, loss 0.321876, acc 0.859375\n",
      "2018-05-04T16:04:16.502744: step 7272, loss 0.217642, acc 0.890625\n",
      "2018-05-04T16:04:17.491904: step 7273, loss 0.231416, acc 0.90625\n",
      "2018-05-04T16:04:18.518490: step 7274, loss 0.249957, acc 0.90625\n",
      "2018-05-04T16:04:19.551179: step 7275, loss 0.37451, acc 0.8125\n",
      "2018-05-04T16:04:20.509365: step 7276, loss 0.355797, acc 0.828125\n",
      "2018-05-04T16:04:21.605066: step 7277, loss 0.192764, acc 0.9375\n",
      "2018-05-04T16:04:22.644050: step 7278, loss 0.23551, acc 0.921875\n",
      "2018-05-04T16:04:23.664780: step 7279, loss 0.189886, acc 0.90625\n",
      "2018-05-04T16:04:24.711724: step 7280, loss 0.374947, acc 0.8125\n",
      "2018-05-04T16:04:25.761726: step 7281, loss 0.264462, acc 0.90625\n",
      "2018-05-04T16:04:26.789548: step 7282, loss 0.222827, acc 0.90625\n",
      "2018-05-04T16:04:27.735684: step 7283, loss 0.283604, acc 0.921875\n",
      "2018-05-04T16:04:28.761965: step 7284, loss 0.35473, acc 0.859375\n",
      "2018-05-04T16:04:29.809630: step 7285, loss 0.251896, acc 0.90625\n",
      "2018-05-04T16:04:30.864207: step 7286, loss 0.214069, acc 0.921875\n",
      "2018-05-04T16:04:31.919063: step 7287, loss 0.427009, acc 0.828125\n",
      "2018-05-04T16:04:32.983306: step 7288, loss 0.223696, acc 0.875\n",
      "2018-05-04T16:04:34.122537: step 7289, loss 0.187357, acc 0.921875\n",
      "2018-05-04T16:04:35.235623: step 7290, loss 0.352037, acc 0.859375\n",
      "2018-05-04T16:04:36.315710: step 7291, loss 0.306067, acc 0.84375\n",
      "2018-05-04T16:04:37.375840: step 7292, loss 0.315851, acc 0.875\n",
      "2018-05-04T16:04:38.436207: step 7293, loss 0.232753, acc 0.90625\n",
      "2018-05-04T16:04:39.395785: step 7294, loss 0.31109, acc 0.875\n",
      "2018-05-04T16:04:40.433550: step 7295, loss 0.157741, acc 0.984375\n",
      "2018-05-04T16:04:41.534239: step 7296, loss 0.206628, acc 0.921875\n",
      "2018-05-04T16:04:42.580828: step 7297, loss 0.225638, acc 0.90625\n",
      "2018-05-04T16:04:43.614004: step 7298, loss 0.276985, acc 0.890625\n",
      "2018-05-04T16:04:44.658044: step 7299, loss 0.278069, acc 0.84375\n",
      "2018-05-04T16:04:45.697652: step 7300, loss 0.135526, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T16:04:48.165472: step 7300, loss 0.249261, acc 0.904\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-7300\n",
      "\n",
      "2018-05-04T16:04:49.245761: step 7301, loss 0.193119, acc 0.921875\n",
      "2018-05-04T16:04:50.254003: step 7302, loss 0.187002, acc 0.953125\n",
      "2018-05-04T16:04:51.325869: step 7303, loss 0.276312, acc 0.875\n",
      "2018-05-04T16:04:52.386647: step 7304, loss 0.291601, acc 0.921875\n",
      "2018-05-04T16:04:53.439610: step 7305, loss 0.311735, acc 0.84375\n",
      "2018-05-04T16:04:54.469716: step 7306, loss 0.413308, acc 0.84375\n",
      "2018-05-04T16:04:55.488757: step 7307, loss 0.31701, acc 0.84375\n",
      "2018-05-04T16:04:56.497153: step 7308, loss 0.24873, acc 0.890625\n",
      "2018-05-04T16:04:57.496241: step 7309, loss 0.330216, acc 0.859375\n",
      "2018-05-04T16:04:58.467459: step 7310, loss 0.292266, acc 0.859375\n",
      "2018-05-04T16:04:59.461051: step 7311, loss 0.204646, acc 0.90625\n",
      "2018-05-04T16:05:00.449139: step 7312, loss 0.194712, acc 0.953125\n",
      "2018-05-04T16:05:01.536570: step 7313, loss 0.33171, acc 0.828125\n",
      "2018-05-04T16:05:02.634304: step 7314, loss 0.172936, acc 0.9375\n",
      "2018-05-04T16:05:03.625487: step 7315, loss 0.346567, acc 0.875\n",
      "2018-05-04T16:05:04.628532: step 7316, loss 0.223347, acc 0.890625\n",
      "2018-05-04T16:05:05.738255: step 7317, loss 0.334128, acc 0.84375\n",
      "2018-05-04T16:05:06.732042: step 7318, loss 0.223216, acc 0.921875\n",
      "2018-05-04T16:05:07.713578: step 7319, loss 0.176687, acc 0.9375\n",
      "2018-05-04T16:05:08.706106: step 7320, loss 0.267406, acc 0.890625\n",
      "2018-05-04T16:05:09.696515: step 7321, loss 0.4633, acc 0.8125\n",
      "2018-05-04T16:05:10.774129: step 7322, loss 0.374364, acc 0.828125\n",
      "2018-05-04T16:05:11.803141: step 7323, loss 0.348155, acc 0.84375\n",
      "2018-05-04T16:05:12.858591: step 7324, loss 0.201635, acc 0.890625\n",
      "2018-05-04T16:05:13.852937: step 7325, loss 0.231576, acc 0.90625\n",
      "2018-05-04T16:05:14.827447: step 7326, loss 0.279302, acc 0.890625\n",
      "2018-05-04T16:05:15.824106: step 7327, loss 0.391062, acc 0.828125\n",
      "2018-05-04T16:05:16.850345: step 7328, loss 0.242828, acc 0.890625\n",
      "2018-05-04T16:05:17.919922: step 7329, loss 0.185218, acc 0.90625\n",
      "2018-05-04T16:05:18.933057: step 7330, loss 0.307608, acc 0.890625\n",
      "2018-05-04T16:05:19.961642: step 7331, loss 0.216004, acc 0.953125\n",
      "2018-05-04T16:05:20.971431: step 7332, loss 0.391235, acc 0.78125\n",
      "2018-05-04T16:05:21.968372: step 7333, loss 0.286982, acc 0.890625\n",
      "2018-05-04T16:05:22.953866: step 7334, loss 0.207488, acc 0.90625\n",
      "2018-05-04T16:05:23.928701: step 7335, loss 0.382204, acc 0.84375\n",
      "2018-05-04T16:05:24.951801: step 7336, loss 0.190251, acc 0.921875\n",
      "2018-05-04T16:05:25.977547: step 7337, loss 0.263979, acc 0.90625\n",
      "2018-05-04T16:05:26.992949: step 7338, loss 0.181138, acc 0.921875\n",
      "2018-05-04T16:05:28.041332: step 7339, loss 0.209468, acc 0.921875\n",
      "2018-05-04T16:05:29.025135: step 7340, loss 0.406765, acc 0.890625\n",
      "2018-05-04T16:05:30.033149: step 7341, loss 0.242008, acc 0.9375\n",
      "2018-05-04T16:05:31.038863: step 7342, loss 0.408402, acc 0.828125\n",
      "2018-05-04T16:05:32.107345: step 7343, loss 0.236159, acc 0.921875\n",
      "2018-05-04T16:05:33.111819: step 7344, loss 0.302141, acc 0.84375\n",
      "2018-05-04T16:05:34.127649: step 7345, loss 0.491076, acc 0.890625\n",
      "2018-05-04T16:05:35.111871: step 7346, loss 0.20473, acc 0.953125\n",
      "2018-05-04T16:05:36.118617: step 7347, loss 0.213539, acc 0.90625\n",
      "2018-05-04T16:05:37.118775: step 7348, loss 0.323273, acc 0.859375\n",
      "2018-05-04T16:05:38.108695: step 7349, loss 0.337422, acc 0.859375\n",
      "2018-05-04T16:05:39.185891: step 7350, loss 0.193112, acc 0.90625\n",
      "2018-05-04T16:05:40.165087: step 7351, loss 0.174228, acc 0.9375\n",
      "2018-05-04T16:05:41.140142: step 7352, loss 0.429291, acc 0.765625\n",
      "2018-05-04T16:05:42.125153: step 7353, loss 0.267305, acc 0.890625\n",
      "2018-05-04T16:05:43.141769: step 7354, loss 0.224591, acc 0.875\n",
      "2018-05-04T16:05:44.132682: step 7355, loss 0.325995, acc 0.890625\n",
      "2018-05-04T16:05:45.140152: step 7356, loss 0.128403, acc 0.96875\n",
      "2018-05-04T16:05:46.143817: step 7357, loss 0.462156, acc 0.8125\n",
      "2018-05-04T16:05:47.155433: step 7358, loss 0.270343, acc 0.890625\n",
      "2018-05-04T16:05:48.239402: step 7359, loss 0.20715, acc 0.921875\n",
      "2018-05-04T16:05:49.247955: step 7360, loss 0.562344, acc 0.78125\n",
      "2018-05-04T16:05:50.235521: step 7361, loss 0.193012, acc 0.921875\n",
      "2018-05-04T16:05:51.245926: step 7362, loss 0.249673, acc 0.921875\n",
      "2018-05-04T16:05:52.253263: step 7363, loss 0.342958, acc 0.8125\n",
      "2018-05-04T16:05:53.258319: step 7364, loss 0.191303, acc 0.9375\n",
      "2018-05-04T16:05:54.275722: step 7365, loss 0.334579, acc 0.90625\n",
      "2018-05-04T16:05:55.270766: step 7366, loss 0.243254, acc 0.921875\n",
      "2018-05-04T16:05:56.291651: step 7367, loss 0.178785, acc 0.9375\n",
      "2018-05-04T16:05:57.288589: step 7368, loss 0.253307, acc 0.890625\n",
      "2018-05-04T16:05:58.259864: step 7369, loss 0.388674, acc 0.84375\n",
      "2018-05-04T16:05:59.264388: step 7370, loss 0.312705, acc 0.828125\n",
      "2018-05-04T16:06:00.262915: step 7371, loss 0.309203, acc 0.84375\n",
      "2018-05-04T16:06:01.254801: step 7372, loss 0.289167, acc 0.890625\n",
      "2018-05-04T16:06:02.261067: step 7373, loss 0.270692, acc 0.875\n",
      "2018-05-04T16:06:03.262806: step 7374, loss 0.223783, acc 0.90625\n",
      "2018-05-04T16:06:04.247700: step 7375, loss 0.251142, acc 0.890625\n",
      "2018-05-04T16:06:05.208256: step 7376, loss 0.284292, acc 0.890625\n",
      "2018-05-04T16:06:06.189548: step 7377, loss 0.260021, acc 0.90625\n",
      "2018-05-04T16:06:07.174314: step 7378, loss 0.365303, acc 0.78125\n",
      "2018-05-04T16:06:08.174369: step 7379, loss 0.441419, acc 0.78125\n",
      "2018-05-04T16:06:09.171036: step 7380, loss 0.271203, acc 0.890625\n",
      "2018-05-04T16:06:10.221040: step 7381, loss 0.195384, acc 0.90625\n",
      "2018-05-04T16:06:11.227726: step 7382, loss 0.254453, acc 0.859375\n",
      "2018-05-04T16:06:12.283733: step 7383, loss 0.340353, acc 0.890625\n",
      "2018-05-04T16:06:13.275563: step 7384, loss 0.248205, acc 0.921875\n",
      "2018-05-04T16:06:14.270882: step 7385, loss 0.157316, acc 0.953125\n",
      "2018-05-04T16:06:15.253272: step 7386, loss 0.278154, acc 0.921875\n",
      "2018-05-04T16:06:16.243304: step 7387, loss 0.244804, acc 0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T16:06:17.235040: step 7388, loss 0.158904, acc 0.9375\n",
      "2018-05-04T16:06:18.228846: step 7389, loss 0.325534, acc 0.875\n",
      "2018-05-04T16:06:19.234403: step 7390, loss 0.177124, acc 0.9375\n",
      "2018-05-04T16:06:20.228390: step 7391, loss 0.195413, acc 0.90625\n",
      "2018-05-04T16:06:21.215557: step 7392, loss 0.368389, acc 0.859375\n",
      "2018-05-04T16:06:22.212334: step 7393, loss 0.305583, acc 0.875\n",
      "2018-05-04T16:06:23.206423: step 7394, loss 0.194934, acc 0.953125\n",
      "2018-05-04T16:06:24.319554: step 7395, loss 0.157282, acc 0.9375\n",
      "2018-05-04T16:06:25.328631: step 7396, loss 0.302434, acc 0.859375\n",
      "2018-05-04T16:06:26.356644: step 7397, loss 0.248349, acc 0.890625\n",
      "2018-05-04T16:06:27.318300: step 7398, loss 0.246913, acc 0.90625\n",
      "2018-05-04T16:06:28.281708: step 7399, loss 0.23153, acc 0.890625\n",
      "2018-05-04T16:06:29.265294: step 7400, loss 0.294231, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T16:06:31.916258: step 7400, loss 0.250535, acc 0.9\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-7400\n",
      "\n",
      "2018-05-04T16:06:33.048309: step 7401, loss 0.254752, acc 0.90625\n",
      "2018-05-04T16:06:34.107510: step 7402, loss 0.334476, acc 0.875\n",
      "2018-05-04T16:06:35.161599: step 7403, loss 0.291057, acc 0.84375\n",
      "2018-05-04T16:06:36.250946: step 7404, loss 0.127658, acc 0.953125\n",
      "2018-05-04T16:06:37.303442: step 7405, loss 0.302892, acc 0.90625\n",
      "2018-05-04T16:06:38.314802: step 7406, loss 0.175359, acc 0.9375\n",
      "2018-05-04T16:06:39.355461: step 7407, loss 0.367993, acc 0.84375\n",
      "2018-05-04T16:06:40.380517: step 7408, loss 0.272291, acc 0.890625\n",
      "2018-05-04T16:06:41.389206: step 7409, loss 0.420028, acc 0.859375\n",
      "2018-05-04T16:06:42.399729: step 7410, loss 0.225292, acc 0.859375\n",
      "2018-05-04T16:06:43.409239: step 7411, loss 0.343203, acc 0.921875\n",
      "2018-05-04T16:06:44.401855: step 7412, loss 0.251194, acc 0.890625\n",
      "2018-05-04T16:06:45.408465: step 7413, loss 0.33293, acc 0.875\n",
      "2018-05-04T16:06:46.409368: step 7414, loss 0.250915, acc 0.875\n",
      "2018-05-04T16:06:47.427088: step 7415, loss 0.230937, acc 0.921875\n",
      "2018-05-04T16:06:48.455885: step 7416, loss 0.391882, acc 0.84375\n",
      "2018-05-04T16:06:49.474320: step 7417, loss 0.3052, acc 0.875\n",
      "2018-05-04T16:06:50.495329: step 7418, loss 0.244789, acc 0.921875\n",
      "2018-05-04T16:06:51.519039: step 7419, loss 0.525478, acc 0.734375\n",
      "2018-05-04T16:06:52.580544: step 7420, loss 0.237772, acc 0.890625\n",
      "2018-05-04T16:06:53.585860: step 7421, loss 0.251798, acc 0.859375\n",
      "2018-05-04T16:06:54.586270: step 7422, loss 0.24815, acc 0.875\n",
      "2018-05-04T16:06:55.605171: step 7423, loss 0.295519, acc 0.890625\n",
      "2018-05-04T16:06:56.638859: step 7424, loss 0.267333, acc 0.90625\n",
      "2018-05-04T16:06:57.647658: step 7425, loss 0.350063, acc 0.859375\n",
      "2018-05-04T16:06:58.701215: step 7426, loss 0.286839, acc 0.890625\n",
      "2018-05-04T16:06:59.716064: step 7427, loss 0.32255, acc 0.859375\n",
      "2018-05-04T16:07:00.740265: step 7428, loss 0.229094, acc 0.859375\n",
      "2018-05-04T16:07:01.731442: step 7429, loss 0.387915, acc 0.828125\n",
      "2018-05-04T16:07:02.805630: step 7430, loss 0.235362, acc 0.921875\n",
      "2018-05-04T16:07:03.817980: step 7431, loss 0.264997, acc 0.90625\n",
      "2018-05-04T16:07:04.836197: step 7432, loss 0.306893, acc 0.890625\n",
      "2018-05-04T16:07:05.840245: step 7433, loss 0.418819, acc 0.84375\n",
      "2018-05-04T16:07:06.862378: step 7434, loss 0.394176, acc 0.84375\n",
      "2018-05-04T16:07:07.929600: step 7435, loss 0.417013, acc 0.8125\n",
      "2018-05-04T16:07:08.972117: step 7436, loss 0.267819, acc 0.890625\n",
      "2018-05-04T16:07:09.938156: step 7437, loss 0.277709, acc 0.90625\n",
      "2018-05-04T16:07:10.937874: step 7438, loss 0.350367, acc 0.828125\n",
      "2018-05-04T16:07:12.024748: step 7439, loss 0.286692, acc 0.890625\n",
      "2018-05-04T16:07:13.075531: step 7440, loss 0.304353, acc 0.890625\n",
      "2018-05-04T16:07:14.077867: step 7441, loss 0.410815, acc 0.828125\n",
      "2018-05-04T16:07:15.098602: step 7442, loss 0.288385, acc 0.875\n",
      "2018-05-04T16:07:16.112690: step 7443, loss 0.216072, acc 0.890625\n",
      "2018-05-04T16:07:17.150023: step 7444, loss 0.240952, acc 0.890625\n",
      "2018-05-04T16:07:18.162437: step 7445, loss 0.269398, acc 0.90625\n",
      "2018-05-04T16:07:19.166435: step 7446, loss 0.303557, acc 0.859375\n",
      "2018-05-04T16:07:20.164861: step 7447, loss 0.322538, acc 0.875\n",
      "2018-05-04T16:07:21.213212: step 7448, loss 0.245919, acc 0.90625\n",
      "2018-05-04T16:07:22.249963: step 7449, loss 0.242667, acc 0.890625\n",
      "2018-05-04T16:07:23.281294: step 7450, loss 0.275993, acc 0.90625\n",
      "2018-05-04T16:07:24.337912: step 7451, loss 0.345661, acc 0.90625\n",
      "2018-05-04T16:07:25.406101: step 7452, loss 0.265094, acc 0.875\n",
      "2018-05-04T16:07:26.444407: step 7453, loss 0.365885, acc 0.875\n",
      "2018-05-04T16:07:27.449665: step 7454, loss 0.257039, acc 0.921875\n",
      "2018-05-04T16:07:28.453820: step 7455, loss 0.37007, acc 0.828125\n",
      "2018-05-04T16:07:29.457061: step 7456, loss 0.175607, acc 0.921875\n",
      "2018-05-04T16:07:30.541058: step 7457, loss 0.40608, acc 0.875\n",
      "2018-05-04T16:07:31.557775: step 7458, loss 0.321295, acc 0.90625\n",
      "2018-05-04T16:07:32.607910: step 7459, loss 0.338846, acc 0.796875\n",
      "2018-05-04T16:07:33.749889: step 7460, loss 0.388551, acc 0.796875\n",
      "2018-05-04T16:07:34.840672: step 7461, loss 0.276818, acc 0.90625\n",
      "2018-05-04T16:07:36.019878: step 7462, loss 0.360602, acc 0.890625\n",
      "2018-05-04T16:07:37.095196: step 7463, loss 0.20086, acc 0.890625\n",
      "2018-05-04T16:07:38.145243: step 7464, loss 0.222635, acc 0.90625\n",
      "2018-05-04T16:07:39.173194: step 7465, loss 0.275417, acc 0.890625\n",
      "2018-05-04T16:07:40.233228: step 7466, loss 0.255892, acc 0.890625\n",
      "2018-05-04T16:07:41.274966: step 7467, loss 0.291026, acc 0.859375\n",
      "2018-05-04T16:07:42.307029: step 7468, loss 0.363493, acc 0.84375\n",
      "2018-05-04T16:07:43.339901: step 7469, loss 0.284813, acc 0.90625\n",
      "2018-05-04T16:07:44.382518: step 7470, loss 0.200659, acc 0.90625\n",
      "2018-05-04T16:07:45.412418: step 7471, loss 0.396013, acc 0.875\n",
      "2018-05-04T16:07:46.426167: step 7472, loss 0.182174, acc 0.96875\n",
      "2018-05-04T16:07:47.449519: step 7473, loss 0.419553, acc 0.8125\n",
      "2018-05-04T16:07:48.458450: step 7474, loss 0.331123, acc 0.828125\n",
      "2018-05-04T16:07:49.498901: step 7475, loss 0.35739, acc 0.859375\n",
      "2018-05-04T16:07:50.504873: step 7476, loss 0.407665, acc 0.828125\n",
      "2018-05-04T16:07:51.497507: step 7477, loss 0.192896, acc 0.921875\n",
      "2018-05-04T16:07:52.503801: step 7478, loss 0.407226, acc 0.84375\n",
      "2018-05-04T16:07:53.540216: step 7479, loss 0.257295, acc 0.875\n",
      "2018-05-04T16:07:54.555590: step 7480, loss 0.273226, acc 0.875\n",
      "2018-05-04T16:07:55.577509: step 7481, loss 0.275939, acc 0.875\n",
      "2018-05-04T16:07:56.598510: step 7482, loss 0.191501, acc 0.921875\n",
      "2018-05-04T16:07:57.650250: step 7483, loss 0.335237, acc 0.859375\n",
      "2018-05-04T16:07:58.686878: step 7484, loss 0.359949, acc 0.84375\n",
      "2018-05-04T16:07:59.767126: step 7485, loss 0.200227, acc 0.9375\n",
      "2018-05-04T16:08:00.788241: step 7486, loss 0.283624, acc 0.84375\n",
      "2018-05-04T16:08:01.886963: step 7487, loss 0.268665, acc 0.90625\n",
      "2018-05-04T16:08:02.898015: step 7488, loss 0.138573, acc 0.96875\n",
      "2018-05-04T16:08:03.924964: step 7489, loss 0.272699, acc 0.875\n",
      "2018-05-04T16:08:04.947252: step 7490, loss 0.344623, acc 0.8125\n",
      "2018-05-04T16:08:06.046495: step 7491, loss 0.239528, acc 0.890625\n",
      "2018-05-04T16:08:07.072124: step 7492, loss 0.323741, acc 0.859375\n",
      "2018-05-04T16:08:08.056849: step 7493, loss 0.284393, acc 0.890625\n",
      "2018-05-04T16:08:09.065957: step 7494, loss 0.325314, acc 0.8125\n",
      "2018-05-04T16:08:10.072493: step 7495, loss 0.258509, acc 0.875\n",
      "2018-05-04T16:08:11.097319: step 7496, loss 0.263963, acc 0.890625\n",
      "2018-05-04T16:08:12.110450: step 7497, loss 0.474953, acc 0.828125\n",
      "2018-05-04T16:08:13.116712: step 7498, loss 0.428615, acc 0.8125\n",
      "2018-05-04T16:08:14.143718: step 7499, loss 0.278154, acc 0.90625\n",
      "2018-05-04T16:08:15.172801: step 7500, loss 0.323654, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T16:08:17.424809: step 7500, loss 0.239737, acc 0.912\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-7500\n",
      "\n",
      "2018-05-04T16:08:18.550810: step 7501, loss 0.164056, acc 0.9375\n",
      "2018-05-04T16:08:19.572307: step 7502, loss 0.285927, acc 0.90625\n",
      "2018-05-04T16:08:20.653836: step 7503, loss 0.329231, acc 0.84375\n",
      "2018-05-04T16:08:21.674154: step 7504, loss 0.26256, acc 0.90625\n",
      "2018-05-04T16:08:22.773981: step 7505, loss 0.30145, acc 0.921875\n",
      "2018-05-04T16:08:23.818874: step 7506, loss 0.343592, acc 0.859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T16:08:24.840280: step 7507, loss 0.341011, acc 0.859375\n",
      "2018-05-04T16:08:25.862611: step 7508, loss 0.213652, acc 0.9375\n",
      "2018-05-04T16:08:26.859736: step 7509, loss 0.250574, acc 0.890625\n",
      "2018-05-04T16:08:27.887915: step 7510, loss 0.365317, acc 0.84375\n",
      "2018-05-04T16:08:28.998144: step 7511, loss 0.277395, acc 0.875\n",
      "2018-05-04T16:08:30.018863: step 7512, loss 0.47005, acc 0.828125\n",
      "2018-05-04T16:08:31.019661: step 7513, loss 0.196558, acc 0.90625\n",
      "2018-05-04T16:08:32.031362: step 7514, loss 0.296349, acc 0.875\n",
      "2018-05-04T16:08:33.074189: step 7515, loss 0.252782, acc 0.90625\n",
      "2018-05-04T16:08:34.099355: step 7516, loss 0.312113, acc 0.84375\n",
      "2018-05-04T16:08:35.130480: step 7517, loss 0.282537, acc 0.875\n",
      "2018-05-04T16:08:36.144071: step 7518, loss 0.178104, acc 0.9375\n",
      "2018-05-04T16:08:37.168558: step 7519, loss 0.281613, acc 0.875\n",
      "2018-05-04T16:08:38.189160: step 7520, loss 0.165123, acc 0.953125\n",
      "2018-05-04T16:08:39.213865: step 7521, loss 0.340295, acc 0.859375\n",
      "2018-05-04T16:08:40.252008: step 7522, loss 0.365845, acc 0.8125\n",
      "2018-05-04T16:08:41.319461: step 7523, loss 0.247918, acc 0.84375\n",
      "2018-05-04T16:08:42.356638: step 7524, loss 0.218113, acc 0.9375\n",
      "2018-05-04T16:08:43.397367: step 7525, loss 0.222798, acc 0.890625\n",
      "2018-05-04T16:08:44.424108: step 7526, loss 0.210229, acc 0.90625\n",
      "2018-05-04T16:08:45.431843: step 7527, loss 0.226348, acc 0.890625\n",
      "2018-05-04T16:08:46.444175: step 7528, loss 0.295622, acc 0.859375\n",
      "2018-05-04T16:08:47.459930: step 7529, loss 0.24718, acc 0.875\n",
      "2018-05-04T16:08:48.476575: step 7530, loss 0.384415, acc 0.859375\n",
      "2018-05-04T16:08:49.503113: step 7531, loss 0.206548, acc 0.921875\n",
      "2018-05-04T16:08:50.552025: step 7532, loss 0.298472, acc 0.828125\n",
      "2018-05-04T16:08:51.666550: step 7533, loss 0.285739, acc 0.890625\n",
      "2018-05-04T16:08:52.759701: step 7534, loss 0.220873, acc 0.90625\n",
      "2018-05-04T16:08:53.789282: step 7535, loss 0.257071, acc 0.890625\n",
      "2018-05-04T16:08:54.860827: step 7536, loss 0.235904, acc 0.890625\n",
      "2018-05-04T16:08:55.964402: step 7537, loss 0.281226, acc 0.890625\n",
      "2018-05-04T16:08:56.981139: step 7538, loss 0.300199, acc 0.859375\n",
      "2018-05-04T16:08:58.057756: step 7539, loss 0.344207, acc 0.828125\n",
      "2018-05-04T16:08:59.063426: step 7540, loss 0.243081, acc 0.890625\n",
      "2018-05-04T16:09:00.040274: step 7541, loss 0.212952, acc 0.953125\n",
      "2018-05-04T16:09:01.140475: step 7542, loss 0.23309, acc 0.90625\n",
      "2018-05-04T16:09:02.230372: step 7543, loss 0.158549, acc 0.9375\n",
      "2018-05-04T16:09:03.262884: step 7544, loss 0.316483, acc 0.90625\n",
      "2018-05-04T16:09:04.322001: step 7545, loss 0.239412, acc 0.875\n",
      "2018-05-04T16:09:05.321372: step 7546, loss 0.422286, acc 0.859375\n",
      "2018-05-04T16:09:06.303375: step 7547, loss 0.213071, acc 0.921875\n",
      "2018-05-04T16:09:07.359071: step 7548, loss 0.188457, acc 0.921875\n",
      "2018-05-04T16:09:08.427510: step 7549, loss 0.288238, acc 0.859375\n",
      "2018-05-04T16:09:09.455263: step 7550, loss 0.193777, acc 0.921875\n",
      "2018-05-04T16:09:10.501596: step 7551, loss 0.367562, acc 0.859375\n",
      "2018-05-04T16:09:11.523937: step 7552, loss 0.275287, acc 0.921875\n",
      "2018-05-04T16:09:12.613111: step 7553, loss 0.331017, acc 0.84375\n",
      "2018-05-04T16:09:13.626966: step 7554, loss 0.389332, acc 0.875\n",
      "2018-05-04T16:09:14.642244: step 7555, loss 0.405849, acc 0.859375\n",
      "2018-05-04T16:09:15.723834: step 7556, loss 0.209059, acc 0.9375\n",
      "2018-05-04T16:09:16.730549: step 7557, loss 0.315001, acc 0.890625\n",
      "2018-05-04T16:09:17.759622: step 7558, loss 0.253634, acc 0.90625\n",
      "2018-05-04T16:09:18.768609: step 7559, loss 0.294392, acc 0.875\n",
      "2018-05-04T16:09:19.800185: step 7560, loss 0.210394, acc 0.90625\n",
      "2018-05-04T16:09:20.827355: step 7561, loss 0.31954, acc 0.859375\n",
      "2018-05-04T16:09:21.851055: step 7562, loss 0.286042, acc 0.859375\n",
      "2018-05-04T16:09:22.948927: step 7563, loss 0.392316, acc 0.875\n",
      "2018-05-04T16:09:23.965643: step 7564, loss 0.306111, acc 0.875\n",
      "2018-05-04T16:09:24.997254: step 7565, loss 0.230323, acc 0.921875\n",
      "2018-05-04T16:09:26.068531: step 7566, loss 0.169438, acc 0.9375\n",
      "2018-05-04T16:09:27.126056: step 7567, loss 0.281301, acc 0.828125\n",
      "2018-05-04T16:09:28.188848: step 7568, loss 0.246134, acc 0.890625\n",
      "2018-05-04T16:09:29.259764: step 7569, loss 0.269854, acc 0.921875\n",
      "2018-05-04T16:09:30.404585: step 7570, loss 0.294491, acc 0.859375\n",
      "2018-05-04T16:09:31.399945: step 7571, loss 0.453125, acc 0.84375\n",
      "2018-05-04T16:09:32.442291: step 7572, loss 0.228206, acc 0.9375\n",
      "2018-05-04T16:09:33.537137: step 7573, loss 0.336969, acc 0.875\n",
      "2018-05-04T16:09:34.633114: step 7574, loss 0.240859, acc 0.90625\n",
      "2018-05-04T16:09:35.665020: step 7575, loss 0.343477, acc 0.859375\n",
      "2018-05-04T16:09:36.711705: step 7576, loss 0.231781, acc 0.90625\n",
      "2018-05-04T16:09:37.768450: step 7577, loss 0.303176, acc 0.90625\n",
      "2018-05-04T16:09:38.843687: step 7578, loss 0.222883, acc 0.90625\n",
      "2018-05-04T16:09:39.918872: step 7579, loss 0.232063, acc 0.890625\n",
      "2018-05-04T16:09:40.914613: step 7580, loss 0.276738, acc 0.90625\n",
      "2018-05-04T16:09:41.969942: step 7581, loss 0.384601, acc 0.765625\n",
      "2018-05-04T16:09:42.964977: step 7582, loss 0.406166, acc 0.875\n",
      "2018-05-04T16:09:44.012341: step 7583, loss 0.287285, acc 0.890625\n",
      "2018-05-04T16:09:44.985266: step 7584, loss 0.279743, acc 0.875\n",
      "2018-05-04T16:09:46.037697: step 7585, loss 0.298707, acc 0.875\n",
      "2018-05-04T16:09:47.081233: step 7586, loss 0.195939, acc 0.9375\n",
      "2018-05-04T16:09:48.136405: step 7587, loss 0.20843, acc 0.953125\n",
      "2018-05-04T16:09:49.193880: step 7588, loss 0.389121, acc 0.828125\n",
      "2018-05-04T16:09:50.237435: step 7589, loss 0.252439, acc 0.890625\n",
      "2018-05-04T16:09:51.219680: step 7590, loss 0.191861, acc 0.921875\n",
      "2018-05-04T16:09:52.327210: step 7591, loss 0.240165, acc 0.84375\n",
      "2018-05-04T16:09:53.396449: step 7592, loss 0.295123, acc 0.875\n",
      "2018-05-04T16:09:54.452675: step 7593, loss 0.234197, acc 0.890625\n",
      "2018-05-04T16:09:55.513020: step 7594, loss 0.231879, acc 0.90625\n",
      "2018-05-04T16:09:56.574233: step 7595, loss 0.358215, acc 0.875\n",
      "2018-05-04T16:09:57.628141: step 7596, loss 0.233937, acc 0.921875\n",
      "2018-05-04T16:09:58.661980: step 7597, loss 0.27932, acc 0.875\n",
      "2018-05-04T16:09:59.715362: step 7598, loss 0.197649, acc 0.921875\n",
      "2018-05-04T16:10:00.669729: step 7599, loss 0.264576, acc 0.875\n",
      "2018-05-04T16:10:01.726406: step 7600, loss 0.316652, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T16:10:04.489140: step 7600, loss 0.234905, acc 0.922\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-7600\n",
      "\n",
      "2018-05-04T16:10:05.624116: step 7601, loss 0.311852, acc 0.890625\n",
      "2018-05-04T16:10:06.701105: step 7602, loss 0.246264, acc 0.875\n",
      "2018-05-04T16:10:07.786398: step 7603, loss 0.371093, acc 0.84375\n",
      "2018-05-04T16:10:08.877328: step 7604, loss 0.437927, acc 0.8125\n",
      "2018-05-04T16:10:09.903828: step 7605, loss 0.410996, acc 0.859375\n",
      "2018-05-04T16:10:10.922644: step 7606, loss 0.307675, acc 0.828125\n",
      "2018-05-04T16:10:11.955261: step 7607, loss 0.242543, acc 0.890625\n",
      "2018-05-04T16:10:13.017349: step 7608, loss 0.477753, acc 0.84375\n",
      "2018-05-04T16:10:14.076602: step 7609, loss 0.24877, acc 0.875\n",
      "2018-05-04T16:10:15.094365: step 7610, loss 0.330877, acc 0.796875\n",
      "2018-05-04T16:10:16.100849: step 7611, loss 0.337605, acc 0.875\n",
      "2018-05-04T16:10:17.112317: step 7612, loss 0.352765, acc 0.921875\n",
      "2018-05-04T16:10:18.129137: step 7613, loss 0.361572, acc 0.8125\n",
      "2018-05-04T16:10:19.139691: step 7614, loss 0.296988, acc 0.875\n",
      "2018-05-04T16:10:20.162536: step 7615, loss 0.206278, acc 0.921875\n",
      "2018-05-04T16:10:21.221281: step 7616, loss 0.278994, acc 0.875\n",
      "2018-05-04T16:10:22.344652: step 7617, loss 0.205808, acc 0.953125\n",
      "2018-05-04T16:10:23.336420: step 7618, loss 0.273134, acc 0.90625\n",
      "2018-05-04T16:10:24.333475: step 7619, loss 0.223729, acc 0.890625\n",
      "2018-05-04T16:10:25.319909: step 7620, loss 0.28811, acc 0.828125\n",
      "2018-05-04T16:10:26.317980: step 7621, loss 0.333007, acc 0.796875\n",
      "2018-05-04T16:10:27.322965: step 7622, loss 0.322483, acc 0.84375\n",
      "2018-05-04T16:10:28.344601: step 7623, loss 0.476104, acc 0.8125\n",
      "2018-05-04T16:10:29.365143: step 7624, loss 0.230639, acc 0.921875\n",
      "2018-05-04T16:10:30.354123: step 7625, loss 0.238701, acc 0.90625\n",
      "2018-05-04T16:10:31.370163: step 7626, loss 0.26912, acc 0.890625\n",
      "2018-05-04T16:10:32.477124: step 7627, loss 0.191978, acc 0.9375\n",
      "2018-05-04T16:10:33.547296: step 7628, loss 0.304789, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T16:10:34.641961: step 7629, loss 0.398902, acc 0.828125\n",
      "2018-05-04T16:10:35.741450: step 7630, loss 0.344754, acc 0.859375\n",
      "2018-05-04T16:10:36.874594: step 7631, loss 0.241435, acc 0.90625\n",
      "2018-05-04T16:10:37.950927: step 7632, loss 0.326733, acc 0.875\n",
      "2018-05-04T16:10:38.990384: step 7633, loss 0.441943, acc 0.84375\n",
      "2018-05-04T16:10:40.041523: step 7634, loss 0.377626, acc 0.859375\n",
      "2018-05-04T16:10:41.063247: step 7635, loss 0.310108, acc 0.890625\n",
      "2018-05-04T16:10:42.071378: step 7636, loss 0.417332, acc 0.875\n",
      "2018-05-04T16:10:43.067677: step 7637, loss 0.258247, acc 0.875\n",
      "2018-05-04T16:10:44.073117: step 7638, loss 0.222248, acc 0.859375\n",
      "2018-05-04T16:10:45.157288: step 7639, loss 0.342305, acc 0.875\n",
      "2018-05-04T16:10:46.188326: step 7640, loss 0.177744, acc 0.96875\n",
      "2018-05-04T16:10:47.181251: step 7641, loss 0.392336, acc 0.859375\n",
      "2018-05-04T16:10:48.187561: step 7642, loss 0.22876, acc 0.90625\n",
      "2018-05-04T16:10:49.176932: step 7643, loss 0.207995, acc 0.90625\n",
      "2018-05-04T16:10:50.169495: step 7644, loss 0.362778, acc 0.8125\n",
      "2018-05-04T16:10:51.148948: step 7645, loss 0.211063, acc 0.921875\n",
      "2018-05-04T16:10:52.144745: step 7646, loss 0.238339, acc 0.90625\n",
      "2018-05-04T16:10:53.172196: step 7647, loss 0.263882, acc 0.890625\n",
      "2018-05-04T16:10:54.178069: step 7648, loss 0.384788, acc 0.859375\n",
      "2018-05-04T16:10:55.190024: step 7649, loss 0.359619, acc 0.890625\n",
      "2018-05-04T16:10:56.204200: step 7650, loss 0.225031, acc 0.9375\n",
      "2018-05-04T16:10:57.180401: step 7651, loss 0.371386, acc 0.859375\n",
      "2018-05-04T16:10:58.184582: step 7652, loss 0.459571, acc 0.8125\n",
      "2018-05-04T16:10:59.174120: step 7653, loss 0.21762, acc 0.9375\n",
      "2018-05-04T16:11:00.154910: step 7654, loss 0.419629, acc 0.796875\n",
      "2018-05-04T16:11:01.141896: step 7655, loss 0.481095, acc 0.828125\n",
      "2018-05-04T16:11:02.151376: step 7656, loss 0.293938, acc 0.84375\n",
      "2018-05-04T16:11:03.176759: step 7657, loss 0.202184, acc 0.9375\n",
      "2018-05-04T16:11:04.205206: step 7658, loss 0.195926, acc 0.953125\n",
      "2018-05-04T16:11:05.202754: step 7659, loss 0.317347, acc 0.875\n",
      "2018-05-04T16:11:06.219004: step 7660, loss 0.337326, acc 0.890625\n",
      "2018-05-04T16:11:07.204189: step 7661, loss 0.280607, acc 0.859375\n",
      "2018-05-04T16:11:08.193224: step 7662, loss 0.307025, acc 0.890625\n",
      "2018-05-04T16:11:09.171380: step 7663, loss 0.240846, acc 0.921875\n",
      "2018-05-04T16:11:10.137755: step 7664, loss 0.298804, acc 0.859375\n",
      "2018-05-04T16:11:11.108853: step 7665, loss 0.338539, acc 0.828125\n",
      "2018-05-04T16:11:12.091662: step 7666, loss 0.347237, acc 0.875\n",
      "2018-05-04T16:11:13.066195: step 7667, loss 0.265639, acc 0.90625\n",
      "2018-05-04T16:11:14.092869: step 7668, loss 0.249923, acc 0.890625\n",
      "2018-05-04T16:11:15.098617: step 7669, loss 0.208402, acc 0.90625\n",
      "2018-05-04T16:11:16.092903: step 7670, loss 0.218584, acc 0.875\n",
      "2018-05-04T16:11:17.159606: step 7671, loss 0.295263, acc 0.84375\n",
      "2018-05-04T16:11:18.137822: step 7672, loss 0.220241, acc 0.890625\n",
      "2018-05-04T16:11:19.124043: step 7673, loss 0.214656, acc 0.921875\n",
      "2018-05-04T16:11:20.087359: step 7674, loss 0.255663, acc 0.921875\n",
      "2018-05-04T16:11:21.063545: step 7675, loss 0.237412, acc 0.9375\n",
      "2018-05-04T16:11:22.089718: step 7676, loss 0.268481, acc 0.859375\n",
      "2018-05-04T16:11:23.053721: step 7677, loss 0.180637, acc 0.9375\n",
      "2018-05-04T16:11:24.056993: step 7678, loss 0.351608, acc 0.859375\n",
      "2018-05-04T16:11:25.032271: step 7679, loss 0.266734, acc 0.9375\n",
      "2018-05-04T16:11:26.041347: step 7680, loss 0.324797, acc 0.859375\n",
      "2018-05-04T16:11:27.029933: step 7681, loss 0.183981, acc 0.953125\n",
      "2018-05-04T16:11:28.023257: step 7682, loss 0.328243, acc 0.84375\n",
      "2018-05-04T16:11:29.037190: step 7683, loss 0.257841, acc 0.90625\n",
      "2018-05-04T16:11:30.001377: step 7684, loss 0.368435, acc 0.828125\n",
      "2018-05-04T16:11:30.964422: step 7685, loss 0.282175, acc 0.84375\n",
      "2018-05-04T16:11:31.913838: step 7686, loss 0.219112, acc 0.90625\n",
      "2018-05-04T16:11:32.949965: step 7687, loss 0.341833, acc 0.890625\n",
      "2018-05-04T16:11:33.927974: step 7688, loss 0.246862, acc 0.90625\n",
      "2018-05-04T16:11:34.902177: step 7689, loss 0.280451, acc 0.859375\n",
      "2018-05-04T16:11:35.863496: step 7690, loss 0.285511, acc 0.90625\n",
      "2018-05-04T16:11:36.849335: step 7691, loss 0.395941, acc 0.84375\n",
      "2018-05-04T16:11:37.803157: step 7692, loss 0.352634, acc 0.828125\n",
      "2018-05-04T16:11:38.794614: step 7693, loss 0.207592, acc 0.9375\n",
      "2018-05-04T16:11:39.774756: step 7694, loss 0.427587, acc 0.828125\n",
      "2018-05-04T16:11:40.770220: step 7695, loss 0.201336, acc 0.9375\n",
      "2018-05-04T16:11:41.783381: step 7696, loss 0.247642, acc 0.921875\n",
      "2018-05-04T16:11:42.835130: step 7697, loss 0.36135, acc 0.84375\n",
      "2018-05-04T16:11:43.833144: step 7698, loss 0.224326, acc 0.9375\n",
      "2018-05-04T16:11:44.840320: step 7699, loss 0.199345, acc 0.921875\n",
      "2018-05-04T16:11:45.810812: step 7700, loss 0.269378, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T16:11:47.950271: step 7700, loss 0.230991, acc 0.916\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-7700\n",
      "\n",
      "2018-05-04T16:11:49.093426: step 7701, loss 0.467126, acc 0.8125\n",
      "2018-05-04T16:11:50.049919: step 7702, loss 0.306667, acc 0.828125\n",
      "2018-05-04T16:11:50.996904: step 7703, loss 0.205877, acc 0.890625\n",
      "2018-05-04T16:11:52.004200: step 7704, loss 0.220122, acc 0.90625\n",
      "2018-05-04T16:11:52.998110: step 7705, loss 0.222736, acc 0.9375\n",
      "2018-05-04T16:11:54.000709: step 7706, loss 0.185939, acc 0.890625\n",
      "2018-05-04T16:11:54.993920: step 7707, loss 0.303979, acc 0.921875\n",
      "2018-05-04T16:11:56.059478: step 7708, loss 0.460527, acc 0.78125\n",
      "2018-05-04T16:11:57.032191: step 7709, loss 0.241086, acc 0.859375\n",
      "2018-05-04T16:11:58.000194: step 7710, loss 0.318889, acc 0.890625\n",
      "2018-05-04T16:11:58.967398: step 7711, loss 0.236973, acc 0.875\n",
      "2018-05-04T16:11:59.940785: step 7712, loss 0.424064, acc 0.828125\n",
      "2018-05-04T16:12:00.931208: step 7713, loss 0.274007, acc 0.875\n",
      "2018-05-04T16:12:01.912504: step 7714, loss 0.307983, acc 0.875\n",
      "2018-05-04T16:12:02.936141: step 7715, loss 0.188623, acc 0.953125\n",
      "2018-05-04T16:12:03.932800: step 7716, loss 0.37409, acc 0.84375\n",
      "2018-05-04T16:12:04.990884: step 7717, loss 0.215721, acc 0.90625\n",
      "2018-05-04T16:12:05.962054: step 7718, loss 0.284552, acc 0.828125\n",
      "2018-05-04T16:12:06.952535: step 7719, loss 0.234016, acc 0.875\n",
      "2018-05-04T16:12:07.934028: step 7720, loss 0.142331, acc 0.953125\n",
      "2018-05-04T16:12:08.913398: step 7721, loss 0.261963, acc 0.921875\n",
      "2018-05-04T16:12:09.868769: step 7722, loss 0.314787, acc 0.859375\n",
      "2018-05-04T16:12:10.846431: step 7723, loss 0.345551, acc 0.84375\n",
      "2018-05-04T16:12:11.826155: step 7724, loss 0.322223, acc 0.890625\n",
      "2018-05-04T16:12:12.790543: step 7725, loss 0.34125, acc 0.828125\n",
      "2018-05-04T16:12:13.778307: step 7726, loss 0.22086, acc 0.890625\n",
      "2018-05-04T16:12:14.778040: step 7727, loss 0.347354, acc 0.84375\n",
      "2018-05-04T16:12:15.768515: step 7728, loss 0.15366, acc 0.9375\n",
      "2018-05-04T16:12:16.755816: step 7729, loss 0.256795, acc 0.90625\n",
      "2018-05-04T16:12:17.794434: step 7730, loss 0.205406, acc 0.9375\n",
      "2018-05-04T16:12:18.767234: step 7731, loss 0.272199, acc 0.90625\n",
      "2018-05-04T16:12:19.803505: step 7732, loss 0.188181, acc 0.921875\n",
      "2018-05-04T16:12:20.754995: step 7733, loss 0.258171, acc 0.90625\n",
      "2018-05-04T16:12:21.710876: step 7734, loss 0.318379, acc 0.875\n",
      "2018-05-04T16:12:22.761759: step 7735, loss 0.385457, acc 0.84375\n",
      "2018-05-04T16:12:23.801665: step 7736, loss 0.128694, acc 0.96875\n",
      "2018-05-04T16:12:24.799988: step 7737, loss 0.420604, acc 0.8125\n",
      "2018-05-04T16:12:25.790347: step 7738, loss 0.286897, acc 0.921875\n",
      "2018-05-04T16:12:26.756704: step 7739, loss 0.318307, acc 0.875\n",
      "2018-05-04T16:12:27.785584: step 7740, loss 0.235001, acc 0.921875\n",
      "2018-05-04T16:12:28.860634: step 7741, loss 0.411612, acc 0.828125\n",
      "2018-05-04T16:12:29.850757: step 7742, loss 0.253258, acc 0.90625\n",
      "2018-05-04T16:12:30.829355: step 7743, loss 0.337465, acc 0.859375\n",
      "2018-05-04T16:12:31.819104: step 7744, loss 0.296323, acc 0.890625\n",
      "2018-05-04T16:12:32.805226: step 7745, loss 0.188369, acc 0.9375\n",
      "2018-05-04T16:12:33.845466: step 7746, loss 0.329357, acc 0.84375\n",
      "2018-05-04T16:12:34.803193: step 7747, loss 0.37009, acc 0.828125\n",
      "2018-05-04T16:12:35.755959: step 7748, loss 0.16623, acc 0.96875\n",
      "2018-05-04T16:12:36.792584: step 7749, loss 0.329065, acc 0.84375\n",
      "2018-05-04T16:12:37.788369: step 7750, loss 0.210277, acc 0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T16:12:38.858189: step 7751, loss 0.347252, acc 0.875\n",
      "2018-05-04T16:12:39.837987: step 7752, loss 0.361037, acc 0.828125\n",
      "2018-05-04T16:12:40.886157: step 7753, loss 0.179084, acc 0.9375\n",
      "2018-05-04T16:12:41.891073: step 7754, loss 0.217536, acc 0.921875\n",
      "2018-05-04T16:12:42.931793: step 7755, loss 0.258879, acc 0.90625\n",
      "2018-05-04T16:12:43.980585: step 7756, loss 0.290666, acc 0.90625\n",
      "2018-05-04T16:12:45.020628: step 7757, loss 0.294877, acc 0.84375\n",
      "2018-05-04T16:12:46.060927: step 7758, loss 0.30457, acc 0.890625\n",
      "2018-05-04T16:12:47.028909: step 7759, loss 0.311703, acc 0.859375\n",
      "2018-05-04T16:12:48.085509: step 7760, loss 0.423493, acc 0.84375\n",
      "2018-05-04T16:12:49.084965: step 7761, loss 0.220695, acc 0.953125\n",
      "2018-05-04T16:12:50.109361: step 7762, loss 0.247807, acc 0.890625\n",
      "2018-05-04T16:12:51.207403: step 7763, loss 0.335846, acc 0.8125\n",
      "2018-05-04T16:12:52.256478: step 7764, loss 0.196267, acc 0.9375\n",
      "2018-05-04T16:12:53.232561: step 7765, loss 0.18446, acc 0.9375\n",
      "2018-05-04T16:12:54.205723: step 7766, loss 0.216311, acc 0.890625\n",
      "2018-05-04T16:12:55.183406: step 7767, loss 0.378895, acc 0.8125\n",
      "2018-05-04T16:12:56.252513: step 7768, loss 0.369713, acc 0.875\n",
      "2018-05-04T16:12:57.236652: step 7769, loss 0.191797, acc 0.921875\n",
      "2018-05-04T16:12:58.226700: step 7770, loss 0.317108, acc 0.875\n",
      "2018-05-04T16:12:59.225663: step 7771, loss 0.195534, acc 0.953125\n",
      "2018-05-04T16:13:00.199333: step 7772, loss 0.402949, acc 0.84375\n",
      "2018-05-04T16:13:01.219702: step 7773, loss 0.175931, acc 0.96875\n",
      "2018-05-04T16:13:02.246266: step 7774, loss 0.295843, acc 0.859375\n",
      "2018-05-04T16:13:03.277907: step 7775, loss 0.202624, acc 0.890625\n",
      "2018-05-04T16:13:04.314594: step 7776, loss 0.312047, acc 0.859375\n",
      "2018-05-04T16:13:05.314007: step 7777, loss 0.330593, acc 0.890625\n",
      "2018-05-04T16:13:06.411687: step 7778, loss 0.365369, acc 0.875\n",
      "2018-05-04T16:13:07.442702: step 7779, loss 0.263038, acc 0.90625\n",
      "2018-05-04T16:13:08.525791: step 7780, loss 0.25665, acc 0.890625\n",
      "2018-05-04T16:13:09.585094: step 7781, loss 0.202996, acc 0.9375\n",
      "2018-05-04T16:13:10.653748: step 7782, loss 0.205315, acc 0.96875\n",
      "2018-05-04T16:13:11.707403: step 7783, loss 0.277653, acc 0.875\n",
      "2018-05-04T16:13:12.764009: step 7784, loss 0.268609, acc 0.90625\n",
      "2018-05-04T16:13:13.773607: step 7785, loss 0.317965, acc 0.875\n",
      "2018-05-04T16:13:14.839196: step 7786, loss 0.240913, acc 0.90625\n",
      "2018-05-04T16:13:15.881647: step 7787, loss 0.330435, acc 0.8125\n",
      "2018-05-04T16:13:16.953056: step 7788, loss 0.348617, acc 0.859375\n",
      "2018-05-04T16:13:18.015999: step 7789, loss 0.246791, acc 0.90625\n",
      "2018-05-04T16:13:19.085292: step 7790, loss 0.258162, acc 0.90625\n",
      "2018-05-04T16:13:20.135890: step 7791, loss 0.314486, acc 0.859375\n",
      "2018-05-04T16:13:21.177065: step 7792, loss 0.345645, acc 0.828125\n",
      "2018-05-04T16:13:22.190824: step 7793, loss 0.299799, acc 0.8125\n",
      "2018-05-04T16:13:23.221827: step 7794, loss 0.23711, acc 0.90625\n",
      "2018-05-04T16:13:24.294065: step 7795, loss 0.302948, acc 0.859375\n",
      "2018-05-04T16:13:25.284814: step 7796, loss 0.232607, acc 0.890625\n",
      "2018-05-04T16:13:26.323960: step 7797, loss 0.272946, acc 0.90625\n",
      "2018-05-04T16:13:27.386703: step 7798, loss 0.262029, acc 0.875\n",
      "2018-05-04T16:13:28.649088: step 7799, loss 0.238153, acc 0.90625\n",
      "2018-05-04T16:13:29.659856: step 7800, loss 0.435362, acc 0.796875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T16:13:32.413685: step 7800, loss 0.242941, acc 0.902\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-7800\n",
      "\n",
      "2018-05-04T16:13:33.570517: step 7801, loss 0.229986, acc 0.890625\n",
      "2018-05-04T16:13:34.665841: step 7802, loss 0.24986, acc 0.890625\n",
      "2018-05-04T16:13:35.793137: step 7803, loss 0.283847, acc 0.859375\n",
      "2018-05-04T16:13:36.971020: step 7804, loss 0.152793, acc 0.96875\n",
      "2018-05-04T16:13:38.115763: step 7805, loss 0.247339, acc 0.921875\n",
      "2018-05-04T16:13:39.263823: step 7806, loss 0.340003, acc 0.84375\n",
      "2018-05-04T16:13:40.331261: step 7807, loss 0.450801, acc 0.875\n",
      "2018-05-04T16:13:41.390353: step 7808, loss 0.270754, acc 0.859375\n",
      "2018-05-04T16:13:42.462849: step 7809, loss 0.201431, acc 0.9375\n",
      "2018-05-04T16:13:43.541565: step 7810, loss 0.408016, acc 0.8125\n",
      "2018-05-04T16:13:44.662893: step 7811, loss 0.203476, acc 0.90625\n",
      "2018-05-04T16:13:45.749351: step 7812, loss 0.222314, acc 0.921875\n",
      "2018-05-04T16:13:46.812531: step 7813, loss 0.304431, acc 0.875\n",
      "2018-05-04T16:13:47.877414: step 7814, loss 0.266404, acc 0.890625\n",
      "2018-05-04T16:13:48.954050: step 7815, loss 0.335164, acc 0.859375\n",
      "2018-05-04T16:13:49.992584: step 7816, loss 0.48049, acc 0.8125\n",
      "2018-05-04T16:13:51.027967: step 7817, loss 0.446297, acc 0.828125\n",
      "2018-05-04T16:13:52.045908: step 7818, loss 0.184626, acc 0.90625\n",
      "2018-05-04T16:13:53.047941: step 7819, loss 0.247816, acc 0.875\n",
      "2018-05-04T16:13:54.091184: step 7820, loss 0.221322, acc 0.890625\n",
      "2018-05-04T16:13:55.101996: step 7821, loss 0.449519, acc 0.8125\n",
      "2018-05-04T16:13:56.148589: step 7822, loss 0.229866, acc 0.890625\n",
      "2018-05-04T16:13:57.191080: step 7823, loss 0.398869, acc 0.84375\n",
      "2018-05-04T16:13:58.222768: step 7824, loss 0.224627, acc 0.890625\n",
      "2018-05-04T16:13:59.272127: step 7825, loss 0.260714, acc 0.90625\n",
      "2018-05-04T16:14:00.307389: step 7826, loss 0.383543, acc 0.859375\n",
      "2018-05-04T16:14:01.338842: step 7827, loss 0.358783, acc 0.8125\n",
      "2018-05-04T16:14:02.396007: step 7828, loss 0.263796, acc 0.875\n",
      "2018-05-04T16:14:03.439955: step 7829, loss 0.229907, acc 0.890625\n",
      "2018-05-04T16:14:04.440182: step 7830, loss 0.36989, acc 0.875\n",
      "2018-05-04T16:14:05.504106: step 7831, loss 0.365428, acc 0.859375\n",
      "2018-05-04T16:14:06.542616: step 7832, loss 0.243181, acc 0.875\n",
      "2018-05-04T16:14:07.588330: step 7833, loss 0.27696, acc 0.90625\n",
      "2018-05-04T16:14:08.616986: step 7834, loss 0.330646, acc 0.875\n",
      "2018-05-04T16:14:09.693672: step 7835, loss 0.347992, acc 0.859375\n",
      "2018-05-04T16:14:10.742607: step 7836, loss 0.407429, acc 0.84375\n",
      "2018-05-04T16:14:11.799785: step 7837, loss 0.19843, acc 0.90625\n",
      "2018-05-04T16:14:12.812426: step 7838, loss 0.238755, acc 0.921875\n",
      "2018-05-04T16:14:13.923479: step 7839, loss 0.308388, acc 0.84375\n",
      "2018-05-04T16:14:14.943140: step 7840, loss 0.384005, acc 0.796875\n",
      "2018-05-04T16:14:15.965995: step 7841, loss 0.331355, acc 0.875\n",
      "2018-05-04T16:14:16.987797: step 7842, loss 0.269756, acc 0.890625\n",
      "2018-05-04T16:14:18.041730: step 7843, loss 0.292418, acc 0.90625\n",
      "2018-05-04T16:14:19.104033: step 7844, loss 0.365926, acc 0.828125\n",
      "2018-05-04T16:14:20.142318: step 7845, loss 0.257478, acc 0.90625\n",
      "2018-05-04T16:14:21.235181: step 7846, loss 0.42855, acc 0.796875\n",
      "2018-05-04T16:14:22.236637: step 7847, loss 0.271903, acc 0.890625\n",
      "2018-05-04T16:14:23.301672: step 7848, loss 0.302939, acc 0.90625\n",
      "2018-05-04T16:14:24.303239: step 7849, loss 0.402843, acc 0.84375\n",
      "2018-05-04T16:14:25.312524: step 7850, loss 0.248136, acc 0.875\n",
      "2018-05-04T16:14:26.346141: step 7851, loss 0.370498, acc 0.828125\n",
      "2018-05-04T16:14:27.367981: step 7852, loss 0.269903, acc 0.859375\n",
      "2018-05-04T16:14:28.401848: step 7853, loss 0.287606, acc 0.859375\n",
      "2018-05-04T16:14:29.547233: step 7854, loss 0.371014, acc 0.859375\n",
      "2018-05-04T16:14:30.689635: step 7855, loss 0.243775, acc 0.859375\n",
      "2018-05-04T16:14:31.706613: step 7856, loss 0.311933, acc 0.90625\n",
      "2018-05-04T16:14:32.747635: step 7857, loss 0.334934, acc 0.84375\n",
      "2018-05-04T16:14:33.792785: step 7858, loss 0.34724, acc 0.84375\n",
      "2018-05-04T16:14:34.830450: step 7859, loss 0.322215, acc 0.84375\n",
      "2018-05-04T16:14:35.848638: step 7860, loss 0.289509, acc 0.875\n",
      "2018-05-04T16:14:36.849940: step 7861, loss 0.24161, acc 0.90625\n",
      "2018-05-04T16:14:37.853034: step 7862, loss 0.260762, acc 0.90625\n",
      "2018-05-04T16:14:38.893713: step 7863, loss 0.323535, acc 0.84375\n",
      "2018-05-04T16:14:39.918959: step 7864, loss 0.252144, acc 0.890625\n",
      "2018-05-04T16:14:41.006752: step 7865, loss 0.314921, acc 0.859375\n",
      "2018-05-04T16:14:42.026267: step 7866, loss 0.213041, acc 0.9375\n",
      "2018-05-04T16:14:43.067072: step 7867, loss 0.445245, acc 0.890625\n",
      "2018-05-04T16:14:44.118147: step 7868, loss 0.29548, acc 0.859375\n",
      "2018-05-04T16:14:45.155709: step 7869, loss 0.200068, acc 0.921875\n",
      "2018-05-04T16:14:46.175970: step 7870, loss 0.226197, acc 0.90625\n",
      "2018-05-04T16:14:47.210510: step 7871, loss 0.297014, acc 0.890625\n",
      "2018-05-04T16:14:48.222284: step 7872, loss 0.278557, acc 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T16:14:49.239733: step 7873, loss 0.23627, acc 0.890625\n",
      "2018-05-04T16:14:50.306032: step 7874, loss 0.262387, acc 0.875\n",
      "2018-05-04T16:14:51.419740: step 7875, loss 0.303383, acc 0.859375\n",
      "2018-05-04T16:14:52.486254: step 7876, loss 0.325107, acc 0.859375\n",
      "2018-05-04T16:14:53.505572: step 7877, loss 0.394415, acc 0.859375\n",
      "2018-05-04T16:14:54.534159: step 7878, loss 0.244096, acc 0.90625\n",
      "2018-05-04T16:14:55.578612: step 7879, loss 0.211217, acc 0.90625\n",
      "2018-05-04T16:14:56.595440: step 7880, loss 0.185589, acc 0.953125\n",
      "2018-05-04T16:14:57.638686: step 7881, loss 0.212749, acc 0.921875\n",
      "2018-05-04T16:14:58.644212: step 7882, loss 0.252085, acc 0.890625\n",
      "2018-05-04T16:14:59.747717: step 7883, loss 0.344171, acc 0.84375\n",
      "2018-05-04T16:15:00.787722: step 7884, loss 0.259474, acc 0.859375\n",
      "2018-05-04T16:15:01.844306: step 7885, loss 0.30506, acc 0.859375\n",
      "2018-05-04T16:15:02.870950: step 7886, loss 0.213459, acc 0.921875\n",
      "2018-05-04T16:15:03.910900: step 7887, loss 0.271193, acc 0.921875\n",
      "2018-05-04T16:15:04.946219: step 7888, loss 0.266051, acc 0.90625\n",
      "2018-05-04T16:15:05.982237: step 7889, loss 0.253918, acc 0.890625\n",
      "2018-05-04T16:15:07.001606: step 7890, loss 0.417988, acc 0.8125\n",
      "2018-05-04T16:15:08.016958: step 7891, loss 0.195356, acc 0.90625\n",
      "2018-05-04T16:15:09.040511: step 7892, loss 0.246659, acc 0.890625\n",
      "2018-05-04T16:15:10.062662: step 7893, loss 0.230104, acc 0.890625\n",
      "2018-05-04T16:15:11.091185: step 7894, loss 0.494046, acc 0.75\n",
      "2018-05-04T16:15:12.122042: step 7895, loss 0.23216, acc 0.890625\n",
      "2018-05-04T16:15:13.151189: step 7896, loss 0.241401, acc 0.921875\n",
      "2018-05-04T16:15:14.191288: step 7897, loss 0.264492, acc 0.90625\n",
      "2018-05-04T16:15:15.209742: step 7898, loss 0.320888, acc 0.859375\n",
      "2018-05-04T16:15:16.229324: step 7899, loss 0.217015, acc 0.9375\n",
      "2018-05-04T16:15:17.258290: step 7900, loss 0.267054, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T16:15:19.534289: step 7900, loss 0.239127, acc 0.912\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-7900\n",
      "\n",
      "2018-05-04T16:15:20.618568: step 7901, loss 0.352793, acc 0.828125\n",
      "2018-05-04T16:15:21.700732: step 7902, loss 0.329955, acc 0.90625\n",
      "2018-05-04T16:15:22.740753: step 7903, loss 0.292438, acc 0.859375\n",
      "2018-05-04T16:15:23.751749: step 7904, loss 0.290624, acc 0.90625\n",
      "2018-05-04T16:15:24.776107: step 7905, loss 0.324668, acc 0.9375\n",
      "2018-05-04T16:15:25.797300: step 7906, loss 0.228498, acc 0.921875\n",
      "2018-05-04T16:15:26.834560: step 7907, loss 0.345487, acc 0.84375\n",
      "2018-05-04T16:15:27.861894: step 7908, loss 0.196857, acc 0.921875\n",
      "2018-05-04T16:15:28.881449: step 7909, loss 0.314802, acc 0.859375\n",
      "2018-05-04T16:15:29.906404: step 7910, loss 0.266457, acc 0.90625\n",
      "2018-05-04T16:15:31.012975: step 7911, loss 0.29877, acc 0.84375\n",
      "2018-05-04T16:15:32.155352: step 7912, loss 0.333291, acc 0.921875\n",
      "2018-05-04T16:15:33.195772: step 7913, loss 0.179187, acc 0.921875\n",
      "2018-05-04T16:15:34.237328: step 7914, loss 0.300024, acc 0.84375\n",
      "2018-05-04T16:15:35.257935: step 7915, loss 0.311336, acc 0.859375\n",
      "2018-05-04T16:15:36.313430: step 7916, loss 0.264354, acc 0.90625\n",
      "2018-05-04T16:15:37.339043: step 7917, loss 0.162917, acc 0.9375\n",
      "2018-05-04T16:15:38.357649: step 7918, loss 0.300918, acc 0.921875\n",
      "2018-05-04T16:15:39.375862: step 7919, loss 0.404053, acc 0.828125\n",
      "2018-05-04T16:15:40.405342: step 7920, loss 0.210251, acc 0.921875\n",
      "2018-05-04T16:15:41.415060: step 7921, loss 0.298911, acc 0.828125\n",
      "2018-05-04T16:15:42.464886: step 7922, loss 0.317988, acc 0.84375\n",
      "2018-05-04T16:15:43.491127: step 7923, loss 0.388804, acc 0.78125\n",
      "2018-05-04T16:15:44.522482: step 7924, loss 0.263578, acc 0.875\n",
      "2018-05-04T16:15:45.522377: step 7925, loss 0.269216, acc 0.875\n",
      "2018-05-04T16:15:46.538679: step 7926, loss 0.150262, acc 0.9375\n",
      "2018-05-04T16:15:47.569545: step 7927, loss 0.283787, acc 0.890625\n",
      "2018-05-04T16:15:48.576008: step 7928, loss 0.225757, acc 0.90625\n",
      "2018-05-04T16:15:49.557545: step 7929, loss 0.257146, acc 0.875\n",
      "2018-05-04T16:15:50.546214: step 7930, loss 0.192048, acc 0.921875\n",
      "2018-05-04T16:15:51.632632: step 7931, loss 0.208086, acc 0.9375\n",
      "2018-05-04T16:15:52.651267: step 7932, loss 0.230276, acc 0.90625\n",
      "2018-05-04T16:15:53.736449: step 7933, loss 0.232611, acc 0.90625\n",
      "2018-05-04T16:15:54.785530: step 7934, loss 0.295729, acc 0.859375\n",
      "2018-05-04T16:15:55.816416: step 7935, loss 0.244704, acc 0.890625\n",
      "2018-05-04T16:15:56.830483: step 7936, loss 0.308876, acc 0.875\n",
      "2018-05-04T16:15:57.896133: step 7937, loss 0.252854, acc 0.921875\n",
      "2018-05-04T16:15:58.970688: step 7938, loss 0.366411, acc 0.890625\n",
      "2018-05-04T16:15:59.974711: step 7939, loss 0.27255, acc 0.875\n",
      "2018-05-04T16:16:00.969516: step 7940, loss 0.279718, acc 0.921875\n",
      "2018-05-04T16:16:02.035568: step 7941, loss 0.205933, acc 0.90625\n",
      "2018-05-04T16:16:03.008804: step 7942, loss 0.312704, acc 0.828125\n",
      "2018-05-04T16:16:04.082048: step 7943, loss 0.171714, acc 0.9375\n",
      "2018-05-04T16:16:05.069292: step 7944, loss 0.190425, acc 0.96875\n",
      "2018-05-04T16:16:06.127678: step 7945, loss 0.31203, acc 0.859375\n",
      "2018-05-04T16:16:07.116691: step 7946, loss 0.314995, acc 0.84375\n",
      "2018-05-04T16:16:08.112789: step 7947, loss 0.383083, acc 0.8125\n",
      "2018-05-04T16:16:09.087650: step 7948, loss 0.229426, acc 0.921875\n",
      "2018-05-04T16:16:10.071322: step 7949, loss 0.192181, acc 0.90625\n",
      "2018-05-04T16:16:11.063217: step 7950, loss 0.299417, acc 0.84375\n",
      "2018-05-04T16:16:12.184566: step 7951, loss 0.272482, acc 0.859375\n",
      "2018-05-04T16:16:13.292892: step 7952, loss 0.165804, acc 0.953125\n",
      "2018-05-04T16:16:14.281385: step 7953, loss 0.453338, acc 0.8125\n",
      "2018-05-04T16:16:15.304458: step 7954, loss 0.32914, acc 0.859375\n",
      "2018-05-04T16:16:16.316525: step 7955, loss 0.306307, acc 0.828125\n",
      "2018-05-04T16:16:17.350061: step 7956, loss 0.194578, acc 0.921875\n",
      "2018-05-04T16:16:18.435297: step 7957, loss 0.374324, acc 0.875\n",
      "2018-05-04T16:16:19.453739: step 7958, loss 0.289452, acc 0.875\n",
      "2018-05-04T16:16:20.505186: step 7959, loss 0.219074, acc 0.890625\n",
      "2018-05-04T16:16:21.552726: step 7960, loss 0.274932, acc 0.84375\n",
      "2018-05-04T16:16:22.593574: step 7961, loss 0.278417, acc 0.90625\n",
      "2018-05-04T16:16:23.637133: step 7962, loss 0.369809, acc 0.859375\n",
      "2018-05-04T16:16:24.671580: step 7963, loss 0.171927, acc 0.96875\n",
      "2018-05-04T16:16:25.713737: step 7964, loss 0.405619, acc 0.828125\n",
      "2018-05-04T16:16:26.726152: step 7965, loss 0.225401, acc 0.875\n",
      "2018-05-04T16:16:27.753824: step 7966, loss 0.379244, acc 0.828125\n",
      "2018-05-04T16:16:28.773177: step 7967, loss 0.237508, acc 0.890625\n",
      "2018-05-04T16:16:29.799631: step 7968, loss 0.323184, acc 0.875\n",
      "2018-05-04T16:16:30.842425: step 7969, loss 0.23851, acc 0.90625\n",
      "2018-05-04T16:16:31.860857: step 7970, loss 0.330941, acc 0.90625\n",
      "2018-05-04T16:16:32.949442: step 7971, loss 0.277557, acc 0.90625\n",
      "2018-05-04T16:16:34.073903: step 7972, loss 0.423954, acc 0.828125\n",
      "2018-05-04T16:16:35.197746: step 7973, loss 0.331694, acc 0.84375\n",
      "2018-05-04T16:16:36.247314: step 7974, loss 0.466249, acc 0.78125\n",
      "2018-05-04T16:16:37.318550: step 7975, loss 0.335317, acc 0.859375\n",
      "2018-05-04T16:16:38.353631: step 7976, loss 0.356431, acc 0.859375\n",
      "2018-05-04T16:16:39.381256: step 7977, loss 0.251059, acc 0.921875\n",
      "2018-05-04T16:16:40.410912: step 7978, loss 0.234211, acc 0.921875\n",
      "2018-05-04T16:16:41.492846: step 7979, loss 0.314684, acc 0.875\n",
      "2018-05-04T16:16:42.516547: step 7980, loss 0.219079, acc 0.890625\n",
      "2018-05-04T16:16:43.556648: step 7981, loss 0.169604, acc 0.96875\n",
      "2018-05-04T16:16:44.626578: step 7982, loss 0.365209, acc 0.859375\n",
      "2018-05-04T16:16:45.669259: step 7983, loss 0.471127, acc 0.828125\n",
      "2018-05-04T16:16:46.714359: step 7984, loss 0.269601, acc 0.921875\n",
      "2018-05-04T16:16:47.727768: step 7985, loss 0.273163, acc 0.890625\n",
      "2018-05-04T16:16:48.753488: step 7986, loss 0.318411, acc 0.875\n",
      "2018-05-04T16:16:49.768674: step 7987, loss 0.285114, acc 0.90625\n",
      "2018-05-04T16:16:50.790693: step 7988, loss 0.280761, acc 0.875\n",
      "2018-05-04T16:16:51.818027: step 7989, loss 0.355165, acc 0.828125\n",
      "2018-05-04T16:16:52.807479: step 7990, loss 0.355059, acc 0.875\n",
      "2018-05-04T16:16:53.837567: step 7991, loss 0.192391, acc 0.953125\n",
      "2018-05-04T16:16:54.852127: step 7992, loss 0.397472, acc 0.828125\n",
      "2018-05-04T16:16:55.879860: step 7993, loss 0.332702, acc 0.875\n",
      "2018-05-04T16:16:56.886691: step 7994, loss 0.35938, acc 0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T16:16:57.908048: step 7995, loss 0.297934, acc 0.890625\n",
      "2018-05-04T16:16:58.929443: step 7996, loss 0.314095, acc 0.84375\n",
      "2018-05-04T16:16:59.924139: step 7997, loss 0.342483, acc 0.859375\n",
      "2018-05-04T16:17:00.955241: step 7998, loss 0.20977, acc 0.921875\n",
      "2018-05-04T16:17:02.009398: step 7999, loss 0.284484, acc 0.875\n",
      "2018-05-04T16:17:03.020288: step 8000, loss 0.495594, acc 0.75\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T16:17:05.543497: step 8000, loss 0.257704, acc 0.904\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-8000\n",
      "\n",
      "2018-05-04T16:17:06.677933: step 8001, loss 0.226502, acc 0.90625\n",
      "2018-05-04T16:17:07.750605: step 8002, loss 0.266697, acc 0.890625\n",
      "2018-05-04T16:17:08.854120: step 8003, loss 0.126344, acc 0.96875\n",
      "2018-05-04T16:17:09.866070: step 8004, loss 0.40322, acc 0.859375\n",
      "2018-05-04T16:17:10.862711: step 8005, loss 0.223074, acc 0.9375\n",
      "2018-05-04T16:17:11.964456: step 8006, loss 0.245877, acc 0.9375\n",
      "2018-05-04T16:17:12.992222: step 8007, loss 0.575951, acc 0.734375\n",
      "2018-05-04T16:17:13.972001: step 8008, loss 0.179236, acc 0.890625\n",
      "2018-05-04T16:17:14.956354: step 8009, loss 0.208945, acc 0.9375\n",
      "2018-05-04T16:17:15.952316: step 8010, loss 0.250046, acc 0.890625\n",
      "2018-05-04T16:17:16.958783: step 8011, loss 0.301087, acc 0.90625\n",
      "2018-05-04T16:17:17.936414: step 8012, loss 0.240717, acc 0.875\n",
      "2018-05-04T16:17:18.941718: step 8013, loss 0.337597, acc 0.890625\n",
      "2018-05-04T16:17:19.903091: step 8014, loss 0.309845, acc 0.875\n",
      "2018-05-04T16:17:20.881982: step 8015, loss 0.281745, acc 0.90625\n",
      "2018-05-04T16:17:21.901830: step 8016, loss 0.41548, acc 0.8125\n",
      "2018-05-04T16:17:22.887950: step 8017, loss 0.333905, acc 0.859375\n",
      "2018-05-04T16:17:23.857450: step 8018, loss 0.251623, acc 0.875\n",
      "2018-05-04T16:17:24.820429: step 8019, loss 0.185899, acc 0.9375\n",
      "2018-05-04T16:17:25.818564: step 8020, loss 0.185697, acc 0.953125\n",
      "2018-05-04T16:17:26.803056: step 8021, loss 0.401152, acc 0.875\n",
      "2018-05-04T16:17:27.791204: step 8022, loss 0.288242, acc 0.859375\n",
      "2018-05-04T16:17:28.783645: step 8023, loss 0.236319, acc 0.875\n",
      "2018-05-04T16:17:29.737960: step 8024, loss 0.324379, acc 0.859375\n",
      "2018-05-04T16:17:30.728876: step 8025, loss 0.229906, acc 0.90625\n",
      "2018-05-04T16:17:31.692132: step 8026, loss 0.20801, acc 0.9375\n",
      "2018-05-04T16:17:32.666005: step 8027, loss 0.212734, acc 0.890625\n",
      "2018-05-04T16:17:33.652694: step 8028, loss 0.261235, acc 0.859375\n",
      "2018-05-04T16:17:34.668281: step 8029, loss 0.253207, acc 0.90625\n",
      "2018-05-04T16:17:35.628811: step 8030, loss 0.251049, acc 0.921875\n",
      "2018-05-04T16:17:36.707547: step 8031, loss 0.467065, acc 0.8125\n",
      "2018-05-04T16:17:37.704361: step 8032, loss 0.191338, acc 0.953125\n",
      "2018-05-04T16:17:38.706096: step 8033, loss 0.271948, acc 0.8125\n",
      "2018-05-04T16:17:39.679732: step 8034, loss 0.366947, acc 0.8125\n",
      "2018-05-04T16:17:40.687076: step 8035, loss 0.231938, acc 0.921875\n",
      "2018-05-04T16:17:41.672317: step 8036, loss 0.296438, acc 0.859375\n",
      "2018-05-04T16:17:42.783411: step 8037, loss 0.230759, acc 0.90625\n",
      "2018-05-04T16:17:43.798269: step 8038, loss 0.315221, acc 0.890625\n",
      "2018-05-04T16:17:44.823046: step 8039, loss 0.250542, acc 0.90625\n",
      "2018-05-04T16:17:45.809861: step 8040, loss 0.22891, acc 0.921875\n",
      "2018-05-04T16:17:46.839444: step 8041, loss 0.270665, acc 0.90625\n",
      "2018-05-04T16:17:47.817781: step 8042, loss 0.41956, acc 0.859375\n",
      "2018-05-04T16:17:48.818678: step 8043, loss 0.297267, acc 0.875\n",
      "2018-05-04T16:17:49.833500: step 8044, loss 0.198905, acc 0.921875\n",
      "2018-05-04T16:17:50.918504: step 8045, loss 0.269202, acc 0.859375\n",
      "2018-05-04T16:17:51.942253: step 8046, loss 0.150206, acc 0.9375\n",
      "2018-05-04T16:17:52.916581: step 8047, loss 0.259157, acc 0.859375\n",
      "2018-05-04T16:17:53.887704: step 8048, loss 0.28609, acc 0.875\n",
      "2018-05-04T16:17:54.864537: step 8049, loss 0.30691, acc 0.84375\n",
      "2018-05-04T16:17:55.874258: step 8050, loss 0.33109, acc 0.875\n",
      "2018-05-04T16:17:56.950957: step 8051, loss 0.33857, acc 0.890625\n",
      "2018-05-04T16:17:57.948483: step 8052, loss 0.286434, acc 0.9375\n",
      "2018-05-04T16:17:58.978815: step 8053, loss 0.317208, acc 0.859375\n",
      "2018-05-04T16:17:59.954678: step 8054, loss 0.224134, acc 0.921875\n",
      "2018-05-04T16:18:00.930660: step 8055, loss 0.305477, acc 0.890625\n",
      "2018-05-04T16:18:01.901427: step 8056, loss 0.190515, acc 0.9375\n",
      "2018-05-04T16:18:02.911253: step 8057, loss 0.282987, acc 0.859375\n",
      "2018-05-04T16:18:03.916948: step 8058, loss 0.393344, acc 0.859375\n",
      "2018-05-04T16:18:04.904381: step 8059, loss 0.274202, acc 0.859375\n",
      "2018-05-04T16:18:05.920405: step 8060, loss 0.290868, acc 0.859375\n",
      "2018-05-04T16:18:06.922756: step 8061, loss 0.288022, acc 0.875\n",
      "2018-05-04T16:18:07.928093: step 8062, loss 0.2062, acc 0.90625\n",
      "2018-05-04T16:18:08.928155: step 8063, loss 0.162553, acc 0.953125\n",
      "2018-05-04T16:18:09.993524: step 8064, loss 0.315486, acc 0.890625\n",
      "2018-05-04T16:18:10.979469: step 8065, loss 0.205947, acc 0.890625\n",
      "2018-05-04T16:18:12.022672: step 8066, loss 0.15742, acc 0.953125\n",
      "2018-05-04T16:18:12.984675: step 8067, loss 0.18922, acc 0.921875\n",
      "2018-05-04T16:18:13.972168: step 8068, loss 0.231848, acc 0.9375\n",
      "2018-05-04T16:18:14.978990: step 8069, loss 0.239428, acc 0.890625\n",
      "2018-05-04T16:18:15.979483: step 8070, loss 0.294925, acc 0.859375\n",
      "2018-05-04T16:18:16.993897: step 8071, loss 0.215931, acc 0.953125\n",
      "2018-05-04T16:18:18.065995: step 8072, loss 0.265893, acc 0.90625\n",
      "2018-05-04T16:18:19.051743: step 8073, loss 0.434975, acc 0.796875\n",
      "2018-05-04T16:18:20.036984: step 8074, loss 0.173447, acc 0.96875\n",
      "2018-05-04T16:18:21.041829: step 8075, loss 0.272299, acc 0.890625\n",
      "2018-05-04T16:18:22.019315: step 8076, loss 0.305479, acc 0.90625\n",
      "2018-05-04T16:18:23.017503: step 8077, loss 0.268824, acc 0.890625\n",
      "2018-05-04T16:18:24.007143: step 8078, loss 0.296116, acc 0.859375\n",
      "2018-05-04T16:18:25.002054: step 8079, loss 0.240942, acc 0.84375\n",
      "2018-05-04T16:18:25.973299: step 8080, loss 0.287544, acc 0.890625\n",
      "2018-05-04T16:18:26.936317: step 8081, loss 0.286674, acc 0.8125\n",
      "2018-05-04T16:18:27.906194: step 8082, loss 0.249729, acc 0.859375\n",
      "2018-05-04T16:18:28.909863: step 8083, loss 0.397671, acc 0.875\n",
      "2018-05-04T16:18:29.951199: step 8084, loss 0.272839, acc 0.90625\n",
      "2018-05-04T16:18:30.952015: step 8085, loss 0.396579, acc 0.890625\n",
      "2018-05-04T16:18:31.951829: step 8086, loss 0.289568, acc 0.890625\n",
      "2018-05-04T16:18:32.957629: step 8087, loss 0.312522, acc 0.828125\n",
      "2018-05-04T16:18:33.961337: step 8088, loss 0.360825, acc 0.828125\n",
      "2018-05-04T16:18:34.958175: step 8089, loss 0.374467, acc 0.859375\n",
      "2018-05-04T16:18:36.035170: step 8090, loss 0.256135, acc 0.9375\n",
      "2018-05-04T16:18:37.033974: step 8091, loss 0.33434, acc 0.875\n",
      "2018-05-04T16:18:38.031935: step 8092, loss 0.338797, acc 0.875\n",
      "2018-05-04T16:18:39.025461: step 8093, loss 0.329998, acc 0.859375\n",
      "2018-05-04T16:18:40.021396: step 8094, loss 0.271948, acc 0.859375\n",
      "2018-05-04T16:18:41.004820: step 8095, loss 0.24865, acc 0.875\n",
      "2018-05-04T16:18:42.006989: step 8096, loss 0.288291, acc 0.828125\n",
      "2018-05-04T16:18:43.023029: step 8097, loss 0.233008, acc 0.890625\n",
      "2018-05-04T16:18:44.001904: step 8098, loss 0.298223, acc 0.828125\n",
      "2018-05-04T16:18:44.957048: step 8099, loss 0.171682, acc 0.921875\n",
      "2018-05-04T16:18:45.928188: step 8100, loss 0.414738, acc 0.78125\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T16:18:48.254404: step 8100, loss 0.255221, acc 0.898\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-8100\n",
      "\n",
      "2018-05-04T16:18:49.401910: step 8101, loss 0.327335, acc 0.875\n",
      "2018-05-04T16:18:50.448917: step 8102, loss 0.304579, acc 0.921875\n",
      "2018-05-04T16:18:51.521543: step 8103, loss 0.275073, acc 0.890625\n",
      "2018-05-04T16:18:52.577097: step 8104, loss 0.258523, acc 0.875\n",
      "2018-05-04T16:18:53.724354: step 8105, loss 0.264491, acc 0.90625\n",
      "2018-05-04T16:18:54.767132: step 8106, loss 0.583992, acc 0.734375\n",
      "2018-05-04T16:18:55.793768: step 8107, loss 0.219619, acc 0.890625\n",
      "2018-05-04T16:18:56.913157: step 8108, loss 0.281704, acc 0.890625\n",
      "2018-05-04T16:18:57.931862: step 8109, loss 0.186072, acc 0.9375\n",
      "2018-05-04T16:18:58.937731: step 8110, loss 0.333589, acc 0.84375\n",
      "2018-05-04T16:18:59.965491: step 8111, loss 0.189577, acc 0.890625\n",
      "2018-05-04T16:19:00.988257: step 8112, loss 0.250651, acc 0.921875\n",
      "2018-05-04T16:19:02.012782: step 8113, loss 0.350105, acc 0.84375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T16:19:03.080229: step 8114, loss 0.255241, acc 0.890625\n",
      "2018-05-04T16:19:04.066855: step 8115, loss 0.305279, acc 0.875\n",
      "2018-05-04T16:19:05.040815: step 8116, loss 0.336965, acc 0.84375\n",
      "2018-05-04T16:19:06.123922: step 8117, loss 0.182955, acc 0.984375\n",
      "2018-05-04T16:19:07.119664: step 8118, loss 0.340467, acc 0.84375\n",
      "2018-05-04T16:19:08.213938: step 8119, loss 0.282186, acc 0.890625\n",
      "2018-05-04T16:19:09.252148: step 8120, loss 0.369484, acc 0.875\n",
      "2018-05-04T16:19:10.267381: step 8121, loss 0.443695, acc 0.8125\n",
      "2018-05-04T16:19:11.264303: step 8122, loss 0.328575, acc 0.859375\n",
      "2018-05-04T16:19:12.272023: step 8123, loss 0.354975, acc 0.84375\n",
      "2018-05-04T16:19:13.294906: step 8124, loss 0.300767, acc 0.828125\n",
      "2018-05-04T16:19:14.360389: step 8125, loss 0.399706, acc 0.78125\n",
      "2018-05-04T16:19:15.354538: step 8126, loss 0.249193, acc 0.921875\n",
      "2018-05-04T16:19:16.345531: step 8127, loss 0.423793, acc 0.828125\n",
      "2018-05-04T16:19:17.388817: step 8128, loss 0.348642, acc 0.84375\n",
      "2018-05-04T16:19:18.408801: step 8129, loss 0.248057, acc 0.921875\n",
      "2018-05-04T16:19:19.468429: step 8130, loss 0.233847, acc 0.890625\n",
      "2018-05-04T16:19:20.481498: step 8131, loss 0.309157, acc 0.890625\n",
      "2018-05-04T16:19:21.494189: step 8132, loss 0.216596, acc 0.90625\n",
      "2018-05-04T16:19:22.484702: step 8133, loss 0.29652, acc 0.875\n",
      "2018-05-04T16:19:23.496517: step 8134, loss 0.320736, acc 0.875\n",
      "2018-05-04T16:19:24.595496: step 8135, loss 0.196011, acc 0.9375\n",
      "2018-05-04T16:19:25.612757: step 8136, loss 0.393148, acc 0.828125\n",
      "2018-05-04T16:19:26.611025: step 8137, loss 0.130297, acc 0.984375\n",
      "2018-05-04T16:19:27.644249: step 8138, loss 0.309616, acc 0.84375\n",
      "2018-05-04T16:19:28.674146: step 8139, loss 0.245468, acc 0.875\n",
      "2018-05-04T16:19:29.769581: step 8140, loss 0.263129, acc 0.875\n",
      "2018-05-04T16:19:30.784416: step 8141, loss 0.197967, acc 0.90625\n",
      "2018-05-04T16:19:31.805507: step 8142, loss 0.385066, acc 0.765625\n",
      "2018-05-04T16:19:32.861177: step 8143, loss 0.335568, acc 0.859375\n",
      "2018-05-04T16:19:33.971225: step 8144, loss 0.189353, acc 0.90625\n",
      "2018-05-04T16:19:35.071199: step 8145, loss 0.461008, acc 0.796875\n",
      "2018-05-04T16:19:36.198747: step 8146, loss 0.36693, acc 0.859375\n",
      "2018-05-04T16:19:37.283489: step 8147, loss 0.263314, acc 0.875\n",
      "2018-05-04T16:19:38.326974: step 8148, loss 0.44151, acc 0.796875\n",
      "2018-05-04T16:19:39.403635: step 8149, loss 0.29787, acc 0.875\n",
      "2018-05-04T16:19:40.455431: step 8150, loss 0.416671, acc 0.796875\n",
      "2018-05-04T16:19:41.504776: step 8151, loss 0.190574, acc 0.953125\n",
      "2018-05-04T16:19:42.536410: step 8152, loss 0.187679, acc 0.921875\n",
      "2018-05-04T16:19:43.575425: step 8153, loss 0.245026, acc 0.890625\n",
      "2018-05-04T16:19:44.616195: step 8154, loss 0.212653, acc 0.9375\n",
      "2018-05-04T16:19:45.646038: step 8155, loss 0.357243, acc 0.859375\n",
      "2018-05-04T16:19:46.705731: step 8156, loss 0.286025, acc 0.828125\n",
      "2018-05-04T16:19:47.693008: step 8157, loss 0.228113, acc 0.90625\n",
      "2018-05-04T16:19:48.700556: step 8158, loss 0.372885, acc 0.84375\n",
      "2018-05-04T16:19:49.702267: step 8159, loss 0.254552, acc 0.890625\n",
      "2018-05-04T16:19:50.747615: step 8160, loss 0.300168, acc 0.890625\n",
      "2018-05-04T16:19:51.769114: step 8161, loss 0.371443, acc 0.859375\n",
      "2018-05-04T16:19:52.886434: step 8162, loss 0.254662, acc 0.890625\n",
      "2018-05-04T16:19:53.969185: step 8163, loss 0.182889, acc 0.9375\n",
      "2018-05-04T16:19:54.989086: step 8164, loss 0.235536, acc 0.890625\n",
      "2018-05-04T16:19:56.050415: step 8165, loss 0.33288, acc 0.859375\n",
      "2018-05-04T16:19:57.076724: step 8166, loss 0.249644, acc 0.921875\n",
      "2018-05-04T16:19:58.099934: step 8167, loss 0.282532, acc 0.875\n",
      "2018-05-04T16:19:59.138491: step 8168, loss 0.354864, acc 0.890625\n",
      "2018-05-04T16:20:00.229516: step 8169, loss 0.249667, acc 0.9375\n",
      "2018-05-04T16:20:01.312052: step 8170, loss 0.280901, acc 0.890625\n",
      "2018-05-04T16:20:02.394511: step 8171, loss 0.245455, acc 0.859375\n",
      "2018-05-04T16:20:03.390104: step 8172, loss 0.283042, acc 0.859375\n",
      "2018-05-04T16:20:04.404488: step 8173, loss 0.354084, acc 0.890625\n",
      "2018-05-04T16:20:05.429983: step 8174, loss 0.146801, acc 0.96875\n",
      "2018-05-04T16:20:06.475304: step 8175, loss 0.28205, acc 0.875\n",
      "2018-05-04T16:20:07.589152: step 8176, loss 0.222232, acc 0.890625\n",
      "2018-05-04T16:20:08.624171: step 8177, loss 0.333638, acc 0.875\n",
      "2018-05-04T16:20:09.622805: step 8178, loss 0.354183, acc 0.828125\n",
      "2018-05-04T16:20:10.696266: step 8179, loss 0.251045, acc 0.90625\n",
      "2018-05-04T16:20:11.697627: step 8180, loss 0.201834, acc 0.921875\n",
      "2018-05-04T16:20:12.696732: step 8181, loss 0.238847, acc 0.890625\n",
      "2018-05-04T16:20:13.711244: step 8182, loss 0.403323, acc 0.8125\n",
      "2018-05-04T16:20:14.811577: step 8183, loss 0.307238, acc 0.875\n",
      "2018-05-04T16:20:15.852012: step 8184, loss 0.220467, acc 0.90625\n",
      "2018-05-04T16:20:16.887467: step 8185, loss 0.386977, acc 0.859375\n",
      "2018-05-04T16:20:17.964638: step 8186, loss 0.19473, acc 0.921875\n",
      "2018-05-04T16:20:18.975121: step 8187, loss 0.287174, acc 0.859375\n",
      "2018-05-04T16:20:19.995083: step 8188, loss 0.316408, acc 0.90625\n",
      "2018-05-04T16:20:21.061689: step 8189, loss 0.250435, acc 0.84375\n",
      "2018-05-04T16:20:22.134928: step 8190, loss 0.283251, acc 0.890625\n",
      "2018-05-04T16:20:23.152797: step 8191, loss 0.344643, acc 0.84375\n",
      "2018-05-04T16:20:24.170624: step 8192, loss 0.269746, acc 0.828125\n",
      "2018-05-04T16:20:25.199094: step 8193, loss 0.242985, acc 0.875\n",
      "2018-05-04T16:20:26.212744: step 8194, loss 0.210476, acc 0.890625\n",
      "2018-05-04T16:20:27.229665: step 8195, loss 0.37465, acc 0.875\n",
      "2018-05-04T16:20:28.249358: step 8196, loss 0.330064, acc 0.890625\n",
      "2018-05-04T16:20:29.298020: step 8197, loss 0.216111, acc 0.9375\n",
      "2018-05-04T16:20:30.311159: step 8198, loss 0.192482, acc 0.9375\n",
      "2018-05-04T16:20:31.346799: step 8199, loss 0.336471, acc 0.78125\n",
      "2018-05-04T16:20:32.366757: step 8200, loss 0.500689, acc 0.796875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T16:20:34.930356: step 8200, loss 0.243866, acc 0.9\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-8200\n",
      "\n",
      "2018-05-04T16:20:36.103798: step 8201, loss 0.263197, acc 0.875\n",
      "2018-05-04T16:20:37.173324: step 8202, loss 0.258058, acc 0.90625\n",
      "2018-05-04T16:20:38.265760: step 8203, loss 0.406912, acc 0.859375\n",
      "2018-05-04T16:20:39.350258: step 8204, loss 0.243496, acc 0.890625\n",
      "2018-05-04T16:20:40.427794: step 8205, loss 0.348841, acc 0.859375\n",
      "2018-05-04T16:20:41.457513: step 8206, loss 0.314846, acc 0.859375\n",
      "2018-05-04T16:20:42.476107: step 8207, loss 0.15898, acc 0.9375\n",
      "2018-05-04T16:20:43.541357: step 8208, loss 0.236174, acc 0.890625\n",
      "2018-05-04T16:20:44.609673: step 8209, loss 0.259097, acc 0.859375\n",
      "2018-05-04T16:20:45.664742: step 8210, loss 0.278913, acc 0.890625\n",
      "2018-05-04T16:20:46.704530: step 8211, loss 0.153673, acc 0.953125\n",
      "2018-05-04T16:20:47.736829: step 8212, loss 0.189864, acc 0.9375\n",
      "2018-05-04T16:20:48.758220: step 8213, loss 0.281224, acc 0.875\n",
      "2018-05-04T16:20:49.871852: step 8214, loss 0.264081, acc 0.890625\n",
      "2018-05-04T16:20:50.881174: step 8215, loss 0.292705, acc 0.890625\n",
      "2018-05-04T16:20:51.937654: step 8216, loss 0.206908, acc 0.890625\n",
      "2018-05-04T16:20:52.952486: step 8217, loss 0.353362, acc 0.875\n",
      "2018-05-04T16:20:53.988184: step 8218, loss 0.338852, acc 0.859375\n",
      "2018-05-04T16:20:55.039048: step 8219, loss 0.400288, acc 0.828125\n",
      "2018-05-04T16:20:56.149939: step 8220, loss 0.218656, acc 0.90625\n",
      "2018-05-04T16:20:57.171252: step 8221, loss 0.265243, acc 0.84375\n",
      "2018-05-04T16:20:58.164806: step 8222, loss 0.24711, acc 0.875\n",
      "2018-05-04T16:20:59.173061: step 8223, loss 0.193397, acc 0.90625\n",
      "2018-05-04T16:21:00.174031: step 8224, loss 0.229125, acc 0.921875\n",
      "2018-05-04T16:21:01.241658: step 8225, loss 0.440317, acc 0.828125\n",
      "2018-05-04T16:21:02.327230: step 8226, loss 0.351285, acc 0.875\n",
      "2018-05-04T16:21:03.371831: step 8227, loss 0.299258, acc 0.890625\n",
      "2018-05-04T16:21:04.426100: step 8228, loss 0.357738, acc 0.859375\n",
      "2018-05-04T16:21:05.468469: step 8229, loss 0.115012, acc 1\n",
      "2018-05-04T16:21:06.507245: step 8230, loss 0.371227, acc 0.859375\n",
      "2018-05-04T16:21:07.540360: step 8231, loss 0.195579, acc 0.921875\n",
      "2018-05-04T16:21:08.575442: step 8232, loss 0.228243, acc 0.921875\n",
      "2018-05-04T16:21:09.582035: step 8233, loss 0.331578, acc 0.875\n",
      "2018-05-04T16:21:10.605413: step 8234, loss 0.271378, acc 0.921875\n",
      "2018-05-04T16:21:11.660158: step 8235, loss 0.27658, acc 0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T16:21:12.688385: step 8236, loss 0.348081, acc 0.859375\n",
      "2018-05-04T16:21:13.736967: step 8237, loss 0.390861, acc 0.828125\n",
      "2018-05-04T16:21:14.763429: step 8238, loss 0.213069, acc 0.9375\n",
      "2018-05-04T16:21:15.802012: step 8239, loss 0.207893, acc 0.921875\n",
      "2018-05-04T16:21:16.848710: step 8240, loss 0.222202, acc 0.9375\n",
      "2018-05-04T16:21:17.917659: step 8241, loss 0.30669, acc 0.859375\n",
      "2018-05-04T16:21:18.939514: step 8242, loss 0.248129, acc 0.90625\n",
      "2018-05-04T16:21:20.043243: step 8243, loss 0.229006, acc 0.90625\n",
      "2018-05-04T16:21:21.070784: step 8244, loss 0.476127, acc 0.8125\n",
      "2018-05-04T16:21:22.089299: step 8245, loss 0.422397, acc 0.84375\n",
      "2018-05-04T16:21:23.125498: step 8246, loss 0.210717, acc 0.890625\n",
      "2018-05-04T16:21:24.141601: step 8247, loss 0.238212, acc 0.890625\n",
      "2018-05-04T16:21:25.168692: step 8248, loss 0.432579, acc 0.859375\n",
      "2018-05-04T16:21:26.200127: step 8249, loss 0.212767, acc 0.90625\n",
      "2018-05-04T16:21:27.293487: step 8250, loss 0.371187, acc 0.828125\n",
      "2018-05-04T16:21:28.423264: step 8251, loss 0.340623, acc 0.875\n",
      "2018-05-04T16:21:29.429982: step 8252, loss 0.236948, acc 0.890625\n",
      "2018-05-04T16:21:30.428038: step 8253, loss 0.24497, acc 0.90625\n",
      "2018-05-04T16:21:31.491307: step 8254, loss 0.124938, acc 0.953125\n",
      "2018-05-04T16:21:32.500123: step 8255, loss 0.278901, acc 0.875\n",
      "2018-05-04T16:21:33.549313: step 8256, loss 0.266208, acc 0.875\n",
      "2018-05-04T16:21:34.602866: step 8257, loss 0.263253, acc 0.890625\n",
      "2018-05-04T16:21:35.644192: step 8258, loss 0.217439, acc 0.90625\n",
      "2018-05-04T16:21:36.694021: step 8259, loss 0.334845, acc 0.859375\n",
      "2018-05-04T16:21:37.791327: step 8260, loss 0.22467, acc 0.921875\n",
      "2018-05-04T16:21:38.810951: step 8261, loss 0.269063, acc 0.890625\n",
      "2018-05-04T16:21:39.831186: step 8262, loss 0.230637, acc 0.859375\n",
      "2018-05-04T16:21:40.831365: step 8263, loss 0.409722, acc 0.828125\n",
      "2018-05-04T16:21:41.841553: step 8264, loss 0.215528, acc 0.890625\n",
      "2018-05-04T16:21:42.880614: step 8265, loss 0.271696, acc 0.875\n",
      "2018-05-04T16:21:43.882617: step 8266, loss 0.35608, acc 0.828125\n",
      "2018-05-04T16:21:44.939191: step 8267, loss 0.299942, acc 0.90625\n",
      "2018-05-04T16:21:45.961842: step 8268, loss 0.341379, acc 0.90625\n",
      "2018-05-04T16:21:46.991594: step 8269, loss 0.332706, acc 0.875\n",
      "2018-05-04T16:21:48.014015: step 8270, loss 0.289314, acc 0.890625\n",
      "2018-05-04T16:21:49.040105: step 8271, loss 0.330966, acc 0.890625\n",
      "2018-05-04T16:21:50.120044: step 8272, loss 0.437623, acc 0.828125\n",
      "2018-05-04T16:21:51.168631: step 8273, loss 0.158213, acc 0.984375\n",
      "2018-05-04T16:21:52.222007: step 8274, loss 0.263994, acc 0.84375\n",
      "2018-05-04T16:21:53.253040: step 8275, loss 0.185092, acc 0.921875\n",
      "2018-05-04T16:21:54.327682: step 8276, loss 0.271168, acc 0.859375\n",
      "2018-05-04T16:21:55.345792: step 8277, loss 0.255008, acc 0.921875\n",
      "2018-05-04T16:21:56.371482: step 8278, loss 0.220595, acc 0.921875\n",
      "2018-05-04T16:21:57.391033: step 8279, loss 0.286243, acc 0.875\n",
      "2018-05-04T16:21:58.416532: step 8280, loss 0.274795, acc 0.875\n",
      "2018-05-04T16:21:59.453585: step 8281, loss 0.319051, acc 0.890625\n",
      "2018-05-04T16:22:00.469348: step 8282, loss 0.31162, acc 0.828125\n",
      "2018-05-04T16:22:01.505052: step 8283, loss 0.325969, acc 0.875\n",
      "2018-05-04T16:22:02.540411: step 8284, loss 0.273381, acc 0.890625\n",
      "2018-05-04T16:22:03.571318: step 8285, loss 0.189422, acc 0.921875\n",
      "2018-05-04T16:22:04.598300: step 8286, loss 0.331038, acc 0.875\n",
      "2018-05-04T16:22:05.607000: step 8287, loss 0.271152, acc 0.828125\n",
      "2018-05-04T16:22:06.623075: step 8288, loss 0.262953, acc 0.859375\n",
      "2018-05-04T16:22:07.622019: step 8289, loss 0.359611, acc 0.875\n",
      "2018-05-04T16:22:08.623306: step 8290, loss 0.176616, acc 0.921875\n",
      "2018-05-04T16:22:09.638106: step 8291, loss 0.273928, acc 0.859375\n",
      "2018-05-04T16:22:10.664453: step 8292, loss 0.190003, acc 0.90625\n",
      "2018-05-04T16:22:11.733071: step 8293, loss 0.310621, acc 0.890625\n",
      "2018-05-04T16:22:12.763555: step 8294, loss 0.277064, acc 0.859375\n",
      "2018-05-04T16:22:13.795933: step 8295, loss 0.223943, acc 0.890625\n",
      "2018-05-04T16:22:14.813630: step 8296, loss 0.460284, acc 0.78125\n",
      "2018-05-04T16:22:15.812730: step 8297, loss 0.270821, acc 0.921875\n",
      "2018-05-04T16:22:16.846039: step 8298, loss 0.224108, acc 0.90625\n",
      "2018-05-04T16:22:17.878504: step 8299, loss 0.275931, acc 0.890625\n",
      "2018-05-04T16:22:18.910070: step 8300, loss 0.550113, acc 0.8125\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T16:22:21.386146: step 8300, loss 0.238283, acc 0.904\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-8300\n",
      "\n",
      "2018-05-04T16:22:22.524721: step 8301, loss 0.255453, acc 0.875\n",
      "2018-05-04T16:22:23.658217: step 8302, loss 0.437081, acc 0.875\n",
      "2018-05-04T16:22:24.743237: step 8303, loss 0.411672, acc 0.828125\n",
      "2018-05-04T16:22:25.928726: step 8304, loss 0.243568, acc 0.84375\n",
      "2018-05-04T16:22:26.996131: step 8305, loss 0.188649, acc 0.9375\n",
      "2018-05-04T16:22:28.098401: step 8306, loss 0.244957, acc 0.875\n",
      "2018-05-04T16:22:29.211285: step 8307, loss 0.522789, acc 0.828125\n",
      "2018-05-04T16:22:30.223990: step 8308, loss 0.288323, acc 0.875\n",
      "2018-05-04T16:22:31.251669: step 8309, loss 0.222202, acc 0.921875\n",
      "2018-05-04T16:22:32.260128: step 8310, loss 0.414785, acc 0.828125\n",
      "2018-05-04T16:22:33.333296: step 8311, loss 0.211012, acc 0.921875\n",
      "2018-05-04T16:22:34.402047: step 8312, loss 0.245945, acc 0.90625\n",
      "2018-05-04T16:22:35.503019: step 8313, loss 0.338113, acc 0.859375\n",
      "2018-05-04T16:22:36.580227: step 8314, loss 0.178675, acc 0.9375\n",
      "2018-05-04T16:22:37.655945: step 8315, loss 0.468357, acc 0.828125\n",
      "2018-05-04T16:22:38.697574: step 8316, loss 0.292283, acc 0.875\n",
      "2018-05-04T16:22:39.733741: step 8317, loss 0.253898, acc 0.890625\n",
      "2018-05-04T16:22:40.798210: step 8318, loss 0.243503, acc 0.90625\n",
      "2018-05-04T16:22:41.952334: step 8319, loss 0.3157, acc 0.90625\n",
      "2018-05-04T16:22:43.047625: step 8320, loss 0.230163, acc 0.953125\n",
      "2018-05-04T16:22:44.052332: step 8321, loss 0.336318, acc 0.90625\n",
      "2018-05-04T16:22:45.054016: step 8322, loss 0.347381, acc 0.875\n",
      "2018-05-04T16:22:46.075889: step 8323, loss 0.345516, acc 0.890625\n",
      "2018-05-04T16:22:47.107872: step 8324, loss 0.220223, acc 0.9375\n",
      "2018-05-04T16:22:48.129496: step 8325, loss 0.317646, acc 0.859375\n",
      "2018-05-04T16:22:49.144933: step 8326, loss 0.31327, acc 0.859375\n",
      "2018-05-04T16:22:50.154415: step 8327, loss 0.284915, acc 0.90625\n",
      "2018-05-04T16:22:51.187407: step 8328, loss 0.187955, acc 0.96875\n",
      "2018-05-04T16:22:52.195068: step 8329, loss 0.26651, acc 0.890625\n",
      "2018-05-04T16:22:53.198030: step 8330, loss 0.217323, acc 0.921875\n",
      "2018-05-04T16:22:54.222210: step 8331, loss 0.327579, acc 0.875\n",
      "2018-05-04T16:22:55.228833: step 8332, loss 0.280082, acc 0.875\n",
      "2018-05-04T16:22:56.275054: step 8333, loss 0.243061, acc 0.890625\n",
      "2018-05-04T16:22:57.278507: step 8334, loss 0.298247, acc 0.875\n",
      "2018-05-04T16:22:58.287255: step 8335, loss 0.279956, acc 0.921875\n",
      "2018-05-04T16:22:59.304402: step 8336, loss 0.286162, acc 0.890625\n",
      "2018-05-04T16:23:00.330697: step 8337, loss 0.197125, acc 0.921875\n",
      "2018-05-04T16:23:01.432282: step 8338, loss 0.248955, acc 0.890625\n",
      "2018-05-04T16:23:02.552611: step 8339, loss 0.585027, acc 0.703125\n",
      "2018-05-04T16:23:03.554039: step 8340, loss 0.285981, acc 0.890625\n",
      "2018-05-04T16:23:04.554956: step 8341, loss 0.183552, acc 0.9375\n",
      "2018-05-04T16:23:05.563095: step 8342, loss 0.264615, acc 0.921875\n",
      "2018-05-04T16:23:06.576013: step 8343, loss 0.310373, acc 0.890625\n",
      "2018-05-04T16:23:07.603221: step 8344, loss 0.469844, acc 0.765625\n",
      "2018-05-04T16:23:08.611679: step 8345, loss 0.330402, acc 0.890625\n",
      "2018-05-04T16:23:09.646615: step 8346, loss 0.332339, acc 0.8125\n",
      "2018-05-04T16:23:10.662026: step 8347, loss 0.389167, acc 0.84375\n",
      "2018-05-04T16:23:11.669547: step 8348, loss 0.229097, acc 0.90625\n",
      "2018-05-04T16:23:12.673953: step 8349, loss 0.323087, acc 0.828125\n",
      "2018-05-04T16:23:13.727120: step 8350, loss 0.324882, acc 0.84375\n",
      "2018-05-04T16:23:14.792105: step 8351, loss 0.258237, acc 0.890625\n",
      "2018-05-04T16:23:15.775269: step 8352, loss 0.389091, acc 0.859375\n",
      "2018-05-04T16:23:16.766404: step 8353, loss 0.363802, acc 0.859375\n",
      "2018-05-04T16:23:17.768019: step 8354, loss 0.355097, acc 0.8125\n",
      "2018-05-04T16:23:18.742183: step 8355, loss 0.236778, acc 0.9375\n",
      "2018-05-04T16:23:19.738299: step 8356, loss 0.257299, acc 0.90625\n",
      "2018-05-04T16:23:20.719072: step 8357, loss 0.323125, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T16:23:21.709784: step 8358, loss 0.255197, acc 0.90625\n",
      "2018-05-04T16:23:22.772684: step 8359, loss 0.267131, acc 0.890625\n",
      "2018-05-04T16:23:23.766124: step 8360, loss 0.321276, acc 0.875\n",
      "2018-05-04T16:23:24.771523: step 8361, loss 0.263018, acc 0.875\n",
      "2018-05-04T16:23:25.757459: step 8362, loss 0.214603, acc 0.890625\n",
      "2018-05-04T16:23:26.824843: step 8363, loss 0.373137, acc 0.828125\n",
      "2018-05-04T16:23:27.840980: step 8364, loss 0.278575, acc 0.890625\n",
      "2018-05-04T16:23:28.803481: step 8365, loss 0.290956, acc 0.875\n",
      "2018-05-04T16:23:29.812914: step 8366, loss 0.338018, acc 0.8125\n",
      "2018-05-04T16:23:30.851326: step 8367, loss 0.33611, acc 0.859375\n",
      "2018-05-04T16:23:31.936620: step 8368, loss 0.369171, acc 0.84375\n",
      "2018-05-04T16:23:32.921110: step 8369, loss 0.326931, acc 0.890625\n",
      "2018-05-04T16:23:33.892809: step 8370, loss 0.206952, acc 0.90625\n",
      "2018-05-04T16:23:34.842438: step 8371, loss 0.378003, acc 0.859375\n",
      "2018-05-04T16:23:35.899797: step 8372, loss 0.394426, acc 0.8125\n",
      "2018-05-04T16:23:36.848068: step 8373, loss 0.24458, acc 0.90625\n",
      "2018-05-04T16:23:37.818523: step 8374, loss 0.250165, acc 0.875\n",
      "2018-05-04T16:23:38.874627: step 8375, loss 0.398511, acc 0.796875\n",
      "2018-05-04T16:23:39.838132: step 8376, loss 0.333516, acc 0.84375\n",
      "2018-05-04T16:23:40.822494: step 8377, loss 0.29757, acc 0.90625\n",
      "2018-05-04T16:23:41.803906: step 8378, loss 0.220586, acc 0.875\n",
      "2018-05-04T16:23:42.791407: step 8379, loss 0.27498, acc 0.890625\n",
      "2018-05-04T16:23:43.766990: step 8380, loss 0.182457, acc 0.953125\n",
      "2018-05-04T16:23:44.800496: step 8381, loss 0.358622, acc 0.90625\n",
      "2018-05-04T16:23:45.768179: step 8382, loss 0.212438, acc 0.90625\n",
      "2018-05-04T16:23:46.746686: step 8383, loss 0.234171, acc 0.890625\n",
      "2018-05-04T16:23:47.715016: step 8384, loss 0.258353, acc 0.875\n",
      "2018-05-04T16:23:48.688293: step 8385, loss 0.294986, acc 0.890625\n",
      "2018-05-04T16:23:49.674480: step 8386, loss 0.18054, acc 0.953125\n",
      "2018-05-04T16:23:50.648605: step 8387, loss 0.227475, acc 0.953125\n",
      "2018-05-04T16:23:51.613176: step 8388, loss 0.227701, acc 0.921875\n",
      "2018-05-04T16:23:52.585726: step 8389, loss 0.394568, acc 0.828125\n",
      "2018-05-04T16:23:53.562699: step 8390, loss 0.293834, acc 0.90625\n",
      "2018-05-04T16:23:54.537986: step 8391, loss 0.244605, acc 0.875\n",
      "2018-05-04T16:23:55.516983: step 8392, loss 0.191762, acc 0.90625\n",
      "2018-05-04T16:23:56.496344: step 8393, loss 0.209892, acc 0.890625\n",
      "2018-05-04T16:23:57.456020: step 8394, loss 0.319094, acc 0.890625\n",
      "2018-05-04T16:23:58.461977: step 8395, loss 0.133612, acc 0.921875\n",
      "2018-05-04T16:23:59.425786: step 8396, loss 0.152276, acc 0.96875\n",
      "2018-05-04T16:24:00.384375: step 8397, loss 0.277869, acc 0.9375\n",
      "2018-05-04T16:24:01.352834: step 8398, loss 0.584779, acc 0.71875\n",
      "2018-05-04T16:24:02.334315: step 8399, loss 0.257851, acc 0.90625\n",
      "2018-05-04T16:24:03.295997: step 8400, loss 0.204195, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T16:24:05.794482: step 8400, loss 0.239379, acc 0.928\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-8400\n",
      "\n",
      "2018-05-04T16:24:06.954883: step 8401, loss 0.301417, acc 0.859375\n",
      "2018-05-04T16:24:07.985858: step 8402, loss 0.27356, acc 0.828125\n",
      "2018-05-04T16:24:09.013053: step 8403, loss 0.31831, acc 0.890625\n",
      "2018-05-04T16:24:10.029481: step 8404, loss 0.244001, acc 0.90625\n",
      "2018-05-04T16:24:11.032747: step 8405, loss 0.293575, acc 0.859375\n",
      "2018-05-04T16:24:12.028720: step 8406, loss 0.172491, acc 0.9375\n",
      "2018-05-04T16:24:13.072377: step 8407, loss 0.284688, acc 0.890625\n",
      "2018-05-04T16:24:14.071616: step 8408, loss 0.24167, acc 0.953125\n",
      "2018-05-04T16:24:15.132373: step 8409, loss 0.36336, acc 0.859375\n",
      "2018-05-04T16:24:16.110304: step 8410, loss 0.358241, acc 0.84375\n",
      "2018-05-04T16:24:17.090278: step 8411, loss 0.218817, acc 0.90625\n",
      "2018-05-04T16:24:18.035672: step 8412, loss 0.214548, acc 0.90625\n",
      "2018-05-04T16:24:19.013413: step 8413, loss 0.368956, acc 0.875\n",
      "2018-05-04T16:24:19.996662: step 8414, loss 0.210345, acc 0.90625\n",
      "2018-05-04T16:24:20.991733: step 8415, loss 0.261115, acc 0.875\n",
      "2018-05-04T16:24:21.947216: step 8416, loss 0.264368, acc 0.9375\n",
      "2018-05-04T16:24:22.950032: step 8417, loss 0.281472, acc 0.890625\n",
      "2018-05-04T16:24:23.945015: step 8418, loss 0.386619, acc 0.875\n",
      "2018-05-04T16:24:25.011875: step 8419, loss 0.385674, acc 0.84375\n",
      "2018-05-04T16:24:26.040290: step 8420, loss 0.21058, acc 0.890625\n",
      "2018-05-04T16:24:27.036925: step 8421, loss 0.364664, acc 0.828125\n",
      "2018-05-04T16:24:28.024297: step 8422, loss 0.259243, acc 0.890625\n",
      "2018-05-04T16:24:29.048539: step 8423, loss 0.28948, acc 0.890625\n",
      "2018-05-04T16:24:30.019405: step 8424, loss 0.372407, acc 0.859375\n",
      "2018-05-04T16:24:31.022266: step 8425, loss 0.320798, acc 0.875\n",
      "2018-05-04T16:24:32.038261: step 8426, loss 0.412427, acc 0.828125\n",
      "2018-05-04T16:24:33.019621: step 8427, loss 0.223088, acc 0.875\n",
      "2018-05-04T16:24:34.022935: step 8428, loss 0.473521, acc 0.796875\n",
      "2018-05-04T16:24:35.029545: step 8429, loss 0.227361, acc 0.921875\n",
      "2018-05-04T16:24:35.995854: step 8430, loss 0.287868, acc 0.859375\n",
      "2018-05-04T16:24:36.977509: step 8431, loss 0.304197, acc 0.890625\n",
      "2018-05-04T16:24:38.047109: step 8432, loss 0.242537, acc 0.953125\n",
      "2018-05-04T16:24:39.029439: step 8433, loss 0.238397, acc 0.90625\n",
      "2018-05-04T16:24:40.124346: step 8434, loss 0.235586, acc 0.90625\n",
      "2018-05-04T16:24:41.124960: step 8435, loss 0.390036, acc 0.8125\n",
      "2018-05-04T16:24:42.129479: step 8436, loss 0.210795, acc 0.90625\n",
      "2018-05-04T16:24:43.126847: step 8437, loss 0.316808, acc 0.84375\n",
      "2018-05-04T16:24:44.111126: step 8438, loss 0.239639, acc 0.953125\n",
      "2018-05-04T16:24:45.120994: step 8439, loss 0.255925, acc 0.875\n",
      "2018-05-04T16:24:46.109967: step 8440, loss 0.252165, acc 0.921875\n",
      "2018-05-04T16:24:47.096897: step 8441, loss 0.274286, acc 0.90625\n",
      "2018-05-04T16:24:48.151968: step 8442, loss 0.202031, acc 0.921875\n",
      "2018-05-04T16:24:49.114271: step 8443, loss 0.229718, acc 0.921875\n",
      "2018-05-04T16:24:50.101948: step 8444, loss 0.220019, acc 0.921875\n",
      "2018-05-04T16:24:51.113110: step 8445, loss 0.2409, acc 0.90625\n",
      "2018-05-04T16:24:52.102034: step 8446, loss 0.218596, acc 0.9375\n",
      "2018-05-04T16:24:53.091658: step 8447, loss 0.286511, acc 0.890625\n",
      "2018-05-04T16:24:54.098938: step 8448, loss 0.404912, acc 0.796875\n",
      "2018-05-04T16:24:55.105830: step 8449, loss 0.28918, acc 0.875\n",
      "2018-05-04T16:24:56.126156: step 8450, loss 0.211801, acc 0.90625\n",
      "2018-05-04T16:24:57.135899: step 8451, loss 0.304783, acc 0.84375\n",
      "2018-05-04T16:24:58.104696: step 8452, loss 0.412082, acc 0.84375\n",
      "2018-05-04T16:24:59.177339: step 8453, loss 0.192323, acc 0.921875\n",
      "2018-05-04T16:25:00.185240: step 8454, loss 0.281414, acc 0.875\n",
      "2018-05-04T16:25:01.170482: step 8455, loss 0.311373, acc 0.796875\n",
      "2018-05-04T16:25:02.237753: step 8456, loss 0.267763, acc 0.90625\n",
      "2018-05-04T16:25:03.291318: step 8457, loss 0.407085, acc 0.765625\n",
      "2018-05-04T16:25:04.302688: step 8458, loss 0.250643, acc 0.890625\n",
      "2018-05-04T16:25:05.396496: step 8459, loss 0.156757, acc 0.953125\n",
      "2018-05-04T16:25:06.398303: step 8460, loss 0.335693, acc 0.8125\n",
      "2018-05-04T16:25:07.373067: step 8461, loss 0.294967, acc 0.859375\n",
      "2018-05-04T16:25:08.343393: step 8462, loss 0.348383, acc 0.84375\n",
      "2018-05-04T16:25:09.331275: step 8463, loss 0.203664, acc 0.921875\n",
      "2018-05-04T16:25:10.332903: step 8464, loss 0.297384, acc 0.859375\n",
      "2018-05-04T16:25:11.346807: step 8465, loss 0.2201, acc 0.90625\n",
      "2018-05-04T16:25:12.388572: step 8466, loss 0.277017, acc 0.90625\n",
      "2018-05-04T16:25:13.389109: step 8467, loss 0.170677, acc 0.921875\n",
      "2018-05-04T16:25:14.384554: step 8468, loss 0.21831, acc 0.9375\n",
      "2018-05-04T16:25:15.400849: step 8469, loss 0.242617, acc 0.9375\n",
      "2018-05-04T16:25:16.417638: step 8470, loss 0.265232, acc 0.890625\n",
      "2018-05-04T16:25:17.449451: step 8471, loss 0.251986, acc 0.890625\n",
      "2018-05-04T16:25:18.468286: step 8472, loss 0.397269, acc 0.875\n",
      "2018-05-04T16:25:19.476401: step 8473, loss 0.249999, acc 0.859375\n",
      "2018-05-04T16:25:20.463546: step 8474, loss 0.405258, acc 0.875\n",
      "2018-05-04T16:25:21.459999: step 8475, loss 0.518003, acc 0.796875\n",
      "2018-05-04T16:25:22.454293: step 8476, loss 0.234538, acc 0.859375\n",
      "2018-05-04T16:25:23.512190: step 8477, loss 0.176076, acc 0.90625\n",
      "2018-05-04T16:25:24.513952: step 8478, loss 0.364544, acc 0.84375\n",
      "2018-05-04T16:25:25.518130: step 8479, loss 0.44688, acc 0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T16:25:26.525961: step 8480, loss 0.321075, acc 0.859375\n",
      "2018-05-04T16:25:27.514704: step 8481, loss 0.311187, acc 0.875\n",
      "2018-05-04T16:25:28.494691: step 8482, loss 0.2321, acc 0.875\n",
      "2018-05-04T16:25:29.496172: step 8483, loss 0.218966, acc 0.90625\n",
      "2018-05-04T16:25:30.515580: step 8484, loss 0.252679, acc 0.90625\n",
      "2018-05-04T16:25:31.537345: step 8485, loss 0.330554, acc 0.84375\n",
      "2018-05-04T16:25:32.588799: step 8486, loss 0.220479, acc 0.890625\n",
      "2018-05-04T16:25:33.644067: step 8487, loss 0.285121, acc 0.828125\n",
      "2018-05-04T16:25:34.699050: step 8488, loss 0.377725, acc 0.90625\n",
      "2018-05-04T16:25:35.797540: step 8489, loss 0.333373, acc 0.84375\n",
      "2018-05-04T16:25:36.885584: step 8490, loss 0.269695, acc 0.921875\n",
      "2018-05-04T16:25:37.897215: step 8491, loss 0.316938, acc 0.859375\n",
      "2018-05-04T16:25:38.961728: step 8492, loss 0.20032, acc 0.90625\n",
      "2018-05-04T16:25:39.962370: step 8493, loss 0.388624, acc 0.78125\n",
      "2018-05-04T16:25:41.155891: step 8494, loss 0.290672, acc 0.90625\n",
      "2018-05-04T16:25:42.201699: step 8495, loss 0.208587, acc 0.921875\n",
      "2018-05-04T16:25:43.183475: step 8496, loss 0.315913, acc 0.859375\n",
      "2018-05-04T16:25:44.175609: step 8497, loss 0.280275, acc 0.90625\n",
      "2018-05-04T16:25:45.157075: step 8498, loss 0.28231, acc 0.890625\n",
      "2018-05-04T16:25:46.152469: step 8499, loss 0.218931, acc 0.890625\n",
      "2018-05-04T16:25:47.183011: step 8500, loss 0.434565, acc 0.78125\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T16:25:50.070531: step 8500, loss 0.245154, acc 0.918\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-8500\n",
      "\n",
      "2018-05-04T16:25:51.228082: step 8501, loss 0.431136, acc 0.828125\n",
      "2018-05-04T16:25:52.277004: step 8502, loss 0.346538, acc 0.90625\n",
      "2018-05-04T16:25:53.384758: step 8503, loss 0.300768, acc 0.859375\n",
      "2018-05-04T16:25:54.455973: step 8504, loss 0.117153, acc 0.984375\n",
      "2018-05-04T16:25:55.544605: step 8505, loss 0.224808, acc 0.890625\n",
      "2018-05-04T16:25:56.605849: step 8506, loss 0.354327, acc 0.84375\n",
      "2018-05-04T16:25:57.678703: step 8507, loss 0.267344, acc 0.875\n",
      "2018-05-04T16:25:58.736690: step 8508, loss 0.219968, acc 0.9375\n",
      "2018-05-04T16:25:59.759948: step 8509, loss 0.27636, acc 0.890625\n",
      "2018-05-04T16:26:00.884885: step 8510, loss 0.182646, acc 0.9375\n",
      "2018-05-04T16:26:01.890190: step 8511, loss 0.307575, acc 0.875\n",
      "2018-05-04T16:26:02.910720: step 8512, loss 0.24129, acc 0.921875\n",
      "2018-05-04T16:26:03.921940: step 8513, loss 0.341247, acc 0.8125\n",
      "2018-05-04T16:26:04.936894: step 8514, loss 0.324759, acc 0.921875\n",
      "2018-05-04T16:26:05.967499: step 8515, loss 0.311417, acc 0.875\n",
      "2018-05-04T16:26:07.005788: step 8516, loss 0.304076, acc 0.875\n",
      "2018-05-04T16:26:08.136078: step 8517, loss 0.233168, acc 0.921875\n",
      "2018-05-04T16:26:09.244954: step 8518, loss 0.27701, acc 0.875\n",
      "2018-05-04T16:26:10.266222: step 8519, loss 0.178462, acc 0.9375\n",
      "2018-05-04T16:26:11.272835: step 8520, loss 0.364698, acc 0.859375\n",
      "2018-05-04T16:26:12.292579: step 8521, loss 0.352346, acc 0.859375\n",
      "2018-05-04T16:26:13.314472: step 8522, loss 0.265033, acc 0.921875\n",
      "2018-05-04T16:26:14.343011: step 8523, loss 0.281847, acc 0.875\n",
      "2018-05-04T16:26:15.442399: step 8524, loss 0.186087, acc 0.9375\n",
      "2018-05-04T16:26:16.499173: step 8525, loss 0.197031, acc 0.953125\n",
      "2018-05-04T16:26:17.551484: step 8526, loss 0.260565, acc 0.921875\n",
      "2018-05-04T16:26:18.588516: step 8527, loss 0.252568, acc 0.859375\n",
      "2018-05-04T16:26:19.614471: step 8528, loss 0.34123, acc 0.890625\n",
      "2018-05-04T16:26:20.669162: step 8529, loss 0.195951, acc 0.890625\n",
      "2018-05-04T16:26:21.722128: step 8530, loss 0.218276, acc 0.9375\n",
      "2018-05-04T16:26:22.763955: step 8531, loss 0.183182, acc 0.9375\n",
      "2018-05-04T16:26:23.804095: step 8532, loss 0.283607, acc 0.90625\n",
      "2018-05-04T16:26:24.846518: step 8533, loss 0.282123, acc 0.9375\n",
      "2018-05-04T16:26:25.875170: step 8534, loss 0.356666, acc 0.84375\n",
      "2018-05-04T16:26:26.908278: step 8535, loss 0.43607, acc 0.78125\n",
      "2018-05-04T16:26:27.933323: step 8536, loss 0.197636, acc 0.9375\n",
      "2018-05-04T16:26:28.959696: step 8537, loss 0.351724, acc 0.890625\n",
      "2018-05-04T16:26:30.022774: step 8538, loss 0.2778, acc 0.859375\n",
      "2018-05-04T16:26:31.042506: step 8539, loss 0.257461, acc 0.890625\n",
      "2018-05-04T16:26:32.064817: step 8540, loss 0.392956, acc 0.84375\n",
      "2018-05-04T16:26:33.118669: step 8541, loss 0.398099, acc 0.8125\n",
      "2018-05-04T16:26:34.245338: step 8542, loss 0.247264, acc 0.90625\n",
      "2018-05-04T16:26:35.291237: step 8543, loss 0.300693, acc 0.90625\n",
      "2018-05-04T16:26:36.416786: step 8544, loss 0.364891, acc 0.84375\n",
      "2018-05-04T16:26:37.440421: step 8545, loss 0.354314, acc 0.875\n",
      "2018-05-04T16:26:38.470026: step 8546, loss 0.143556, acc 0.9375\n",
      "2018-05-04T16:26:39.509115: step 8547, loss 0.202862, acc 0.90625\n",
      "2018-05-04T16:26:40.552584: step 8548, loss 0.259963, acc 0.9375\n",
      "2018-05-04T16:26:41.689576: step 8549, loss 0.261456, acc 0.90625\n",
      "2018-05-04T16:26:42.806909: step 8550, loss 0.334719, acc 0.875\n",
      "2018-05-04T16:26:43.903576: step 8551, loss 0.492455, acc 0.796875\n",
      "2018-05-04T16:26:45.107056: step 8552, loss 0.209973, acc 0.921875\n",
      "2018-05-04T16:26:46.229686: step 8553, loss 0.239155, acc 0.90625\n",
      "2018-05-04T16:26:47.299039: step 8554, loss 0.295157, acc 0.84375\n",
      "2018-05-04T16:26:48.336368: step 8555, loss 0.243378, acc 0.90625\n",
      "2018-05-04T16:26:49.374921: step 8556, loss 0.1919, acc 0.9375\n",
      "2018-05-04T16:26:50.404610: step 8557, loss 0.20923, acc 0.90625\n",
      "2018-05-04T16:26:51.458015: step 8558, loss 0.355881, acc 0.828125\n",
      "2018-05-04T16:26:52.506675: step 8559, loss 0.391764, acc 0.828125\n",
      "2018-05-04T16:26:53.521689: step 8560, loss 0.154487, acc 0.9375\n",
      "2018-05-04T16:26:54.550222: step 8561, loss 0.259562, acc 0.875\n",
      "2018-05-04T16:26:55.604954: step 8562, loss 0.208692, acc 0.890625\n",
      "2018-05-04T16:26:56.627907: step 8563, loss 0.240128, acc 0.890625\n",
      "2018-05-04T16:26:57.660121: step 8564, loss 0.332011, acc 0.828125\n",
      "2018-05-04T16:26:58.674780: step 8565, loss 0.292725, acc 0.859375\n",
      "2018-05-04T16:26:59.739868: step 8566, loss 0.252942, acc 0.890625\n",
      "2018-05-04T16:27:00.763844: step 8567, loss 0.290951, acc 0.859375\n",
      "2018-05-04T16:27:01.881751: step 8568, loss 0.326044, acc 0.875\n",
      "2018-05-04T16:27:02.922818: step 8569, loss 0.3742, acc 0.859375\n",
      "2018-05-04T16:27:03.959780: step 8570, loss 0.362118, acc 0.84375\n",
      "2018-05-04T16:27:04.982586: step 8571, loss 0.321954, acc 0.90625\n",
      "2018-05-04T16:27:05.999038: step 8572, loss 0.251539, acc 0.875\n",
      "2018-05-04T16:27:07.009324: step 8573, loss 0.298278, acc 0.875\n",
      "2018-05-04T16:27:08.034073: step 8574, loss 0.292937, acc 0.875\n",
      "2018-05-04T16:27:09.059272: step 8575, loss 0.320844, acc 0.859375\n",
      "2018-05-04T16:27:10.069058: step 8576, loss 0.313034, acc 0.90625\n",
      "2018-05-04T16:27:11.099229: step 8577, loss 0.189557, acc 0.90625\n",
      "2018-05-04T16:27:12.117438: step 8578, loss 0.251064, acc 0.90625\n",
      "2018-05-04T16:27:13.150123: step 8579, loss 0.314676, acc 0.875\n",
      "2018-05-04T16:27:14.156679: step 8580, loss 0.34549, acc 0.875\n",
      "2018-05-04T16:27:15.171608: step 8581, loss 0.180189, acc 0.921875\n",
      "2018-05-04T16:27:16.195273: step 8582, loss 0.215813, acc 0.9375\n",
      "2018-05-04T16:27:17.233777: step 8583, loss 0.188282, acc 0.921875\n",
      "2018-05-04T16:27:18.243298: step 8584, loss 0.299383, acc 0.921875\n",
      "2018-05-04T16:27:19.280593: step 8585, loss 0.26052, acc 0.890625\n",
      "2018-05-04T16:27:20.351260: step 8586, loss 0.404318, acc 0.875\n",
      "2018-05-04T16:27:21.370796: step 8587, loss 0.246117, acc 0.90625\n",
      "2018-05-04T16:27:22.390868: step 8588, loss 0.234588, acc 0.90625\n",
      "2018-05-04T16:27:23.415464: step 8589, loss 0.306125, acc 0.828125\n",
      "2018-05-04T16:27:24.421060: step 8590, loss 0.230261, acc 0.90625\n",
      "2018-05-04T16:27:25.451442: step 8591, loss 0.33717, acc 0.84375\n",
      "2018-05-04T16:27:26.475516: step 8592, loss 0.3669, acc 0.8125\n",
      "2018-05-04T16:27:27.492519: step 8593, loss 0.206239, acc 0.921875\n",
      "2018-05-04T16:27:28.524239: step 8594, loss 0.212438, acc 0.9375\n",
      "2018-05-04T16:27:29.557315: step 8595, loss 0.179387, acc 0.953125\n",
      "2018-05-04T16:27:30.569739: step 8596, loss 0.26388, acc 0.890625\n",
      "2018-05-04T16:27:31.580311: step 8597, loss 0.320693, acc 0.875\n",
      "2018-05-04T16:27:32.601569: step 8598, loss 0.275968, acc 0.921875\n",
      "2018-05-04T16:27:33.690037: step 8599, loss 0.257849, acc 0.875\n",
      "2018-05-04T16:27:34.736181: step 8600, loss 0.351996, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T16:27:37.371340: step 8600, loss 0.24155, acc 0.908\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-8600\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T16:27:38.523218: step 8601, loss 0.42952, acc 0.8125\n",
      "2018-05-04T16:27:39.587847: step 8602, loss 0.201746, acc 0.921875\n",
      "2018-05-04T16:27:40.681912: step 8603, loss 0.186791, acc 0.90625\n",
      "2018-05-04T16:27:41.801846: step 8604, loss 0.256029, acc 0.9375\n",
      "2018-05-04T16:27:42.966891: step 8605, loss 0.23873, acc 0.9375\n",
      "2018-05-04T16:27:44.060004: step 8606, loss 0.193932, acc 0.9375\n",
      "2018-05-04T16:27:45.129271: step 8607, loss 0.251441, acc 0.9375\n",
      "2018-05-04T16:27:46.210932: step 8608, loss 0.2933, acc 0.921875\n",
      "2018-05-04T16:27:47.272461: step 8609, loss 0.399618, acc 0.875\n",
      "2018-05-04T16:27:48.322852: step 8610, loss 0.378496, acc 0.84375\n",
      "2018-05-04T16:27:49.376607: step 8611, loss 0.221208, acc 0.921875\n",
      "2018-05-04T16:27:50.410081: step 8612, loss 0.316854, acc 0.859375\n",
      "2018-05-04T16:27:51.477584: step 8613, loss 0.323166, acc 0.859375\n",
      "2018-05-04T16:27:52.473586: step 8614, loss 0.361738, acc 0.859375\n",
      "2018-05-04T16:27:53.503065: step 8615, loss 0.296448, acc 0.796875\n",
      "2018-05-04T16:27:54.607434: step 8616, loss 0.190693, acc 0.9375\n",
      "2018-05-04T16:27:55.642255: step 8617, loss 0.395941, acc 0.859375\n",
      "2018-05-04T16:27:56.699573: step 8618, loss 0.328953, acc 0.875\n",
      "2018-05-04T16:27:57.794658: step 8619, loss 0.269452, acc 0.875\n",
      "2018-05-04T16:27:58.811696: step 8620, loss 0.263, acc 0.875\n",
      "2018-05-04T16:27:59.844187: step 8621, loss 0.368371, acc 0.8125\n",
      "2018-05-04T16:28:00.860227: step 8622, loss 0.260255, acc 0.875\n",
      "2018-05-04T16:28:01.885880: step 8623, loss 0.226358, acc 0.890625\n",
      "2018-05-04T16:28:02.884059: step 8624, loss 0.313545, acc 0.875\n",
      "2018-05-04T16:28:03.905924: step 8625, loss 0.272379, acc 0.875\n",
      "2018-05-04T16:28:05.083311: step 8626, loss 0.240516, acc 0.90625\n",
      "2018-05-04T16:28:06.237715: step 8627, loss 0.31688, acc 0.875\n",
      "2018-05-04T16:28:07.281210: step 8628, loss 0.25156, acc 0.890625\n",
      "2018-05-04T16:28:08.286149: step 8629, loss 0.276908, acc 0.890625\n",
      "2018-05-04T16:28:09.314200: step 8630, loss 0.253468, acc 0.890625\n",
      "2018-05-04T16:28:10.323937: step 8631, loss 0.223114, acc 0.90625\n",
      "2018-05-04T16:28:11.347532: step 8632, loss 0.283759, acc 0.890625\n",
      "2018-05-04T16:28:12.385118: step 8633, loss 0.225497, acc 0.890625\n",
      "2018-05-04T16:28:13.423067: step 8634, loss 0.270273, acc 0.875\n",
      "2018-05-04T16:28:14.455522: step 8635, loss 0.294602, acc 0.90625\n",
      "2018-05-04T16:28:15.491387: step 8636, loss 0.333016, acc 0.828125\n",
      "2018-05-04T16:28:16.530109: step 8637, loss 0.278813, acc 0.921875\n",
      "2018-05-04T16:28:17.601915: step 8638, loss 0.277554, acc 0.890625\n",
      "2018-05-04T16:28:18.607507: step 8639, loss 0.232487, acc 0.9375\n",
      "2018-05-04T16:28:19.620082: step 8640, loss 0.316791, acc 0.890625\n",
      "2018-05-04T16:28:20.704118: step 8641, loss 0.221697, acc 0.953125\n",
      "2018-05-04T16:28:21.715300: step 8642, loss 0.306565, acc 0.859375\n",
      "2018-05-04T16:28:22.730556: step 8643, loss 0.445134, acc 0.828125\n",
      "2018-05-04T16:28:23.754631: step 8644, loss 0.203592, acc 0.9375\n",
      "2018-05-04T16:28:24.947801: step 8645, loss 0.411616, acc 0.859375\n",
      "2018-05-04T16:28:26.043031: step 8646, loss 0.281238, acc 0.875\n",
      "2018-05-04T16:28:27.060325: step 8647, loss 0.268025, acc 0.859375\n",
      "2018-05-04T16:28:28.074920: step 8648, loss 0.252468, acc 0.890625\n",
      "2018-05-04T16:28:29.075511: step 8649, loss 0.421114, acc 0.859375\n",
      "2018-05-04T16:28:30.083943: step 8650, loss 0.274502, acc 0.890625\n",
      "2018-05-04T16:28:31.120450: step 8651, loss 0.383853, acc 0.84375\n",
      "2018-05-04T16:28:32.181358: step 8652, loss 0.282361, acc 0.890625\n",
      "2018-05-04T16:28:33.287458: step 8653, loss 0.331539, acc 0.859375\n",
      "2018-05-04T16:28:34.391165: step 8654, loss 0.250624, acc 0.90625\n",
      "2018-05-04T16:28:35.495793: step 8655, loss 0.377291, acc 0.875\n",
      "2018-05-04T16:28:36.647267: step 8656, loss 0.223484, acc 0.9375\n",
      "2018-05-04T16:28:37.760428: step 8657, loss 0.2868, acc 0.875\n",
      "2018-05-04T16:28:38.794421: step 8658, loss 0.244812, acc 0.9375\n",
      "2018-05-04T16:28:39.840559: step 8659, loss 0.298258, acc 0.890625\n",
      "2018-05-04T16:28:40.913128: step 8660, loss 0.35333, acc 0.859375\n",
      "2018-05-04T16:28:41.945433: step 8661, loss 0.444693, acc 0.8125\n",
      "2018-05-04T16:28:42.944225: step 8662, loss 0.243635, acc 0.921875\n",
      "2018-05-04T16:28:43.966436: step 8663, loss 0.489967, acc 0.828125\n",
      "2018-05-04T16:28:44.963840: step 8664, loss 0.247783, acc 0.84375\n",
      "2018-05-04T16:28:46.033188: step 8665, loss 0.41826, acc 0.859375\n",
      "2018-05-04T16:28:47.077340: step 8666, loss 0.2781, acc 0.875\n",
      "2018-05-04T16:28:48.149152: step 8667, loss 0.262278, acc 0.890625\n",
      "2018-05-04T16:28:49.177155: step 8668, loss 0.284677, acc 0.90625\n",
      "2018-05-04T16:28:50.209952: step 8669, loss 0.315695, acc 0.84375\n",
      "2018-05-04T16:28:51.325783: step 8670, loss 0.355905, acc 0.828125\n",
      "2018-05-04T16:28:52.418326: step 8671, loss 0.221187, acc 0.921875\n",
      "2018-05-04T16:28:53.434724: step 8672, loss 0.306009, acc 0.828125\n",
      "2018-05-04T16:28:54.521781: step 8673, loss 0.387554, acc 0.828125\n",
      "2018-05-04T16:28:55.541288: step 8674, loss 0.273928, acc 0.890625\n",
      "2018-05-04T16:28:56.540676: step 8675, loss 0.328157, acc 0.84375\n",
      "2018-05-04T16:28:57.535368: step 8676, loss 0.31613, acc 0.859375\n",
      "2018-05-04T16:28:58.536014: step 8677, loss 0.260428, acc 0.90625\n",
      "2018-05-04T16:28:59.550407: step 8678, loss 0.304602, acc 0.859375\n",
      "2018-05-04T16:29:00.600846: step 8679, loss 0.254771, acc 0.875\n",
      "2018-05-04T16:29:01.619028: step 8680, loss 0.312002, acc 0.875\n",
      "2018-05-04T16:29:02.640218: step 8681, loss 0.390981, acc 0.828125\n",
      "2018-05-04T16:29:03.668444: step 8682, loss 0.22397, acc 0.90625\n",
      "2018-05-04T16:29:04.773806: step 8683, loss 0.288773, acc 0.859375\n",
      "2018-05-04T16:29:05.771691: step 8684, loss 0.306281, acc 0.859375\n",
      "2018-05-04T16:29:06.847803: step 8685, loss 0.384978, acc 0.828125\n",
      "2018-05-04T16:29:07.843059: step 8686, loss 0.245148, acc 0.90625\n",
      "2018-05-04T16:29:08.865292: step 8687, loss 0.196799, acc 0.953125\n",
      "2018-05-04T16:29:09.874278: step 8688, loss 0.212301, acc 0.921875\n",
      "2018-05-04T16:29:10.884761: step 8689, loss 0.289532, acc 0.859375\n",
      "2018-05-04T16:29:11.974013: step 8690, loss 0.321815, acc 0.875\n",
      "2018-05-04T16:29:12.989097: step 8691, loss 0.255265, acc 0.875\n",
      "2018-05-04T16:29:14.013553: step 8692, loss 0.35887, acc 0.8125\n",
      "2018-05-04T16:29:15.100721: step 8693, loss 0.291127, acc 0.859375\n",
      "2018-05-04T16:29:16.118742: step 8694, loss 0.308624, acc 0.875\n",
      "2018-05-04T16:29:17.194209: step 8695, loss 0.454756, acc 0.796875\n",
      "2018-05-04T16:29:18.269066: step 8696, loss 0.274005, acc 0.890625\n",
      "2018-05-04T16:29:19.289094: step 8697, loss 0.350179, acc 0.859375\n",
      "2018-05-04T16:29:20.306974: step 8698, loss 0.302109, acc 0.875\n",
      "2018-05-04T16:29:21.287148: step 8699, loss 0.194974, acc 0.890625\n",
      "2018-05-04T16:29:22.280408: step 8700, loss 0.243759, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T16:29:24.503903: step 8700, loss 0.245115, acc 0.906\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-8700\n",
      "\n",
      "2018-05-04T16:29:25.589927: step 8701, loss 0.290902, acc 0.859375\n",
      "2018-05-04T16:29:26.610017: step 8702, loss 0.194965, acc 0.90625\n",
      "2018-05-04T16:29:27.711923: step 8703, loss 0.262502, acc 0.890625\n",
      "2018-05-04T16:29:28.709053: step 8704, loss 0.309701, acc 0.859375\n",
      "2018-05-04T16:29:29.694398: step 8705, loss 0.414163, acc 0.84375\n",
      "2018-05-04T16:29:30.695006: step 8706, loss 0.39, acc 0.828125\n",
      "2018-05-04T16:29:31.784217: step 8707, loss 0.285317, acc 0.921875\n",
      "2018-05-04T16:29:32.900183: step 8708, loss 0.370717, acc 0.84375\n",
      "2018-05-04T16:29:33.892490: step 8709, loss 0.34623, acc 0.84375\n",
      "2018-05-04T16:29:34.962570: step 8710, loss 0.359419, acc 0.859375\n",
      "2018-05-04T16:29:35.961181: step 8711, loss 0.227261, acc 0.90625\n",
      "2018-05-04T16:29:36.985244: step 8712, loss 0.213817, acc 0.9375\n",
      "2018-05-04T16:29:37.997988: step 8713, loss 0.392299, acc 0.828125\n",
      "2018-05-04T16:29:39.031120: step 8714, loss 0.279011, acc 0.875\n",
      "2018-05-04T16:29:40.062762: step 8715, loss 0.372849, acc 0.8125\n",
      "2018-05-04T16:29:41.128735: step 8716, loss 0.444377, acc 0.8125\n",
      "2018-05-04T16:29:42.205108: step 8717, loss 0.187313, acc 0.90625\n",
      "2018-05-04T16:29:43.285080: step 8718, loss 0.440302, acc 0.78125\n",
      "2018-05-04T16:29:44.285584: step 8719, loss 0.271907, acc 0.828125\n",
      "2018-05-04T16:29:45.301226: step 8720, loss 0.403619, acc 0.828125\n",
      "2018-05-04T16:29:46.277326: step 8721, loss 0.30454, acc 0.859375\n",
      "2018-05-04T16:29:47.274451: step 8722, loss 0.233757, acc 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T16:29:48.250056: step 8723, loss 0.259695, acc 0.890625\n",
      "2018-05-04T16:29:49.240167: step 8724, loss 0.309128, acc 0.890625\n",
      "2018-05-04T16:29:50.210285: step 8725, loss 0.32706, acc 0.859375\n",
      "2018-05-04T16:29:51.196321: step 8726, loss 0.424544, acc 0.859375\n",
      "2018-05-04T16:29:52.188951: step 8727, loss 0.29801, acc 0.859375\n",
      "2018-05-04T16:29:53.223187: step 8728, loss 0.334159, acc 0.921875\n",
      "2018-05-04T16:29:54.265774: step 8729, loss 0.235712, acc 0.9375\n",
      "2018-05-04T16:29:55.293780: step 8730, loss 0.293642, acc 0.859375\n",
      "2018-05-04T16:29:56.351701: step 8731, loss 0.18586, acc 0.921875\n",
      "2018-05-04T16:29:57.361732: step 8732, loss 0.245648, acc 0.890625\n",
      "2018-05-04T16:29:58.337895: step 8733, loss 0.250113, acc 0.953125\n",
      "2018-05-04T16:29:59.331166: step 8734, loss 0.25328, acc 0.859375\n",
      "2018-05-04T16:30:00.322926: step 8735, loss 0.299952, acc 0.84375\n",
      "2018-05-04T16:30:01.359528: step 8736, loss 0.339787, acc 0.859375\n",
      "2018-05-04T16:30:02.414330: step 8737, loss 0.394055, acc 0.890625\n",
      "2018-05-04T16:30:03.438412: step 8738, loss 0.305103, acc 0.859375\n",
      "2018-05-04T16:30:04.461088: step 8739, loss 0.246207, acc 0.890625\n",
      "2018-05-04T16:30:05.465551: step 8740, loss 0.239693, acc 0.859375\n",
      "2018-05-04T16:30:06.441264: step 8741, loss 0.50369, acc 0.84375\n",
      "2018-05-04T16:30:07.429301: step 8742, loss 0.265313, acc 0.890625\n",
      "2018-05-04T16:30:08.434846: step 8743, loss 0.369009, acc 0.84375\n",
      "2018-05-04T16:30:09.445661: step 8744, loss 0.28998, acc 0.8125\n",
      "2018-05-04T16:30:10.441024: step 8745, loss 0.29156, acc 0.859375\n",
      "2018-05-04T16:30:11.412163: step 8746, loss 0.337104, acc 0.828125\n",
      "2018-05-04T16:30:12.365976: step 8747, loss 0.289055, acc 0.890625\n",
      "2018-05-04T16:30:13.346312: step 8748, loss 0.221775, acc 0.90625\n",
      "2018-05-04T16:30:14.404806: step 8749, loss 0.23781, acc 0.9375\n",
      "2018-05-04T16:30:15.449381: step 8750, loss 0.261399, acc 0.90625\n",
      "2018-05-04T16:30:16.396588: step 8751, loss 0.25056, acc 0.890625\n",
      "2018-05-04T16:30:17.369265: step 8752, loss 0.280438, acc 0.90625\n",
      "2018-05-04T16:30:18.404896: step 8753, loss 0.239918, acc 0.90625\n",
      "2018-05-04T16:30:19.430628: step 8754, loss 0.231949, acc 0.890625\n",
      "2018-05-04T16:30:20.388501: step 8755, loss 0.248017, acc 0.890625\n",
      "2018-05-04T16:30:21.328149: step 8756, loss 0.218726, acc 0.890625\n",
      "2018-05-04T16:30:22.333506: step 8757, loss 0.393058, acc 0.828125\n",
      "2018-05-04T16:30:23.399474: step 8758, loss 0.220883, acc 0.890625\n",
      "2018-05-04T16:30:24.449171: step 8759, loss 0.330493, acc 0.90625\n",
      "2018-05-04T16:30:25.406915: step 8760, loss 0.329037, acc 0.859375\n",
      "2018-05-04T16:30:26.357441: step 8761, loss 0.346057, acc 0.890625\n",
      "2018-05-04T16:30:27.329683: step 8762, loss 0.261958, acc 0.90625\n",
      "2018-05-04T16:30:28.373469: step 8763, loss 0.194069, acc 0.9375\n",
      "2018-05-04T16:30:29.330916: step 8764, loss 0.293295, acc 0.90625\n",
      "2018-05-04T16:30:30.296977: step 8765, loss 0.301107, acc 0.84375\n",
      "2018-05-04T16:30:31.338156: step 8766, loss 0.287501, acc 0.890625\n",
      "2018-05-04T16:30:32.286595: step 8767, loss 0.275211, acc 0.890625\n",
      "2018-05-04T16:30:33.316062: step 8768, loss 0.194875, acc 0.921875\n",
      "2018-05-04T16:30:34.270071: step 8769, loss 0.254862, acc 0.90625\n",
      "2018-05-04T16:30:35.314454: step 8770, loss 0.268878, acc 0.921875\n",
      "2018-05-04T16:30:36.340644: step 8771, loss 0.353577, acc 0.796875\n",
      "2018-05-04T16:30:37.276803: step 8772, loss 0.24383, acc 0.890625\n",
      "2018-05-04T16:30:38.340236: step 8773, loss 0.214832, acc 0.9375\n",
      "2018-05-04T16:30:39.355685: step 8774, loss 0.289523, acc 0.875\n",
      "2018-05-04T16:30:40.310534: step 8775, loss 0.205272, acc 0.9375\n",
      "2018-05-04T16:30:41.342578: step 8776, loss 0.310446, acc 0.84375\n",
      "2018-05-04T16:30:42.357184: step 8777, loss 0.313439, acc 0.890625\n",
      "2018-05-04T16:30:43.317807: step 8778, loss 0.29012, acc 0.890625\n",
      "2018-05-04T16:30:44.274195: step 8779, loss 0.224007, acc 0.90625\n",
      "2018-05-04T16:30:45.301975: step 8780, loss 0.210865, acc 0.921875\n",
      "2018-05-04T16:30:46.331223: step 8781, loss 0.266745, acc 0.9375\n",
      "2018-05-04T16:30:47.263124: step 8782, loss 0.231392, acc 0.84375\n",
      "2018-05-04T16:30:48.215732: step 8783, loss 0.29038, acc 0.859375\n",
      "2018-05-04T16:30:49.242322: step 8784, loss 0.171734, acc 0.953125\n",
      "2018-05-04T16:30:50.203045: step 8785, loss 0.240297, acc 0.9375\n",
      "2018-05-04T16:30:51.240384: step 8786, loss 0.335443, acc 0.890625\n",
      "2018-05-04T16:30:52.221354: step 8787, loss 0.213803, acc 0.953125\n",
      "2018-05-04T16:30:53.243536: step 8788, loss 0.206076, acc 0.890625\n",
      "2018-05-04T16:30:54.172591: step 8789, loss 0.32267, acc 0.890625\n",
      "2018-05-04T16:30:55.194815: step 8790, loss 0.318956, acc 0.875\n",
      "2018-05-04T16:30:56.210832: step 8791, loss 0.352666, acc 0.828125\n",
      "2018-05-04T16:30:57.146052: step 8792, loss 0.322453, acc 0.90625\n",
      "2018-05-04T16:30:58.111920: step 8793, loss 0.508126, acc 0.796875\n",
      "2018-05-04T16:30:59.073849: step 8794, loss 0.187273, acc 0.9375\n",
      "2018-05-04T16:31:00.082450: step 8795, loss 0.255894, acc 0.890625\n",
      "2018-05-04T16:31:01.208183: step 8796, loss 0.216314, acc 0.921875\n",
      "2018-05-04T16:31:02.243463: step 8797, loss 0.187135, acc 0.921875\n",
      "2018-05-04T16:31:03.291897: step 8798, loss 0.303302, acc 0.890625\n",
      "2018-05-04T16:31:04.343298: step 8799, loss 0.219632, acc 0.90625\n",
      "2018-05-04T16:31:05.298481: step 8800, loss 0.177862, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T16:31:07.831632: step 8800, loss 0.258974, acc 0.902\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-8800\n",
      "\n",
      "2018-05-04T16:31:08.911564: step 8801, loss 0.350551, acc 0.875\n",
      "2018-05-04T16:31:09.949281: step 8802, loss 0.256088, acc 0.890625\n",
      "2018-05-04T16:31:10.991004: step 8803, loss 0.186671, acc 0.921875\n",
      "2018-05-04T16:31:12.057153: step 8804, loss 0.252639, acc 0.9375\n",
      "2018-05-04T16:31:13.094871: step 8805, loss 0.215103, acc 0.890625\n",
      "2018-05-04T16:31:14.142133: step 8806, loss 0.327635, acc 0.859375\n",
      "2018-05-04T16:31:15.144281: step 8807, loss 0.233986, acc 0.953125\n",
      "2018-05-04T16:31:16.124663: step 8808, loss 0.24481, acc 0.890625\n",
      "2018-05-04T16:31:17.140980: step 8809, loss 0.384876, acc 0.796875\n",
      "2018-05-04T16:31:18.143832: step 8810, loss 0.268481, acc 0.890625\n",
      "2018-05-04T16:31:19.221127: step 8811, loss 0.405445, acc 0.828125\n",
      "2018-05-04T16:31:20.190354: step 8812, loss 0.224635, acc 0.90625\n",
      "2018-05-04T16:31:21.184174: step 8813, loss 0.499632, acc 0.78125\n",
      "2018-05-04T16:31:22.197643: step 8814, loss 0.231329, acc 0.921875\n",
      "2018-05-04T16:31:23.189848: step 8815, loss 0.286129, acc 0.890625\n",
      "2018-05-04T16:31:24.189545: step 8816, loss 0.335391, acc 0.859375\n",
      "2018-05-04T16:31:25.170845: step 8817, loss 0.211896, acc 0.90625\n",
      "2018-05-04T16:31:26.140765: step 8818, loss 0.32127, acc 0.84375\n",
      "2018-05-04T16:31:27.145385: step 8819, loss 0.286977, acc 0.921875\n",
      "2018-05-04T16:31:28.128786: step 8820, loss 0.362654, acc 0.796875\n",
      "2018-05-04T16:31:29.117848: step 8821, loss 0.484927, acc 0.84375\n",
      "2018-05-04T16:31:30.098982: step 8822, loss 0.240409, acc 0.90625\n",
      "2018-05-04T16:31:31.079752: step 8823, loss 0.322574, acc 0.859375\n",
      "2018-05-04T16:31:32.064598: step 8824, loss 0.394718, acc 0.828125\n",
      "2018-05-04T16:31:33.089408: step 8825, loss 0.227678, acc 0.921875\n",
      "2018-05-04T16:31:34.130794: step 8826, loss 0.242634, acc 0.859375\n",
      "2018-05-04T16:31:35.148274: step 8827, loss 0.437354, acc 0.84375\n",
      "2018-05-04T16:31:36.253340: step 8828, loss 0.365086, acc 0.875\n",
      "2018-05-04T16:31:37.289663: step 8829, loss 0.220829, acc 0.921875\n",
      "2018-05-04T16:31:38.285517: step 8830, loss 0.2442, acc 0.890625\n",
      "2018-05-04T16:31:39.274679: step 8831, loss 0.256415, acc 0.8125\n",
      "2018-05-04T16:31:40.239695: step 8832, loss 0.240032, acc 0.890625\n",
      "2018-05-04T16:31:41.295205: step 8833, loss 0.146415, acc 0.96875\n",
      "2018-05-04T16:31:42.362920: step 8834, loss 0.386146, acc 0.84375\n",
      "2018-05-04T16:31:43.423368: step 8835, loss 0.333923, acc 0.875\n",
      "2018-05-04T16:31:44.410816: step 8836, loss 0.301613, acc 0.859375\n",
      "2018-05-04T16:31:45.422471: step 8837, loss 0.29824, acc 0.859375\n",
      "2018-05-04T16:31:46.411635: step 8838, loss 0.225397, acc 0.875\n",
      "2018-05-04T16:31:47.388650: step 8839, loss 0.282578, acc 0.84375\n",
      "2018-05-04T16:31:48.376482: step 8840, loss 0.289317, acc 0.8125\n",
      "2018-05-04T16:31:49.369561: step 8841, loss 0.242868, acc 0.890625\n",
      "2018-05-04T16:31:50.358272: step 8842, loss 0.305829, acc 0.890625\n",
      "2018-05-04T16:31:51.349803: step 8843, loss 0.219788, acc 0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T16:31:52.318714: step 8844, loss 0.235755, acc 0.90625\n",
      "2018-05-04T16:31:53.302799: step 8845, loss 0.287278, acc 0.875\n",
      "2018-05-04T16:31:54.286551: step 8846, loss 0.217237, acc 0.90625\n",
      "2018-05-04T16:31:55.250836: step 8847, loss 0.337398, acc 0.859375\n",
      "2018-05-04T16:31:56.255714: step 8848, loss 0.286325, acc 0.84375\n",
      "2018-05-04T16:31:57.229068: step 8849, loss 0.238297, acc 0.921875\n",
      "2018-05-04T16:31:58.241256: step 8850, loss 0.24517, acc 0.875\n",
      "2018-05-04T16:31:59.259528: step 8851, loss 0.3682, acc 0.859375\n",
      "2018-05-04T16:32:00.294912: step 8852, loss 0.310472, acc 0.859375\n",
      "2018-05-04T16:32:01.290623: step 8853, loss 0.340174, acc 0.859375\n",
      "2018-05-04T16:32:02.318207: step 8854, loss 0.234706, acc 0.953125\n",
      "2018-05-04T16:32:03.324925: step 8855, loss 0.240314, acc 0.953125\n",
      "2018-05-04T16:32:04.363333: step 8856, loss 0.280259, acc 0.90625\n",
      "2018-05-04T16:32:05.380780: step 8857, loss 0.341079, acc 0.84375\n",
      "2018-05-04T16:32:06.379671: step 8858, loss 0.259606, acc 0.875\n",
      "2018-05-04T16:32:07.359066: step 8859, loss 0.243153, acc 0.890625\n",
      "2018-05-04T16:32:08.328350: step 8860, loss 0.375197, acc 0.828125\n",
      "2018-05-04T16:32:09.315725: step 8861, loss 0.217156, acc 0.953125\n",
      "2018-05-04T16:32:10.291677: step 8862, loss 0.248955, acc 0.890625\n",
      "2018-05-04T16:32:11.325417: step 8863, loss 0.204497, acc 0.921875\n",
      "2018-05-04T16:32:12.403250: step 8864, loss 0.308388, acc 0.859375\n",
      "2018-05-04T16:32:13.416835: step 8865, loss 0.398087, acc 0.796875\n",
      "2018-05-04T16:32:14.447797: step 8866, loss 0.358845, acc 0.8125\n",
      "2018-05-04T16:32:15.437644: step 8867, loss 0.222859, acc 0.90625\n",
      "2018-05-04T16:32:16.424780: step 8868, loss 0.300895, acc 0.90625\n",
      "2018-05-04T16:32:17.402109: step 8869, loss 0.2619, acc 0.890625\n",
      "2018-05-04T16:32:18.377579: step 8870, loss 0.279574, acc 0.875\n",
      "2018-05-04T16:32:19.445787: step 8871, loss 0.197933, acc 0.890625\n",
      "2018-05-04T16:32:20.456324: step 8872, loss 0.207527, acc 0.921875\n",
      "2018-05-04T16:32:21.447990: step 8873, loss 0.22737, acc 0.921875\n",
      "2018-05-04T16:32:22.452659: step 8874, loss 0.369959, acc 0.875\n",
      "2018-05-04T16:32:23.420219: step 8875, loss 0.30294, acc 0.875\n",
      "2018-05-04T16:32:24.414452: step 8876, loss 0.380855, acc 0.84375\n",
      "2018-05-04T16:32:25.406840: step 8877, loss 0.332907, acc 0.84375\n",
      "2018-05-04T16:32:26.399216: step 8878, loss 0.357264, acc 0.828125\n",
      "2018-05-04T16:32:27.403472: step 8879, loss 0.383905, acc 0.828125\n",
      "2018-05-04T16:32:28.406491: step 8880, loss 0.327925, acc 0.875\n",
      "2018-05-04T16:32:29.422556: step 8881, loss 0.399156, acc 0.828125\n",
      "2018-05-04T16:32:30.430969: step 8882, loss 0.280698, acc 0.875\n",
      "2018-05-04T16:32:31.487428: step 8883, loss 0.196673, acc 0.9375\n",
      "2018-05-04T16:32:32.504757: step 8884, loss 0.337626, acc 0.875\n",
      "2018-05-04T16:32:33.490164: step 8885, loss 0.160558, acc 0.921875\n",
      "2018-05-04T16:32:34.505993: step 8886, loss 0.223981, acc 0.921875\n",
      "2018-05-04T16:32:35.512404: step 8887, loss 0.283351, acc 0.921875\n",
      "2018-05-04T16:32:36.506462: step 8888, loss 0.368388, acc 0.84375\n",
      "2018-05-04T16:32:37.499873: step 8889, loss 0.402979, acc 0.828125\n",
      "2018-05-04T16:32:38.494431: step 8890, loss 0.380255, acc 0.828125\n",
      "2018-05-04T16:32:39.524663: step 8891, loss 0.333154, acc 0.84375\n",
      "2018-05-04T16:32:40.542609: step 8892, loss 0.335542, acc 0.828125\n",
      "2018-05-04T16:32:41.576693: step 8893, loss 0.392673, acc 0.875\n",
      "2018-05-04T16:32:42.607682: step 8894, loss 0.36246, acc 0.84375\n",
      "2018-05-04T16:32:43.595190: step 8895, loss 0.336009, acc 0.796875\n",
      "2018-05-04T16:32:44.586023: step 8896, loss 0.250753, acc 0.875\n",
      "2018-05-04T16:32:45.610594: step 8897, loss 0.179894, acc 0.953125\n",
      "2018-05-04T16:32:46.614536: step 8898, loss 0.357095, acc 0.8125\n",
      "2018-05-04T16:32:47.638226: step 8899, loss 0.321506, acc 0.828125\n",
      "2018-05-04T16:32:48.650794: step 8900, loss 0.185601, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T16:32:51.168498: step 8900, loss 0.26333, acc 0.894\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-8900\n",
      "\n",
      "2018-05-04T16:32:52.382591: step 8901, loss 0.330926, acc 0.859375\n",
      "2018-05-04T16:32:53.447300: step 8902, loss 0.366336, acc 0.765625\n",
      "2018-05-04T16:32:54.528018: step 8903, loss 0.273512, acc 0.875\n",
      "2018-05-04T16:32:55.591623: step 8904, loss 0.190493, acc 0.9375\n",
      "2018-05-04T16:32:56.646189: step 8905, loss 0.334153, acc 0.90625\n",
      "2018-05-04T16:32:57.679048: step 8906, loss 0.373501, acc 0.84375\n",
      "2018-05-04T16:32:58.781997: step 8907, loss 0.474972, acc 0.796875\n",
      "2018-05-04T16:32:59.801416: step 8908, loss 0.339052, acc 0.859375\n",
      "2018-05-04T16:33:00.822328: step 8909, loss 0.161467, acc 0.984375\n",
      "2018-05-04T16:33:01.857241: step 8910, loss 0.305011, acc 0.859375\n",
      "2018-05-04T16:33:02.906789: step 8911, loss 0.33266, acc 0.859375\n",
      "2018-05-04T16:33:03.922728: step 8912, loss 0.51264, acc 0.78125\n",
      "2018-05-04T16:33:04.944533: step 8913, loss 0.265171, acc 0.921875\n",
      "2018-05-04T16:33:06.037891: step 8914, loss 0.385495, acc 0.84375\n",
      "2018-05-04T16:33:07.050615: step 8915, loss 0.446975, acc 0.859375\n",
      "2018-05-04T16:33:08.060139: step 8916, loss 0.23189, acc 0.90625\n",
      "2018-05-04T16:33:09.078956: step 8917, loss 0.29286, acc 0.859375\n",
      "2018-05-04T16:33:10.116597: step 8918, loss 0.287002, acc 0.8125\n",
      "2018-05-04T16:33:11.179017: step 8919, loss 0.278082, acc 0.90625\n",
      "2018-05-04T16:33:12.272227: step 8920, loss 0.310553, acc 0.859375\n",
      "2018-05-04T16:33:13.328258: step 8921, loss 0.322347, acc 0.84375\n",
      "2018-05-04T16:33:14.357088: step 8922, loss 0.253624, acc 0.921875\n",
      "2018-05-04T16:33:15.377740: step 8923, loss 0.241082, acc 0.890625\n",
      "2018-05-04T16:33:16.441682: step 8924, loss 0.51321, acc 0.78125\n",
      "2018-05-04T16:33:17.491250: step 8925, loss 0.231607, acc 0.921875\n",
      "2018-05-04T16:33:18.531896: step 8926, loss 0.231859, acc 0.921875\n",
      "2018-05-04T16:33:19.661438: step 8927, loss 0.367902, acc 0.859375\n",
      "2018-05-04T16:33:20.684580: step 8928, loss 0.243691, acc 0.890625\n",
      "2018-05-04T16:33:21.712877: step 8929, loss 0.166958, acc 0.96875\n",
      "2018-05-04T16:33:22.723711: step 8930, loss 0.180177, acc 0.9375\n",
      "2018-05-04T16:33:23.736713: step 8931, loss 0.34245, acc 0.859375\n",
      "2018-05-04T16:33:24.824405: step 8932, loss 0.294388, acc 0.890625\n",
      "2018-05-04T16:33:25.876117: step 8933, loss 0.246745, acc 0.90625\n",
      "2018-05-04T16:33:26.897661: step 8934, loss 0.459279, acc 0.78125\n",
      "2018-05-04T16:33:27.914336: step 8935, loss 0.333703, acc 0.875\n",
      "2018-05-04T16:33:28.914186: step 8936, loss 0.258084, acc 0.890625\n",
      "2018-05-04T16:33:29.905011: step 8937, loss 0.200545, acc 0.953125\n",
      "2018-05-04T16:33:30.927565: step 8938, loss 0.269784, acc 0.890625\n",
      "2018-05-04T16:33:32.047244: step 8939, loss 0.33663, acc 0.859375\n",
      "2018-05-04T16:33:33.152839: step 8940, loss 0.20313, acc 0.9375\n",
      "2018-05-04T16:33:34.182049: step 8941, loss 0.191308, acc 0.953125\n",
      "2018-05-04T16:33:35.199133: step 8942, loss 0.403927, acc 0.84375\n",
      "2018-05-04T16:33:36.213180: step 8943, loss 0.254843, acc 0.859375\n",
      "2018-05-04T16:33:37.213950: step 8944, loss 0.140959, acc 0.953125\n",
      "2018-05-04T16:33:38.222492: step 8945, loss 0.26153, acc 0.90625\n",
      "2018-05-04T16:33:39.232890: step 8946, loss 0.267412, acc 0.875\n",
      "2018-05-04T16:33:40.287846: step 8947, loss 0.32042, acc 0.890625\n",
      "2018-05-04T16:33:41.306846: step 8948, loss 0.365106, acc 0.875\n",
      "2018-05-04T16:33:42.429859: step 8949, loss 0.25982, acc 0.9375\n",
      "2018-05-04T16:33:43.473945: step 8950, loss 0.254308, acc 0.859375\n",
      "2018-05-04T16:33:44.502432: step 8951, loss 0.216616, acc 0.875\n",
      "2018-05-04T16:33:45.501015: step 8952, loss 0.304818, acc 0.90625\n",
      "2018-05-04T16:33:46.505725: step 8953, loss 0.214673, acc 0.9375\n",
      "2018-05-04T16:33:47.532305: step 8954, loss 0.229363, acc 0.90625\n",
      "2018-05-04T16:33:48.540427: step 8955, loss 0.339392, acc 0.859375\n",
      "2018-05-04T16:33:49.576244: step 8956, loss 0.341935, acc 0.8125\n",
      "2018-05-04T16:33:50.711304: step 8957, loss 0.350816, acc 0.84375\n",
      "2018-05-04T16:33:51.725661: step 8958, loss 0.235703, acc 0.9375\n",
      "2018-05-04T16:33:52.737887: step 8959, loss 0.266022, acc 0.875\n",
      "2018-05-04T16:33:53.728709: step 8960, loss 0.130972, acc 0.96875\n",
      "2018-05-04T16:33:54.730434: step 8961, loss 0.281102, acc 0.84375\n",
      "2018-05-04T16:33:55.749727: step 8962, loss 0.291754, acc 0.890625\n",
      "2018-05-04T16:33:56.764017: step 8963, loss 0.228845, acc 0.90625\n",
      "2018-05-04T16:33:57.776889: step 8964, loss 0.332847, acc 0.859375\n",
      "2018-05-04T16:33:58.808478: step 8965, loss 0.174419, acc 0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T16:33:59.909669: step 8966, loss 0.2912, acc 0.90625\n",
      "2018-05-04T16:34:00.948670: step 8967, loss 0.282109, acc 0.859375\n",
      "2018-05-04T16:34:02.033842: step 8968, loss 0.274044, acc 0.890625\n",
      "2018-05-04T16:34:03.056457: step 8969, loss 0.235846, acc 0.890625\n",
      "2018-05-04T16:34:04.090815: step 8970, loss 0.301177, acc 0.890625\n",
      "2018-05-04T16:34:05.103008: step 8971, loss 0.124662, acc 0.96875\n",
      "2018-05-04T16:34:06.088951: step 8972, loss 0.268698, acc 0.890625\n",
      "2018-05-04T16:34:07.086417: step 8973, loss 0.183037, acc 0.921875\n",
      "2018-05-04T16:34:08.091350: step 8974, loss 0.37346, acc 0.796875\n",
      "2018-05-04T16:34:09.101247: step 8975, loss 0.249296, acc 0.890625\n",
      "2018-05-04T16:34:10.139479: step 8976, loss 0.222325, acc 0.90625\n",
      "2018-05-04T16:34:11.152807: step 8977, loss 0.325879, acc 0.875\n",
      "2018-05-04T16:34:12.203124: step 8978, loss 0.223588, acc 0.90625\n",
      "2018-05-04T16:34:13.205880: step 8979, loss 0.256567, acc 0.875\n",
      "2018-05-04T16:34:14.208712: step 8980, loss 0.197235, acc 0.90625\n",
      "2018-05-04T16:34:15.204230: step 8981, loss 0.256658, acc 0.921875\n",
      "2018-05-04T16:34:16.216912: step 8982, loss 0.297331, acc 0.828125\n",
      "2018-05-04T16:34:17.297621: step 8983, loss 0.196035, acc 0.921875\n",
      "2018-05-04T16:34:18.329494: step 8984, loss 0.365577, acc 0.828125\n",
      "2018-05-04T16:34:19.336930: step 8985, loss 0.334072, acc 0.84375\n",
      "2018-05-04T16:34:20.342465: step 8986, loss 0.251665, acc 0.890625\n",
      "2018-05-04T16:34:21.406070: step 8987, loss 0.314389, acc 0.921875\n",
      "2018-05-04T16:34:22.476902: step 8988, loss 0.230432, acc 0.90625\n",
      "2018-05-04T16:34:23.516236: step 8989, loss 0.28111, acc 0.890625\n",
      "2018-05-04T16:34:24.552103: step 8990, loss 0.243424, acc 0.90625\n",
      "2018-05-04T16:34:25.584914: step 8991, loss 0.37317, acc 0.828125\n",
      "2018-05-04T16:34:26.587258: step 8992, loss 0.268115, acc 0.890625\n",
      "2018-05-04T16:34:27.632797: step 8993, loss 0.21976, acc 0.953125\n",
      "2018-05-04T16:34:28.630075: step 8994, loss 0.250152, acc 0.890625\n",
      "2018-05-04T16:34:29.632296: step 8995, loss 0.231015, acc 0.890625\n",
      "2018-05-04T16:34:30.626710: step 8996, loss 0.175343, acc 0.953125\n",
      "2018-05-04T16:34:31.623955: step 8997, loss 0.285411, acc 0.875\n",
      "2018-05-04T16:34:32.722987: step 8998, loss 0.222678, acc 0.859375\n",
      "2018-05-04T16:34:33.831113: step 8999, loss 0.42717, acc 0.796875\n",
      "2018-05-04T16:34:34.935624: step 9000, loss 0.195231, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T16:34:37.388821: step 9000, loss 0.243699, acc 0.902\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-9000\n",
      "\n",
      "2018-05-04T16:34:38.535458: step 9001, loss 0.312279, acc 0.859375\n",
      "2018-05-04T16:34:39.597794: step 9002, loss 0.261836, acc 0.875\n",
      "2018-05-04T16:34:40.664814: step 9003, loss 0.364801, acc 0.8125\n",
      "2018-05-04T16:34:41.723568: step 9004, loss 0.231535, acc 0.875\n",
      "2018-05-04T16:34:42.854380: step 9005, loss 0.262939, acc 0.921875\n",
      "2018-05-04T16:34:43.935017: step 9006, loss 0.182257, acc 0.921875\n",
      "2018-05-04T16:34:44.952413: step 9007, loss 0.118053, acc 0.96875\n",
      "2018-05-04T16:34:46.063792: step 9008, loss 0.278783, acc 0.890625\n",
      "2018-05-04T16:34:47.080966: step 9009, loss 0.404492, acc 0.875\n",
      "2018-05-04T16:34:48.095455: step 9010, loss 0.226056, acc 0.890625\n",
      "2018-05-04T16:34:49.134830: step 9011, loss 0.219772, acc 0.90625\n",
      "2018-05-04T16:34:50.144542: step 9012, loss 0.206918, acc 0.921875\n",
      "2018-05-04T16:34:51.172283: step 9013, loss 0.187333, acc 0.921875\n",
      "2018-05-04T16:34:52.209101: step 9014, loss 0.238879, acc 0.875\n",
      "2018-05-04T16:34:53.224811: step 9015, loss 0.190663, acc 0.9375\n",
      "2018-05-04T16:34:54.263016: step 9016, loss 0.396038, acc 0.84375\n",
      "2018-05-04T16:34:55.290604: step 9017, loss 0.152915, acc 0.953125\n",
      "2018-05-04T16:34:56.338865: step 9018, loss 0.293103, acc 0.875\n",
      "2018-05-04T16:34:57.365916: step 9019, loss 0.310879, acc 0.828125\n",
      "2018-05-04T16:34:58.397561: step 9020, loss 0.290801, acc 0.890625\n",
      "2018-05-04T16:34:59.415615: step 9021, loss 0.227734, acc 0.921875\n",
      "2018-05-04T16:35:00.436743: step 9022, loss 0.542791, acc 0.84375\n",
      "2018-05-04T16:35:01.458713: step 9023, loss 0.212718, acc 0.9375\n",
      "2018-05-04T16:35:02.460641: step 9024, loss 0.282701, acc 0.90625\n",
      "2018-05-04T16:35:03.474574: step 9025, loss 0.365624, acc 0.84375\n",
      "2018-05-04T16:35:04.512500: step 9026, loss 0.243853, acc 0.875\n",
      "2018-05-04T16:35:05.550582: step 9027, loss 0.490927, acc 0.875\n",
      "2018-05-04T16:35:06.553228: step 9028, loss 0.236316, acc 0.890625\n",
      "2018-05-04T16:35:07.570780: step 9029, loss 0.287856, acc 0.875\n",
      "2018-05-04T16:35:08.600075: step 9030, loss 0.244035, acc 0.9375\n",
      "2018-05-04T16:35:09.681618: step 9031, loss 0.411336, acc 0.8125\n",
      "2018-05-04T16:35:10.720947: step 9032, loss 0.275436, acc 0.875\n",
      "2018-05-04T16:35:11.757672: step 9033, loss 0.332962, acc 0.828125\n",
      "2018-05-04T16:35:12.771833: step 9034, loss 0.350154, acc 0.875\n",
      "2018-05-04T16:35:13.947928: step 9035, loss 0.299169, acc 0.859375\n",
      "2018-05-04T16:35:14.961885: step 9036, loss 0.197826, acc 0.9375\n",
      "2018-05-04T16:35:15.989679: step 9037, loss 0.302026, acc 0.859375\n",
      "2018-05-04T16:35:17.010653: step 9038, loss 0.263295, acc 0.890625\n",
      "2018-05-04T16:35:18.023986: step 9039, loss 0.283886, acc 0.859375\n",
      "2018-05-04T16:35:19.045748: step 9040, loss 0.25018, acc 0.890625\n",
      "2018-05-04T16:35:20.094965: step 9041, loss 0.270296, acc 0.890625\n",
      "2018-05-04T16:35:21.117968: step 9042, loss 0.232305, acc 0.890625\n",
      "2018-05-04T16:35:22.221960: step 9043, loss 0.210633, acc 0.90625\n",
      "2018-05-04T16:35:23.224891: step 9044, loss 0.33976, acc 0.859375\n",
      "2018-05-04T16:35:24.221780: step 9045, loss 0.30788, acc 0.875\n",
      "2018-05-04T16:35:25.215474: step 9046, loss 0.321124, acc 0.875\n",
      "2018-05-04T16:35:26.242926: step 9047, loss 0.267648, acc 0.890625\n",
      "2018-05-04T16:35:27.267866: step 9048, loss 0.281634, acc 0.859375\n",
      "2018-05-04T16:35:28.286846: step 9049, loss 0.294691, acc 0.875\n",
      "2018-05-04T16:35:29.294125: step 9050, loss 0.147332, acc 0.984375\n",
      "2018-05-04T16:35:30.306272: step 9051, loss 0.381837, acc 0.84375\n",
      "2018-05-04T16:35:31.336191: step 9052, loss 0.257655, acc 0.875\n",
      "2018-05-04T16:35:32.348906: step 9053, loss 0.208431, acc 0.90625\n",
      "2018-05-04T16:35:33.453468: step 9054, loss 0.331213, acc 0.796875\n",
      "2018-05-04T16:35:34.500791: step 9055, loss 0.168088, acc 0.953125\n",
      "2018-05-04T16:35:35.535143: step 9056, loss 0.449971, acc 0.890625\n",
      "2018-05-04T16:35:36.647003: step 9057, loss 0.202735, acc 0.921875\n",
      "2018-05-04T16:35:37.680859: step 9058, loss 0.157741, acc 0.9375\n",
      "2018-05-04T16:35:38.689844: step 9059, loss 0.300563, acc 0.875\n",
      "2018-05-04T16:35:39.778418: step 9060, loss 0.309599, acc 0.875\n",
      "2018-05-04T16:35:40.793755: step 9061, loss 0.20888, acc 0.90625\n",
      "2018-05-04T16:35:41.814031: step 9062, loss 0.294053, acc 0.890625\n",
      "2018-05-04T16:35:42.817667: step 9063, loss 0.191353, acc 0.953125\n",
      "2018-05-04T16:35:43.833270: step 9064, loss 0.393555, acc 0.84375\n",
      "2018-05-04T16:35:44.832079: step 9065, loss 0.23051, acc 0.890625\n",
      "2018-05-04T16:35:45.857786: step 9066, loss 0.211321, acc 0.921875\n",
      "2018-05-04T16:35:46.857751: step 9067, loss 0.218589, acc 0.921875\n",
      "2018-05-04T16:35:47.956405: step 9068, loss 0.279062, acc 0.90625\n",
      "2018-05-04T16:35:48.990116: step 9069, loss 0.206299, acc 0.921875\n",
      "2018-05-04T16:35:49.983846: step 9070, loss 0.243196, acc 0.90625\n",
      "2018-05-04T16:35:51.018486: step 9071, loss 0.201016, acc 0.90625\n",
      "2018-05-04T16:35:52.012906: step 9072, loss 0.32149, acc 0.90625\n",
      "2018-05-04T16:35:53.034852: step 9073, loss 0.353126, acc 0.84375\n",
      "2018-05-04T16:35:54.036482: step 9074, loss 0.305717, acc 0.875\n",
      "2018-05-04T16:35:55.025244: step 9075, loss 0.303232, acc 0.875\n",
      "2018-05-04T16:35:56.075954: step 9076, loss 0.347105, acc 0.890625\n",
      "2018-05-04T16:35:57.104158: step 9077, loss 0.201097, acc 0.9375\n",
      "2018-05-04T16:35:58.120810: step 9078, loss 0.304991, acc 0.859375\n",
      "2018-05-04T16:35:59.173221: step 9079, loss 0.319862, acc 0.859375\n",
      "2018-05-04T16:36:00.178883: step 9080, loss 0.280516, acc 0.890625\n",
      "2018-05-04T16:36:01.234398: step 9081, loss 0.290576, acc 0.890625\n",
      "2018-05-04T16:36:02.254503: step 9082, loss 0.41109, acc 0.875\n",
      "2018-05-04T16:36:03.274044: step 9083, loss 0.35787, acc 0.828125\n",
      "2018-05-04T16:36:04.314221: step 9084, loss 0.427288, acc 0.828125\n",
      "2018-05-04T16:36:05.341168: step 9085, loss 0.358769, acc 0.84375\n",
      "2018-05-04T16:36:06.378579: step 9086, loss 0.231618, acc 0.890625\n",
      "2018-05-04T16:36:07.385294: step 9087, loss 0.261769, acc 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T16:36:08.398556: step 9088, loss 0.196184, acc 0.9375\n",
      "2018-05-04T16:36:09.389409: step 9089, loss 0.149505, acc 0.921875\n",
      "2018-05-04T16:36:10.393643: step 9090, loss 0.268759, acc 0.90625\n",
      "2018-05-04T16:36:11.416084: step 9091, loss 0.295707, acc 0.875\n",
      "2018-05-04T16:36:12.402315: step 9092, loss 0.432624, acc 0.828125\n",
      "2018-05-04T16:36:13.420143: step 9093, loss 0.308737, acc 0.875\n",
      "2018-05-04T16:36:14.451969: step 9094, loss 0.279964, acc 0.859375\n",
      "2018-05-04T16:36:15.477605: step 9095, loss 0.289628, acc 0.859375\n",
      "2018-05-04T16:36:16.489826: step 9096, loss 0.417883, acc 0.8125\n",
      "2018-05-04T16:36:17.512865: step 9097, loss 0.235006, acc 0.890625\n",
      "2018-05-04T16:36:18.519940: step 9098, loss 0.318216, acc 0.875\n",
      "2018-05-04T16:36:19.517398: step 9099, loss 0.242612, acc 0.921875\n",
      "2018-05-04T16:36:20.509329: step 9100, loss 0.238732, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T16:36:23.021122: step 9100, loss 0.249566, acc 0.9\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-9100\n",
      "\n",
      "2018-05-04T16:36:24.171283: step 9101, loss 0.218869, acc 0.9375\n",
      "2018-05-04T16:36:25.265602: step 9102, loss 0.342653, acc 0.859375\n",
      "2018-05-04T16:36:26.352235: step 9103, loss 0.415892, acc 0.84375\n",
      "2018-05-04T16:36:27.404851: step 9104, loss 0.319858, acc 0.859375\n",
      "2018-05-04T16:36:28.452300: step 9105, loss 0.258748, acc 0.890625\n",
      "2018-05-04T16:36:29.488560: step 9106, loss 0.252171, acc 0.90625\n",
      "2018-05-04T16:36:30.602982: step 9107, loss 0.319617, acc 0.859375\n",
      "2018-05-04T16:36:31.623283: step 9108, loss 0.233771, acc 0.90625\n",
      "2018-05-04T16:36:32.646577: step 9109, loss 0.420296, acc 0.84375\n",
      "2018-05-04T16:36:33.654566: step 9110, loss 0.330317, acc 0.875\n",
      "2018-05-04T16:36:34.685846: step 9111, loss 0.268331, acc 0.90625\n",
      "2018-05-04T16:36:35.720079: step 9112, loss 0.447122, acc 0.8125\n",
      "2018-05-04T16:36:36.751833: step 9113, loss 0.264678, acc 0.890625\n",
      "2018-05-04T16:36:37.766860: step 9114, loss 0.422725, acc 0.8125\n",
      "2018-05-04T16:36:38.785999: step 9115, loss 0.264467, acc 0.890625\n",
      "2018-05-04T16:36:39.893218: step 9116, loss 0.385474, acc 0.859375\n",
      "2018-05-04T16:36:40.919180: step 9117, loss 0.340511, acc 0.84375\n",
      "2018-05-04T16:36:41.969975: step 9118, loss 0.313084, acc 0.875\n",
      "2018-05-04T16:36:43.013012: step 9119, loss 0.380893, acc 0.84375\n",
      "2018-05-04T16:36:44.032879: step 9120, loss 0.24802, acc 0.90625\n",
      "2018-05-04T16:36:45.042123: step 9121, loss 0.421484, acc 0.859375\n",
      "2018-05-04T16:36:46.063324: step 9122, loss 0.348904, acc 0.859375\n",
      "2018-05-04T16:36:47.168104: step 9123, loss 0.305124, acc 0.828125\n",
      "2018-05-04T16:36:48.195777: step 9124, loss 0.281774, acc 0.859375\n",
      "2018-05-04T16:36:49.234073: step 9125, loss 0.283766, acc 0.890625\n",
      "2018-05-04T16:36:50.256694: step 9126, loss 0.283068, acc 0.90625\n",
      "2018-05-04T16:36:51.354884: step 9127, loss 0.388349, acc 0.8125\n",
      "2018-05-04T16:36:52.364059: step 9128, loss 0.25613, acc 0.90625\n",
      "2018-05-04T16:36:53.457277: step 9129, loss 0.316913, acc 0.828125\n",
      "2018-05-04T16:36:54.581988: step 9130, loss 0.245919, acc 0.859375\n",
      "2018-05-04T16:36:55.590451: step 9131, loss 0.327184, acc 0.875\n",
      "2018-05-04T16:36:56.627449: step 9132, loss 0.258165, acc 0.859375\n",
      "2018-05-04T16:36:57.651729: step 9133, loss 0.303217, acc 0.890625\n",
      "2018-05-04T16:36:58.682273: step 9134, loss 0.223027, acc 0.890625\n",
      "2018-05-04T16:36:59.708591: step 9135, loss 0.270268, acc 0.890625\n",
      "2018-05-04T16:37:00.733511: step 9136, loss 0.218146, acc 0.890625\n",
      "2018-05-04T16:37:01.748699: step 9137, loss 0.294878, acc 0.875\n",
      "2018-05-04T16:37:02.783322: step 9138, loss 0.339206, acc 0.875\n",
      "2018-05-04T16:37:03.826732: step 9139, loss 0.218959, acc 0.9375\n",
      "2018-05-04T16:37:04.930237: step 9140, loss 0.333232, acc 0.90625\n",
      "2018-05-04T16:37:06.045826: step 9141, loss 0.314536, acc 0.890625\n",
      "2018-05-04T16:37:07.091459: step 9142, loss 0.353059, acc 0.84375\n",
      "2018-05-04T16:37:08.096138: step 9143, loss 0.241404, acc 0.890625\n",
      "2018-05-04T16:37:09.138675: step 9144, loss 0.269874, acc 0.890625\n",
      "2018-05-04T16:37:10.140267: step 9145, loss 0.216361, acc 0.90625\n",
      "2018-05-04T16:37:11.152454: step 9146, loss 0.205891, acc 0.90625\n",
      "2018-05-04T16:37:12.170722: step 9147, loss 0.319658, acc 0.875\n",
      "2018-05-04T16:37:13.183313: step 9148, loss 0.272501, acc 0.859375\n",
      "2018-05-04T16:37:14.228640: step 9149, loss 0.179541, acc 0.953125\n",
      "2018-05-04T16:37:15.288971: step 9150, loss 0.273723, acc 0.84375\n",
      "2018-05-04T16:37:16.337840: step 9151, loss 0.260035, acc 0.90625\n",
      "2018-05-04T16:37:17.407021: step 9152, loss 0.291109, acc 0.890625\n",
      "2018-05-04T16:37:18.417089: step 9153, loss 0.318899, acc 0.890625\n",
      "2018-05-04T16:37:19.427382: step 9154, loss 0.281102, acc 0.921875\n",
      "2018-05-04T16:37:20.486737: step 9155, loss 0.375721, acc 0.84375\n",
      "2018-05-04T16:37:21.485364: step 9156, loss 0.350092, acc 0.8125\n",
      "2018-05-04T16:37:22.492218: step 9157, loss 0.261737, acc 0.890625\n",
      "2018-05-04T16:37:23.530183: step 9158, loss 0.259809, acc 0.890625\n",
      "2018-05-04T16:37:24.592841: step 9159, loss 0.216234, acc 0.921875\n",
      "2018-05-04T16:37:25.707192: step 9160, loss 0.203164, acc 0.921875\n",
      "2018-05-04T16:37:26.744523: step 9161, loss 0.178339, acc 0.90625\n",
      "2018-05-04T16:37:27.781899: step 9162, loss 0.157, acc 0.953125\n",
      "2018-05-04T16:37:28.836886: step 9163, loss 0.243482, acc 0.875\n",
      "2018-05-04T16:37:29.835185: step 9164, loss 0.446268, acc 0.828125\n",
      "2018-05-04T16:37:30.857519: step 9165, loss 0.211924, acc 0.921875\n",
      "2018-05-04T16:37:31.868327: step 9166, loss 0.233966, acc 0.921875\n",
      "2018-05-04T16:37:32.915945: step 9167, loss 0.276853, acc 0.921875\n",
      "2018-05-04T16:37:33.997136: step 9168, loss 0.236136, acc 0.921875\n",
      "2018-05-04T16:37:35.080797: step 9169, loss 0.253344, acc 0.90625\n",
      "2018-05-04T16:37:36.168354: step 9170, loss 0.350941, acc 0.84375\n",
      "2018-05-04T16:37:37.216352: step 9171, loss 0.223378, acc 0.9375\n",
      "2018-05-04T16:37:38.235994: step 9172, loss 0.15238, acc 0.90625\n",
      "2018-05-04T16:37:39.264502: step 9173, loss 0.209003, acc 0.875\n",
      "2018-05-04T16:37:40.298181: step 9174, loss 0.319542, acc 0.890625\n",
      "2018-05-04T16:37:41.344720: step 9175, loss 0.310042, acc 0.90625\n",
      "2018-05-04T16:37:42.384433: step 9176, loss 0.370312, acc 0.859375\n",
      "2018-05-04T16:37:43.429339: step 9177, loss 0.269865, acc 0.84375\n",
      "2018-05-04T16:37:44.450248: step 9178, loss 0.370783, acc 0.859375\n",
      "2018-05-04T16:37:45.522974: step 9179, loss 0.233955, acc 0.90625\n",
      "2018-05-04T16:37:46.591693: step 9180, loss 0.220536, acc 0.9375\n",
      "2018-05-04T16:37:47.632785: step 9181, loss 0.173182, acc 0.921875\n",
      "2018-05-04T16:37:48.647347: step 9182, loss 0.208878, acc 0.90625\n",
      "2018-05-04T16:37:49.651137: step 9183, loss 0.36185, acc 0.8125\n",
      "2018-05-04T16:37:50.642874: step 9184, loss 0.217936, acc 0.9375\n",
      "2018-05-04T16:37:51.695397: step 9185, loss 0.259929, acc 0.9375\n",
      "2018-05-04T16:37:52.719891: step 9186, loss 0.385099, acc 0.859375\n",
      "2018-05-04T16:37:53.750019: step 9187, loss 0.230748, acc 0.953125\n",
      "2018-05-04T16:37:54.848141: step 9188, loss 0.163927, acc 0.9375\n",
      "2018-05-04T16:37:55.972138: step 9189, loss 0.245739, acc 0.890625\n",
      "2018-05-04T16:37:56.980484: step 9190, loss 0.268084, acc 0.875\n",
      "2018-05-04T16:37:57.981866: step 9191, loss 0.235417, acc 0.90625\n",
      "2018-05-04T16:37:58.967637: step 9192, loss 0.322607, acc 0.859375\n",
      "2018-05-04T16:37:59.958528: step 9193, loss 0.289277, acc 0.796875\n",
      "2018-05-04T16:38:00.957105: step 9194, loss 0.195384, acc 0.90625\n",
      "2018-05-04T16:38:01.969072: step 9195, loss 0.219298, acc 0.890625\n",
      "2018-05-04T16:38:02.992973: step 9196, loss 0.444131, acc 0.875\n",
      "2018-05-04T16:38:04.035660: step 9197, loss 0.42328, acc 0.859375\n",
      "2018-05-04T16:38:05.066818: step 9198, loss 0.291102, acc 0.875\n",
      "2018-05-04T16:38:06.092293: step 9199, loss 0.262992, acc 0.859375\n",
      "2018-05-04T16:38:07.148148: step 9200, loss 0.212582, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T16:38:09.351832: step 9200, loss 0.239566, acc 0.918\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-9200\n",
      "\n",
      "2018-05-04T16:38:10.447889: step 9201, loss 0.577218, acc 0.796875\n",
      "2018-05-04T16:38:11.539316: step 9202, loss 0.179534, acc 0.9375\n",
      "2018-05-04T16:38:12.557917: step 9203, loss 0.363167, acc 0.828125\n",
      "2018-05-04T16:38:13.581320: step 9204, loss 0.159428, acc 0.9375\n",
      "2018-05-04T16:38:14.574533: step 9205, loss 0.281726, acc 0.84375\n",
      "2018-05-04T16:38:15.562126: step 9206, loss 0.290328, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T16:38:16.543405: step 9207, loss 0.287957, acc 0.90625\n",
      "2018-05-04T16:38:17.567911: step 9208, loss 0.368768, acc 0.859375\n",
      "2018-05-04T16:38:18.595628: step 9209, loss 0.311101, acc 0.84375\n",
      "2018-05-04T16:38:19.634480: step 9210, loss 0.221439, acc 0.90625\n",
      "2018-05-04T16:38:20.634975: step 9211, loss 0.32124, acc 0.875\n",
      "2018-05-04T16:38:21.621124: step 9212, loss 0.172586, acc 0.90625\n",
      "2018-05-04T16:38:22.599528: step 9213, loss 0.402119, acc 0.84375\n",
      "2018-05-04T16:38:23.596287: step 9214, loss 0.269988, acc 0.859375\n",
      "2018-05-04T16:38:24.590339: step 9215, loss 0.275333, acc 0.84375\n",
      "2018-05-04T16:38:25.577384: step 9216, loss 0.14947, acc 0.9375\n",
      "2018-05-04T16:38:26.605353: step 9217, loss 0.258539, acc 0.890625\n",
      "2018-05-04T16:38:27.628720: step 9218, loss 0.271062, acc 0.859375\n",
      "2018-05-04T16:38:28.653493: step 9219, loss 0.226278, acc 0.875\n",
      "2018-05-04T16:38:29.665309: step 9220, loss 0.27248, acc 0.90625\n",
      "2018-05-04T16:38:30.774896: step 9221, loss 0.410029, acc 0.875\n",
      "2018-05-04T16:38:31.796810: step 9222, loss 0.227724, acc 0.921875\n",
      "2018-05-04T16:38:32.811497: step 9223, loss 0.296813, acc 0.859375\n",
      "2018-05-04T16:38:33.817096: step 9224, loss 0.252377, acc 0.875\n",
      "2018-05-04T16:38:34.877645: step 9225, loss 0.234308, acc 0.890625\n",
      "2018-05-04T16:38:35.948012: step 9226, loss 0.337483, acc 0.90625\n",
      "2018-05-04T16:38:36.914800: step 9227, loss 0.322912, acc 0.828125\n",
      "2018-05-04T16:38:37.877205: step 9228, loss 0.332022, acc 0.84375\n",
      "2018-05-04T16:38:38.858825: step 9229, loss 0.24818, acc 0.875\n",
      "2018-05-04T16:38:39.857483: step 9230, loss 0.257632, acc 0.90625\n",
      "2018-05-04T16:38:40.869300: step 9231, loss 0.321738, acc 0.859375\n",
      "2018-05-04T16:38:41.832209: step 9232, loss 0.25306, acc 0.921875\n",
      "2018-05-04T16:38:42.809881: step 9233, loss 0.344816, acc 0.859375\n",
      "2018-05-04T16:38:43.808219: step 9234, loss 0.355062, acc 0.828125\n",
      "2018-05-04T16:38:44.796655: step 9235, loss 0.498182, acc 0.8125\n",
      "2018-05-04T16:38:45.785285: step 9236, loss 0.327022, acc 0.8125\n",
      "2018-05-04T16:38:46.775661: step 9237, loss 0.256371, acc 0.890625\n",
      "2018-05-04T16:38:47.750354: step 9238, loss 0.296324, acc 0.875\n",
      "2018-05-04T16:38:48.803358: step 9239, loss 0.421466, acc 0.765625\n",
      "2018-05-04T16:38:49.772302: step 9240, loss 0.215166, acc 0.921875\n",
      "2018-05-04T16:38:50.818941: step 9241, loss 0.429673, acc 0.84375\n",
      "2018-05-04T16:38:51.771158: step 9242, loss 0.39566, acc 0.875\n",
      "2018-05-04T16:38:52.863388: step 9243, loss 0.233088, acc 0.875\n",
      "2018-05-04T16:38:53.847840: step 9244, loss 0.317624, acc 0.828125\n",
      "2018-05-04T16:38:54.805658: step 9245, loss 0.312001, acc 0.90625\n",
      "2018-05-04T16:38:55.769725: step 9246, loss 0.226807, acc 0.953125\n",
      "2018-05-04T16:38:56.761042: step 9247, loss 0.356494, acc 0.875\n",
      "2018-05-04T16:38:57.788459: step 9248, loss 0.258654, acc 0.890625\n",
      "2018-05-04T16:38:58.828522: step 9249, loss 0.303607, acc 0.875\n",
      "2018-05-04T16:38:59.833527: step 9250, loss 0.348129, acc 0.890625\n",
      "2018-05-04T16:39:00.808058: step 9251, loss 0.158477, acc 0.953125\n",
      "2018-05-04T16:39:01.817099: step 9252, loss 0.34358, acc 0.859375\n",
      "2018-05-04T16:39:02.775757: step 9253, loss 0.332708, acc 0.84375\n",
      "2018-05-04T16:39:03.748576: step 9254, loss 0.287291, acc 0.90625\n",
      "2018-05-04T16:39:04.780135: step 9255, loss 0.260971, acc 0.890625\n",
      "2018-05-04T16:39:05.834699: step 9256, loss 0.309373, acc 0.84375\n",
      "2018-05-04T16:39:06.880957: step 9257, loss 0.387912, acc 0.859375\n",
      "2018-05-04T16:39:07.830227: step 9258, loss 0.322669, acc 0.890625\n",
      "2018-05-04T16:39:08.794557: step 9259, loss 0.209338, acc 0.9375\n",
      "2018-05-04T16:39:09.822482: step 9260, loss 0.284391, acc 0.875\n",
      "2018-05-04T16:39:10.844980: step 9261, loss 0.242191, acc 0.921875\n",
      "2018-05-04T16:39:11.883380: step 9262, loss 0.258902, acc 0.90625\n",
      "2018-05-04T16:39:12.821105: step 9263, loss 0.40365, acc 0.828125\n",
      "2018-05-04T16:39:13.753810: step 9264, loss 0.330041, acc 0.859375\n",
      "2018-05-04T16:39:14.829879: step 9265, loss 0.250237, acc 0.90625\n",
      "2018-05-04T16:39:15.812648: step 9266, loss 0.277575, acc 0.90625\n",
      "2018-05-04T16:39:16.755691: step 9267, loss 0.440553, acc 0.828125\n",
      "2018-05-04T16:39:17.805193: step 9268, loss 0.391733, acc 0.828125\n",
      "2018-05-04T16:39:18.801578: step 9269, loss 0.284251, acc 0.875\n",
      "2018-05-04T16:39:19.790972: step 9270, loss 0.304581, acc 0.90625\n",
      "2018-05-04T16:39:20.774205: step 9271, loss 0.333104, acc 0.859375\n",
      "2018-05-04T16:39:21.813587: step 9272, loss 0.214966, acc 0.90625\n",
      "2018-05-04T16:39:22.842669: step 9273, loss 0.281138, acc 0.859375\n",
      "2018-05-04T16:39:23.788586: step 9274, loss 0.174687, acc 0.9375\n",
      "2018-05-04T16:39:24.727260: step 9275, loss 0.234801, acc 0.890625\n",
      "2018-05-04T16:39:25.677884: step 9276, loss 0.261949, acc 0.890625\n",
      "2018-05-04T16:39:26.668576: step 9277, loss 0.239945, acc 0.9375\n",
      "2018-05-04T16:39:27.641990: step 9278, loss 0.26729, acc 0.859375\n",
      "2018-05-04T16:39:28.641581: step 9279, loss 0.247891, acc 0.90625\n",
      "2018-05-04T16:39:29.654425: step 9280, loss 0.305073, acc 0.890625\n",
      "2018-05-04T16:39:30.606656: step 9281, loss 0.200682, acc 0.9375\n",
      "2018-05-04T16:39:31.611552: step 9282, loss 0.360093, acc 0.875\n",
      "2018-05-04T16:39:32.626224: step 9283, loss 0.281834, acc 0.890625\n",
      "2018-05-04T16:39:33.659222: step 9284, loss 0.262256, acc 0.90625\n",
      "2018-05-04T16:39:34.692910: step 9285, loss 0.233012, acc 0.875\n",
      "2018-05-04T16:39:35.715107: step 9286, loss 0.22661, acc 0.921875\n",
      "2018-05-04T16:39:36.633651: step 9287, loss 0.265577, acc 0.875\n",
      "2018-05-04T16:39:37.612452: step 9288, loss 0.457167, acc 0.84375\n",
      "2018-05-04T16:39:38.545124: step 9289, loss 0.243831, acc 0.875\n",
      "2018-05-04T16:39:39.548723: step 9290, loss 0.357311, acc 0.875\n",
      "2018-05-04T16:39:40.534290: step 9291, loss 0.280613, acc 0.890625\n",
      "2018-05-04T16:39:41.545700: step 9292, loss 0.321464, acc 0.90625\n",
      "2018-05-04T16:39:42.563431: step 9293, loss 0.261311, acc 0.890625\n",
      "2018-05-04T16:39:43.553245: step 9294, loss 0.25184, acc 0.890625\n",
      "2018-05-04T16:39:44.555943: step 9295, loss 0.194466, acc 0.90625\n",
      "2018-05-04T16:39:45.561686: step 9296, loss 0.194703, acc 0.90625\n",
      "2018-05-04T16:39:46.569982: step 9297, loss 0.282552, acc 0.921875\n",
      "2018-05-04T16:39:47.577563: step 9298, loss 0.357828, acc 0.828125\n",
      "2018-05-04T16:39:48.576301: step 9299, loss 0.259744, acc 0.90625\n",
      "2018-05-04T16:39:49.571562: step 9300, loss 0.288264, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T16:39:51.957017: step 9300, loss 0.239888, acc 0.91\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-9300\n",
      "\n",
      "2018-05-04T16:39:53.034878: step 9301, loss 0.211841, acc 0.921875\n",
      "2018-05-04T16:39:54.055038: step 9302, loss 0.323168, acc 0.859375\n",
      "2018-05-04T16:39:55.049884: step 9303, loss 0.30766, acc 0.859375\n",
      "2018-05-04T16:39:56.130507: step 9304, loss 0.427288, acc 0.828125\n",
      "2018-05-04T16:39:57.185326: step 9305, loss 0.337287, acc 0.84375\n",
      "2018-05-04T16:39:58.191965: step 9306, loss 0.1924, acc 0.921875\n",
      "2018-05-04T16:39:59.253484: step 9307, loss 0.292154, acc 0.90625\n",
      "2018-05-04T16:40:00.248897: step 9308, loss 0.228202, acc 0.875\n",
      "2018-05-04T16:40:01.300037: step 9309, loss 0.276234, acc 0.875\n",
      "2018-05-04T16:40:02.293812: step 9310, loss 0.296999, acc 0.875\n",
      "2018-05-04T16:40:03.292844: step 9311, loss 0.261635, acc 0.890625\n",
      "2018-05-04T16:40:04.306337: step 9312, loss 0.265034, acc 0.890625\n",
      "2018-05-04T16:40:05.293743: step 9313, loss 0.278291, acc 0.875\n",
      "2018-05-04T16:40:06.277733: step 9314, loss 0.353982, acc 0.84375\n",
      "2018-05-04T16:40:07.366898: step 9315, loss 0.340611, acc 0.859375\n",
      "2018-05-04T16:40:08.334341: step 9316, loss 0.247468, acc 0.875\n",
      "2018-05-04T16:40:09.304883: step 9317, loss 0.349926, acc 0.875\n",
      "2018-05-04T16:40:10.287569: step 9318, loss 0.286983, acc 0.875\n",
      "2018-05-04T16:40:11.272393: step 9319, loss 0.212057, acc 0.921875\n",
      "2018-05-04T16:40:12.277768: step 9320, loss 0.261949, acc 0.875\n",
      "2018-05-04T16:40:13.258173: step 9321, loss 0.231794, acc 0.90625\n",
      "2018-05-04T16:40:14.232135: step 9322, loss 0.281191, acc 0.90625\n",
      "2018-05-04T16:40:15.207825: step 9323, loss 0.229434, acc 0.90625\n",
      "2018-05-04T16:40:16.166516: step 9324, loss 0.355897, acc 0.84375\n",
      "2018-05-04T16:40:17.152833: step 9325, loss 0.154754, acc 0.9375\n",
      "2018-05-04T16:40:18.142131: step 9326, loss 0.291746, acc 0.890625\n",
      "2018-05-04T16:40:19.126214: step 9327, loss 0.230896, acc 0.921875\n",
      "2018-05-04T16:40:20.144588: step 9328, loss 0.354795, acc 0.828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T16:40:21.156002: step 9329, loss 0.219618, acc 0.921875\n",
      "2018-05-04T16:40:22.163082: step 9330, loss 0.312861, acc 0.84375\n",
      "2018-05-04T16:40:23.166752: step 9331, loss 0.276194, acc 0.890625\n",
      "2018-05-04T16:40:24.184755: step 9332, loss 0.281305, acc 0.875\n",
      "2018-05-04T16:40:25.132503: step 9333, loss 0.261855, acc 0.921875\n",
      "2018-05-04T16:40:26.140448: step 9334, loss 0.304663, acc 0.84375\n",
      "2018-05-04T16:40:27.137513: step 9335, loss 0.331533, acc 0.84375\n",
      "2018-05-04T16:40:28.119061: step 9336, loss 0.62889, acc 0.796875\n",
      "2018-05-04T16:40:29.122648: step 9337, loss 0.190873, acc 0.953125\n",
      "2018-05-04T16:40:30.138882: step 9338, loss 0.252538, acc 0.90625\n",
      "2018-05-04T16:40:31.145507: step 9339, loss 0.291427, acc 0.875\n",
      "2018-05-04T16:40:32.168385: step 9340, loss 0.258511, acc 0.890625\n",
      "2018-05-04T16:40:33.223146: step 9341, loss 0.164435, acc 0.921875\n",
      "2018-05-04T16:40:34.298549: step 9342, loss 0.155611, acc 0.9375\n",
      "2018-05-04T16:40:35.383820: step 9343, loss 0.272103, acc 0.890625\n",
      "2018-05-04T16:40:36.443204: step 9344, loss 0.237238, acc 0.9375\n",
      "2018-05-04T16:40:37.491078: step 9345, loss 0.218098, acc 0.890625\n",
      "2018-05-04T16:40:38.532656: step 9346, loss 0.317351, acc 0.84375\n",
      "2018-05-04T16:40:39.552392: step 9347, loss 0.308329, acc 0.890625\n",
      "2018-05-04T16:40:40.589096: step 9348, loss 0.166676, acc 0.953125\n",
      "2018-05-04T16:40:41.573426: step 9349, loss 0.248745, acc 0.890625\n",
      "2018-05-04T16:40:42.541355: step 9350, loss 0.222319, acc 0.921875\n",
      "2018-05-04T16:40:43.530528: step 9351, loss 0.251761, acc 0.875\n",
      "2018-05-04T16:40:44.515990: step 9352, loss 0.309064, acc 0.890625\n",
      "2018-05-04T16:40:45.504484: step 9353, loss 0.273083, acc 0.875\n",
      "2018-05-04T16:40:46.539909: step 9354, loss 0.268519, acc 0.859375\n",
      "2018-05-04T16:40:47.566633: step 9355, loss 0.210488, acc 0.90625\n",
      "2018-05-04T16:40:48.594593: step 9356, loss 0.22813, acc 0.921875\n",
      "2018-05-04T16:40:49.672544: step 9357, loss 0.309875, acc 0.90625\n",
      "2018-05-04T16:40:50.664379: step 9358, loss 0.298848, acc 0.859375\n",
      "2018-05-04T16:40:51.746360: step 9359, loss 0.246104, acc 0.875\n",
      "2018-05-04T16:40:52.737618: step 9360, loss 0.395279, acc 0.828125\n",
      "2018-05-04T16:40:53.733010: step 9361, loss 0.316032, acc 0.828125\n",
      "2018-05-04T16:40:54.726632: step 9362, loss 0.336042, acc 0.890625\n",
      "2018-05-04T16:40:55.721181: step 9363, loss 0.297258, acc 0.859375\n",
      "2018-05-04T16:40:56.718370: step 9364, loss 0.238565, acc 0.921875\n",
      "2018-05-04T16:40:57.714048: step 9365, loss 0.489307, acc 0.8125\n",
      "2018-05-04T16:40:58.667274: step 9366, loss 0.197193, acc 0.953125\n",
      "2018-05-04T16:40:59.638324: step 9367, loss 0.31146, acc 0.84375\n",
      "2018-05-04T16:41:00.656973: step 9368, loss 0.225341, acc 0.90625\n",
      "2018-05-04T16:41:01.742180: step 9369, loss 0.210627, acc 0.921875\n",
      "2018-05-04T16:41:02.737916: step 9370, loss 0.189768, acc 0.921875\n",
      "2018-05-04T16:41:03.737330: step 9371, loss 0.219645, acc 0.90625\n",
      "2018-05-04T16:41:04.728594: step 9372, loss 0.286232, acc 0.875\n",
      "2018-05-04T16:41:05.725492: step 9373, loss 0.416526, acc 0.84375\n",
      "2018-05-04T16:41:06.727348: step 9374, loss 0.235414, acc 0.921875\n",
      "2018-05-04T16:41:07.720760: step 9375, loss 0.241885, acc 0.890625\n",
      "2018-05-04T16:41:08.723459: step 9376, loss 0.206782, acc 0.9375\n",
      "2018-05-04T16:41:09.740405: step 9377, loss 0.217345, acc 0.9375\n",
      "2018-05-04T16:41:10.709118: step 9378, loss 0.292399, acc 0.84375\n",
      "2018-05-04T16:41:11.682567: step 9379, loss 0.301855, acc 0.84375\n",
      "2018-05-04T16:41:12.655372: step 9380, loss 0.259641, acc 0.90625\n",
      "2018-05-04T16:41:13.638734: step 9381, loss 0.385178, acc 0.796875\n",
      "2018-05-04T16:41:14.637259: step 9382, loss 0.240906, acc 0.921875\n",
      "2018-05-04T16:41:15.633310: step 9383, loss 0.192217, acc 0.921875\n",
      "2018-05-04T16:41:16.625391: step 9384, loss 0.181851, acc 0.921875\n",
      "2018-05-04T16:41:17.666018: step 9385, loss 0.181082, acc 0.96875\n",
      "2018-05-04T16:41:18.676777: step 9386, loss 0.21441, acc 0.90625\n",
      "2018-05-04T16:41:19.678046: step 9387, loss 0.224791, acc 0.859375\n",
      "2018-05-04T16:41:20.682122: step 9388, loss 0.362183, acc 0.875\n",
      "2018-05-04T16:41:21.707880: step 9389, loss 0.327755, acc 0.84375\n",
      "2018-05-04T16:41:22.749730: step 9390, loss 0.360175, acc 0.90625\n",
      "2018-05-04T16:41:23.746699: step 9391, loss 0.229187, acc 0.9375\n",
      "2018-05-04T16:41:24.820033: step 9392, loss 0.106261, acc 0.984375\n",
      "2018-05-04T16:41:25.816392: step 9393, loss 0.236678, acc 0.921875\n",
      "2018-05-04T16:41:26.879485: step 9394, loss 0.282864, acc 0.828125\n",
      "2018-05-04T16:41:27.864182: step 9395, loss 0.25928, acc 0.890625\n",
      "2018-05-04T16:41:28.869475: step 9396, loss 0.184276, acc 0.921875\n",
      "2018-05-04T16:41:29.851991: step 9397, loss 0.43535, acc 0.875\n",
      "2018-05-04T16:41:30.852926: step 9398, loss 0.291555, acc 0.859375\n",
      "2018-05-04T16:41:31.849623: step 9399, loss 0.49571, acc 0.859375\n",
      "2018-05-04T16:41:32.864105: step 9400, loss 0.248827, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T16:41:35.530982: step 9400, loss 0.240353, acc 0.904\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-9400\n",
      "\n",
      "2018-05-04T16:41:36.688470: step 9401, loss 0.335193, acc 0.875\n",
      "2018-05-04T16:41:37.697473: step 9402, loss 0.402044, acc 0.859375\n",
      "2018-05-04T16:41:38.718659: step 9403, loss 0.244468, acc 0.90625\n",
      "2018-05-04T16:41:39.790873: step 9404, loss 0.232586, acc 0.90625\n",
      "2018-05-04T16:41:40.922078: step 9405, loss 0.164977, acc 0.9375\n",
      "2018-05-04T16:41:41.934337: step 9406, loss 0.288206, acc 0.875\n",
      "2018-05-04T16:41:43.018014: step 9407, loss 0.202895, acc 0.921875\n",
      "2018-05-04T16:41:44.055261: step 9408, loss 0.278377, acc 0.90625\n",
      "2018-05-04T16:41:45.085139: step 9409, loss 0.219105, acc 0.921875\n",
      "2018-05-04T16:41:46.108319: step 9410, loss 0.297746, acc 0.90625\n",
      "2018-05-04T16:41:47.117586: step 9411, loss 0.254239, acc 0.875\n",
      "2018-05-04T16:41:48.121634: step 9412, loss 0.319069, acc 0.859375\n",
      "2018-05-04T16:41:49.104693: step 9413, loss 0.246941, acc 0.890625\n",
      "2018-05-04T16:41:50.132840: step 9414, loss 0.27199, acc 0.890625\n",
      "2018-05-04T16:41:51.236863: step 9415, loss 0.417431, acc 0.84375\n",
      "2018-05-04T16:41:52.257952: step 9416, loss 0.308904, acc 0.921875\n",
      "2018-05-04T16:41:53.257502: step 9417, loss 0.247482, acc 0.921875\n",
      "2018-05-04T16:41:54.360340: step 9418, loss 0.335479, acc 0.90625\n",
      "2018-05-04T16:41:55.441939: step 9419, loss 0.300782, acc 0.90625\n",
      "2018-05-04T16:41:56.521827: step 9420, loss 0.349605, acc 0.90625\n",
      "2018-05-04T16:41:57.521332: step 9421, loss 0.280742, acc 0.859375\n",
      "2018-05-04T16:41:58.503665: step 9422, loss 0.273253, acc 0.875\n",
      "2018-05-04T16:41:59.496385: step 9423, loss 0.339538, acc 0.890625\n",
      "2018-05-04T16:42:00.499578: step 9424, loss 0.252567, acc 0.890625\n",
      "2018-05-04T16:42:01.601927: step 9425, loss 0.201549, acc 0.921875\n",
      "2018-05-04T16:42:02.630326: step 9426, loss 0.258152, acc 0.890625\n",
      "2018-05-04T16:42:03.723268: step 9427, loss 0.264493, acc 0.859375\n",
      "2018-05-04T16:42:04.752298: step 9428, loss 0.218812, acc 0.90625\n",
      "2018-05-04T16:42:05.843927: step 9429, loss 0.21943, acc 0.890625\n",
      "2018-05-04T16:42:06.840580: step 9430, loss 0.261466, acc 0.859375\n",
      "2018-05-04T16:42:07.856556: step 9431, loss 0.227439, acc 0.921875\n",
      "2018-05-04T16:42:08.852172: step 9432, loss 0.261218, acc 0.859375\n",
      "2018-05-04T16:42:09.840989: step 9433, loss 0.234907, acc 0.875\n",
      "2018-05-04T16:42:10.866843: step 9434, loss 0.272065, acc 0.859375\n",
      "2018-05-04T16:42:11.893978: step 9435, loss 0.20828, acc 0.90625\n",
      "2018-05-04T16:42:12.901201: step 9436, loss 0.369712, acc 0.84375\n",
      "2018-05-04T16:42:13.892621: step 9437, loss 0.259363, acc 0.9375\n",
      "2018-05-04T16:42:14.893369: step 9438, loss 0.386829, acc 0.859375\n",
      "2018-05-04T16:42:15.979468: step 9439, loss 0.304164, acc 0.921875\n",
      "2018-05-04T16:42:16.992585: step 9440, loss 0.32954, acc 0.84375\n",
      "2018-05-04T16:42:18.008824: step 9441, loss 0.335822, acc 0.84375\n",
      "2018-05-04T16:42:19.030984: step 9442, loss 0.216877, acc 0.890625\n",
      "2018-05-04T16:42:20.026454: step 9443, loss 0.387163, acc 0.890625\n",
      "2018-05-04T16:42:21.050537: step 9444, loss 0.357766, acc 0.828125\n",
      "2018-05-04T16:42:22.079610: step 9445, loss 0.298579, acc 0.84375\n",
      "2018-05-04T16:42:23.112426: step 9446, loss 0.210077, acc 0.9375\n",
      "2018-05-04T16:42:24.120922: step 9447, loss 0.301375, acc 0.890625\n",
      "2018-05-04T16:42:25.194777: step 9448, loss 0.199375, acc 0.890625\n",
      "2018-05-04T16:42:26.170664: step 9449, loss 0.230119, acc 0.921875\n",
      "2018-05-04T16:42:27.155061: step 9450, loss 0.375465, acc 0.84375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T16:42:28.160559: step 9451, loss 0.27398, acc 0.890625\n",
      "2018-05-04T16:42:29.186925: step 9452, loss 0.319542, acc 0.890625\n",
      "2018-05-04T16:42:30.173973: step 9453, loss 0.281655, acc 0.890625\n",
      "2018-05-04T16:42:31.182069: step 9454, loss 0.234304, acc 0.875\n",
      "2018-05-04T16:42:32.269161: step 9455, loss 0.26514, acc 0.890625\n",
      "2018-05-04T16:42:33.277742: step 9456, loss 0.386564, acc 0.8125\n",
      "2018-05-04T16:42:34.360649: step 9457, loss 0.251265, acc 0.90625\n",
      "2018-05-04T16:42:35.365031: step 9458, loss 0.172771, acc 0.9375\n",
      "2018-05-04T16:42:36.405789: step 9459, loss 0.273015, acc 0.890625\n",
      "2018-05-04T16:42:37.437015: step 9460, loss 0.349101, acc 0.875\n",
      "2018-05-04T16:42:38.461692: step 9461, loss 0.365945, acc 0.828125\n",
      "2018-05-04T16:42:39.467592: step 9462, loss 0.214176, acc 0.90625\n",
      "2018-05-04T16:42:40.467817: step 9463, loss 0.457575, acc 0.8125\n",
      "2018-05-04T16:42:41.480652: step 9464, loss 0.338158, acc 0.859375\n",
      "2018-05-04T16:42:42.484991: step 9465, loss 0.172605, acc 0.9375\n",
      "2018-05-04T16:42:43.487839: step 9466, loss 0.405366, acc 0.8125\n",
      "2018-05-04T16:42:44.484500: step 9467, loss 0.244208, acc 0.84375\n",
      "2018-05-04T16:42:45.498205: step 9468, loss 0.319642, acc 0.859375\n",
      "2018-05-04T16:42:46.515151: step 9469, loss 0.210117, acc 0.9375\n",
      "2018-05-04T16:42:47.513476: step 9470, loss 0.47172, acc 0.734375\n",
      "2018-05-04T16:42:48.566868: step 9471, loss 0.296513, acc 0.84375\n",
      "2018-05-04T16:42:49.596121: step 9472, loss 0.257441, acc 0.890625\n",
      "2018-05-04T16:42:50.679393: step 9473, loss 0.242006, acc 0.953125\n",
      "2018-05-04T16:42:51.734393: step 9474, loss 0.281403, acc 0.890625\n",
      "2018-05-04T16:42:52.719622: step 9475, loss 0.436978, acc 0.8125\n",
      "2018-05-04T16:42:53.732555: step 9476, loss 0.423021, acc 0.8125\n",
      "2018-05-04T16:42:54.739194: step 9477, loss 0.22875, acc 0.953125\n",
      "2018-05-04T16:42:55.726870: step 9478, loss 0.286002, acc 0.875\n",
      "2018-05-04T16:42:56.732466: step 9479, loss 0.19171, acc 0.953125\n",
      "2018-05-04T16:42:57.746433: step 9480, loss 0.232768, acc 0.9375\n",
      "2018-05-04T16:42:58.747789: step 9481, loss 0.307441, acc 0.875\n",
      "2018-05-04T16:42:59.761285: step 9482, loss 0.232605, acc 0.890625\n",
      "2018-05-04T16:43:00.783010: step 9483, loss 0.159154, acc 0.921875\n",
      "2018-05-04T16:43:01.823543: step 9484, loss 0.298523, acc 0.875\n",
      "2018-05-04T16:43:02.821960: step 9485, loss 0.190378, acc 0.921875\n",
      "2018-05-04T16:43:03.846824: step 9486, loss 0.294624, acc 0.84375\n",
      "2018-05-04T16:43:04.882261: step 9487, loss 0.34226, acc 0.859375\n",
      "2018-05-04T16:43:06.009768: step 9488, loss 0.285677, acc 0.9375\n",
      "2018-05-04T16:43:07.000560: step 9489, loss 0.353969, acc 0.859375\n",
      "2018-05-04T16:43:07.996814: step 9490, loss 0.224682, acc 0.90625\n",
      "2018-05-04T16:43:09.011251: step 9491, loss 0.362801, acc 0.859375\n",
      "2018-05-04T16:43:10.003637: step 9492, loss 0.223181, acc 0.9375\n",
      "2018-05-04T16:43:11.022702: step 9493, loss 0.338366, acc 0.90625\n",
      "2018-05-04T16:43:12.039366: step 9494, loss 0.343177, acc 0.875\n",
      "2018-05-04T16:43:13.064293: step 9495, loss 0.170828, acc 0.953125\n",
      "2018-05-04T16:43:14.077272: step 9496, loss 0.319202, acc 0.875\n",
      "2018-05-04T16:43:15.092229: step 9497, loss 0.387849, acc 0.859375\n",
      "2018-05-04T16:43:16.104333: step 9498, loss 0.18502, acc 0.90625\n",
      "2018-05-04T16:43:17.171314: step 9499, loss 0.251785, acc 0.859375\n",
      "2018-05-04T16:43:18.198316: step 9500, loss 0.22499, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T16:43:20.389760: step 9500, loss 0.237658, acc 0.922\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-9500\n",
      "\n",
      "2018-05-04T16:43:21.489098: step 9501, loss 0.295065, acc 0.90625\n",
      "2018-05-04T16:43:22.474450: step 9502, loss 0.245692, acc 0.9375\n",
      "2018-05-04T16:43:23.471723: step 9503, loss 0.316098, acc 0.890625\n",
      "2018-05-04T16:43:24.479719: step 9504, loss 0.348741, acc 0.796875\n",
      "2018-05-04T16:43:25.477662: step 9505, loss 0.327406, acc 0.875\n",
      "2018-05-04T16:43:26.466436: step 9506, loss 0.328969, acc 0.859375\n",
      "2018-05-04T16:43:27.472769: step 9507, loss 0.334752, acc 0.875\n",
      "2018-05-04T16:43:28.475800: step 9508, loss 0.355285, acc 0.859375\n",
      "2018-05-04T16:43:29.479322: step 9509, loss 0.311949, acc 0.875\n",
      "2018-05-04T16:43:30.473360: step 9510, loss 0.377666, acc 0.875\n",
      "2018-05-04T16:43:31.459551: step 9511, loss 0.245607, acc 0.921875\n",
      "2018-05-04T16:43:32.484940: step 9512, loss 0.264512, acc 0.890625\n",
      "2018-05-04T16:43:33.580696: step 9513, loss 0.260504, acc 0.890625\n",
      "2018-05-04T16:43:34.666771: step 9514, loss 0.256448, acc 0.90625\n",
      "2018-05-04T16:43:35.750411: step 9515, loss 0.226883, acc 0.890625\n",
      "2018-05-04T16:43:36.844560: step 9516, loss 0.382503, acc 0.859375\n",
      "2018-05-04T16:43:37.886614: step 9517, loss 0.387608, acc 0.84375\n",
      "2018-05-04T16:43:38.968430: step 9518, loss 0.319255, acc 0.828125\n",
      "2018-05-04T16:43:39.984574: step 9519, loss 0.273095, acc 0.859375\n",
      "2018-05-04T16:43:40.976506: step 9520, loss 0.2068, acc 0.9375\n",
      "2018-05-04T16:43:41.941443: step 9521, loss 0.274278, acc 0.90625\n",
      "2018-05-04T16:43:42.929665: step 9522, loss 0.278821, acc 0.890625\n",
      "2018-05-04T16:43:43.920287: step 9523, loss 0.226402, acc 0.84375\n",
      "2018-05-04T16:43:44.905942: step 9524, loss 0.306687, acc 0.90625\n",
      "2018-05-04T16:43:45.916923: step 9525, loss 0.474448, acc 0.828125\n",
      "2018-05-04T16:43:46.966884: step 9526, loss 0.2551, acc 0.875\n",
      "2018-05-04T16:43:47.983433: step 9527, loss 0.301957, acc 0.859375\n",
      "2018-05-04T16:43:49.042806: step 9528, loss 0.25699, acc 0.921875\n",
      "2018-05-04T16:43:50.038948: step 9529, loss 0.273616, acc 0.859375\n",
      "2018-05-04T16:43:51.015422: step 9530, loss 0.273852, acc 0.890625\n",
      "2018-05-04T16:43:52.033407: step 9531, loss 0.252961, acc 0.90625\n",
      "2018-05-04T16:43:53.036705: step 9532, loss 0.208716, acc 0.921875\n",
      "2018-05-04T16:43:54.031689: step 9533, loss 0.419973, acc 0.828125\n",
      "2018-05-04T16:43:55.020567: step 9534, loss 0.302668, acc 0.890625\n",
      "2018-05-04T16:43:56.008904: step 9535, loss 0.379766, acc 0.890625\n",
      "2018-05-04T16:43:57.001575: step 9536, loss 0.324146, acc 0.90625\n",
      "2018-05-04T16:43:57.974768: step 9537, loss 0.420458, acc 0.890625\n",
      "2018-05-04T16:43:59.029657: step 9538, loss 0.307844, acc 0.890625\n",
      "2018-05-04T16:44:00.017863: step 9539, loss 0.282706, acc 0.890625\n",
      "2018-05-04T16:44:01.047501: step 9540, loss 0.235495, acc 0.9375\n",
      "2018-05-04T16:44:02.074818: step 9541, loss 0.285003, acc 0.859375\n",
      "2018-05-04T16:44:03.104271: step 9542, loss 0.239212, acc 0.90625\n",
      "2018-05-04T16:44:04.189429: step 9543, loss 0.350525, acc 0.875\n",
      "2018-05-04T16:44:05.253948: step 9544, loss 0.208994, acc 0.9375\n",
      "2018-05-04T16:44:06.247317: step 9545, loss 0.264248, acc 0.875\n",
      "2018-05-04T16:44:07.263228: step 9546, loss 0.299676, acc 0.921875\n",
      "2018-05-04T16:44:08.249847: step 9547, loss 0.284956, acc 0.890625\n",
      "2018-05-04T16:44:09.222897: step 9548, loss 0.347355, acc 0.859375\n",
      "2018-05-04T16:44:10.201204: step 9549, loss 0.439482, acc 0.859375\n",
      "2018-05-04T16:44:11.200757: step 9550, loss 0.269053, acc 0.875\n",
      "2018-05-04T16:44:12.175095: step 9551, loss 0.289661, acc 0.890625\n",
      "2018-05-04T16:44:13.172066: step 9552, loss 0.215747, acc 0.90625\n",
      "2018-05-04T16:44:14.169305: step 9553, loss 0.352694, acc 0.8125\n",
      "2018-05-04T16:44:15.146828: step 9554, loss 0.317256, acc 0.90625\n",
      "2018-05-04T16:44:16.138855: step 9555, loss 0.329859, acc 0.859375\n",
      "2018-05-04T16:44:17.162408: step 9556, loss 0.247216, acc 0.890625\n",
      "2018-05-04T16:44:18.173864: step 9557, loss 0.201986, acc 0.921875\n",
      "2018-05-04T16:44:19.305172: step 9558, loss 0.261357, acc 0.921875\n",
      "2018-05-04T16:44:20.377526: step 9559, loss 0.194373, acc 0.890625\n",
      "2018-05-04T16:44:21.422374: step 9560, loss 0.221087, acc 0.90625\n",
      "2018-05-04T16:44:22.404200: step 9561, loss 0.379269, acc 0.8125\n",
      "2018-05-04T16:44:23.396635: step 9562, loss 0.396662, acc 0.8125\n",
      "2018-05-04T16:44:24.387980: step 9563, loss 0.341164, acc 0.90625\n",
      "2018-05-04T16:44:25.443338: step 9564, loss 0.183358, acc 0.921875\n",
      "2018-05-04T16:44:26.445015: step 9565, loss 0.336138, acc 0.875\n",
      "2018-05-04T16:44:27.438954: step 9566, loss 0.229459, acc 0.90625\n",
      "2018-05-04T16:44:28.423688: step 9567, loss 0.197685, acc 0.96875\n",
      "2018-05-04T16:44:29.507820: step 9568, loss 0.18198, acc 0.921875\n",
      "2018-05-04T16:44:30.498968: step 9569, loss 0.381738, acc 0.859375\n",
      "2018-05-04T16:44:31.546964: step 9570, loss 0.427176, acc 0.796875\n",
      "2018-05-04T16:44:32.535650: step 9571, loss 0.338429, acc 0.828125\n",
      "2018-05-04T16:44:33.601101: step 9572, loss 0.278724, acc 0.859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T16:44:34.671244: step 9573, loss 0.342541, acc 0.828125\n",
      "2018-05-04T16:44:35.731508: step 9574, loss 0.236241, acc 0.890625\n",
      "2018-05-04T16:44:36.794399: step 9575, loss 0.189499, acc 0.9375\n",
      "2018-05-04T16:44:37.802128: step 9576, loss 0.354009, acc 0.859375\n",
      "2018-05-04T16:44:38.889367: step 9577, loss 0.183443, acc 0.96875\n",
      "2018-05-04T16:44:39.939607: step 9578, loss 0.359138, acc 0.828125\n",
      "2018-05-04T16:44:40.906232: step 9579, loss 0.381245, acc 0.8125\n",
      "2018-05-04T16:44:41.906793: step 9580, loss 0.30596, acc 0.875\n",
      "2018-05-04T16:44:42.904851: step 9581, loss 0.263168, acc 0.875\n",
      "2018-05-04T16:44:43.887333: step 9582, loss 0.367085, acc 0.84375\n",
      "2018-05-04T16:44:44.869835: step 9583, loss 0.413468, acc 0.84375\n",
      "2018-05-04T16:44:45.932175: step 9584, loss 0.21474, acc 0.875\n",
      "2018-05-04T16:44:46.958243: step 9585, loss 0.21234, acc 0.953125\n",
      "2018-05-04T16:44:48.015947: step 9586, loss 0.237513, acc 0.90625\n",
      "2018-05-04T16:44:49.080179: step 9587, loss 0.324208, acc 0.828125\n",
      "2018-05-04T16:44:50.124910: step 9588, loss 0.213971, acc 0.921875\n",
      "2018-05-04T16:44:51.187092: step 9589, loss 0.231147, acc 0.875\n",
      "2018-05-04T16:44:52.187112: step 9590, loss 0.306644, acc 0.859375\n",
      "2018-05-04T16:44:53.246249: step 9591, loss 0.358592, acc 0.875\n",
      "2018-05-04T16:44:54.286072: step 9592, loss 0.25798, acc 0.90625\n",
      "2018-05-04T16:44:55.317113: step 9593, loss 0.267688, acc 0.921875\n",
      "2018-05-04T16:44:56.308295: step 9594, loss 0.363461, acc 0.828125\n",
      "2018-05-04T16:44:57.343764: step 9595, loss 0.469462, acc 0.84375\n",
      "2018-05-04T16:44:58.387300: step 9596, loss 0.248235, acc 0.90625\n",
      "2018-05-04T16:44:59.403482: step 9597, loss 0.459162, acc 0.828125\n",
      "2018-05-04T16:45:00.435154: step 9598, loss 0.554284, acc 0.765625\n",
      "2018-05-04T16:45:01.409687: step 9599, loss 0.252131, acc 0.921875\n",
      "2018-05-04T16:45:02.426324: step 9600, loss 0.230233, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T16:45:05.137687: step 9600, loss 0.23703, acc 0.926\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-9600\n",
      "\n",
      "2018-05-04T16:45:06.274008: step 9601, loss 0.231502, acc 0.953125\n",
      "2018-05-04T16:45:07.333699: step 9602, loss 0.280416, acc 0.921875\n",
      "2018-05-04T16:45:08.382053: step 9603, loss 0.312097, acc 0.859375\n",
      "2018-05-04T16:45:09.481110: step 9604, loss 0.441774, acc 0.859375\n",
      "2018-05-04T16:45:10.549874: step 9605, loss 0.273921, acc 0.90625\n",
      "2018-05-04T16:45:11.595482: step 9606, loss 0.286402, acc 0.859375\n",
      "2018-05-04T16:45:12.653769: step 9607, loss 0.301016, acc 0.890625\n",
      "2018-05-04T16:45:13.768074: step 9608, loss 0.167828, acc 0.953125\n",
      "2018-05-04T16:45:14.773085: step 9609, loss 0.223162, acc 0.90625\n",
      "2018-05-04T16:45:15.817153: step 9610, loss 0.340611, acc 0.875\n",
      "2018-05-04T16:45:16.864828: step 9611, loss 0.227082, acc 0.890625\n",
      "2018-05-04T16:45:17.903370: step 9612, loss 0.329432, acc 0.890625\n",
      "2018-05-04T16:45:19.039512: step 9613, loss 0.262993, acc 0.90625\n",
      "2018-05-04T16:45:20.060550: step 9614, loss 0.391865, acc 0.828125\n",
      "2018-05-04T16:45:21.173478: step 9615, loss 0.223688, acc 0.890625\n",
      "2018-05-04T16:45:22.188980: step 9616, loss 0.146996, acc 0.953125\n",
      "2018-05-04T16:45:23.253136: step 9617, loss 0.267067, acc 0.875\n",
      "2018-05-04T16:45:24.271246: step 9618, loss 0.347995, acc 0.875\n",
      "2018-05-04T16:45:25.290839: step 9619, loss 0.23772, acc 0.90625\n",
      "2018-05-04T16:45:26.316889: step 9620, loss 0.517409, acc 0.796875\n",
      "2018-05-04T16:45:27.340348: step 9621, loss 0.243227, acc 0.875\n",
      "2018-05-04T16:45:28.345757: step 9622, loss 0.188641, acc 0.984375\n",
      "2018-05-04T16:45:29.364230: step 9623, loss 0.45938, acc 0.84375\n",
      "2018-05-04T16:45:30.380943: step 9624, loss 0.362511, acc 0.84375\n",
      "2018-05-04T16:45:31.466871: step 9625, loss 0.272196, acc 0.921875\n",
      "2018-05-04T16:45:32.487050: step 9626, loss 0.412795, acc 0.84375\n",
      "2018-05-04T16:45:33.499621: step 9627, loss 0.239231, acc 0.90625\n",
      "2018-05-04T16:45:34.508556: step 9628, loss 0.205702, acc 0.90625\n",
      "2018-05-04T16:45:35.540983: step 9629, loss 0.452948, acc 0.8125\n",
      "2018-05-04T16:45:36.556417: step 9630, loss 0.265954, acc 0.90625\n",
      "2018-05-04T16:45:37.600325: step 9631, loss 0.297257, acc 0.890625\n",
      "2018-05-04T16:45:38.671586: step 9632, loss 0.358283, acc 0.828125\n",
      "2018-05-04T16:45:39.679644: step 9633, loss 0.221545, acc 0.953125\n",
      "2018-05-04T16:45:40.724586: step 9634, loss 0.250305, acc 0.90625\n",
      "2018-05-04T16:45:41.762780: step 9635, loss 0.23175, acc 0.875\n",
      "2018-05-04T16:45:42.846073: step 9636, loss 0.369179, acc 0.890625\n",
      "2018-05-04T16:45:43.861073: step 9637, loss 0.315659, acc 0.828125\n",
      "2018-05-04T16:45:44.862779: step 9638, loss 0.309001, acc 0.875\n",
      "2018-05-04T16:45:45.886992: step 9639, loss 0.234267, acc 0.90625\n",
      "2018-05-04T16:45:46.977623: step 9640, loss 0.20551, acc 0.9375\n",
      "2018-05-04T16:45:47.971262: step 9641, loss 0.423804, acc 0.84375\n",
      "2018-05-04T16:45:49.078489: step 9642, loss 0.338892, acc 0.84375\n",
      "2018-05-04T16:45:50.199328: step 9643, loss 0.227008, acc 0.875\n",
      "2018-05-04T16:45:51.216895: step 9644, loss 0.204093, acc 0.953125\n",
      "2018-05-04T16:45:52.228454: step 9645, loss 0.339486, acc 0.859375\n",
      "2018-05-04T16:45:53.244481: step 9646, loss 0.307051, acc 0.875\n",
      "2018-05-04T16:45:54.270850: step 9647, loss 0.292618, acc 0.859375\n",
      "2018-05-04T16:45:55.275923: step 9648, loss 0.222488, acc 0.875\n",
      "2018-05-04T16:45:56.282298: step 9649, loss 0.181303, acc 0.9375\n",
      "2018-05-04T16:45:57.306573: step 9650, loss 0.231, acc 0.9375\n",
      "2018-05-04T16:45:58.323073: step 9651, loss 0.280427, acc 0.890625\n",
      "2018-05-04T16:45:59.360955: step 9652, loss 0.313185, acc 0.890625\n",
      "2018-05-04T16:46:00.393958: step 9653, loss 0.300835, acc 0.859375\n",
      "2018-05-04T16:46:01.442014: step 9654, loss 0.323519, acc 0.84375\n",
      "2018-05-04T16:46:02.474867: step 9655, loss 0.379545, acc 0.828125\n",
      "2018-05-04T16:46:03.493348: step 9656, loss 0.173786, acc 0.9375\n",
      "2018-05-04T16:46:04.503846: step 9657, loss 0.249871, acc 0.953125\n",
      "2018-05-04T16:46:05.501124: step 9658, loss 0.353539, acc 0.828125\n",
      "2018-05-04T16:46:06.513141: step 9659, loss 0.340375, acc 0.859375\n",
      "2018-05-04T16:46:07.533710: step 9660, loss 0.153362, acc 0.953125\n",
      "2018-05-04T16:46:08.536353: step 9661, loss 0.343571, acc 0.859375\n",
      "2018-05-04T16:46:09.571723: step 9662, loss 0.257222, acc 0.9375\n",
      "2018-05-04T16:46:10.701193: step 9663, loss 0.216501, acc 0.90625\n",
      "2018-05-04T16:46:11.776190: step 9664, loss 0.198454, acc 0.921875\n",
      "2018-05-04T16:46:12.854284: step 9665, loss 0.355573, acc 0.859375\n",
      "2018-05-04T16:46:13.879596: step 9666, loss 0.334044, acc 0.84375\n",
      "2018-05-04T16:46:14.885672: step 9667, loss 0.24404, acc 0.921875\n",
      "2018-05-04T16:46:15.886266: step 9668, loss 0.270333, acc 0.859375\n",
      "2018-05-04T16:46:16.903435: step 9669, loss 0.190478, acc 0.921875\n",
      "2018-05-04T16:46:17.895163: step 9670, loss 0.300664, acc 0.875\n",
      "2018-05-04T16:46:18.898792: step 9671, loss 0.222665, acc 0.890625\n",
      "2018-05-04T16:46:19.968513: step 9672, loss 0.206448, acc 0.921875\n",
      "2018-05-04T16:46:21.038182: step 9673, loss 0.401007, acc 0.828125\n",
      "2018-05-04T16:46:22.030176: step 9674, loss 0.348096, acc 0.875\n",
      "2018-05-04T16:46:23.034000: step 9675, loss 0.286255, acc 0.859375\n",
      "2018-05-04T16:46:24.047769: step 9676, loss 0.291169, acc 0.890625\n",
      "2018-05-04T16:46:25.043246: step 9677, loss 0.281361, acc 0.890625\n",
      "2018-05-04T16:46:26.043911: step 9678, loss 0.273984, acc 0.90625\n",
      "2018-05-04T16:46:27.063414: step 9679, loss 0.309625, acc 0.890625\n",
      "2018-05-04T16:46:28.110902: step 9680, loss 0.177955, acc 0.921875\n",
      "2018-05-04T16:46:29.153997: step 9681, loss 0.219779, acc 0.90625\n",
      "2018-05-04T16:46:30.212441: step 9682, loss 0.373711, acc 0.859375\n",
      "2018-05-04T16:46:31.207411: step 9683, loss 0.195434, acc 0.90625\n",
      "2018-05-04T16:46:32.255247: step 9684, loss 0.260569, acc 0.890625\n",
      "2018-05-04T16:46:33.348858: step 9685, loss 0.224294, acc 0.953125\n",
      "2018-05-04T16:46:34.439871: step 9686, loss 0.249015, acc 0.890625\n",
      "2018-05-04T16:46:35.531091: step 9687, loss 0.268993, acc 0.875\n",
      "2018-05-04T16:46:36.595306: step 9688, loss 0.304841, acc 0.90625\n",
      "2018-05-04T16:46:37.661345: step 9689, loss 0.273477, acc 0.859375\n",
      "2018-05-04T16:46:38.782863: step 9690, loss 0.366848, acc 0.875\n",
      "2018-05-04T16:46:39.813623: step 9691, loss 0.152595, acc 0.9375\n",
      "2018-05-04T16:46:40.896698: step 9692, loss 0.423284, acc 0.828125\n",
      "2018-05-04T16:46:41.880417: step 9693, loss 0.195091, acc 0.953125\n",
      "2018-05-04T16:46:42.956994: step 9694, loss 0.233001, acc 0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T16:46:43.971764: step 9695, loss 0.125016, acc 0.953125\n",
      "2018-05-04T16:46:45.035618: step 9696, loss 0.316362, acc 0.890625\n",
      "2018-05-04T16:46:46.061833: step 9697, loss 0.454667, acc 0.828125\n",
      "2018-05-04T16:46:47.088902: step 9698, loss 0.176534, acc 0.890625\n",
      "2018-05-04T16:46:48.152384: step 9699, loss 0.270384, acc 0.90625\n",
      "2018-05-04T16:46:49.166242: step 9700, loss 0.258907, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T16:46:51.452975: step 9700, loss 0.242391, acc 0.914\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-9700\n",
      "\n",
      "2018-05-04T16:46:52.565582: step 9701, loss 0.27299, acc 0.875\n",
      "2018-05-04T16:46:53.604565: step 9702, loss 0.242509, acc 0.9375\n",
      "2018-05-04T16:46:54.619283: step 9703, loss 0.241775, acc 0.90625\n",
      "2018-05-04T16:46:55.628270: step 9704, loss 0.349036, acc 0.875\n",
      "2018-05-04T16:46:56.612886: step 9705, loss 0.33455, acc 0.84375\n",
      "2018-05-04T16:46:57.608991: step 9706, loss 0.365059, acc 0.84375\n",
      "2018-05-04T16:46:58.598144: step 9707, loss 0.296244, acc 0.875\n",
      "2018-05-04T16:46:59.604026: step 9708, loss 0.172662, acc 0.921875\n",
      "2018-05-04T16:47:00.613072: step 9709, loss 0.198996, acc 0.9375\n",
      "2018-05-04T16:47:01.616354: step 9710, loss 0.288829, acc 0.84375\n",
      "2018-05-04T16:47:02.650838: step 9711, loss 0.227885, acc 0.9375\n",
      "2018-05-04T16:47:03.647868: step 9712, loss 0.28638, acc 0.890625\n",
      "2018-05-04T16:47:04.728272: step 9713, loss 0.351108, acc 0.875\n",
      "2018-05-04T16:47:05.746018: step 9714, loss 0.326801, acc 0.890625\n",
      "2018-05-04T16:47:06.796931: step 9715, loss 0.276584, acc 0.875\n",
      "2018-05-04T16:47:07.793528: step 9716, loss 0.302887, acc 0.890625\n",
      "2018-05-04T16:47:08.779799: step 9717, loss 0.287942, acc 0.84375\n",
      "2018-05-04T16:47:09.769581: step 9718, loss 0.259606, acc 0.90625\n",
      "2018-05-04T16:47:10.759559: step 9719, loss 0.347529, acc 0.859375\n",
      "2018-05-04T16:47:11.750642: step 9720, loss 0.182156, acc 0.921875\n",
      "2018-05-04T16:47:12.768500: step 9721, loss 0.241875, acc 0.9375\n",
      "2018-05-04T16:47:13.813694: step 9722, loss 0.552617, acc 0.765625\n",
      "2018-05-04T16:47:14.832504: step 9723, loss 0.354348, acc 0.90625\n",
      "2018-05-04T16:47:15.851516: step 9724, loss 0.252708, acc 0.890625\n",
      "2018-05-04T16:47:16.873132: step 9725, loss 0.349183, acc 0.796875\n",
      "2018-05-04T16:47:17.963787: step 9726, loss 0.20407, acc 0.90625\n",
      "2018-05-04T16:47:18.955284: step 9727, loss 0.29825, acc 0.875\n",
      "2018-05-04T16:47:19.932915: step 9728, loss 0.292457, acc 0.90625\n",
      "2018-05-04T16:47:20.923276: step 9729, loss 0.191573, acc 0.953125\n",
      "2018-05-04T16:47:21.907492: step 9730, loss 0.2311, acc 0.921875\n",
      "2018-05-04T16:47:22.913977: step 9731, loss 0.288352, acc 0.859375\n",
      "2018-05-04T16:47:23.937616: step 9732, loss 0.226093, acc 0.90625\n",
      "2018-05-04T16:47:24.969428: step 9733, loss 0.224155, acc 0.921875\n",
      "2018-05-04T16:47:26.023783: step 9734, loss 0.278799, acc 0.90625\n",
      "2018-05-04T16:47:27.041531: step 9735, loss 0.364334, acc 0.859375\n",
      "2018-05-04T16:47:28.064898: step 9736, loss 0.255249, acc 0.84375\n",
      "2018-05-04T16:47:29.087070: step 9737, loss 0.314479, acc 0.890625\n",
      "2018-05-04T16:47:30.109152: step 9738, loss 0.244241, acc 0.875\n",
      "2018-05-04T16:47:31.088680: step 9739, loss 0.378802, acc 0.796875\n",
      "2018-05-04T16:47:32.075140: step 9740, loss 0.329116, acc 0.921875\n",
      "2018-05-04T16:47:33.055775: step 9741, loss 0.286889, acc 0.875\n",
      "2018-05-04T16:47:34.120632: step 9742, loss 0.328301, acc 0.828125\n",
      "2018-05-04T16:47:35.114876: step 9743, loss 0.211023, acc 0.953125\n",
      "2018-05-04T16:47:36.137417: step 9744, loss 0.199487, acc 0.9375\n",
      "2018-05-04T16:47:37.152286: step 9745, loss 0.364594, acc 0.8125\n",
      "2018-05-04T16:47:38.234388: step 9746, loss 0.204368, acc 0.90625\n",
      "2018-05-04T16:47:39.213086: step 9747, loss 0.191001, acc 0.9375\n",
      "2018-05-04T16:47:40.200842: step 9748, loss 0.216134, acc 0.9375\n",
      "2018-05-04T16:47:41.206557: step 9749, loss 0.1993, acc 0.9375\n",
      "2018-05-04T16:47:42.284455: step 9750, loss 0.285657, acc 0.859375\n",
      "2018-05-04T16:47:43.300871: step 9751, loss 0.266687, acc 0.921875\n",
      "2018-05-04T16:47:44.386768: step 9752, loss 0.261912, acc 0.90625\n",
      "2018-05-04T16:47:45.397308: step 9753, loss 0.179251, acc 0.9375\n",
      "2018-05-04T16:47:46.398218: step 9754, loss 0.259102, acc 0.953125\n",
      "2018-05-04T16:47:47.469059: step 9755, loss 0.34394, acc 0.859375\n",
      "2018-05-04T16:47:48.478983: step 9756, loss 0.221268, acc 0.921875\n",
      "2018-05-04T16:47:49.480887: step 9757, loss 0.323415, acc 0.875\n",
      "2018-05-04T16:47:50.549007: step 9758, loss 0.255824, acc 0.890625\n",
      "2018-05-04T16:47:51.627719: step 9759, loss 0.343998, acc 0.859375\n",
      "2018-05-04T16:47:52.682767: step 9760, loss 0.203678, acc 0.90625\n",
      "2018-05-04T16:47:53.750192: step 9761, loss 0.327812, acc 0.84375\n",
      "2018-05-04T16:47:54.746513: step 9762, loss 0.17567, acc 0.890625\n",
      "2018-05-04T16:47:55.767397: step 9763, loss 0.196069, acc 0.921875\n",
      "2018-05-04T16:47:56.805426: step 9764, loss 0.33704, acc 0.890625\n",
      "2018-05-04T16:47:57.802067: step 9765, loss 0.220057, acc 0.875\n",
      "2018-05-04T16:47:58.789578: step 9766, loss 0.293594, acc 0.84375\n",
      "2018-05-04T16:47:59.794830: step 9767, loss 0.29246, acc 0.890625\n",
      "2018-05-04T16:48:00.861692: step 9768, loss 0.257067, acc 0.859375\n",
      "2018-05-04T16:48:01.921659: step 9769, loss 0.403938, acc 0.828125\n",
      "2018-05-04T16:48:02.891001: step 9770, loss 0.2363, acc 0.890625\n",
      "2018-05-04T16:48:03.961117: step 9771, loss 0.201633, acc 0.90625\n",
      "2018-05-04T16:48:04.926093: step 9772, loss 0.309532, acc 0.84375\n",
      "2018-05-04T16:48:05.907005: step 9773, loss 0.357373, acc 0.84375\n",
      "2018-05-04T16:48:06.962345: step 9774, loss 0.280518, acc 0.890625\n",
      "2018-05-04T16:48:07.950710: step 9775, loss 0.211297, acc 0.90625\n",
      "2018-05-04T16:48:09.029811: step 9776, loss 0.170182, acc 0.9375\n",
      "2018-05-04T16:48:10.015081: step 9777, loss 0.261662, acc 0.890625\n",
      "2018-05-04T16:48:11.070613: step 9778, loss 0.343847, acc 0.796875\n",
      "2018-05-04T16:48:12.147449: step 9779, loss 0.205263, acc 0.921875\n",
      "2018-05-04T16:48:13.193876: step 9780, loss 0.347469, acc 0.84375\n",
      "2018-05-04T16:48:14.233854: step 9781, loss 0.283476, acc 0.890625\n",
      "2018-05-04T16:48:15.303477: step 9782, loss 0.281962, acc 0.90625\n",
      "2018-05-04T16:48:16.371772: step 9783, loss 0.386905, acc 0.828125\n",
      "2018-05-04T16:48:17.334958: step 9784, loss 0.531072, acc 0.765625\n",
      "2018-05-04T16:48:18.386273: step 9785, loss 0.291486, acc 0.859375\n",
      "2018-05-04T16:48:19.435021: step 9786, loss 0.181105, acc 0.9375\n",
      "2018-05-04T16:48:20.466584: step 9787, loss 0.318009, acc 0.90625\n",
      "2018-05-04T16:48:21.504417: step 9788, loss 0.295443, acc 0.890625\n",
      "2018-05-04T16:48:22.502677: step 9789, loss 0.215589, acc 0.921875\n",
      "2018-05-04T16:48:23.534117: step 9790, loss 0.450705, acc 0.84375\n",
      "2018-05-04T16:48:24.530428: step 9791, loss 0.2772, acc 0.890625\n",
      "2018-05-04T16:48:25.548232: step 9792, loss 0.353418, acc 0.875\n",
      "2018-05-04T16:48:26.566308: step 9793, loss 0.187057, acc 0.921875\n",
      "2018-05-04T16:48:27.574847: step 9794, loss 0.306634, acc 0.890625\n",
      "2018-05-04T16:48:28.590563: step 9795, loss 0.233923, acc 0.921875\n",
      "2018-05-04T16:48:29.609373: step 9796, loss 0.262124, acc 0.890625\n",
      "2018-05-04T16:48:30.631170: step 9797, loss 0.236001, acc 0.921875\n",
      "2018-05-04T16:48:31.682380: step 9798, loss 0.341785, acc 0.859375\n",
      "2018-05-04T16:48:32.704286: step 9799, loss 0.172648, acc 0.921875\n",
      "2018-05-04T16:48:33.729183: step 9800, loss 0.2338, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T16:48:35.880822: step 9800, loss 0.247026, acc 0.908\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-9800\n",
      "\n",
      "2018-05-04T16:48:36.985075: step 9801, loss 0.251664, acc 0.890625\n",
      "2018-05-04T16:48:38.033577: step 9802, loss 0.253391, acc 0.890625\n",
      "2018-05-04T16:48:38.988256: step 9803, loss 0.265643, acc 0.875\n",
      "2018-05-04T16:48:40.020878: step 9804, loss 0.387548, acc 0.796875\n",
      "2018-05-04T16:48:41.071482: step 9805, loss 0.266454, acc 0.875\n",
      "2018-05-04T16:48:42.010480: step 9806, loss 0.302318, acc 0.859375\n",
      "2018-05-04T16:48:43.036343: step 9807, loss 0.310291, acc 0.859375\n",
      "2018-05-04T16:48:44.035491: step 9808, loss 0.411858, acc 0.8125\n",
      "2018-05-04T16:48:45.078556: step 9809, loss 0.291115, acc 0.875\n",
      "2018-05-04T16:48:46.102209: step 9810, loss 0.126626, acc 0.96875\n",
      "2018-05-04T16:48:47.084830: step 9811, loss 0.220854, acc 0.90625\n",
      "2018-05-04T16:48:48.092798: step 9812, loss 0.358431, acc 0.84375\n",
      "2018-05-04T16:48:49.018975: step 9813, loss 0.245035, acc 0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T16:48:50.031842: step 9814, loss 0.299013, acc 0.890625\n",
      "2018-05-04T16:48:51.030622: step 9815, loss 0.21436, acc 0.921875\n",
      "2018-05-04T16:48:52.028732: step 9816, loss 0.350919, acc 0.8125\n",
      "2018-05-04T16:48:53.091099: step 9817, loss 0.304401, acc 0.859375\n",
      "2018-05-04T16:48:54.093995: step 9818, loss 0.270609, acc 0.921875\n",
      "2018-05-04T16:48:55.119760: step 9819, loss 0.204829, acc 0.921875\n",
      "2018-05-04T16:48:56.127427: step 9820, loss 0.290382, acc 0.8125\n",
      "2018-05-04T16:48:57.071392: step 9821, loss 0.270749, acc 0.890625\n",
      "2018-05-04T16:48:58.070005: step 9822, loss 0.185056, acc 0.921875\n",
      "2018-05-04T16:48:59.082280: step 9823, loss 0.267741, acc 0.90625\n",
      "2018-05-04T16:49:00.090194: step 9824, loss 0.2847, acc 0.859375\n",
      "2018-05-04T16:49:01.136448: step 9825, loss 0.244272, acc 0.921875\n",
      "2018-05-04T16:49:02.153445: step 9826, loss 0.321539, acc 0.890625\n",
      "2018-05-04T16:49:03.150863: step 9827, loss 0.221006, acc 0.90625\n",
      "2018-05-04T16:49:04.175791: step 9828, loss 0.471953, acc 0.8125\n",
      "2018-05-04T16:49:05.146480: step 9829, loss 0.269712, acc 0.921875\n",
      "2018-05-04T16:49:06.148834: step 9830, loss 0.29172, acc 0.84375\n",
      "2018-05-04T16:49:07.143040: step 9831, loss 0.208212, acc 0.90625\n",
      "2018-05-04T16:49:08.150472: step 9832, loss 0.246248, acc 0.859375\n",
      "2018-05-04T16:49:09.161757: step 9833, loss 0.19759, acc 0.96875\n",
      "2018-05-04T16:49:10.159682: step 9834, loss 0.370661, acc 0.875\n",
      "2018-05-04T16:49:11.178204: step 9835, loss 0.13198, acc 0.984375\n",
      "2018-05-04T16:49:12.191931: step 9836, loss 0.267, acc 0.9375\n",
      "2018-05-04T16:49:13.190610: step 9837, loss 0.201245, acc 0.953125\n",
      "2018-05-04T16:49:14.206944: step 9838, loss 0.269199, acc 0.859375\n",
      "2018-05-04T16:49:15.234905: step 9839, loss 0.213562, acc 0.890625\n",
      "2018-05-04T16:49:16.217124: step 9840, loss 0.281283, acc 0.90625\n",
      "2018-05-04T16:49:17.297869: step 9841, loss 0.293539, acc 0.84375\n",
      "2018-05-04T16:49:18.269180: step 9842, loss 0.204666, acc 0.921875\n",
      "2018-05-04T16:49:19.295851: step 9843, loss 0.330994, acc 0.890625\n",
      "2018-05-04T16:49:20.307798: step 9844, loss 0.33069, acc 0.859375\n",
      "2018-05-04T16:49:21.312156: step 9845, loss 0.181324, acc 0.9375\n",
      "2018-05-04T16:49:22.296462: step 9846, loss 0.261123, acc 0.90625\n",
      "2018-05-04T16:49:23.300439: step 9847, loss 0.321101, acc 0.890625\n",
      "2018-05-04T16:49:24.290071: step 9848, loss 0.333339, acc 0.890625\n",
      "2018-05-04T16:49:25.303353: step 9849, loss 0.288649, acc 0.875\n",
      "2018-05-04T16:49:26.329690: step 9850, loss 0.268495, acc 0.890625\n",
      "2018-05-04T16:49:27.335109: step 9851, loss 0.33401, acc 0.796875\n",
      "2018-05-04T16:49:28.354806: step 9852, loss 0.229309, acc 0.875\n",
      "2018-05-04T16:49:29.349980: step 9853, loss 0.391577, acc 0.796875\n",
      "2018-05-04T16:49:30.372419: step 9854, loss 0.304688, acc 0.859375\n",
      "2018-05-04T16:49:31.367662: step 9855, loss 0.253756, acc 0.90625\n",
      "2018-05-04T16:49:32.386391: step 9856, loss 0.318531, acc 0.875\n",
      "2018-05-04T16:49:33.457045: step 9857, loss 0.322235, acc 0.921875\n",
      "2018-05-04T16:49:34.516500: step 9858, loss 0.16375, acc 0.921875\n",
      "2018-05-04T16:49:35.618357: step 9859, loss 0.231973, acc 0.90625\n",
      "2018-05-04T16:49:36.688359: step 9860, loss 0.525671, acc 0.796875\n",
      "2018-05-04T16:49:37.721494: step 9861, loss 0.275281, acc 0.90625\n",
      "2018-05-04T16:49:38.734326: step 9862, loss 0.191592, acc 0.953125\n",
      "2018-05-04T16:49:39.766292: step 9863, loss 0.170267, acc 0.9375\n",
      "2018-05-04T16:49:40.793644: step 9864, loss 0.274601, acc 0.859375\n",
      "2018-05-04T16:49:41.825543: step 9865, loss 0.210734, acc 0.890625\n",
      "2018-05-04T16:49:42.843820: step 9866, loss 0.201334, acc 0.921875\n",
      "2018-05-04T16:49:43.856208: step 9867, loss 0.219544, acc 0.9375\n",
      "2018-05-04T16:49:44.879868: step 9868, loss 0.181216, acc 0.9375\n",
      "2018-05-04T16:49:45.895743: step 9869, loss 0.34263, acc 0.84375\n",
      "2018-05-04T16:49:46.921966: step 9870, loss 0.169123, acc 0.9375\n",
      "2018-05-04T16:49:47.921011: step 9871, loss 0.287819, acc 0.84375\n",
      "2018-05-04T16:49:49.020612: step 9872, loss 0.317548, acc 0.859375\n",
      "2018-05-04T16:49:50.025805: step 9873, loss 0.306398, acc 0.890625\n",
      "2018-05-04T16:49:51.034471: step 9874, loss 0.270988, acc 0.921875\n",
      "2018-05-04T16:49:52.046239: step 9875, loss 0.274713, acc 0.875\n",
      "2018-05-04T16:49:53.036776: step 9876, loss 0.334286, acc 0.890625\n",
      "2018-05-04T16:49:54.038992: step 9877, loss 0.378758, acc 0.890625\n",
      "2018-05-04T16:49:55.101371: step 9878, loss 0.266853, acc 0.921875\n",
      "2018-05-04T16:49:56.121641: step 9879, loss 0.366381, acc 0.84375\n",
      "2018-05-04T16:49:57.124802: step 9880, loss 0.233224, acc 0.953125\n",
      "2018-05-04T16:49:58.140425: step 9881, loss 0.277762, acc 0.90625\n",
      "2018-05-04T16:49:59.153108: step 9882, loss 0.333916, acc 0.859375\n",
      "2018-05-04T16:50:00.146664: step 9883, loss 0.228056, acc 0.90625\n",
      "2018-05-04T16:50:01.206410: step 9884, loss 0.203173, acc 0.953125\n",
      "2018-05-04T16:50:02.200242: step 9885, loss 0.356428, acc 0.875\n",
      "2018-05-04T16:50:03.213085: step 9886, loss 0.320134, acc 0.875\n",
      "2018-05-04T16:50:04.247094: step 9887, loss 0.233064, acc 0.890625\n",
      "2018-05-04T16:50:05.255420: step 9888, loss 0.450874, acc 0.8125\n",
      "2018-05-04T16:50:06.270172: step 9889, loss 0.214615, acc 0.921875\n",
      "2018-05-04T16:50:07.243756: step 9890, loss 0.275862, acc 0.84375\n",
      "2018-05-04T16:50:08.224612: step 9891, loss 0.326984, acc 0.8125\n",
      "2018-05-04T16:50:09.227453: step 9892, loss 0.228432, acc 0.890625\n",
      "2018-05-04T16:50:10.224747: step 9893, loss 0.318219, acc 0.890625\n",
      "2018-05-04T16:50:11.226701: step 9894, loss 0.263827, acc 0.9375\n",
      "2018-05-04T16:50:12.223062: step 9895, loss 0.189786, acc 0.953125\n",
      "2018-05-04T16:50:13.234002: step 9896, loss 0.198081, acc 0.921875\n",
      "2018-05-04T16:50:14.256015: step 9897, loss 0.189445, acc 0.921875\n",
      "2018-05-04T16:50:15.251891: step 9898, loss 0.261011, acc 0.921875\n",
      "2018-05-04T16:50:16.246515: step 9899, loss 0.374737, acc 0.8125\n",
      "2018-05-04T16:50:17.231042: step 9900, loss 0.228233, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T16:50:20.241541: step 9900, loss 0.240388, acc 0.92\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-9900\n",
      "\n",
      "2018-05-04T16:50:21.338510: step 9901, loss 0.220183, acc 0.921875\n",
      "2018-05-04T16:50:22.333760: step 9902, loss 0.270658, acc 0.90625\n",
      "2018-05-04T16:50:23.355425: step 9903, loss 0.271852, acc 0.890625\n",
      "2018-05-04T16:50:24.379908: step 9904, loss 0.171161, acc 0.96875\n",
      "2018-05-04T16:50:25.396155: step 9905, loss 0.341427, acc 0.8125\n",
      "2018-05-04T16:50:26.421439: step 9906, loss 0.178807, acc 0.9375\n",
      "2018-05-04T16:50:27.421336: step 9907, loss 0.189889, acc 0.9375\n",
      "2018-05-04T16:50:28.478688: step 9908, loss 0.436971, acc 0.890625\n",
      "2018-05-04T16:50:29.523413: step 9909, loss 0.302857, acc 0.859375\n",
      "2018-05-04T16:50:30.548643: step 9910, loss 0.221659, acc 0.9375\n",
      "2018-05-04T16:50:31.562590: step 9911, loss 0.199153, acc 0.9375\n",
      "2018-05-04T16:50:32.543285: step 9912, loss 0.305829, acc 0.90625\n",
      "2018-05-04T16:50:33.558301: step 9913, loss 0.357264, acc 0.875\n",
      "2018-05-04T16:50:34.558612: step 9914, loss 0.33324, acc 0.859375\n",
      "2018-05-04T16:50:35.560788: step 9915, loss 0.417726, acc 0.828125\n",
      "2018-05-04T16:50:36.546316: step 9916, loss 0.355364, acc 0.859375\n",
      "2018-05-04T16:50:37.532086: step 9917, loss 0.562278, acc 0.75\n",
      "2018-05-04T16:50:38.532763: step 9918, loss 0.227608, acc 0.890625\n",
      "2018-05-04T16:50:39.504749: step 9919, loss 0.468865, acc 0.828125\n",
      "2018-05-04T16:50:40.576532: step 9920, loss 0.245149, acc 0.875\n",
      "2018-05-04T16:50:41.538743: step 9921, loss 0.245678, acc 0.890625\n",
      "2018-05-04T16:50:42.517773: step 9922, loss 0.149976, acc 0.921875\n",
      "2018-05-04T16:50:43.505120: step 9923, loss 0.306414, acc 0.875\n",
      "2018-05-04T16:50:44.481888: step 9924, loss 0.301095, acc 0.859375\n",
      "2018-05-04T16:50:45.460671: step 9925, loss 0.239154, acc 0.921875\n",
      "2018-05-04T16:50:46.443720: step 9926, loss 0.282033, acc 0.890625\n",
      "2018-05-04T16:50:47.422177: step 9927, loss 0.408626, acc 0.875\n",
      "2018-05-04T16:50:48.396111: step 9928, loss 0.261792, acc 0.90625\n",
      "2018-05-04T16:50:49.397166: step 9929, loss 0.47143, acc 0.8125\n",
      "2018-05-04T16:50:50.423268: step 9930, loss 0.360118, acc 0.875\n",
      "2018-05-04T16:50:51.435241: step 9931, loss 0.263166, acc 0.890625\n",
      "2018-05-04T16:50:52.438403: step 9932, loss 0.230317, acc 0.90625\n",
      "2018-05-04T16:50:53.451243: step 9933, loss 0.320777, acc 0.84375\n",
      "2018-05-04T16:50:54.423675: step 9934, loss 0.317577, acc 0.890625\n",
      "2018-05-04T16:50:55.423819: step 9935, loss 0.210581, acc 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T16:50:56.403288: step 9936, loss 0.254496, acc 0.890625\n",
      "2018-05-04T16:50:57.393270: step 9937, loss 0.245524, acc 0.90625\n",
      "2018-05-04T16:50:58.358345: step 9938, loss 0.25769, acc 0.859375\n",
      "2018-05-04T16:50:59.357837: step 9939, loss 0.339602, acc 0.8125\n",
      "2018-05-04T16:51:00.362625: step 9940, loss 0.258014, acc 0.9375\n",
      "2018-05-04T16:51:01.423336: step 9941, loss 0.334061, acc 0.890625\n",
      "2018-05-04T16:51:02.469109: step 9942, loss 0.201036, acc 0.890625\n",
      "2018-05-04T16:51:03.475670: step 9943, loss 0.373021, acc 0.828125\n",
      "2018-05-04T16:51:04.485297: step 9944, loss 0.275667, acc 0.890625\n",
      "2018-05-04T16:51:05.505949: step 9945, loss 0.302488, acc 0.828125\n",
      "2018-05-04T16:51:06.506476: step 9946, loss 0.284589, acc 0.859375\n",
      "2018-05-04T16:51:07.526143: step 9947, loss 0.192049, acc 0.90625\n",
      "2018-05-04T16:51:08.554080: step 9948, loss 0.252503, acc 0.90625\n",
      "2018-05-04T16:51:09.549938: step 9949, loss 0.376865, acc 0.859375\n",
      "2018-05-04T16:51:10.537140: step 9950, loss 0.317487, acc 0.875\n",
      "2018-05-04T16:51:11.532874: step 9951, loss 0.323138, acc 0.875\n",
      "2018-05-04T16:51:12.510675: step 9952, loss 0.420173, acc 0.859375\n",
      "2018-05-04T16:51:13.503913: step 9953, loss 0.302978, acc 0.890625\n",
      "2018-05-04T16:51:14.524366: step 9954, loss 0.26745, acc 0.859375\n",
      "2018-05-04T16:51:15.532073: step 9955, loss 0.121613, acc 0.96875\n",
      "2018-05-04T16:51:16.548518: step 9956, loss 0.193356, acc 0.9375\n",
      "2018-05-04T16:51:17.581334: step 9957, loss 0.266961, acc 0.875\n",
      "2018-05-04T16:51:18.582331: step 9958, loss 0.179164, acc 0.9375\n",
      "2018-05-04T16:51:19.682173: step 9959, loss 0.220285, acc 0.921875\n",
      "2018-05-04T16:51:20.749448: step 9960, loss 0.183373, acc 0.921875\n",
      "2018-05-04T16:51:21.783040: step 9961, loss 0.364724, acc 0.875\n",
      "2018-05-04T16:51:22.784517: step 9962, loss 0.450509, acc 0.796875\n",
      "2018-05-04T16:51:23.790576: step 9963, loss 0.243006, acc 0.875\n",
      "2018-05-04T16:51:24.804947: step 9964, loss 0.357057, acc 0.84375\n",
      "2018-05-04T16:51:25.816153: step 9965, loss 0.235992, acc 0.953125\n",
      "2018-05-04T16:51:26.830781: step 9966, loss 0.195885, acc 0.953125\n",
      "2018-05-04T16:51:27.834391: step 9967, loss 0.395188, acc 0.890625\n",
      "2018-05-04T16:51:28.851552: step 9968, loss 0.212336, acc 0.921875\n",
      "2018-05-04T16:51:29.846726: step 9969, loss 0.285615, acc 0.90625\n",
      "2018-05-04T16:51:30.856511: step 9970, loss 0.275763, acc 0.859375\n",
      "2018-05-04T16:51:31.871152: step 9971, loss 0.288259, acc 0.859375\n",
      "2018-05-04T16:51:32.866926: step 9972, loss 0.2478, acc 0.890625\n",
      "2018-05-04T16:51:33.892068: step 9973, loss 0.239885, acc 0.875\n",
      "2018-05-04T16:51:34.964550: step 9974, loss 0.224855, acc 0.875\n",
      "2018-05-04T16:51:35.930305: step 9975, loss 0.377748, acc 0.828125\n",
      "2018-05-04T16:51:36.912378: step 9976, loss 0.240916, acc 0.90625\n",
      "2018-05-04T16:51:37.889693: step 9977, loss 0.234454, acc 0.875\n",
      "2018-05-04T16:51:38.886691: step 9978, loss 0.300994, acc 0.84375\n",
      "2018-05-04T16:51:39.889680: step 9979, loss 0.239869, acc 0.890625\n",
      "2018-05-04T16:51:40.876706: step 9980, loss 0.408034, acc 0.828125\n",
      "2018-05-04T16:51:41.888554: step 9981, loss 0.349834, acc 0.859375\n",
      "2018-05-04T16:51:42.884465: step 9982, loss 0.260961, acc 0.875\n",
      "2018-05-04T16:51:43.908281: step 9983, loss 0.3848, acc 0.828125\n",
      "2018-05-04T16:51:44.894378: step 9984, loss 0.227729, acc 0.890625\n",
      "2018-05-04T16:51:45.903109: step 9985, loss 0.374116, acc 0.859375\n",
      "2018-05-04T16:51:46.889948: step 9986, loss 0.252214, acc 0.921875\n",
      "2018-05-04T16:51:47.900967: step 9987, loss 0.322318, acc 0.859375\n",
      "2018-05-04T16:51:48.892640: step 9988, loss 0.235099, acc 0.90625\n",
      "2018-05-04T16:51:49.876600: step 9989, loss 0.283529, acc 0.90625\n",
      "2018-05-04T16:51:50.896852: step 9990, loss 0.143902, acc 0.96875\n",
      "2018-05-04T16:51:51.919889: step 9991, loss 0.248485, acc 0.875\n",
      "2018-05-04T16:51:52.970748: step 9992, loss 0.226916, acc 0.9375\n",
      "2018-05-04T16:51:53.959041: step 9993, loss 0.225409, acc 0.9375\n",
      "2018-05-04T16:51:54.953825: step 9994, loss 0.185085, acc 0.90625\n",
      "2018-05-04T16:51:55.963848: step 9995, loss 0.173476, acc 0.9375\n",
      "2018-05-04T16:51:56.958153: step 9996, loss 0.276474, acc 0.859375\n",
      "2018-05-04T16:51:57.933327: step 9997, loss 0.235322, acc 0.890625\n",
      "2018-05-04T16:51:58.933474: step 9998, loss 0.348462, acc 0.859375\n",
      "2018-05-04T16:51:59.916178: step 9999, loss 0.218838, acc 0.921875\n",
      "2018-05-04T16:52:00.890574: step 10000, loss 0.37014, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T16:52:03.129386: step 10000, loss 0.227341, acc 0.918\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-10000\n",
      "\n",
      "2018-05-04T16:52:04.334824: step 10001, loss 0.319523, acc 0.84375\n",
      "2018-05-04T16:52:05.333679: step 10002, loss 0.283957, acc 0.875\n",
      "2018-05-04T16:52:06.328959: step 10003, loss 0.239418, acc 0.921875\n",
      "2018-05-04T16:52:07.326896: step 10004, loss 0.290743, acc 0.859375\n",
      "2018-05-04T16:52:08.390822: step 10005, loss 0.144366, acc 0.953125\n",
      "2018-05-04T16:52:09.382692: step 10006, loss 0.242826, acc 0.90625\n",
      "2018-05-04T16:52:10.366478: step 10007, loss 0.334522, acc 0.875\n",
      "2018-05-04T16:52:11.417550: step 10008, loss 0.257289, acc 0.921875\n",
      "2018-05-04T16:52:12.395911: step 10009, loss 0.322416, acc 0.828125\n",
      "2018-05-04T16:52:13.388236: step 10010, loss 0.255041, acc 0.84375\n",
      "2018-05-04T16:52:14.402387: step 10011, loss 0.292044, acc 0.875\n",
      "2018-05-04T16:52:15.391831: step 10012, loss 0.206386, acc 0.9375\n",
      "2018-05-04T16:52:16.388159: step 10013, loss 0.280215, acc 0.890625\n",
      "2018-05-04T16:52:17.459342: step 10014, loss 0.532705, acc 0.8125\n",
      "2018-05-04T16:52:18.468858: step 10015, loss 0.205939, acc 0.921875\n",
      "2018-05-04T16:52:19.447696: step 10016, loss 0.356962, acc 0.859375\n",
      "2018-05-04T16:52:20.428486: step 10017, loss 0.250969, acc 0.875\n",
      "2018-05-04T16:52:21.425517: step 10018, loss 0.308295, acc 0.890625\n",
      "2018-05-04T16:52:22.411970: step 10019, loss 0.233381, acc 0.921875\n",
      "2018-05-04T16:52:23.432569: step 10020, loss 0.232929, acc 0.921875\n",
      "2018-05-04T16:52:24.443234: step 10021, loss 0.316443, acc 0.859375\n",
      "2018-05-04T16:52:25.548118: step 10022, loss 0.271701, acc 0.859375\n",
      "2018-05-04T16:52:26.597069: step 10023, loss 0.401103, acc 0.84375\n",
      "2018-05-04T16:52:27.574218: step 10024, loss 0.468746, acc 0.84375\n",
      "2018-05-04T16:52:28.559419: step 10025, loss 0.256255, acc 0.890625\n",
      "2018-05-04T16:52:29.575526: step 10026, loss 0.295648, acc 0.875\n",
      "2018-05-04T16:52:30.600754: step 10027, loss 0.271318, acc 0.921875\n",
      "2018-05-04T16:52:31.587739: step 10028, loss 0.188132, acc 0.9375\n",
      "2018-05-04T16:52:32.593956: step 10029, loss 0.227253, acc 0.875\n",
      "2018-05-04T16:52:33.645135: step 10030, loss 0.314664, acc 0.828125\n",
      "2018-05-04T16:52:34.726323: step 10031, loss 0.315714, acc 0.84375\n",
      "2018-05-04T16:52:35.790133: step 10032, loss 0.226549, acc 0.875\n",
      "2018-05-04T16:52:36.867869: step 10033, loss 0.251149, acc 0.90625\n",
      "2018-05-04T16:52:37.892949: step 10034, loss 0.339875, acc 0.875\n",
      "2018-05-04T16:52:38.895581: step 10035, loss 0.177077, acc 0.921875\n",
      "2018-05-04T16:52:39.905926: step 10036, loss 0.271339, acc 0.859375\n",
      "2018-05-04T16:52:40.913024: step 10037, loss 0.227201, acc 0.921875\n",
      "2018-05-04T16:52:41.974206: step 10038, loss 0.349943, acc 0.8125\n",
      "2018-05-04T16:52:43.002510: step 10039, loss 0.44603, acc 0.78125\n",
      "2018-05-04T16:52:43.984870: step 10040, loss 0.184208, acc 0.921875\n",
      "2018-05-04T16:52:44.985020: step 10041, loss 0.240618, acc 0.890625\n",
      "2018-05-04T16:52:45.968206: step 10042, loss 0.266109, acc 0.890625\n",
      "2018-05-04T16:52:46.974117: step 10043, loss 0.308747, acc 0.859375\n",
      "2018-05-04T16:52:48.043554: step 10044, loss 0.242162, acc 0.90625\n",
      "2018-05-04T16:52:49.043785: step 10045, loss 0.317638, acc 0.859375\n",
      "2018-05-04T16:52:50.110868: step 10046, loss 0.379173, acc 0.828125\n",
      "2018-05-04T16:52:51.122636: step 10047, loss 0.287669, acc 0.859375\n",
      "2018-05-04T16:52:52.183054: step 10048, loss 0.249804, acc 0.875\n",
      "2018-05-04T16:52:53.170574: step 10049, loss 0.316911, acc 0.859375\n",
      "2018-05-04T16:52:54.205510: step 10050, loss 0.270086, acc 0.875\n",
      "2018-05-04T16:52:55.198227: step 10051, loss 0.406847, acc 0.828125\n",
      "2018-05-04T16:52:56.192846: step 10052, loss 0.380982, acc 0.875\n",
      "2018-05-04T16:52:57.193561: step 10053, loss 0.349707, acc 0.875\n",
      "2018-05-04T16:52:58.191039: step 10054, loss 0.248479, acc 0.90625\n",
      "2018-05-04T16:52:59.175847: step 10055, loss 0.192943, acc 0.9375\n",
      "2018-05-04T16:53:00.199919: step 10056, loss 0.412446, acc 0.84375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T16:53:01.191346: step 10057, loss 0.16076, acc 0.953125\n",
      "2018-05-04T16:53:02.169909: step 10058, loss 0.360381, acc 0.875\n",
      "2018-05-04T16:53:03.169038: step 10059, loss 0.226017, acc 0.890625\n",
      "2018-05-04T16:53:04.167076: step 10060, loss 0.315737, acc 0.921875\n",
      "2018-05-04T16:53:05.227482: step 10061, loss 0.307196, acc 0.828125\n",
      "2018-05-04T16:53:06.291968: step 10062, loss 0.302845, acc 0.828125\n",
      "2018-05-04T16:53:07.279065: step 10063, loss 0.411891, acc 0.84375\n",
      "2018-05-04T16:53:08.338614: step 10064, loss 0.314841, acc 0.875\n",
      "2018-05-04T16:53:09.382191: step 10065, loss 0.310674, acc 0.828125\n",
      "2018-05-04T16:53:10.474933: step 10066, loss 0.38908, acc 0.859375\n",
      "2018-05-04T16:53:11.527850: step 10067, loss 0.198053, acc 0.9375\n",
      "2018-05-04T16:53:12.547706: step 10068, loss 0.331617, acc 0.875\n",
      "2018-05-04T16:53:13.535293: step 10069, loss 0.225177, acc 0.9375\n",
      "2018-05-04T16:53:14.599775: step 10070, loss 0.40165, acc 0.8125\n",
      "2018-05-04T16:53:15.576371: step 10071, loss 0.278079, acc 0.90625\n",
      "2018-05-04T16:53:16.540649: step 10072, loss 0.278495, acc 0.90625\n",
      "2018-05-04T16:53:17.641465: step 10073, loss 0.266676, acc 0.90625\n",
      "2018-05-04T16:53:18.639396: step 10074, loss 0.229392, acc 0.921875\n",
      "2018-05-04T16:53:19.716075: step 10075, loss 0.19, acc 0.890625\n",
      "2018-05-04T16:53:20.706541: step 10076, loss 0.315383, acc 0.875\n",
      "2018-05-04T16:53:21.680543: step 10077, loss 0.297739, acc 0.859375\n",
      "2018-05-04T16:53:22.733190: step 10078, loss 0.373329, acc 0.84375\n",
      "2018-05-04T16:53:23.721817: step 10079, loss 0.264085, acc 0.859375\n",
      "2018-05-04T16:53:24.771270: step 10080, loss 0.224787, acc 0.921875\n",
      "2018-05-04T16:53:25.871620: step 10081, loss 0.329017, acc 0.84375\n",
      "2018-05-04T16:53:26.884487: step 10082, loss 0.25081, acc 0.875\n",
      "2018-05-04T16:53:27.915933: step 10083, loss 0.313499, acc 0.859375\n",
      "2018-05-04T16:53:28.923520: step 10084, loss 0.285099, acc 0.828125\n",
      "2018-05-04T16:53:29.960716: step 10085, loss 0.28175, acc 0.859375\n",
      "2018-05-04T16:53:31.013930: step 10086, loss 0.332268, acc 0.84375\n",
      "2018-05-04T16:53:32.045493: step 10087, loss 0.420716, acc 0.8125\n",
      "2018-05-04T16:53:33.071072: step 10088, loss 0.305238, acc 0.84375\n",
      "2018-05-04T16:53:34.043652: step 10089, loss 0.2372, acc 0.890625\n",
      "2018-05-04T16:53:35.087642: step 10090, loss 0.31492, acc 0.890625\n",
      "2018-05-04T16:53:36.117993: step 10091, loss 0.223567, acc 0.890625\n",
      "2018-05-04T16:53:37.082878: step 10092, loss 0.25977, acc 0.921875\n",
      "2018-05-04T16:53:38.128068: step 10093, loss 0.263985, acc 0.890625\n",
      "2018-05-04T16:53:39.179518: step 10094, loss 0.230283, acc 0.875\n",
      "2018-05-04T16:53:40.143348: step 10095, loss 0.194867, acc 0.90625\n",
      "2018-05-04T16:53:41.183035: step 10096, loss 0.23993, acc 0.9375\n",
      "2018-05-04T16:53:42.233813: step 10097, loss 0.371914, acc 0.8125\n",
      "2018-05-04T16:53:43.256867: step 10098, loss 0.163197, acc 0.9375\n",
      "2018-05-04T16:53:44.299524: step 10099, loss 0.339103, acc 0.828125\n",
      "2018-05-04T16:53:45.269543: step 10100, loss 0.337371, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T16:53:47.861301: step 10100, loss 0.236743, acc 0.918\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-10100\n",
      "\n",
      "2018-05-04T16:53:48.958494: step 10101, loss 0.32729, acc 0.84375\n",
      "2018-05-04T16:53:50.012868: step 10102, loss 0.258964, acc 0.875\n",
      "2018-05-04T16:53:51.128067: step 10103, loss 0.157058, acc 0.953125\n",
      "2018-05-04T16:53:52.178497: step 10104, loss 0.301164, acc 0.84375\n",
      "2018-05-04T16:53:53.261641: step 10105, loss 0.259039, acc 0.90625\n",
      "2018-05-04T16:53:54.353929: step 10106, loss 0.229681, acc 0.953125\n",
      "2018-05-04T16:53:55.373627: step 10107, loss 0.214595, acc 0.890625\n",
      "2018-05-04T16:53:56.428377: step 10108, loss 0.296724, acc 0.890625\n",
      "2018-05-04T16:53:57.466983: step 10109, loss 0.196169, acc 0.921875\n",
      "2018-05-04T16:53:58.502420: step 10110, loss 0.366492, acc 0.8125\n",
      "2018-05-04T16:53:59.529085: step 10111, loss 0.293921, acc 0.90625\n",
      "2018-05-04T16:54:00.562558: step 10112, loss 0.235221, acc 0.90625\n",
      "2018-05-04T16:54:01.584898: step 10113, loss 0.247352, acc 0.9375\n",
      "2018-05-04T16:54:02.622503: step 10114, loss 0.298416, acc 0.921875\n",
      "2018-05-04T16:54:03.648811: step 10115, loss 0.257229, acc 0.90625\n",
      "2018-05-04T16:54:04.743560: step 10116, loss 0.280638, acc 0.921875\n",
      "2018-05-04T16:54:05.794781: step 10117, loss 0.186846, acc 0.953125\n",
      "2018-05-04T16:54:06.834802: step 10118, loss 0.245359, acc 0.921875\n",
      "2018-05-04T16:54:07.862577: step 10119, loss 0.145201, acc 0.96875\n",
      "2018-05-04T16:54:08.870929: step 10120, loss 0.231164, acc 0.90625\n",
      "2018-05-04T16:54:09.878520: step 10121, loss 0.349438, acc 0.890625\n",
      "2018-05-04T16:54:10.892181: step 10122, loss 0.463668, acc 0.78125\n",
      "2018-05-04T16:54:11.881800: step 10123, loss 0.373872, acc 0.8125\n",
      "2018-05-04T16:54:12.885741: step 10124, loss 0.25116, acc 0.9375\n",
      "2018-05-04T16:54:13.936888: step 10125, loss 0.202365, acc 0.90625\n",
      "2018-05-04T16:54:14.939651: step 10126, loss 0.292697, acc 0.828125\n",
      "2018-05-04T16:54:16.011970: step 10127, loss 0.213188, acc 0.90625\n",
      "2018-05-04T16:54:17.002170: step 10128, loss 0.206014, acc 0.90625\n",
      "2018-05-04T16:54:18.027980: step 10129, loss 0.276134, acc 0.859375\n",
      "2018-05-04T16:54:19.043506: step 10130, loss 0.347527, acc 0.859375\n",
      "2018-05-04T16:54:20.101052: step 10131, loss 0.184971, acc 0.9375\n",
      "2018-05-04T16:54:21.105244: step 10132, loss 0.238782, acc 0.90625\n",
      "2018-05-04T16:54:22.117613: step 10133, loss 0.177195, acc 0.953125\n",
      "2018-05-04T16:54:23.144603: step 10134, loss 0.282941, acc 0.890625\n",
      "2018-05-04T16:54:24.231769: step 10135, loss 0.224663, acc 0.9375\n",
      "2018-05-04T16:54:25.230322: step 10136, loss 0.338782, acc 0.859375\n",
      "2018-05-04T16:54:26.233626: step 10137, loss 0.289722, acc 0.875\n",
      "2018-05-04T16:54:27.274778: step 10138, loss 0.211324, acc 0.9375\n",
      "2018-05-04T16:54:28.292299: step 10139, loss 0.192595, acc 0.921875\n",
      "2018-05-04T16:54:29.305276: step 10140, loss 0.268189, acc 0.9375\n",
      "2018-05-04T16:54:30.328375: step 10141, loss 0.353124, acc 0.84375\n",
      "2018-05-04T16:54:31.378697: step 10142, loss 0.429075, acc 0.84375\n",
      "2018-05-04T16:54:32.396776: step 10143, loss 0.45733, acc 0.90625\n",
      "2018-05-04T16:54:33.423507: step 10144, loss 0.247598, acc 0.875\n",
      "2018-05-04T16:54:34.458042: step 10145, loss 0.38205, acc 0.828125\n",
      "2018-05-04T16:54:35.481648: step 10146, loss 0.244379, acc 0.921875\n",
      "2018-05-04T16:54:36.506429: step 10147, loss 0.261072, acc 0.84375\n",
      "2018-05-04T16:54:37.544360: step 10148, loss 0.356113, acc 0.84375\n",
      "2018-05-04T16:54:38.579819: step 10149, loss 0.283048, acc 0.890625\n",
      "2018-05-04T16:54:39.688481: step 10150, loss 0.360355, acc 0.84375\n",
      "2018-05-04T16:54:40.789387: step 10151, loss 0.253831, acc 0.90625\n",
      "2018-05-04T16:54:41.840275: step 10152, loss 0.278668, acc 0.890625\n",
      "2018-05-04T16:54:42.867505: step 10153, loss 0.28695, acc 0.890625\n",
      "2018-05-04T16:54:43.886672: step 10154, loss 0.294661, acc 0.890625\n",
      "2018-05-04T16:54:44.929951: step 10155, loss 0.305354, acc 0.890625\n",
      "2018-05-04T16:54:45.955510: step 10156, loss 0.273496, acc 0.921875\n",
      "2018-05-04T16:54:46.962911: step 10157, loss 0.244541, acc 0.875\n",
      "2018-05-04T16:54:47.956869: step 10158, loss 0.436594, acc 0.828125\n",
      "2018-05-04T16:54:48.971098: step 10159, loss 0.315937, acc 0.875\n",
      "2018-05-04T16:54:49.965956: step 10160, loss 0.413897, acc 0.875\n",
      "2018-05-04T16:54:50.994188: step 10161, loss 0.324829, acc 0.859375\n",
      "2018-05-04T16:54:52.014378: step 10162, loss 0.262022, acc 0.859375\n",
      "2018-05-04T16:54:53.086312: step 10163, loss 0.327577, acc 0.84375\n",
      "2018-05-04T16:54:54.086342: step 10164, loss 0.27247, acc 0.84375\n",
      "2018-05-04T16:54:55.076827: step 10165, loss 0.20134, acc 0.90625\n",
      "2018-05-04T16:54:56.097511: step 10166, loss 0.3533, acc 0.828125\n",
      "2018-05-04T16:54:57.129010: step 10167, loss 0.264813, acc 0.875\n",
      "2018-05-04T16:54:58.171415: step 10168, loss 0.287902, acc 0.875\n",
      "2018-05-04T16:54:59.187019: step 10169, loss 0.373418, acc 0.828125\n",
      "2018-05-04T16:55:00.270228: step 10170, loss 0.276674, acc 0.90625\n",
      "2018-05-04T16:55:01.308278: step 10171, loss 0.418017, acc 0.84375\n",
      "2018-05-04T16:55:02.338308: step 10172, loss 0.190072, acc 0.9375\n",
      "2018-05-04T16:55:03.371590: step 10173, loss 0.24677, acc 0.875\n",
      "2018-05-04T16:55:04.416329: step 10174, loss 0.177445, acc 0.9375\n",
      "2018-05-04T16:55:05.425789: step 10175, loss 0.243006, acc 0.90625\n",
      "2018-05-04T16:55:06.451990: step 10176, loss 0.220458, acc 0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T16:55:07.478037: step 10177, loss 0.21658, acc 0.90625\n",
      "2018-05-04T16:55:08.518692: step 10178, loss 0.158363, acc 0.984375\n",
      "2018-05-04T16:55:09.540179: step 10179, loss 0.398436, acc 0.828125\n",
      "2018-05-04T16:55:10.577405: step 10180, loss 0.263245, acc 0.859375\n",
      "2018-05-04T16:55:11.606896: step 10181, loss 0.329359, acc 0.90625\n",
      "2018-05-04T16:55:12.632875: step 10182, loss 0.132213, acc 0.96875\n",
      "2018-05-04T16:55:13.653762: step 10183, loss 0.259084, acc 0.9375\n",
      "2018-05-04T16:55:14.674523: step 10184, loss 0.238992, acc 0.921875\n",
      "2018-05-04T16:55:15.706119: step 10185, loss 0.203582, acc 0.953125\n",
      "2018-05-04T16:55:16.741555: step 10186, loss 0.218229, acc 0.90625\n",
      "2018-05-04T16:55:17.788698: step 10187, loss 0.318656, acc 0.875\n",
      "2018-05-04T16:55:18.861953: step 10188, loss 0.355427, acc 0.890625\n",
      "2018-05-04T16:55:19.892848: step 10189, loss 0.314751, acc 0.875\n",
      "2018-05-04T16:55:21.003788: step 10190, loss 0.373786, acc 0.921875\n",
      "2018-05-04T16:55:22.043443: step 10191, loss 0.227702, acc 0.90625\n",
      "2018-05-04T16:55:23.133127: step 10192, loss 0.307336, acc 0.875\n",
      "2018-05-04T16:55:24.161530: step 10193, loss 0.230812, acc 0.921875\n",
      "2018-05-04T16:55:25.171440: step 10194, loss 0.218042, acc 0.90625\n",
      "2018-05-04T16:55:26.225318: step 10195, loss 0.378418, acc 0.859375\n",
      "2018-05-04T16:55:27.279593: step 10196, loss 0.439143, acc 0.859375\n",
      "2018-05-04T16:55:28.335539: step 10197, loss 0.407666, acc 0.859375\n",
      "2018-05-04T16:55:29.412389: step 10198, loss 0.277614, acc 0.84375\n",
      "2018-05-04T16:55:30.437790: step 10199, loss 0.340644, acc 0.828125\n",
      "2018-05-04T16:55:31.467515: step 10200, loss 0.234674, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T16:55:34.191937: step 10200, loss 0.23807, acc 0.91\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-10200\n",
      "\n",
      "2018-05-04T16:55:35.420084: step 10201, loss 0.480745, acc 0.890625\n",
      "2018-05-04T16:55:36.544778: step 10202, loss 0.296851, acc 0.9375\n",
      "2018-05-04T16:55:37.646404: step 10203, loss 0.257958, acc 0.90625\n",
      "2018-05-04T16:55:38.774266: step 10204, loss 0.268413, acc 0.875\n",
      "2018-05-04T16:55:39.902178: step 10205, loss 0.24654, acc 0.890625\n",
      "2018-05-04T16:55:41.015473: step 10206, loss 0.293143, acc 0.859375\n",
      "2018-05-04T16:55:42.128956: step 10207, loss 0.21193, acc 0.9375\n",
      "2018-05-04T16:55:43.274207: step 10208, loss 0.249043, acc 0.859375\n",
      "2018-05-04T16:55:44.380860: step 10209, loss 0.273534, acc 0.921875\n",
      "2018-05-04T16:55:45.438506: step 10210, loss 0.18826, acc 0.9375\n",
      "2018-05-04T16:55:46.501609: step 10211, loss 0.421152, acc 0.796875\n",
      "2018-05-04T16:55:47.549307: step 10212, loss 0.256385, acc 0.90625\n",
      "2018-05-04T16:55:48.619235: step 10213, loss 0.246333, acc 0.890625\n",
      "2018-05-04T16:55:49.669929: step 10214, loss 0.28251, acc 0.890625\n",
      "2018-05-04T16:55:50.719022: step 10215, loss 0.29498, acc 0.875\n",
      "2018-05-04T16:55:51.834496: step 10216, loss 0.245828, acc 0.953125\n",
      "2018-05-04T16:55:52.858554: step 10217, loss 0.33021, acc 0.828125\n",
      "2018-05-04T16:55:53.885556: step 10218, loss 0.262473, acc 0.921875\n",
      "2018-05-04T16:55:54.920852: step 10219, loss 0.349605, acc 0.84375\n",
      "2018-05-04T16:55:55.950735: step 10220, loss 0.36302, acc 0.90625\n",
      "2018-05-04T16:55:56.986100: step 10221, loss 0.297666, acc 0.921875\n",
      "2018-05-04T16:55:58.033978: step 10222, loss 0.149574, acc 0.9375\n",
      "2018-05-04T16:55:59.100979: step 10223, loss 0.305307, acc 0.859375\n",
      "2018-05-04T16:56:00.164570: step 10224, loss 0.254705, acc 0.9375\n",
      "2018-05-04T16:56:01.208731: step 10225, loss 0.315779, acc 0.859375\n",
      "2018-05-04T16:56:02.229757: step 10226, loss 0.246857, acc 0.890625\n",
      "2018-05-04T16:56:03.254732: step 10227, loss 0.284269, acc 0.828125\n",
      "2018-05-04T16:56:04.328329: step 10228, loss 0.302901, acc 0.90625\n",
      "2018-05-04T16:56:05.374989: step 10229, loss 0.295644, acc 0.890625\n",
      "2018-05-04T16:56:06.431849: step 10230, loss 0.25679, acc 0.859375\n",
      "2018-05-04T16:56:07.474170: step 10231, loss 0.303949, acc 0.859375\n",
      "2018-05-04T16:56:08.524138: step 10232, loss 0.208075, acc 0.9375\n",
      "2018-05-04T16:56:09.572407: step 10233, loss 0.366855, acc 0.8125\n",
      "2018-05-04T16:56:10.626505: step 10234, loss 0.232616, acc 0.90625\n",
      "2018-05-04T16:56:11.669478: step 10235, loss 0.296222, acc 0.875\n",
      "2018-05-04T16:56:12.697219: step 10236, loss 0.396918, acc 0.875\n",
      "2018-05-04T16:56:13.717495: step 10237, loss 0.418368, acc 0.828125\n",
      "2018-05-04T16:56:14.724403: step 10238, loss 0.24764, acc 0.9375\n",
      "2018-05-04T16:56:15.759087: step 10239, loss 0.298998, acc 0.890625\n",
      "2018-05-04T16:56:16.789830: step 10240, loss 0.251593, acc 0.890625\n",
      "2018-05-04T16:56:17.914420: step 10241, loss 0.222774, acc 0.921875\n",
      "2018-05-04T16:56:18.934565: step 10242, loss 0.209662, acc 0.921875\n",
      "2018-05-04T16:56:19.933712: step 10243, loss 0.381159, acc 0.8125\n",
      "2018-05-04T16:56:20.945393: step 10244, loss 0.353512, acc 0.828125\n",
      "2018-05-04T16:56:21.934817: step 10245, loss 0.197643, acc 0.90625\n",
      "2018-05-04T16:56:22.952107: step 10246, loss 0.308605, acc 0.890625\n",
      "2018-05-04T16:56:24.043826: step 10247, loss 0.226854, acc 0.953125\n",
      "2018-05-04T16:56:25.094365: step 10248, loss 0.388995, acc 0.796875\n",
      "2018-05-04T16:56:26.130970: step 10249, loss 0.245501, acc 0.921875\n",
      "2018-05-04T16:56:27.180500: step 10250, loss 0.281996, acc 0.84375\n",
      "2018-05-04T16:56:28.229039: step 10251, loss 0.198768, acc 0.90625\n",
      "2018-05-04T16:56:29.251727: step 10252, loss 0.256994, acc 0.90625\n",
      "2018-05-04T16:56:30.262424: step 10253, loss 0.158203, acc 0.921875\n",
      "2018-05-04T16:56:31.362149: step 10254, loss 0.277253, acc 0.84375\n",
      "2018-05-04T16:56:32.360089: step 10255, loss 0.275898, acc 0.875\n",
      "2018-05-04T16:56:33.372036: step 10256, loss 0.342682, acc 0.796875\n",
      "2018-05-04T16:56:34.433170: step 10257, loss 0.25484, acc 0.859375\n",
      "2018-05-04T16:56:35.492823: step 10258, loss 0.259642, acc 0.875\n",
      "2018-05-04T16:56:36.532835: step 10259, loss 0.311383, acc 0.875\n",
      "2018-05-04T16:56:37.546431: step 10260, loss 0.323604, acc 0.875\n",
      "2018-05-04T16:56:38.560945: step 10261, loss 0.341926, acc 0.90625\n",
      "2018-05-04T16:56:39.647494: step 10262, loss 0.231885, acc 0.890625\n",
      "2018-05-04T16:56:40.655813: step 10263, loss 0.230021, acc 0.9375\n",
      "2018-05-04T16:56:41.675754: step 10264, loss 0.260891, acc 0.875\n",
      "2018-05-04T16:56:42.680319: step 10265, loss 0.225409, acc 0.84375\n",
      "2018-05-04T16:56:43.680792: step 10266, loss 0.252291, acc 0.859375\n",
      "2018-05-04T16:56:44.767690: step 10267, loss 0.269437, acc 0.890625\n",
      "2018-05-04T16:56:45.862968: step 10268, loss 0.189581, acc 0.953125\n",
      "2018-05-04T16:56:46.891128: step 10269, loss 0.229334, acc 0.859375\n",
      "2018-05-04T16:56:47.913929: step 10270, loss 0.326039, acc 0.859375\n",
      "2018-05-04T16:56:48.930870: step 10271, loss 0.267468, acc 0.90625\n",
      "2018-05-04T16:56:49.985041: step 10272, loss 0.225991, acc 0.9375\n",
      "2018-05-04T16:56:50.999380: step 10273, loss 0.167857, acc 0.9375\n",
      "2018-05-04T16:56:52.015171: step 10274, loss 0.238261, acc 0.90625\n",
      "2018-05-04T16:56:53.008035: step 10275, loss 0.234386, acc 0.921875\n",
      "2018-05-04T16:56:54.017612: step 10276, loss 0.265491, acc 0.90625\n",
      "2018-05-04T16:56:55.028973: step 10277, loss 0.207831, acc 0.90625\n",
      "2018-05-04T16:56:56.028827: step 10278, loss 0.313574, acc 0.859375\n",
      "2018-05-04T16:56:57.053212: step 10279, loss 0.221372, acc 0.90625\n",
      "2018-05-04T16:56:58.069183: step 10280, loss 0.305917, acc 0.859375\n",
      "2018-05-04T16:56:59.104848: step 10281, loss 0.306682, acc 0.84375\n",
      "2018-05-04T16:57:00.131084: step 10282, loss 0.309136, acc 0.875\n",
      "2018-05-04T16:57:01.156169: step 10283, loss 0.484965, acc 0.828125\n",
      "2018-05-04T16:57:02.203642: step 10284, loss 0.289768, acc 0.90625\n",
      "2018-05-04T16:57:03.233749: step 10285, loss 0.25199, acc 0.90625\n",
      "2018-05-04T16:57:04.272078: step 10286, loss 0.271369, acc 0.875\n",
      "2018-05-04T16:57:05.307923: step 10287, loss 0.432455, acc 0.828125\n",
      "2018-05-04T16:57:06.334531: step 10288, loss 0.168421, acc 0.953125\n",
      "2018-05-04T16:57:07.369234: step 10289, loss 0.215253, acc 0.890625\n",
      "2018-05-04T16:57:08.373384: step 10290, loss 0.368825, acc 0.8125\n",
      "2018-05-04T16:57:09.395828: step 10291, loss 0.281622, acc 0.859375\n",
      "2018-05-04T16:57:10.426580: step 10292, loss 0.315059, acc 0.875\n",
      "2018-05-04T16:57:11.483585: step 10293, loss 0.224805, acc 0.890625\n",
      "2018-05-04T16:57:12.511680: step 10294, loss 0.292272, acc 0.90625\n",
      "2018-05-04T16:57:13.543556: step 10295, loss 0.289992, acc 0.890625\n",
      "2018-05-04T16:57:14.631254: step 10296, loss 0.259866, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T16:57:15.654598: step 10297, loss 0.247174, acc 0.890625\n",
      "2018-05-04T16:57:16.681329: step 10298, loss 0.354114, acc 0.84375\n",
      "2018-05-04T16:57:17.712992: step 10299, loss 0.310051, acc 0.90625\n",
      "2018-05-04T16:57:18.727836: step 10300, loss 0.287032, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T16:57:21.040311: step 10300, loss 0.2532, acc 0.906\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-10300\n",
      "\n",
      "2018-05-04T16:57:22.158608: step 10301, loss 0.298433, acc 0.890625\n",
      "2018-05-04T16:57:23.214624: step 10302, loss 0.169754, acc 0.953125\n",
      "2018-05-04T16:57:24.317523: step 10303, loss 0.235822, acc 0.90625\n",
      "2018-05-04T16:57:25.341439: step 10304, loss 0.222983, acc 0.9375\n",
      "2018-05-04T16:57:26.394760: step 10305, loss 0.195813, acc 0.90625\n",
      "2018-05-04T16:57:27.430414: step 10306, loss 0.179, acc 0.921875\n",
      "2018-05-04T16:57:28.508707: step 10307, loss 0.221966, acc 0.921875\n",
      "2018-05-04T16:57:29.620248: step 10308, loss 0.368294, acc 0.84375\n",
      "2018-05-04T16:57:30.681190: step 10309, loss 0.28889, acc 0.875\n",
      "2018-05-04T16:57:31.768926: step 10310, loss 0.258404, acc 0.90625\n",
      "2018-05-04T16:57:32.821037: step 10311, loss 0.316259, acc 0.859375\n",
      "2018-05-04T16:57:33.978144: step 10312, loss 0.250816, acc 0.890625\n",
      "2018-05-04T16:57:34.986078: step 10313, loss 0.299681, acc 0.859375\n",
      "2018-05-04T16:57:36.009759: step 10314, loss 0.302145, acc 0.921875\n",
      "2018-05-04T16:57:37.043932: step 10315, loss 0.396307, acc 0.796875\n",
      "2018-05-04T16:57:38.071334: step 10316, loss 0.277596, acc 0.84375\n",
      "2018-05-04T16:57:39.111310: step 10317, loss 0.185343, acc 0.953125\n",
      "2018-05-04T16:57:40.156603: step 10318, loss 0.270494, acc 0.90625\n",
      "2018-05-04T16:57:41.206831: step 10319, loss 0.174203, acc 0.90625\n",
      "2018-05-04T16:57:42.262393: step 10320, loss 0.223707, acc 0.890625\n",
      "2018-05-04T16:57:43.302170: step 10321, loss 0.284847, acc 0.90625\n",
      "2018-05-04T16:57:44.320282: step 10322, loss 0.374526, acc 0.859375\n",
      "2018-05-04T16:57:45.342605: step 10323, loss 0.305072, acc 0.8125\n",
      "2018-05-04T16:57:46.380003: step 10324, loss 0.376251, acc 0.84375\n",
      "2018-05-04T16:57:47.393293: step 10325, loss 0.390211, acc 0.875\n",
      "2018-05-04T16:57:48.413761: step 10326, loss 0.266473, acc 0.859375\n",
      "2018-05-04T16:57:49.451512: step 10327, loss 0.291739, acc 0.84375\n",
      "2018-05-04T16:57:50.502941: step 10328, loss 0.283334, acc 0.921875\n",
      "2018-05-04T16:57:51.530328: step 10329, loss 0.323782, acc 0.90625\n",
      "2018-05-04T16:57:52.551599: step 10330, loss 0.245508, acc 0.921875\n",
      "2018-05-04T16:57:53.558834: step 10331, loss 0.24876, acc 0.890625\n",
      "2018-05-04T16:57:54.583086: step 10332, loss 0.3198, acc 0.84375\n",
      "2018-05-04T16:57:55.589431: step 10333, loss 0.260007, acc 0.90625\n",
      "2018-05-04T16:57:56.613233: step 10334, loss 0.426624, acc 0.859375\n",
      "2018-05-04T16:57:57.622338: step 10335, loss 0.169236, acc 0.9375\n",
      "2018-05-04T16:57:58.644583: step 10336, loss 0.453496, acc 0.828125\n",
      "2018-05-04T16:57:59.685643: step 10337, loss 0.259405, acc 0.890625\n",
      "2018-05-04T16:58:00.712155: step 10338, loss 0.256357, acc 0.890625\n",
      "2018-05-04T16:58:01.702853: step 10339, loss 0.474314, acc 0.796875\n",
      "2018-05-04T16:58:02.693533: step 10340, loss 0.196716, acc 0.9375\n",
      "2018-05-04T16:58:03.682343: step 10341, loss 0.424636, acc 0.828125\n",
      "2018-05-04T16:58:04.696963: step 10342, loss 0.214325, acc 0.921875\n",
      "2018-05-04T16:58:05.682176: step 10343, loss 0.36822, acc 0.875\n",
      "2018-05-04T16:58:06.664187: step 10344, loss 0.393727, acc 0.828125\n",
      "2018-05-04T16:58:07.715416: step 10345, loss 0.37141, acc 0.859375\n",
      "2018-05-04T16:58:08.699492: step 10346, loss 0.170074, acc 0.953125\n",
      "2018-05-04T16:58:09.705288: step 10347, loss 0.201013, acc 0.921875\n",
      "2018-05-04T16:58:10.722961: step 10348, loss 0.284157, acc 0.84375\n",
      "2018-05-04T16:58:11.711134: step 10349, loss 0.318854, acc 0.859375\n",
      "2018-05-04T16:58:12.777062: step 10350, loss 0.325184, acc 0.875\n",
      "2018-05-04T16:58:13.760131: step 10351, loss 0.385424, acc 0.78125\n",
      "2018-05-04T16:58:14.755809: step 10352, loss 0.416091, acc 0.875\n",
      "2018-05-04T16:58:15.748290: step 10353, loss 0.212877, acc 0.921875\n",
      "2018-05-04T16:58:16.725256: step 10354, loss 0.203314, acc 0.953125\n",
      "2018-05-04T16:58:17.774592: step 10355, loss 0.195084, acc 0.9375\n",
      "2018-05-04T16:58:18.819079: step 10356, loss 0.250458, acc 0.90625\n",
      "2018-05-04T16:58:19.827606: step 10357, loss 0.32601, acc 0.84375\n",
      "2018-05-04T16:58:20.795458: step 10358, loss 0.316643, acc 0.859375\n",
      "2018-05-04T16:58:21.845461: step 10359, loss 0.202555, acc 0.9375\n",
      "2018-05-04T16:58:22.882196: step 10360, loss 0.226286, acc 0.875\n",
      "2018-05-04T16:58:23.842274: step 10361, loss 0.227005, acc 0.90625\n",
      "2018-05-04T16:58:24.815633: step 10362, loss 0.275164, acc 0.859375\n",
      "2018-05-04T16:58:25.849859: step 10363, loss 0.281763, acc 0.859375\n",
      "2018-05-04T16:58:26.800195: step 10364, loss 0.35405, acc 0.84375\n",
      "2018-05-04T16:58:27.752647: step 10365, loss 0.210025, acc 0.90625\n",
      "2018-05-04T16:58:28.723471: step 10366, loss 0.193369, acc 0.921875\n",
      "2018-05-04T16:58:29.779144: step 10367, loss 0.286211, acc 0.90625\n",
      "2018-05-04T16:58:30.814365: step 10368, loss 0.243972, acc 0.9375\n",
      "2018-05-04T16:58:31.894700: step 10369, loss 0.208335, acc 0.96875\n",
      "2018-05-04T16:58:32.849468: step 10370, loss 0.185001, acc 0.9375\n",
      "2018-05-04T16:58:33.929395: step 10371, loss 0.282891, acc 0.859375\n",
      "2018-05-04T16:58:35.061352: step 10372, loss 0.236065, acc 0.921875\n",
      "2018-05-04T16:58:36.169778: step 10373, loss 0.20189, acc 0.90625\n",
      "2018-05-04T16:58:37.228633: step 10374, loss 0.327238, acc 0.828125\n",
      "2018-05-04T16:58:38.188328: step 10375, loss 0.307775, acc 0.84375\n",
      "2018-05-04T16:58:39.152961: step 10376, loss 0.303154, acc 0.875\n",
      "2018-05-04T16:58:40.166090: step 10377, loss 0.232956, acc 0.90625\n",
      "2018-05-04T16:58:41.188612: step 10378, loss 0.275059, acc 0.90625\n",
      "2018-05-04T16:58:42.213231: step 10379, loss 0.257466, acc 0.875\n",
      "2018-05-04T16:58:43.204517: step 10380, loss 0.242492, acc 0.90625\n",
      "2018-05-04T16:58:44.237679: step 10381, loss 0.284085, acc 0.890625\n",
      "2018-05-04T16:58:45.177297: step 10382, loss 0.297552, acc 0.875\n",
      "2018-05-04T16:58:46.115324: step 10383, loss 0.424796, acc 0.828125\n",
      "2018-05-04T16:58:47.155908: step 10384, loss 0.360826, acc 0.875\n",
      "2018-05-04T16:58:48.188001: step 10385, loss 0.237726, acc 0.890625\n",
      "2018-05-04T16:58:49.137505: step 10386, loss 0.262239, acc 0.859375\n",
      "2018-05-04T16:58:50.196535: step 10387, loss 0.3243, acc 0.8125\n",
      "2018-05-04T16:58:51.228501: step 10388, loss 0.257761, acc 0.890625\n",
      "2018-05-04T16:58:52.282069: step 10389, loss 0.39968, acc 0.859375\n",
      "2018-05-04T16:58:53.272812: step 10390, loss 0.290662, acc 0.921875\n",
      "2018-05-04T16:58:54.324799: step 10391, loss 0.322447, acc 0.859375\n",
      "2018-05-04T16:58:55.359828: step 10392, loss 0.327466, acc 0.84375\n",
      "2018-05-04T16:58:56.298978: step 10393, loss 0.304551, acc 0.828125\n",
      "2018-05-04T16:58:57.255428: step 10394, loss 0.27056, acc 0.859375\n",
      "2018-05-04T16:58:58.292924: step 10395, loss 0.370864, acc 0.875\n",
      "2018-05-04T16:58:59.345545: step 10396, loss 0.304146, acc 0.859375\n",
      "2018-05-04T16:59:00.299068: step 10397, loss 0.352268, acc 0.875\n",
      "2018-05-04T16:59:01.335626: step 10398, loss 0.338597, acc 0.828125\n",
      "2018-05-04T16:59:02.295453: step 10399, loss 0.378209, acc 0.84375\n",
      "2018-05-04T16:59:03.321085: step 10400, loss 0.275811, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T16:59:05.622266: step 10400, loss 0.242241, acc 0.906\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-10400\n",
      "\n",
      "2018-05-04T16:59:06.758029: step 10401, loss 0.23889, acc 0.90625\n",
      "2018-05-04T16:59:07.795335: step 10402, loss 0.190881, acc 0.9375\n",
      "2018-05-04T16:59:08.845140: step 10403, loss 0.301241, acc 0.84375\n",
      "2018-05-04T16:59:09.893305: step 10404, loss 0.377779, acc 0.84375\n",
      "2018-05-04T16:59:11.021777: step 10405, loss 0.295829, acc 0.90625\n",
      "2018-05-04T16:59:12.142447: step 10406, loss 0.385144, acc 0.859375\n",
      "2018-05-04T16:59:13.176278: step 10407, loss 0.153994, acc 0.953125\n",
      "2018-05-04T16:59:14.210119: step 10408, loss 0.344402, acc 0.828125\n",
      "2018-05-04T16:59:15.253427: step 10409, loss 0.266104, acc 0.921875\n",
      "2018-05-04T16:59:16.353427: step 10410, loss 0.138913, acc 0.96875\n",
      "2018-05-04T16:59:17.391654: step 10411, loss 0.254576, acc 0.921875\n",
      "2018-05-04T16:59:18.403237: step 10412, loss 0.345732, acc 0.84375\n",
      "2018-05-04T16:59:19.405815: step 10413, loss 0.384214, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T16:59:20.419494: step 10414, loss 0.258921, acc 0.953125\n",
      "2018-05-04T16:59:21.442257: step 10415, loss 0.204859, acc 0.921875\n",
      "2018-05-04T16:59:22.476748: step 10416, loss 0.34543, acc 0.84375\n",
      "2018-05-04T16:59:23.506051: step 10417, loss 0.317051, acc 0.875\n",
      "2018-05-04T16:59:24.534364: step 10418, loss 0.221493, acc 0.953125\n",
      "2018-05-04T16:59:25.541422: step 10419, loss 0.284272, acc 0.875\n",
      "2018-05-04T16:59:26.571351: step 10420, loss 0.325384, acc 0.859375\n",
      "2018-05-04T16:59:27.570701: step 10421, loss 0.261134, acc 0.890625\n",
      "2018-05-04T16:59:28.593476: step 10422, loss 0.284457, acc 0.828125\n",
      "2018-05-04T16:59:29.714802: step 10423, loss 0.239175, acc 0.890625\n",
      "2018-05-04T16:59:30.741075: step 10424, loss 0.233372, acc 0.90625\n",
      "2018-05-04T16:59:31.779255: step 10425, loss 0.181663, acc 0.9375\n",
      "2018-05-04T16:59:32.844993: step 10426, loss 0.257228, acc 0.921875\n",
      "2018-05-04T16:59:33.870621: step 10427, loss 0.235736, acc 0.9375\n",
      "2018-05-04T16:59:34.980057: step 10428, loss 0.284189, acc 0.875\n",
      "2018-05-04T16:59:35.998619: step 10429, loss 0.245693, acc 0.9375\n",
      "2018-05-04T16:59:37.046200: step 10430, loss 0.365145, acc 0.875\n",
      "2018-05-04T16:59:38.061570: step 10431, loss 0.221941, acc 0.921875\n",
      "2018-05-04T16:59:39.095894: step 10432, loss 0.27752, acc 0.90625\n",
      "2018-05-04T16:59:40.116585: step 10433, loss 0.292085, acc 0.890625\n",
      "2018-05-04T16:59:41.155468: step 10434, loss 0.322777, acc 0.890625\n",
      "2018-05-04T16:59:42.204195: step 10435, loss 0.256034, acc 0.890625\n",
      "2018-05-04T16:59:43.231964: step 10436, loss 0.385625, acc 0.875\n",
      "2018-05-04T16:59:44.332705: step 10437, loss 0.244688, acc 0.921875\n",
      "2018-05-04T16:59:45.367052: step 10438, loss 0.282094, acc 0.90625\n",
      "2018-05-04T16:59:46.397341: step 10439, loss 0.266728, acc 0.890625\n",
      "2018-05-04T16:59:47.430246: step 10440, loss 0.314288, acc 0.90625\n",
      "2018-05-04T16:59:48.430693: step 10441, loss 0.257687, acc 0.921875\n",
      "2018-05-04T16:59:49.517168: step 10442, loss 0.307526, acc 0.890625\n",
      "2018-05-04T16:59:50.517791: step 10443, loss 0.214683, acc 0.90625\n",
      "2018-05-04T16:59:51.503085: step 10444, loss 0.330151, acc 0.90625\n",
      "2018-05-04T16:59:52.492889: step 10445, loss 0.357867, acc 0.890625\n",
      "2018-05-04T16:59:53.511702: step 10446, loss 0.267725, acc 0.90625\n",
      "2018-05-04T16:59:54.532853: step 10447, loss 0.310962, acc 0.921875\n",
      "2018-05-04T16:59:55.565364: step 10448, loss 0.305197, acc 0.90625\n",
      "2018-05-04T16:59:56.586667: step 10449, loss 0.458832, acc 0.78125\n",
      "2018-05-04T16:59:57.593318: step 10450, loss 0.385211, acc 0.875\n",
      "2018-05-04T16:59:58.612039: step 10451, loss 0.263523, acc 0.859375\n",
      "2018-05-04T16:59:59.722021: step 10452, loss 0.153657, acc 0.953125\n",
      "2018-05-04T17:00:00.789787: step 10453, loss 0.298482, acc 0.859375\n",
      "2018-05-04T17:00:01.778820: step 10454, loss 0.234768, acc 0.9375\n",
      "2018-05-04T17:00:02.752663: step 10455, loss 0.235203, acc 0.890625\n",
      "2018-05-04T17:00:03.751508: step 10456, loss 0.178942, acc 0.96875\n",
      "2018-05-04T17:00:04.756384: step 10457, loss 0.270983, acc 0.890625\n",
      "2018-05-04T17:00:05.782047: step 10458, loss 0.319918, acc 0.84375\n",
      "2018-05-04T17:00:06.788683: step 10459, loss 0.391672, acc 0.859375\n",
      "2018-05-04T17:00:07.811844: step 10460, loss 0.342403, acc 0.84375\n",
      "2018-05-04T17:00:08.834931: step 10461, loss 0.216965, acc 0.875\n",
      "2018-05-04T17:00:09.840528: step 10462, loss 0.282051, acc 0.90625\n",
      "2018-05-04T17:00:10.835004: step 10463, loss 0.31377, acc 0.875\n",
      "2018-05-04T17:00:11.891018: step 10464, loss 0.210635, acc 0.90625\n",
      "2018-05-04T17:00:12.882642: step 10465, loss 0.422062, acc 0.78125\n",
      "2018-05-04T17:00:13.844791: step 10466, loss 0.22973, acc 0.9375\n",
      "2018-05-04T17:00:14.830839: step 10467, loss 0.322517, acc 0.921875\n",
      "2018-05-04T17:00:15.927691: step 10468, loss 0.15795, acc 0.9375\n",
      "2018-05-04T17:00:16.930552: step 10469, loss 0.354541, acc 0.859375\n",
      "2018-05-04T17:00:17.984632: step 10470, loss 0.253591, acc 0.921875\n",
      "2018-05-04T17:00:18.985248: step 10471, loss 0.355306, acc 0.84375\n",
      "2018-05-04T17:00:19.968617: step 10472, loss 0.260758, acc 0.890625\n",
      "2018-05-04T17:00:20.967944: step 10473, loss 0.230941, acc 0.90625\n",
      "2018-05-04T17:00:21.958432: step 10474, loss 0.213571, acc 0.96875\n",
      "2018-05-04T17:00:22.963782: step 10475, loss 0.197732, acc 0.921875\n",
      "2018-05-04T17:00:23.962766: step 10476, loss 0.30658, acc 0.859375\n",
      "2018-05-04T17:00:24.958481: step 10477, loss 0.205575, acc 0.9375\n",
      "2018-05-04T17:00:25.958621: step 10478, loss 0.315701, acc 0.859375\n",
      "2018-05-04T17:00:26.976158: step 10479, loss 0.252605, acc 0.890625\n",
      "2018-05-04T17:00:27.985886: step 10480, loss 0.226549, acc 0.890625\n",
      "2018-05-04T17:00:28.978645: step 10481, loss 0.243407, acc 0.84375\n",
      "2018-05-04T17:00:29.937780: step 10482, loss 0.231161, acc 0.890625\n",
      "2018-05-04T17:00:30.916299: step 10483, loss 0.210764, acc 0.921875\n",
      "2018-05-04T17:00:31.884790: step 10484, loss 0.198317, acc 0.9375\n",
      "2018-05-04T17:00:32.867746: step 10485, loss 0.228999, acc 0.921875\n",
      "2018-05-04T17:00:33.856650: step 10486, loss 0.338008, acc 0.890625\n",
      "2018-05-04T17:00:34.859454: step 10487, loss 0.268547, acc 0.875\n",
      "2018-05-04T17:00:35.855652: step 10488, loss 0.345857, acc 0.84375\n",
      "2018-05-04T17:00:36.904115: step 10489, loss 0.122717, acc 0.96875\n",
      "2018-05-04T17:00:37.884081: step 10490, loss 0.277351, acc 0.890625\n",
      "2018-05-04T17:00:38.851554: step 10491, loss 0.260913, acc 0.890625\n",
      "2018-05-04T17:00:39.846966: step 10492, loss 0.351366, acc 0.875\n",
      "2018-05-04T17:00:40.885365: step 10493, loss 0.262155, acc 0.90625\n",
      "2018-05-04T17:00:41.864031: step 10494, loss 0.294872, acc 0.875\n",
      "2018-05-04T17:00:42.884428: step 10495, loss 0.204847, acc 0.9375\n",
      "2018-05-04T17:00:43.894386: step 10496, loss 0.202448, acc 0.953125\n",
      "2018-05-04T17:00:44.889735: step 10497, loss 0.172649, acc 0.953125\n",
      "2018-05-04T17:00:45.887631: step 10498, loss 0.171386, acc 0.9375\n",
      "2018-05-04T17:00:46.862815: step 10499, loss 0.306051, acc 0.875\n",
      "2018-05-04T17:00:47.867622: step 10500, loss 0.24171, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T17:00:49.993291: step 10500, loss 0.250664, acc 0.914\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-10500\n",
      "\n",
      "2018-05-04T17:00:51.046739: step 10501, loss 0.373107, acc 0.859375\n",
      "2018-05-04T17:00:52.010467: step 10502, loss 0.470671, acc 0.796875\n",
      "2018-05-04T17:00:52.973364: step 10503, loss 0.211722, acc 0.890625\n",
      "2018-05-04T17:00:53.937809: step 10504, loss 0.137654, acc 0.921875\n",
      "2018-05-04T17:00:54.896898: step 10505, loss 0.145255, acc 0.953125\n",
      "2018-05-04T17:00:55.868126: step 10506, loss 0.357828, acc 0.8125\n",
      "2018-05-04T17:00:56.861166: step 10507, loss 0.337892, acc 0.859375\n",
      "2018-05-04T17:00:57.824491: step 10508, loss 0.160872, acc 0.9375\n",
      "2018-05-04T17:00:58.798402: step 10509, loss 0.223047, acc 0.9375\n",
      "2018-05-04T17:00:59.762795: step 10510, loss 0.305575, acc 0.921875\n",
      "2018-05-04T17:01:00.726439: step 10511, loss 0.344124, acc 0.859375\n",
      "2018-05-04T17:01:01.685961: step 10512, loss 0.252473, acc 0.953125\n",
      "2018-05-04T17:01:02.715242: step 10513, loss 0.292298, acc 0.9375\n",
      "2018-05-04T17:01:03.702677: step 10514, loss 0.39019, acc 0.828125\n",
      "2018-05-04T17:01:04.729807: step 10515, loss 0.285154, acc 0.890625\n",
      "2018-05-04T17:01:05.783242: step 10516, loss 0.262062, acc 0.890625\n",
      "2018-05-04T17:01:06.746391: step 10517, loss 0.249609, acc 0.890625\n",
      "2018-05-04T17:01:07.693204: step 10518, loss 0.292581, acc 0.90625\n",
      "2018-05-04T17:01:08.675868: step 10519, loss 0.189953, acc 0.921875\n",
      "2018-05-04T17:01:09.643393: step 10520, loss 0.250286, acc 0.90625\n",
      "2018-05-04T17:01:10.625252: step 10521, loss 0.374043, acc 0.875\n",
      "2018-05-04T17:01:11.586394: step 10522, loss 0.301353, acc 0.921875\n",
      "2018-05-04T17:01:12.545078: step 10523, loss 0.177482, acc 0.921875\n",
      "2018-05-04T17:01:13.512512: step 10524, loss 0.245242, acc 0.921875\n",
      "2018-05-04T17:01:14.471121: step 10525, loss 0.233732, acc 0.859375\n",
      "2018-05-04T17:01:15.440628: step 10526, loss 0.16825, acc 0.9375\n",
      "2018-05-04T17:01:16.410196: step 10527, loss 0.156785, acc 0.953125\n",
      "2018-05-04T17:01:17.391353: step 10528, loss 0.277313, acc 0.890625\n",
      "2018-05-04T17:01:18.335972: step 10529, loss 0.205063, acc 0.921875\n",
      "2018-05-04T17:01:19.302169: step 10530, loss 0.277934, acc 0.859375\n",
      "2018-05-04T17:01:20.283085: step 10531, loss 0.188372, acc 0.90625\n",
      "2018-05-04T17:01:21.268984: step 10532, loss 0.254752, acc 0.875\n",
      "2018-05-04T17:01:22.312959: step 10533, loss 0.305884, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T17:01:23.315464: step 10534, loss 0.265421, acc 0.890625\n",
      "2018-05-04T17:01:24.292744: step 10535, loss 0.266786, acc 0.859375\n",
      "2018-05-04T17:01:25.254314: step 10536, loss 0.204406, acc 0.90625\n",
      "2018-05-04T17:01:26.234966: step 10537, loss 0.318803, acc 0.90625\n",
      "2018-05-04T17:01:27.175593: step 10538, loss 0.26995, acc 0.890625\n",
      "2018-05-04T17:01:28.133001: step 10539, loss 0.365113, acc 0.84375\n",
      "2018-05-04T17:01:29.105634: step 10540, loss 0.354765, acc 0.875\n",
      "2018-05-04T17:01:30.074215: step 10541, loss 0.0958038, acc 0.96875\n",
      "2018-05-04T17:01:31.052664: step 10542, loss 0.350678, acc 0.8125\n",
      "2018-05-04T17:01:32.048868: step 10543, loss 0.263704, acc 0.84375\n",
      "2018-05-04T17:01:33.048693: step 10544, loss 0.304082, acc 0.921875\n",
      "2018-05-04T17:01:34.075575: step 10545, loss 0.287358, acc 0.875\n",
      "2018-05-04T17:01:35.185391: step 10546, loss 0.362141, acc 0.828125\n",
      "2018-05-04T17:01:36.303332: step 10547, loss 0.309881, acc 0.859375\n",
      "2018-05-04T17:01:37.348703: step 10548, loss 0.241524, acc 0.890625\n",
      "2018-05-04T17:01:38.307433: step 10549, loss 0.317246, acc 0.875\n",
      "2018-05-04T17:01:39.287094: step 10550, loss 0.436451, acc 0.8125\n",
      "2018-05-04T17:01:40.239268: step 10551, loss 0.291644, acc 0.890625\n",
      "2018-05-04T17:01:41.297911: step 10552, loss 0.23343, acc 0.921875\n",
      "2018-05-04T17:01:42.331313: step 10553, loss 0.260419, acc 0.875\n",
      "2018-05-04T17:01:43.293056: step 10554, loss 0.274657, acc 0.875\n",
      "2018-05-04T17:01:44.299445: step 10555, loss 0.150509, acc 0.953125\n",
      "2018-05-04T17:01:45.273267: step 10556, loss 0.318447, acc 0.859375\n",
      "2018-05-04T17:01:46.239310: step 10557, loss 0.388455, acc 0.828125\n",
      "2018-05-04T17:01:47.202161: step 10558, loss 0.198337, acc 0.90625\n",
      "2018-05-04T17:01:48.163706: step 10559, loss 0.210211, acc 0.90625\n",
      "2018-05-04T17:01:49.218058: step 10560, loss 0.257672, acc 0.890625\n",
      "2018-05-04T17:01:50.176155: step 10561, loss 0.205404, acc 0.921875\n",
      "2018-05-04T17:01:51.126964: step 10562, loss 0.277293, acc 0.875\n",
      "2018-05-04T17:01:52.085626: step 10563, loss 0.272326, acc 0.859375\n",
      "2018-05-04T17:01:53.041212: step 10564, loss 0.239393, acc 0.90625\n",
      "2018-05-04T17:01:54.048561: step 10565, loss 0.276091, acc 0.875\n",
      "2018-05-04T17:01:55.031595: step 10566, loss 0.431838, acc 0.828125\n",
      "2018-05-04T17:01:56.092669: step 10567, loss 0.380108, acc 0.859375\n",
      "2018-05-04T17:01:57.060918: step 10568, loss 0.345096, acc 0.875\n",
      "2018-05-04T17:01:58.023369: step 10569, loss 0.19958, acc 0.9375\n",
      "2018-05-04T17:01:58.984497: step 10570, loss 0.559306, acc 0.75\n",
      "2018-05-04T17:02:00.018073: step 10571, loss 0.140534, acc 0.96875\n",
      "2018-05-04T17:02:00.985598: step 10572, loss 0.346533, acc 0.875\n",
      "2018-05-04T17:02:01.951513: step 10573, loss 0.288904, acc 0.890625\n",
      "2018-05-04T17:02:02.995604: step 10574, loss 0.265106, acc 0.875\n",
      "2018-05-04T17:02:03.954484: step 10575, loss 0.232526, acc 0.90625\n",
      "2018-05-04T17:02:04.917224: step 10576, loss 0.305053, acc 0.875\n",
      "2018-05-04T17:02:05.971728: step 10577, loss 0.454159, acc 0.796875\n",
      "2018-05-04T17:02:06.974718: step 10578, loss 0.237753, acc 0.9375\n",
      "2018-05-04T17:02:07.925471: step 10579, loss 0.197161, acc 0.921875\n",
      "2018-05-04T17:02:08.935612: step 10580, loss 0.278373, acc 0.890625\n",
      "2018-05-04T17:02:09.875151: step 10581, loss 0.264755, acc 0.875\n",
      "2018-05-04T17:02:10.942336: step 10582, loss 0.195079, acc 0.96875\n",
      "2018-05-04T17:02:11.980351: step 10583, loss 0.335003, acc 0.875\n",
      "2018-05-04T17:02:12.987637: step 10584, loss 0.336638, acc 0.859375\n",
      "2018-05-04T17:02:13.951922: step 10585, loss 0.325731, acc 0.828125\n",
      "2018-05-04T17:02:14.900654: step 10586, loss 0.348432, acc 0.859375\n",
      "2018-05-04T17:02:15.860478: step 10587, loss 0.264381, acc 0.90625\n",
      "2018-05-04T17:02:16.921462: step 10588, loss 0.226414, acc 0.90625\n",
      "2018-05-04T17:02:17.898849: step 10589, loss 0.18541, acc 0.921875\n",
      "2018-05-04T17:02:18.885109: step 10590, loss 0.281884, acc 0.859375\n",
      "2018-05-04T17:02:19.924943: step 10591, loss 0.302016, acc 0.890625\n",
      "2018-05-04T17:02:20.866436: step 10592, loss 0.46398, acc 0.84375\n",
      "2018-05-04T17:02:21.895628: step 10593, loss 0.259474, acc 0.890625\n",
      "2018-05-04T17:02:22.849830: step 10594, loss 0.166687, acc 0.953125\n",
      "2018-05-04T17:02:23.849989: step 10595, loss 0.253452, acc 0.859375\n",
      "2018-05-04T17:02:24.902893: step 10596, loss 0.322511, acc 0.90625\n",
      "2018-05-04T17:02:25.912822: step 10597, loss 0.312353, acc 0.859375\n",
      "2018-05-04T17:02:26.867747: step 10598, loss 0.333009, acc 0.890625\n",
      "2018-05-04T17:02:27.896886: step 10599, loss 0.297422, acc 0.859375\n",
      "2018-05-04T17:02:28.914246: step 10600, loss 0.229996, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T17:02:31.411169: step 10600, loss 0.244498, acc 0.906\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-10600\n",
      "\n",
      "2018-05-04T17:02:32.594877: step 10601, loss 0.29465, acc 0.859375\n",
      "2018-05-04T17:02:33.660540: step 10602, loss 0.356041, acc 0.84375\n",
      "2018-05-04T17:02:34.782297: step 10603, loss 0.260186, acc 0.921875\n",
      "2018-05-04T17:02:35.824126: step 10604, loss 0.223307, acc 0.921875\n",
      "2018-05-04T17:02:36.883646: step 10605, loss 0.172706, acc 0.953125\n",
      "2018-05-04T17:02:37.876343: step 10606, loss 0.298382, acc 0.921875\n",
      "2018-05-04T17:02:38.907080: step 10607, loss 0.229205, acc 0.890625\n",
      "2018-05-04T17:02:39.925728: step 10608, loss 0.291049, acc 0.890625\n",
      "2018-05-04T17:02:40.975157: step 10609, loss 0.338774, acc 0.875\n",
      "2018-05-04T17:02:41.977687: step 10610, loss 0.316385, acc 0.875\n",
      "2018-05-04T17:02:42.979368: step 10611, loss 0.290469, acc 0.890625\n",
      "2018-05-04T17:02:43.956203: step 10612, loss 0.439163, acc 0.890625\n",
      "2018-05-04T17:02:44.983203: step 10613, loss 0.31484, acc 0.875\n",
      "2018-05-04T17:02:46.017575: step 10614, loss 0.203445, acc 0.90625\n",
      "2018-05-04T17:02:47.035073: step 10615, loss 0.240185, acc 0.921875\n",
      "2018-05-04T17:02:48.061805: step 10616, loss 0.254999, acc 0.890625\n",
      "2018-05-04T17:02:49.141496: step 10617, loss 0.187962, acc 0.9375\n",
      "2018-05-04T17:02:50.142753: step 10618, loss 0.271879, acc 0.875\n",
      "2018-05-04T17:02:51.193178: step 10619, loss 0.335899, acc 0.890625\n",
      "2018-05-04T17:02:52.211976: step 10620, loss 0.275105, acc 0.84375\n",
      "2018-05-04T17:02:53.198293: step 10621, loss 0.315488, acc 0.890625\n",
      "2018-05-04T17:02:54.318281: step 10622, loss 0.331263, acc 0.875\n",
      "2018-05-04T17:02:55.328211: step 10623, loss 0.321298, acc 0.828125\n",
      "2018-05-04T17:02:56.336204: step 10624, loss 0.344307, acc 0.875\n",
      "2018-05-04T17:02:57.370645: step 10625, loss 0.231427, acc 0.921875\n",
      "2018-05-04T17:02:58.391781: step 10626, loss 0.531258, acc 0.8125\n",
      "2018-05-04T17:02:59.403238: step 10627, loss 0.450194, acc 0.8125\n",
      "2018-05-04T17:03:00.393194: step 10628, loss 0.263463, acc 0.921875\n",
      "2018-05-04T17:03:01.444959: step 10629, loss 0.228166, acc 0.875\n",
      "2018-05-04T17:03:02.450055: step 10630, loss 0.213008, acc 0.90625\n",
      "2018-05-04T17:03:03.462902: step 10631, loss 0.225685, acc 0.953125\n",
      "2018-05-04T17:03:04.483013: step 10632, loss 0.347095, acc 0.828125\n",
      "2018-05-04T17:03:05.501041: step 10633, loss 0.257516, acc 0.953125\n",
      "2018-05-04T17:03:06.519105: step 10634, loss 0.294024, acc 0.875\n",
      "2018-05-04T17:03:07.523524: step 10635, loss 0.188907, acc 0.9375\n",
      "2018-05-04T17:03:08.559124: step 10636, loss 0.208243, acc 0.921875\n",
      "2018-05-04T17:03:09.592311: step 10637, loss 0.334006, acc 0.875\n",
      "2018-05-04T17:03:10.627138: step 10638, loss 0.218952, acc 0.921875\n",
      "2018-05-04T17:03:11.655741: step 10639, loss 0.285041, acc 0.875\n",
      "2018-05-04T17:03:12.702652: step 10640, loss 0.269769, acc 0.921875\n",
      "2018-05-04T17:03:13.746329: step 10641, loss 0.414298, acc 0.84375\n",
      "2018-05-04T17:03:14.798909: step 10642, loss 0.27056, acc 0.84375\n",
      "2018-05-04T17:03:15.827382: step 10643, loss 0.349486, acc 0.875\n",
      "2018-05-04T17:03:16.855125: step 10644, loss 0.164971, acc 0.953125\n",
      "2018-05-04T17:03:17.984855: step 10645, loss 0.26713, acc 0.90625\n",
      "2018-05-04T17:03:19.040167: step 10646, loss 0.308314, acc 0.875\n",
      "2018-05-04T17:03:20.047954: step 10647, loss 0.235451, acc 0.890625\n",
      "2018-05-04T17:03:21.138239: step 10648, loss 0.328866, acc 0.859375\n",
      "2018-05-04T17:03:22.126968: step 10649, loss 0.212721, acc 0.921875\n",
      "2018-05-04T17:03:23.124918: step 10650, loss 0.421029, acc 0.875\n",
      "2018-05-04T17:03:24.146584: step 10651, loss 0.259895, acc 0.890625\n",
      "2018-05-04T17:03:25.151882: step 10652, loss 0.329304, acc 0.796875\n",
      "2018-05-04T17:03:26.155640: step 10653, loss 0.210243, acc 0.953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T17:03:27.165843: step 10654, loss 0.261384, acc 0.875\n",
      "2018-05-04T17:03:28.175796: step 10655, loss 0.303832, acc 0.8125\n",
      "2018-05-04T17:03:29.203236: step 10656, loss 0.23496, acc 0.9375\n",
      "2018-05-04T17:03:30.213515: step 10657, loss 0.34758, acc 0.859375\n",
      "2018-05-04T17:03:31.206028: step 10658, loss 0.325882, acc 0.890625\n",
      "2018-05-04T17:03:32.213720: step 10659, loss 0.248752, acc 0.90625\n",
      "2018-05-04T17:03:33.245354: step 10660, loss 0.383649, acc 0.796875\n",
      "2018-05-04T17:03:34.297476: step 10661, loss 0.24835, acc 0.875\n",
      "2018-05-04T17:03:35.377994: step 10662, loss 0.359955, acc 0.828125\n",
      "2018-05-04T17:03:36.420725: step 10663, loss 0.229251, acc 0.890625\n",
      "2018-05-04T17:03:37.436896: step 10664, loss 0.231903, acc 0.953125\n",
      "2018-05-04T17:03:38.465303: step 10665, loss 0.218866, acc 0.953125\n",
      "2018-05-04T17:03:39.473568: step 10666, loss 0.288742, acc 0.859375\n",
      "2018-05-04T17:03:40.475210: step 10667, loss 0.223359, acc 0.890625\n",
      "2018-05-04T17:03:41.510698: step 10668, loss 0.345314, acc 0.828125\n",
      "2018-05-04T17:03:42.531988: step 10669, loss 0.272819, acc 0.921875\n",
      "2018-05-04T17:03:43.558493: step 10670, loss 0.271201, acc 0.875\n",
      "2018-05-04T17:03:44.580527: step 10671, loss 0.443908, acc 0.828125\n",
      "2018-05-04T17:03:45.636076: step 10672, loss 0.404456, acc 0.84375\n",
      "2018-05-04T17:03:46.639673: step 10673, loss 0.211788, acc 0.9375\n",
      "2018-05-04T17:03:47.640570: step 10674, loss 0.182963, acc 0.9375\n",
      "2018-05-04T17:03:48.628607: step 10675, loss 0.252477, acc 0.828125\n",
      "2018-05-04T17:03:49.711941: step 10676, loss 0.222121, acc 0.921875\n",
      "2018-05-04T17:03:50.722641: step 10677, loss 0.365688, acc 0.828125\n",
      "2018-05-04T17:03:51.743952: step 10678, loss 0.258862, acc 0.859375\n",
      "2018-05-04T17:03:52.743555: step 10679, loss 0.211557, acc 0.890625\n",
      "2018-05-04T17:03:53.797268: step 10680, loss 0.244823, acc 0.90625\n",
      "2018-05-04T17:03:54.889189: step 10681, loss 0.32752, acc 0.875\n",
      "2018-05-04T17:03:55.892053: step 10682, loss 0.225836, acc 0.90625\n",
      "2018-05-04T17:03:56.955727: step 10683, loss 0.301786, acc 0.921875\n",
      "2018-05-04T17:03:57.953812: step 10684, loss 0.249369, acc 0.921875\n",
      "2018-05-04T17:03:58.951756: step 10685, loss 0.200995, acc 0.90625\n",
      "2018-05-04T17:03:59.956296: step 10686, loss 0.336599, acc 0.84375\n",
      "2018-05-04T17:04:00.947991: step 10687, loss 0.278633, acc 0.875\n",
      "2018-05-04T17:04:02.027959: step 10688, loss 0.298677, acc 0.875\n",
      "2018-05-04T17:04:03.015330: step 10689, loss 0.339206, acc 0.84375\n",
      "2018-05-04T17:04:04.032715: step 10690, loss 0.269745, acc 0.9375\n",
      "2018-05-04T17:04:05.039187: step 10691, loss 0.225726, acc 0.90625\n",
      "2018-05-04T17:04:06.104183: step 10692, loss 0.264069, acc 0.9375\n",
      "2018-05-04T17:04:07.176311: step 10693, loss 0.285687, acc 0.875\n",
      "2018-05-04T17:04:08.161058: step 10694, loss 0.192245, acc 0.90625\n",
      "2018-05-04T17:04:09.119087: step 10695, loss 0.174702, acc 0.953125\n",
      "2018-05-04T17:04:10.084790: step 10696, loss 0.274207, acc 0.921875\n",
      "2018-05-04T17:04:11.076607: step 10697, loss 0.217908, acc 0.890625\n",
      "2018-05-04T17:04:12.072106: step 10698, loss 0.332805, acc 0.890625\n",
      "2018-05-04T17:04:13.072895: step 10699, loss 0.239846, acc 0.875\n",
      "2018-05-04T17:04:14.051159: step 10700, loss 0.264237, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T17:04:16.422432: step 10700, loss 0.228248, acc 0.916\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-10700\n",
      "\n",
      "2018-05-04T17:04:17.585687: step 10701, loss 0.439985, acc 0.84375\n",
      "2018-05-04T17:04:18.656456: step 10702, loss 0.208577, acc 0.90625\n",
      "2018-05-04T17:04:19.726916: step 10703, loss 0.433966, acc 0.78125\n",
      "2018-05-04T17:04:20.900323: step 10704, loss 0.22657, acc 0.890625\n",
      "2018-05-04T17:04:22.048560: step 10705, loss 0.247732, acc 0.890625\n",
      "2018-05-04T17:04:23.096838: step 10706, loss 0.138189, acc 0.984375\n",
      "2018-05-04T17:04:24.116639: step 10707, loss 0.153747, acc 0.9375\n",
      "2018-05-04T17:04:25.096693: step 10708, loss 0.286541, acc 0.875\n",
      "2018-05-04T17:04:26.100274: step 10709, loss 0.2479, acc 0.90625\n",
      "2018-05-04T17:04:27.111057: step 10710, loss 0.242316, acc 0.890625\n",
      "2018-05-04T17:04:28.173170: step 10711, loss 0.424644, acc 0.84375\n",
      "2018-05-04T17:04:29.236837: step 10712, loss 0.26298, acc 0.9375\n",
      "2018-05-04T17:04:30.280556: step 10713, loss 0.253022, acc 0.875\n",
      "2018-05-04T17:04:31.314225: step 10714, loss 0.326647, acc 0.875\n",
      "2018-05-04T17:04:32.348139: step 10715, loss 0.216489, acc 0.90625\n",
      "2018-05-04T17:04:33.421286: step 10716, loss 0.291938, acc 0.90625\n",
      "2018-05-04T17:04:34.488456: step 10717, loss 0.29432, acc 0.875\n",
      "2018-05-04T17:04:35.553487: step 10718, loss 0.165593, acc 0.9375\n",
      "2018-05-04T17:04:36.605193: step 10719, loss 0.515499, acc 0.765625\n",
      "2018-05-04T17:04:37.644530: step 10720, loss 0.268372, acc 0.890625\n",
      "2018-05-04T17:04:38.674002: step 10721, loss 0.38218, acc 0.875\n",
      "2018-05-04T17:04:39.708339: step 10722, loss 0.311971, acc 0.875\n",
      "2018-05-04T17:04:40.745220: step 10723, loss 0.334083, acc 0.859375\n",
      "2018-05-04T17:04:41.786677: step 10724, loss 0.226331, acc 0.9375\n",
      "2018-05-04T17:04:42.814016: step 10725, loss 0.382121, acc 0.859375\n",
      "2018-05-04T17:04:43.845153: step 10726, loss 0.240532, acc 0.921875\n",
      "2018-05-04T17:04:44.860553: step 10727, loss 0.200119, acc 0.921875\n",
      "2018-05-04T17:04:45.881617: step 10728, loss 0.270942, acc 0.890625\n",
      "2018-05-04T17:04:46.901255: step 10729, loss 0.240234, acc 0.90625\n",
      "2018-05-04T17:04:48.021556: step 10730, loss 0.275439, acc 0.9375\n",
      "2018-05-04T17:04:49.139744: step 10731, loss 0.315074, acc 0.859375\n",
      "2018-05-04T17:04:50.245234: step 10732, loss 0.274788, acc 0.90625\n",
      "2018-05-04T17:04:51.249453: step 10733, loss 0.301734, acc 0.921875\n",
      "2018-05-04T17:04:52.246707: step 10734, loss 0.314949, acc 0.84375\n",
      "2018-05-04T17:04:53.232790: step 10735, loss 0.346407, acc 0.84375\n",
      "2018-05-04T17:04:54.345008: step 10736, loss 0.324904, acc 0.859375\n",
      "2018-05-04T17:04:55.387490: step 10737, loss 0.341319, acc 0.921875\n",
      "2018-05-04T17:04:56.445874: step 10738, loss 0.276264, acc 0.875\n",
      "2018-05-04T17:04:57.470743: step 10739, loss 0.164143, acc 0.96875\n",
      "2018-05-04T17:04:58.479676: step 10740, loss 0.305348, acc 0.875\n",
      "2018-05-04T17:04:59.497995: step 10741, loss 0.219298, acc 0.921875\n",
      "2018-05-04T17:05:00.511719: step 10742, loss 0.297684, acc 0.84375\n",
      "2018-05-04T17:05:01.590628: step 10743, loss 0.327704, acc 0.921875\n",
      "2018-05-04T17:05:02.642325: step 10744, loss 0.272606, acc 0.875\n",
      "2018-05-04T17:05:03.658388: step 10745, loss 0.288018, acc 0.890625\n",
      "2018-05-04T17:05:04.757314: step 10746, loss 0.423705, acc 0.828125\n",
      "2018-05-04T17:05:05.776794: step 10747, loss 0.280932, acc 0.84375\n",
      "2018-05-04T17:05:06.799684: step 10748, loss 0.250353, acc 0.890625\n",
      "2018-05-04T17:05:07.817163: step 10749, loss 0.343173, acc 0.828125\n",
      "2018-05-04T17:05:08.820026: step 10750, loss 0.335131, acc 0.890625\n",
      "2018-05-04T17:05:09.844787: step 10751, loss 0.235815, acc 0.859375\n",
      "2018-05-04T17:05:10.954833: step 10752, loss 0.329275, acc 0.875\n",
      "2018-05-04T17:05:12.051766: step 10753, loss 0.278585, acc 0.859375\n",
      "2018-05-04T17:05:13.035554: step 10754, loss 0.430422, acc 0.84375\n",
      "2018-05-04T17:05:14.021588: step 10755, loss 0.19986, acc 0.90625\n",
      "2018-05-04T17:05:15.014105: step 10756, loss 0.300799, acc 0.828125\n",
      "2018-05-04T17:05:16.030571: step 10757, loss 0.279577, acc 0.828125\n",
      "2018-05-04T17:05:17.040816: step 10758, loss 0.360233, acc 0.859375\n",
      "2018-05-04T17:05:18.083370: step 10759, loss 0.416612, acc 0.828125\n",
      "2018-05-04T17:05:19.098888: step 10760, loss 0.404645, acc 0.875\n",
      "2018-05-04T17:05:20.107510: step 10761, loss 0.247811, acc 0.890625\n",
      "2018-05-04T17:05:21.122965: step 10762, loss 0.284441, acc 0.890625\n",
      "2018-05-04T17:05:22.134681: step 10763, loss 0.263708, acc 0.90625\n",
      "2018-05-04T17:05:23.189123: step 10764, loss 0.294709, acc 0.890625\n",
      "2018-05-04T17:05:24.246972: step 10765, loss 0.23958, acc 0.9375\n",
      "2018-05-04T17:05:25.271065: step 10766, loss 0.221512, acc 0.90625\n",
      "2018-05-04T17:05:26.258152: step 10767, loss 0.300835, acc 0.890625\n",
      "2018-05-04T17:05:27.260745: step 10768, loss 0.29457, acc 0.875\n",
      "2018-05-04T17:05:28.262332: step 10769, loss 0.331214, acc 0.84375\n",
      "2018-05-04T17:05:29.301915: step 10770, loss 0.196225, acc 0.90625\n",
      "2018-05-04T17:05:30.307525: step 10771, loss 0.223289, acc 0.890625\n",
      "2018-05-04T17:05:31.341320: step 10772, loss 0.210502, acc 0.921875\n",
      "2018-05-04T17:05:32.373963: step 10773, loss 0.514794, acc 0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T17:05:33.419992: step 10774, loss 0.295039, acc 0.890625\n",
      "2018-05-04T17:05:34.440744: step 10775, loss 0.220261, acc 0.9375\n",
      "2018-05-04T17:05:35.470610: step 10776, loss 0.327597, acc 0.859375\n",
      "2018-05-04T17:05:36.553418: step 10777, loss 0.274395, acc 0.890625\n",
      "2018-05-04T17:05:37.555901: step 10778, loss 0.264324, acc 0.875\n",
      "2018-05-04T17:05:38.553863: step 10779, loss 0.243187, acc 0.890625\n",
      "2018-05-04T17:05:39.552862: step 10780, loss 0.432386, acc 0.8125\n",
      "2018-05-04T17:05:40.551992: step 10781, loss 0.273519, acc 0.890625\n",
      "2018-05-04T17:05:41.548865: step 10782, loss 0.264755, acc 0.921875\n",
      "2018-05-04T17:05:42.530337: step 10783, loss 0.436885, acc 0.734375\n",
      "2018-05-04T17:05:43.520153: step 10784, loss 0.278839, acc 0.859375\n",
      "2018-05-04T17:05:44.529563: step 10785, loss 0.253737, acc 0.90625\n",
      "2018-05-04T17:05:45.508564: step 10786, loss 0.268296, acc 0.90625\n",
      "2018-05-04T17:05:46.511689: step 10787, loss 0.248197, acc 0.921875\n",
      "2018-05-04T17:05:47.514752: step 10788, loss 0.258716, acc 0.9375\n",
      "2018-05-04T17:05:48.519179: step 10789, loss 0.305392, acc 0.859375\n",
      "2018-05-04T17:05:49.570759: step 10790, loss 0.191966, acc 0.921875\n",
      "2018-05-04T17:05:50.612771: step 10791, loss 0.34883, acc 0.859375\n",
      "2018-05-04T17:05:51.685146: step 10792, loss 0.263031, acc 0.921875\n",
      "2018-05-04T17:05:52.774309: step 10793, loss 0.155322, acc 0.96875\n",
      "2018-05-04T17:05:53.781929: step 10794, loss 0.281063, acc 0.890625\n",
      "2018-05-04T17:05:54.774730: step 10795, loss 0.239537, acc 0.9375\n",
      "2018-05-04T17:05:55.757004: step 10796, loss 0.221913, acc 0.875\n",
      "2018-05-04T17:05:56.735978: step 10797, loss 0.294854, acc 0.84375\n",
      "2018-05-04T17:05:57.723708: step 10798, loss 0.20527, acc 0.90625\n",
      "2018-05-04T17:05:58.737039: step 10799, loss 0.152047, acc 0.96875\n",
      "2018-05-04T17:05:59.802448: step 10800, loss 0.215953, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T17:06:01.997423: step 10800, loss 0.240702, acc 0.904\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-10800\n",
      "\n",
      "2018-05-04T17:06:03.091634: step 10801, loss 0.33704, acc 0.859375\n",
      "2018-05-04T17:06:04.108227: step 10802, loss 0.232509, acc 0.890625\n",
      "2018-05-04T17:06:05.102975: step 10803, loss 0.299126, acc 0.890625\n",
      "2018-05-04T17:06:06.188179: step 10804, loss 0.151841, acc 0.984375\n",
      "2018-05-04T17:06:07.183950: step 10805, loss 0.22375, acc 0.859375\n",
      "2018-05-04T17:06:08.195886: step 10806, loss 0.235136, acc 0.953125\n",
      "2018-05-04T17:06:09.187151: step 10807, loss 0.450177, acc 0.828125\n",
      "2018-05-04T17:06:10.185465: step 10808, loss 0.238377, acc 0.890625\n",
      "2018-05-04T17:06:11.186801: step 10809, loss 0.161633, acc 0.96875\n",
      "2018-05-04T17:06:12.200997: step 10810, loss 0.337359, acc 0.890625\n",
      "2018-05-04T17:06:13.279087: step 10811, loss 0.326302, acc 0.84375\n",
      "2018-05-04T17:06:14.294737: step 10812, loss 0.162903, acc 0.9375\n",
      "2018-05-04T17:06:15.300805: step 10813, loss 0.25679, acc 0.90625\n",
      "2018-05-04T17:06:16.300361: step 10814, loss 0.196718, acc 0.90625\n",
      "2018-05-04T17:06:17.288330: step 10815, loss 0.324555, acc 0.859375\n",
      "2018-05-04T17:06:18.291850: step 10816, loss 0.23926, acc 0.890625\n",
      "2018-05-04T17:06:19.289601: step 10817, loss 0.383673, acc 0.84375\n",
      "2018-05-04T17:06:20.348627: step 10818, loss 0.280548, acc 0.859375\n",
      "2018-05-04T17:06:21.370294: step 10819, loss 0.45285, acc 0.8125\n",
      "2018-05-04T17:06:22.381657: step 10820, loss 0.153612, acc 0.953125\n",
      "2018-05-04T17:06:23.366901: step 10821, loss 0.224508, acc 0.859375\n",
      "2018-05-04T17:06:24.429482: step 10822, loss 0.22389, acc 0.921875\n",
      "2018-05-04T17:06:25.402770: step 10823, loss 0.302194, acc 0.890625\n",
      "2018-05-04T17:06:26.446895: step 10824, loss 0.206327, acc 0.9375\n",
      "2018-05-04T17:06:27.428848: step 10825, loss 0.22599, acc 0.90625\n",
      "2018-05-04T17:06:28.423943: step 10826, loss 0.229744, acc 0.90625\n",
      "2018-05-04T17:06:29.408186: step 10827, loss 0.287259, acc 0.859375\n",
      "2018-05-04T17:06:30.395932: step 10828, loss 0.266098, acc 0.875\n",
      "2018-05-04T17:06:31.445403: step 10829, loss 0.438555, acc 0.84375\n",
      "2018-05-04T17:06:32.442189: step 10830, loss 0.251208, acc 0.84375\n",
      "2018-05-04T17:06:33.427219: step 10831, loss 0.167563, acc 0.90625\n",
      "2018-05-04T17:06:34.440464: step 10832, loss 0.292096, acc 0.875\n",
      "2018-05-04T17:06:35.426499: step 10833, loss 0.273579, acc 0.90625\n",
      "2018-05-04T17:06:36.429779: step 10834, loss 0.34102, acc 0.859375\n",
      "2018-05-04T17:06:37.490947: step 10835, loss 0.392958, acc 0.859375\n",
      "2018-05-04T17:06:38.479679: step 10836, loss 0.147446, acc 0.953125\n",
      "2018-05-04T17:06:39.493820: step 10837, loss 0.26433, acc 0.890625\n",
      "2018-05-04T17:06:40.477379: step 10838, loss 0.233478, acc 0.921875\n",
      "2018-05-04T17:06:41.467326: step 10839, loss 0.152754, acc 0.96875\n",
      "2018-05-04T17:06:42.469032: step 10840, loss 0.249385, acc 0.859375\n",
      "2018-05-04T17:06:43.556153: step 10841, loss 0.272879, acc 0.9375\n",
      "2018-05-04T17:06:44.549568: step 10842, loss 0.263259, acc 0.90625\n",
      "2018-05-04T17:06:45.546310: step 10843, loss 0.345842, acc 0.859375\n",
      "2018-05-04T17:06:46.538446: step 10844, loss 0.291746, acc 0.890625\n",
      "2018-05-04T17:06:47.510791: step 10845, loss 0.210562, acc 0.90625\n",
      "2018-05-04T17:06:48.484244: step 10846, loss 0.268365, acc 0.921875\n",
      "2018-05-04T17:06:49.544108: step 10847, loss 0.300582, acc 0.859375\n",
      "2018-05-04T17:06:50.606518: step 10848, loss 0.20152, acc 0.890625\n",
      "2018-05-04T17:06:51.622184: step 10849, loss 0.299084, acc 0.859375\n",
      "2018-05-04T17:06:52.626843: step 10850, loss 0.368343, acc 0.859375\n",
      "2018-05-04T17:06:53.611750: step 10851, loss 0.204642, acc 0.9375\n",
      "2018-05-04T17:06:54.605779: step 10852, loss 0.365691, acc 0.859375\n",
      "2018-05-04T17:06:55.601278: step 10853, loss 0.216445, acc 0.90625\n",
      "2018-05-04T17:06:56.593710: step 10854, loss 0.172978, acc 0.921875\n",
      "2018-05-04T17:06:57.583740: step 10855, loss 0.186151, acc 0.9375\n",
      "2018-05-04T17:06:58.635564: step 10856, loss 0.365209, acc 0.859375\n",
      "2018-05-04T17:06:59.712475: step 10857, loss 0.396801, acc 0.859375\n",
      "2018-05-04T17:07:00.764126: step 10858, loss 0.292645, acc 0.875\n",
      "2018-05-04T17:07:01.787789: step 10859, loss 0.422165, acc 0.8125\n",
      "2018-05-04T17:07:02.803088: step 10860, loss 0.244702, acc 0.890625\n",
      "2018-05-04T17:07:03.769504: step 10861, loss 0.246367, acc 0.921875\n",
      "2018-05-04T17:07:04.730204: step 10862, loss 0.312177, acc 0.875\n",
      "2018-05-04T17:07:05.708437: step 10863, loss 0.196054, acc 0.9375\n",
      "2018-05-04T17:07:06.783668: step 10864, loss 0.214834, acc 0.953125\n",
      "2018-05-04T17:07:07.774150: step 10865, loss 0.34683, acc 0.890625\n",
      "2018-05-04T17:07:08.823046: step 10866, loss 0.284388, acc 0.90625\n",
      "2018-05-04T17:07:09.856227: step 10867, loss 0.227338, acc 0.9375\n",
      "2018-05-04T17:07:10.886470: step 10868, loss 0.369868, acc 0.859375\n",
      "2018-05-04T17:07:11.840709: step 10869, loss 0.384483, acc 0.828125\n",
      "2018-05-04T17:07:12.799950: step 10870, loss 0.342041, acc 0.828125\n",
      "2018-05-04T17:07:13.837967: step 10871, loss 0.207031, acc 0.9375\n",
      "2018-05-04T17:07:14.895156: step 10872, loss 0.369675, acc 0.8125\n",
      "2018-05-04T17:07:15.933593: step 10873, loss 0.226035, acc 0.875\n",
      "2018-05-04T17:07:16.899158: step 10874, loss 0.386255, acc 0.828125\n",
      "2018-05-04T17:07:17.966404: step 10875, loss 0.217813, acc 0.921875\n",
      "2018-05-04T17:07:18.955451: step 10876, loss 0.321769, acc 0.84375\n",
      "2018-05-04T17:07:20.005092: step 10877, loss 0.298295, acc 0.875\n",
      "2018-05-04T17:07:21.021647: step 10878, loss 0.279065, acc 0.890625\n",
      "2018-05-04T17:07:22.046899: step 10879, loss 0.268085, acc 0.84375\n",
      "2018-05-04T17:07:23.024722: step 10880, loss 0.258099, acc 0.921875\n",
      "2018-05-04T17:07:24.099625: step 10881, loss 0.33637, acc 0.84375\n",
      "2018-05-04T17:07:25.120534: step 10882, loss 0.191704, acc 0.953125\n",
      "2018-05-04T17:07:26.188993: step 10883, loss 0.214086, acc 0.953125\n",
      "2018-05-04T17:07:27.161188: step 10884, loss 0.344152, acc 0.828125\n",
      "2018-05-04T17:07:28.157935: step 10885, loss 0.416883, acc 0.78125\n",
      "2018-05-04T17:07:29.224949: step 10886, loss 0.176994, acc 0.953125\n",
      "2018-05-04T17:07:30.210812: step 10887, loss 0.513009, acc 0.8125\n",
      "2018-05-04T17:07:31.297174: step 10888, loss 0.236593, acc 0.890625\n",
      "2018-05-04T17:07:32.332942: step 10889, loss 0.17438, acc 0.9375\n",
      "2018-05-04T17:07:33.437566: step 10890, loss 0.300905, acc 0.859375\n",
      "2018-05-04T17:07:34.510913: step 10891, loss 0.237641, acc 0.953125\n",
      "2018-05-04T17:07:35.610686: step 10892, loss 0.30759, acc 0.875\n",
      "2018-05-04T17:07:36.715016: step 10893, loss 0.238279, acc 0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T17:07:37.776225: step 10894, loss 0.249397, acc 0.921875\n",
      "2018-05-04T17:07:38.774165: step 10895, loss 0.232904, acc 0.890625\n",
      "2018-05-04T17:07:39.840010: step 10896, loss 0.28382, acc 0.84375\n",
      "2018-05-04T17:07:40.879211: step 10897, loss 0.312414, acc 0.84375\n",
      "2018-05-04T17:07:41.963823: step 10898, loss 0.276348, acc 0.90625\n",
      "2018-05-04T17:07:43.010785: step 10899, loss 0.29721, acc 0.875\n",
      "2018-05-04T17:07:43.957245: step 10900, loss 0.218715, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T17:07:46.507539: step 10900, loss 0.249358, acc 0.916\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-10900\n",
      "\n",
      "2018-05-04T17:07:47.649412: step 10901, loss 0.250441, acc 0.890625\n",
      "2018-05-04T17:07:48.711582: step 10902, loss 0.276616, acc 0.875\n",
      "2018-05-04T17:07:49.788894: step 10903, loss 0.365177, acc 0.859375\n",
      "2018-05-04T17:07:50.856716: step 10904, loss 0.34723, acc 0.859375\n",
      "2018-05-04T17:07:51.936571: step 10905, loss 0.240224, acc 0.875\n",
      "2018-05-04T17:07:52.972716: step 10906, loss 0.188186, acc 0.9375\n",
      "2018-05-04T17:07:53.990401: step 10907, loss 0.364621, acc 0.875\n",
      "2018-05-04T17:07:55.101027: step 10908, loss 0.222657, acc 0.921875\n",
      "2018-05-04T17:07:56.164135: step 10909, loss 0.247752, acc 0.90625\n",
      "2018-05-04T17:07:57.200697: step 10910, loss 0.233964, acc 0.875\n",
      "2018-05-04T17:07:58.229407: step 10911, loss 0.23458, acc 0.890625\n",
      "2018-05-04T17:07:59.351715: step 10912, loss 0.472145, acc 0.796875\n",
      "2018-05-04T17:08:00.360054: step 10913, loss 0.205935, acc 0.921875\n",
      "2018-05-04T17:08:01.380830: step 10914, loss 0.306099, acc 0.84375\n",
      "2018-05-04T17:08:02.391076: step 10915, loss 0.27616, acc 0.875\n",
      "2018-05-04T17:08:03.433744: step 10916, loss 0.262617, acc 0.921875\n",
      "2018-05-04T17:08:04.453135: step 10917, loss 0.214151, acc 0.90625\n",
      "2018-05-04T17:08:05.479056: step 10918, loss 0.276663, acc 0.90625\n",
      "2018-05-04T17:08:06.490661: step 10919, loss 0.241933, acc 0.921875\n",
      "2018-05-04T17:08:07.512182: step 10920, loss 0.231424, acc 0.90625\n",
      "2018-05-04T17:08:08.560370: step 10921, loss 0.269949, acc 0.90625\n",
      "2018-05-04T17:08:09.623438: step 10922, loss 0.246709, acc 0.921875\n",
      "2018-05-04T17:08:10.650036: step 10923, loss 0.366226, acc 0.828125\n",
      "2018-05-04T17:08:11.678145: step 10924, loss 0.391729, acc 0.84375\n",
      "2018-05-04T17:08:12.750901: step 10925, loss 0.482122, acc 0.765625\n",
      "2018-05-04T17:08:13.776425: step 10926, loss 0.480621, acc 0.828125\n",
      "2018-05-04T17:08:14.787393: step 10927, loss 0.444932, acc 0.84375\n",
      "2018-05-04T17:08:15.802800: step 10928, loss 0.276123, acc 0.859375\n",
      "2018-05-04T17:08:16.813750: step 10929, loss 0.252938, acc 0.890625\n",
      "2018-05-04T17:08:17.815287: step 10930, loss 0.274929, acc 0.90625\n",
      "2018-05-04T17:08:18.899814: step 10931, loss 0.317232, acc 0.859375\n",
      "2018-05-04T17:08:19.899677: step 10932, loss 0.265801, acc 0.859375\n",
      "2018-05-04T17:08:20.949127: step 10933, loss 0.231304, acc 0.90625\n",
      "2018-05-04T17:08:21.991298: step 10934, loss 0.309026, acc 0.90625\n",
      "2018-05-04T17:08:22.999529: step 10935, loss 0.310376, acc 0.84375\n",
      "2018-05-04T17:08:24.014582: step 10936, loss 0.233131, acc 0.9375\n",
      "2018-05-04T17:08:25.019196: step 10937, loss 0.309275, acc 0.875\n",
      "2018-05-04T17:08:26.033734: step 10938, loss 0.343655, acc 0.828125\n",
      "2018-05-04T17:08:27.087414: step 10939, loss 0.207272, acc 0.890625\n",
      "2018-05-04T17:08:28.108521: step 10940, loss 0.35428, acc 0.84375\n",
      "2018-05-04T17:08:29.132308: step 10941, loss 0.224694, acc 0.90625\n",
      "2018-05-04T17:08:30.134979: step 10942, loss 0.364372, acc 0.8125\n",
      "2018-05-04T17:08:31.150846: step 10943, loss 0.260826, acc 0.875\n",
      "2018-05-04T17:08:32.216122: step 10944, loss 0.379598, acc 0.8125\n",
      "2018-05-04T17:08:33.257802: step 10945, loss 0.326186, acc 0.875\n",
      "2018-05-04T17:08:34.314523: step 10946, loss 0.241215, acc 0.890625\n",
      "2018-05-04T17:08:35.332448: step 10947, loss 0.300769, acc 0.859375\n",
      "2018-05-04T17:08:36.431693: step 10948, loss 0.253563, acc 0.921875\n",
      "2018-05-04T17:08:37.465787: step 10949, loss 0.274173, acc 0.875\n",
      "2018-05-04T17:08:38.490719: step 10950, loss 0.400809, acc 0.859375\n",
      "2018-05-04T17:08:39.504682: step 10951, loss 0.225313, acc 0.90625\n",
      "2018-05-04T17:08:40.514464: step 10952, loss 0.139506, acc 0.984375\n",
      "2018-05-04T17:08:41.592065: step 10953, loss 0.273117, acc 0.875\n",
      "2018-05-04T17:08:42.599386: step 10954, loss 0.328307, acc 0.8125\n",
      "2018-05-04T17:08:43.634595: step 10955, loss 0.196901, acc 0.953125\n",
      "2018-05-04T17:08:44.654524: step 10956, loss 0.284089, acc 0.890625\n",
      "2018-05-04T17:08:45.677272: step 10957, loss 0.307858, acc 0.875\n",
      "2018-05-04T17:08:46.697818: step 10958, loss 0.210625, acc 0.921875\n",
      "2018-05-04T17:08:47.704126: step 10959, loss 0.292596, acc 0.875\n",
      "2018-05-04T17:08:48.722342: step 10960, loss 0.229965, acc 0.890625\n",
      "2018-05-04T17:08:49.739939: step 10961, loss 0.219157, acc 0.90625\n",
      "2018-05-04T17:08:50.781838: step 10962, loss 0.32315, acc 0.84375\n",
      "2018-05-04T17:08:51.852100: step 10963, loss 0.267789, acc 0.875\n",
      "2018-05-04T17:08:52.897962: step 10964, loss 0.16931, acc 0.953125\n",
      "2018-05-04T17:08:53.931937: step 10965, loss 0.313099, acc 0.875\n",
      "2018-05-04T17:08:54.940219: step 10966, loss 0.194681, acc 0.9375\n",
      "2018-05-04T17:08:55.974356: step 10967, loss 0.399049, acc 0.796875\n",
      "2018-05-04T17:08:57.006085: step 10968, loss 0.218061, acc 0.921875\n",
      "2018-05-04T17:08:58.022808: step 10969, loss 0.14185, acc 0.90625\n",
      "2018-05-04T17:08:59.014531: step 10970, loss 0.263966, acc 0.875\n",
      "2018-05-04T17:09:00.066589: step 10971, loss 0.226745, acc 0.9375\n",
      "2018-05-04T17:09:01.088036: step 10972, loss 0.181565, acc 0.96875\n",
      "2018-05-04T17:09:02.115964: step 10973, loss 0.384231, acc 0.859375\n",
      "2018-05-04T17:09:03.150243: step 10974, loss 0.273774, acc 0.90625\n",
      "2018-05-04T17:09:04.189264: step 10975, loss 0.286613, acc 0.890625\n",
      "2018-05-04T17:09:05.222736: step 10976, loss 0.252883, acc 0.90625\n",
      "2018-05-04T17:09:06.250303: step 10977, loss 0.215148, acc 0.953125\n",
      "2018-05-04T17:09:07.280422: step 10978, loss 0.0955355, acc 0.96875\n",
      "2018-05-04T17:09:08.324917: step 10979, loss 0.439721, acc 0.859375\n",
      "2018-05-04T17:09:09.366770: step 10980, loss 0.311515, acc 0.84375\n",
      "2018-05-04T17:09:10.402237: step 10981, loss 0.16281, acc 0.953125\n",
      "2018-05-04T17:09:11.409878: step 10982, loss 0.270139, acc 0.9375\n",
      "2018-05-04T17:09:12.413079: step 10983, loss 0.212276, acc 0.921875\n",
      "2018-05-04T17:09:13.421035: step 10984, loss 0.3633, acc 0.90625\n",
      "2018-05-04T17:09:14.440195: step 10985, loss 0.340333, acc 0.875\n",
      "2018-05-04T17:09:15.466287: step 10986, loss 0.145576, acc 0.96875\n",
      "2018-05-04T17:09:16.496804: step 10987, loss 0.262724, acc 0.90625\n",
      "2018-05-04T17:09:17.540942: step 10988, loss 0.276985, acc 0.921875\n",
      "2018-05-04T17:09:18.577873: step 10989, loss 0.278975, acc 0.890625\n",
      "2018-05-04T17:09:19.627151: step 10990, loss 0.259248, acc 0.90625\n",
      "2018-05-04T17:09:20.681181: step 10991, loss 0.304406, acc 0.859375\n",
      "2018-05-04T17:09:21.723586: step 10992, loss 0.296966, acc 0.859375\n",
      "2018-05-04T17:09:22.756776: step 10993, loss 0.336358, acc 0.84375\n",
      "2018-05-04T17:09:23.792295: step 10994, loss 0.251271, acc 0.875\n",
      "2018-05-04T17:09:24.882712: step 10995, loss 0.301018, acc 0.875\n",
      "2018-05-04T17:09:25.874036: step 10996, loss 0.300416, acc 0.84375\n",
      "2018-05-04T17:09:26.889207: step 10997, loss 0.212199, acc 0.890625\n",
      "2018-05-04T17:09:27.895433: step 10998, loss 0.259209, acc 0.921875\n",
      "2018-05-04T17:09:28.892652: step 10999, loss 0.380339, acc 0.8125\n",
      "2018-05-04T17:09:30.002239: step 11000, loss 0.343104, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T17:09:32.509892: step 11000, loss 0.234404, acc 0.914\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-11000\n",
      "\n",
      "2018-05-04T17:09:33.671011: step 11001, loss 0.350889, acc 0.84375\n",
      "2018-05-04T17:09:34.757718: step 11002, loss 0.226349, acc 0.890625\n",
      "2018-05-04T17:09:35.844801: step 11003, loss 0.368423, acc 0.859375\n",
      "2018-05-04T17:09:36.899629: step 11004, loss 0.269837, acc 0.890625\n",
      "2018-05-04T17:09:38.011921: step 11005, loss 0.258197, acc 0.890625\n",
      "2018-05-04T17:09:39.065417: step 11006, loss 0.315963, acc 0.84375\n",
      "2018-05-04T17:09:40.100324: step 11007, loss 0.371538, acc 0.828125\n",
      "2018-05-04T17:09:41.130809: step 11008, loss 0.406261, acc 0.78125\n",
      "2018-05-04T17:09:42.228760: step 11009, loss 0.375994, acc 0.875\n",
      "2018-05-04T17:09:43.268354: step 11010, loss 0.344746, acc 0.828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T17:09:44.323530: step 11011, loss 0.33255, acc 0.859375\n",
      "2018-05-04T17:09:45.367031: step 11012, loss 0.30557, acc 0.9375\n",
      "2018-05-04T17:09:46.393658: step 11013, loss 0.289309, acc 0.890625\n",
      "2018-05-04T17:09:47.451064: step 11014, loss 0.238847, acc 0.90625\n",
      "2018-05-04T17:09:48.463784: step 11015, loss 0.267503, acc 0.890625\n",
      "2018-05-04T17:09:49.480251: step 11016, loss 0.394818, acc 0.890625\n",
      "2018-05-04T17:09:50.537263: step 11017, loss 0.28223, acc 0.875\n",
      "2018-05-04T17:09:51.587428: step 11018, loss 0.193183, acc 0.9375\n",
      "2018-05-04T17:09:52.605801: step 11019, loss 0.344573, acc 0.875\n",
      "2018-05-04T17:09:53.728209: step 11020, loss 0.318656, acc 0.84375\n",
      "2018-05-04T17:09:54.741409: step 11021, loss 0.228748, acc 0.90625\n",
      "2018-05-04T17:09:55.784972: step 11022, loss 0.297712, acc 0.859375\n",
      "2018-05-04T17:09:56.801036: step 11023, loss 0.292226, acc 0.90625\n",
      "2018-05-04T17:09:57.876531: step 11024, loss 0.299136, acc 0.875\n",
      "2018-05-04T17:09:58.979341: step 11025, loss 0.488275, acc 0.8125\n",
      "2018-05-04T17:09:59.998824: step 11026, loss 0.354339, acc 0.84375\n",
      "2018-05-04T17:10:01.077239: step 11027, loss 0.280915, acc 0.84375\n",
      "2018-05-04T17:10:02.091990: step 11028, loss 0.225965, acc 0.875\n",
      "2018-05-04T17:10:03.160466: step 11029, loss 0.307969, acc 0.859375\n",
      "2018-05-04T17:10:04.217394: step 11030, loss 0.386837, acc 0.875\n",
      "2018-05-04T17:10:05.243013: step 11031, loss 0.23772, acc 0.890625\n",
      "2018-05-04T17:10:06.277179: step 11032, loss 0.276673, acc 0.875\n",
      "2018-05-04T17:10:07.298660: step 11033, loss 0.340469, acc 0.796875\n",
      "2018-05-04T17:10:08.348201: step 11034, loss 0.174303, acc 0.9375\n",
      "2018-05-04T17:10:09.381727: step 11035, loss 0.298044, acc 0.890625\n",
      "2018-05-04T17:10:10.387131: step 11036, loss 0.215815, acc 0.9375\n",
      "2018-05-04T17:10:11.430833: step 11037, loss 0.292768, acc 0.890625\n",
      "2018-05-04T17:10:12.443783: step 11038, loss 0.178579, acc 0.9375\n",
      "2018-05-04T17:10:13.462958: step 11039, loss 0.278295, acc 0.84375\n",
      "2018-05-04T17:10:14.473845: step 11040, loss 0.453203, acc 0.828125\n",
      "2018-05-04T17:10:15.554936: step 11041, loss 0.219013, acc 0.890625\n",
      "2018-05-04T17:10:16.583925: step 11042, loss 0.18179, acc 0.921875\n",
      "2018-05-04T17:10:17.605867: step 11043, loss 0.329237, acc 0.828125\n",
      "2018-05-04T17:10:18.615378: step 11044, loss 0.270431, acc 0.875\n",
      "2018-05-04T17:10:19.637042: step 11045, loss 0.442042, acc 0.84375\n",
      "2018-05-04T17:10:20.716169: step 11046, loss 0.249383, acc 0.890625\n",
      "2018-05-04T17:10:21.720205: step 11047, loss 0.24929, acc 0.90625\n",
      "2018-05-04T17:10:22.735226: step 11048, loss 0.427295, acc 0.890625\n",
      "2018-05-04T17:10:23.803779: step 11049, loss 0.307129, acc 0.90625\n",
      "2018-05-04T17:10:24.903160: step 11050, loss 0.357953, acc 0.875\n",
      "2018-05-04T17:10:25.982861: step 11051, loss 0.311943, acc 0.890625\n",
      "2018-05-04T17:10:27.001236: step 11052, loss 0.274037, acc 0.890625\n",
      "2018-05-04T17:10:28.018942: step 11053, loss 0.292008, acc 0.859375\n",
      "2018-05-04T17:10:29.018438: step 11054, loss 0.251995, acc 0.875\n",
      "2018-05-04T17:10:30.032230: step 11055, loss 0.18948, acc 0.921875\n",
      "2018-05-04T17:10:31.050556: step 11056, loss 0.212224, acc 0.90625\n",
      "2018-05-04T17:10:32.062202: step 11057, loss 0.392966, acc 0.84375\n",
      "2018-05-04T17:10:33.114567: step 11058, loss 0.297844, acc 0.890625\n",
      "2018-05-04T17:10:34.245324: step 11059, loss 0.245842, acc 0.875\n",
      "2018-05-04T17:10:35.319915: step 11060, loss 0.328063, acc 0.796875\n",
      "2018-05-04T17:10:36.417421: step 11061, loss 0.263455, acc 0.890625\n",
      "2018-05-04T17:10:37.570108: step 11062, loss 0.326544, acc 0.875\n",
      "2018-05-04T17:10:38.580420: step 11063, loss 0.394228, acc 0.890625\n",
      "2018-05-04T17:10:39.585225: step 11064, loss 0.265363, acc 0.890625\n",
      "2018-05-04T17:10:40.620009: step 11065, loss 0.439765, acc 0.796875\n",
      "2018-05-04T17:10:41.643473: step 11066, loss 0.21757, acc 0.90625\n",
      "2018-05-04T17:10:42.672945: step 11067, loss 0.22696, acc 0.890625\n",
      "2018-05-04T17:10:43.680248: step 11068, loss 0.260238, acc 0.875\n",
      "2018-05-04T17:10:44.765554: step 11069, loss 0.295199, acc 0.90625\n",
      "2018-05-04T17:10:45.880122: step 11070, loss 0.365631, acc 0.84375\n",
      "2018-05-04T17:10:46.874453: step 11071, loss 0.292624, acc 0.875\n",
      "2018-05-04T17:10:47.869915: step 11072, loss 0.253392, acc 0.890625\n",
      "2018-05-04T17:10:48.882141: step 11073, loss 0.346777, acc 0.859375\n",
      "2018-05-04T17:10:49.874410: step 11074, loss 0.3666, acc 0.84375\n",
      "2018-05-04T17:10:50.869154: step 11075, loss 0.425124, acc 0.78125\n",
      "2018-05-04T17:10:51.889545: step 11076, loss 0.188309, acc 0.921875\n",
      "2018-05-04T17:10:52.876728: step 11077, loss 0.321426, acc 0.84375\n",
      "2018-05-04T17:10:53.886123: step 11078, loss 0.286546, acc 0.890625\n",
      "2018-05-04T17:10:54.885714: step 11079, loss 0.42654, acc 0.890625\n",
      "2018-05-04T17:10:55.886410: step 11080, loss 0.234669, acc 0.875\n",
      "2018-05-04T17:10:56.887976: step 11081, loss 0.194316, acc 0.890625\n",
      "2018-05-04T17:10:57.888154: step 11082, loss 0.332802, acc 0.859375\n",
      "2018-05-04T17:10:58.892914: step 11083, loss 0.126117, acc 0.984375\n",
      "2018-05-04T17:10:59.923883: step 11084, loss 0.229369, acc 0.90625\n",
      "2018-05-04T17:11:00.928878: step 11085, loss 0.428956, acc 0.84375\n",
      "2018-05-04T17:11:01.997659: step 11086, loss 0.334145, acc 0.90625\n",
      "2018-05-04T17:11:02.988528: step 11087, loss 0.252557, acc 0.890625\n",
      "2018-05-04T17:11:03.982962: step 11088, loss 0.422175, acc 0.859375\n",
      "2018-05-04T17:11:05.009513: step 11089, loss 0.289727, acc 0.90625\n",
      "2018-05-04T17:11:05.998919: step 11090, loss 0.33889, acc 0.84375\n",
      "2018-05-04T17:11:06.982117: step 11091, loss 0.258153, acc 0.890625\n",
      "2018-05-04T17:11:08.055933: step 11092, loss 0.25249, acc 0.875\n",
      "2018-05-04T17:11:09.083755: step 11093, loss 0.320242, acc 0.875\n",
      "2018-05-04T17:11:10.105626: step 11094, loss 0.28752, acc 0.90625\n",
      "2018-05-04T17:11:11.106208: step 11095, loss 0.23551, acc 0.921875\n",
      "2018-05-04T17:11:12.133469: step 11096, loss 0.202546, acc 0.921875\n",
      "2018-05-04T17:11:13.138264: step 11097, loss 0.221277, acc 0.890625\n",
      "2018-05-04T17:11:14.164795: step 11098, loss 0.147963, acc 0.96875\n",
      "2018-05-04T17:11:15.180851: step 11099, loss 0.330793, acc 0.84375\n",
      "2018-05-04T17:11:16.188517: step 11100, loss 0.314712, acc 0.8125\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T17:11:18.421389: step 11100, loss 0.238408, acc 0.914\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-11100\n",
      "\n",
      "2018-05-04T17:11:19.528489: step 11101, loss 0.274672, acc 0.890625\n",
      "2018-05-04T17:11:20.522880: step 11102, loss 0.485685, acc 0.8125\n",
      "2018-05-04T17:11:21.603958: step 11103, loss 0.303987, acc 0.890625\n",
      "2018-05-04T17:11:22.578346: step 11104, loss 0.349867, acc 0.921875\n",
      "2018-05-04T17:11:23.582485: step 11105, loss 0.27932, acc 0.875\n",
      "2018-05-04T17:11:24.576715: step 11106, loss 0.298371, acc 0.890625\n",
      "2018-05-04T17:11:25.569240: step 11107, loss 0.221302, acc 0.890625\n",
      "2018-05-04T17:11:26.561891: step 11108, loss 0.198427, acc 0.9375\n",
      "2018-05-04T17:11:27.577439: step 11109, loss 0.240541, acc 0.859375\n",
      "2018-05-04T17:11:28.550017: step 11110, loss 0.305687, acc 0.859375\n",
      "2018-05-04T17:11:29.542857: step 11111, loss 0.24033, acc 0.875\n",
      "2018-05-04T17:11:30.713244: step 11112, loss 0.240975, acc 0.921875\n",
      "2018-05-04T17:11:31.719155: step 11113, loss 0.281337, acc 0.875\n",
      "2018-05-04T17:11:32.746467: step 11114, loss 0.412088, acc 0.859375\n",
      "2018-05-04T17:11:33.742559: step 11115, loss 0.261586, acc 0.859375\n",
      "2018-05-04T17:11:34.814171: step 11116, loss 0.287481, acc 0.890625\n",
      "2018-05-04T17:11:35.826444: step 11117, loss 0.357968, acc 0.84375\n",
      "2018-05-04T17:11:36.815331: step 11118, loss 0.259771, acc 0.90625\n",
      "2018-05-04T17:11:37.797120: step 11119, loss 0.199332, acc 0.921875\n",
      "2018-05-04T17:11:38.792963: step 11120, loss 0.307239, acc 0.890625\n",
      "2018-05-04T17:11:39.788139: step 11121, loss 0.254009, acc 0.890625\n",
      "2018-05-04T17:11:40.810523: step 11122, loss 0.278922, acc 0.890625\n",
      "2018-05-04T17:11:41.831660: step 11123, loss 0.24103, acc 0.90625\n",
      "2018-05-04T17:11:42.814291: step 11124, loss 0.264128, acc 0.890625\n",
      "2018-05-04T17:11:43.804015: step 11125, loss 0.328204, acc 0.84375\n",
      "2018-05-04T17:11:44.811818: step 11126, loss 0.254826, acc 0.90625\n",
      "2018-05-04T17:11:45.820020: step 11127, loss 0.248644, acc 0.90625\n",
      "2018-05-04T17:11:46.802575: step 11128, loss 0.227447, acc 0.890625\n",
      "2018-05-04T17:11:47.803983: step 11129, loss 0.30834, acc 0.828125\n",
      "2018-05-04T17:11:48.811098: step 11130, loss 0.2457, acc 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T17:11:49.840926: step 11131, loss 0.368742, acc 0.890625\n",
      "2018-05-04T17:11:50.918540: step 11132, loss 0.290707, acc 0.859375\n",
      "2018-05-04T17:11:51.992831: step 11133, loss 0.320536, acc 0.90625\n",
      "2018-05-04T17:11:53.006976: step 11134, loss 0.324036, acc 0.859375\n",
      "2018-05-04T17:11:53.995426: step 11135, loss 0.244651, acc 0.890625\n",
      "2018-05-04T17:11:55.053109: step 11136, loss 0.275889, acc 0.90625\n",
      "2018-05-04T17:11:56.033843: step 11137, loss 0.367684, acc 0.859375\n",
      "2018-05-04T17:11:57.029142: step 11138, loss 0.313298, acc 0.828125\n",
      "2018-05-04T17:11:58.019938: step 11139, loss 0.316228, acc 0.875\n",
      "2018-05-04T17:11:58.999107: step 11140, loss 0.319646, acc 0.875\n",
      "2018-05-04T17:11:59.989114: step 11141, loss 0.252253, acc 0.875\n",
      "2018-05-04T17:12:00.989017: step 11142, loss 0.233526, acc 0.9375\n",
      "2018-05-04T17:12:01.990334: step 11143, loss 0.397775, acc 0.859375\n",
      "2018-05-04T17:12:03.010175: step 11144, loss 0.29754, acc 0.890625\n",
      "2018-05-04T17:12:04.046267: step 11145, loss 0.207047, acc 0.90625\n",
      "2018-05-04T17:12:05.067529: step 11146, loss 0.275264, acc 0.875\n",
      "2018-05-04T17:12:06.123093: step 11147, loss 0.274549, acc 0.921875\n",
      "2018-05-04T17:12:07.176490: step 11148, loss 0.186595, acc 0.921875\n",
      "2018-05-04T17:12:08.165540: step 11149, loss 0.351131, acc 0.796875\n",
      "2018-05-04T17:12:09.160409: step 11150, loss 0.204356, acc 0.96875\n",
      "2018-05-04T17:12:10.152537: step 11151, loss 0.140436, acc 0.953125\n",
      "2018-05-04T17:12:11.213148: step 11152, loss 0.238264, acc 0.90625\n",
      "2018-05-04T17:12:12.251524: step 11153, loss 0.29133, acc 0.859375\n",
      "2018-05-04T17:12:13.234638: step 11154, loss 0.133128, acc 0.953125\n",
      "2018-05-04T17:12:14.220257: step 11155, loss 0.323479, acc 0.84375\n",
      "2018-05-04T17:12:15.293229: step 11156, loss 0.152217, acc 0.953125\n",
      "2018-05-04T17:12:16.371746: step 11157, loss 0.289007, acc 0.828125\n",
      "2018-05-04T17:12:17.356554: step 11158, loss 0.322993, acc 0.8125\n",
      "2018-05-04T17:12:18.362981: step 11159, loss 0.152894, acc 0.953125\n",
      "2018-05-04T17:12:19.415536: step 11160, loss 0.38589, acc 0.84375\n",
      "2018-05-04T17:12:20.465892: step 11161, loss 0.34833, acc 0.859375\n",
      "2018-05-04T17:12:21.526752: step 11162, loss 0.31873, acc 0.90625\n",
      "2018-05-04T17:12:22.516898: step 11163, loss 0.177102, acc 0.9375\n",
      "2018-05-04T17:12:23.508391: step 11164, loss 0.255072, acc 0.875\n",
      "2018-05-04T17:12:24.498404: step 11165, loss 0.168789, acc 0.953125\n",
      "2018-05-04T17:12:25.497690: step 11166, loss 0.264014, acc 0.90625\n",
      "2018-05-04T17:12:26.478334: step 11167, loss 0.185896, acc 0.921875\n",
      "2018-05-04T17:12:27.470424: step 11168, loss 0.242084, acc 0.890625\n",
      "2018-05-04T17:12:28.496893: step 11169, loss 0.285574, acc 0.84375\n",
      "2018-05-04T17:12:29.505729: step 11170, loss 0.291431, acc 0.890625\n",
      "2018-05-04T17:12:30.509329: step 11171, loss 0.273182, acc 0.890625\n",
      "2018-05-04T17:12:31.596737: step 11172, loss 0.296654, acc 0.90625\n",
      "2018-05-04T17:12:32.635947: step 11173, loss 0.17103, acc 0.921875\n",
      "2018-05-04T17:12:33.735025: step 11174, loss 0.294332, acc 0.875\n",
      "2018-05-04T17:12:34.763696: step 11175, loss 0.259311, acc 0.890625\n",
      "2018-05-04T17:12:35.835686: step 11176, loss 0.268503, acc 0.890625\n",
      "2018-05-04T17:12:36.895482: step 11177, loss 0.275068, acc 0.875\n",
      "2018-05-04T17:12:37.941282: step 11178, loss 0.295512, acc 0.890625\n",
      "2018-05-04T17:12:38.999789: step 11179, loss 0.312345, acc 0.859375\n",
      "2018-05-04T17:12:39.993099: step 11180, loss 0.302869, acc 0.875\n",
      "2018-05-04T17:12:41.048765: step 11181, loss 0.32657, acc 0.859375\n",
      "2018-05-04T17:12:42.117982: step 11182, loss 0.322237, acc 0.875\n",
      "2018-05-04T17:12:43.109784: step 11183, loss 0.480058, acc 0.8125\n",
      "2018-05-04T17:12:44.151986: step 11184, loss 0.19142, acc 0.90625\n",
      "2018-05-04T17:12:45.162154: step 11185, loss 0.244038, acc 0.875\n",
      "2018-05-04T17:12:46.154547: step 11186, loss 0.427612, acc 0.796875\n",
      "2018-05-04T17:12:47.141040: step 11187, loss 0.21402, acc 0.90625\n",
      "2018-05-04T17:12:48.136538: step 11188, loss 0.273468, acc 0.890625\n",
      "2018-05-04T17:12:49.208924: step 11189, loss 0.18827, acc 0.9375\n",
      "2018-05-04T17:12:50.280611: step 11190, loss 0.367664, acc 0.8125\n",
      "2018-05-04T17:12:51.323583: step 11191, loss 0.207301, acc 0.9375\n",
      "2018-05-04T17:12:52.305264: step 11192, loss 0.29559, acc 0.859375\n",
      "2018-05-04T17:12:53.362579: step 11193, loss 0.345836, acc 0.859375\n",
      "2018-05-04T17:12:54.366728: step 11194, loss 0.395569, acc 0.828125\n",
      "2018-05-04T17:12:55.417516: step 11195, loss 0.22279, acc 0.921875\n",
      "2018-05-04T17:12:56.485746: step 11196, loss 0.475421, acc 0.8125\n",
      "2018-05-04T17:12:57.462266: step 11197, loss 0.262496, acc 0.90625\n",
      "2018-05-04T17:12:58.532353: step 11198, loss 0.244065, acc 0.90625\n",
      "2018-05-04T17:12:59.600198: step 11199, loss 0.329333, acc 0.875\n",
      "2018-05-04T17:13:00.608835: step 11200, loss 0.216468, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T17:13:03.517934: step 11200, loss 0.226794, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-11200\n",
      "\n",
      "2018-05-04T17:13:04.670710: step 11201, loss 0.241335, acc 0.90625\n",
      "2018-05-04T17:13:05.727721: step 11202, loss 0.218101, acc 0.921875\n",
      "2018-05-04T17:13:06.809845: step 11203, loss 0.321773, acc 0.875\n",
      "2018-05-04T17:13:07.933382: step 11204, loss 0.318672, acc 0.875\n",
      "2018-05-04T17:13:08.998814: step 11205, loss 0.321449, acc 0.875\n",
      "2018-05-04T17:13:10.071252: step 11206, loss 0.292557, acc 0.84375\n",
      "2018-05-04T17:13:11.099523: step 11207, loss 0.260617, acc 0.875\n",
      "2018-05-04T17:13:12.136988: step 11208, loss 0.266906, acc 0.875\n",
      "2018-05-04T17:13:13.179098: step 11209, loss 0.225668, acc 0.890625\n",
      "2018-05-04T17:13:14.204639: step 11210, loss 0.291293, acc 0.890625\n",
      "2018-05-04T17:13:15.216957: step 11211, loss 0.211356, acc 0.921875\n",
      "2018-05-04T17:13:16.272790: step 11212, loss 0.354866, acc 0.875\n",
      "2018-05-04T17:13:17.316236: step 11213, loss 0.334164, acc 0.859375\n",
      "2018-05-04T17:13:18.345978: step 11214, loss 0.211834, acc 0.96875\n",
      "2018-05-04T17:13:19.384876: step 11215, loss 0.305066, acc 0.875\n",
      "2018-05-04T17:13:20.407013: step 11216, loss 0.141438, acc 0.96875\n",
      "2018-05-04T17:13:21.495823: step 11217, loss 0.312357, acc 0.875\n",
      "2018-05-04T17:13:22.547178: step 11218, loss 0.195329, acc 0.9375\n",
      "2018-05-04T17:13:23.565429: step 11219, loss 0.178171, acc 0.921875\n",
      "2018-05-04T17:13:24.587240: step 11220, loss 0.248602, acc 0.890625\n",
      "2018-05-04T17:13:25.704416: step 11221, loss 0.183636, acc 0.96875\n",
      "2018-05-04T17:13:26.793416: step 11222, loss 0.248851, acc 0.9375\n",
      "2018-05-04T17:13:27.757561: step 11223, loss 0.19435, acc 0.9375\n",
      "2018-05-04T17:13:28.760584: step 11224, loss 0.217888, acc 0.890625\n",
      "2018-05-04T17:13:29.761821: step 11225, loss 0.272834, acc 0.890625\n",
      "2018-05-04T17:13:30.803834: step 11226, loss 0.353739, acc 0.859375\n",
      "2018-05-04T17:13:31.891325: step 11227, loss 0.226979, acc 0.890625\n",
      "2018-05-04T17:13:32.940474: step 11228, loss 0.295278, acc 0.9375\n",
      "2018-05-04T17:13:34.010176: step 11229, loss 0.173158, acc 0.96875\n",
      "2018-05-04T17:13:35.165147: step 11230, loss 0.330962, acc 0.890625\n",
      "2018-05-04T17:13:36.228060: step 11231, loss 0.308136, acc 0.9375\n",
      "2018-05-04T17:13:37.290361: step 11232, loss 0.227011, acc 0.875\n",
      "2018-05-04T17:13:38.333867: step 11233, loss 0.209183, acc 0.921875\n",
      "2018-05-04T17:13:39.372618: step 11234, loss 0.22296, acc 0.890625\n",
      "2018-05-04T17:13:40.384139: step 11235, loss 0.235679, acc 0.90625\n",
      "2018-05-04T17:13:41.459512: step 11236, loss 0.537361, acc 0.78125\n",
      "2018-05-04T17:13:42.451813: step 11237, loss 0.349015, acc 0.875\n",
      "2018-05-04T17:13:43.457296: step 11238, loss 0.208422, acc 0.9375\n",
      "2018-05-04T17:13:44.485751: step 11239, loss 0.213116, acc 0.890625\n",
      "2018-05-04T17:13:45.490527: step 11240, loss 0.247563, acc 0.921875\n",
      "2018-05-04T17:13:46.523563: step 11241, loss 0.225765, acc 0.890625\n",
      "2018-05-04T17:13:47.523434: step 11242, loss 0.279556, acc 0.859375\n",
      "2018-05-04T17:13:48.533310: step 11243, loss 0.212349, acc 0.921875\n",
      "2018-05-04T17:13:49.534720: step 11244, loss 0.254698, acc 0.875\n",
      "2018-05-04T17:13:50.545843: step 11245, loss 0.39528, acc 0.84375\n",
      "2018-05-04T17:13:51.573410: step 11246, loss 0.187962, acc 0.9375\n",
      "2018-05-04T17:13:52.593276: step 11247, loss 0.35026, acc 0.875\n",
      "2018-05-04T17:13:53.735075: step 11248, loss 0.215059, acc 0.90625\n",
      "2018-05-04T17:13:54.749643: step 11249, loss 0.216779, acc 0.921875\n",
      "2018-05-04T17:13:55.737945: step 11250, loss 0.196414, acc 0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T17:13:56.748574: step 11251, loss 0.215884, acc 0.890625\n",
      "2018-05-04T17:13:57.766712: step 11252, loss 0.238867, acc 0.90625\n",
      "2018-05-04T17:13:58.778875: step 11253, loss 0.220142, acc 0.921875\n",
      "2018-05-04T17:13:59.841205: step 11254, loss 0.217878, acc 0.890625\n",
      "2018-05-04T17:14:00.864588: step 11255, loss 0.207973, acc 0.9375\n",
      "2018-05-04T17:14:01.898081: step 11256, loss 0.289035, acc 0.90625\n",
      "2018-05-04T17:14:02.909046: step 11257, loss 0.363033, acc 0.859375\n",
      "2018-05-04T17:14:03.910004: step 11258, loss 0.23246, acc 0.890625\n",
      "2018-05-04T17:14:04.937267: step 11259, loss 0.436231, acc 0.859375\n",
      "2018-05-04T17:14:05.978298: step 11260, loss 0.310597, acc 0.875\n",
      "2018-05-04T17:14:06.991729: step 11261, loss 0.237115, acc 0.921875\n",
      "2018-05-04T17:14:07.995767: step 11262, loss 0.352016, acc 0.859375\n",
      "2018-05-04T17:14:09.071583: step 11263, loss 0.376685, acc 0.859375\n",
      "2018-05-04T17:14:10.095318: step 11264, loss 0.274033, acc 0.890625\n",
      "2018-05-04T17:14:11.115327: step 11265, loss 0.30153, acc 0.875\n",
      "2018-05-04T17:14:12.129117: step 11266, loss 0.269594, acc 0.859375\n",
      "2018-05-04T17:14:13.186413: step 11267, loss 0.188904, acc 0.953125\n",
      "2018-05-04T17:14:14.190750: step 11268, loss 0.191778, acc 0.953125\n",
      "2018-05-04T17:14:15.269131: step 11269, loss 0.251804, acc 0.875\n",
      "2018-05-04T17:14:16.269523: step 11270, loss 0.321714, acc 0.84375\n",
      "2018-05-04T17:14:17.283969: step 11271, loss 0.248955, acc 0.875\n",
      "2018-05-04T17:14:18.303135: step 11272, loss 0.139211, acc 0.9375\n",
      "2018-05-04T17:14:19.333483: step 11273, loss 0.201286, acc 0.921875\n",
      "2018-05-04T17:14:20.382155: step 11274, loss 0.254908, acc 0.859375\n",
      "2018-05-04T17:14:21.409408: step 11275, loss 0.281073, acc 0.90625\n",
      "2018-05-04T17:14:22.459528: step 11276, loss 0.38212, acc 0.90625\n",
      "2018-05-04T17:14:23.488773: step 11277, loss 0.260216, acc 0.90625\n",
      "2018-05-04T17:14:24.491014: step 11278, loss 0.202957, acc 0.921875\n",
      "2018-05-04T17:14:25.486138: step 11279, loss 0.211343, acc 0.9375\n",
      "2018-05-04T17:14:26.477640: step 11280, loss 0.224989, acc 0.890625\n",
      "2018-05-04T17:14:27.477430: step 11281, loss 0.268075, acc 0.890625\n",
      "2018-05-04T17:14:28.496606: step 11282, loss 0.143095, acc 0.984375\n",
      "2018-05-04T17:14:29.486389: step 11283, loss 0.25963, acc 0.921875\n",
      "2018-05-04T17:14:30.498987: step 11284, loss 0.197188, acc 0.875\n",
      "2018-05-04T17:14:31.503499: step 11285, loss 0.380392, acc 0.84375\n",
      "2018-05-04T17:14:32.512985: step 11286, loss 0.267822, acc 0.921875\n",
      "2018-05-04T17:14:33.542824: step 11287, loss 0.230201, acc 0.875\n",
      "2018-05-04T17:14:34.589395: step 11288, loss 0.273557, acc 0.890625\n",
      "2018-05-04T17:14:35.580303: step 11289, loss 0.243605, acc 0.875\n",
      "2018-05-04T17:14:36.605026: step 11290, loss 0.334892, acc 0.796875\n",
      "2018-05-04T17:14:37.612973: step 11291, loss 0.473731, acc 0.796875\n",
      "2018-05-04T17:14:38.625708: step 11292, loss 0.304818, acc 0.90625\n",
      "2018-05-04T17:14:39.618177: step 11293, loss 0.309665, acc 0.84375\n",
      "2018-05-04T17:14:40.611777: step 11294, loss 0.238191, acc 0.9375\n",
      "2018-05-04T17:14:41.614582: step 11295, loss 0.220642, acc 0.90625\n",
      "2018-05-04T17:14:42.651211: step 11296, loss 0.283731, acc 0.90625\n",
      "2018-05-04T17:14:43.681489: step 11297, loss 0.185214, acc 0.9375\n",
      "2018-05-04T17:14:44.694691: step 11298, loss 0.390634, acc 0.828125\n",
      "2018-05-04T17:14:45.725674: step 11299, loss 0.267288, acc 0.90625\n",
      "2018-05-04T17:14:46.812565: step 11300, loss 0.263283, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T17:14:48.998257: step 11300, loss 0.234773, acc 0.912\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-11300\n",
      "\n",
      "2018-05-04T17:14:50.078343: step 11301, loss 0.308266, acc 0.828125\n",
      "2018-05-04T17:14:51.055645: step 11302, loss 0.28441, acc 0.84375\n",
      "2018-05-04T17:14:52.057802: step 11303, loss 0.205666, acc 0.9375\n",
      "2018-05-04T17:14:53.052972: step 11304, loss 0.230986, acc 0.875\n",
      "2018-05-04T17:14:54.055054: step 11305, loss 0.282778, acc 0.859375\n",
      "2018-05-04T17:14:55.051979: step 11306, loss 0.183899, acc 0.921875\n",
      "2018-05-04T17:14:56.105002: step 11307, loss 0.207395, acc 0.921875\n",
      "2018-05-04T17:14:57.162875: step 11308, loss 0.206721, acc 0.9375\n",
      "2018-05-04T17:14:58.253980: step 11309, loss 0.315752, acc 0.859375\n",
      "2018-05-04T17:14:59.246237: step 11310, loss 0.272526, acc 0.90625\n",
      "2018-05-04T17:15:00.250461: step 11311, loss 0.234072, acc 0.921875\n",
      "2018-05-04T17:15:01.244989: step 11312, loss 0.292201, acc 0.90625\n",
      "2018-05-04T17:15:02.305873: step 11313, loss 0.395041, acc 0.875\n",
      "2018-05-04T17:15:03.399166: step 11314, loss 0.191443, acc 0.921875\n",
      "2018-05-04T17:15:04.447491: step 11315, loss 0.279986, acc 0.875\n",
      "2018-05-04T17:15:05.427421: step 11316, loss 0.293231, acc 0.890625\n",
      "2018-05-04T17:15:06.485237: step 11317, loss 0.265597, acc 0.875\n",
      "2018-05-04T17:15:07.508356: step 11318, loss 0.254527, acc 0.890625\n",
      "2018-05-04T17:15:08.505310: step 11319, loss 0.39781, acc 0.828125\n",
      "2018-05-04T17:15:09.513357: step 11320, loss 0.316541, acc 0.875\n",
      "2018-05-04T17:15:10.504842: step 11321, loss 0.332197, acc 0.890625\n",
      "2018-05-04T17:15:11.600396: step 11322, loss 0.249352, acc 0.875\n",
      "2018-05-04T17:15:12.625102: step 11323, loss 0.396864, acc 0.828125\n",
      "2018-05-04T17:15:13.651522: step 11324, loss 0.365772, acc 0.828125\n",
      "2018-05-04T17:15:14.674047: step 11325, loss 0.299033, acc 0.84375\n",
      "2018-05-04T17:15:15.725779: step 11326, loss 0.248939, acc 0.9375\n",
      "2018-05-04T17:15:16.719988: step 11327, loss 0.283814, acc 0.875\n",
      "2018-05-04T17:15:17.746277: step 11328, loss 0.314315, acc 0.828125\n",
      "2018-05-04T17:15:18.845150: step 11329, loss 0.226636, acc 0.90625\n",
      "2018-05-04T17:15:19.837032: step 11330, loss 0.257396, acc 0.84375\n",
      "2018-05-04T17:15:20.846201: step 11331, loss 0.314146, acc 0.859375\n",
      "2018-05-04T17:15:21.851451: step 11332, loss 0.396214, acc 0.828125\n",
      "2018-05-04T17:15:22.865201: step 11333, loss 0.361292, acc 0.84375\n",
      "2018-05-04T17:15:23.847548: step 11334, loss 0.261621, acc 0.84375\n",
      "2018-05-04T17:15:24.838821: step 11335, loss 0.329529, acc 0.875\n",
      "2018-05-04T17:15:25.845308: step 11336, loss 0.264766, acc 0.90625\n",
      "2018-05-04T17:15:26.949525: step 11337, loss 0.23791, acc 0.921875\n",
      "2018-05-04T17:15:27.944846: step 11338, loss 0.206504, acc 0.90625\n",
      "2018-05-04T17:15:28.925342: step 11339, loss 0.279421, acc 0.890625\n",
      "2018-05-04T17:15:29.893352: step 11340, loss 0.273696, acc 0.921875\n",
      "2018-05-04T17:15:30.871773: step 11341, loss 0.238364, acc 0.890625\n",
      "2018-05-04T17:15:31.898032: step 11342, loss 0.363673, acc 0.875\n",
      "2018-05-04T17:15:32.912254: step 11343, loss 0.302627, acc 0.90625\n",
      "2018-05-04T17:15:33.951795: step 11344, loss 0.137132, acc 0.9375\n",
      "2018-05-04T17:15:34.959961: step 11345, loss 0.30771, acc 0.859375\n",
      "2018-05-04T17:15:35.987819: step 11346, loss 0.268183, acc 0.875\n",
      "2018-05-04T17:15:37.024498: step 11347, loss 0.232457, acc 0.921875\n",
      "2018-05-04T17:15:38.020271: step 11348, loss 0.317394, acc 0.875\n",
      "2018-05-04T17:15:39.008908: step 11349, loss 0.206523, acc 0.90625\n",
      "2018-05-04T17:15:40.075930: step 11350, loss 0.138978, acc 0.96875\n",
      "2018-05-04T17:15:41.052677: step 11351, loss 0.128972, acc 0.953125\n",
      "2018-05-04T17:15:42.052508: step 11352, loss 0.200526, acc 0.921875\n",
      "2018-05-04T17:15:43.035700: step 11353, loss 0.123137, acc 0.96875\n",
      "2018-05-04T17:15:44.019229: step 11354, loss 0.217774, acc 0.90625\n",
      "2018-05-04T17:15:45.018130: step 11355, loss 0.363282, acc 0.84375\n",
      "2018-05-04T17:15:46.012160: step 11356, loss 0.398656, acc 0.859375\n",
      "2018-05-04T17:15:47.007458: step 11357, loss 0.338724, acc 0.890625\n",
      "2018-05-04T17:15:47.992077: step 11358, loss 0.261599, acc 0.859375\n",
      "2018-05-04T17:15:49.000582: step 11359, loss 0.166846, acc 0.90625\n",
      "2018-05-04T17:15:50.089640: step 11360, loss 0.214643, acc 0.921875\n",
      "2018-05-04T17:15:51.092522: step 11361, loss 0.337176, acc 0.859375\n",
      "2018-05-04T17:15:52.132928: step 11362, loss 0.411103, acc 0.84375\n",
      "2018-05-04T17:15:53.174217: step 11363, loss 0.275569, acc 0.875\n",
      "2018-05-04T17:15:54.242665: step 11364, loss 0.357694, acc 0.84375\n",
      "2018-05-04T17:15:55.237426: step 11365, loss 0.279708, acc 0.859375\n",
      "2018-05-04T17:15:56.219154: step 11366, loss 0.307372, acc 0.90625\n",
      "2018-05-04T17:15:57.216298: step 11367, loss 0.172336, acc 0.9375\n",
      "2018-05-04T17:15:58.213347: step 11368, loss 0.315131, acc 0.890625\n",
      "2018-05-04T17:15:59.198029: step 11369, loss 0.321852, acc 0.921875\n",
      "2018-05-04T17:16:00.257381: step 11370, loss 0.358639, acc 0.859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T17:16:01.242033: step 11371, loss 0.341568, acc 0.859375\n",
      "2018-05-04T17:16:02.304231: step 11372, loss 0.552159, acc 0.765625\n",
      "2018-05-04T17:16:03.296005: step 11373, loss 0.366515, acc 0.890625\n",
      "2018-05-04T17:16:04.289420: step 11374, loss 0.22255, acc 0.921875\n",
      "2018-05-04T17:16:05.267378: step 11375, loss 0.378517, acc 0.84375\n",
      "2018-05-04T17:16:06.330572: step 11376, loss 0.364255, acc 0.84375\n",
      "2018-05-04T17:16:07.374828: step 11377, loss 0.253775, acc 0.875\n",
      "2018-05-04T17:16:08.408095: step 11378, loss 0.273745, acc 0.90625\n",
      "2018-05-04T17:16:09.490578: step 11379, loss 0.341256, acc 0.859375\n",
      "2018-05-04T17:16:10.430777: step 11380, loss 0.245885, acc 0.890625\n",
      "2018-05-04T17:16:11.402986: step 11381, loss 0.349915, acc 0.84375\n",
      "2018-05-04T17:16:12.512217: step 11382, loss 0.16666, acc 0.953125\n",
      "2018-05-04T17:16:13.577804: step 11383, loss 0.416122, acc 0.828125\n",
      "2018-05-04T17:16:14.591705: step 11384, loss 0.251184, acc 0.859375\n",
      "2018-05-04T17:16:15.639603: step 11385, loss 0.299348, acc 0.859375\n",
      "2018-05-04T17:16:16.597904: step 11386, loss 0.355808, acc 0.859375\n",
      "2018-05-04T17:16:17.559703: step 11387, loss 0.239676, acc 0.890625\n",
      "2018-05-04T17:16:18.524256: step 11388, loss 0.260373, acc 0.9375\n",
      "2018-05-04T17:16:19.582559: step 11389, loss 0.276644, acc 0.90625\n",
      "2018-05-04T17:16:20.639108: step 11390, loss 0.260498, acc 0.90625\n",
      "2018-05-04T17:16:21.663998: step 11391, loss 0.26345, acc 0.890625\n",
      "2018-05-04T17:16:22.705855: step 11392, loss 0.316102, acc 0.859375\n",
      "2018-05-04T17:16:23.739367: step 11393, loss 0.148356, acc 0.9375\n",
      "2018-05-04T17:16:24.694133: step 11394, loss 0.332834, acc 0.828125\n",
      "2018-05-04T17:16:25.737611: step 11395, loss 0.126479, acc 0.96875\n",
      "2018-05-04T17:16:26.696540: step 11396, loss 0.277993, acc 0.90625\n",
      "2018-05-04T17:16:27.648616: step 11397, loss 0.235343, acc 0.890625\n",
      "2018-05-04T17:16:28.652795: step 11398, loss 0.235936, acc 0.875\n",
      "2018-05-04T17:16:29.674646: step 11399, loss 0.20837, acc 0.90625\n",
      "2018-05-04T17:16:30.708692: step 11400, loss 0.240717, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T17:16:33.426207: step 11400, loss 0.229976, acc 0.916\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-11400\n",
      "\n",
      "2018-05-04T17:16:34.538999: step 11401, loss 0.226819, acc 0.890625\n",
      "2018-05-04T17:16:35.630830: step 11402, loss 0.296674, acc 0.875\n",
      "2018-05-04T17:16:36.749507: step 11403, loss 0.321989, acc 0.8125\n",
      "2018-05-04T17:16:37.790959: step 11404, loss 0.281665, acc 0.875\n",
      "2018-05-04T17:16:38.835630: step 11405, loss 0.245188, acc 0.90625\n",
      "2018-05-04T17:16:39.895120: step 11406, loss 0.209024, acc 0.9375\n",
      "2018-05-04T17:16:40.948722: step 11407, loss 0.292136, acc 0.84375\n",
      "2018-05-04T17:16:41.996549: step 11408, loss 0.202649, acc 0.890625\n",
      "2018-05-04T17:16:43.139972: step 11409, loss 0.209682, acc 0.953125\n",
      "2018-05-04T17:16:44.154805: step 11410, loss 0.218441, acc 0.875\n",
      "2018-05-04T17:16:45.143617: step 11411, loss 0.328699, acc 0.84375\n",
      "2018-05-04T17:16:46.159117: step 11412, loss 0.205844, acc 0.921875\n",
      "2018-05-04T17:16:47.154744: step 11413, loss 0.333639, acc 0.859375\n",
      "2018-05-04T17:16:48.172535: step 11414, loss 0.356853, acc 0.859375\n",
      "2018-05-04T17:16:49.168158: step 11415, loss 0.219293, acc 0.9375\n",
      "2018-05-04T17:16:50.133910: step 11416, loss 0.387084, acc 0.84375\n",
      "2018-05-04T17:16:51.132051: step 11417, loss 0.22428, acc 0.890625\n",
      "2018-05-04T17:16:52.111597: step 11418, loss 0.259427, acc 0.9375\n",
      "2018-05-04T17:16:53.093561: step 11419, loss 0.29604, acc 0.90625\n",
      "2018-05-04T17:16:54.091250: step 11420, loss 0.392596, acc 0.828125\n",
      "2018-05-04T17:16:55.080871: step 11421, loss 0.27792, acc 0.859375\n",
      "2018-05-04T17:16:56.051413: step 11422, loss 0.138865, acc 0.953125\n",
      "2018-05-04T17:16:57.017986: step 11423, loss 0.295412, acc 0.859375\n",
      "2018-05-04T17:16:57.995015: step 11424, loss 0.271611, acc 0.90625\n",
      "2018-05-04T17:16:59.039834: step 11425, loss 0.225504, acc 0.9375\n",
      "2018-05-04T17:17:00.036246: step 11426, loss 0.212433, acc 0.9375\n",
      "2018-05-04T17:17:01.087725: step 11427, loss 0.162217, acc 0.96875\n",
      "2018-05-04T17:17:02.040241: step 11428, loss 0.275278, acc 0.859375\n",
      "2018-05-04T17:17:03.015364: step 11429, loss 0.290427, acc 0.90625\n",
      "2018-05-04T17:17:03.985231: step 11430, loss 0.273698, acc 0.859375\n",
      "2018-05-04T17:17:05.037879: step 11431, loss 0.175846, acc 0.96875\n",
      "2018-05-04T17:17:06.008526: step 11432, loss 0.236297, acc 0.890625\n",
      "2018-05-04T17:17:06.949706: step 11433, loss 0.240761, acc 0.9375\n",
      "2018-05-04T17:17:07.926066: step 11434, loss 0.446987, acc 0.875\n",
      "2018-05-04T17:17:08.892006: step 11435, loss 0.313914, acc 0.875\n",
      "2018-05-04T17:17:09.941895: step 11436, loss 0.406336, acc 0.890625\n",
      "2018-05-04T17:17:10.895037: step 11437, loss 0.193337, acc 0.890625\n",
      "2018-05-04T17:17:11.859025: step 11438, loss 0.321308, acc 0.84375\n",
      "2018-05-04T17:17:12.901470: step 11439, loss 0.36993, acc 0.84375\n",
      "2018-05-04T17:17:13.963049: step 11440, loss 0.18041, acc 0.96875\n",
      "2018-05-04T17:17:14.924153: step 11441, loss 0.284285, acc 0.875\n",
      "2018-05-04T17:17:15.952865: step 11442, loss 0.243887, acc 0.90625\n",
      "2018-05-04T17:17:16.907456: step 11443, loss 0.171246, acc 0.921875\n",
      "2018-05-04T17:17:17.918814: step 11444, loss 0.312043, acc 0.84375\n",
      "2018-05-04T17:17:18.905692: step 11445, loss 0.230897, acc 0.90625\n",
      "2018-05-04T17:17:19.879884: step 11446, loss 0.209523, acc 0.9375\n",
      "2018-05-04T17:17:20.844346: step 11447, loss 0.17909, acc 0.953125\n",
      "2018-05-04T17:17:21.954917: step 11448, loss 0.102611, acc 0.96875\n",
      "2018-05-04T17:17:22.915313: step 11449, loss 0.245747, acc 0.890625\n",
      "2018-05-04T17:17:23.964444: step 11450, loss 0.221794, acc 0.90625\n",
      "2018-05-04T17:17:24.922227: step 11451, loss 0.153078, acc 0.9375\n",
      "2018-05-04T17:17:25.874176: step 11452, loss 0.249568, acc 0.890625\n",
      "2018-05-04T17:17:26.913244: step 11453, loss 0.209955, acc 0.90625\n",
      "2018-05-04T17:17:27.866591: step 11454, loss 0.385802, acc 0.796875\n",
      "2018-05-04T17:17:28.835919: step 11455, loss 0.28, acc 0.84375\n",
      "2018-05-04T17:17:29.809968: step 11456, loss 0.219854, acc 0.921875\n",
      "2018-05-04T17:17:30.850626: step 11457, loss 0.271703, acc 0.890625\n",
      "2018-05-04T17:17:31.820710: step 11458, loss 0.337192, acc 0.859375\n",
      "2018-05-04T17:17:32.788256: step 11459, loss 0.274282, acc 0.875\n",
      "2018-05-04T17:17:33.757715: step 11460, loss 0.224309, acc 0.921875\n",
      "2018-05-04T17:17:34.698067: step 11461, loss 0.284147, acc 0.875\n",
      "2018-05-04T17:17:35.732738: step 11462, loss 0.281967, acc 0.90625\n",
      "2018-05-04T17:17:36.686235: step 11463, loss 0.351425, acc 0.859375\n",
      "2018-05-04T17:17:37.657389: step 11464, loss 0.184724, acc 0.9375\n",
      "2018-05-04T17:17:38.645218: step 11465, loss 0.229551, acc 0.921875\n",
      "2018-05-04T17:17:39.646872: step 11466, loss 0.250701, acc 0.921875\n",
      "2018-05-04T17:17:40.656565: step 11467, loss 0.326302, acc 0.84375\n",
      "2018-05-04T17:17:41.624923: step 11468, loss 0.284716, acc 0.921875\n",
      "2018-05-04T17:17:42.615613: step 11469, loss 0.423893, acc 0.875\n",
      "2018-05-04T17:17:43.588070: step 11470, loss 0.275497, acc 0.890625\n",
      "2018-05-04T17:17:44.538188: step 11471, loss 0.235424, acc 0.90625\n",
      "2018-05-04T17:17:45.493408: step 11472, loss 0.24631, acc 0.90625\n",
      "2018-05-04T17:17:46.458077: step 11473, loss 0.381769, acc 0.828125\n",
      "2018-05-04T17:17:47.446636: step 11474, loss 0.332507, acc 0.875\n",
      "2018-05-04T17:17:48.409148: step 11475, loss 0.185258, acc 0.921875\n",
      "2018-05-04T17:17:49.388977: step 11476, loss 0.469464, acc 0.796875\n",
      "2018-05-04T17:17:50.385195: step 11477, loss 0.363419, acc 0.828125\n",
      "2018-05-04T17:17:51.375479: step 11478, loss 0.228892, acc 0.9375\n",
      "2018-05-04T17:17:52.305443: step 11479, loss 0.187464, acc 0.921875\n",
      "2018-05-04T17:17:53.260070: step 11480, loss 0.22974, acc 0.890625\n",
      "2018-05-04T17:17:54.223092: step 11481, loss 0.252415, acc 0.90625\n",
      "2018-05-04T17:17:55.180605: step 11482, loss 0.215641, acc 0.875\n",
      "2018-05-04T17:17:56.155605: step 11483, loss 0.185725, acc 0.953125\n",
      "2018-05-04T17:17:57.114473: step 11484, loss 0.282018, acc 0.875\n",
      "2018-05-04T17:17:58.092319: step 11485, loss 0.275341, acc 0.890625\n",
      "2018-05-04T17:17:59.071468: step 11486, loss 0.219651, acc 0.921875\n",
      "2018-05-04T17:18:00.053448: step 11487, loss 0.230852, acc 0.890625\n",
      "2018-05-04T17:18:01.058231: step 11488, loss 0.212385, acc 0.859375\n",
      "2018-05-04T17:18:02.098878: step 11489, loss 0.210735, acc 0.90625\n",
      "2018-05-04T17:18:03.090995: step 11490, loss 0.205387, acc 0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T17:18:04.066072: step 11491, loss 0.142525, acc 0.984375\n",
      "2018-05-04T17:18:05.020773: step 11492, loss 0.361226, acc 0.8125\n",
      "2018-05-04T17:18:06.035426: step 11493, loss 0.34073, acc 0.859375\n",
      "2018-05-04T17:18:07.012470: step 11494, loss 0.259268, acc 0.921875\n",
      "2018-05-04T17:18:08.006034: step 11495, loss 0.223088, acc 0.9375\n",
      "2018-05-04T17:18:08.993353: step 11496, loss 0.244561, acc 0.921875\n",
      "2018-05-04T17:18:09.956158: step 11497, loss 0.193381, acc 0.953125\n",
      "2018-05-04T17:18:10.921494: step 11498, loss 0.219445, acc 0.9375\n",
      "2018-05-04T17:18:11.882892: step 11499, loss 0.29255, acc 0.828125\n",
      "2018-05-04T17:18:12.863650: step 11500, loss 0.271635, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T17:18:15.049388: step 11500, loss 0.232028, acc 0.912\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-11500\n",
      "\n",
      "2018-05-04T17:18:16.109072: step 11501, loss 0.510275, acc 0.828125\n",
      "2018-05-04T17:18:17.118769: step 11502, loss 0.257103, acc 0.90625\n",
      "2018-05-04T17:18:18.114394: step 11503, loss 0.292829, acc 0.875\n",
      "2018-05-04T17:18:19.106374: step 11504, loss 0.164848, acc 0.9375\n",
      "2018-05-04T17:18:20.084046: step 11505, loss 0.270321, acc 0.921875\n",
      "2018-05-04T17:18:21.093116: step 11506, loss 0.300008, acc 0.890625\n",
      "2018-05-04T17:18:22.205471: step 11507, loss 0.193666, acc 0.90625\n",
      "2018-05-04T17:18:23.225789: step 11508, loss 0.376546, acc 0.890625\n",
      "2018-05-04T17:18:24.212861: step 11509, loss 0.244709, acc 0.890625\n",
      "2018-05-04T17:18:25.204971: step 11510, loss 0.201236, acc 0.921875\n",
      "2018-05-04T17:18:26.196873: step 11511, loss 0.256843, acc 0.890625\n",
      "2018-05-04T17:18:27.172883: step 11512, loss 0.242859, acc 0.890625\n",
      "2018-05-04T17:18:28.152563: step 11513, loss 0.174185, acc 0.921875\n",
      "2018-05-04T17:18:29.131791: step 11514, loss 0.156201, acc 0.953125\n",
      "2018-05-04T17:18:30.110027: step 11515, loss 0.262675, acc 0.890625\n",
      "2018-05-04T17:18:31.106498: step 11516, loss 0.178492, acc 0.9375\n",
      "2018-05-04T17:18:32.096184: step 11517, loss 0.235259, acc 0.9375\n",
      "2018-05-04T17:18:33.094381: step 11518, loss 0.359552, acc 0.84375\n",
      "2018-05-04T17:18:34.087940: step 11519, loss 0.354021, acc 0.859375\n",
      "2018-05-04T17:18:35.106033: step 11520, loss 0.304216, acc 0.890625\n",
      "2018-05-04T17:18:36.090781: step 11521, loss 0.35865, acc 0.90625\n",
      "2018-05-04T17:18:37.055607: step 11522, loss 0.179284, acc 0.90625\n",
      "2018-05-04T17:18:38.013035: step 11523, loss 0.293094, acc 0.859375\n",
      "2018-05-04T17:18:39.011699: step 11524, loss 0.255695, acc 0.875\n",
      "2018-05-04T17:18:39.994340: step 11525, loss 0.182375, acc 0.953125\n",
      "2018-05-04T17:18:40.997727: step 11526, loss 0.222434, acc 0.90625\n",
      "2018-05-04T17:18:41.979936: step 11527, loss 0.278477, acc 0.90625\n",
      "2018-05-04T17:18:43.001275: step 11528, loss 0.344353, acc 0.859375\n",
      "2018-05-04T17:18:43.983796: step 11529, loss 0.397399, acc 0.8125\n",
      "2018-05-04T17:18:44.966259: step 11530, loss 0.36336, acc 0.828125\n",
      "2018-05-04T17:18:45.957188: step 11531, loss 0.335337, acc 0.875\n",
      "2018-05-04T17:18:46.951613: step 11532, loss 0.306653, acc 0.890625\n",
      "2018-05-04T17:18:47.946780: step 11533, loss 0.241439, acc 0.90625\n",
      "2018-05-04T17:18:49.004425: step 11534, loss 0.483727, acc 0.859375\n",
      "2018-05-04T17:18:49.999885: step 11535, loss 0.418586, acc 0.796875\n",
      "2018-05-04T17:18:50.981120: step 11536, loss 0.310028, acc 0.875\n",
      "2018-05-04T17:18:51.972585: step 11537, loss 0.23755, acc 0.921875\n",
      "2018-05-04T17:18:52.950871: step 11538, loss 0.233252, acc 0.921875\n",
      "2018-05-04T17:18:53.941042: step 11539, loss 0.260595, acc 0.921875\n",
      "2018-05-04T17:18:54.927340: step 11540, loss 0.345507, acc 0.84375\n",
      "2018-05-04T17:18:55.903753: step 11541, loss 0.278423, acc 0.890625\n",
      "2018-05-04T17:18:56.895882: step 11542, loss 0.38184, acc 0.84375\n",
      "2018-05-04T17:18:57.922318: step 11543, loss 0.300197, acc 0.859375\n",
      "2018-05-04T17:18:58.927717: step 11544, loss 0.351338, acc 0.8125\n",
      "2018-05-04T17:18:59.922052: step 11545, loss 0.373847, acc 0.8125\n",
      "2018-05-04T17:19:00.991312: step 11546, loss 0.347051, acc 0.859375\n",
      "2018-05-04T17:19:02.010828: step 11547, loss 0.327358, acc 0.875\n",
      "2018-05-04T17:19:03.007832: step 11548, loss 0.283642, acc 0.84375\n",
      "2018-05-04T17:19:04.009808: step 11549, loss 0.222094, acc 0.859375\n",
      "2018-05-04T17:19:05.003141: step 11550, loss 0.182054, acc 0.921875\n",
      "2018-05-04T17:19:05.973422: step 11551, loss 0.242424, acc 0.953125\n",
      "2018-05-04T17:19:06.984322: step 11552, loss 0.356482, acc 0.84375\n",
      "2018-05-04T17:19:07.976662: step 11553, loss 0.409222, acc 0.859375\n",
      "2018-05-04T17:19:09.002681: step 11554, loss 0.243748, acc 0.875\n",
      "2018-05-04T17:19:09.999354: step 11555, loss 0.318413, acc 0.875\n",
      "2018-05-04T17:19:10.980350: step 11556, loss 0.163139, acc 0.953125\n",
      "2018-05-04T17:19:11.939120: step 11557, loss 0.241273, acc 0.921875\n",
      "2018-05-04T17:19:12.902268: step 11558, loss 0.40301, acc 0.890625\n",
      "2018-05-04T17:19:13.855970: step 11559, loss 0.290139, acc 0.859375\n",
      "2018-05-04T17:19:14.913548: step 11560, loss 0.226055, acc 0.890625\n",
      "2018-05-04T17:19:16.004869: step 11561, loss 0.254387, acc 0.890625\n",
      "2018-05-04T17:19:16.996564: step 11562, loss 0.229497, acc 0.921875\n",
      "2018-05-04T17:19:18.056630: step 11563, loss 0.234442, acc 0.921875\n",
      "2018-05-04T17:19:19.016281: step 11564, loss 0.248777, acc 0.890625\n",
      "2018-05-04T17:19:20.003502: step 11565, loss 0.274146, acc 0.875\n",
      "2018-05-04T17:19:20.993220: step 11566, loss 0.317682, acc 0.828125\n",
      "2018-05-04T17:19:22.093487: step 11567, loss 0.240159, acc 0.90625\n",
      "2018-05-04T17:19:23.093154: step 11568, loss 0.30117, acc 0.890625\n",
      "2018-05-04T17:19:24.156198: step 11569, loss 0.205565, acc 0.90625\n",
      "2018-05-04T17:19:25.112480: step 11570, loss 0.146746, acc 0.96875\n",
      "2018-05-04T17:19:26.067298: step 11571, loss 0.284803, acc 0.859375\n",
      "2018-05-04T17:19:27.039271: step 11572, loss 0.324243, acc 0.828125\n",
      "2018-05-04T17:19:28.072733: step 11573, loss 0.216248, acc 0.90625\n",
      "2018-05-04T17:19:29.050433: step 11574, loss 0.311978, acc 0.859375\n",
      "2018-05-04T17:19:30.088548: step 11575, loss 0.418391, acc 0.828125\n",
      "2018-05-04T17:19:31.178480: step 11576, loss 0.166754, acc 0.90625\n",
      "2018-05-04T17:19:32.172221: step 11577, loss 0.273664, acc 0.875\n",
      "2018-05-04T17:19:33.178978: step 11578, loss 0.31452, acc 0.8125\n",
      "2018-05-04T17:19:34.224034: step 11579, loss 0.206327, acc 0.9375\n",
      "2018-05-04T17:19:35.265594: step 11580, loss 0.179032, acc 0.921875\n",
      "2018-05-04T17:19:36.317637: step 11581, loss 0.239065, acc 0.9375\n",
      "2018-05-04T17:19:37.305828: step 11582, loss 0.230999, acc 0.90625\n",
      "2018-05-04T17:19:38.355974: step 11583, loss 0.262597, acc 0.859375\n",
      "2018-05-04T17:19:39.416253: step 11584, loss 0.233348, acc 0.9375\n",
      "2018-05-04T17:19:40.395705: step 11585, loss 0.218798, acc 0.9375\n",
      "2018-05-04T17:19:41.385969: step 11586, loss 0.349647, acc 0.859375\n",
      "2018-05-04T17:19:42.423113: step 11587, loss 0.368836, acc 0.8125\n",
      "2018-05-04T17:19:43.378359: step 11588, loss 0.266545, acc 0.90625\n",
      "2018-05-04T17:19:44.409329: step 11589, loss 0.195178, acc 0.921875\n",
      "2018-05-04T17:19:45.380958: step 11590, loss 0.444345, acc 0.8125\n",
      "2018-05-04T17:19:46.462102: step 11591, loss 0.385009, acc 0.828125\n",
      "2018-05-04T17:19:47.424567: step 11592, loss 0.131982, acc 0.96875\n",
      "2018-05-04T17:19:48.471422: step 11593, loss 0.321498, acc 0.84375\n",
      "2018-05-04T17:19:49.497780: step 11594, loss 0.31385, acc 0.84375\n",
      "2018-05-04T17:19:50.468862: step 11595, loss 0.283819, acc 0.875\n",
      "2018-05-04T17:19:51.458035: step 11596, loss 0.219418, acc 0.921875\n",
      "2018-05-04T17:19:52.442627: step 11597, loss 0.224252, acc 0.90625\n",
      "2018-05-04T17:19:53.476382: step 11598, loss 0.248158, acc 0.875\n",
      "2018-05-04T17:19:54.506685: step 11599, loss 0.368379, acc 0.84375\n",
      "2018-05-04T17:19:55.535644: step 11600, loss 0.30626, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T17:19:57.981914: step 11600, loss 0.252427, acc 0.91\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-11600\n",
      "\n",
      "2018-05-04T17:19:59.147230: step 11601, loss 0.288014, acc 0.859375\n",
      "2018-05-04T17:20:00.151897: step 11602, loss 0.279234, acc 0.90625\n",
      "2018-05-04T17:20:01.260581: step 11603, loss 0.274248, acc 0.875\n",
      "2018-05-04T17:20:02.309823: step 11604, loss 0.253595, acc 0.875\n",
      "2018-05-04T17:20:03.325960: step 11605, loss 0.317715, acc 0.890625\n",
      "2018-05-04T17:20:04.375466: step 11606, loss 0.335633, acc 0.875\n",
      "2018-05-04T17:20:05.388885: step 11607, loss 0.286872, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T17:20:06.495864: step 11608, loss 0.249719, acc 0.921875\n",
      "2018-05-04T17:20:07.501837: step 11609, loss 0.265246, acc 0.84375\n",
      "2018-05-04T17:20:08.535989: step 11610, loss 0.146616, acc 0.96875\n",
      "2018-05-04T17:20:09.620623: step 11611, loss 0.248788, acc 0.875\n",
      "2018-05-04T17:20:10.610379: step 11612, loss 0.304482, acc 0.890625\n",
      "2018-05-04T17:20:11.607334: step 11613, loss 0.313369, acc 0.859375\n",
      "2018-05-04T17:20:12.694064: step 11614, loss 0.342906, acc 0.828125\n",
      "2018-05-04T17:20:13.677717: step 11615, loss 0.320605, acc 0.875\n",
      "2018-05-04T17:20:14.676202: step 11616, loss 0.276507, acc 0.890625\n",
      "2018-05-04T17:20:15.691475: step 11617, loss 0.250267, acc 0.875\n",
      "2018-05-04T17:20:16.682482: step 11618, loss 0.153029, acc 0.953125\n",
      "2018-05-04T17:20:17.686352: step 11619, loss 0.340884, acc 0.84375\n",
      "2018-05-04T17:20:18.691226: step 11620, loss 0.29787, acc 0.859375\n",
      "2018-05-04T17:20:19.671650: step 11621, loss 0.274592, acc 0.921875\n",
      "2018-05-04T17:20:20.667116: step 11622, loss 0.201343, acc 0.890625\n",
      "2018-05-04T17:20:21.702683: step 11623, loss 0.243839, acc 0.921875\n",
      "2018-05-04T17:20:22.703067: step 11624, loss 0.452593, acc 0.796875\n",
      "2018-05-04T17:20:23.717568: step 11625, loss 0.174518, acc 0.953125\n",
      "2018-05-04T17:20:24.712247: step 11626, loss 0.284889, acc 0.90625\n",
      "2018-05-04T17:20:25.705920: step 11627, loss 0.303543, acc 0.90625\n",
      "2018-05-04T17:20:26.686227: step 11628, loss 0.270836, acc 0.921875\n",
      "2018-05-04T17:20:27.693002: step 11629, loss 0.24518, acc 0.890625\n",
      "2018-05-04T17:20:28.681221: step 11630, loss 0.24736, acc 0.890625\n",
      "2018-05-04T17:20:29.721825: step 11631, loss 0.268448, acc 0.875\n",
      "2018-05-04T17:20:30.702687: step 11632, loss 0.224829, acc 0.890625\n",
      "2018-05-04T17:20:31.684592: step 11633, loss 0.330911, acc 0.875\n",
      "2018-05-04T17:20:32.809877: step 11634, loss 0.335733, acc 0.890625\n",
      "2018-05-04T17:20:33.832823: step 11635, loss 0.155042, acc 0.96875\n",
      "2018-05-04T17:20:34.865206: step 11636, loss 0.379083, acc 0.84375\n",
      "2018-05-04T17:20:35.869981: step 11637, loss 0.175209, acc 0.921875\n",
      "2018-05-04T17:20:36.888980: step 11638, loss 0.327218, acc 0.890625\n",
      "2018-05-04T17:20:37.860683: step 11639, loss 0.171899, acc 0.9375\n",
      "2018-05-04T17:20:38.855081: step 11640, loss 0.374328, acc 0.828125\n",
      "2018-05-04T17:20:39.866493: step 11641, loss 0.377529, acc 0.828125\n",
      "2018-05-04T17:20:40.862231: step 11642, loss 0.37841, acc 0.78125\n",
      "2018-05-04T17:20:41.986392: step 11643, loss 0.323424, acc 0.828125\n",
      "2018-05-04T17:20:43.002858: step 11644, loss 0.213325, acc 0.90625\n",
      "2018-05-04T17:20:44.010252: step 11645, loss 0.305831, acc 0.859375\n",
      "2018-05-04T17:20:45.026635: step 11646, loss 0.23376, acc 0.875\n",
      "2018-05-04T17:20:46.004632: step 11647, loss 0.195492, acc 0.953125\n",
      "2018-05-04T17:20:47.006300: step 11648, loss 0.263009, acc 0.890625\n",
      "2018-05-04T17:20:47.972703: step 11649, loss 0.328313, acc 0.84375\n",
      "2018-05-04T17:20:49.034743: step 11650, loss 0.26266, acc 0.890625\n",
      "2018-05-04T17:20:50.047067: step 11651, loss 0.179479, acc 0.90625\n",
      "2018-05-04T17:20:51.097294: step 11652, loss 0.267178, acc 0.890625\n",
      "2018-05-04T17:20:52.119300: step 11653, loss 0.36954, acc 0.8125\n",
      "2018-05-04T17:20:53.117904: step 11654, loss 0.276245, acc 0.921875\n",
      "2018-05-04T17:20:54.110466: step 11655, loss 0.245084, acc 0.921875\n",
      "2018-05-04T17:20:55.095031: step 11656, loss 0.237095, acc 0.9375\n",
      "2018-05-04T17:20:56.162968: step 11657, loss 0.305629, acc 0.890625\n",
      "2018-05-04T17:20:57.167715: step 11658, loss 0.328771, acc 0.890625\n",
      "2018-05-04T17:20:58.158766: step 11659, loss 0.289868, acc 0.890625\n",
      "2018-05-04T17:20:59.163744: step 11660, loss 0.227193, acc 0.875\n",
      "2018-05-04T17:21:00.186739: step 11661, loss 0.230078, acc 0.921875\n",
      "2018-05-04T17:21:01.200823: step 11662, loss 0.223272, acc 0.890625\n",
      "2018-05-04T17:21:02.209022: step 11663, loss 0.145331, acc 0.96875\n",
      "2018-05-04T17:21:03.208347: step 11664, loss 0.20366, acc 0.90625\n",
      "2018-05-04T17:21:04.222231: step 11665, loss 0.231116, acc 0.90625\n",
      "2018-05-04T17:21:05.235511: step 11666, loss 0.272895, acc 0.875\n",
      "2018-05-04T17:21:06.242424: step 11667, loss 0.207241, acc 0.9375\n",
      "2018-05-04T17:21:07.235836: step 11668, loss 0.255708, acc 0.84375\n",
      "2018-05-04T17:21:08.195280: step 11669, loss 0.38649, acc 0.796875\n",
      "2018-05-04T17:21:09.195238: step 11670, loss 0.20173, acc 0.921875\n",
      "2018-05-04T17:21:10.217735: step 11671, loss 0.334082, acc 0.796875\n",
      "2018-05-04T17:21:11.234068: step 11672, loss 0.19848, acc 0.953125\n",
      "2018-05-04T17:21:12.251622: step 11673, loss 0.21275, acc 0.90625\n",
      "2018-05-04T17:21:13.250205: step 11674, loss 0.319279, acc 0.9375\n",
      "2018-05-04T17:21:14.252568: step 11675, loss 0.239389, acc 0.921875\n",
      "2018-05-04T17:21:15.271703: step 11676, loss 0.192781, acc 0.9375\n",
      "2018-05-04T17:21:16.254604: step 11677, loss 0.285505, acc 0.875\n",
      "2018-05-04T17:21:17.337471: step 11678, loss 0.34099, acc 0.859375\n",
      "2018-05-04T17:21:18.317331: step 11679, loss 0.251279, acc 0.90625\n",
      "2018-05-04T17:21:19.342873: step 11680, loss 0.246624, acc 0.859375\n",
      "2018-05-04T17:21:20.355875: step 11681, loss 0.34836, acc 0.828125\n",
      "2018-05-04T17:21:21.379430: step 11682, loss 0.193545, acc 0.9375\n",
      "2018-05-04T17:21:22.398112: step 11683, loss 0.409456, acc 0.828125\n",
      "2018-05-04T17:21:23.387706: step 11684, loss 0.286601, acc 0.90625\n",
      "2018-05-04T17:21:24.388102: step 11685, loss 0.284297, acc 0.875\n",
      "2018-05-04T17:21:25.369849: step 11686, loss 0.256995, acc 0.921875\n",
      "2018-05-04T17:21:26.352912: step 11687, loss 0.182375, acc 0.921875\n",
      "2018-05-04T17:21:27.336876: step 11688, loss 0.127939, acc 0.96875\n",
      "2018-05-04T17:21:28.349071: step 11689, loss 0.24621, acc 0.90625\n",
      "2018-05-04T17:21:29.347592: step 11690, loss 0.233819, acc 0.90625\n",
      "2018-05-04T17:21:30.361932: step 11691, loss 0.285561, acc 0.859375\n",
      "2018-05-04T17:21:31.350612: step 11692, loss 0.239123, acc 0.90625\n",
      "2018-05-04T17:21:32.419413: step 11693, loss 0.236557, acc 0.90625\n",
      "2018-05-04T17:21:33.428889: step 11694, loss 0.351867, acc 0.875\n",
      "2018-05-04T17:21:34.448547: step 11695, loss 0.270511, acc 0.890625\n",
      "2018-05-04T17:21:35.423997: step 11696, loss 0.249007, acc 0.890625\n",
      "2018-05-04T17:21:36.383520: step 11697, loss 0.359018, acc 0.828125\n",
      "2018-05-04T17:21:37.350409: step 11698, loss 0.189593, acc 0.875\n",
      "2018-05-04T17:21:38.334631: step 11699, loss 0.293529, acc 0.90625\n",
      "2018-05-04T17:21:39.333381: step 11700, loss 0.2215, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T17:21:41.537468: step 11700, loss 0.218233, acc 0.93\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-11700\n",
      "\n",
      "2018-05-04T17:21:42.681180: step 11701, loss 0.121384, acc 0.96875\n",
      "2018-05-04T17:21:43.689138: step 11702, loss 0.546581, acc 0.765625\n",
      "2018-05-04T17:21:44.748344: step 11703, loss 0.215954, acc 0.953125\n",
      "2018-05-04T17:21:45.775516: step 11704, loss 0.358122, acc 0.859375\n",
      "2018-05-04T17:21:46.762164: step 11705, loss 0.198934, acc 0.875\n",
      "2018-05-04T17:21:47.850577: step 11706, loss 0.205759, acc 0.9375\n",
      "2018-05-04T17:21:48.870272: step 11707, loss 0.302438, acc 0.875\n",
      "2018-05-04T17:21:49.901130: step 11708, loss 0.301774, acc 0.875\n",
      "2018-05-04T17:21:50.927237: step 11709, loss 0.205995, acc 0.90625\n",
      "2018-05-04T17:21:51.944504: step 11710, loss 0.194869, acc 0.921875\n",
      "2018-05-04T17:21:52.920783: step 11711, loss 0.275627, acc 0.90625\n",
      "2018-05-04T17:21:53.921861: step 11712, loss 0.278774, acc 0.859375\n",
      "2018-05-04T17:21:54.905191: step 11713, loss 0.219303, acc 0.90625\n",
      "2018-05-04T17:21:55.904802: step 11714, loss 0.205009, acc 0.921875\n",
      "2018-05-04T17:21:56.898382: step 11715, loss 0.164889, acc 0.96875\n",
      "2018-05-04T17:21:57.896567: step 11716, loss 0.294083, acc 0.859375\n",
      "2018-05-04T17:21:58.884931: step 11717, loss 0.265289, acc 0.875\n",
      "2018-05-04T17:21:59.872194: step 11718, loss 0.426937, acc 0.796875\n",
      "2018-05-04T17:22:00.860173: step 11719, loss 0.272766, acc 0.828125\n",
      "2018-05-04T17:22:01.855520: step 11720, loss 0.395942, acc 0.796875\n",
      "2018-05-04T17:22:02.854299: step 11721, loss 0.23636, acc 0.921875\n",
      "2018-05-04T17:22:03.849570: step 11722, loss 0.337591, acc 0.796875\n",
      "2018-05-04T17:22:04.899644: step 11723, loss 0.32493, acc 0.859375\n",
      "2018-05-04T17:22:05.887888: step 11724, loss 0.23044, acc 0.90625\n",
      "2018-05-04T17:22:06.886646: step 11725, loss 0.216307, acc 0.921875\n",
      "2018-05-04T17:22:07.937617: step 11726, loss 0.228394, acc 0.9375\n",
      "2018-05-04T17:22:08.939210: step 11727, loss 0.193761, acc 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T17:22:09.932559: step 11728, loss 0.170391, acc 0.953125\n",
      "2018-05-04T17:22:10.928835: step 11729, loss 0.233579, acc 0.9375\n",
      "2018-05-04T17:22:11.922262: step 11730, loss 0.27433, acc 0.890625\n",
      "2018-05-04T17:22:12.919304: step 11731, loss 0.414001, acc 0.8125\n",
      "2018-05-04T17:22:13.915386: step 11732, loss 0.253416, acc 0.90625\n",
      "2018-05-04T17:22:14.951502: step 11733, loss 0.139644, acc 0.953125\n",
      "2018-05-04T17:22:15.910572: step 11734, loss 0.412533, acc 0.859375\n",
      "2018-05-04T17:22:16.858226: step 11735, loss 0.30883, acc 0.859375\n",
      "2018-05-04T17:22:17.902939: step 11736, loss 0.38071, acc 0.890625\n",
      "2018-05-04T17:22:18.874454: step 11737, loss 0.24806, acc 0.90625\n",
      "2018-05-04T17:22:19.877779: step 11738, loss 0.220791, acc 0.9375\n",
      "2018-05-04T17:22:20.865463: step 11739, loss 0.198115, acc 0.921875\n",
      "2018-05-04T17:22:21.892212: step 11740, loss 0.25945, acc 0.84375\n",
      "2018-05-04T17:22:22.884039: step 11741, loss 0.23833, acc 0.859375\n",
      "2018-05-04T17:22:23.888280: step 11742, loss 0.241373, acc 0.859375\n",
      "2018-05-04T17:22:24.879672: step 11743, loss 0.268982, acc 0.890625\n",
      "2018-05-04T17:22:25.916999: step 11744, loss 0.341549, acc 0.859375\n",
      "2018-05-04T17:22:26.888563: step 11745, loss 0.216594, acc 0.90625\n",
      "2018-05-04T17:22:27.877586: step 11746, loss 0.214371, acc 0.890625\n",
      "2018-05-04T17:22:28.874533: step 11747, loss 0.319897, acc 0.859375\n",
      "2018-05-04T17:22:29.862168: step 11748, loss 0.177707, acc 0.921875\n",
      "2018-05-04T17:22:30.847964: step 11749, loss 0.465289, acc 0.828125\n",
      "2018-05-04T17:22:31.832463: step 11750, loss 0.319394, acc 0.828125\n",
      "2018-05-04T17:22:32.844625: step 11751, loss 0.305683, acc 0.875\n",
      "2018-05-04T17:22:33.907629: step 11752, loss 0.17732, acc 0.9375\n",
      "2018-05-04T17:22:35.025868: step 11753, loss 0.405363, acc 0.859375\n",
      "2018-05-04T17:22:36.127702: step 11754, loss 0.201126, acc 0.890625\n",
      "2018-05-04T17:22:37.187559: step 11755, loss 0.168092, acc 0.953125\n",
      "2018-05-04T17:22:38.153538: step 11756, loss 0.397653, acc 0.828125\n",
      "2018-05-04T17:22:39.137511: step 11757, loss 0.23895, acc 0.90625\n",
      "2018-05-04T17:22:40.196973: step 11758, loss 0.409382, acc 0.84375\n",
      "2018-05-04T17:22:41.254840: step 11759, loss 0.232321, acc 0.921875\n",
      "2018-05-04T17:22:42.296436: step 11760, loss 0.326713, acc 0.90625\n",
      "2018-05-04T17:22:43.253930: step 11761, loss 0.310908, acc 0.875\n",
      "2018-05-04T17:22:44.210503: step 11762, loss 0.240098, acc 0.90625\n",
      "2018-05-04T17:22:45.161166: step 11763, loss 0.269378, acc 0.890625\n",
      "2018-05-04T17:22:46.182588: step 11764, loss 0.309806, acc 0.875\n",
      "2018-05-04T17:22:47.179821: step 11765, loss 0.358272, acc 0.796875\n",
      "2018-05-04T17:22:48.250892: step 11766, loss 0.286963, acc 0.890625\n",
      "2018-05-04T17:22:49.240755: step 11767, loss 0.27661, acc 0.859375\n",
      "2018-05-04T17:22:50.226166: step 11768, loss 0.217791, acc 0.90625\n",
      "2018-05-04T17:22:51.287276: step 11769, loss 0.366064, acc 0.859375\n",
      "2018-05-04T17:22:52.299331: step 11770, loss 0.411176, acc 0.796875\n",
      "2018-05-04T17:22:53.349091: step 11771, loss 0.303887, acc 0.875\n",
      "2018-05-04T17:22:54.396313: step 11772, loss 0.349444, acc 0.828125\n",
      "2018-05-04T17:22:55.355414: step 11773, loss 0.32322, acc 0.828125\n",
      "2018-05-04T17:22:56.314715: step 11774, loss 0.253476, acc 0.90625\n",
      "2018-05-04T17:22:57.355441: step 11775, loss 0.225448, acc 0.859375\n",
      "2018-05-04T17:22:58.322481: step 11776, loss 0.200517, acc 0.953125\n",
      "2018-05-04T17:22:59.291419: step 11777, loss 0.21652, acc 0.90625\n",
      "2018-05-04T17:23:00.297613: step 11778, loss 0.384761, acc 0.8125\n",
      "2018-05-04T17:23:01.352757: step 11779, loss 0.146031, acc 0.953125\n",
      "2018-05-04T17:23:02.342403: step 11780, loss 0.191333, acc 0.890625\n",
      "2018-05-04T17:23:03.344184: step 11781, loss 0.25843, acc 0.90625\n",
      "2018-05-04T17:23:04.407090: step 11782, loss 0.244463, acc 0.921875\n",
      "2018-05-04T17:23:05.441966: step 11783, loss 0.337108, acc 0.875\n",
      "2018-05-04T17:23:06.493484: step 11784, loss 0.262196, acc 0.890625\n",
      "2018-05-04T17:23:07.497369: step 11785, loss 0.300451, acc 0.875\n",
      "2018-05-04T17:23:08.469019: step 11786, loss 0.241527, acc 0.890625\n",
      "2018-05-04T17:23:09.515471: step 11787, loss 0.253807, acc 0.890625\n",
      "2018-05-04T17:23:10.558700: step 11788, loss 0.151387, acc 0.953125\n",
      "2018-05-04T17:23:11.634391: step 11789, loss 0.376069, acc 0.84375\n",
      "2018-05-04T17:23:12.574476: step 11790, loss 0.223627, acc 0.875\n",
      "2018-05-04T17:23:13.534233: step 11791, loss 0.401759, acc 0.8125\n",
      "2018-05-04T17:23:14.571084: step 11792, loss 0.220191, acc 0.890625\n",
      "2018-05-04T17:23:15.620456: step 11793, loss 0.3291, acc 0.875\n",
      "2018-05-04T17:23:16.672207: step 11794, loss 0.184148, acc 0.921875\n",
      "2018-05-04T17:23:17.718902: step 11795, loss 0.223475, acc 0.921875\n",
      "2018-05-04T17:23:18.791917: step 11796, loss 0.200656, acc 0.921875\n",
      "2018-05-04T17:23:19.852419: step 11797, loss 0.403225, acc 0.875\n",
      "2018-05-04T17:23:20.839489: step 11798, loss 0.258798, acc 0.890625\n",
      "2018-05-04T17:23:21.891613: step 11799, loss 0.243852, acc 0.890625\n",
      "2018-05-04T17:23:22.841579: step 11800, loss 0.299628, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T17:23:25.383299: step 11800, loss 0.2257, acc 0.928\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-11800\n",
      "\n",
      "2018-05-04T17:23:26.512719: step 11801, loss 0.32378, acc 0.875\n",
      "2018-05-04T17:23:27.571559: step 11802, loss 0.412755, acc 0.84375\n",
      "2018-05-04T17:23:28.619676: step 11803, loss 0.168197, acc 0.9375\n",
      "2018-05-04T17:23:29.741210: step 11804, loss 0.155732, acc 0.953125\n",
      "2018-05-04T17:23:30.779830: step 11805, loss 0.411028, acc 0.8125\n",
      "2018-05-04T17:23:31.890067: step 11806, loss 0.153672, acc 0.96875\n",
      "2018-05-04T17:23:32.982181: step 11807, loss 0.359726, acc 0.84375\n",
      "2018-05-04T17:23:34.006956: step 11808, loss 0.351677, acc 0.84375\n",
      "2018-05-04T17:23:35.010214: step 11809, loss 0.299797, acc 0.859375\n",
      "2018-05-04T17:23:36.094990: step 11810, loss 0.276495, acc 0.890625\n",
      "2018-05-04T17:23:37.184143: step 11811, loss 0.245599, acc 0.90625\n",
      "2018-05-04T17:23:38.167450: step 11812, loss 0.225353, acc 0.953125\n",
      "2018-05-04T17:23:39.154459: step 11813, loss 0.194048, acc 0.921875\n",
      "2018-05-04T17:23:40.156857: step 11814, loss 0.300051, acc 0.921875\n",
      "2018-05-04T17:23:41.187499: step 11815, loss 0.209555, acc 0.9375\n",
      "2018-05-04T17:23:42.191999: step 11816, loss 0.350203, acc 0.859375\n",
      "2018-05-04T17:23:43.199120: step 11817, loss 0.225434, acc 0.890625\n",
      "2018-05-04T17:23:44.191040: step 11818, loss 0.359415, acc 0.84375\n",
      "2018-05-04T17:23:45.173129: step 11819, loss 0.294273, acc 0.890625\n",
      "2018-05-04T17:23:46.185485: step 11820, loss 0.305129, acc 0.90625\n",
      "2018-05-04T17:23:47.205937: step 11821, loss 0.315099, acc 0.859375\n",
      "2018-05-04T17:23:48.216444: step 11822, loss 0.296769, acc 0.875\n",
      "2018-05-04T17:23:49.219447: step 11823, loss 0.196702, acc 0.9375\n",
      "2018-05-04T17:23:50.202476: step 11824, loss 0.317734, acc 0.828125\n",
      "2018-05-04T17:23:51.189684: step 11825, loss 0.287473, acc 0.875\n",
      "2018-05-04T17:23:52.284132: step 11826, loss 0.328371, acc 0.890625\n",
      "2018-05-04T17:23:53.338810: step 11827, loss 0.190632, acc 0.9375\n",
      "2018-05-04T17:23:54.368235: step 11828, loss 0.231844, acc 0.953125\n",
      "2018-05-04T17:23:55.352753: step 11829, loss 0.25757, acc 0.890625\n",
      "2018-05-04T17:23:56.351648: step 11830, loss 0.288001, acc 0.84375\n",
      "2018-05-04T17:23:57.352172: step 11831, loss 0.211188, acc 0.90625\n",
      "2018-05-04T17:23:58.401003: step 11832, loss 0.231356, acc 0.90625\n",
      "2018-05-04T17:23:59.417350: step 11833, loss 0.249943, acc 0.875\n",
      "2018-05-04T17:24:00.406179: step 11834, loss 0.436098, acc 0.78125\n",
      "2018-05-04T17:24:01.445587: step 11835, loss 0.34462, acc 0.90625\n",
      "2018-05-04T17:24:02.458489: step 11836, loss 0.445192, acc 0.84375\n",
      "2018-05-04T17:24:03.453831: step 11837, loss 0.217473, acc 0.96875\n",
      "2018-05-04T17:24:04.453070: step 11838, loss 0.44568, acc 0.8125\n",
      "2018-05-04T17:24:05.458663: step 11839, loss 0.27267, acc 0.859375\n",
      "2018-05-04T17:24:06.474011: step 11840, loss 0.369411, acc 0.84375\n",
      "2018-05-04T17:24:07.501432: step 11841, loss 0.318413, acc 0.875\n",
      "2018-05-04T17:24:08.520837: step 11842, loss 0.27082, acc 0.84375\n",
      "2018-05-04T17:24:09.524873: step 11843, loss 0.219764, acc 0.90625\n",
      "2018-05-04T17:24:10.535074: step 11844, loss 0.163876, acc 0.9375\n",
      "2018-05-04T17:24:11.534208: step 11845, loss 0.32478, acc 0.890625\n",
      "2018-05-04T17:24:12.526927: step 11846, loss 0.206346, acc 0.921875\n",
      "2018-05-04T17:24:13.519876: step 11847, loss 0.330535, acc 0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T17:24:14.512992: step 11848, loss 0.232312, acc 0.890625\n",
      "2018-05-04T17:24:15.529539: step 11849, loss 0.324501, acc 0.84375\n",
      "2018-05-04T17:24:16.537788: step 11850, loss 0.375542, acc 0.828125\n",
      "2018-05-04T17:24:17.570705: step 11851, loss 0.304283, acc 0.859375\n",
      "2018-05-04T17:24:18.638444: step 11852, loss 0.206308, acc 0.921875\n",
      "2018-05-04T17:24:19.635587: step 11853, loss 0.172855, acc 0.9375\n",
      "2018-05-04T17:24:20.647613: step 11854, loss 0.242848, acc 0.890625\n",
      "2018-05-04T17:24:21.754007: step 11855, loss 0.458849, acc 0.828125\n",
      "2018-05-04T17:24:22.762678: step 11856, loss 0.314546, acc 0.875\n",
      "2018-05-04T17:24:23.788981: step 11857, loss 0.265985, acc 0.90625\n",
      "2018-05-04T17:24:24.798039: step 11858, loss 0.255093, acc 0.890625\n",
      "2018-05-04T17:24:25.842690: step 11859, loss 0.136544, acc 0.984375\n",
      "2018-05-04T17:24:26.936591: step 11860, loss 0.394252, acc 0.84375\n",
      "2018-05-04T17:24:27.935190: step 11861, loss 0.363953, acc 0.8125\n",
      "2018-05-04T17:24:28.927353: step 11862, loss 0.192589, acc 0.9375\n",
      "2018-05-04T17:24:29.991594: step 11863, loss 0.359577, acc 0.828125\n",
      "2018-05-04T17:24:30.974487: step 11864, loss 0.319536, acc 0.890625\n",
      "2018-05-04T17:24:31.985000: step 11865, loss 0.17872, acc 0.9375\n",
      "2018-05-04T17:24:33.004813: step 11866, loss 0.26446, acc 0.890625\n",
      "2018-05-04T17:24:34.013908: step 11867, loss 0.316359, acc 0.859375\n",
      "2018-05-04T17:24:35.020710: step 11868, loss 0.21016, acc 0.90625\n",
      "2018-05-04T17:24:36.111979: step 11869, loss 0.18803, acc 0.96875\n",
      "2018-05-04T17:24:37.105945: step 11870, loss 0.410993, acc 0.84375\n",
      "2018-05-04T17:24:38.071714: step 11871, loss 0.279919, acc 0.90625\n",
      "2018-05-04T17:24:39.064264: step 11872, loss 0.310356, acc 0.828125\n",
      "2018-05-04T17:24:40.061868: step 11873, loss 0.301348, acc 0.859375\n",
      "2018-05-04T17:24:41.067636: step 11874, loss 0.212063, acc 0.921875\n",
      "2018-05-04T17:24:42.049528: step 11875, loss 0.299713, acc 0.875\n",
      "2018-05-04T17:24:43.046970: step 11876, loss 0.261065, acc 0.90625\n",
      "2018-05-04T17:24:44.064249: step 11877, loss 0.357473, acc 0.859375\n",
      "2018-05-04T17:24:45.168727: step 11878, loss 0.331169, acc 0.875\n",
      "2018-05-04T17:24:46.158855: step 11879, loss 0.221366, acc 0.921875\n",
      "2018-05-04T17:24:47.138707: step 11880, loss 0.235535, acc 0.875\n",
      "2018-05-04T17:24:48.113035: step 11881, loss 0.271676, acc 0.90625\n",
      "2018-05-04T17:24:49.114782: step 11882, loss 0.336288, acc 0.875\n",
      "2018-05-04T17:24:50.103470: step 11883, loss 0.233652, acc 0.90625\n",
      "2018-05-04T17:24:51.098124: step 11884, loss 0.287455, acc 0.90625\n",
      "2018-05-04T17:24:52.086149: step 11885, loss 0.350477, acc 0.8125\n",
      "2018-05-04T17:24:53.091159: step 11886, loss 0.201542, acc 0.90625\n",
      "2018-05-04T17:24:54.073283: step 11887, loss 0.378355, acc 0.875\n",
      "2018-05-04T17:24:55.058326: step 11888, loss 0.227232, acc 0.90625\n",
      "2018-05-04T17:24:56.132131: step 11889, loss 0.21253, acc 0.921875\n",
      "2018-05-04T17:24:57.141700: step 11890, loss 0.203835, acc 0.9375\n",
      "2018-05-04T17:24:58.131419: step 11891, loss 0.285857, acc 0.90625\n",
      "2018-05-04T17:24:59.118597: step 11892, loss 0.392741, acc 0.859375\n",
      "2018-05-04T17:25:00.201721: step 11893, loss 0.310358, acc 0.796875\n",
      "2018-05-04T17:25:01.221906: step 11894, loss 0.402525, acc 0.78125\n",
      "2018-05-04T17:25:02.224769: step 11895, loss 0.234184, acc 0.921875\n",
      "2018-05-04T17:25:03.254197: step 11896, loss 0.254846, acc 0.90625\n",
      "2018-05-04T17:25:04.251564: step 11897, loss 0.46221, acc 0.78125\n",
      "2018-05-04T17:25:05.279911: step 11898, loss 0.333442, acc 0.84375\n",
      "2018-05-04T17:25:06.259886: step 11899, loss 0.26134, acc 0.890625\n",
      "2018-05-04T17:25:07.256394: step 11900, loss 0.274469, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T17:25:09.463265: step 11900, loss 0.238866, acc 0.908\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-11900\n",
      "\n",
      "2018-05-04T17:25:10.562332: step 11901, loss 0.317164, acc 0.875\n",
      "2018-05-04T17:25:11.621633: step 11902, loss 0.373404, acc 0.828125\n",
      "2018-05-04T17:25:12.604481: step 11903, loss 0.217968, acc 0.921875\n",
      "2018-05-04T17:25:13.599117: step 11904, loss 0.367539, acc 0.84375\n",
      "2018-05-04T17:25:14.587683: step 11905, loss 0.209476, acc 0.953125\n",
      "2018-05-04T17:25:15.598321: step 11906, loss 0.405037, acc 0.796875\n",
      "2018-05-04T17:25:16.598040: step 11907, loss 0.297424, acc 0.859375\n",
      "2018-05-04T17:25:17.628671: step 11908, loss 0.397228, acc 0.8125\n",
      "2018-05-04T17:25:18.626862: step 11909, loss 0.24616, acc 0.921875\n",
      "2018-05-04T17:25:19.625574: step 11910, loss 0.320706, acc 0.875\n",
      "2018-05-04T17:25:20.610383: step 11911, loss 0.323464, acc 0.859375\n",
      "2018-05-04T17:25:21.599951: step 11912, loss 0.314221, acc 0.890625\n",
      "2018-05-04T17:25:22.595018: step 11913, loss 0.33537, acc 0.875\n",
      "2018-05-04T17:25:23.601901: step 11914, loss 0.269634, acc 0.90625\n",
      "2018-05-04T17:25:24.585486: step 11915, loss 0.255205, acc 0.890625\n",
      "2018-05-04T17:25:25.589009: step 11916, loss 0.304486, acc 0.859375\n",
      "2018-05-04T17:25:26.580738: step 11917, loss 0.285074, acc 0.875\n",
      "2018-05-04T17:25:27.683718: step 11918, loss 0.407841, acc 0.796875\n",
      "2018-05-04T17:25:28.694744: step 11919, loss 0.17528, acc 0.953125\n",
      "2018-05-04T17:25:29.765023: step 11920, loss 0.411284, acc 0.859375\n",
      "2018-05-04T17:25:30.761404: step 11921, loss 0.334717, acc 0.84375\n",
      "2018-05-04T17:25:31.827558: step 11922, loss 0.267138, acc 0.890625\n",
      "2018-05-04T17:25:32.852395: step 11923, loss 0.211273, acc 0.90625\n",
      "2018-05-04T17:25:33.911288: step 11924, loss 0.316108, acc 0.828125\n",
      "2018-05-04T17:25:35.046404: step 11925, loss 0.232828, acc 0.90625\n",
      "2018-05-04T17:25:36.185102: step 11926, loss 0.276687, acc 0.890625\n",
      "2018-05-04T17:25:37.240209: step 11927, loss 0.263845, acc 0.875\n",
      "2018-05-04T17:25:38.223778: step 11928, loss 0.164614, acc 0.953125\n",
      "2018-05-04T17:25:39.252983: step 11929, loss 0.300478, acc 0.859375\n",
      "2018-05-04T17:25:40.280328: step 11930, loss 0.259655, acc 0.90625\n",
      "2018-05-04T17:25:41.279988: step 11931, loss 0.240056, acc 0.890625\n",
      "2018-05-04T17:25:42.284474: step 11932, loss 0.322838, acc 0.84375\n",
      "2018-05-04T17:25:43.263647: step 11933, loss 0.356997, acc 0.890625\n",
      "2018-05-04T17:25:44.263584: step 11934, loss 0.3033, acc 0.875\n",
      "2018-05-04T17:25:45.267983: step 11935, loss 0.364254, acc 0.78125\n",
      "2018-05-04T17:25:46.257947: step 11936, loss 0.252175, acc 0.890625\n",
      "2018-05-04T17:25:47.237831: step 11937, loss 0.176349, acc 0.90625\n",
      "2018-05-04T17:25:48.214548: step 11938, loss 0.341761, acc 0.84375\n",
      "2018-05-04T17:25:49.191422: step 11939, loss 0.18157, acc 0.9375\n",
      "2018-05-04T17:25:50.183368: step 11940, loss 0.481703, acc 0.765625\n",
      "2018-05-04T17:25:51.168783: step 11941, loss 0.188728, acc 0.921875\n",
      "2018-05-04T17:25:52.195167: step 11942, loss 0.202935, acc 0.90625\n",
      "2018-05-04T17:25:53.185526: step 11943, loss 0.297012, acc 0.921875\n",
      "2018-05-04T17:25:54.167642: step 11944, loss 0.399448, acc 0.78125\n",
      "2018-05-04T17:25:55.145481: step 11945, loss 0.250724, acc 0.875\n",
      "2018-05-04T17:25:56.126157: step 11946, loss 0.219309, acc 0.921875\n",
      "2018-05-04T17:25:57.107333: step 11947, loss 0.201827, acc 0.890625\n",
      "2018-05-04T17:25:58.082575: step 11948, loss 0.398359, acc 0.859375\n",
      "2018-05-04T17:25:59.131339: step 11949, loss 0.295917, acc 0.875\n",
      "2018-05-04T17:26:00.125735: step 11950, loss 0.306944, acc 0.84375\n",
      "2018-05-04T17:26:01.117223: step 11951, loss 0.274178, acc 0.90625\n",
      "2018-05-04T17:26:02.109124: step 11952, loss 0.259073, acc 0.890625\n",
      "2018-05-04T17:26:03.092530: step 11953, loss 0.266719, acc 0.890625\n",
      "2018-05-04T17:26:04.152968: step 11954, loss 0.197493, acc 0.90625\n",
      "2018-05-04T17:26:05.193238: step 11955, loss 0.271004, acc 0.921875\n",
      "2018-05-04T17:26:06.194950: step 11956, loss 0.355425, acc 0.828125\n",
      "2018-05-04T17:26:07.185793: step 11957, loss 0.248069, acc 0.90625\n",
      "2018-05-04T17:26:08.249200: step 11958, loss 0.195868, acc 0.921875\n",
      "2018-05-04T17:26:09.248602: step 11959, loss 0.249091, acc 0.90625\n",
      "2018-05-04T17:26:10.231499: step 11960, loss 0.408753, acc 0.921875\n",
      "2018-05-04T17:26:11.223848: step 11961, loss 0.260629, acc 0.90625\n",
      "2018-05-04T17:26:12.321720: step 11962, loss 0.348416, acc 0.859375\n",
      "2018-05-04T17:26:13.323280: step 11963, loss 0.279524, acc 0.859375\n",
      "2018-05-04T17:26:14.346377: step 11964, loss 0.221743, acc 0.90625\n",
      "2018-05-04T17:26:15.293983: step 11965, loss 0.233318, acc 0.9375\n",
      "2018-05-04T17:26:16.272502: step 11966, loss 0.306268, acc 0.859375\n",
      "2018-05-04T17:26:17.297372: step 11967, loss 0.250836, acc 0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T17:26:18.282244: step 11968, loss 0.282166, acc 0.890625\n",
      "2018-05-04T17:26:19.344524: step 11969, loss 0.344218, acc 0.875\n",
      "2018-05-04T17:26:20.379351: step 11970, loss 0.289065, acc 0.875\n",
      "2018-05-04T17:26:21.419466: step 11971, loss 0.242955, acc 0.890625\n",
      "2018-05-04T17:26:22.407599: step 11972, loss 0.291064, acc 0.875\n",
      "2018-05-04T17:26:23.406441: step 11973, loss 0.324919, acc 0.796875\n",
      "2018-05-04T17:26:24.457856: step 11974, loss 0.181194, acc 0.953125\n",
      "2018-05-04T17:26:25.493766: step 11975, loss 0.253052, acc 0.90625\n",
      "2018-05-04T17:26:26.441907: step 11976, loss 0.13404, acc 0.984375\n",
      "2018-05-04T17:26:27.496694: step 11977, loss 0.237376, acc 0.890625\n",
      "2018-05-04T17:26:28.454448: step 11978, loss 0.156561, acc 0.96875\n",
      "2018-05-04T17:26:29.432996: step 11979, loss 0.337558, acc 0.8125\n",
      "2018-05-04T17:26:30.494675: step 11980, loss 0.219826, acc 0.921875\n",
      "2018-05-04T17:26:31.532551: step 11981, loss 0.274021, acc 0.859375\n",
      "2018-05-04T17:26:32.496727: step 11982, loss 0.224983, acc 0.9375\n",
      "2018-05-04T17:26:33.507939: step 11983, loss 0.278713, acc 0.859375\n",
      "2018-05-04T17:26:34.516753: step 11984, loss 0.204327, acc 0.9375\n",
      "2018-05-04T17:26:35.558538: step 11985, loss 0.399274, acc 0.890625\n",
      "2018-05-04T17:26:36.516764: step 11986, loss 0.301396, acc 0.875\n",
      "2018-05-04T17:26:37.479817: step 11987, loss 0.257147, acc 0.890625\n",
      "2018-05-04T17:26:38.514636: step 11988, loss 0.261803, acc 0.921875\n",
      "2018-05-04T17:26:39.485964: step 11989, loss 0.235191, acc 0.875\n",
      "2018-05-04T17:26:40.541150: step 11990, loss 0.172682, acc 0.9375\n",
      "2018-05-04T17:26:41.638082: step 11991, loss 0.190695, acc 0.953125\n",
      "2018-05-04T17:26:42.739951: step 11992, loss 0.200665, acc 0.921875\n",
      "2018-05-04T17:26:43.837295: step 11993, loss 0.188815, acc 0.9375\n",
      "2018-05-04T17:26:44.952582: step 11994, loss 0.221467, acc 0.921875\n",
      "2018-05-04T17:26:46.045713: step 11995, loss 0.398959, acc 0.796875\n",
      "2018-05-04T17:26:47.061772: step 11996, loss 0.360636, acc 0.859375\n",
      "2018-05-04T17:26:48.099571: step 11997, loss 0.245863, acc 0.875\n",
      "2018-05-04T17:26:49.160375: step 11998, loss 0.257897, acc 0.90625\n",
      "2018-05-04T17:26:50.162135: step 11999, loss 0.346342, acc 0.828125\n",
      "2018-05-04T17:26:51.177228: step 12000, loss 0.41589, acc 0.828125\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T17:26:54.513426: step 12000, loss 0.227953, acc 0.926\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-12000\n",
      "\n",
      "2018-05-04T17:26:55.658901: step 12001, loss 0.285399, acc 0.875\n",
      "2018-05-04T17:26:56.740155: step 12002, loss 0.373664, acc 0.875\n",
      "2018-05-04T17:26:57.776700: step 12003, loss 0.237202, acc 0.90625\n",
      "2018-05-04T17:26:58.809299: step 12004, loss 0.402247, acc 0.859375\n",
      "2018-05-04T17:26:59.849016: step 12005, loss 0.148287, acc 0.9375\n",
      "2018-05-04T17:27:01.057688: step 12006, loss 0.287223, acc 0.90625\n",
      "2018-05-04T17:27:02.124169: step 12007, loss 0.242935, acc 0.890625\n",
      "2018-05-04T17:27:03.144187: step 12008, loss 0.291951, acc 0.859375\n",
      "2018-05-04T17:27:04.250799: step 12009, loss 0.248654, acc 0.890625\n",
      "2018-05-04T17:27:05.338365: step 12010, loss 0.18438, acc 0.921875\n",
      "2018-05-04T17:27:06.339461: step 12011, loss 0.414708, acc 0.875\n",
      "2018-05-04T17:27:07.400129: step 12012, loss 0.227034, acc 0.9375\n",
      "2018-05-04T17:27:08.484940: step 12013, loss 0.371807, acc 0.875\n",
      "2018-05-04T17:27:09.468091: step 12014, loss 0.281688, acc 0.9375\n",
      "2018-05-04T17:27:10.440040: step 12015, loss 0.304815, acc 0.859375\n",
      "2018-05-04T17:27:11.454869: step 12016, loss 0.275306, acc 0.859375\n",
      "2018-05-04T17:27:12.450597: step 12017, loss 0.28119, acc 0.859375\n",
      "2018-05-04T17:27:13.451874: step 12018, loss 0.251362, acc 0.890625\n",
      "2018-05-04T17:27:14.454186: step 12019, loss 0.220565, acc 0.921875\n",
      "2018-05-04T17:27:15.442744: step 12020, loss 0.220502, acc 0.90625\n",
      "2018-05-04T17:27:16.446748: step 12021, loss 0.218803, acc 0.890625\n",
      "2018-05-04T17:27:17.477632: step 12022, loss 0.183388, acc 0.9375\n",
      "2018-05-04T17:27:18.484871: step 12023, loss 0.235263, acc 0.921875\n",
      "2018-05-04T17:27:19.518755: step 12024, loss 0.371712, acc 0.859375\n",
      "2018-05-04T17:27:20.608586: step 12025, loss 0.313214, acc 0.859375\n",
      "2018-05-04T17:27:21.613577: step 12026, loss 0.290855, acc 0.859375\n",
      "2018-05-04T17:27:22.666079: step 12027, loss 0.246272, acc 0.859375\n",
      "2018-05-04T17:27:23.645343: step 12028, loss 0.272844, acc 0.859375\n",
      "2018-05-04T17:27:24.631264: step 12029, loss 0.304334, acc 0.859375\n",
      "2018-05-04T17:27:25.637837: step 12030, loss 0.1744, acc 0.953125\n",
      "2018-05-04T17:27:26.673391: step 12031, loss 0.371473, acc 0.875\n",
      "2018-05-04T17:27:27.699206: step 12032, loss 0.349372, acc 0.890625\n",
      "2018-05-04T17:27:28.722534: step 12033, loss 0.182276, acc 0.921875\n",
      "2018-05-04T17:27:29.724172: step 12034, loss 0.388706, acc 0.890625\n",
      "2018-05-04T17:27:30.728886: step 12035, loss 0.283848, acc 0.875\n",
      "2018-05-04T17:27:31.731119: step 12036, loss 0.309335, acc 0.875\n",
      "2018-05-04T17:27:32.714497: step 12037, loss 0.187932, acc 0.9375\n",
      "2018-05-04T17:27:33.713232: step 12038, loss 0.293797, acc 0.90625\n",
      "2018-05-04T17:27:34.755301: step 12039, loss 0.287866, acc 0.90625\n",
      "2018-05-04T17:27:35.788769: step 12040, loss 0.331377, acc 0.859375\n",
      "2018-05-04T17:27:36.883105: step 12041, loss 0.291362, acc 0.921875\n",
      "2018-05-04T17:27:37.885716: step 12042, loss 0.448424, acc 0.84375\n",
      "2018-05-04T17:27:38.869419: step 12043, loss 0.161154, acc 0.921875\n",
      "2018-05-04T17:27:39.863023: step 12044, loss 0.341218, acc 0.875\n",
      "2018-05-04T17:27:40.864986: step 12045, loss 0.200463, acc 0.921875\n",
      "2018-05-04T17:27:41.877528: step 12046, loss 0.467253, acc 0.8125\n",
      "2018-05-04T17:27:42.871950: step 12047, loss 0.22827, acc 0.890625\n",
      "2018-05-04T17:27:43.884216: step 12048, loss 0.109569, acc 1\n",
      "2018-05-04T17:27:44.898757: step 12049, loss 0.264058, acc 0.90625\n",
      "2018-05-04T17:27:45.906512: step 12050, loss 0.294135, acc 0.875\n",
      "2018-05-04T17:27:46.929913: step 12051, loss 0.258335, acc 0.921875\n",
      "2018-05-04T17:27:47.950966: step 12052, loss 0.298819, acc 0.859375\n",
      "2018-05-04T17:27:48.969256: step 12053, loss 0.306688, acc 0.90625\n",
      "2018-05-04T17:27:49.997786: step 12054, loss 0.19285, acc 0.921875\n",
      "2018-05-04T17:27:51.016368: step 12055, loss 0.278206, acc 0.890625\n",
      "2018-05-04T17:27:52.029734: step 12056, loss 0.427634, acc 0.859375\n",
      "2018-05-04T17:27:53.017894: step 12057, loss 0.230582, acc 0.890625\n",
      "2018-05-04T17:27:54.104749: step 12058, loss 0.229825, acc 0.890625\n",
      "2018-05-04T17:27:55.081313: step 12059, loss 0.136178, acc 0.953125\n",
      "2018-05-04T17:27:56.057071: step 12060, loss 0.217148, acc 0.921875\n",
      "2018-05-04T17:27:57.030413: step 12061, loss 0.196088, acc 0.921875\n",
      "2018-05-04T17:27:58.032095: step 12062, loss 0.166639, acc 0.9375\n",
      "2018-05-04T17:27:59.031725: step 12063, loss 0.263702, acc 0.90625\n",
      "2018-05-04T17:28:00.030918: step 12064, loss 0.166348, acc 0.9375\n",
      "2018-05-04T17:28:01.040455: step 12065, loss 0.371059, acc 0.828125\n",
      "2018-05-04T17:28:02.059671: step 12066, loss 0.275336, acc 0.9375\n",
      "2018-05-04T17:28:03.078797: step 12067, loss 0.307983, acc 0.890625\n",
      "2018-05-04T17:28:04.130386: step 12068, loss 0.305357, acc 0.84375\n",
      "2018-05-04T17:28:05.139632: step 12069, loss 0.380818, acc 0.890625\n",
      "2018-05-04T17:28:06.162216: step 12070, loss 0.26894, acc 0.90625\n",
      "2018-05-04T17:28:07.176956: step 12071, loss 0.283076, acc 0.890625\n",
      "2018-05-04T17:28:08.166583: step 12072, loss 0.285918, acc 0.90625\n",
      "2018-05-04T17:28:09.136319: step 12073, loss 0.250729, acc 0.90625\n",
      "2018-05-04T17:28:10.117436: step 12074, loss 0.227413, acc 0.90625\n",
      "2018-05-04T17:28:11.118858: step 12075, loss 0.267311, acc 0.890625\n",
      "2018-05-04T17:28:12.119215: step 12076, loss 0.396942, acc 0.859375\n",
      "2018-05-04T17:28:13.182406: step 12077, loss 0.414845, acc 0.84375\n",
      "2018-05-04T17:28:14.182524: step 12078, loss 0.163365, acc 0.953125\n",
      "2018-05-04T17:28:15.225612: step 12079, loss 0.203898, acc 0.953125\n",
      "2018-05-04T17:28:16.187736: step 12080, loss 0.350708, acc 0.84375\n",
      "2018-05-04T17:28:17.171922: step 12081, loss 0.289731, acc 0.921875\n",
      "2018-05-04T17:28:18.143429: step 12082, loss 0.228969, acc 0.96875\n",
      "2018-05-04T17:28:19.144416: step 12083, loss 0.380906, acc 0.84375\n",
      "2018-05-04T17:28:20.140513: step 12084, loss 0.144247, acc 0.96875\n",
      "2018-05-04T17:28:21.150517: step 12085, loss 0.266481, acc 0.921875\n",
      "2018-05-04T17:28:22.145012: step 12086, loss 0.214659, acc 0.90625\n",
      "2018-05-04T17:28:23.155827: step 12087, loss 0.248473, acc 0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T17:28:24.202029: step 12088, loss 0.199446, acc 0.90625\n",
      "2018-05-04T17:28:25.205237: step 12089, loss 0.385606, acc 0.828125\n",
      "2018-05-04T17:28:26.197018: step 12090, loss 0.262054, acc 0.875\n",
      "2018-05-04T17:28:27.266820: step 12091, loss 0.189916, acc 0.9375\n",
      "2018-05-04T17:28:28.253723: step 12092, loss 0.325309, acc 0.859375\n",
      "2018-05-04T17:28:29.249760: step 12093, loss 0.261059, acc 0.84375\n",
      "2018-05-04T17:28:30.245859: step 12094, loss 0.231219, acc 0.90625\n",
      "2018-05-04T17:28:31.291989: step 12095, loss 0.191677, acc 0.921875\n",
      "2018-05-04T17:28:32.279037: step 12096, loss 0.303184, acc 0.90625\n",
      "2018-05-04T17:28:33.387995: step 12097, loss 0.143079, acc 0.96875\n",
      "2018-05-04T17:28:34.468688: step 12098, loss 0.253394, acc 0.90625\n",
      "2018-05-04T17:28:35.519392: step 12099, loss 0.17805, acc 0.953125\n",
      "2018-05-04T17:28:36.562649: step 12100, loss 0.287841, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T17:28:38.820849: step 12100, loss 0.239424, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-12100\n",
      "\n",
      "2018-05-04T17:28:39.953684: step 12101, loss 0.330571, acc 0.859375\n",
      "2018-05-04T17:28:40.963108: step 12102, loss 0.261241, acc 0.90625\n",
      "2018-05-04T17:28:42.066543: step 12103, loss 0.291595, acc 0.90625\n",
      "2018-05-04T17:28:43.096363: step 12104, loss 0.366342, acc 0.890625\n",
      "2018-05-04T17:28:44.101521: step 12105, loss 0.196064, acc 0.890625\n",
      "2018-05-04T17:28:45.083530: step 12106, loss 0.34027, acc 0.875\n",
      "2018-05-04T17:28:46.057837: step 12107, loss 0.385874, acc 0.828125\n",
      "2018-05-04T17:28:47.036241: step 12108, loss 0.29805, acc 0.890625\n",
      "2018-05-04T17:28:48.023855: step 12109, loss 0.241847, acc 0.9375\n",
      "2018-05-04T17:28:49.029269: step 12110, loss 0.389815, acc 0.796875\n",
      "2018-05-04T17:28:50.090590: step 12111, loss 0.208129, acc 0.921875\n",
      "2018-05-04T17:28:51.081710: step 12112, loss 0.290232, acc 0.875\n",
      "2018-05-04T17:28:52.087205: step 12113, loss 0.272152, acc 0.859375\n",
      "2018-05-04T17:28:53.068108: step 12114, loss 0.286415, acc 0.828125\n",
      "2018-05-04T17:28:54.077414: step 12115, loss 0.196411, acc 0.921875\n",
      "2018-05-04T17:28:55.048922: step 12116, loss 0.291296, acc 0.875\n",
      "2018-05-04T17:28:56.029888: step 12117, loss 0.404536, acc 0.828125\n",
      "2018-05-04T17:28:57.010177: step 12118, loss 0.236127, acc 0.921875\n",
      "2018-05-04T17:28:58.000841: step 12119, loss 0.369615, acc 0.890625\n",
      "2018-05-04T17:28:59.084006: step 12120, loss 0.273346, acc 0.875\n",
      "2018-05-04T17:29:00.058960: step 12121, loss 0.342418, acc 0.875\n",
      "2018-05-04T17:29:01.054027: step 12122, loss 0.19306, acc 0.890625\n",
      "2018-05-04T17:29:02.090836: step 12123, loss 0.359829, acc 0.875\n",
      "2018-05-04T17:29:03.052740: step 12124, loss 0.309001, acc 0.84375\n",
      "2018-05-04T17:29:04.039870: step 12125, loss 0.240253, acc 0.90625\n",
      "2018-05-04T17:29:05.102202: step 12126, loss 0.325014, acc 0.828125\n",
      "2018-05-04T17:29:06.103255: step 12127, loss 0.200313, acc 0.890625\n",
      "2018-05-04T17:29:07.084373: step 12128, loss 0.269237, acc 0.890625\n",
      "2018-05-04T17:29:08.090816: step 12129, loss 0.321073, acc 0.828125\n",
      "2018-05-04T17:29:09.129827: step 12130, loss 0.324164, acc 0.828125\n",
      "2018-05-04T17:29:10.130589: step 12131, loss 0.269258, acc 0.875\n",
      "2018-05-04T17:29:11.100191: step 12132, loss 0.250094, acc 0.875\n",
      "2018-05-04T17:29:12.081086: step 12133, loss 0.397537, acc 0.84375\n",
      "2018-05-04T17:29:13.068487: step 12134, loss 0.177711, acc 0.9375\n",
      "2018-05-04T17:29:14.147676: step 12135, loss 0.248677, acc 0.875\n",
      "2018-05-04T17:29:15.150343: step 12136, loss 0.210552, acc 0.9375\n",
      "2018-05-04T17:29:16.124206: step 12137, loss 0.27118, acc 0.90625\n",
      "2018-05-04T17:29:17.103199: step 12138, loss 0.269946, acc 0.875\n",
      "2018-05-04T17:29:18.121560: step 12139, loss 0.319472, acc 0.90625\n",
      "2018-05-04T17:29:19.194143: step 12140, loss 0.182272, acc 0.953125\n",
      "2018-05-04T17:29:20.176842: step 12141, loss 0.323126, acc 0.828125\n",
      "2018-05-04T17:29:21.167604: step 12142, loss 0.205239, acc 0.921875\n",
      "2018-05-04T17:29:22.150808: step 12143, loss 0.262807, acc 0.9375\n",
      "2018-05-04T17:29:23.196462: step 12144, loss 0.494096, acc 0.8125\n",
      "2018-05-04T17:29:24.252850: step 12145, loss 0.144487, acc 0.96875\n",
      "2018-05-04T17:29:25.284670: step 12146, loss 0.269511, acc 0.84375\n",
      "2018-05-04T17:29:26.345978: step 12147, loss 0.164205, acc 0.90625\n",
      "2018-05-04T17:29:27.303537: step 12148, loss 0.400145, acc 0.890625\n",
      "2018-05-04T17:29:28.268111: step 12149, loss 0.206839, acc 0.9375\n",
      "2018-05-04T17:29:29.296482: step 12150, loss 0.124571, acc 0.96875\n",
      "2018-05-04T17:29:30.405229: step 12151, loss 0.267654, acc 0.890625\n",
      "2018-05-04T17:29:31.476896: step 12152, loss 0.167515, acc 0.9375\n",
      "2018-05-04T17:29:32.538811: step 12153, loss 0.149246, acc 0.953125\n",
      "2018-05-04T17:29:33.499682: step 12154, loss 0.298791, acc 0.84375\n",
      "2018-05-04T17:29:34.525342: step 12155, loss 0.390935, acc 0.84375\n",
      "2018-05-04T17:29:35.509829: step 12156, loss 0.419946, acc 0.8125\n",
      "2018-05-04T17:29:36.548135: step 12157, loss 0.37682, acc 0.859375\n",
      "2018-05-04T17:29:37.510306: step 12158, loss 0.290812, acc 0.890625\n",
      "2018-05-04T17:29:38.593406: step 12159, loss 0.36893, acc 0.875\n",
      "2018-05-04T17:29:39.586470: step 12160, loss 0.241036, acc 0.90625\n",
      "2018-05-04T17:29:40.582825: step 12161, loss 0.203374, acc 0.90625\n",
      "2018-05-04T17:29:41.613789: step 12162, loss 0.286003, acc 0.90625\n",
      "2018-05-04T17:29:42.637843: step 12163, loss 0.328985, acc 0.828125\n",
      "2018-05-04T17:29:43.686261: step 12164, loss 0.332727, acc 0.875\n",
      "2018-05-04T17:29:44.764344: step 12165, loss 0.321062, acc 0.875\n",
      "2018-05-04T17:29:45.827388: step 12166, loss 0.463078, acc 0.75\n",
      "2018-05-04T17:29:46.873159: step 12167, loss 0.220749, acc 0.875\n",
      "2018-05-04T17:29:47.922050: step 12168, loss 0.307694, acc 0.875\n",
      "2018-05-04T17:29:48.972591: step 12169, loss 0.332102, acc 0.859375\n",
      "2018-05-04T17:29:49.994402: step 12170, loss 0.410108, acc 0.828125\n",
      "2018-05-04T17:29:51.034909: step 12171, loss 0.164303, acc 0.953125\n",
      "2018-05-04T17:29:52.074419: step 12172, loss 0.238417, acc 0.90625\n",
      "2018-05-04T17:29:53.109118: step 12173, loss 0.357052, acc 0.921875\n",
      "2018-05-04T17:29:54.162630: step 12174, loss 0.36939, acc 0.859375\n",
      "2018-05-04T17:29:55.172521: step 12175, loss 0.286201, acc 0.859375\n",
      "2018-05-04T17:29:56.117552: step 12176, loss 0.203306, acc 0.921875\n",
      "2018-05-04T17:29:57.145130: step 12177, loss 0.37692, acc 0.84375\n",
      "2018-05-04T17:29:58.200686: step 12178, loss 0.268216, acc 0.90625\n",
      "2018-05-04T17:29:59.169406: step 12179, loss 0.311023, acc 0.796875\n",
      "2018-05-04T17:30:00.160913: step 12180, loss 0.302571, acc 0.90625\n",
      "2018-05-04T17:30:01.200805: step 12181, loss 0.266962, acc 0.84375\n",
      "2018-05-04T17:30:02.222424: step 12182, loss 0.420782, acc 0.890625\n",
      "2018-05-04T17:30:03.256387: step 12183, loss 0.225025, acc 0.921875\n",
      "2018-05-04T17:30:04.334435: step 12184, loss 0.246024, acc 0.9375\n",
      "2018-05-04T17:30:05.413800: step 12185, loss 0.339699, acc 0.859375\n",
      "2018-05-04T17:30:06.394449: step 12186, loss 0.25922, acc 0.90625\n",
      "2018-05-04T17:30:07.342173: step 12187, loss 0.200767, acc 0.9375\n",
      "2018-05-04T17:30:08.386252: step 12188, loss 0.303438, acc 0.859375\n",
      "2018-05-04T17:30:09.438270: step 12189, loss 0.150556, acc 0.9375\n",
      "2018-05-04T17:30:10.463488: step 12190, loss 0.251004, acc 0.875\n",
      "2018-05-04T17:30:11.520777: step 12191, loss 0.149308, acc 0.96875\n",
      "2018-05-04T17:30:12.570108: step 12192, loss 0.176754, acc 0.9375\n",
      "2018-05-04T17:30:13.611997: step 12193, loss 0.348478, acc 0.890625\n",
      "2018-05-04T17:30:14.622058: step 12194, loss 0.318832, acc 0.828125\n",
      "2018-05-04T17:30:15.656223: step 12195, loss 0.260494, acc 0.90625\n",
      "2018-05-04T17:30:16.587200: step 12196, loss 0.290387, acc 0.890625\n",
      "2018-05-04T17:30:17.641165: step 12197, loss 0.300815, acc 0.9375\n",
      "2018-05-04T17:30:18.713307: step 12198, loss 0.248435, acc 0.890625\n",
      "2018-05-04T17:30:19.802089: step 12199, loss 0.270944, acc 0.875\n",
      "2018-05-04T17:30:20.857440: step 12200, loss 0.324963, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T17:30:23.871897: step 12200, loss 0.245645, acc 0.912\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-12200\n",
      "\n",
      "2018-05-04T17:30:25.000175: step 12201, loss 0.510668, acc 0.859375\n",
      "2018-05-04T17:30:25.992008: step 12202, loss 0.139471, acc 0.953125\n",
      "2018-05-04T17:30:27.014288: step 12203, loss 0.174008, acc 0.96875\n",
      "2018-05-04T17:30:28.083183: step 12204, loss 0.29889, acc 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T17:30:29.159770: step 12205, loss 0.268993, acc 0.828125\n",
      "2018-05-04T17:30:30.237751: step 12206, loss 0.229498, acc 0.90625\n",
      "2018-05-04T17:30:31.293516: step 12207, loss 0.326667, acc 0.921875\n",
      "2018-05-04T17:30:32.364167: step 12208, loss 0.323114, acc 0.859375\n",
      "2018-05-04T17:30:33.412363: step 12209, loss 0.370883, acc 0.84375\n",
      "2018-05-04T17:30:34.429611: step 12210, loss 0.276337, acc 0.859375\n",
      "2018-05-04T17:30:35.440409: step 12211, loss 0.322653, acc 0.890625\n",
      "2018-05-04T17:30:36.444543: step 12212, loss 0.268278, acc 0.890625\n",
      "2018-05-04T17:30:37.481887: step 12213, loss 0.263409, acc 0.890625\n",
      "2018-05-04T17:30:38.484472: step 12214, loss 0.16735, acc 0.9375\n",
      "2018-05-04T17:30:39.619099: step 12215, loss 0.226557, acc 0.875\n",
      "2018-05-04T17:30:40.639419: step 12216, loss 0.24988, acc 0.84375\n",
      "2018-05-04T17:30:41.697068: step 12217, loss 0.19396, acc 0.921875\n",
      "2018-05-04T17:30:42.707302: step 12218, loss 0.262311, acc 0.875\n",
      "2018-05-04T17:30:43.738001: step 12219, loss 0.341444, acc 0.859375\n",
      "2018-05-04T17:30:44.832754: step 12220, loss 0.284851, acc 0.859375\n",
      "2018-05-04T17:30:45.888637: step 12221, loss 0.210786, acc 0.921875\n",
      "2018-05-04T17:30:46.885506: step 12222, loss 0.30447, acc 0.875\n",
      "2018-05-04T17:30:47.943893: step 12223, loss 0.367946, acc 0.875\n",
      "2018-05-04T17:30:48.929275: step 12224, loss 0.432279, acc 0.875\n",
      "2018-05-04T17:30:49.929790: step 12225, loss 0.291074, acc 0.859375\n",
      "2018-05-04T17:30:50.918636: step 12226, loss 0.30067, acc 0.890625\n",
      "2018-05-04T17:30:51.984395: step 12227, loss 0.289743, acc 0.875\n",
      "2018-05-04T17:30:52.975362: step 12228, loss 0.408396, acc 0.78125\n",
      "2018-05-04T17:30:53.969488: step 12229, loss 0.406891, acc 0.828125\n",
      "2018-05-04T17:30:54.932685: step 12230, loss 0.248705, acc 0.890625\n",
      "2018-05-04T17:30:55.950009: step 12231, loss 0.395135, acc 0.828125\n",
      "2018-05-04T17:30:56.965101: step 12232, loss 0.173087, acc 0.953125\n",
      "2018-05-04T17:30:57.967515: step 12233, loss 0.167411, acc 0.9375\n",
      "2018-05-04T17:30:58.987752: step 12234, loss 0.319955, acc 0.859375\n",
      "2018-05-04T17:30:59.985055: step 12235, loss 0.400181, acc 0.734375\n",
      "2018-05-04T17:31:01.005648: step 12236, loss 0.207752, acc 0.953125\n",
      "2018-05-04T17:31:02.032447: step 12237, loss 0.442361, acc 0.875\n",
      "2018-05-04T17:31:03.020930: step 12238, loss 0.218218, acc 0.890625\n",
      "2018-05-04T17:31:04.021356: step 12239, loss 0.302842, acc 0.890625\n",
      "2018-05-04T17:31:05.028992: step 12240, loss 0.230836, acc 0.90625\n",
      "2018-05-04T17:31:06.136336: step 12241, loss 0.33074, acc 0.84375\n",
      "2018-05-04T17:31:07.163566: step 12242, loss 0.333574, acc 0.84375\n",
      "2018-05-04T17:31:08.174133: step 12243, loss 0.302611, acc 0.90625\n",
      "2018-05-04T17:31:09.175115: step 12244, loss 0.206982, acc 0.921875\n",
      "2018-05-04T17:31:10.166823: step 12245, loss 0.136631, acc 0.96875\n",
      "2018-05-04T17:31:11.186787: step 12246, loss 0.187821, acc 0.9375\n",
      "2018-05-04T17:31:12.188276: step 12247, loss 0.254502, acc 0.890625\n",
      "2018-05-04T17:31:13.213495: step 12248, loss 0.298146, acc 0.9375\n",
      "2018-05-04T17:31:14.253817: step 12249, loss 0.211661, acc 0.953125\n",
      "2018-05-04T17:31:15.356597: step 12250, loss 0.231156, acc 0.90625\n",
      "2018-05-04T17:31:16.352329: step 12251, loss 0.320385, acc 0.84375\n",
      "2018-05-04T17:31:17.357268: step 12252, loss 0.270274, acc 0.890625\n",
      "2018-05-04T17:31:18.345054: step 12253, loss 0.406673, acc 0.859375\n",
      "2018-05-04T17:31:19.336715: step 12254, loss 0.211467, acc 0.921875\n",
      "2018-05-04T17:31:20.333399: step 12255, loss 0.255129, acc 0.890625\n",
      "2018-05-04T17:31:21.363177: step 12256, loss 0.189133, acc 0.9375\n",
      "2018-05-04T17:31:22.383013: step 12257, loss 0.345125, acc 0.875\n",
      "2018-05-04T17:31:23.417709: step 12258, loss 0.263418, acc 0.859375\n",
      "2018-05-04T17:31:24.426738: step 12259, loss 0.256639, acc 0.828125\n",
      "2018-05-04T17:31:25.438808: step 12260, loss 0.247927, acc 0.890625\n",
      "2018-05-04T17:31:26.452645: step 12261, loss 0.213303, acc 0.921875\n",
      "2018-05-04T17:31:27.492312: step 12262, loss 0.239766, acc 0.90625\n",
      "2018-05-04T17:31:28.464097: step 12263, loss 0.314665, acc 0.859375\n",
      "2018-05-04T17:31:29.454269: step 12264, loss 0.209992, acc 0.921875\n",
      "2018-05-04T17:31:30.444947: step 12265, loss 0.404596, acc 0.828125\n",
      "2018-05-04T17:31:31.431490: step 12266, loss 0.172198, acc 0.9375\n",
      "2018-05-04T17:31:32.451194: step 12267, loss 0.361379, acc 0.828125\n",
      "2018-05-04T17:31:33.565744: step 12268, loss 0.419666, acc 0.84375\n",
      "2018-05-04T17:31:34.630940: step 12269, loss 0.288381, acc 0.890625\n",
      "2018-05-04T17:31:35.741193: step 12270, loss 0.300027, acc 0.859375\n",
      "2018-05-04T17:31:36.816431: step 12271, loss 0.219616, acc 0.90625\n",
      "2018-05-04T17:31:37.812907: step 12272, loss 0.260323, acc 0.90625\n",
      "2018-05-04T17:31:38.817696: step 12273, loss 0.286845, acc 0.890625\n",
      "2018-05-04T17:31:39.864983: step 12274, loss 0.23288, acc 0.921875\n",
      "2018-05-04T17:31:40.872171: step 12275, loss 0.402397, acc 0.84375\n",
      "2018-05-04T17:31:41.887672: step 12276, loss 0.24878, acc 0.90625\n",
      "2018-05-04T17:31:42.957510: step 12277, loss 0.183023, acc 0.9375\n",
      "2018-05-04T17:31:44.045635: step 12278, loss 0.264123, acc 0.875\n",
      "2018-05-04T17:31:44.997343: step 12279, loss 0.335951, acc 0.859375\n",
      "2018-05-04T17:31:45.978510: step 12280, loss 0.331893, acc 0.875\n",
      "2018-05-04T17:31:46.944371: step 12281, loss 0.272163, acc 0.90625\n",
      "2018-05-04T17:31:48.026677: step 12282, loss 0.190541, acc 0.9375\n",
      "2018-05-04T17:31:49.037530: step 12283, loss 0.131253, acc 0.96875\n",
      "2018-05-04T17:31:50.007623: step 12284, loss 0.316189, acc 0.890625\n",
      "2018-05-04T17:31:50.995123: step 12285, loss 0.369922, acc 0.828125\n",
      "2018-05-04T17:31:52.002143: step 12286, loss 0.156154, acc 0.921875\n",
      "2018-05-04T17:31:52.980080: step 12287, loss 0.277033, acc 0.890625\n",
      "2018-05-04T17:31:53.964281: step 12288, loss 0.196557, acc 0.921875\n",
      "2018-05-04T17:31:54.958358: step 12289, loss 0.246799, acc 0.90625\n",
      "2018-05-04T17:31:55.951931: step 12290, loss 0.244764, acc 0.90625\n",
      "2018-05-04T17:31:56.953580: step 12291, loss 0.262681, acc 0.875\n",
      "2018-05-04T17:31:57.942731: step 12292, loss 0.196362, acc 0.921875\n",
      "2018-05-04T17:31:58.955701: step 12293, loss 0.172812, acc 0.921875\n",
      "2018-05-04T17:31:59.955304: step 12294, loss 0.225578, acc 0.90625\n",
      "2018-05-04T17:32:00.979042: step 12295, loss 0.36127, acc 0.875\n",
      "2018-05-04T17:32:01.962482: step 12296, loss 0.18278, acc 0.9375\n",
      "2018-05-04T17:32:02.912970: step 12297, loss 0.544438, acc 0.765625\n",
      "2018-05-04T17:32:03.880363: step 12298, loss 0.171373, acc 0.953125\n",
      "2018-05-04T17:32:04.950821: step 12299, loss 0.257105, acc 0.890625\n",
      "2018-05-04T17:32:06.012394: step 12300, loss 0.224544, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T17:32:08.183519: step 12300, loss 0.236083, acc 0.918\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-12300\n",
      "\n",
      "2018-05-04T17:32:09.260001: step 12301, loss 0.341211, acc 0.84375\n",
      "2018-05-04T17:32:10.284976: step 12302, loss 0.356536, acc 0.90625\n",
      "2018-05-04T17:32:11.311166: step 12303, loss 0.156423, acc 0.96875\n",
      "2018-05-04T17:32:12.315426: step 12304, loss 0.365, acc 0.875\n",
      "2018-05-04T17:32:13.326732: step 12305, loss 0.159728, acc 0.9375\n",
      "2018-05-04T17:32:14.324841: step 12306, loss 0.34343, acc 0.859375\n",
      "2018-05-04T17:32:15.311738: step 12307, loss 0.467341, acc 0.90625\n",
      "2018-05-04T17:32:16.294231: step 12308, loss 0.200994, acc 0.921875\n",
      "2018-05-04T17:32:17.271838: step 12309, loss 0.311345, acc 0.828125\n",
      "2018-05-04T17:32:18.233358: step 12310, loss 0.379894, acc 0.859375\n",
      "2018-05-04T17:32:19.272685: step 12311, loss 0.324861, acc 0.859375\n",
      "2018-05-04T17:32:20.259314: step 12312, loss 0.374976, acc 0.828125\n",
      "2018-05-04T17:32:21.245072: step 12313, loss 0.283021, acc 0.921875\n",
      "2018-05-04T17:32:22.222589: step 12314, loss 0.252007, acc 0.859375\n",
      "2018-05-04T17:32:23.297027: step 12315, loss 0.25712, acc 0.890625\n",
      "2018-05-04T17:32:24.297133: step 12316, loss 0.24845, acc 0.921875\n",
      "2018-05-04T17:32:25.302728: step 12317, loss 0.29947, acc 0.859375\n",
      "2018-05-04T17:32:26.265462: step 12318, loss 0.281996, acc 0.875\n",
      "2018-05-04T17:32:27.220537: step 12319, loss 0.177863, acc 0.921875\n",
      "2018-05-04T17:32:28.180001: step 12320, loss 0.221938, acc 0.875\n",
      "2018-05-04T17:32:29.162270: step 12321, loss 0.232862, acc 0.9375\n",
      "2018-05-04T17:32:30.160068: step 12322, loss 0.34014, acc 0.828125\n",
      "2018-05-04T17:32:31.163906: step 12323, loss 0.293689, acc 0.84375\n",
      "2018-05-04T17:32:32.217690: step 12324, loss 0.268269, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T17:32:33.224771: step 12325, loss 0.305093, acc 0.890625\n",
      "2018-05-04T17:32:34.220328: step 12326, loss 0.383329, acc 0.890625\n",
      "2018-05-04T17:32:35.230850: step 12327, loss 0.26254, acc 0.859375\n",
      "2018-05-04T17:32:36.224458: step 12328, loss 0.222316, acc 0.921875\n",
      "2018-05-04T17:32:37.200959: step 12329, loss 0.300104, acc 0.859375\n",
      "2018-05-04T17:32:38.185467: step 12330, loss 0.169619, acc 0.953125\n",
      "2018-05-04T17:32:39.183851: step 12331, loss 0.315974, acc 0.859375\n",
      "2018-05-04T17:32:40.176311: step 12332, loss 0.350961, acc 0.8125\n",
      "2018-05-04T17:32:41.179730: step 12333, loss 0.265853, acc 0.890625\n",
      "2018-05-04T17:32:42.141588: step 12334, loss 0.209536, acc 0.90625\n",
      "2018-05-04T17:32:43.112839: step 12335, loss 0.212551, acc 0.921875\n",
      "2018-05-04T17:32:44.116203: step 12336, loss 0.391626, acc 0.875\n",
      "2018-05-04T17:32:45.093678: step 12337, loss 0.24913, acc 0.859375\n",
      "2018-05-04T17:32:46.077812: step 12338, loss 0.149977, acc 0.96875\n",
      "2018-05-04T17:32:47.061627: step 12339, loss 0.281492, acc 0.859375\n",
      "2018-05-04T17:32:48.056244: step 12340, loss 0.235089, acc 0.890625\n",
      "2018-05-04T17:32:49.048834: step 12341, loss 0.263517, acc 0.890625\n",
      "2018-05-04T17:32:50.031202: step 12342, loss 0.335331, acc 0.875\n",
      "2018-05-04T17:32:51.017072: step 12343, loss 0.38333, acc 0.890625\n",
      "2018-05-04T17:32:52.018163: step 12344, loss 0.301854, acc 0.84375\n",
      "2018-05-04T17:32:53.050062: step 12345, loss 0.316568, acc 0.890625\n",
      "2018-05-04T17:32:54.049006: step 12346, loss 0.232979, acc 0.875\n",
      "2018-05-04T17:32:55.027247: step 12347, loss 0.101975, acc 0.96875\n",
      "2018-05-04T17:32:56.023114: step 12348, loss 0.182149, acc 0.90625\n",
      "2018-05-04T17:32:57.026725: step 12349, loss 0.25418, acc 0.859375\n",
      "2018-05-04T17:32:57.998861: step 12350, loss 0.208973, acc 0.90625\n",
      "2018-05-04T17:32:58.991719: step 12351, loss 0.281159, acc 0.890625\n",
      "2018-05-04T17:32:59.994073: step 12352, loss 0.246124, acc 0.90625\n",
      "2018-05-04T17:33:01.000869: step 12353, loss 0.359086, acc 0.84375\n",
      "2018-05-04T17:33:02.003443: step 12354, loss 0.231588, acc 0.90625\n",
      "2018-05-04T17:33:03.004117: step 12355, loss 0.175966, acc 0.9375\n",
      "2018-05-04T17:33:04.002070: step 12356, loss 0.276112, acc 0.890625\n",
      "2018-05-04T17:33:05.021323: step 12357, loss 0.230428, acc 0.875\n",
      "2018-05-04T17:33:06.021659: step 12358, loss 0.407026, acc 0.8125\n",
      "2018-05-04T17:33:07.014534: step 12359, loss 0.24982, acc 0.90625\n",
      "2018-05-04T17:33:07.987887: step 12360, loss 0.324815, acc 0.828125\n",
      "2018-05-04T17:33:08.955490: step 12361, loss 0.126701, acc 0.96875\n",
      "2018-05-04T17:33:09.918145: step 12362, loss 0.181978, acc 0.96875\n",
      "2018-05-04T17:33:10.904501: step 12363, loss 0.39866, acc 0.859375\n",
      "2018-05-04T17:33:11.976086: step 12364, loss 0.176687, acc 0.921875\n",
      "2018-05-04T17:33:13.043484: step 12365, loss 0.281404, acc 0.84375\n",
      "2018-05-04T17:33:14.108244: step 12366, loss 0.561292, acc 0.828125\n",
      "2018-05-04T17:33:15.107017: step 12367, loss 0.365603, acc 0.796875\n",
      "2018-05-04T17:33:16.067601: step 12368, loss 0.32962, acc 0.859375\n",
      "2018-05-04T17:33:17.028664: step 12369, loss 0.368939, acc 0.828125\n",
      "2018-05-04T17:33:18.096409: step 12370, loss 0.361211, acc 0.828125\n",
      "2018-05-04T17:33:19.114357: step 12371, loss 0.287309, acc 0.875\n",
      "2018-05-04T17:33:20.134973: step 12372, loss 0.282356, acc 0.921875\n",
      "2018-05-04T17:33:21.102222: step 12373, loss 0.36126, acc 0.859375\n",
      "2018-05-04T17:33:22.096013: step 12374, loss 0.160224, acc 0.9375\n",
      "2018-05-04T17:33:23.146417: step 12375, loss 0.207418, acc 0.90625\n",
      "2018-05-04T17:33:24.148118: step 12376, loss 0.212434, acc 0.921875\n",
      "2018-05-04T17:33:25.152491: step 12377, loss 0.266005, acc 0.90625\n",
      "2018-05-04T17:33:26.147220: step 12378, loss 0.507498, acc 0.765625\n",
      "2018-05-04T17:33:27.196253: step 12379, loss 0.229028, acc 0.90625\n",
      "2018-05-04T17:33:28.185165: step 12380, loss 0.244854, acc 0.890625\n",
      "2018-05-04T17:33:29.189416: step 12381, loss 0.380822, acc 0.84375\n",
      "2018-05-04T17:33:30.256988: step 12382, loss 0.171536, acc 0.9375\n",
      "2018-05-04T17:33:31.246405: step 12383, loss 0.267595, acc 0.890625\n",
      "2018-05-04T17:33:32.239380: step 12384, loss 0.220817, acc 0.921875\n",
      "2018-05-04T17:33:33.222613: step 12385, loss 0.270201, acc 0.921875\n",
      "2018-05-04T17:33:34.281841: step 12386, loss 0.303423, acc 0.875\n",
      "2018-05-04T17:33:35.307850: step 12387, loss 0.232383, acc 0.875\n",
      "2018-05-04T17:33:36.358805: step 12388, loss 0.251531, acc 0.875\n",
      "2018-05-04T17:33:37.322843: step 12389, loss 0.182027, acc 0.9375\n",
      "2018-05-04T17:33:38.355855: step 12390, loss 0.322344, acc 0.90625\n",
      "2018-05-04T17:33:39.308101: step 12391, loss 0.313158, acc 0.859375\n",
      "2018-05-04T17:33:40.337255: step 12392, loss 0.240637, acc 0.921875\n",
      "2018-05-04T17:33:41.381840: step 12393, loss 0.383538, acc 0.796875\n",
      "2018-05-04T17:33:42.364469: step 12394, loss 0.288824, acc 0.875\n",
      "2018-05-04T17:33:43.433624: step 12395, loss 0.469539, acc 0.828125\n",
      "2018-05-04T17:33:44.497075: step 12396, loss 0.230653, acc 0.890625\n",
      "2018-05-04T17:33:45.498360: step 12397, loss 0.311361, acc 0.859375\n",
      "2018-05-04T17:33:46.562062: step 12398, loss 0.315063, acc 0.890625\n",
      "2018-05-04T17:33:47.612026: step 12399, loss 0.277262, acc 0.84375\n",
      "2018-05-04T17:33:48.653079: step 12400, loss 0.247662, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T17:33:51.313668: step 12400, loss 0.244761, acc 0.91\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-12400\n",
      "\n",
      "2018-05-04T17:33:52.410601: step 12401, loss 0.214787, acc 0.921875\n",
      "2018-05-04T17:33:53.470024: step 12402, loss 0.174395, acc 0.921875\n",
      "2018-05-04T17:33:54.520944: step 12403, loss 0.213949, acc 0.9375\n",
      "2018-05-04T17:33:55.584786: step 12404, loss 0.278525, acc 0.859375\n",
      "2018-05-04T17:33:56.629545: step 12405, loss 0.257693, acc 0.921875\n",
      "2018-05-04T17:33:57.701559: step 12406, loss 0.184754, acc 0.9375\n",
      "2018-05-04T17:33:58.762054: step 12407, loss 0.208646, acc 0.921875\n",
      "2018-05-04T17:33:59.830074: step 12408, loss 0.228033, acc 0.953125\n",
      "2018-05-04T17:34:00.846417: step 12409, loss 0.295641, acc 0.890625\n",
      "2018-05-04T17:34:01.933203: step 12410, loss 0.155366, acc 0.96875\n",
      "2018-05-04T17:34:02.968937: step 12411, loss 0.328652, acc 0.84375\n",
      "2018-05-04T17:34:04.028416: step 12412, loss 0.178587, acc 0.9375\n",
      "2018-05-04T17:34:05.050592: step 12413, loss 0.208564, acc 0.90625\n",
      "2018-05-04T17:34:06.067847: step 12414, loss 0.44717, acc 0.84375\n",
      "2018-05-04T17:34:07.057193: step 12415, loss 0.239485, acc 0.921875\n",
      "2018-05-04T17:34:08.057707: step 12416, loss 0.331862, acc 0.875\n",
      "2018-05-04T17:34:09.149005: step 12417, loss 0.326379, acc 0.859375\n",
      "2018-05-04T17:34:10.131506: step 12418, loss 0.165013, acc 0.953125\n",
      "2018-05-04T17:34:11.145144: step 12419, loss 0.2565, acc 0.890625\n",
      "2018-05-04T17:34:12.139850: step 12420, loss 0.245018, acc 0.90625\n",
      "2018-05-04T17:34:13.164251: step 12421, loss 0.343523, acc 0.859375\n",
      "2018-05-04T17:34:14.197364: step 12422, loss 0.239449, acc 0.9375\n",
      "2018-05-04T17:34:15.199047: step 12423, loss 0.282877, acc 0.875\n",
      "2018-05-04T17:34:16.237446: step 12424, loss 0.255124, acc 0.859375\n",
      "2018-05-04T17:34:17.204541: step 12425, loss 0.278396, acc 0.875\n",
      "2018-05-04T17:34:18.187948: step 12426, loss 0.450048, acc 0.84375\n",
      "2018-05-04T17:34:19.171017: step 12427, loss 0.192924, acc 0.9375\n",
      "2018-05-04T17:34:20.145216: step 12428, loss 0.21727, acc 0.890625\n",
      "2018-05-04T17:34:21.160595: step 12429, loss 0.184336, acc 0.921875\n",
      "2018-05-04T17:34:22.142109: step 12430, loss 0.283305, acc 0.90625\n",
      "2018-05-04T17:34:23.115946: step 12431, loss 0.318411, acc 0.84375\n",
      "2018-05-04T17:34:24.113921: step 12432, loss 0.284874, acc 0.890625\n",
      "2018-05-04T17:34:25.081976: step 12433, loss 0.344048, acc 0.875\n",
      "2018-05-04T17:34:26.070009: step 12434, loss 0.307003, acc 0.875\n",
      "2018-05-04T17:34:27.024365: step 12435, loss 0.216576, acc 0.890625\n",
      "2018-05-04T17:34:28.093792: step 12436, loss 0.335534, acc 0.875\n",
      "2018-05-04T17:34:29.060836: step 12437, loss 0.235996, acc 0.921875\n",
      "2018-05-04T17:34:30.048615: step 12438, loss 0.320595, acc 0.890625\n",
      "2018-05-04T17:34:31.028873: step 12439, loss 0.197104, acc 0.96875\n",
      "2018-05-04T17:34:32.052343: step 12440, loss 0.2946, acc 0.84375\n",
      "2018-05-04T17:34:33.064893: step 12441, loss 0.403092, acc 0.859375\n",
      "2018-05-04T17:34:34.139097: step 12442, loss 0.161256, acc 0.9375\n",
      "2018-05-04T17:34:35.190842: step 12443, loss 0.192621, acc 0.9375\n",
      "2018-05-04T17:34:36.238438: step 12444, loss 0.278755, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T17:34:37.282762: step 12445, loss 0.309901, acc 0.859375\n",
      "2018-05-04T17:34:38.305173: step 12446, loss 0.323024, acc 0.859375\n",
      "2018-05-04T17:34:39.311407: step 12447, loss 0.204564, acc 0.953125\n",
      "2018-05-04T17:34:40.316049: step 12448, loss 0.315329, acc 0.875\n",
      "2018-05-04T17:34:41.295471: step 12449, loss 0.378587, acc 0.828125\n",
      "2018-05-04T17:34:42.274986: step 12450, loss 0.196561, acc 0.90625\n",
      "2018-05-04T17:34:43.263602: step 12451, loss 0.241825, acc 0.890625\n",
      "2018-05-04T17:34:44.313433: step 12452, loss 0.343749, acc 0.859375\n",
      "2018-05-04T17:34:45.409580: step 12453, loss 0.378997, acc 0.828125\n",
      "2018-05-04T17:34:46.465685: step 12454, loss 0.287405, acc 0.875\n",
      "2018-05-04T17:34:47.423366: step 12455, loss 0.264615, acc 0.84375\n",
      "2018-05-04T17:34:48.414131: step 12456, loss 0.201285, acc 0.921875\n",
      "2018-05-04T17:34:49.441526: step 12457, loss 0.218603, acc 0.921875\n",
      "2018-05-04T17:34:50.425613: step 12458, loss 0.194373, acc 0.9375\n",
      "2018-05-04T17:34:51.464415: step 12459, loss 0.368883, acc 0.828125\n",
      "2018-05-04T17:34:52.453286: step 12460, loss 0.23093, acc 0.875\n",
      "2018-05-04T17:34:53.477170: step 12461, loss 0.150574, acc 0.953125\n",
      "2018-05-04T17:34:54.475024: step 12462, loss 0.297163, acc 0.875\n",
      "2018-05-04T17:34:55.476430: step 12463, loss 0.232764, acc 0.90625\n",
      "2018-05-04T17:34:56.465522: step 12464, loss 0.428839, acc 0.875\n",
      "2018-05-04T17:34:57.439990: step 12465, loss 0.324125, acc 0.84375\n",
      "2018-05-04T17:34:58.443000: step 12466, loss 0.415486, acc 0.828125\n",
      "2018-05-04T17:34:59.436843: step 12467, loss 0.22663, acc 0.9375\n",
      "2018-05-04T17:35:00.420930: step 12468, loss 0.364121, acc 0.84375\n",
      "2018-05-04T17:35:01.398213: step 12469, loss 0.187728, acc 0.921875\n",
      "2018-05-04T17:35:02.385256: step 12470, loss 0.232894, acc 0.921875\n",
      "2018-05-04T17:35:03.359972: step 12471, loss 0.263953, acc 0.890625\n",
      "2018-05-04T17:35:04.370721: step 12472, loss 0.41772, acc 0.78125\n",
      "2018-05-04T17:35:05.368604: step 12473, loss 0.201847, acc 0.921875\n",
      "2018-05-04T17:35:06.459547: step 12474, loss 0.263469, acc 0.890625\n",
      "2018-05-04T17:35:07.515381: step 12475, loss 0.241367, acc 0.859375\n",
      "2018-05-04T17:35:08.513983: step 12476, loss 0.286003, acc 0.828125\n",
      "2018-05-04T17:35:09.508681: step 12477, loss 0.322339, acc 0.9375\n",
      "2018-05-04T17:35:10.481595: step 12478, loss 0.234893, acc 0.890625\n",
      "2018-05-04T17:35:11.522765: step 12479, loss 0.28878, acc 0.890625\n",
      "2018-05-04T17:35:12.515106: step 12480, loss 0.340967, acc 0.8125\n",
      "2018-05-04T17:35:13.491766: step 12481, loss 0.270041, acc 0.875\n",
      "2018-05-04T17:35:14.486615: step 12482, loss 0.341235, acc 0.875\n",
      "2018-05-04T17:35:15.456964: step 12483, loss 0.206124, acc 0.921875\n",
      "2018-05-04T17:35:16.491149: step 12484, loss 0.267057, acc 0.859375\n",
      "2018-05-04T17:35:17.563097: step 12485, loss 0.248368, acc 0.921875\n",
      "2018-05-04T17:35:18.530928: step 12486, loss 0.201503, acc 0.9375\n",
      "2018-05-04T17:35:19.517624: step 12487, loss 0.317891, acc 0.921875\n",
      "2018-05-04T17:35:20.492128: step 12488, loss 0.220189, acc 0.953125\n",
      "2018-05-04T17:35:21.514416: step 12489, loss 0.208713, acc 0.90625\n",
      "2018-05-04T17:35:22.481179: step 12490, loss 0.233862, acc 0.90625\n",
      "2018-05-04T17:35:23.478354: step 12491, loss 0.267531, acc 0.921875\n",
      "2018-05-04T17:35:24.459803: step 12492, loss 0.227211, acc 0.90625\n",
      "2018-05-04T17:35:25.424668: step 12493, loss 0.396603, acc 0.90625\n",
      "2018-05-04T17:35:26.380624: step 12494, loss 0.268243, acc 0.890625\n",
      "2018-05-04T17:35:27.372118: step 12495, loss 0.291109, acc 0.84375\n",
      "2018-05-04T17:35:28.362574: step 12496, loss 0.219859, acc 0.890625\n",
      "2018-05-04T17:35:29.332181: step 12497, loss 0.255767, acc 0.859375\n",
      "2018-05-04T17:35:30.302032: step 12498, loss 0.253536, acc 0.9375\n",
      "2018-05-04T17:35:31.270361: step 12499, loss 0.123546, acc 0.953125\n",
      "2018-05-04T17:35:32.236911: step 12500, loss 0.336853, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T17:35:34.418315: step 12500, loss 0.236145, acc 0.912\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-12500\n",
      "\n",
      "2018-05-04T17:35:35.464601: step 12501, loss 0.228865, acc 0.875\n",
      "2018-05-04T17:35:36.513395: step 12502, loss 0.293907, acc 0.90625\n",
      "2018-05-04T17:35:37.483432: step 12503, loss 0.227005, acc 0.90625\n",
      "2018-05-04T17:35:38.445583: step 12504, loss 0.224005, acc 0.90625\n",
      "2018-05-04T17:35:39.400213: step 12505, loss 0.205217, acc 0.90625\n",
      "2018-05-04T17:35:40.421289: step 12506, loss 0.315856, acc 0.859375\n",
      "2018-05-04T17:35:41.372677: step 12507, loss 0.212698, acc 0.9375\n",
      "2018-05-04T17:35:42.331684: step 12508, loss 0.305697, acc 0.859375\n",
      "2018-05-04T17:35:43.298175: step 12509, loss 0.277299, acc 0.890625\n",
      "2018-05-04T17:35:44.253751: step 12510, loss 0.285324, acc 0.875\n",
      "2018-05-04T17:35:45.220125: step 12511, loss 0.433805, acc 0.796875\n",
      "2018-05-04T17:35:46.194901: step 12512, loss 0.265848, acc 0.84375\n",
      "2018-05-04T17:35:47.176783: step 12513, loss 0.212585, acc 0.921875\n",
      "2018-05-04T17:35:48.129549: step 12514, loss 0.261882, acc 0.890625\n",
      "2018-05-04T17:35:49.092029: step 12515, loss 0.367061, acc 0.890625\n",
      "2018-05-04T17:35:50.065361: step 12516, loss 0.311763, acc 0.9375\n",
      "2018-05-04T17:35:50.990661: step 12517, loss 0.363348, acc 0.859375\n",
      "2018-05-04T17:35:51.928825: step 12518, loss 0.3567, acc 0.875\n",
      "2018-05-04T17:35:52.887867: step 12519, loss 0.138731, acc 0.953125\n",
      "2018-05-04T17:35:53.910579: step 12520, loss 0.245202, acc 0.875\n",
      "2018-05-04T17:35:54.992878: step 12521, loss 0.329346, acc 0.859375\n",
      "2018-05-04T17:35:56.013341: step 12522, loss 0.367764, acc 0.875\n",
      "2018-05-04T17:35:56.962325: step 12523, loss 0.384546, acc 0.875\n",
      "2018-05-04T17:35:57.873571: step 12524, loss 0.29727, acc 0.890625\n",
      "2018-05-04T17:35:58.810918: step 12525, loss 0.26231, acc 0.859375\n",
      "2018-05-04T17:35:59.747718: step 12526, loss 0.32989, acc 0.84375\n",
      "2018-05-04T17:36:00.774923: step 12527, loss 0.230686, acc 0.9375\n",
      "2018-05-04T17:36:01.729355: step 12528, loss 0.343138, acc 0.84375\n",
      "2018-05-04T17:36:02.760060: step 12529, loss 0.385567, acc 0.84375\n",
      "2018-05-04T17:36:03.700064: step 12530, loss 0.206039, acc 0.90625\n",
      "2018-05-04T17:36:04.645661: step 12531, loss 0.263332, acc 0.921875\n",
      "2018-05-04T17:36:05.580443: step 12532, loss 0.410893, acc 0.78125\n",
      "2018-05-04T17:36:06.529149: step 12533, loss 0.454041, acc 0.796875\n",
      "2018-05-04T17:36:07.481205: step 12534, loss 0.158591, acc 0.96875\n",
      "2018-05-04T17:36:08.418781: step 12535, loss 0.284842, acc 0.890625\n",
      "2018-05-04T17:36:09.368059: step 12536, loss 0.242606, acc 0.90625\n",
      "2018-05-04T17:36:10.295711: step 12537, loss 0.260054, acc 0.890625\n",
      "2018-05-04T17:36:11.244360: step 12538, loss 0.241365, acc 0.890625\n",
      "2018-05-04T17:36:12.192670: step 12539, loss 0.29362, acc 0.875\n",
      "2018-05-04T17:36:13.149300: step 12540, loss 0.391093, acc 0.84375\n",
      "2018-05-04T17:36:14.112033: step 12541, loss 0.312736, acc 0.859375\n",
      "2018-05-04T17:36:15.075490: step 12542, loss 0.28213, acc 0.90625\n",
      "2018-05-04T17:36:16.077347: step 12543, loss 0.215157, acc 0.90625\n",
      "2018-05-04T17:36:17.055912: step 12544, loss 0.254363, acc 0.875\n",
      "2018-05-04T17:36:18.044659: step 12545, loss 0.234957, acc 0.921875\n",
      "2018-05-04T17:36:19.051783: step 12546, loss 0.314921, acc 0.828125\n",
      "2018-05-04T17:36:19.966356: step 12547, loss 0.354623, acc 0.890625\n",
      "2018-05-04T17:36:21.004659: step 12548, loss 0.345218, acc 0.84375\n",
      "2018-05-04T17:36:22.071684: step 12549, loss 0.332509, acc 0.84375\n",
      "2018-05-04T17:36:23.014652: step 12550, loss 0.316487, acc 0.890625\n",
      "2018-05-04T17:36:24.041149: step 12551, loss 0.439563, acc 0.859375\n",
      "2018-05-04T17:36:25.073579: step 12552, loss 0.334969, acc 0.90625\n",
      "2018-05-04T17:36:26.022134: step 12553, loss 0.184859, acc 0.90625\n",
      "2018-05-04T17:36:26.955854: step 12554, loss 0.241418, acc 0.859375\n",
      "2018-05-04T17:36:27.879789: step 12555, loss 0.314458, acc 0.84375\n",
      "2018-05-04T17:36:28.822265: step 12556, loss 0.343234, acc 0.828125\n",
      "2018-05-04T17:36:29.756059: step 12557, loss 0.343077, acc 0.890625\n",
      "2018-05-04T17:36:30.709593: step 12558, loss 0.310119, acc 0.859375\n",
      "2018-05-04T17:36:31.676820: step 12559, loss 0.334163, acc 0.8125\n",
      "2018-05-04T17:36:32.634779: step 12560, loss 0.107642, acc 0.984375\n",
      "2018-05-04T17:36:33.590771: step 12561, loss 0.281662, acc 0.859375\n",
      "2018-05-04T17:36:34.568122: step 12562, loss 0.327793, acc 0.859375\n",
      "2018-05-04T17:36:35.551540: step 12563, loss 0.272306, acc 0.84375\n",
      "2018-05-04T17:36:36.517298: step 12564, loss 0.258358, acc 0.84375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T17:36:37.455337: step 12565, loss 0.201969, acc 0.921875\n",
      "2018-05-04T17:36:38.390124: step 12566, loss 0.299496, acc 0.859375\n",
      "2018-05-04T17:36:39.372190: step 12567, loss 0.306521, acc 0.875\n",
      "2018-05-04T17:36:40.419397: step 12568, loss 0.200131, acc 0.921875\n",
      "2018-05-04T17:36:41.404054: step 12569, loss 0.223587, acc 0.90625\n",
      "2018-05-04T17:36:42.428144: step 12570, loss 0.203904, acc 0.90625\n",
      "2018-05-04T17:36:43.383379: step 12571, loss 0.294344, acc 0.890625\n",
      "2018-05-04T17:36:44.330590: step 12572, loss 0.216456, acc 0.90625\n",
      "2018-05-04T17:36:45.351781: step 12573, loss 0.225675, acc 0.90625\n",
      "2018-05-04T17:36:46.278177: step 12574, loss 0.515389, acc 0.796875\n",
      "2018-05-04T17:36:47.223489: step 12575, loss 0.335556, acc 0.859375\n",
      "2018-05-04T17:36:48.273454: step 12576, loss 0.334896, acc 0.828125\n",
      "2018-05-04T17:36:49.282083: step 12577, loss 0.260233, acc 0.90625\n",
      "2018-05-04T17:36:50.236576: step 12578, loss 0.326751, acc 0.859375\n",
      "2018-05-04T17:36:51.206794: step 12579, loss 0.27339, acc 0.890625\n",
      "2018-05-04T17:36:52.237139: step 12580, loss 0.310849, acc 0.875\n",
      "2018-05-04T17:36:53.225023: step 12581, loss 0.449277, acc 0.8125\n",
      "2018-05-04T17:36:54.152908: step 12582, loss 0.332941, acc 0.875\n",
      "2018-05-04T17:36:55.175222: step 12583, loss 0.42066, acc 0.828125\n",
      "2018-05-04T17:36:56.114541: step 12584, loss 0.287886, acc 0.890625\n",
      "2018-05-04T17:36:57.139024: step 12585, loss 0.294679, acc 0.875\n",
      "2018-05-04T17:36:58.072728: step 12586, loss 0.22458, acc 0.9375\n",
      "2018-05-04T17:36:59.109673: step 12587, loss 0.263459, acc 0.875\n",
      "2018-05-04T17:37:00.189342: step 12588, loss 0.254475, acc 0.890625\n",
      "2018-05-04T17:37:01.200915: step 12589, loss 0.184967, acc 0.90625\n",
      "2018-05-04T17:37:02.224716: step 12590, loss 0.172309, acc 0.921875\n",
      "2018-05-04T17:37:03.243152: step 12591, loss 0.258334, acc 0.890625\n",
      "2018-05-04T17:37:04.268122: step 12592, loss 0.278164, acc 0.90625\n",
      "2018-05-04T17:37:05.198370: step 12593, loss 0.303563, acc 0.859375\n",
      "2018-05-04T17:37:06.235031: step 12594, loss 0.373459, acc 0.84375\n",
      "2018-05-04T17:37:07.250732: step 12595, loss 0.40198, acc 0.8125\n",
      "2018-05-04T17:37:08.261516: step 12596, loss 0.178339, acc 0.953125\n",
      "2018-05-04T17:37:09.262071: step 12597, loss 0.185796, acc 0.921875\n",
      "2018-05-04T17:37:10.169255: step 12598, loss 0.210182, acc 0.921875\n",
      "2018-05-04T17:37:11.177408: step 12599, loss 0.280402, acc 0.890625\n",
      "2018-05-04T17:37:12.191955: step 12600, loss 0.238131, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T17:37:14.917298: step 12600, loss 0.244741, acc 0.918\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-12600\n",
      "\n",
      "2018-05-04T17:37:15.976205: step 12601, loss 0.186974, acc 0.9375\n",
      "2018-05-04T17:37:16.986444: step 12602, loss 0.21656, acc 0.890625\n",
      "2018-05-04T17:37:17.991671: step 12603, loss 0.324624, acc 0.84375\n",
      "2018-05-04T17:37:19.009321: step 12604, loss 0.241397, acc 0.9375\n",
      "2018-05-04T17:37:20.059340: step 12605, loss 0.229757, acc 0.90625\n",
      "2018-05-04T17:37:21.172669: step 12606, loss 0.310396, acc 0.875\n",
      "2018-05-04T17:37:22.228234: step 12607, loss 0.163504, acc 0.921875\n",
      "2018-05-04T17:37:23.264337: step 12608, loss 0.162611, acc 0.9375\n",
      "2018-05-04T17:37:24.276537: step 12609, loss 0.38913, acc 0.84375\n",
      "2018-05-04T17:37:25.286201: step 12610, loss 0.19517, acc 0.921875\n",
      "2018-05-04T17:37:26.306519: step 12611, loss 0.530612, acc 0.84375\n",
      "2018-05-04T17:37:27.322766: step 12612, loss 0.258378, acc 0.90625\n",
      "2018-05-04T17:37:28.315625: step 12613, loss 0.206716, acc 0.921875\n",
      "2018-05-04T17:37:29.303816: step 12614, loss 0.196275, acc 0.9375\n",
      "2018-05-04T17:37:30.263776: step 12615, loss 0.27761, acc 0.90625\n",
      "2018-05-04T17:37:31.261516: step 12616, loss 0.275496, acc 0.890625\n",
      "2018-05-04T17:37:32.283502: step 12617, loss 0.212293, acc 0.921875\n",
      "2018-05-04T17:37:33.352092: step 12618, loss 0.322227, acc 0.90625\n",
      "2018-05-04T17:37:34.368551: step 12619, loss 0.206441, acc 0.875\n",
      "2018-05-04T17:37:35.408266: step 12620, loss 0.273679, acc 0.90625\n",
      "2018-05-04T17:37:36.440900: step 12621, loss 0.320114, acc 0.890625\n",
      "2018-05-04T17:37:37.465964: step 12622, loss 0.25713, acc 0.875\n",
      "2018-05-04T17:37:38.463660: step 12623, loss 0.274724, acc 0.875\n",
      "2018-05-04T17:37:39.454625: step 12624, loss 0.164033, acc 0.921875\n",
      "2018-05-04T17:37:40.440762: step 12625, loss 0.276083, acc 0.921875\n",
      "2018-05-04T17:37:41.434759: step 12626, loss 0.186943, acc 0.9375\n",
      "2018-05-04T17:37:42.434762: step 12627, loss 0.104393, acc 0.984375\n",
      "2018-05-04T17:37:43.486827: step 12628, loss 0.265318, acc 0.921875\n",
      "2018-05-04T17:37:44.488319: step 12629, loss 0.181328, acc 0.90625\n",
      "2018-05-04T17:37:45.483834: step 12630, loss 0.347271, acc 0.875\n",
      "2018-05-04T17:37:46.476143: step 12631, loss 0.252309, acc 0.90625\n",
      "2018-05-04T17:37:47.421951: step 12632, loss 0.203599, acc 0.921875\n",
      "2018-05-04T17:37:48.457038: step 12633, loss 0.316887, acc 0.8125\n",
      "2018-05-04T17:37:49.403408: step 12634, loss 0.330842, acc 0.875\n",
      "2018-05-04T17:37:50.379421: step 12635, loss 0.301661, acc 0.890625\n",
      "2018-05-04T17:37:51.406296: step 12636, loss 0.157629, acc 0.96875\n",
      "2018-05-04T17:37:52.386362: step 12637, loss 0.39447, acc 0.890625\n",
      "2018-05-04T17:37:53.367080: step 12638, loss 0.516888, acc 0.8125\n",
      "2018-05-04T17:37:54.362986: step 12639, loss 0.428581, acc 0.8125\n",
      "2018-05-04T17:37:55.357977: step 12640, loss 0.206497, acc 0.875\n",
      "2018-05-04T17:37:56.338297: step 12641, loss 0.354949, acc 0.828125\n",
      "2018-05-04T17:37:57.326834: step 12642, loss 0.220309, acc 0.90625\n",
      "2018-05-04T17:37:58.317418: step 12643, loss 0.201017, acc 0.921875\n",
      "2018-05-04T17:37:59.290725: step 12644, loss 0.242616, acc 0.90625\n",
      "2018-05-04T17:38:00.297491: step 12645, loss 0.274757, acc 0.84375\n",
      "2018-05-04T17:38:01.260146: step 12646, loss 0.316508, acc 0.890625\n",
      "2018-05-04T17:38:02.235526: step 12647, loss 0.27968, acc 0.890625\n",
      "2018-05-04T17:38:03.219083: step 12648, loss 0.223717, acc 0.875\n",
      "2018-05-04T17:38:04.257882: step 12649, loss 0.261366, acc 0.875\n",
      "2018-05-04T17:38:05.252300: step 12650, loss 0.314379, acc 0.859375\n",
      "2018-05-04T17:38:06.326527: step 12651, loss 0.150759, acc 0.96875\n",
      "2018-05-04T17:38:07.325698: step 12652, loss 0.185008, acc 0.953125\n",
      "2018-05-04T17:38:08.310694: step 12653, loss 0.155852, acc 0.953125\n",
      "2018-05-04T17:38:09.287676: step 12654, loss 0.279064, acc 0.859375\n",
      "2018-05-04T17:38:10.261852: step 12655, loss 0.249202, acc 0.875\n",
      "2018-05-04T17:38:11.246713: step 12656, loss 0.307446, acc 0.921875\n",
      "2018-05-04T17:38:12.240157: step 12657, loss 0.16857, acc 0.953125\n",
      "2018-05-04T17:38:13.221234: step 12658, loss 0.256822, acc 0.921875\n",
      "2018-05-04T17:38:14.215683: step 12659, loss 0.209491, acc 0.90625\n",
      "2018-05-04T17:38:15.170066: step 12660, loss 0.289097, acc 0.859375\n",
      "2018-05-04T17:38:16.167536: step 12661, loss 0.230725, acc 0.875\n",
      "2018-05-04T17:38:17.193776: step 12662, loss 0.299543, acc 0.90625\n",
      "2018-05-04T17:38:18.171078: step 12663, loss 0.230509, acc 0.921875\n",
      "2018-05-04T17:38:19.133521: step 12664, loss 0.193186, acc 0.90625\n",
      "2018-05-04T17:38:20.111697: step 12665, loss 0.272085, acc 0.859375\n",
      "2018-05-04T17:38:21.221200: step 12666, loss 0.229276, acc 0.890625\n",
      "2018-05-04T17:38:22.227644: step 12667, loss 0.284527, acc 0.90625\n",
      "2018-05-04T17:38:23.235476: step 12668, loss 0.199313, acc 0.90625\n",
      "2018-05-04T17:38:24.263325: step 12669, loss 0.235593, acc 0.90625\n",
      "2018-05-04T17:38:25.254868: step 12670, loss 0.305742, acc 0.84375\n",
      "2018-05-04T17:38:26.235423: step 12671, loss 0.233441, acc 0.90625\n",
      "2018-05-04T17:38:27.212263: step 12672, loss 0.292346, acc 0.84375\n",
      "2018-05-04T17:38:28.180334: step 12673, loss 0.280696, acc 0.890625\n",
      "2018-05-04T17:38:29.174003: step 12674, loss 0.290092, acc 0.875\n",
      "2018-05-04T17:38:30.163851: step 12675, loss 0.407195, acc 0.859375\n",
      "2018-05-04T17:38:31.151833: step 12676, loss 0.307158, acc 0.875\n",
      "2018-05-04T17:38:32.137443: step 12677, loss 0.176557, acc 0.9375\n",
      "2018-05-04T17:38:33.198555: step 12678, loss 0.189985, acc 0.90625\n",
      "2018-05-04T17:38:34.190749: step 12679, loss 0.241843, acc 0.90625\n",
      "2018-05-04T17:38:35.158017: step 12680, loss 0.368339, acc 0.859375\n",
      "2018-05-04T17:38:36.157377: step 12681, loss 0.22629, acc 0.921875\n",
      "2018-05-04T17:38:37.139180: step 12682, loss 0.432206, acc 0.828125\n",
      "2018-05-04T17:38:38.099743: step 12683, loss 0.348777, acc 0.796875\n",
      "2018-05-04T17:38:39.076551: step 12684, loss 0.256588, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T17:38:40.046280: step 12685, loss 0.170827, acc 0.90625\n",
      "2018-05-04T17:38:41.011622: step 12686, loss 0.259959, acc 0.90625\n",
      "2018-05-04T17:38:41.992175: step 12687, loss 0.297406, acc 0.828125\n",
      "2018-05-04T17:38:42.974780: step 12688, loss 0.230507, acc 0.9375\n",
      "2018-05-04T17:38:43.987692: step 12689, loss 0.398888, acc 0.828125\n",
      "2018-05-04T17:38:44.985028: step 12690, loss 0.208092, acc 0.90625\n",
      "2018-05-04T17:38:45.952078: step 12691, loss 0.398308, acc 0.828125\n",
      "2018-05-04T17:38:46.902540: step 12692, loss 0.227795, acc 0.921875\n",
      "2018-05-04T17:38:47.861842: step 12693, loss 0.291177, acc 0.875\n",
      "2018-05-04T17:38:48.838710: step 12694, loss 0.231282, acc 0.90625\n",
      "2018-05-04T17:38:49.843086: step 12695, loss 0.205519, acc 0.9375\n",
      "2018-05-04T17:38:50.893171: step 12696, loss 0.316818, acc 0.875\n",
      "2018-05-04T17:38:51.875755: step 12697, loss 0.197916, acc 0.921875\n",
      "2018-05-04T17:38:52.839698: step 12698, loss 0.280024, acc 0.890625\n",
      "2018-05-04T17:38:53.917350: step 12699, loss 0.366744, acc 0.875\n",
      "2018-05-04T17:38:54.904789: step 12700, loss 0.433795, acc 0.8125\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T17:38:57.022084: step 12700, loss 0.221889, acc 0.928\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-12700\n",
      "\n",
      "2018-05-04T17:38:58.072247: step 12701, loss 0.167005, acc 0.9375\n",
      "2018-05-04T17:38:59.058254: step 12702, loss 0.240697, acc 0.90625\n",
      "2018-05-04T17:39:00.017240: step 12703, loss 0.356831, acc 0.890625\n",
      "2018-05-04T17:39:00.977993: step 12704, loss 0.218947, acc 0.921875\n",
      "2018-05-04T17:39:01.949074: step 12705, loss 0.320894, acc 0.859375\n",
      "2018-05-04T17:39:03.009660: step 12706, loss 0.206574, acc 0.9375\n",
      "2018-05-04T17:39:03.971413: step 12707, loss 0.269181, acc 0.890625\n",
      "2018-05-04T17:39:05.006017: step 12708, loss 0.40205, acc 0.78125\n",
      "2018-05-04T17:39:05.975263: step 12709, loss 0.277619, acc 0.890625\n",
      "2018-05-04T17:39:06.950837: step 12710, loss 0.229812, acc 0.90625\n",
      "2018-05-04T17:39:07.909307: step 12711, loss 0.246946, acc 0.9375\n",
      "2018-05-04T17:39:08.871890: step 12712, loss 0.171799, acc 0.921875\n",
      "2018-05-04T17:39:09.865070: step 12713, loss 0.243679, acc 0.890625\n",
      "2018-05-04T17:39:10.863369: step 12714, loss 0.16372, acc 0.96875\n",
      "2018-05-04T17:39:11.909150: step 12715, loss 0.298639, acc 0.859375\n",
      "2018-05-04T17:39:12.873190: step 12716, loss 0.31385, acc 0.84375\n",
      "2018-05-04T17:39:13.835432: step 12717, loss 0.279158, acc 0.890625\n",
      "2018-05-04T17:39:14.801238: step 12718, loss 0.296387, acc 0.890625\n",
      "2018-05-04T17:39:15.752933: step 12719, loss 0.330686, acc 0.859375\n",
      "2018-05-04T17:39:16.706542: step 12720, loss 0.26515, acc 0.875\n",
      "2018-05-04T17:39:17.718662: step 12721, loss 0.420582, acc 0.828125\n",
      "2018-05-04T17:39:18.682852: step 12722, loss 0.313713, acc 0.890625\n",
      "2018-05-04T17:39:19.639009: step 12723, loss 0.26219, acc 0.84375\n",
      "2018-05-04T17:39:20.626612: step 12724, loss 0.401438, acc 0.828125\n",
      "2018-05-04T17:39:21.681340: step 12725, loss 0.312175, acc 0.859375\n",
      "2018-05-04T17:39:22.659112: step 12726, loss 0.277486, acc 0.921875\n",
      "2018-05-04T17:39:23.636671: step 12727, loss 0.348642, acc 0.84375\n",
      "2018-05-04T17:39:24.628918: step 12728, loss 0.30627, acc 0.84375\n",
      "2018-05-04T17:39:25.589552: step 12729, loss 0.253009, acc 0.875\n",
      "2018-05-04T17:39:26.555725: step 12730, loss 0.227068, acc 0.921875\n",
      "2018-05-04T17:39:27.509405: step 12731, loss 0.158465, acc 0.9375\n",
      "2018-05-04T17:39:28.473316: step 12732, loss 0.319974, acc 0.859375\n",
      "2018-05-04T17:39:29.464641: step 12733, loss 0.218917, acc 0.890625\n",
      "2018-05-04T17:39:30.481053: step 12734, loss 0.293688, acc 0.796875\n",
      "2018-05-04T17:39:31.515850: step 12735, loss 0.283155, acc 0.90625\n",
      "2018-05-04T17:39:32.530592: step 12736, loss 0.290008, acc 0.921875\n",
      "2018-05-04T17:39:33.539820: step 12737, loss 0.261792, acc 0.921875\n",
      "2018-05-04T17:39:34.588599: step 12738, loss 0.281065, acc 0.828125\n",
      "2018-05-04T17:39:35.551218: step 12739, loss 0.323005, acc 0.890625\n",
      "2018-05-04T17:39:36.508780: step 12740, loss 0.255204, acc 0.90625\n",
      "2018-05-04T17:39:37.485300: step 12741, loss 0.24679, acc 0.90625\n",
      "2018-05-04T17:39:38.436540: step 12742, loss 0.264512, acc 0.90625\n",
      "2018-05-04T17:39:39.387080: step 12743, loss 0.316588, acc 0.875\n",
      "2018-05-04T17:39:40.350606: step 12744, loss 0.298449, acc 0.859375\n",
      "2018-05-04T17:39:41.322846: step 12745, loss 0.41551, acc 0.796875\n",
      "2018-05-04T17:39:42.348142: step 12746, loss 0.473196, acc 0.8125\n",
      "2018-05-04T17:39:43.304463: step 12747, loss 0.209367, acc 0.921875\n",
      "2018-05-04T17:39:44.259469: step 12748, loss 0.456127, acc 0.84375\n",
      "2018-05-04T17:39:45.327221: step 12749, loss 0.332043, acc 0.859375\n",
      "2018-05-04T17:39:46.311856: step 12750, loss 0.332701, acc 0.859375\n",
      "2018-05-04T17:39:47.274264: step 12751, loss 0.212627, acc 0.921875\n",
      "2018-05-04T17:39:48.218448: step 12752, loss 0.282473, acc 0.90625\n",
      "2018-05-04T17:39:49.181604: step 12753, loss 0.260776, acc 0.90625\n",
      "2018-05-04T17:39:50.136973: step 12754, loss 0.345012, acc 0.875\n",
      "2018-05-04T17:39:51.109838: step 12755, loss 0.291631, acc 0.859375\n",
      "2018-05-04T17:39:52.141790: step 12756, loss 0.254147, acc 0.875\n",
      "2018-05-04T17:39:53.157607: step 12757, loss 0.321306, acc 0.875\n",
      "2018-05-04T17:39:54.151130: step 12758, loss 0.37322, acc 0.84375\n",
      "2018-05-04T17:39:55.213537: step 12759, loss 0.267084, acc 0.890625\n",
      "2018-05-04T17:39:56.178343: step 12760, loss 0.240547, acc 0.921875\n",
      "2018-05-04T17:39:57.138255: step 12761, loss 0.235127, acc 0.921875\n",
      "2018-05-04T17:39:58.100357: step 12762, loss 0.23657, acc 0.90625\n",
      "2018-05-04T17:39:59.140006: step 12763, loss 0.259935, acc 0.90625\n",
      "2018-05-04T17:40:00.179177: step 12764, loss 0.311055, acc 0.84375\n",
      "2018-05-04T17:40:01.188779: step 12765, loss 0.292084, acc 0.890625\n",
      "2018-05-04T17:40:02.149966: step 12766, loss 0.297218, acc 0.828125\n",
      "2018-05-04T17:40:03.160513: step 12767, loss 0.185004, acc 0.90625\n",
      "2018-05-04T17:40:04.200754: step 12768, loss 0.314592, acc 0.859375\n",
      "2018-05-04T17:40:05.143671: step 12769, loss 0.252134, acc 0.890625\n",
      "2018-05-04T17:40:06.176979: step 12770, loss 0.363884, acc 0.796875\n",
      "2018-05-04T17:40:07.242759: step 12771, loss 0.298034, acc 0.890625\n",
      "2018-05-04T17:40:08.275845: step 12772, loss 0.369087, acc 0.859375\n",
      "2018-05-04T17:40:09.290706: step 12773, loss 0.277536, acc 0.875\n",
      "2018-05-04T17:40:10.294027: step 12774, loss 0.375919, acc 0.84375\n",
      "2018-05-04T17:40:11.366028: step 12775, loss 0.171435, acc 0.953125\n",
      "2018-05-04T17:40:12.298042: step 12776, loss 0.210194, acc 0.90625\n",
      "2018-05-04T17:40:13.263081: step 12777, loss 0.298955, acc 0.890625\n",
      "2018-05-04T17:40:14.234942: step 12778, loss 0.296809, acc 0.890625\n",
      "2018-05-04T17:40:15.190425: step 12779, loss 0.306961, acc 0.890625\n",
      "2018-05-04T17:40:16.139664: step 12780, loss 0.220224, acc 0.890625\n",
      "2018-05-04T17:40:17.122012: step 12781, loss 0.34562, acc 0.90625\n",
      "2018-05-04T17:40:18.107636: step 12782, loss 0.447541, acc 0.8125\n",
      "2018-05-04T17:40:19.159194: step 12783, loss 0.426587, acc 0.796875\n",
      "2018-05-04T17:40:20.146876: step 12784, loss 0.395459, acc 0.859375\n",
      "2018-05-04T17:40:21.133370: step 12785, loss 0.184648, acc 0.90625\n",
      "2018-05-04T17:40:22.077185: step 12786, loss 0.270602, acc 0.890625\n",
      "2018-05-04T17:40:23.043409: step 12787, loss 0.146519, acc 0.96875\n",
      "2018-05-04T17:40:23.993599: step 12788, loss 0.210716, acc 0.90625\n",
      "2018-05-04T17:40:25.025886: step 12789, loss 0.297024, acc 0.859375\n",
      "2018-05-04T17:40:25.993652: step 12790, loss 0.300743, acc 0.875\n",
      "2018-05-04T17:40:27.048406: step 12791, loss 0.317526, acc 0.859375\n",
      "2018-05-04T17:40:28.001337: step 12792, loss 0.296161, acc 0.875\n",
      "2018-05-04T17:40:28.977776: step 12793, loss 0.208318, acc 0.953125\n",
      "2018-05-04T17:40:30.017234: step 12794, loss 0.387741, acc 0.859375\n",
      "2018-05-04T17:40:31.038720: step 12795, loss 0.176093, acc 0.953125\n",
      "2018-05-04T17:40:32.082946: step 12796, loss 0.250875, acc 0.890625\n",
      "2018-05-04T17:40:33.155254: step 12797, loss 0.275859, acc 0.90625\n",
      "2018-05-04T17:40:34.260041: step 12798, loss 0.31131, acc 0.8125\n",
      "2018-05-04T17:40:35.371190: step 12799, loss 0.226815, acc 0.875\n",
      "2018-05-04T17:40:36.463873: step 12800, loss 0.195777, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T17:40:38.617017: step 12800, loss 0.24111, acc 0.908\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-12800\n",
      "\n",
      "2018-05-04T17:40:39.676979: step 12801, loss 0.138273, acc 0.953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T17:40:40.690368: step 12802, loss 0.183126, acc 0.953125\n",
      "2018-05-04T17:40:41.680856: step 12803, loss 0.287702, acc 0.859375\n",
      "2018-05-04T17:40:42.716768: step 12804, loss 0.203718, acc 0.90625\n",
      "2018-05-04T17:40:43.680712: step 12805, loss 0.281016, acc 0.890625\n",
      "2018-05-04T17:40:44.711689: step 12806, loss 0.311548, acc 0.875\n",
      "2018-05-04T17:40:45.740920: step 12807, loss 0.304684, acc 0.84375\n",
      "2018-05-04T17:40:46.748950: step 12808, loss 0.264646, acc 0.875\n",
      "2018-05-04T17:40:47.763687: step 12809, loss 0.160319, acc 0.96875\n",
      "2018-05-04T17:40:48.788778: step 12810, loss 0.296239, acc 0.890625\n",
      "2018-05-04T17:40:49.861153: step 12811, loss 0.294574, acc 0.890625\n",
      "2018-05-04T17:40:50.891717: step 12812, loss 0.249954, acc 0.921875\n",
      "2018-05-04T17:40:51.986040: step 12813, loss 0.289951, acc 0.84375\n",
      "2018-05-04T17:40:52.930330: step 12814, loss 0.313817, acc 0.859375\n",
      "2018-05-04T17:40:53.940192: step 12815, loss 0.332603, acc 0.859375\n",
      "2018-05-04T17:40:54.943314: step 12816, loss 0.195977, acc 0.953125\n",
      "2018-05-04T17:40:55.945443: step 12817, loss 0.239483, acc 0.875\n",
      "2018-05-04T17:40:56.982178: step 12818, loss 0.282676, acc 0.875\n",
      "2018-05-04T17:40:58.045677: step 12819, loss 0.215119, acc 0.921875\n",
      "2018-05-04T17:40:59.086237: step 12820, loss 0.221777, acc 0.90625\n",
      "2018-05-04T17:41:00.106781: step 12821, loss 0.260876, acc 0.828125\n",
      "2018-05-04T17:41:01.091854: step 12822, loss 0.387486, acc 0.875\n",
      "2018-05-04T17:41:02.086017: step 12823, loss 0.3503, acc 0.828125\n",
      "2018-05-04T17:41:03.102892: step 12824, loss 0.319789, acc 0.828125\n",
      "2018-05-04T17:41:04.136673: step 12825, loss 0.42485, acc 0.84375\n",
      "2018-05-04T17:41:05.144151: step 12826, loss 0.343203, acc 0.84375\n",
      "2018-05-04T17:41:06.160334: step 12827, loss 0.260142, acc 0.921875\n",
      "2018-05-04T17:41:07.170990: step 12828, loss 0.321728, acc 0.875\n",
      "2018-05-04T17:41:08.180966: step 12829, loss 0.34688, acc 0.890625\n",
      "2018-05-04T17:41:09.114544: step 12830, loss 0.19925, acc 0.921875\n",
      "2018-05-04T17:41:10.142403: step 12831, loss 0.209786, acc 0.90625\n",
      "2018-05-04T17:41:11.185544: step 12832, loss 0.294789, acc 0.875\n",
      "2018-05-04T17:41:12.137087: step 12833, loss 0.236854, acc 0.859375\n",
      "2018-05-04T17:41:13.128823: step 12834, loss 0.216544, acc 0.90625\n",
      "2018-05-04T17:41:14.148376: step 12835, loss 0.278874, acc 0.90625\n",
      "2018-05-04T17:41:15.163937: step 12836, loss 0.283143, acc 0.90625\n",
      "2018-05-04T17:41:16.170704: step 12837, loss 0.335735, acc 0.875\n",
      "2018-05-04T17:41:17.247126: step 12838, loss 0.283596, acc 0.90625\n",
      "2018-05-04T17:41:18.269133: step 12839, loss 0.242169, acc 0.875\n",
      "2018-05-04T17:41:19.301702: step 12840, loss 0.22335, acc 0.90625\n",
      "2018-05-04T17:41:20.248934: step 12841, loss 0.176364, acc 0.953125\n",
      "2018-05-04T17:41:21.199927: step 12842, loss 0.320379, acc 0.859375\n",
      "2018-05-04T17:41:22.236022: step 12843, loss 0.21289, acc 0.9375\n",
      "2018-05-04T17:41:23.309097: step 12844, loss 0.262454, acc 0.875\n",
      "2018-05-04T17:41:24.317840: step 12845, loss 0.266078, acc 0.890625\n",
      "2018-05-04T17:41:25.344221: step 12846, loss 0.345109, acc 0.859375\n",
      "2018-05-04T17:41:26.347876: step 12847, loss 0.290912, acc 0.859375\n",
      "2018-05-04T17:41:27.354691: step 12848, loss 0.284117, acc 0.875\n",
      "2018-05-04T17:41:28.407657: step 12849, loss 0.313039, acc 0.890625\n",
      "2018-05-04T17:41:29.435896: step 12850, loss 0.588578, acc 0.78125\n",
      "2018-05-04T17:41:30.479305: step 12851, loss 0.279411, acc 0.84375\n",
      "2018-05-04T17:41:31.513466: step 12852, loss 0.344483, acc 0.84375\n",
      "2018-05-04T17:41:32.564278: step 12853, loss 0.248234, acc 0.90625\n",
      "2018-05-04T17:41:33.605669: step 12854, loss 0.359384, acc 0.875\n",
      "2018-05-04T17:41:34.629606: step 12855, loss 0.258376, acc 0.90625\n",
      "2018-05-04T17:41:35.650707: step 12856, loss 0.30933, acc 0.84375\n",
      "2018-05-04T17:41:36.660030: step 12857, loss 0.228161, acc 0.90625\n",
      "2018-05-04T17:41:37.684337: step 12858, loss 0.321992, acc 0.875\n",
      "2018-05-04T17:41:38.688010: step 12859, loss 0.189994, acc 0.921875\n",
      "2018-05-04T17:41:39.714351: step 12860, loss 0.314984, acc 0.875\n",
      "2018-05-04T17:41:40.738807: step 12861, loss 0.228498, acc 0.90625\n",
      "2018-05-04T17:41:41.745348: step 12862, loss 0.13966, acc 0.953125\n",
      "2018-05-04T17:41:42.757658: step 12863, loss 0.237311, acc 0.90625\n",
      "2018-05-04T17:41:43.780541: step 12864, loss 0.406859, acc 0.8125\n",
      "2018-05-04T17:41:44.789462: step 12865, loss 0.299594, acc 0.921875\n",
      "2018-05-04T17:41:45.797519: step 12866, loss 0.338031, acc 0.8125\n",
      "2018-05-04T17:41:46.767813: step 12867, loss 0.202538, acc 0.9375\n",
      "2018-05-04T17:41:47.751089: step 12868, loss 0.403751, acc 0.859375\n",
      "2018-05-04T17:41:48.748200: step 12869, loss 0.292343, acc 0.828125\n",
      "2018-05-04T17:41:49.764281: step 12870, loss 0.357389, acc 0.8125\n",
      "2018-05-04T17:41:50.730620: step 12871, loss 0.197117, acc 0.9375\n",
      "2018-05-04T17:41:51.746363: step 12872, loss 0.313246, acc 0.875\n",
      "2018-05-04T17:41:52.777077: step 12873, loss 0.339981, acc 0.875\n",
      "2018-05-04T17:41:53.868826: step 12874, loss 0.24071, acc 0.890625\n",
      "2018-05-04T17:41:54.861924: step 12875, loss 0.330633, acc 0.859375\n",
      "2018-05-04T17:41:55.886984: step 12876, loss 0.227222, acc 0.90625\n",
      "2018-05-04T17:41:56.908553: step 12877, loss 0.168309, acc 0.953125\n",
      "2018-05-04T17:41:57.929779: step 12878, loss 0.327816, acc 0.84375\n",
      "2018-05-04T17:41:58.960942: step 12879, loss 0.264547, acc 0.875\n",
      "2018-05-04T17:41:59.997977: step 12880, loss 0.294857, acc 0.921875\n",
      "2018-05-04T17:42:00.991398: step 12881, loss 0.353911, acc 0.84375\n",
      "2018-05-04T17:42:02.055313: step 12882, loss 0.172132, acc 0.96875\n",
      "2018-05-04T17:42:03.069920: step 12883, loss 0.326649, acc 0.828125\n",
      "2018-05-04T17:42:04.062951: step 12884, loss 0.313489, acc 0.859375\n",
      "2018-05-04T17:42:05.079181: step 12885, loss 0.222544, acc 0.921875\n",
      "2018-05-04T17:42:06.064298: step 12886, loss 0.173471, acc 0.9375\n",
      "2018-05-04T17:42:07.072502: step 12887, loss 0.267363, acc 0.90625\n",
      "2018-05-04T17:42:08.097632: step 12888, loss 0.292804, acc 0.90625\n",
      "2018-05-04T17:42:09.123340: step 12889, loss 0.363791, acc 0.859375\n",
      "2018-05-04T17:42:10.131642: step 12890, loss 0.227003, acc 0.9375\n",
      "2018-05-04T17:42:11.153673: step 12891, loss 0.316062, acc 0.890625\n",
      "2018-05-04T17:42:12.179843: step 12892, loss 0.414197, acc 0.828125\n",
      "2018-05-04T17:42:13.183054: step 12893, loss 0.194987, acc 0.9375\n",
      "2018-05-04T17:42:14.217386: step 12894, loss 0.338794, acc 0.890625\n",
      "2018-05-04T17:42:15.198576: step 12895, loss 0.315759, acc 0.90625\n",
      "2018-05-04T17:42:16.180141: step 12896, loss 0.233172, acc 0.90625\n",
      "2018-05-04T17:42:17.200016: step 12897, loss 0.213054, acc 0.921875\n",
      "2018-05-04T17:42:18.203275: step 12898, loss 0.304385, acc 0.90625\n",
      "2018-05-04T17:42:19.217381: step 12899, loss 0.32601, acc 0.859375\n",
      "2018-05-04T17:42:20.228322: step 12900, loss 0.2734, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T17:42:23.206822: step 12900, loss 0.234311, acc 0.912\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-12900\n",
      "\n",
      "2018-05-04T17:42:24.309674: step 12901, loss 0.411341, acc 0.84375\n",
      "2018-05-04T17:42:25.327574: step 12902, loss 0.27935, acc 0.875\n",
      "2018-05-04T17:42:26.362245: step 12903, loss 0.295014, acc 0.90625\n",
      "2018-05-04T17:42:27.409783: step 12904, loss 0.2597, acc 0.890625\n",
      "2018-05-04T17:42:28.455960: step 12905, loss 0.288612, acc 0.90625\n",
      "2018-05-04T17:42:29.602748: step 12906, loss 0.310722, acc 0.859375\n",
      "2018-05-04T17:42:30.658807: step 12907, loss 0.216347, acc 0.90625\n",
      "2018-05-04T17:42:31.672005: step 12908, loss 0.318212, acc 0.890625\n",
      "2018-05-04T17:42:32.665909: step 12909, loss 0.273241, acc 0.890625\n",
      "2018-05-04T17:42:33.750867: step 12910, loss 0.262458, acc 0.875\n",
      "2018-05-04T17:42:34.770537: step 12911, loss 0.28374, acc 0.90625\n",
      "2018-05-04T17:42:35.769418: step 12912, loss 0.211291, acc 0.921875\n",
      "2018-05-04T17:42:36.782052: step 12913, loss 0.242868, acc 0.90625\n",
      "2018-05-04T17:42:37.785475: step 12914, loss 0.297878, acc 0.90625\n",
      "2018-05-04T17:42:38.845561: step 12915, loss 0.278404, acc 0.890625\n",
      "2018-05-04T17:42:39.801635: step 12916, loss 0.327789, acc 0.875\n",
      "2018-05-04T17:42:40.765665: step 12917, loss 0.336245, acc 0.90625\n",
      "2018-05-04T17:42:41.801574: step 12918, loss 0.346398, acc 0.828125\n",
      "2018-05-04T17:42:42.764525: step 12919, loss 0.343411, acc 0.875\n",
      "2018-05-04T17:42:43.762914: step 12920, loss 0.363653, acc 0.84375\n",
      "2018-05-04T17:42:44.745006: step 12921, loss 0.439655, acc 0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T17:42:45.750096: step 12922, loss 0.291179, acc 0.84375\n",
      "2018-05-04T17:42:46.743545: step 12923, loss 0.281497, acc 0.859375\n",
      "2018-05-04T17:42:47.741085: step 12924, loss 0.263237, acc 0.875\n",
      "2018-05-04T17:42:48.729098: step 12925, loss 0.320336, acc 0.90625\n",
      "2018-05-04T17:42:49.720287: step 12926, loss 0.253211, acc 0.90625\n",
      "2018-05-04T17:42:50.728884: step 12927, loss 0.258087, acc 0.90625\n",
      "2018-05-04T17:42:51.728269: step 12928, loss 0.234215, acc 0.90625\n",
      "2018-05-04T17:42:52.714281: step 12929, loss 0.30197, acc 0.875\n",
      "2018-05-04T17:42:53.708199: step 12930, loss 0.306076, acc 0.890625\n",
      "2018-05-04T17:42:54.694030: step 12931, loss 0.39544, acc 0.875\n",
      "2018-05-04T17:42:55.705535: step 12932, loss 0.293431, acc 0.84375\n",
      "2018-05-04T17:42:56.677313: step 12933, loss 0.271283, acc 0.84375\n",
      "2018-05-04T17:42:57.672662: step 12934, loss 0.253653, acc 0.859375\n",
      "2018-05-04T17:42:58.659422: step 12935, loss 0.289441, acc 0.875\n",
      "2018-05-04T17:42:59.637861: step 12936, loss 0.415473, acc 0.859375\n",
      "2018-05-04T17:43:00.616067: step 12937, loss 0.238574, acc 0.921875\n",
      "2018-05-04T17:43:01.622747: step 12938, loss 0.336114, acc 0.890625\n",
      "2018-05-04T17:43:02.686105: step 12939, loss 0.347984, acc 0.84375\n",
      "2018-05-04T17:43:03.702949: step 12940, loss 0.293284, acc 0.875\n",
      "2018-05-04T17:43:04.778750: step 12941, loss 0.203519, acc 0.921875\n",
      "2018-05-04T17:43:05.762125: step 12942, loss 0.203063, acc 0.9375\n",
      "2018-05-04T17:43:06.742091: step 12943, loss 0.243606, acc 0.90625\n",
      "2018-05-04T17:43:07.741595: step 12944, loss 0.28972, acc 0.859375\n",
      "2018-05-04T17:43:08.729681: step 12945, loss 0.232942, acc 0.890625\n",
      "2018-05-04T17:43:09.703414: step 12946, loss 0.310074, acc 0.875\n",
      "2018-05-04T17:43:10.684886: step 12947, loss 0.221633, acc 0.859375\n",
      "2018-05-04T17:43:11.681550: step 12948, loss 0.235738, acc 0.9375\n",
      "2018-05-04T17:43:12.659961: step 12949, loss 0.256257, acc 0.921875\n",
      "2018-05-04T17:43:13.665941: step 12950, loss 0.326799, acc 0.875\n",
      "2018-05-04T17:43:14.685680: step 12951, loss 0.140158, acc 0.96875\n",
      "2018-05-04T17:43:15.758749: step 12952, loss 0.292274, acc 0.84375\n",
      "2018-05-04T17:43:16.744206: step 12953, loss 0.271085, acc 0.921875\n",
      "2018-05-04T17:43:17.753877: step 12954, loss 0.24527, acc 0.90625\n",
      "2018-05-04T17:43:18.732307: step 12955, loss 0.444229, acc 0.84375\n",
      "2018-05-04T17:43:19.741068: step 12956, loss 0.262897, acc 0.875\n",
      "2018-05-04T17:43:20.725262: step 12957, loss 0.320231, acc 0.828125\n",
      "2018-05-04T17:43:21.707403: step 12958, loss 0.300202, acc 0.859375\n",
      "2018-05-04T17:43:22.688151: step 12959, loss 0.248271, acc 0.921875\n",
      "2018-05-04T17:43:23.668399: step 12960, loss 0.458129, acc 0.78125\n",
      "2018-05-04T17:43:24.646434: step 12961, loss 0.376525, acc 0.859375\n",
      "2018-05-04T17:43:25.619948: step 12962, loss 0.248735, acc 0.921875\n",
      "2018-05-04T17:43:26.606066: step 12963, loss 0.22937, acc 0.90625\n",
      "2018-05-04T17:43:27.598723: step 12964, loss 0.234212, acc 0.890625\n",
      "2018-05-04T17:43:28.576861: step 12965, loss 0.18714, acc 0.953125\n",
      "2018-05-04T17:43:29.589286: step 12966, loss 0.347707, acc 0.859375\n",
      "2018-05-04T17:43:30.569761: step 12967, loss 0.284335, acc 0.875\n",
      "2018-05-04T17:43:31.646836: step 12968, loss 0.182657, acc 0.9375\n",
      "2018-05-04T17:43:32.671861: step 12969, loss 0.270003, acc 0.90625\n",
      "2018-05-04T17:43:33.729945: step 12970, loss 0.3071, acc 0.84375\n",
      "2018-05-04T17:43:34.756742: step 12971, loss 0.311058, acc 0.796875\n",
      "2018-05-04T17:43:35.849036: step 12972, loss 0.21574, acc 0.90625\n",
      "2018-05-04T17:43:36.886207: step 12973, loss 0.280233, acc 0.859375\n",
      "2018-05-04T17:43:37.894323: step 12974, loss 0.294955, acc 0.90625\n",
      "2018-05-04T17:43:38.894579: step 12975, loss 0.362986, acc 0.875\n",
      "2018-05-04T17:43:39.872733: step 12976, loss 0.26901, acc 0.84375\n",
      "2018-05-04T17:43:40.846229: step 12977, loss 0.215136, acc 0.921875\n",
      "2018-05-04T17:43:41.901650: step 12978, loss 0.283893, acc 0.921875\n",
      "2018-05-04T17:43:42.865126: step 12979, loss 0.283333, acc 0.859375\n",
      "2018-05-04T17:43:43.924875: step 12980, loss 0.220267, acc 0.90625\n",
      "2018-05-04T17:43:44.883171: step 12981, loss 0.190369, acc 0.953125\n",
      "2018-05-04T17:43:45.849032: step 12982, loss 0.196865, acc 0.921875\n",
      "2018-05-04T17:43:46.895480: step 12983, loss 0.208693, acc 0.921875\n",
      "2018-05-04T17:43:47.852882: step 12984, loss 0.303665, acc 0.890625\n",
      "2018-05-04T17:43:48.827452: step 12985, loss 0.296381, acc 0.84375\n",
      "2018-05-04T17:43:49.812905: step 12986, loss 0.207623, acc 0.90625\n",
      "2018-05-04T17:43:50.857377: step 12987, loss 0.466015, acc 0.765625\n",
      "2018-05-04T17:43:51.909481: step 12988, loss 0.285186, acc 0.90625\n",
      "2018-05-04T17:43:52.965264: step 12989, loss 0.265862, acc 0.921875\n",
      "2018-05-04T17:43:53.938534: step 12990, loss 0.338002, acc 0.859375\n",
      "2018-05-04T17:43:54.899151: step 12991, loss 0.276041, acc 0.890625\n",
      "2018-05-04T17:43:55.860580: step 12992, loss 0.31897, acc 0.875\n",
      "2018-05-04T17:43:56.815410: step 12993, loss 0.21074, acc 0.890625\n",
      "2018-05-04T17:43:57.858350: step 12994, loss 0.230841, acc 0.90625\n",
      "2018-05-04T17:43:58.898349: step 12995, loss 0.213367, acc 0.9375\n",
      "2018-05-04T17:43:59.851294: step 12996, loss 0.267321, acc 0.859375\n",
      "2018-05-04T17:44:00.826965: step 12997, loss 0.222748, acc 0.9375\n",
      "2018-05-04T17:44:01.784578: step 12998, loss 0.206865, acc 0.890625\n",
      "2018-05-04T17:44:02.749480: step 12999, loss 0.113703, acc 0.984375\n",
      "2018-05-04T17:44:03.745070: step 13000, loss 0.263868, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T17:44:06.271267: step 13000, loss 0.22874, acc 0.908\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-13000\n",
      "\n",
      "2018-05-04T17:44:07.433838: step 13001, loss 0.211381, acc 0.921875\n",
      "2018-05-04T17:44:08.443712: step 13002, loss 0.30279, acc 0.84375\n",
      "2018-05-04T17:44:09.528314: step 13003, loss 0.236865, acc 0.921875\n",
      "2018-05-04T17:44:10.589012: step 13004, loss 0.347828, acc 0.859375\n",
      "2018-05-04T17:44:11.618415: step 13005, loss 0.3856, acc 0.8125\n",
      "2018-05-04T17:44:12.695422: step 13006, loss 0.426923, acc 0.828125\n",
      "2018-05-04T17:44:13.781943: step 13007, loss 0.200093, acc 0.90625\n",
      "2018-05-04T17:44:14.878634: step 13008, loss 0.340534, acc 0.859375\n",
      "2018-05-04T17:44:15.940745: step 13009, loss 0.376058, acc 0.828125\n",
      "2018-05-04T17:44:16.952599: step 13010, loss 0.252734, acc 0.921875\n",
      "2018-05-04T17:44:17.959662: step 13011, loss 0.162983, acc 0.9375\n",
      "2018-05-04T17:44:18.965584: step 13012, loss 0.322572, acc 0.84375\n",
      "2018-05-04T17:44:20.052473: step 13013, loss 0.422054, acc 0.90625\n",
      "2018-05-04T17:44:21.059105: step 13014, loss 0.257733, acc 0.921875\n",
      "2018-05-04T17:44:22.042691: step 13015, loss 0.153358, acc 0.9375\n",
      "2018-05-04T17:44:23.043557: step 13016, loss 0.199675, acc 0.953125\n",
      "2018-05-04T17:44:24.104347: step 13017, loss 0.286325, acc 0.875\n",
      "2018-05-04T17:44:25.091181: step 13018, loss 0.324113, acc 0.859375\n",
      "2018-05-04T17:44:26.139605: step 13019, loss 0.295245, acc 0.921875\n",
      "2018-05-04T17:44:27.122683: step 13020, loss 0.228224, acc 0.9375\n",
      "2018-05-04T17:44:28.111924: step 13021, loss 0.227548, acc 0.859375\n",
      "2018-05-04T17:44:29.111669: step 13022, loss 0.328882, acc 0.890625\n",
      "2018-05-04T17:44:30.099016: step 13023, loss 0.266651, acc 0.875\n",
      "2018-05-04T17:44:31.087188: step 13024, loss 0.262458, acc 0.859375\n",
      "2018-05-04T17:44:32.065673: step 13025, loss 0.256893, acc 0.859375\n",
      "2018-05-04T17:44:33.061502: step 13026, loss 0.266199, acc 0.890625\n",
      "2018-05-04T17:44:34.197635: step 13027, loss 0.204574, acc 0.921875\n",
      "2018-05-04T17:44:35.168967: step 13028, loss 0.179771, acc 0.953125\n",
      "2018-05-04T17:44:36.179933: step 13029, loss 0.305583, acc 0.859375\n",
      "2018-05-04T17:44:37.176637: step 13030, loss 0.105966, acc 0.96875\n",
      "2018-05-04T17:44:38.179334: step 13031, loss 0.250326, acc 0.9375\n",
      "2018-05-04T17:44:39.187802: step 13032, loss 0.324588, acc 0.890625\n",
      "2018-05-04T17:44:40.201368: step 13033, loss 0.303662, acc 0.8125\n",
      "2018-05-04T17:44:41.192471: step 13034, loss 0.233515, acc 0.9375\n",
      "2018-05-04T17:44:42.189017: step 13035, loss 0.26068, acc 0.875\n",
      "2018-05-04T17:44:43.178729: step 13036, loss 0.197101, acc 0.9375\n",
      "2018-05-04T17:44:44.168796: step 13037, loss 0.356068, acc 0.859375\n",
      "2018-05-04T17:44:45.169353: step 13038, loss 0.258286, acc 0.90625\n",
      "2018-05-04T17:44:46.201747: step 13039, loss 0.172222, acc 0.9375\n",
      "2018-05-04T17:44:47.237901: step 13040, loss 0.127307, acc 0.9375\n",
      "2018-05-04T17:44:48.235684: step 13041, loss 0.165038, acc 0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T17:44:49.226490: step 13042, loss 0.200084, acc 0.875\n",
      "2018-05-04T17:44:50.214189: step 13043, loss 0.305111, acc 0.890625\n",
      "2018-05-04T17:44:51.217636: step 13044, loss 0.256207, acc 0.90625\n",
      "2018-05-04T17:44:52.195972: step 13045, loss 0.279363, acc 0.9375\n",
      "2018-05-04T17:44:53.248644: step 13046, loss 0.198596, acc 0.890625\n",
      "2018-05-04T17:44:54.224853: step 13047, loss 0.169608, acc 0.9375\n",
      "2018-05-04T17:44:55.211588: step 13048, loss 0.244826, acc 0.921875\n",
      "2018-05-04T17:44:56.208780: step 13049, loss 0.405356, acc 0.8125\n",
      "2018-05-04T17:44:57.202579: step 13050, loss 0.356498, acc 0.859375\n",
      "2018-05-04T17:44:58.180612: step 13051, loss 0.374616, acc 0.859375\n",
      "2018-05-04T17:44:59.157099: step 13052, loss 0.402885, acc 0.84375\n",
      "2018-05-04T17:45:00.201603: step 13053, loss 0.350625, acc 0.875\n",
      "2018-05-04T17:45:01.212257: step 13054, loss 0.258814, acc 0.921875\n",
      "2018-05-04T17:45:02.233133: step 13055, loss 0.195359, acc 0.875\n",
      "2018-05-04T17:45:03.270505: step 13056, loss 0.351562, acc 0.84375\n",
      "2018-05-04T17:45:04.307324: step 13057, loss 0.175874, acc 0.90625\n",
      "2018-05-04T17:45:05.339618: step 13058, loss 0.190207, acc 0.9375\n",
      "2018-05-04T17:45:06.311536: step 13059, loss 0.312527, acc 0.875\n",
      "2018-05-04T17:45:07.296107: step 13060, loss 0.186871, acc 0.90625\n",
      "2018-05-04T17:45:08.283243: step 13061, loss 0.312161, acc 0.8125\n",
      "2018-05-04T17:45:09.281346: step 13062, loss 0.214358, acc 0.90625\n",
      "2018-05-04T17:45:10.339873: step 13063, loss 0.194959, acc 0.953125\n",
      "2018-05-04T17:45:11.398175: step 13064, loss 0.238862, acc 0.921875\n",
      "2018-05-04T17:45:12.380339: step 13065, loss 0.192097, acc 0.9375\n",
      "2018-05-04T17:45:13.357455: step 13066, loss 0.282073, acc 0.875\n",
      "2018-05-04T17:45:14.363901: step 13067, loss 0.312077, acc 0.859375\n",
      "2018-05-04T17:45:15.339609: step 13068, loss 0.145836, acc 0.96875\n",
      "2018-05-04T17:45:16.352647: step 13069, loss 0.32219, acc 0.859375\n",
      "2018-05-04T17:45:17.389401: step 13070, loss 0.160399, acc 0.953125\n",
      "2018-05-04T17:45:18.393577: step 13071, loss 0.348331, acc 0.828125\n",
      "2018-05-04T17:45:19.395622: step 13072, loss 0.300575, acc 0.828125\n",
      "2018-05-04T17:45:20.418657: step 13073, loss 0.262911, acc 0.890625\n",
      "2018-05-04T17:45:21.464947: step 13074, loss 0.278882, acc 0.890625\n",
      "2018-05-04T17:45:22.469268: step 13075, loss 0.290742, acc 0.875\n",
      "2018-05-04T17:45:23.483165: step 13076, loss 0.258105, acc 0.90625\n",
      "2018-05-04T17:45:24.496708: step 13077, loss 0.365524, acc 0.859375\n",
      "2018-05-04T17:45:25.470846: step 13078, loss 0.270759, acc 0.921875\n",
      "2018-05-04T17:45:26.439046: step 13079, loss 0.198333, acc 0.921875\n",
      "2018-05-04T17:45:27.410823: step 13080, loss 0.159162, acc 0.9375\n",
      "2018-05-04T17:45:28.470426: step 13081, loss 0.310577, acc 0.84375\n",
      "2018-05-04T17:45:29.453234: step 13082, loss 0.167916, acc 0.953125\n",
      "2018-05-04T17:45:30.439251: step 13083, loss 0.302182, acc 0.890625\n",
      "2018-05-04T17:45:31.488336: step 13084, loss 0.280672, acc 0.859375\n",
      "2018-05-04T17:45:32.469536: step 13085, loss 0.208197, acc 0.9375\n",
      "2018-05-04T17:45:33.450421: step 13086, loss 0.32602, acc 0.859375\n",
      "2018-05-04T17:45:34.452285: step 13087, loss 0.265253, acc 0.90625\n",
      "2018-05-04T17:45:35.455324: step 13088, loss 0.266037, acc 0.9375\n",
      "2018-05-04T17:45:36.523480: step 13089, loss 0.338786, acc 0.859375\n",
      "2018-05-04T17:45:37.523421: step 13090, loss 0.3708, acc 0.84375\n",
      "2018-05-04T17:45:38.504015: step 13091, loss 0.302012, acc 0.890625\n",
      "2018-05-04T17:45:39.479059: step 13092, loss 0.273082, acc 0.84375\n",
      "2018-05-04T17:45:40.449840: step 13093, loss 0.28902, acc 0.890625\n",
      "2018-05-04T17:45:41.438333: step 13094, loss 0.18504, acc 0.96875\n",
      "2018-05-04T17:45:42.422135: step 13095, loss 0.343276, acc 0.84375\n",
      "2018-05-04T17:45:43.399764: step 13096, loss 0.216399, acc 0.90625\n",
      "2018-05-04T17:45:44.373664: step 13097, loss 0.268576, acc 0.875\n",
      "2018-05-04T17:45:45.333881: step 13098, loss 0.171907, acc 0.921875\n",
      "2018-05-04T17:45:46.309905: step 13099, loss 0.223951, acc 0.953125\n",
      "2018-05-04T17:45:47.303318: step 13100, loss 0.339011, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T17:45:49.501311: step 13100, loss 0.220689, acc 0.922\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-13100\n",
      "\n",
      "2018-05-04T17:45:50.589718: step 13101, loss 0.205143, acc 0.9375\n",
      "2018-05-04T17:45:51.576070: step 13102, loss 0.19508, acc 0.90625\n",
      "2018-05-04T17:45:52.575495: step 13103, loss 0.363252, acc 0.859375\n",
      "2018-05-04T17:45:53.537648: step 13104, loss 0.24483, acc 0.921875\n",
      "2018-05-04T17:45:54.510832: step 13105, loss 0.174033, acc 0.9375\n",
      "2018-05-04T17:45:55.477018: step 13106, loss 0.211172, acc 0.890625\n",
      "2018-05-04T17:45:56.443495: step 13107, loss 0.325457, acc 0.8125\n",
      "2018-05-04T17:45:57.424277: step 13108, loss 0.242191, acc 0.859375\n",
      "2018-05-04T17:45:58.400918: step 13109, loss 0.335153, acc 0.828125\n",
      "2018-05-04T17:45:59.408357: step 13110, loss 0.427724, acc 0.84375\n",
      "2018-05-04T17:46:00.405004: step 13111, loss 0.171737, acc 0.9375\n",
      "2018-05-04T17:46:01.396313: step 13112, loss 0.30258, acc 0.875\n",
      "2018-05-04T17:46:02.387731: step 13113, loss 0.364705, acc 0.859375\n",
      "2018-05-04T17:46:03.359226: step 13114, loss 0.270998, acc 0.921875\n",
      "2018-05-04T17:46:04.397772: step 13115, loss 0.243938, acc 0.90625\n",
      "2018-05-04T17:46:05.356869: step 13116, loss 0.358472, acc 0.84375\n",
      "2018-05-04T17:46:06.319913: step 13117, loss 0.236418, acc 0.921875\n",
      "2018-05-04T17:46:07.328402: step 13118, loss 0.151473, acc 0.96875\n",
      "2018-05-04T17:46:08.314692: step 13119, loss 0.237114, acc 0.921875\n",
      "2018-05-04T17:46:09.319735: step 13120, loss 0.182335, acc 0.953125\n",
      "2018-05-04T17:46:10.304592: step 13121, loss 0.340346, acc 0.84375\n",
      "2018-05-04T17:46:11.283812: step 13122, loss 0.336032, acc 0.828125\n",
      "2018-05-04T17:46:12.245878: step 13123, loss 0.282441, acc 0.90625\n",
      "2018-05-04T17:46:13.206772: step 13124, loss 0.250538, acc 0.890625\n",
      "2018-05-04T17:46:14.180379: step 13125, loss 0.351172, acc 0.859375\n",
      "2018-05-04T17:46:15.144538: step 13126, loss 0.318563, acc 0.828125\n",
      "2018-05-04T17:46:16.124068: step 13127, loss 0.355349, acc 0.859375\n",
      "2018-05-04T17:46:17.106492: step 13128, loss 0.229075, acc 0.875\n",
      "2018-05-04T17:46:18.076154: step 13129, loss 0.212084, acc 0.921875\n",
      "2018-05-04T17:46:19.069511: step 13130, loss 0.378026, acc 0.90625\n",
      "2018-05-04T17:46:20.069569: step 13131, loss 0.235833, acc 0.921875\n",
      "2018-05-04T17:46:21.028499: step 13132, loss 0.249844, acc 0.890625\n",
      "2018-05-04T17:46:21.994430: step 13133, loss 0.393544, acc 0.765625\n",
      "2018-05-04T17:46:22.944371: step 13134, loss 0.271966, acc 0.9375\n",
      "2018-05-04T17:46:23.920473: step 13135, loss 0.245956, acc 0.9375\n",
      "2018-05-04T17:46:25.014615: step 13136, loss 0.179724, acc 0.9375\n",
      "2018-05-04T17:46:26.025084: step 13137, loss 0.261137, acc 0.921875\n",
      "2018-05-04T17:46:27.011775: step 13138, loss 0.270079, acc 0.890625\n",
      "2018-05-04T17:46:27.976774: step 13139, loss 0.200644, acc 0.921875\n",
      "2018-05-04T17:46:28.916465: step 13140, loss 0.193716, acc 0.90625\n",
      "2018-05-04T17:46:29.872909: step 13141, loss 0.364616, acc 0.84375\n",
      "2018-05-04T17:46:30.850392: step 13142, loss 0.256911, acc 0.890625\n",
      "2018-05-04T17:46:31.907721: step 13143, loss 0.363617, acc 0.8125\n",
      "2018-05-04T17:46:32.944272: step 13144, loss 0.298791, acc 0.875\n",
      "2018-05-04T17:46:34.012771: step 13145, loss 0.27197, acc 0.90625\n",
      "2018-05-04T17:46:35.072297: step 13146, loss 0.435178, acc 0.78125\n",
      "2018-05-04T17:46:36.119878: step 13147, loss 0.287021, acc 0.890625\n",
      "2018-05-04T17:46:37.150754: step 13148, loss 0.299203, acc 0.875\n",
      "2018-05-04T17:46:38.146336: step 13149, loss 0.243746, acc 0.90625\n",
      "2018-05-04T17:46:39.132924: step 13150, loss 0.319801, acc 0.890625\n",
      "2018-05-04T17:46:40.119453: step 13151, loss 0.192423, acc 0.90625\n",
      "2018-05-04T17:46:41.098865: step 13152, loss 0.260449, acc 0.828125\n",
      "2018-05-04T17:46:42.055833: step 13153, loss 0.18139, acc 0.9375\n",
      "2018-05-04T17:46:43.085043: step 13154, loss 0.2666, acc 0.890625\n",
      "2018-05-04T17:46:44.151236: step 13155, loss 0.276534, acc 0.890625\n",
      "2018-05-04T17:46:45.184378: step 13156, loss 0.343339, acc 0.8125\n",
      "2018-05-04T17:46:46.136566: step 13157, loss 0.328669, acc 0.875\n",
      "2018-05-04T17:46:47.091758: step 13158, loss 0.145957, acc 0.953125\n",
      "2018-05-04T17:46:48.031920: step 13159, loss 0.27563, acc 0.890625\n",
      "2018-05-04T17:46:49.008905: step 13160, loss 0.269393, acc 0.875\n",
      "2018-05-04T17:46:50.044435: step 13161, loss 0.395007, acc 0.84375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T17:46:51.090402: step 13162, loss 0.335197, acc 0.828125\n",
      "2018-05-04T17:46:52.156631: step 13163, loss 0.249415, acc 0.90625\n",
      "2018-05-04T17:46:53.106347: step 13164, loss 0.23132, acc 0.890625\n",
      "2018-05-04T17:46:54.135679: step 13165, loss 0.182328, acc 0.890625\n",
      "2018-05-04T17:46:55.073649: step 13166, loss 0.170066, acc 0.9375\n",
      "2018-05-04T17:46:56.021685: step 13167, loss 0.34278, acc 0.828125\n",
      "2018-05-04T17:46:56.967905: step 13168, loss 0.384132, acc 0.859375\n",
      "2018-05-04T17:46:57.928077: step 13169, loss 0.19242, acc 0.921875\n",
      "2018-05-04T17:46:58.981254: step 13170, loss 0.358139, acc 0.90625\n",
      "2018-05-04T17:46:59.953301: step 13171, loss 0.282093, acc 0.875\n",
      "2018-05-04T17:47:00.910901: step 13172, loss 0.280492, acc 0.9375\n",
      "2018-05-04T17:47:01.951718: step 13173, loss 0.31254, acc 0.84375\n",
      "2018-05-04T17:47:02.978853: step 13174, loss 0.158512, acc 0.96875\n",
      "2018-05-04T17:47:03.985593: step 13175, loss 0.231947, acc 0.9375\n",
      "2018-05-04T17:47:05.033997: step 13176, loss 0.138913, acc 0.9375\n",
      "2018-05-04T17:47:05.996547: step 13177, loss 0.216163, acc 0.890625\n",
      "2018-05-04T17:47:06.949577: step 13178, loss 0.345978, acc 0.84375\n",
      "2018-05-04T17:47:07.901167: step 13179, loss 0.330648, acc 0.875\n",
      "2018-05-04T17:47:08.866211: step 13180, loss 0.341015, acc 0.84375\n",
      "2018-05-04T17:47:09.869026: step 13181, loss 0.299446, acc 0.875\n",
      "2018-05-04T17:47:10.827397: step 13182, loss 0.180234, acc 0.921875\n",
      "2018-05-04T17:47:11.844518: step 13183, loss 0.22961, acc 0.90625\n",
      "2018-05-04T17:47:12.857011: step 13184, loss 0.275891, acc 0.90625\n",
      "2018-05-04T17:47:13.807768: step 13185, loss 0.209455, acc 0.921875\n",
      "2018-05-04T17:47:14.796785: step 13186, loss 0.247944, acc 0.875\n",
      "2018-05-04T17:47:15.842558: step 13187, loss 0.295067, acc 0.890625\n",
      "2018-05-04T17:47:16.875486: step 13188, loss 0.229424, acc 0.9375\n",
      "2018-05-04T17:47:17.878396: step 13189, loss 0.326391, acc 0.875\n",
      "2018-05-04T17:47:18.923041: step 13190, loss 0.299135, acc 0.859375\n",
      "2018-05-04T17:47:19.972626: step 13191, loss 0.243729, acc 0.9375\n",
      "2018-05-04T17:47:20.938910: step 13192, loss 0.417265, acc 0.875\n",
      "2018-05-04T17:47:21.973044: step 13193, loss 0.370816, acc 0.84375\n",
      "2018-05-04T17:47:22.985776: step 13194, loss 0.264613, acc 0.859375\n",
      "2018-05-04T17:47:23.911234: step 13195, loss 0.218145, acc 0.921875\n",
      "2018-05-04T17:47:24.895095: step 13196, loss 0.30091, acc 0.90625\n",
      "2018-05-04T17:47:25.869194: step 13197, loss 0.164418, acc 0.953125\n",
      "2018-05-04T17:47:26.831166: step 13198, loss 0.220134, acc 0.90625\n",
      "2018-05-04T17:47:27.787730: step 13199, loss 0.174033, acc 0.9375\n",
      "2018-05-04T17:47:28.803491: step 13200, loss 0.376162, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T17:47:31.850676: step 13200, loss 0.228407, acc 0.914\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-13200\n",
      "\n",
      "2018-05-04T17:47:32.962803: step 13201, loss 0.2897, acc 0.890625\n",
      "2018-05-04T17:47:33.972072: step 13202, loss 0.340858, acc 0.921875\n",
      "2018-05-04T17:47:34.975244: step 13203, loss 0.354454, acc 0.859375\n",
      "2018-05-04T17:47:35.999273: step 13204, loss 0.164911, acc 0.9375\n",
      "2018-05-04T17:47:37.034862: step 13205, loss 0.284927, acc 0.859375\n",
      "2018-05-04T17:47:38.084516: step 13206, loss 0.166914, acc 0.953125\n",
      "2018-05-04T17:47:39.157425: step 13207, loss 0.228111, acc 0.890625\n",
      "2018-05-04T17:47:40.202996: step 13208, loss 0.17783, acc 0.953125\n",
      "2018-05-04T17:47:41.237416: step 13209, loss 0.375308, acc 0.828125\n",
      "2018-05-04T17:47:42.256971: step 13210, loss 0.298719, acc 0.875\n",
      "2018-05-04T17:47:43.277154: step 13211, loss 0.253677, acc 0.90625\n",
      "2018-05-04T17:47:44.279886: step 13212, loss 0.339645, acc 0.90625\n",
      "2018-05-04T17:47:45.300923: step 13213, loss 0.149879, acc 0.9375\n",
      "2018-05-04T17:47:46.338353: step 13214, loss 0.204571, acc 0.90625\n",
      "2018-05-04T17:47:47.351868: step 13215, loss 0.222833, acc 0.890625\n",
      "2018-05-04T17:47:48.347858: step 13216, loss 0.294548, acc 0.890625\n",
      "2018-05-04T17:47:49.356445: step 13217, loss 0.253295, acc 0.921875\n",
      "2018-05-04T17:47:50.360662: step 13218, loss 0.200088, acc 0.921875\n",
      "2018-05-04T17:47:51.361994: step 13219, loss 0.163604, acc 0.90625\n",
      "2018-05-04T17:47:52.378574: step 13220, loss 0.237419, acc 0.875\n",
      "2018-05-04T17:47:53.356896: step 13221, loss 0.228156, acc 0.875\n",
      "2018-05-04T17:47:54.339676: step 13222, loss 0.312401, acc 0.859375\n",
      "2018-05-04T17:47:55.333405: step 13223, loss 0.28024, acc 0.921875\n",
      "2018-05-04T17:47:56.342493: step 13224, loss 0.292154, acc 0.90625\n",
      "2018-05-04T17:47:57.340559: step 13225, loss 0.365543, acc 0.859375\n",
      "2018-05-04T17:47:58.328326: step 13226, loss 0.38808, acc 0.859375\n",
      "2018-05-04T17:47:59.346335: step 13227, loss 0.274858, acc 0.859375\n",
      "2018-05-04T17:48:00.329508: step 13228, loss 0.258892, acc 0.90625\n",
      "2018-05-04T17:48:01.429171: step 13229, loss 0.2281, acc 0.90625\n",
      "2018-05-04T17:48:02.501641: step 13230, loss 0.289256, acc 0.875\n",
      "2018-05-04T17:48:03.467021: step 13231, loss 0.115875, acc 0.984375\n",
      "2018-05-04T17:48:04.432643: step 13232, loss 0.284656, acc 0.875\n",
      "2018-05-04T17:48:05.449405: step 13233, loss 0.191141, acc 0.953125\n",
      "2018-05-04T17:48:06.436498: step 13234, loss 0.372118, acc 0.890625\n",
      "2018-05-04T17:48:07.446893: step 13235, loss 0.2601, acc 0.875\n",
      "2018-05-04T17:48:08.465784: step 13236, loss 0.27948, acc 0.859375\n",
      "2018-05-04T17:48:09.440067: step 13237, loss 0.281546, acc 0.875\n",
      "2018-05-04T17:48:10.446882: step 13238, loss 0.20737, acc 0.890625\n",
      "2018-05-04T17:48:11.471042: step 13239, loss 0.448149, acc 0.8125\n",
      "2018-05-04T17:48:12.453191: step 13240, loss 0.48844, acc 0.796875\n",
      "2018-05-04T17:48:13.444858: step 13241, loss 0.18685, acc 0.96875\n",
      "2018-05-04T17:48:14.467753: step 13242, loss 0.183199, acc 0.90625\n",
      "2018-05-04T17:48:15.460877: step 13243, loss 0.488092, acc 0.8125\n",
      "2018-05-04T17:48:16.466827: step 13244, loss 0.214696, acc 0.890625\n",
      "2018-05-04T17:48:17.466295: step 13245, loss 0.253746, acc 0.90625\n",
      "2018-05-04T17:48:18.482140: step 13246, loss 0.160871, acc 0.953125\n",
      "2018-05-04T17:48:19.497858: step 13247, loss 0.41075, acc 0.859375\n",
      "2018-05-04T17:48:20.497492: step 13248, loss 0.216226, acc 0.921875\n",
      "2018-05-04T17:48:21.509529: step 13249, loss 0.278441, acc 0.90625\n",
      "2018-05-04T17:48:22.512358: step 13250, loss 0.236614, acc 0.90625\n",
      "2018-05-04T17:48:23.491432: step 13251, loss 0.340363, acc 0.859375\n",
      "2018-05-04T17:48:24.469910: step 13252, loss 0.303442, acc 0.875\n",
      "2018-05-04T17:48:25.513694: step 13253, loss 0.348927, acc 0.8125\n",
      "2018-05-04T17:48:26.502558: step 13254, loss 0.3625, acc 0.875\n",
      "2018-05-04T17:48:27.514362: step 13255, loss 0.187638, acc 0.90625\n",
      "2018-05-04T17:48:28.520482: step 13256, loss 0.210512, acc 0.875\n",
      "2018-05-04T17:48:29.524112: step 13257, loss 0.340443, acc 0.8125\n",
      "2018-05-04T17:48:30.525881: step 13258, loss 0.34738, acc 0.84375\n",
      "2018-05-04T17:48:31.516915: step 13259, loss 0.244998, acc 0.921875\n",
      "2018-05-04T17:48:32.505887: step 13260, loss 0.383557, acc 0.859375\n",
      "2018-05-04T17:48:33.510429: step 13261, loss 0.319469, acc 0.875\n",
      "2018-05-04T17:48:34.495985: step 13262, loss 0.342828, acc 0.828125\n",
      "2018-05-04T17:48:35.485053: step 13263, loss 0.214539, acc 0.921875\n",
      "2018-05-04T17:48:36.480015: step 13264, loss 0.266353, acc 0.890625\n",
      "2018-05-04T17:48:37.466926: step 13265, loss 0.276357, acc 0.921875\n",
      "2018-05-04T17:48:38.461825: step 13266, loss 0.54213, acc 0.78125\n",
      "2018-05-04T17:48:39.489360: step 13267, loss 0.253, acc 0.96875\n",
      "2018-05-04T17:48:40.510285: step 13268, loss 0.216443, acc 0.890625\n",
      "2018-05-04T17:48:41.512395: step 13269, loss 0.293138, acc 0.890625\n",
      "2018-05-04T17:48:42.584796: step 13270, loss 0.23945, acc 0.90625\n",
      "2018-05-04T17:48:43.575451: step 13271, loss 0.29168, acc 0.859375\n",
      "2018-05-04T17:48:44.589024: step 13272, loss 0.268878, acc 0.859375\n",
      "2018-05-04T17:48:45.601892: step 13273, loss 0.245137, acc 0.90625\n",
      "2018-05-04T17:48:46.589687: step 13274, loss 0.290518, acc 0.9375\n",
      "2018-05-04T17:48:47.561892: step 13275, loss 0.306579, acc 0.921875\n",
      "2018-05-04T17:48:48.534857: step 13276, loss 0.276913, acc 0.921875\n",
      "2018-05-04T17:48:49.517799: step 13277, loss 0.321241, acc 0.875\n",
      "2018-05-04T17:48:50.503339: step 13278, loss 0.267258, acc 0.890625\n",
      "2018-05-04T17:48:51.544974: step 13279, loss 0.266668, acc 0.9375\n",
      "2018-05-04T17:48:52.542387: step 13280, loss 0.301126, acc 0.875\n",
      "2018-05-04T17:48:53.540700: step 13281, loss 0.449235, acc 0.84375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T17:48:54.563439: step 13282, loss 0.390595, acc 0.8125\n",
      "2018-05-04T17:48:55.565088: step 13283, loss 0.372603, acc 0.875\n",
      "2018-05-04T17:48:56.540433: step 13284, loss 0.262671, acc 0.90625\n",
      "2018-05-04T17:48:57.528139: step 13285, loss 0.391268, acc 0.8125\n",
      "2018-05-04T17:48:58.501525: step 13286, loss 0.293867, acc 0.890625\n",
      "2018-05-04T17:48:59.488635: step 13287, loss 0.23963, acc 0.859375\n",
      "2018-05-04T17:49:00.459239: step 13288, loss 0.230261, acc 0.90625\n",
      "2018-05-04T17:49:01.515948: step 13289, loss 0.377831, acc 0.90625\n",
      "2018-05-04T17:49:02.484038: step 13290, loss 0.303644, acc 0.875\n",
      "2018-05-04T17:49:03.448240: step 13291, loss 0.196849, acc 0.953125\n",
      "2018-05-04T17:49:04.435530: step 13292, loss 0.236364, acc 0.90625\n",
      "2018-05-04T17:49:05.431608: step 13293, loss 0.248825, acc 0.90625\n",
      "2018-05-04T17:49:06.422830: step 13294, loss 0.319775, acc 0.875\n",
      "2018-05-04T17:49:07.426374: step 13295, loss 0.218238, acc 0.9375\n",
      "2018-05-04T17:49:08.421054: step 13296, loss 0.21586, acc 0.90625\n",
      "2018-05-04T17:49:09.421240: step 13297, loss 0.199573, acc 0.9375\n",
      "2018-05-04T17:49:10.428381: step 13298, loss 0.255224, acc 0.90625\n",
      "2018-05-04T17:49:11.393119: step 13299, loss 0.246485, acc 0.921875\n",
      "2018-05-04T17:49:12.375442: step 13300, loss 0.278449, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T17:49:14.819877: step 13300, loss 0.245206, acc 0.902\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-13300\n",
      "\n",
      "2018-05-04T17:49:15.974377: step 13301, loss 0.265848, acc 0.875\n",
      "2018-05-04T17:49:17.091016: step 13302, loss 0.335626, acc 0.90625\n",
      "2018-05-04T17:49:18.133483: step 13303, loss 0.200954, acc 0.890625\n",
      "2018-05-04T17:49:19.168705: step 13304, loss 0.428352, acc 0.828125\n",
      "2018-05-04T17:49:20.278777: step 13305, loss 0.392024, acc 0.875\n",
      "2018-05-04T17:49:21.325695: step 13306, loss 0.29468, acc 0.875\n",
      "2018-05-04T17:49:22.337147: step 13307, loss 0.295146, acc 0.875\n",
      "2018-05-04T17:49:23.354636: step 13308, loss 0.272796, acc 0.921875\n",
      "2018-05-04T17:49:24.358015: step 13309, loss 0.236753, acc 0.921875\n",
      "2018-05-04T17:49:25.450721: step 13310, loss 0.498961, acc 0.796875\n",
      "2018-05-04T17:49:26.471322: step 13311, loss 0.366761, acc 0.8125\n",
      "2018-05-04T17:49:27.550279: step 13312, loss 0.321607, acc 0.859375\n",
      "2018-05-04T17:49:28.546092: step 13313, loss 0.302458, acc 0.890625\n",
      "2018-05-04T17:49:29.563699: step 13314, loss 0.403448, acc 0.84375\n",
      "2018-05-04T17:49:30.571977: step 13315, loss 0.216003, acc 0.890625\n",
      "2018-05-04T17:49:31.578766: step 13316, loss 0.145644, acc 0.96875\n",
      "2018-05-04T17:49:32.671176: step 13317, loss 0.191223, acc 0.953125\n",
      "2018-05-04T17:49:33.701953: step 13318, loss 0.259381, acc 0.890625\n",
      "2018-05-04T17:49:34.754514: step 13319, loss 0.408391, acc 0.8125\n",
      "2018-05-04T17:49:35.826033: step 13320, loss 0.218089, acc 0.921875\n",
      "2018-05-04T17:49:36.896676: step 13321, loss 0.222841, acc 0.921875\n",
      "2018-05-04T17:49:37.928602: step 13322, loss 0.279935, acc 0.921875\n",
      "2018-05-04T17:49:39.023264: step 13323, loss 0.304322, acc 0.84375\n",
      "2018-05-04T17:49:40.010700: step 13324, loss 0.240311, acc 0.890625\n",
      "2018-05-04T17:49:41.000421: step 13325, loss 0.246705, acc 0.859375\n",
      "2018-05-04T17:49:42.010674: step 13326, loss 0.165672, acc 0.9375\n",
      "2018-05-04T17:49:43.010831: step 13327, loss 0.242825, acc 0.90625\n",
      "2018-05-04T17:49:44.108362: step 13328, loss 0.236603, acc 0.890625\n",
      "2018-05-04T17:49:45.102904: step 13329, loss 0.204059, acc 0.890625\n",
      "2018-05-04T17:49:46.081716: step 13330, loss 0.268074, acc 0.890625\n",
      "2018-05-04T17:49:47.057632: step 13331, loss 0.255935, acc 0.890625\n",
      "2018-05-04T17:49:48.100330: step 13332, loss 0.193254, acc 0.9375\n",
      "2018-05-04T17:49:49.207440: step 13333, loss 0.361542, acc 0.84375\n",
      "2018-05-04T17:49:50.233381: step 13334, loss 0.240357, acc 0.921875\n",
      "2018-05-04T17:49:51.276079: step 13335, loss 0.170124, acc 0.921875\n",
      "2018-05-04T17:49:52.313158: step 13336, loss 0.215915, acc 0.90625\n",
      "2018-05-04T17:49:53.376900: step 13337, loss 0.321805, acc 0.859375\n",
      "2018-05-04T17:49:54.379581: step 13338, loss 0.317173, acc 0.859375\n",
      "2018-05-04T17:49:55.393010: step 13339, loss 0.198405, acc 0.9375\n",
      "2018-05-04T17:49:56.405592: step 13340, loss 0.332583, acc 0.890625\n",
      "2018-05-04T17:49:57.399093: step 13341, loss 0.378977, acc 0.859375\n",
      "2018-05-04T17:49:58.403449: step 13342, loss 0.273587, acc 0.8125\n",
      "2018-05-04T17:49:59.397555: step 13343, loss 0.338322, acc 0.859375\n",
      "2018-05-04T17:50:00.472174: step 13344, loss 0.266656, acc 0.890625\n",
      "2018-05-04T17:50:01.503434: step 13345, loss 0.342073, acc 0.859375\n",
      "2018-05-04T17:50:02.503571: step 13346, loss 0.233808, acc 0.90625\n",
      "2018-05-04T17:50:03.503282: step 13347, loss 0.217206, acc 0.859375\n",
      "2018-05-04T17:50:04.495398: step 13348, loss 0.21872, acc 0.90625\n",
      "2018-05-04T17:50:05.550991: step 13349, loss 0.175385, acc 0.921875\n",
      "2018-05-04T17:50:06.527891: step 13350, loss 0.296031, acc 0.84375\n",
      "2018-05-04T17:50:07.540597: step 13351, loss 0.307482, acc 0.859375\n",
      "2018-05-04T17:50:08.534235: step 13352, loss 0.436353, acc 0.78125\n",
      "2018-05-04T17:50:09.536940: step 13353, loss 0.220771, acc 0.90625\n",
      "2018-05-04T17:50:10.511672: step 13354, loss 0.224167, acc 0.890625\n",
      "2018-05-04T17:50:11.516560: step 13355, loss 0.368057, acc 0.890625\n",
      "2018-05-04T17:50:12.500127: step 13356, loss 0.272824, acc 0.921875\n",
      "2018-05-04T17:50:13.508518: step 13357, loss 0.315814, acc 0.890625\n",
      "2018-05-04T17:50:14.479018: step 13358, loss 0.268857, acc 0.84375\n",
      "2018-05-04T17:50:15.516311: step 13359, loss 0.425717, acc 0.84375\n",
      "2018-05-04T17:50:16.505085: step 13360, loss 0.2311, acc 0.921875\n",
      "2018-05-04T17:50:17.502098: step 13361, loss 0.357355, acc 0.859375\n",
      "2018-05-04T17:50:18.485651: step 13362, loss 0.190007, acc 0.921875\n",
      "2018-05-04T17:50:19.492437: step 13363, loss 0.320086, acc 0.921875\n",
      "2018-05-04T17:50:20.458410: step 13364, loss 0.20699, acc 0.9375\n",
      "2018-05-04T17:50:21.454892: step 13365, loss 0.400402, acc 0.828125\n",
      "2018-05-04T17:50:22.439278: step 13366, loss 0.244983, acc 0.953125\n",
      "2018-05-04T17:50:23.458875: step 13367, loss 0.235925, acc 0.9375\n",
      "2018-05-04T17:50:24.546401: step 13368, loss 0.179918, acc 0.9375\n",
      "2018-05-04T17:50:25.606126: step 13369, loss 0.231536, acc 0.890625\n",
      "2018-05-04T17:50:26.607939: step 13370, loss 0.243178, acc 0.921875\n",
      "2018-05-04T17:50:27.556423: step 13371, loss 0.192553, acc 0.953125\n",
      "2018-05-04T17:50:28.540137: step 13372, loss 0.180654, acc 0.9375\n",
      "2018-05-04T17:50:29.523605: step 13373, loss 0.260915, acc 0.890625\n",
      "2018-05-04T17:50:30.501055: step 13374, loss 0.34246, acc 0.859375\n",
      "2018-05-04T17:50:31.502654: step 13375, loss 0.345237, acc 0.828125\n",
      "2018-05-04T17:50:32.476593: step 13376, loss 0.372037, acc 0.890625\n",
      "2018-05-04T17:50:33.431705: step 13377, loss 0.151326, acc 0.9375\n",
      "2018-05-04T17:50:34.474767: step 13378, loss 0.260736, acc 0.90625\n",
      "2018-05-04T17:50:35.461463: step 13379, loss 0.337164, acc 0.875\n",
      "2018-05-04T17:50:36.464565: step 13380, loss 0.334667, acc 0.859375\n",
      "2018-05-04T17:50:37.449872: step 13381, loss 0.182574, acc 0.9375\n",
      "2018-05-04T17:50:38.446194: step 13382, loss 0.258657, acc 0.875\n",
      "2018-05-04T17:50:39.442631: step 13383, loss 0.197418, acc 0.90625\n",
      "2018-05-04T17:50:40.420325: step 13384, loss 0.247207, acc 0.90625\n",
      "2018-05-04T17:50:41.387422: step 13385, loss 0.38284, acc 0.8125\n",
      "2018-05-04T17:50:42.357550: step 13386, loss 0.223797, acc 0.90625\n",
      "2018-05-04T17:50:43.316729: step 13387, loss 0.249469, acc 0.890625\n",
      "2018-05-04T17:50:44.281860: step 13388, loss 0.301995, acc 0.90625\n",
      "2018-05-04T17:50:45.254477: step 13389, loss 0.270403, acc 0.875\n",
      "2018-05-04T17:50:46.259929: step 13390, loss 0.163634, acc 0.953125\n",
      "2018-05-04T17:50:47.252944: step 13391, loss 0.204893, acc 0.953125\n",
      "2018-05-04T17:50:48.259168: step 13392, loss 0.296586, acc 0.890625\n",
      "2018-05-04T17:50:49.284680: step 13393, loss 0.250404, acc 0.875\n",
      "2018-05-04T17:50:50.281400: step 13394, loss 0.228242, acc 0.890625\n",
      "2018-05-04T17:50:51.333677: step 13395, loss 0.269024, acc 0.90625\n",
      "2018-05-04T17:50:52.390424: step 13396, loss 0.269656, acc 0.921875\n",
      "2018-05-04T17:50:53.426899: step 13397, loss 0.239696, acc 0.890625\n",
      "2018-05-04T17:50:54.416155: step 13398, loss 0.31809, acc 0.890625\n",
      "2018-05-04T17:50:55.375316: step 13399, loss 0.23269, acc 0.9375\n",
      "2018-05-04T17:50:56.341805: step 13400, loss 0.270578, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T17:50:58.909962: step 13400, loss 0.235851, acc 0.912\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-13400\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T17:51:00.106804: step 13401, loss 0.224866, acc 0.90625\n",
      "2018-05-04T17:51:01.134073: step 13402, loss 0.229665, acc 0.90625\n",
      "2018-05-04T17:51:02.159411: step 13403, loss 0.244033, acc 0.859375\n",
      "2018-05-04T17:51:03.220665: step 13404, loss 0.222977, acc 0.90625\n",
      "2018-05-04T17:51:04.279058: step 13405, loss 0.358373, acc 0.875\n",
      "2018-05-04T17:51:05.303223: step 13406, loss 0.405505, acc 0.859375\n",
      "2018-05-04T17:51:06.321110: step 13407, loss 0.378106, acc 0.84375\n",
      "2018-05-04T17:51:07.318958: step 13408, loss 0.330238, acc 0.890625\n",
      "2018-05-04T17:51:08.340221: step 13409, loss 0.257629, acc 0.921875\n",
      "2018-05-04T17:51:09.322996: step 13410, loss 0.229749, acc 0.921875\n",
      "2018-05-04T17:51:10.322160: step 13411, loss 0.221333, acc 0.90625\n",
      "2018-05-04T17:51:11.363795: step 13412, loss 0.232973, acc 0.921875\n",
      "2018-05-04T17:51:12.369736: step 13413, loss 0.300312, acc 0.90625\n",
      "2018-05-04T17:51:13.402704: step 13414, loss 0.355006, acc 0.859375\n",
      "2018-05-04T17:51:14.513438: step 13415, loss 0.237502, acc 0.890625\n",
      "2018-05-04T17:51:15.510583: step 13416, loss 0.258178, acc 0.90625\n",
      "2018-05-04T17:51:16.510681: step 13417, loss 0.306479, acc 0.875\n",
      "2018-05-04T17:51:17.632627: step 13418, loss 0.169425, acc 0.953125\n",
      "2018-05-04T17:51:18.648795: step 13419, loss 0.243147, acc 0.921875\n",
      "2018-05-04T17:51:19.651694: step 13420, loss 0.438811, acc 0.828125\n",
      "2018-05-04T17:51:20.638852: step 13421, loss 0.209129, acc 0.921875\n",
      "2018-05-04T17:51:21.709889: step 13422, loss 0.385695, acc 0.828125\n",
      "2018-05-04T17:51:22.718732: step 13423, loss 0.223345, acc 0.90625\n",
      "2018-05-04T17:51:23.741685: step 13424, loss 0.215002, acc 0.9375\n",
      "2018-05-04T17:51:24.720323: step 13425, loss 0.193273, acc 0.9375\n",
      "2018-05-04T17:51:25.743320: step 13426, loss 0.338248, acc 0.890625\n",
      "2018-05-04T17:51:26.740643: step 13427, loss 0.229161, acc 0.9375\n",
      "2018-05-04T17:51:27.817437: step 13428, loss 0.292484, acc 0.875\n",
      "2018-05-04T17:51:28.820687: step 13429, loss 0.234431, acc 0.90625\n",
      "2018-05-04T17:51:29.798519: step 13430, loss 0.294692, acc 0.90625\n",
      "2018-05-04T17:51:30.797167: step 13431, loss 0.26621, acc 0.9375\n",
      "2018-05-04T17:51:31.794459: step 13432, loss 0.201507, acc 0.890625\n",
      "2018-05-04T17:51:32.844723: step 13433, loss 0.30459, acc 0.921875\n",
      "2018-05-04T17:51:33.873283: step 13434, loss 0.222353, acc 0.90625\n",
      "2018-05-04T17:51:34.858379: step 13435, loss 0.427405, acc 0.875\n",
      "2018-05-04T17:51:35.889781: step 13436, loss 0.27598, acc 0.875\n",
      "2018-05-04T17:51:36.877560: step 13437, loss 0.283585, acc 0.90625\n",
      "2018-05-04T17:51:37.892652: step 13438, loss 0.358234, acc 0.875\n",
      "2018-05-04T17:51:38.897595: step 13439, loss 0.329037, acc 0.875\n",
      "2018-05-04T17:51:39.895769: step 13440, loss 0.36441, acc 0.84375\n",
      "2018-05-04T17:51:40.908498: step 13441, loss 0.253367, acc 0.890625\n",
      "2018-05-04T17:51:41.943522: step 13442, loss 0.2984, acc 0.875\n",
      "2018-05-04T17:51:42.967904: step 13443, loss 0.317448, acc 0.875\n",
      "2018-05-04T17:51:43.963021: step 13444, loss 0.351544, acc 0.90625\n",
      "2018-05-04T17:51:44.962592: step 13445, loss 0.287002, acc 0.890625\n",
      "2018-05-04T17:51:45.952125: step 13446, loss 0.239531, acc 0.90625\n",
      "2018-05-04T17:51:46.954174: step 13447, loss 0.294112, acc 0.859375\n",
      "2018-05-04T17:51:47.970968: step 13448, loss 0.413958, acc 0.796875\n",
      "2018-05-04T17:51:48.974335: step 13449, loss 0.146891, acc 0.953125\n",
      "2018-05-04T17:51:49.957395: step 13450, loss 0.219208, acc 0.921875\n",
      "2018-05-04T17:51:50.953832: step 13451, loss 0.269221, acc 0.921875\n",
      "2018-05-04T17:51:51.956264: step 13452, loss 0.332395, acc 0.890625\n",
      "2018-05-04T17:51:52.942814: step 13453, loss 0.246953, acc 0.9375\n",
      "2018-05-04T17:51:53.993653: step 13454, loss 0.323659, acc 0.8125\n",
      "2018-05-04T17:51:55.013307: step 13455, loss 0.292373, acc 0.921875\n",
      "2018-05-04T17:51:56.029371: step 13456, loss 0.276337, acc 0.890625\n",
      "2018-05-04T17:51:57.032382: step 13457, loss 0.206944, acc 0.96875\n",
      "2018-05-04T17:51:58.027075: step 13458, loss 0.201615, acc 0.96875\n",
      "2018-05-04T17:51:58.999100: step 13459, loss 0.277416, acc 0.890625\n",
      "2018-05-04T17:52:00.042604: step 13460, loss 0.22217, acc 0.921875\n",
      "2018-05-04T17:52:01.054947: step 13461, loss 0.356508, acc 0.875\n",
      "2018-05-04T17:52:02.050390: step 13462, loss 0.330538, acc 0.875\n",
      "2018-05-04T17:52:03.044745: step 13463, loss 0.24275, acc 0.921875\n",
      "2018-05-04T17:52:04.028806: step 13464, loss 0.300038, acc 0.859375\n",
      "2018-05-04T17:52:05.009164: step 13465, loss 0.163551, acc 0.953125\n",
      "2018-05-04T17:52:05.999976: step 13466, loss 0.246706, acc 0.90625\n",
      "2018-05-04T17:52:07.082074: step 13467, loss 0.243429, acc 0.953125\n",
      "2018-05-04T17:52:08.077010: step 13468, loss 0.214129, acc 0.890625\n",
      "2018-05-04T17:52:09.059042: step 13469, loss 0.301368, acc 0.859375\n",
      "2018-05-04T17:52:10.040558: step 13470, loss 0.238728, acc 0.9375\n",
      "2018-05-04T17:52:11.022281: step 13471, loss 0.27022, acc 0.890625\n",
      "2018-05-04T17:52:11.982199: step 13472, loss 0.303602, acc 0.859375\n",
      "2018-05-04T17:52:12.967151: step 13473, loss 0.30618, acc 0.859375\n",
      "2018-05-04T17:52:13.977446: step 13474, loss 0.191264, acc 0.984375\n",
      "2018-05-04T17:52:14.976604: step 13475, loss 0.287957, acc 0.890625\n",
      "2018-05-04T17:52:15.963221: step 13476, loss 0.228798, acc 0.90625\n",
      "2018-05-04T17:52:16.931207: step 13477, loss 0.282036, acc 0.890625\n",
      "2018-05-04T17:52:17.909522: step 13478, loss 0.170371, acc 0.921875\n",
      "2018-05-04T17:52:18.893934: step 13479, loss 0.147621, acc 0.9375\n",
      "2018-05-04T17:52:19.934550: step 13480, loss 0.143618, acc 0.9375\n",
      "2018-05-04T17:52:20.981071: step 13481, loss 0.158516, acc 0.96875\n",
      "2018-05-04T17:52:21.943470: step 13482, loss 0.165509, acc 0.9375\n",
      "2018-05-04T17:52:22.929429: step 13483, loss 0.175842, acc 0.953125\n",
      "2018-05-04T17:52:23.975190: step 13484, loss 0.231961, acc 0.890625\n",
      "2018-05-04T17:52:24.930459: step 13485, loss 0.362492, acc 0.84375\n",
      "2018-05-04T17:52:25.912671: step 13486, loss 0.284056, acc 0.90625\n",
      "2018-05-04T17:52:26.874363: step 13487, loss 0.191721, acc 0.921875\n",
      "2018-05-04T17:52:27.870429: step 13488, loss 0.299984, acc 0.859375\n",
      "2018-05-04T17:52:28.944624: step 13489, loss 0.159073, acc 0.9375\n",
      "2018-05-04T17:52:29.922808: step 13490, loss 0.165346, acc 0.921875\n",
      "2018-05-04T17:52:30.906941: step 13491, loss 0.304149, acc 0.859375\n",
      "2018-05-04T17:52:31.875678: step 13492, loss 0.325025, acc 0.875\n",
      "2018-05-04T17:52:32.874348: step 13493, loss 0.345495, acc 0.890625\n",
      "2018-05-04T17:52:33.901901: step 13494, loss 0.185611, acc 0.9375\n",
      "2018-05-04T17:52:35.011038: step 13495, loss 0.192785, acc 0.90625\n",
      "2018-05-04T17:52:36.102169: step 13496, loss 0.334712, acc 0.875\n",
      "2018-05-04T17:52:37.144645: step 13497, loss 0.206458, acc 0.90625\n",
      "2018-05-04T17:52:38.133083: step 13498, loss 0.269083, acc 0.828125\n",
      "2018-05-04T17:52:39.137240: step 13499, loss 0.373452, acc 0.828125\n",
      "2018-05-04T17:52:40.128768: step 13500, loss 0.236123, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T17:52:42.361997: step 13500, loss 0.224919, acc 0.91\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-13500\n",
      "\n",
      "2018-05-04T17:52:43.453188: step 13501, loss 0.476804, acc 0.84375\n",
      "2018-05-04T17:52:44.420664: step 13502, loss 0.318497, acc 0.84375\n",
      "2018-05-04T17:52:45.387825: step 13503, loss 0.277688, acc 0.875\n",
      "2018-05-04T17:52:46.374609: step 13504, loss 0.291402, acc 0.875\n",
      "2018-05-04T17:52:47.354336: step 13505, loss 0.153492, acc 0.953125\n",
      "2018-05-04T17:52:48.318629: step 13506, loss 0.337371, acc 0.875\n",
      "2018-05-04T17:52:49.288330: step 13507, loss 0.487558, acc 0.84375\n",
      "2018-05-04T17:52:50.286741: step 13508, loss 0.281586, acc 0.890625\n",
      "2018-05-04T17:52:51.281540: step 13509, loss 0.243454, acc 0.921875\n",
      "2018-05-04T17:52:52.277964: step 13510, loss 0.229181, acc 0.921875\n",
      "2018-05-04T17:52:53.269966: step 13511, loss 0.243794, acc 0.890625\n",
      "2018-05-04T17:52:54.252662: step 13512, loss 0.251363, acc 0.90625\n",
      "2018-05-04T17:52:55.226465: step 13513, loss 0.228251, acc 0.890625\n",
      "2018-05-04T17:52:56.190806: step 13514, loss 0.44208, acc 0.8125\n",
      "2018-05-04T17:52:57.159932: step 13515, loss 0.194921, acc 0.921875\n",
      "2018-05-04T17:52:58.145806: step 13516, loss 0.3625, acc 0.890625\n",
      "2018-05-04T17:52:59.117243: step 13517, loss 0.189051, acc 0.953125\n",
      "2018-05-04T17:53:00.111062: step 13518, loss 0.316682, acc 0.84375\n",
      "2018-05-04T17:53:01.162746: step 13519, loss 0.24463, acc 0.875\n",
      "2018-05-04T17:53:02.216574: step 13520, loss 0.305167, acc 0.859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T17:53:03.197007: step 13521, loss 0.273574, acc 0.890625\n",
      "2018-05-04T17:53:04.193822: step 13522, loss 0.122987, acc 0.96875\n",
      "2018-05-04T17:53:05.160051: step 13523, loss 0.377317, acc 0.828125\n",
      "2018-05-04T17:53:06.128169: step 13524, loss 0.221191, acc 0.90625\n",
      "2018-05-04T17:53:07.099121: step 13525, loss 0.279236, acc 0.921875\n",
      "2018-05-04T17:53:08.071993: step 13526, loss 0.221439, acc 0.9375\n",
      "2018-05-04T17:53:09.046576: step 13527, loss 0.311476, acc 0.84375\n",
      "2018-05-04T17:53:10.045609: step 13528, loss 0.247172, acc 0.859375\n",
      "2018-05-04T17:53:11.087436: step 13529, loss 0.192961, acc 0.921875\n",
      "2018-05-04T17:53:12.076185: step 13530, loss 0.392014, acc 0.859375\n",
      "2018-05-04T17:53:13.034781: step 13531, loss 0.319009, acc 0.875\n",
      "2018-05-04T17:53:14.008706: step 13532, loss 0.288579, acc 0.875\n",
      "2018-05-04T17:53:14.968380: step 13533, loss 0.19415, acc 0.9375\n",
      "2018-05-04T17:53:16.003803: step 13534, loss 0.141099, acc 0.96875\n",
      "2018-05-04T17:53:16.975607: step 13535, loss 0.194395, acc 0.875\n",
      "2018-05-04T17:53:18.042173: step 13536, loss 0.3107, acc 0.890625\n",
      "2018-05-04T17:53:19.088660: step 13537, loss 0.301358, acc 0.875\n",
      "2018-05-04T17:53:20.068010: step 13538, loss 0.321963, acc 0.875\n",
      "2018-05-04T17:53:21.049387: step 13539, loss 0.223402, acc 0.890625\n",
      "2018-05-04T17:53:22.103691: step 13540, loss 0.236101, acc 0.890625\n",
      "2018-05-04T17:53:23.123204: step 13541, loss 0.443642, acc 0.828125\n",
      "2018-05-04T17:53:24.082088: step 13542, loss 0.354328, acc 0.84375\n",
      "2018-05-04T17:53:25.044358: step 13543, loss 0.142806, acc 0.984375\n",
      "2018-05-04T17:53:26.017717: step 13544, loss 0.260397, acc 0.875\n",
      "2018-05-04T17:53:26.975581: step 13545, loss 0.161215, acc 0.9375\n",
      "2018-05-04T17:53:28.073051: step 13546, loss 0.218598, acc 0.90625\n",
      "2018-05-04T17:53:29.034693: step 13547, loss 0.214923, acc 0.921875\n",
      "2018-05-04T17:53:30.085826: step 13548, loss 0.221317, acc 0.9375\n",
      "2018-05-04T17:53:31.126662: step 13549, loss 0.334967, acc 0.90625\n",
      "2018-05-04T17:53:32.089380: step 13550, loss 0.202395, acc 0.921875\n",
      "2018-05-04T17:53:33.123317: step 13551, loss 0.293173, acc 0.859375\n",
      "2018-05-04T17:53:34.102002: step 13552, loss 0.3777, acc 0.859375\n",
      "2018-05-04T17:53:35.060380: step 13553, loss 0.212581, acc 0.921875\n",
      "2018-05-04T17:53:36.026312: step 13554, loss 0.175116, acc 0.9375\n",
      "2018-05-04T17:53:36.990208: step 13555, loss 0.340237, acc 0.875\n",
      "2018-05-04T17:53:37.954972: step 13556, loss 0.183713, acc 0.953125\n",
      "2018-05-04T17:53:38.925114: step 13557, loss 0.22405, acc 0.953125\n",
      "2018-05-04T17:53:39.899837: step 13558, loss 0.296843, acc 0.890625\n",
      "2018-05-04T17:53:40.849128: step 13559, loss 0.210823, acc 0.9375\n",
      "2018-05-04T17:53:41.878802: step 13560, loss 0.377105, acc 0.84375\n",
      "2018-05-04T17:53:42.856378: step 13561, loss 0.257128, acc 0.90625\n",
      "2018-05-04T17:53:43.864188: step 13562, loss 0.248972, acc 0.90625\n",
      "2018-05-04T17:53:44.853366: step 13563, loss 0.242117, acc 0.84375\n",
      "2018-05-04T17:53:45.923254: step 13564, loss 0.410789, acc 0.84375\n",
      "2018-05-04T17:53:46.888089: step 13565, loss 0.166803, acc 0.921875\n",
      "2018-05-04T17:53:47.918520: step 13566, loss 0.290844, acc 0.84375\n",
      "2018-05-04T17:53:48.879768: step 13567, loss 0.340559, acc 0.875\n",
      "2018-05-04T17:53:49.842675: step 13568, loss 0.297209, acc 0.859375\n",
      "2018-05-04T17:53:50.795712: step 13569, loss 0.23255, acc 0.890625\n",
      "2018-05-04T17:53:51.759870: step 13570, loss 0.277852, acc 0.875\n",
      "2018-05-04T17:53:52.742665: step 13571, loss 0.266396, acc 0.875\n",
      "2018-05-04T17:53:53.719248: step 13572, loss 0.249437, acc 0.875\n",
      "2018-05-04T17:53:54.769867: step 13573, loss 0.167908, acc 0.921875\n",
      "2018-05-04T17:53:55.813550: step 13574, loss 0.219636, acc 0.90625\n",
      "2018-05-04T17:53:56.841310: step 13575, loss 0.261786, acc 0.890625\n",
      "2018-05-04T17:53:57.812605: step 13576, loss 0.282345, acc 0.859375\n",
      "2018-05-04T17:53:58.786368: step 13577, loss 0.281578, acc 0.859375\n",
      "2018-05-04T17:53:59.755079: step 13578, loss 0.215412, acc 0.890625\n",
      "2018-05-04T17:54:00.719521: step 13579, loss 0.239433, acc 0.90625\n",
      "2018-05-04T17:54:01.749427: step 13580, loss 0.188021, acc 0.921875\n",
      "2018-05-04T17:54:02.680694: step 13581, loss 0.145546, acc 0.96875\n",
      "2018-05-04T17:54:03.709929: step 13582, loss 0.21471, acc 0.90625\n",
      "2018-05-04T17:54:04.691380: step 13583, loss 0.316827, acc 0.84375\n",
      "2018-05-04T17:54:05.721558: step 13584, loss 0.317173, acc 0.890625\n",
      "2018-05-04T17:54:06.761367: step 13585, loss 0.222225, acc 0.875\n",
      "2018-05-04T17:54:07.716335: step 13586, loss 0.345941, acc 0.875\n",
      "2018-05-04T17:54:08.678063: step 13587, loss 0.201616, acc 0.9375\n",
      "2018-05-04T17:54:09.633466: step 13588, loss 0.261584, acc 0.859375\n",
      "2018-05-04T17:54:10.649411: step 13589, loss 0.324231, acc 0.875\n",
      "2018-05-04T17:54:11.733610: step 13590, loss 0.280662, acc 0.875\n",
      "2018-05-04T17:54:12.710032: step 13591, loss 0.181636, acc 0.9375\n",
      "2018-05-04T17:54:13.743338: step 13592, loss 0.434856, acc 0.796875\n",
      "2018-05-04T17:54:14.777527: step 13593, loss 0.257127, acc 0.90625\n",
      "2018-05-04T17:54:15.798436: step 13594, loss 0.283112, acc 0.859375\n",
      "2018-05-04T17:54:16.819322: step 13595, loss 0.229553, acc 0.90625\n",
      "2018-05-04T17:54:17.764400: step 13596, loss 0.285726, acc 0.84375\n",
      "2018-05-04T17:54:18.795152: step 13597, loss 0.19141, acc 0.921875\n",
      "2018-05-04T17:54:19.843898: step 13598, loss 0.330791, acc 0.859375\n",
      "2018-05-04T17:54:20.856613: step 13599, loss 0.311551, acc 0.890625\n",
      "2018-05-04T17:54:21.881584: step 13600, loss 0.247612, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T17:54:24.718659: step 13600, loss 0.230618, acc 0.904\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-13600\n",
      "\n",
      "2018-05-04T17:54:25.812819: step 13601, loss 0.317613, acc 0.859375\n",
      "2018-05-04T17:54:26.845981: step 13602, loss 0.348366, acc 0.796875\n",
      "2018-05-04T17:54:27.866421: step 13603, loss 0.348527, acc 0.859375\n",
      "2018-05-04T17:54:28.898179: step 13604, loss 0.279135, acc 0.90625\n",
      "2018-05-04T17:54:29.939671: step 13605, loss 0.171543, acc 0.921875\n",
      "2018-05-04T17:54:30.978007: step 13606, loss 0.230971, acc 0.890625\n",
      "2018-05-04T17:54:32.053928: step 13607, loss 0.352573, acc 0.875\n",
      "2018-05-04T17:54:33.071267: step 13608, loss 0.169615, acc 0.921875\n",
      "2018-05-04T17:54:34.118318: step 13609, loss 0.286737, acc 0.875\n",
      "2018-05-04T17:54:35.109892: step 13610, loss 0.397613, acc 0.84375\n",
      "2018-05-04T17:54:36.123390: step 13611, loss 0.296276, acc 0.890625\n",
      "2018-05-04T17:54:37.238982: step 13612, loss 0.30873, acc 0.796875\n",
      "2018-05-04T17:54:38.270760: step 13613, loss 0.371003, acc 0.796875\n",
      "2018-05-04T17:54:39.292936: step 13614, loss 0.278155, acc 0.875\n",
      "2018-05-04T17:54:40.276907: step 13615, loss 0.200425, acc 0.90625\n",
      "2018-05-04T17:54:41.272269: step 13616, loss 0.370091, acc 0.8125\n",
      "2018-05-04T17:54:42.280737: step 13617, loss 0.182694, acc 0.96875\n",
      "2018-05-04T17:54:43.280247: step 13618, loss 0.263449, acc 0.875\n",
      "2018-05-04T17:54:44.285693: step 13619, loss 0.255594, acc 0.875\n",
      "2018-05-04T17:54:45.268472: step 13620, loss 0.332191, acc 0.890625\n",
      "2018-05-04T17:54:46.274881: step 13621, loss 0.260872, acc 0.875\n",
      "2018-05-04T17:54:47.286490: step 13622, loss 0.368269, acc 0.84375\n",
      "2018-05-04T17:54:48.298491: step 13623, loss 0.303935, acc 0.859375\n",
      "2018-05-04T17:54:49.302865: step 13624, loss 0.261196, acc 0.828125\n",
      "2018-05-04T17:54:50.370244: step 13625, loss 0.443303, acc 0.859375\n",
      "2018-05-04T17:54:51.358467: step 13626, loss 0.22816, acc 0.9375\n",
      "2018-05-04T17:54:52.347139: step 13627, loss 0.280964, acc 0.890625\n",
      "2018-05-04T17:54:53.351451: step 13628, loss 0.219587, acc 0.90625\n",
      "2018-05-04T17:54:54.395878: step 13629, loss 0.178744, acc 0.9375\n",
      "2018-05-04T17:54:55.396757: step 13630, loss 0.212244, acc 0.921875\n",
      "2018-05-04T17:54:56.388728: step 13631, loss 0.381336, acc 0.859375\n",
      "2018-05-04T17:54:57.405235: step 13632, loss 0.222961, acc 0.90625\n",
      "2018-05-04T17:54:58.386488: step 13633, loss 0.218975, acc 0.90625\n",
      "2018-05-04T17:54:59.372620: step 13634, loss 0.188305, acc 0.90625\n",
      "2018-05-04T17:55:00.460851: step 13635, loss 0.330529, acc 0.859375\n",
      "2018-05-04T17:55:01.456856: step 13636, loss 0.299708, acc 0.890625\n",
      "2018-05-04T17:55:02.466201: step 13637, loss 0.391597, acc 0.765625\n",
      "2018-05-04T17:55:03.486709: step 13638, loss 0.221876, acc 0.875\n",
      "2018-05-04T17:55:04.516912: step 13639, loss 0.264068, acc 0.859375\n",
      "2018-05-04T17:55:05.495034: step 13640, loss 0.208594, acc 0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T17:55:06.497890: step 13641, loss 0.227083, acc 0.921875\n",
      "2018-05-04T17:55:07.486316: step 13642, loss 0.288305, acc 0.859375\n",
      "2018-05-04T17:55:08.482897: step 13643, loss 0.178341, acc 0.953125\n",
      "2018-05-04T17:55:09.489494: step 13644, loss 0.309825, acc 0.859375\n",
      "2018-05-04T17:55:10.505191: step 13645, loss 0.204367, acc 0.953125\n",
      "2018-05-04T17:55:11.505997: step 13646, loss 0.252122, acc 0.890625\n",
      "2018-05-04T17:55:12.523853: step 13647, loss 0.239494, acc 0.921875\n",
      "2018-05-04T17:55:13.618839: step 13648, loss 0.333796, acc 0.890625\n",
      "2018-05-04T17:55:14.699240: step 13649, loss 0.417064, acc 0.84375\n",
      "2018-05-04T17:55:15.700353: step 13650, loss 0.357192, acc 0.859375\n",
      "2018-05-04T17:55:16.713710: step 13651, loss 0.170517, acc 0.96875\n",
      "2018-05-04T17:55:17.709174: step 13652, loss 0.230701, acc 0.921875\n",
      "2018-05-04T17:55:18.712982: step 13653, loss 0.330027, acc 0.921875\n",
      "2018-05-04T17:55:19.788615: step 13654, loss 0.288845, acc 0.90625\n",
      "2018-05-04T17:55:20.872198: step 13655, loss 0.314544, acc 0.859375\n",
      "2018-05-04T17:55:21.879470: step 13656, loss 0.335141, acc 0.890625\n",
      "2018-05-04T17:55:22.879036: step 13657, loss 0.193466, acc 0.921875\n",
      "2018-05-04T17:55:23.874185: step 13658, loss 0.213889, acc 0.90625\n",
      "2018-05-04T17:55:24.856949: step 13659, loss 0.300718, acc 0.890625\n",
      "2018-05-04T17:55:25.861468: step 13660, loss 0.288719, acc 0.875\n",
      "2018-05-04T17:55:26.870406: step 13661, loss 0.39641, acc 0.859375\n",
      "2018-05-04T17:55:27.851649: step 13662, loss 0.161897, acc 0.96875\n",
      "2018-05-04T17:55:28.854807: step 13663, loss 0.379551, acc 0.84375\n",
      "2018-05-04T17:55:29.842262: step 13664, loss 0.189445, acc 0.90625\n",
      "2018-05-04T17:55:30.832862: step 13665, loss 0.317575, acc 0.875\n",
      "2018-05-04T17:55:31.813940: step 13666, loss 0.300076, acc 0.875\n",
      "2018-05-04T17:55:32.825530: step 13667, loss 0.391362, acc 0.84375\n",
      "2018-05-04T17:55:33.937996: step 13668, loss 0.338573, acc 0.921875\n",
      "2018-05-04T17:55:35.047096: step 13669, loss 0.247399, acc 0.875\n",
      "2018-05-04T17:55:36.182887: step 13670, loss 0.240931, acc 0.90625\n",
      "2018-05-04T17:55:37.210523: step 13671, loss 0.323418, acc 0.84375\n",
      "2018-05-04T17:55:38.194243: step 13672, loss 0.240871, acc 0.890625\n",
      "2018-05-04T17:55:39.185405: step 13673, loss 0.31258, acc 0.84375\n",
      "2018-05-04T17:55:40.187758: step 13674, loss 0.255444, acc 0.890625\n",
      "2018-05-04T17:55:41.246959: step 13675, loss 0.310545, acc 0.90625\n",
      "2018-05-04T17:55:42.256598: step 13676, loss 0.237392, acc 0.859375\n",
      "2018-05-04T17:55:43.239202: step 13677, loss 0.288624, acc 0.890625\n",
      "2018-05-04T17:55:44.210627: step 13678, loss 0.191961, acc 0.921875\n",
      "2018-05-04T17:55:45.171576: step 13679, loss 0.340649, acc 0.875\n",
      "2018-05-04T17:55:46.167699: step 13680, loss 0.360216, acc 0.890625\n",
      "2018-05-04T17:55:47.146597: step 13681, loss 0.28226, acc 0.875\n",
      "2018-05-04T17:55:48.115071: step 13682, loss 0.481623, acc 0.859375\n",
      "2018-05-04T17:55:49.093882: step 13683, loss 0.302492, acc 0.890625\n",
      "2018-05-04T17:55:50.151509: step 13684, loss 0.246598, acc 0.859375\n",
      "2018-05-04T17:55:51.115172: step 13685, loss 0.239499, acc 0.90625\n",
      "2018-05-04T17:55:52.097325: step 13686, loss 0.333979, acc 0.84375\n",
      "2018-05-04T17:55:53.068435: step 13687, loss 0.267126, acc 0.890625\n",
      "2018-05-04T17:55:54.025709: step 13688, loss 0.321965, acc 0.859375\n",
      "2018-05-04T17:55:55.029173: step 13689, loss 0.326731, acc 0.859375\n",
      "2018-05-04T17:55:56.050632: step 13690, loss 0.287178, acc 0.890625\n",
      "2018-05-04T17:55:57.033175: step 13691, loss 0.237132, acc 0.921875\n",
      "2018-05-04T17:55:58.007508: step 13692, loss 0.244341, acc 0.875\n",
      "2018-05-04T17:55:58.999638: step 13693, loss 0.32019, acc 0.859375\n",
      "2018-05-04T17:56:00.028025: step 13694, loss 0.245451, acc 0.90625\n",
      "2018-05-04T17:56:00.994549: step 13695, loss 0.301487, acc 0.890625\n",
      "2018-05-04T17:56:01.956162: step 13696, loss 0.188368, acc 0.9375\n",
      "2018-05-04T17:56:02.935091: step 13697, loss 0.313418, acc 0.859375\n",
      "2018-05-04T17:56:03.949696: step 13698, loss 0.214058, acc 0.90625\n",
      "2018-05-04T17:56:04.948182: step 13699, loss 0.252318, acc 0.875\n",
      "2018-05-04T17:56:05.933010: step 13700, loss 0.325955, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T17:56:08.357997: step 13700, loss 0.2206, acc 0.908\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-13700\n",
      "\n",
      "2018-05-04T17:56:09.460358: step 13701, loss 0.355304, acc 0.890625\n",
      "2018-05-04T17:56:10.509023: step 13702, loss 0.403184, acc 0.859375\n",
      "2018-05-04T17:56:11.520946: step 13703, loss 0.185254, acc 0.9375\n",
      "2018-05-04T17:56:12.563661: step 13704, loss 0.336879, acc 0.890625\n",
      "2018-05-04T17:56:13.615626: step 13705, loss 0.427975, acc 0.8125\n",
      "2018-05-04T17:56:14.699792: step 13706, loss 0.339994, acc 0.859375\n",
      "2018-05-04T17:56:15.800221: step 13707, loss 0.245242, acc 0.890625\n",
      "2018-05-04T17:56:16.803085: step 13708, loss 0.270406, acc 0.953125\n",
      "2018-05-04T17:56:17.824753: step 13709, loss 0.437656, acc 0.828125\n",
      "2018-05-04T17:56:18.840804: step 13710, loss 0.206012, acc 0.90625\n",
      "2018-05-04T17:56:19.834870: step 13711, loss 0.182143, acc 0.9375\n",
      "2018-05-04T17:56:20.867800: step 13712, loss 0.247622, acc 0.890625\n",
      "2018-05-04T17:56:21.882064: step 13713, loss 0.331428, acc 0.890625\n",
      "2018-05-04T17:56:22.871357: step 13714, loss 0.261873, acc 0.921875\n",
      "2018-05-04T17:56:23.952426: step 13715, loss 0.195445, acc 0.953125\n",
      "2018-05-04T17:56:24.958797: step 13716, loss 0.202922, acc 0.921875\n",
      "2018-05-04T17:56:25.975554: step 13717, loss 0.209061, acc 0.90625\n",
      "2018-05-04T17:56:26.979042: step 13718, loss 0.176635, acc 0.953125\n",
      "2018-05-04T17:56:27.988896: step 13719, loss 0.204548, acc 0.921875\n",
      "2018-05-04T17:56:29.039221: step 13720, loss 0.302504, acc 0.859375\n",
      "2018-05-04T17:56:30.043055: step 13721, loss 0.297712, acc 0.875\n",
      "2018-05-04T17:56:31.049064: step 13722, loss 0.240627, acc 0.890625\n",
      "2018-05-04T17:56:32.058522: step 13723, loss 0.250383, acc 0.921875\n",
      "2018-05-04T17:56:33.083132: step 13724, loss 0.361797, acc 0.859375\n",
      "2018-05-04T17:56:34.181773: step 13725, loss 0.256196, acc 0.90625\n",
      "2018-05-04T17:56:35.194179: step 13726, loss 0.401607, acc 0.890625\n",
      "2018-05-04T17:56:36.222848: step 13727, loss 0.233686, acc 0.859375\n",
      "2018-05-04T17:56:37.236866: step 13728, loss 0.311891, acc 0.84375\n",
      "2018-05-04T17:56:38.239259: step 13729, loss 0.255825, acc 0.875\n",
      "2018-05-04T17:56:39.313283: step 13730, loss 0.286378, acc 0.875\n",
      "2018-05-04T17:56:40.402137: step 13731, loss 0.308365, acc 0.875\n",
      "2018-05-04T17:56:41.393629: step 13732, loss 0.175413, acc 0.9375\n",
      "2018-05-04T17:56:42.377078: step 13733, loss 0.230898, acc 0.921875\n",
      "2018-05-04T17:56:43.375657: step 13734, loss 0.2477, acc 0.890625\n",
      "2018-05-04T17:56:44.449726: step 13735, loss 0.308736, acc 0.90625\n",
      "2018-05-04T17:56:45.435978: step 13736, loss 0.209293, acc 0.9375\n",
      "2018-05-04T17:56:46.440196: step 13737, loss 0.287648, acc 0.890625\n",
      "2018-05-04T17:56:47.500679: step 13738, loss 0.205262, acc 0.90625\n",
      "2018-05-04T17:56:48.550103: step 13739, loss 0.311303, acc 0.859375\n",
      "2018-05-04T17:56:49.563953: step 13740, loss 0.35511, acc 0.890625\n",
      "2018-05-04T17:56:50.557543: step 13741, loss 0.259134, acc 0.875\n",
      "2018-05-04T17:56:51.637818: step 13742, loss 0.199104, acc 0.953125\n",
      "2018-05-04T17:56:52.640554: step 13743, loss 0.234499, acc 0.890625\n",
      "2018-05-04T17:56:53.618684: step 13744, loss 0.237573, acc 0.921875\n",
      "2018-05-04T17:56:54.603183: step 13745, loss 0.29058, acc 0.921875\n",
      "2018-05-04T17:56:55.590740: step 13746, loss 0.201089, acc 0.921875\n",
      "2018-05-04T17:56:56.588779: step 13747, loss 0.496805, acc 0.859375\n",
      "2018-05-04T17:56:57.583744: step 13748, loss 0.213118, acc 0.9375\n",
      "2018-05-04T17:56:58.605743: step 13749, loss 0.233062, acc 0.890625\n",
      "2018-05-04T17:56:59.598775: step 13750, loss 0.257093, acc 0.890625\n",
      "2018-05-04T17:57:00.596492: step 13751, loss 0.200418, acc 0.921875\n",
      "2018-05-04T17:57:01.580000: step 13752, loss 0.297314, acc 0.859375\n",
      "2018-05-04T17:57:02.574302: step 13753, loss 0.339951, acc 0.875\n",
      "2018-05-04T17:57:03.551686: step 13754, loss 0.376044, acc 0.84375\n",
      "2018-05-04T17:57:04.551154: step 13755, loss 0.218972, acc 0.890625\n",
      "2018-05-04T17:57:05.521128: step 13756, loss 0.365861, acc 0.828125\n",
      "2018-05-04T17:57:06.515877: step 13757, loss 0.208259, acc 0.890625\n",
      "2018-05-04T17:57:07.497444: step 13758, loss 0.153351, acc 0.96875\n",
      "2018-05-04T17:57:08.497492: step 13759, loss 0.242342, acc 0.890625\n",
      "2018-05-04T17:57:09.481583: step 13760, loss 0.272148, acc 0.84375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T17:57:10.443235: step 13761, loss 0.290747, acc 0.875\n",
      "2018-05-04T17:57:11.433583: step 13762, loss 0.177529, acc 0.984375\n",
      "2018-05-04T17:57:12.435775: step 13763, loss 0.201149, acc 0.9375\n",
      "2018-05-04T17:57:13.421693: step 13764, loss 0.154108, acc 0.96875\n",
      "2018-05-04T17:57:14.446408: step 13765, loss 0.24192, acc 0.921875\n",
      "2018-05-04T17:57:15.461336: step 13766, loss 0.194017, acc 0.953125\n",
      "2018-05-04T17:57:16.433731: step 13767, loss 0.285658, acc 0.90625\n",
      "2018-05-04T17:57:17.484849: step 13768, loss 0.340068, acc 0.828125\n",
      "2018-05-04T17:57:18.460789: step 13769, loss 0.414311, acc 0.859375\n",
      "2018-05-04T17:57:19.436148: step 13770, loss 0.183171, acc 0.953125\n",
      "2018-05-04T17:57:20.487682: step 13771, loss 0.241268, acc 0.921875\n",
      "2018-05-04T17:57:21.518008: step 13772, loss 0.32525, acc 0.828125\n",
      "2018-05-04T17:57:22.507226: step 13773, loss 0.322123, acc 0.84375\n",
      "2018-05-04T17:57:23.494610: step 13774, loss 0.153131, acc 0.9375\n",
      "2018-05-04T17:57:24.506920: step 13775, loss 0.239728, acc 0.859375\n",
      "2018-05-04T17:57:25.504084: step 13776, loss 0.452908, acc 0.78125\n",
      "2018-05-04T17:57:26.486563: step 13777, loss 0.311895, acc 0.8125\n",
      "2018-05-04T17:57:27.486249: step 13778, loss 0.402776, acc 0.875\n",
      "2018-05-04T17:57:28.481063: step 13779, loss 0.313554, acc 0.8125\n",
      "2018-05-04T17:57:29.479015: step 13780, loss 0.319141, acc 0.84375\n",
      "2018-05-04T17:57:30.455309: step 13781, loss 0.255872, acc 0.921875\n",
      "2018-05-04T17:57:31.514043: step 13782, loss 0.136256, acc 0.953125\n",
      "2018-05-04T17:57:32.503272: step 13783, loss 0.198122, acc 0.921875\n",
      "2018-05-04T17:57:33.465098: step 13784, loss 0.343262, acc 0.84375\n",
      "2018-05-04T17:57:34.429761: step 13785, loss 0.257937, acc 0.921875\n",
      "2018-05-04T17:57:35.395602: step 13786, loss 0.323455, acc 0.84375\n",
      "2018-05-04T17:57:36.365019: step 13787, loss 0.360144, acc 0.875\n",
      "2018-05-04T17:57:37.346507: step 13788, loss 0.247645, acc 0.90625\n",
      "2018-05-04T17:57:38.325951: step 13789, loss 0.209282, acc 0.890625\n",
      "2018-05-04T17:57:39.297886: step 13790, loss 0.219071, acc 0.90625\n",
      "2018-05-04T17:57:40.274573: step 13791, loss 0.281875, acc 0.890625\n",
      "2018-05-04T17:57:41.248934: step 13792, loss 0.274563, acc 0.890625\n",
      "2018-05-04T17:57:42.279161: step 13793, loss 0.176863, acc 0.96875\n",
      "2018-05-04T17:57:43.255670: step 13794, loss 0.299642, acc 0.84375\n",
      "2018-05-04T17:57:44.220936: step 13795, loss 0.192312, acc 0.90625\n",
      "2018-05-04T17:57:45.218061: step 13796, loss 0.287277, acc 0.875\n",
      "2018-05-04T17:57:46.202015: step 13797, loss 0.295997, acc 0.875\n",
      "2018-05-04T17:57:47.204195: step 13798, loss 0.246435, acc 0.890625\n",
      "2018-05-04T17:57:48.167101: step 13799, loss 0.287202, acc 0.890625\n",
      "2018-05-04T17:57:49.130637: step 13800, loss 0.312679, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T17:57:51.682763: step 13800, loss 0.221952, acc 0.92\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-13800\n",
      "\n",
      "2018-05-04T17:57:52.781940: step 13801, loss 0.257714, acc 0.875\n",
      "2018-05-04T17:57:53.842300: step 13802, loss 0.262976, acc 0.921875\n",
      "2018-05-04T17:57:54.866332: step 13803, loss 0.197899, acc 0.9375\n",
      "2018-05-04T17:57:55.925558: step 13804, loss 0.272838, acc 0.875\n",
      "2018-05-04T17:57:57.010867: step 13805, loss 0.311801, acc 0.859375\n",
      "2018-05-04T17:57:58.046974: step 13806, loss 0.314407, acc 0.890625\n",
      "2018-05-04T17:57:59.048003: step 13807, loss 0.273692, acc 0.90625\n",
      "2018-05-04T17:58:00.044113: step 13808, loss 0.219947, acc 0.890625\n",
      "2018-05-04T17:58:01.015242: step 13809, loss 0.398162, acc 0.796875\n",
      "2018-05-04T17:58:02.020873: step 13810, loss 0.304212, acc 0.90625\n",
      "2018-05-04T17:58:03.093535: step 13811, loss 0.346659, acc 0.84375\n",
      "2018-05-04T17:58:04.184197: step 13812, loss 0.246163, acc 0.921875\n",
      "2018-05-04T17:58:05.260293: step 13813, loss 0.24099, acc 0.921875\n",
      "2018-05-04T17:58:06.232501: step 13814, loss 0.238084, acc 0.90625\n",
      "2018-05-04T17:58:07.218898: step 13815, loss 0.227877, acc 0.875\n",
      "2018-05-04T17:58:08.205055: step 13816, loss 0.221497, acc 0.90625\n",
      "2018-05-04T17:58:09.185365: step 13817, loss 0.231065, acc 0.90625\n",
      "2018-05-04T17:58:10.275775: step 13818, loss 0.271805, acc 0.890625\n",
      "2018-05-04T17:58:11.308184: step 13819, loss 0.412363, acc 0.8125\n",
      "2018-05-04T17:58:12.274890: step 13820, loss 0.265592, acc 0.859375\n",
      "2018-05-04T17:58:13.294615: step 13821, loss 0.336922, acc 0.828125\n",
      "2018-05-04T17:58:14.419408: step 13822, loss 0.0821526, acc 1\n",
      "2018-05-04T17:58:15.406217: step 13823, loss 0.231846, acc 0.921875\n",
      "2018-05-04T17:58:16.392125: step 13824, loss 0.252581, acc 0.890625\n",
      "2018-05-04T17:58:17.383198: step 13825, loss 0.248941, acc 0.859375\n",
      "2018-05-04T17:58:18.382323: step 13826, loss 0.350643, acc 0.828125\n",
      "2018-05-04T17:58:19.386736: step 13827, loss 0.267997, acc 0.90625\n",
      "2018-05-04T17:58:20.472866: step 13828, loss 0.33309, acc 0.859375\n",
      "2018-05-04T17:58:21.547359: step 13829, loss 0.257036, acc 0.890625\n",
      "2018-05-04T17:58:22.529865: step 13830, loss 0.138973, acc 0.96875\n",
      "2018-05-04T17:58:23.518584: step 13831, loss 0.496783, acc 0.71875\n",
      "2018-05-04T17:58:24.531838: step 13832, loss 0.240353, acc 0.90625\n",
      "2018-05-04T17:58:25.517590: step 13833, loss 0.262984, acc 0.875\n",
      "2018-05-04T17:58:26.504402: step 13834, loss 0.376908, acc 0.859375\n",
      "2018-05-04T17:58:27.503007: step 13835, loss 0.267635, acc 0.859375\n",
      "2018-05-04T17:58:28.503780: step 13836, loss 0.329992, acc 0.8125\n",
      "2018-05-04T17:58:29.580350: step 13837, loss 0.194447, acc 0.9375\n",
      "2018-05-04T17:58:30.585605: step 13838, loss 0.173198, acc 0.9375\n",
      "2018-05-04T17:58:31.625484: step 13839, loss 0.516431, acc 0.8125\n",
      "2018-05-04T17:58:32.641287: step 13840, loss 0.377174, acc 0.828125\n",
      "2018-05-04T17:58:33.698011: step 13841, loss 0.290915, acc 0.90625\n",
      "2018-05-04T17:58:34.740883: step 13842, loss 0.347179, acc 0.890625\n",
      "2018-05-04T17:58:35.794351: step 13843, loss 0.145626, acc 0.96875\n",
      "2018-05-04T17:58:36.852215: step 13844, loss 0.22057, acc 0.90625\n",
      "2018-05-04T17:58:37.879790: step 13845, loss 0.243149, acc 0.859375\n",
      "2018-05-04T17:58:38.889194: step 13846, loss 0.219379, acc 0.9375\n",
      "2018-05-04T17:58:39.875616: step 13847, loss 0.303594, acc 0.90625\n",
      "2018-05-04T17:58:40.870366: step 13848, loss 0.308443, acc 0.890625\n",
      "2018-05-04T17:58:41.881308: step 13849, loss 0.276731, acc 0.890625\n",
      "2018-05-04T17:58:42.893959: step 13850, loss 0.196667, acc 0.875\n",
      "2018-05-04T17:58:43.891237: step 13851, loss 0.271186, acc 0.921875\n",
      "2018-05-04T17:58:44.898674: step 13852, loss 0.464418, acc 0.84375\n",
      "2018-05-04T17:58:45.888643: step 13853, loss 0.261972, acc 0.921875\n",
      "2018-05-04T17:58:46.876154: step 13854, loss 0.242981, acc 0.890625\n",
      "2018-05-04T17:58:47.949724: step 13855, loss 0.243883, acc 0.859375\n",
      "2018-05-04T17:58:48.943665: step 13856, loss 0.1404, acc 0.96875\n",
      "2018-05-04T17:58:49.930470: step 13857, loss 0.254172, acc 0.890625\n",
      "2018-05-04T17:58:50.903386: step 13858, loss 0.310191, acc 0.890625\n",
      "2018-05-04T17:58:51.898724: step 13859, loss 0.202786, acc 0.890625\n",
      "2018-05-04T17:58:52.886344: step 13860, loss 0.280824, acc 0.90625\n",
      "2018-05-04T17:58:53.873327: step 13861, loss 0.291284, acc 0.875\n",
      "2018-05-04T17:58:54.913560: step 13862, loss 0.201779, acc 0.921875\n",
      "2018-05-04T17:58:55.920878: step 13863, loss 0.281628, acc 0.859375\n",
      "2018-05-04T17:58:56.875600: step 13864, loss 0.35543, acc 0.90625\n",
      "2018-05-04T17:58:57.847428: step 13865, loss 0.252823, acc 0.875\n",
      "2018-05-04T17:58:58.833549: step 13866, loss 0.305583, acc 0.875\n",
      "2018-05-04T17:58:59.822400: step 13867, loss 0.356485, acc 0.859375\n",
      "2018-05-04T17:59:00.818650: step 13868, loss 0.277855, acc 0.875\n",
      "2018-05-04T17:59:01.792603: step 13869, loss 0.487649, acc 0.890625\n",
      "2018-05-04T17:59:02.802328: step 13870, loss 0.251948, acc 0.90625\n",
      "2018-05-04T17:59:03.889231: step 13871, loss 0.354697, acc 0.8125\n",
      "2018-05-04T17:59:04.859928: step 13872, loss 0.357257, acc 0.8125\n",
      "2018-05-04T17:59:05.916333: step 13873, loss 0.23187, acc 0.90625\n",
      "2018-05-04T17:59:06.892242: step 13874, loss 0.269566, acc 0.921875\n",
      "2018-05-04T17:59:07.867052: step 13875, loss 0.236728, acc 0.90625\n",
      "2018-05-04T17:59:08.847766: step 13876, loss 0.195352, acc 0.921875\n",
      "2018-05-04T17:59:09.814628: step 13877, loss 0.235227, acc 0.9375\n",
      "2018-05-04T17:59:10.789206: step 13878, loss 0.216921, acc 0.953125\n",
      "2018-05-04T17:59:11.816969: step 13879, loss 0.311039, acc 0.84375\n",
      "2018-05-04T17:59:12.864730: step 13880, loss 0.325224, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T17:59:13.808754: step 13881, loss 0.227356, acc 0.890625\n",
      "2018-05-04T17:59:14.788349: step 13882, loss 0.206524, acc 0.953125\n",
      "2018-05-04T17:59:15.851369: step 13883, loss 0.232095, acc 0.921875\n",
      "2018-05-04T17:59:16.814144: step 13884, loss 0.276141, acc 0.90625\n",
      "2018-05-04T17:59:17.813614: step 13885, loss 0.227992, acc 0.921875\n",
      "2018-05-04T17:59:18.794804: step 13886, loss 0.145328, acc 0.96875\n",
      "2018-05-04T17:59:19.777027: step 13887, loss 0.40028, acc 0.796875\n",
      "2018-05-04T17:59:20.778121: step 13888, loss 0.475575, acc 0.75\n",
      "2018-05-04T17:59:21.765801: step 13889, loss 0.263576, acc 0.921875\n",
      "2018-05-04T17:59:22.743733: step 13890, loss 0.236576, acc 0.875\n",
      "2018-05-04T17:59:23.723590: step 13891, loss 0.280311, acc 0.84375\n",
      "2018-05-04T17:59:24.697979: step 13892, loss 0.241654, acc 0.890625\n",
      "2018-05-04T17:59:25.750023: step 13893, loss 0.277382, acc 0.875\n",
      "2018-05-04T17:59:26.730590: step 13894, loss 0.243264, acc 0.890625\n",
      "2018-05-04T17:59:27.710643: step 13895, loss 0.265473, acc 0.90625\n",
      "2018-05-04T17:59:28.685768: step 13896, loss 0.251693, acc 0.90625\n",
      "2018-05-04T17:59:29.703735: step 13897, loss 0.346738, acc 0.921875\n",
      "2018-05-04T17:59:30.695958: step 13898, loss 0.253668, acc 0.890625\n",
      "2018-05-04T17:59:31.679687: step 13899, loss 0.360909, acc 0.75\n",
      "2018-05-04T17:59:32.657505: step 13900, loss 0.175309, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T17:59:35.292518: step 13900, loss 0.227417, acc 0.926\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-13900\n",
      "\n",
      "2018-05-04T17:59:36.472376: step 13901, loss 0.216859, acc 0.90625\n",
      "2018-05-04T17:59:37.481940: step 13902, loss 0.159725, acc 0.921875\n",
      "2018-05-04T17:59:38.513366: step 13903, loss 0.259334, acc 0.875\n",
      "2018-05-04T17:59:39.517739: step 13904, loss 0.21907, acc 0.890625\n",
      "2018-05-04T17:59:40.543802: step 13905, loss 0.231042, acc 0.890625\n",
      "2018-05-04T17:59:41.666671: step 13906, loss 0.26983, acc 0.890625\n",
      "2018-05-04T17:59:42.799561: step 13907, loss 0.240428, acc 0.921875\n",
      "2018-05-04T17:59:43.808190: step 13908, loss 0.203671, acc 0.9375\n",
      "2018-05-04T17:59:44.832943: step 13909, loss 0.274084, acc 0.890625\n",
      "2018-05-04T17:59:45.926452: step 13910, loss 0.270958, acc 0.859375\n",
      "2018-05-04T17:59:46.921182: step 13911, loss 0.303851, acc 0.8125\n",
      "2018-05-04T17:59:47.905096: step 13912, loss 0.383658, acc 0.828125\n",
      "2018-05-04T17:59:48.905746: step 13913, loss 0.340484, acc 0.875\n",
      "2018-05-04T17:59:49.965130: step 13914, loss 0.517822, acc 0.765625\n",
      "2018-05-04T17:59:50.961046: step 13915, loss 0.182973, acc 0.9375\n",
      "2018-05-04T17:59:51.976259: step 13916, loss 0.192571, acc 0.9375\n",
      "2018-05-04T17:59:52.980876: step 13917, loss 0.283483, acc 0.859375\n",
      "2018-05-04T17:59:54.051164: step 13918, loss 0.504315, acc 0.8125\n",
      "2018-05-04T17:59:55.034050: step 13919, loss 0.218643, acc 0.921875\n",
      "2018-05-04T17:59:56.043646: step 13920, loss 0.256641, acc 0.859375\n",
      "2018-05-04T17:59:57.031287: step 13921, loss 0.347502, acc 0.84375\n",
      "2018-05-04T17:59:58.000159: step 13922, loss 0.387233, acc 0.84375\n",
      "2018-05-04T17:59:58.999502: step 13923, loss 0.167303, acc 0.953125\n",
      "2018-05-04T17:59:59.991971: step 13924, loss 0.219196, acc 0.90625\n",
      "2018-05-04T18:00:00.993928: step 13925, loss 0.285729, acc 0.890625\n",
      "2018-05-04T18:00:02.025252: step 13926, loss 0.148649, acc 0.921875\n",
      "2018-05-04T18:00:03.022468: step 13927, loss 0.318523, acc 0.890625\n",
      "2018-05-04T18:00:04.038828: step 13928, loss 0.158811, acc 0.953125\n",
      "2018-05-04T18:00:05.061242: step 13929, loss 0.224229, acc 0.921875\n",
      "2018-05-04T18:00:06.093272: step 13930, loss 0.279906, acc 0.84375\n",
      "2018-05-04T18:00:07.099777: step 13931, loss 0.307753, acc 0.875\n",
      "2018-05-04T18:00:08.166529: step 13932, loss 0.244295, acc 0.890625\n",
      "2018-05-04T18:00:09.173935: step 13933, loss 0.269324, acc 0.890625\n",
      "2018-05-04T18:00:10.171848: step 13934, loss 0.309987, acc 0.84375\n",
      "2018-05-04T18:00:11.168473: step 13935, loss 0.220346, acc 0.890625\n",
      "2018-05-04T18:00:12.182294: step 13936, loss 0.323194, acc 0.875\n",
      "2018-05-04T18:00:13.198411: step 13937, loss 0.272987, acc 0.84375\n",
      "2018-05-04T18:00:14.219507: step 13938, loss 0.285096, acc 0.890625\n",
      "2018-05-04T18:00:15.216941: step 13939, loss 0.219854, acc 0.890625\n",
      "2018-05-04T18:00:16.311608: step 13940, loss 0.404792, acc 0.84375\n",
      "2018-05-04T18:00:17.318671: step 13941, loss 0.247957, acc 0.890625\n",
      "2018-05-04T18:00:18.327484: step 13942, loss 0.203581, acc 0.921875\n",
      "2018-05-04T18:00:19.343441: step 13943, loss 0.255246, acc 0.859375\n",
      "2018-05-04T18:00:20.330093: step 13944, loss 0.363716, acc 0.890625\n",
      "2018-05-04T18:00:21.331209: step 13945, loss 0.20401, acc 0.90625\n",
      "2018-05-04T18:00:22.349975: step 13946, loss 0.144138, acc 0.953125\n",
      "2018-05-04T18:00:23.362321: step 13947, loss 0.291223, acc 0.875\n",
      "2018-05-04T18:00:24.351562: step 13948, loss 0.141193, acc 0.9375\n",
      "2018-05-04T18:00:25.364624: step 13949, loss 0.353057, acc 0.8125\n",
      "2018-05-04T18:00:26.372614: step 13950, loss 0.345648, acc 0.875\n",
      "2018-05-04T18:00:27.409928: step 13951, loss 0.220477, acc 0.9375\n",
      "2018-05-04T18:00:28.396304: step 13952, loss 0.366364, acc 0.828125\n",
      "2018-05-04T18:00:29.396725: step 13953, loss 0.208826, acc 0.9375\n",
      "2018-05-04T18:00:30.382277: step 13954, loss 0.267488, acc 0.875\n",
      "2018-05-04T18:00:31.426672: step 13955, loss 0.273432, acc 0.859375\n",
      "2018-05-04T18:00:32.434464: step 13956, loss 0.336066, acc 0.84375\n",
      "2018-05-04T18:00:33.428791: step 13957, loss 0.307072, acc 0.859375\n",
      "2018-05-04T18:00:34.439994: step 13958, loss 0.271822, acc 0.921875\n",
      "2018-05-04T18:00:35.501477: step 13959, loss 0.283729, acc 0.890625\n",
      "2018-05-04T18:00:36.485079: step 13960, loss 0.255388, acc 0.90625\n",
      "2018-05-04T18:00:37.465125: step 13961, loss 0.370939, acc 0.84375\n",
      "2018-05-04T18:00:38.477576: step 13962, loss 0.349189, acc 0.875\n",
      "2018-05-04T18:00:39.474392: step 13963, loss 0.256718, acc 0.90625\n",
      "2018-05-04T18:00:40.453145: step 13964, loss 0.19003, acc 0.921875\n",
      "2018-05-04T18:00:41.449501: step 13965, loss 0.263013, acc 0.90625\n",
      "2018-05-04T18:00:42.463430: step 13966, loss 0.267203, acc 0.875\n",
      "2018-05-04T18:00:43.471762: step 13967, loss 0.201862, acc 0.90625\n",
      "2018-05-04T18:00:44.459166: step 13968, loss 0.264769, acc 0.875\n",
      "2018-05-04T18:00:45.470545: step 13969, loss 0.250032, acc 0.90625\n",
      "2018-05-04T18:00:46.483650: step 13970, loss 0.372626, acc 0.875\n",
      "2018-05-04T18:00:47.464618: step 13971, loss 0.201338, acc 0.890625\n",
      "2018-05-04T18:00:48.451835: step 13972, loss 0.256333, acc 0.890625\n",
      "2018-05-04T18:00:49.495056: step 13973, loss 0.388322, acc 0.8125\n",
      "2018-05-04T18:00:50.462240: step 13974, loss 0.392199, acc 0.828125\n",
      "2018-05-04T18:00:51.460368: step 13975, loss 0.283405, acc 0.859375\n",
      "2018-05-04T18:00:52.439593: step 13976, loss 0.323472, acc 0.875\n",
      "2018-05-04T18:00:53.410012: step 13977, loss 0.355353, acc 0.796875\n",
      "2018-05-04T18:00:54.387628: step 13978, loss 0.275466, acc 0.859375\n",
      "2018-05-04T18:00:55.466280: step 13979, loss 0.220321, acc 0.921875\n",
      "2018-05-04T18:00:56.443207: step 13980, loss 0.287167, acc 0.890625\n",
      "2018-05-04T18:00:57.418843: step 13981, loss 0.23366, acc 0.9375\n",
      "2018-05-04T18:00:58.388239: step 13982, loss 0.218176, acc 0.921875\n",
      "2018-05-04T18:00:59.379626: step 13983, loss 0.145094, acc 0.953125\n",
      "2018-05-04T18:01:00.355931: step 13984, loss 0.213026, acc 0.921875\n",
      "2018-05-04T18:01:01.334989: step 13985, loss 0.202559, acc 0.921875\n",
      "2018-05-04T18:01:02.314050: step 13986, loss 0.283487, acc 0.859375\n",
      "2018-05-04T18:01:03.282118: step 13987, loss 0.242874, acc 0.890625\n",
      "2018-05-04T18:01:04.259029: step 13988, loss 0.309157, acc 0.890625\n",
      "2018-05-04T18:01:05.237098: step 13989, loss 0.174337, acc 0.90625\n",
      "2018-05-04T18:01:06.276338: step 13990, loss 0.226154, acc 0.921875\n",
      "2018-05-04T18:01:07.289102: step 13991, loss 0.200548, acc 0.90625\n",
      "2018-05-04T18:01:08.358989: step 13992, loss 0.324475, acc 0.84375\n",
      "2018-05-04T18:01:09.442189: step 13993, loss 0.313027, acc 0.875\n",
      "2018-05-04T18:01:10.404817: step 13994, loss 0.235843, acc 0.90625\n",
      "2018-05-04T18:01:11.408501: step 13995, loss 0.222421, acc 0.875\n",
      "2018-05-04T18:01:12.378563: step 13996, loss 0.355128, acc 0.859375\n",
      "2018-05-04T18:01:13.363134: step 13997, loss 0.277082, acc 0.875\n",
      "2018-05-04T18:01:14.343553: step 13998, loss 0.317771, acc 0.828125\n",
      "2018-05-04T18:01:15.334530: step 13999, loss 0.291009, acc 0.875\n",
      "2018-05-04T18:01:16.281351: step 14000, loss 0.303487, acc 0.859375\n",
      "\n",
      "Evaluation:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T18:01:18.840850: step 14000, loss 0.226606, acc 0.914\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-14000\n",
      "\n",
      "2018-05-04T18:01:19.988960: step 14001, loss 0.301386, acc 0.921875\n",
      "2018-05-04T18:01:21.026218: step 14002, loss 0.190448, acc 0.890625\n",
      "2018-05-04T18:01:22.033122: step 14003, loss 0.261743, acc 0.875\n",
      "2018-05-04T18:01:23.075052: step 14004, loss 0.196778, acc 0.921875\n",
      "2018-05-04T18:01:24.100233: step 14005, loss 0.166521, acc 0.90625\n",
      "2018-05-04T18:01:25.128659: step 14006, loss 0.271402, acc 0.921875\n",
      "2018-05-04T18:01:26.150753: step 14007, loss 0.51554, acc 0.765625\n",
      "2018-05-04T18:01:27.181887: step 14008, loss 0.229645, acc 0.875\n",
      "2018-05-04T18:01:28.184770: step 14009, loss 0.22661, acc 0.890625\n",
      "2018-05-04T18:01:29.230094: step 14010, loss 0.361162, acc 0.84375\n",
      "2018-05-04T18:01:30.250794: step 14011, loss 0.292247, acc 0.859375\n",
      "2018-05-04T18:01:31.243487: step 14012, loss 0.232728, acc 0.90625\n",
      "2018-05-04T18:01:32.228450: step 14013, loss 0.383017, acc 0.875\n",
      "2018-05-04T18:01:33.313369: step 14014, loss 0.359452, acc 0.84375\n",
      "2018-05-04T18:01:34.352836: step 14015, loss 0.286111, acc 0.859375\n",
      "2018-05-04T18:01:35.399439: step 14016, loss 0.208248, acc 0.875\n",
      "2018-05-04T18:01:36.474731: step 14017, loss 0.258788, acc 0.90625\n",
      "2018-05-04T18:01:37.567560: step 14018, loss 0.280623, acc 0.90625\n",
      "2018-05-04T18:01:38.607414: step 14019, loss 0.452502, acc 0.796875\n",
      "2018-05-04T18:01:39.649869: step 14020, loss 0.239407, acc 0.90625\n",
      "2018-05-04T18:01:40.628962: step 14021, loss 0.283947, acc 0.859375\n",
      "2018-05-04T18:01:41.669333: step 14022, loss 0.249692, acc 0.90625\n",
      "2018-05-04T18:01:42.693720: step 14023, loss 0.251709, acc 0.859375\n",
      "2018-05-04T18:01:43.711889: step 14024, loss 0.338154, acc 0.890625\n",
      "2018-05-04T18:01:44.698147: step 14025, loss 0.189885, acc 0.9375\n",
      "2018-05-04T18:01:45.688210: step 14026, loss 0.167412, acc 0.953125\n",
      "2018-05-04T18:01:46.685465: step 14027, loss 0.391635, acc 0.84375\n",
      "2018-05-04T18:01:47.679456: step 14028, loss 0.337933, acc 0.890625\n",
      "2018-05-04T18:01:48.740529: step 14029, loss 0.204162, acc 0.90625\n",
      "2018-05-04T18:01:49.721521: step 14030, loss 0.335633, acc 0.859375\n",
      "2018-05-04T18:01:50.822240: step 14031, loss 0.246288, acc 0.90625\n",
      "2018-05-04T18:01:51.820288: step 14032, loss 0.30076, acc 0.875\n",
      "2018-05-04T18:01:52.819113: step 14033, loss 0.441418, acc 0.828125\n",
      "2018-05-04T18:01:53.816707: step 14034, loss 0.339517, acc 0.859375\n",
      "2018-05-04T18:01:54.902562: step 14035, loss 0.245191, acc 0.890625\n",
      "2018-05-04T18:01:55.891677: step 14036, loss 0.34384, acc 0.890625\n",
      "2018-05-04T18:01:56.891459: step 14037, loss 0.322007, acc 0.875\n",
      "2018-05-04T18:01:57.877100: step 14038, loss 0.254716, acc 0.890625\n",
      "2018-05-04T18:01:58.932643: step 14039, loss 0.2657, acc 0.90625\n",
      "2018-05-04T18:01:59.949143: step 14040, loss 0.257415, acc 0.890625\n",
      "2018-05-04T18:02:01.025922: step 14041, loss 0.205469, acc 0.953125\n",
      "2018-05-04T18:02:02.046060: step 14042, loss 0.225531, acc 0.890625\n",
      "2018-05-04T18:02:03.103794: step 14043, loss 0.277751, acc 0.875\n",
      "2018-05-04T18:02:04.114683: step 14044, loss 0.306958, acc 0.890625\n",
      "2018-05-04T18:02:05.095156: step 14045, loss 0.271354, acc 0.921875\n",
      "2018-05-04T18:02:06.114668: step 14046, loss 0.246085, acc 0.953125\n",
      "2018-05-04T18:02:07.178096: step 14047, loss 0.20644, acc 0.921875\n",
      "2018-05-04T18:02:08.199467: step 14048, loss 0.304986, acc 0.859375\n",
      "2018-05-04T18:02:09.185551: step 14049, loss 0.341696, acc 0.875\n",
      "2018-05-04T18:02:10.179128: step 14050, loss 0.201719, acc 0.921875\n",
      "2018-05-04T18:02:11.169707: step 14051, loss 0.307652, acc 0.890625\n",
      "2018-05-04T18:02:12.160256: step 14052, loss 0.27357, acc 0.875\n",
      "2018-05-04T18:02:13.155371: step 14053, loss 0.288762, acc 0.90625\n",
      "2018-05-04T18:02:14.146347: step 14054, loss 0.271452, acc 0.859375\n",
      "2018-05-04T18:02:15.127661: step 14055, loss 0.313743, acc 0.875\n",
      "2018-05-04T18:02:16.122966: step 14056, loss 0.210292, acc 0.90625\n",
      "2018-05-04T18:02:17.088284: step 14057, loss 0.286486, acc 0.875\n",
      "2018-05-04T18:02:18.068047: step 14058, loss 0.230018, acc 0.890625\n",
      "2018-05-04T18:02:19.130762: step 14059, loss 0.254325, acc 0.90625\n",
      "2018-05-04T18:02:20.071342: step 14060, loss 0.228832, acc 0.890625\n",
      "2018-05-04T18:02:21.041479: step 14061, loss 0.341253, acc 0.859375\n",
      "2018-05-04T18:02:22.068481: step 14062, loss 0.353119, acc 0.859375\n",
      "2018-05-04T18:02:23.043733: step 14063, loss 0.284434, acc 0.921875\n",
      "2018-05-04T18:02:24.100536: step 14064, loss 0.220537, acc 0.90625\n",
      "2018-05-04T18:02:25.091592: step 14065, loss 0.287168, acc 0.859375\n",
      "2018-05-04T18:02:26.074881: step 14066, loss 0.369196, acc 0.875\n",
      "2018-05-04T18:02:27.062606: step 14067, loss 0.162482, acc 0.90625\n",
      "2018-05-04T18:02:28.056499: step 14068, loss 0.154557, acc 0.90625\n",
      "2018-05-04T18:02:29.048315: step 14069, loss 0.34079, acc 0.84375\n",
      "2018-05-04T18:02:30.007432: step 14070, loss 0.298129, acc 0.890625\n",
      "2018-05-04T18:02:31.029458: step 14071, loss 0.332989, acc 0.859375\n",
      "2018-05-04T18:02:32.026182: step 14072, loss 0.33353, acc 0.90625\n",
      "2018-05-04T18:02:32.993556: step 14073, loss 0.396624, acc 0.84375\n",
      "2018-05-04T18:02:33.972751: step 14074, loss 0.359106, acc 0.828125\n",
      "2018-05-04T18:02:34.945238: step 14075, loss 0.209289, acc 0.9375\n",
      "2018-05-04T18:02:35.910535: step 14076, loss 0.242801, acc 0.890625\n",
      "2018-05-04T18:02:36.869679: step 14077, loss 0.30173, acc 0.875\n",
      "2018-05-04T18:02:37.849784: step 14078, loss 0.277441, acc 0.90625\n",
      "2018-05-04T18:02:38.834670: step 14079, loss 0.195598, acc 0.90625\n",
      "2018-05-04T18:02:39.853810: step 14080, loss 0.294418, acc 0.875\n",
      "2018-05-04T18:02:40.870654: step 14081, loss 0.279993, acc 0.875\n",
      "2018-05-04T18:02:41.858516: step 14082, loss 0.254325, acc 0.875\n",
      "2018-05-04T18:02:42.859072: step 14083, loss 0.291643, acc 0.921875\n",
      "2018-05-04T18:02:43.834453: step 14084, loss 0.213613, acc 0.90625\n",
      "2018-05-04T18:02:44.836135: step 14085, loss 0.293082, acc 0.890625\n",
      "2018-05-04T18:02:45.823955: step 14086, loss 0.228204, acc 0.90625\n",
      "2018-05-04T18:02:46.799393: step 14087, loss 0.225908, acc 0.9375\n",
      "2018-05-04T18:02:47.787264: step 14088, loss 0.304185, acc 0.8125\n",
      "2018-05-04T18:02:48.776114: step 14089, loss 0.393905, acc 0.828125\n",
      "2018-05-04T18:02:49.845776: step 14090, loss 0.301851, acc 0.90625\n",
      "2018-05-04T18:02:50.829729: step 14091, loss 0.202899, acc 0.90625\n",
      "2018-05-04T18:02:51.814980: step 14092, loss 0.226637, acc 0.90625\n",
      "2018-05-04T18:02:52.779692: step 14093, loss 0.278808, acc 0.875\n",
      "2018-05-04T18:02:53.752113: step 14094, loss 0.315336, acc 0.875\n",
      "2018-05-04T18:02:54.722127: step 14095, loss 0.0937992, acc 0.984375\n",
      "2018-05-04T18:02:55.775227: step 14096, loss 0.317878, acc 0.875\n",
      "2018-05-04T18:02:56.748499: step 14097, loss 0.237983, acc 0.890625\n",
      "2018-05-04T18:02:57.724325: step 14098, loss 0.292967, acc 0.859375\n",
      "2018-05-04T18:02:58.726425: step 14099, loss 0.156025, acc 0.953125\n",
      "2018-05-04T18:02:59.700815: step 14100, loss 0.413267, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T18:03:01.840713: step 14100, loss 0.21934, acc 0.918\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-14100\n",
      "\n",
      "2018-05-04T18:03:02.988378: step 14101, loss 0.257477, acc 0.9375\n",
      "2018-05-04T18:03:03.983258: step 14102, loss 0.281726, acc 0.859375\n",
      "2018-05-04T18:03:04.957627: step 14103, loss 0.309086, acc 0.84375\n",
      "2018-05-04T18:03:05.914968: step 14104, loss 0.207142, acc 0.890625\n",
      "2018-05-04T18:03:06.873740: step 14105, loss 0.314337, acc 0.875\n",
      "2018-05-04T18:03:07.855468: step 14106, loss 0.263767, acc 0.875\n",
      "2018-05-04T18:03:08.836058: step 14107, loss 0.234875, acc 0.890625\n",
      "2018-05-04T18:03:09.795963: step 14108, loss 0.354445, acc 0.859375\n",
      "2018-05-04T18:03:10.794561: step 14109, loss 0.180353, acc 0.9375\n",
      "2018-05-04T18:03:11.912629: step 14110, loss 0.129288, acc 0.953125\n",
      "2018-05-04T18:03:12.940777: step 14111, loss 0.283335, acc 0.90625\n",
      "2018-05-04T18:03:13.910842: step 14112, loss 0.168192, acc 0.9375\n",
      "2018-05-04T18:03:14.872943: step 14113, loss 0.359046, acc 0.890625\n",
      "2018-05-04T18:03:15.840423: step 14114, loss 0.269424, acc 0.890625\n",
      "2018-05-04T18:03:16.802890: step 14115, loss 0.299051, acc 0.84375\n",
      "2018-05-04T18:03:17.812617: step 14116, loss 0.285445, acc 0.890625\n",
      "2018-05-04T18:03:18.788556: step 14117, loss 0.299854, acc 0.84375\n",
      "2018-05-04T18:03:19.766267: step 14118, loss 0.262433, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T18:03:20.757447: step 14119, loss 0.346394, acc 0.890625\n",
      "2018-05-04T18:03:21.730790: step 14120, loss 0.302411, acc 0.90625\n",
      "2018-05-04T18:03:22.695730: step 14121, loss 0.317319, acc 0.890625\n",
      "2018-05-04T18:03:23.653397: step 14122, loss 0.215746, acc 0.90625\n",
      "2018-05-04T18:03:24.717838: step 14123, loss 0.230626, acc 0.890625\n",
      "2018-05-04T18:03:25.761820: step 14124, loss 0.192679, acc 0.921875\n",
      "2018-05-04T18:03:26.716380: step 14125, loss 0.20954, acc 0.9375\n",
      "2018-05-04T18:03:27.696283: step 14126, loss 0.202914, acc 0.921875\n",
      "2018-05-04T18:03:28.663331: step 14127, loss 0.366857, acc 0.890625\n",
      "2018-05-04T18:03:29.618449: step 14128, loss 0.255254, acc 0.890625\n",
      "2018-05-04T18:03:30.588752: step 14129, loss 0.297253, acc 0.890625\n",
      "2018-05-04T18:03:31.544262: step 14130, loss 0.349299, acc 0.921875\n",
      "2018-05-04T18:03:32.517783: step 14131, loss 0.168207, acc 0.921875\n",
      "2018-05-04T18:03:33.482975: step 14132, loss 0.199131, acc 0.9375\n",
      "2018-05-04T18:03:34.466680: step 14133, loss 0.283744, acc 0.8125\n",
      "2018-05-04T18:03:35.430208: step 14134, loss 0.268607, acc 0.921875\n",
      "2018-05-04T18:03:36.396850: step 14135, loss 0.321419, acc 0.875\n",
      "2018-05-04T18:03:37.374253: step 14136, loss 0.483801, acc 0.8125\n",
      "2018-05-04T18:03:38.378786: step 14137, loss 0.136224, acc 0.96875\n",
      "2018-05-04T18:03:39.354299: step 14138, loss 0.258901, acc 0.875\n",
      "2018-05-04T18:03:40.347388: step 14139, loss 0.227547, acc 0.890625\n",
      "2018-05-04T18:03:41.320020: step 14140, loss 0.3264, acc 0.84375\n",
      "2018-05-04T18:03:42.290163: step 14141, loss 0.279079, acc 0.875\n",
      "2018-05-04T18:03:43.248988: step 14142, loss 0.378387, acc 0.859375\n",
      "2018-05-04T18:03:44.202033: step 14143, loss 0.253131, acc 0.875\n",
      "2018-05-04T18:03:45.187443: step 14144, loss 0.20079, acc 0.890625\n",
      "2018-05-04T18:03:46.181491: step 14145, loss 0.231264, acc 0.90625\n",
      "2018-05-04T18:03:47.144715: step 14146, loss 0.27684, acc 0.90625\n",
      "2018-05-04T18:03:48.135347: step 14147, loss 0.252194, acc 0.90625\n",
      "2018-05-04T18:03:49.129137: step 14148, loss 0.308216, acc 0.890625\n",
      "2018-05-04T18:03:50.129043: step 14149, loss 0.35374, acc 0.84375\n",
      "2018-05-04T18:03:51.113274: step 14150, loss 0.186634, acc 0.953125\n",
      "2018-05-04T18:03:52.066783: step 14151, loss 0.248926, acc 0.875\n",
      "2018-05-04T18:03:53.058756: step 14152, loss 0.168834, acc 0.953125\n",
      "2018-05-04T18:03:54.000834: step 14153, loss 0.220867, acc 0.890625\n",
      "2018-05-04T18:03:55.028806: step 14154, loss 0.326718, acc 0.875\n",
      "2018-05-04T18:03:55.992705: step 14155, loss 0.346222, acc 0.84375\n",
      "2018-05-04T18:03:56.931887: step 14156, loss 0.344883, acc 0.828125\n",
      "2018-05-04T18:03:57.960295: step 14157, loss 0.342254, acc 0.859375\n",
      "2018-05-04T18:03:58.932566: step 14158, loss 0.195476, acc 0.921875\n",
      "2018-05-04T18:03:59.888006: step 14159, loss 0.349148, acc 0.890625\n",
      "2018-05-04T18:04:00.853509: step 14160, loss 0.226449, acc 0.90625\n",
      "2018-05-04T18:04:01.901864: step 14161, loss 0.201353, acc 0.953125\n",
      "2018-05-04T18:04:02.946642: step 14162, loss 0.226472, acc 0.90625\n",
      "2018-05-04T18:04:03.891094: step 14163, loss 0.324257, acc 0.875\n",
      "2018-05-04T18:04:04.901547: step 14164, loss 0.326472, acc 0.890625\n",
      "2018-05-04T18:04:05.903052: step 14165, loss 0.24292, acc 0.90625\n",
      "2018-05-04T18:04:06.882435: step 14166, loss 0.268369, acc 0.875\n",
      "2018-05-04T18:04:07.916054: step 14167, loss 0.218151, acc 0.921875\n",
      "2018-05-04T18:04:08.863748: step 14168, loss 0.210474, acc 0.9375\n",
      "2018-05-04T18:04:09.826493: step 14169, loss 0.251505, acc 0.921875\n",
      "2018-05-04T18:04:10.813509: step 14170, loss 0.255464, acc 0.90625\n",
      "2018-05-04T18:04:11.850499: step 14171, loss 0.295966, acc 0.84375\n",
      "2018-05-04T18:04:12.865259: step 14172, loss 0.223761, acc 0.890625\n",
      "2018-05-04T18:04:13.843847: step 14173, loss 0.347378, acc 0.828125\n",
      "2018-05-04T18:04:14.801211: step 14174, loss 0.452832, acc 0.828125\n",
      "2018-05-04T18:04:15.761856: step 14175, loss 0.298221, acc 0.859375\n",
      "2018-05-04T18:04:16.713405: step 14176, loss 0.387915, acc 0.828125\n",
      "2018-05-04T18:04:17.674600: step 14177, loss 0.176003, acc 0.9375\n",
      "2018-05-04T18:04:18.697523: step 14178, loss 0.322111, acc 0.8125\n",
      "2018-05-04T18:04:19.656463: step 14179, loss 0.200449, acc 0.890625\n",
      "2018-05-04T18:04:20.678323: step 14180, loss 0.208114, acc 0.875\n",
      "2018-05-04T18:04:21.726706: step 14181, loss 0.419907, acc 0.859375\n",
      "2018-05-04T18:04:22.651873: step 14182, loss 0.212049, acc 0.9375\n",
      "2018-05-04T18:04:23.675225: step 14183, loss 0.350065, acc 0.859375\n",
      "2018-05-04T18:04:24.707904: step 14184, loss 0.237478, acc 0.921875\n",
      "2018-05-04T18:04:25.729608: step 14185, loss 0.271876, acc 0.890625\n",
      "2018-05-04T18:04:26.752864: step 14186, loss 0.247678, acc 0.921875\n",
      "2018-05-04T18:04:27.704771: step 14187, loss 0.188914, acc 0.9375\n",
      "2018-05-04T18:04:28.711633: step 14188, loss 0.277104, acc 0.890625\n",
      "2018-05-04T18:04:29.718213: step 14189, loss 0.247812, acc 0.953125\n",
      "2018-05-04T18:04:30.648520: step 14190, loss 0.302605, acc 0.890625\n",
      "2018-05-04T18:04:31.721941: step 14191, loss 0.47226, acc 0.8125\n",
      "2018-05-04T18:04:32.694492: step 14192, loss 0.361082, acc 0.875\n",
      "2018-05-04T18:04:33.702695: step 14193, loss 0.332032, acc 0.890625\n",
      "2018-05-04T18:04:34.753839: step 14194, loss 0.116369, acc 0.984375\n",
      "2018-05-04T18:04:35.859001: step 14195, loss 0.223691, acc 0.9375\n",
      "2018-05-04T18:04:36.919357: step 14196, loss 0.266238, acc 0.890625\n",
      "2018-05-04T18:04:37.968990: step 14197, loss 0.294363, acc 0.828125\n",
      "2018-05-04T18:04:38.941616: step 14198, loss 0.278898, acc 0.953125\n",
      "2018-05-04T18:04:39.957182: step 14199, loss 0.309391, acc 0.859375\n",
      "2018-05-04T18:04:40.993664: step 14200, loss 0.187738, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T18:04:43.815493: step 14200, loss 0.228022, acc 0.92\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-14200\n",
      "\n",
      "2018-05-04T18:04:44.875678: step 14201, loss 0.373651, acc 0.859375\n",
      "2018-05-04T18:04:45.876395: step 14202, loss 0.216572, acc 0.859375\n",
      "2018-05-04T18:04:46.906103: step 14203, loss 0.313399, acc 0.84375\n",
      "2018-05-04T18:04:47.925361: step 14204, loss 0.238665, acc 0.875\n",
      "2018-05-04T18:04:48.964230: step 14205, loss 0.195759, acc 0.921875\n",
      "2018-05-04T18:04:50.014726: step 14206, loss 0.234299, acc 0.859375\n",
      "2018-05-04T18:04:51.102779: step 14207, loss 0.21356, acc 0.90625\n",
      "2018-05-04T18:04:52.136012: step 14208, loss 0.200875, acc 0.9375\n",
      "2018-05-04T18:04:53.122543: step 14209, loss 0.201264, acc 0.921875\n",
      "2018-05-04T18:04:54.142294: step 14210, loss 0.321687, acc 0.875\n",
      "2018-05-04T18:04:55.168179: step 14211, loss 0.403728, acc 0.84375\n",
      "2018-05-04T18:04:56.163481: step 14212, loss 0.27604, acc 0.890625\n",
      "2018-05-04T18:04:57.180907: step 14213, loss 0.268714, acc 0.890625\n",
      "2018-05-04T18:04:58.156647: step 14214, loss 0.305167, acc 0.890625\n",
      "2018-05-04T18:04:59.166430: step 14215, loss 0.229035, acc 0.921875\n",
      "2018-05-04T18:05:00.177387: step 14216, loss 0.256002, acc 0.890625\n",
      "2018-05-04T18:05:01.189801: step 14217, loss 0.327123, acc 0.890625\n",
      "2018-05-04T18:05:02.198129: step 14218, loss 0.144428, acc 0.953125\n",
      "2018-05-04T18:05:03.214379: step 14219, loss 0.329375, acc 0.890625\n",
      "2018-05-04T18:05:04.229795: step 14220, loss 0.154962, acc 0.921875\n",
      "2018-05-04T18:05:05.228870: step 14221, loss 0.144991, acc 0.96875\n",
      "2018-05-04T18:05:06.300436: step 14222, loss 0.322974, acc 0.84375\n",
      "2018-05-04T18:05:07.291479: step 14223, loss 0.348471, acc 0.84375\n",
      "2018-05-04T18:05:08.298049: step 14224, loss 0.170869, acc 0.921875\n",
      "2018-05-04T18:05:09.300976: step 14225, loss 0.269985, acc 0.875\n",
      "2018-05-04T18:05:10.390422: step 14226, loss 0.28009, acc 0.890625\n",
      "2018-05-04T18:05:11.380231: step 14227, loss 0.328956, acc 0.828125\n",
      "2018-05-04T18:05:12.460803: step 14228, loss 0.430518, acc 0.8125\n",
      "2018-05-04T18:05:13.518610: step 14229, loss 0.271744, acc 0.90625\n",
      "2018-05-04T18:05:14.542337: step 14230, loss 0.214852, acc 0.921875\n",
      "2018-05-04T18:05:15.548545: step 14231, loss 0.152177, acc 0.9375\n",
      "2018-05-04T18:05:16.556104: step 14232, loss 0.282237, acc 0.90625\n",
      "2018-05-04T18:05:17.587762: step 14233, loss 0.223179, acc 0.921875\n",
      "2018-05-04T18:05:18.623892: step 14234, loss 0.189933, acc 0.90625\n",
      "2018-05-04T18:05:19.616606: step 14235, loss 0.223071, acc 0.890625\n",
      "2018-05-04T18:05:20.625159: step 14236, loss 0.353702, acc 0.859375\n",
      "2018-05-04T18:05:21.688965: step 14237, loss 0.348068, acc 0.890625\n",
      "2018-05-04T18:05:22.767500: step 14238, loss 0.345909, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T18:05:23.779198: step 14239, loss 0.284944, acc 0.90625\n",
      "2018-05-04T18:05:24.786612: step 14240, loss 0.294012, acc 0.875\n",
      "2018-05-04T18:05:25.790130: step 14241, loss 0.178564, acc 0.90625\n",
      "2018-05-04T18:05:26.853966: step 14242, loss 0.237035, acc 0.890625\n",
      "2018-05-04T18:05:27.830592: step 14243, loss 0.290182, acc 0.890625\n",
      "2018-05-04T18:05:28.808788: step 14244, loss 0.263221, acc 0.875\n",
      "2018-05-04T18:05:29.786391: step 14245, loss 0.28929, acc 0.875\n",
      "2018-05-04T18:05:30.782578: step 14246, loss 0.337321, acc 0.921875\n",
      "2018-05-04T18:05:31.823161: step 14247, loss 0.390249, acc 0.890625\n",
      "2018-05-04T18:05:32.817557: step 14248, loss 0.176436, acc 0.90625\n",
      "2018-05-04T18:05:33.916777: step 14249, loss 0.442216, acc 0.84375\n",
      "2018-05-04T18:05:34.970290: step 14250, loss 0.309566, acc 0.84375\n",
      "2018-05-04T18:05:35.946063: step 14251, loss 0.221455, acc 0.890625\n",
      "2018-05-04T18:05:36.982615: step 14252, loss 0.116983, acc 0.96875\n",
      "2018-05-04T18:05:37.955703: step 14253, loss 0.257963, acc 0.859375\n",
      "2018-05-04T18:05:39.032180: step 14254, loss 0.39581, acc 0.828125\n",
      "2018-05-04T18:05:40.050129: step 14255, loss 0.175043, acc 0.921875\n",
      "2018-05-04T18:05:41.039524: step 14256, loss 0.278412, acc 0.84375\n",
      "2018-05-04T18:05:42.103500: step 14257, loss 0.193662, acc 0.890625\n",
      "2018-05-04T18:05:43.102593: step 14258, loss 0.314807, acc 0.90625\n",
      "2018-05-04T18:05:44.179546: step 14259, loss 0.289682, acc 0.875\n",
      "2018-05-04T18:05:45.161681: step 14260, loss 0.522816, acc 0.796875\n",
      "2018-05-04T18:05:46.132275: step 14261, loss 0.212643, acc 0.90625\n",
      "2018-05-04T18:05:47.104536: step 14262, loss 0.309465, acc 0.84375\n",
      "2018-05-04T18:05:48.081344: step 14263, loss 0.214865, acc 0.890625\n",
      "2018-05-04T18:05:49.075926: step 14264, loss 0.239856, acc 0.921875\n",
      "2018-05-04T18:05:50.075247: step 14265, loss 0.350947, acc 0.84375\n",
      "2018-05-04T18:05:51.071175: step 14266, loss 0.259938, acc 0.9375\n",
      "2018-05-04T18:05:52.051708: step 14267, loss 0.174009, acc 0.953125\n",
      "2018-05-04T18:05:53.041005: step 14268, loss 0.375868, acc 0.84375\n",
      "2018-05-04T18:05:54.012840: step 14269, loss 0.288654, acc 0.859375\n",
      "2018-05-04T18:05:55.060753: step 14270, loss 0.318336, acc 0.828125\n",
      "2018-05-04T18:05:56.038454: step 14271, loss 0.320192, acc 0.921875\n",
      "2018-05-04T18:05:57.032257: step 14272, loss 0.339422, acc 0.84375\n",
      "2018-05-04T18:05:58.002931: step 14273, loss 0.250984, acc 0.90625\n",
      "2018-05-04T18:05:58.989917: step 14274, loss 0.143822, acc 0.953125\n",
      "2018-05-04T18:05:59.962008: step 14275, loss 0.33931, acc 0.84375\n",
      "2018-05-04T18:06:01.012002: step 14276, loss 0.31016, acc 0.859375\n",
      "2018-05-04T18:06:01.968176: step 14277, loss 0.188608, acc 0.90625\n",
      "2018-05-04T18:06:02.966973: step 14278, loss 0.244027, acc 0.890625\n",
      "2018-05-04T18:06:04.052988: step 14279, loss 0.325459, acc 0.859375\n",
      "2018-05-04T18:06:05.016287: step 14280, loss 0.206195, acc 0.921875\n",
      "2018-05-04T18:06:05.980332: step 14281, loss 0.236164, acc 0.890625\n",
      "2018-05-04T18:06:06.938282: step 14282, loss 0.222527, acc 0.921875\n",
      "2018-05-04T18:06:07.906287: step 14283, loss 0.205607, acc 0.953125\n",
      "2018-05-04T18:06:08.897649: step 14284, loss 0.218421, acc 0.90625\n",
      "2018-05-04T18:06:09.871299: step 14285, loss 0.3996, acc 0.84375\n",
      "2018-05-04T18:06:10.870794: step 14286, loss 0.216387, acc 0.921875\n",
      "2018-05-04T18:06:11.851231: step 14287, loss 0.210343, acc 0.875\n",
      "2018-05-04T18:06:12.832797: step 14288, loss 0.346624, acc 0.859375\n",
      "2018-05-04T18:06:13.805036: step 14289, loss 0.239663, acc 0.90625\n",
      "2018-05-04T18:06:14.844338: step 14290, loss 0.294409, acc 0.90625\n",
      "2018-05-04T18:06:15.880942: step 14291, loss 0.35629, acc 0.90625\n",
      "2018-05-04T18:06:16.877173: step 14292, loss 0.219118, acc 0.90625\n",
      "2018-05-04T18:06:17.841788: step 14293, loss 0.224119, acc 0.921875\n",
      "2018-05-04T18:06:18.821203: step 14294, loss 0.262912, acc 0.890625\n",
      "2018-05-04T18:06:19.811006: step 14295, loss 0.253746, acc 0.890625\n",
      "2018-05-04T18:06:20.783350: step 14296, loss 0.239677, acc 0.90625\n",
      "2018-05-04T18:06:21.780436: step 14297, loss 0.208589, acc 0.921875\n",
      "2018-05-04T18:06:22.767961: step 14298, loss 0.24576, acc 0.875\n",
      "2018-05-04T18:06:23.742248: step 14299, loss 0.206913, acc 0.90625\n",
      "2018-05-04T18:06:24.798531: step 14300, loss 0.325098, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T18:06:27.032205: step 14300, loss 0.219792, acc 0.922\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-14300\n",
      "\n",
      "2018-05-04T18:06:28.139231: step 14301, loss 0.260625, acc 0.890625\n",
      "2018-05-04T18:06:29.285314: step 14302, loss 0.261012, acc 0.90625\n",
      "2018-05-04T18:06:30.291904: step 14303, loss 0.323528, acc 0.875\n",
      "2018-05-04T18:06:31.376155: step 14304, loss 0.265974, acc 0.890625\n",
      "2018-05-04T18:06:32.419413: step 14305, loss 0.250496, acc 0.890625\n",
      "2018-05-04T18:06:33.463413: step 14306, loss 0.285117, acc 0.84375\n",
      "2018-05-04T18:06:34.560649: step 14307, loss 0.190376, acc 0.9375\n",
      "2018-05-04T18:06:35.549917: step 14308, loss 0.23163, acc 0.90625\n",
      "2018-05-04T18:06:36.554270: step 14309, loss 0.221165, acc 0.90625\n",
      "2018-05-04T18:06:37.538433: step 14310, loss 0.360906, acc 0.890625\n",
      "2018-05-04T18:06:38.539584: step 14311, loss 0.279091, acc 0.90625\n",
      "2018-05-04T18:06:39.578545: step 14312, loss 0.313444, acc 0.890625\n",
      "2018-05-04T18:06:40.584782: step 14313, loss 0.256319, acc 0.90625\n",
      "2018-05-04T18:06:41.608808: step 14314, loss 0.297107, acc 0.890625\n",
      "2018-05-04T18:06:42.597453: step 14315, loss 0.31138, acc 0.875\n",
      "2018-05-04T18:06:43.586641: step 14316, loss 0.160051, acc 0.9375\n",
      "2018-05-04T18:06:44.558885: step 14317, loss 0.204891, acc 0.890625\n",
      "2018-05-04T18:06:45.651323: step 14318, loss 0.342236, acc 0.90625\n",
      "2018-05-04T18:06:46.653306: step 14319, loss 0.218004, acc 0.90625\n",
      "2018-05-04T18:06:47.662788: step 14320, loss 0.2087, acc 0.890625\n",
      "2018-05-04T18:06:48.673264: step 14321, loss 0.270859, acc 0.84375\n",
      "2018-05-04T18:06:49.677684: step 14322, loss 0.205349, acc 0.953125\n",
      "2018-05-04T18:06:50.683957: step 14323, loss 0.236996, acc 0.890625\n",
      "2018-05-04T18:06:51.748575: step 14324, loss 0.25966, acc 0.921875\n",
      "2018-05-04T18:06:52.781831: step 14325, loss 0.26808, acc 0.90625\n",
      "2018-05-04T18:06:53.805925: step 14326, loss 0.203926, acc 0.9375\n",
      "2018-05-04T18:06:54.808777: step 14327, loss 0.327826, acc 0.859375\n",
      "2018-05-04T18:06:55.810163: step 14328, loss 0.275581, acc 0.90625\n",
      "2018-05-04T18:06:56.806826: step 14329, loss 0.32876, acc 0.84375\n",
      "2018-05-04T18:06:57.801943: step 14330, loss 0.246348, acc 0.875\n",
      "2018-05-04T18:06:58.871008: step 14331, loss 0.32928, acc 0.859375\n",
      "2018-05-04T18:06:59.871595: step 14332, loss 0.233806, acc 0.859375\n",
      "2018-05-04T18:07:00.940523: step 14333, loss 0.274567, acc 0.890625\n",
      "2018-05-04T18:07:02.033222: step 14334, loss 0.22149, acc 0.921875\n",
      "2018-05-04T18:07:03.025126: step 14335, loss 0.378961, acc 0.875\n",
      "2018-05-04T18:07:04.029389: step 14336, loss 0.336712, acc 0.875\n",
      "2018-05-04T18:07:05.025146: step 14337, loss 0.14892, acc 0.96875\n",
      "2018-05-04T18:07:06.053220: step 14338, loss 0.245547, acc 0.921875\n",
      "2018-05-04T18:07:07.110521: step 14339, loss 0.287699, acc 0.875\n",
      "2018-05-04T18:07:08.106918: step 14340, loss 0.208425, acc 0.953125\n",
      "2018-05-04T18:07:09.128192: step 14341, loss 0.196762, acc 0.9375\n",
      "2018-05-04T18:07:10.119982: step 14342, loss 0.12229, acc 0.953125\n",
      "2018-05-04T18:07:11.117862: step 14343, loss 0.256671, acc 0.9375\n",
      "2018-05-04T18:07:12.101182: step 14344, loss 0.197329, acc 0.921875\n",
      "2018-05-04T18:07:13.100692: step 14345, loss 0.259773, acc 0.90625\n",
      "2018-05-04T18:07:14.089244: step 14346, loss 0.340533, acc 0.875\n",
      "2018-05-04T18:07:15.071271: step 14347, loss 0.309218, acc 0.859375\n",
      "2018-05-04T18:07:16.053411: step 14348, loss 0.328073, acc 0.84375\n",
      "2018-05-04T18:07:17.031897: step 14349, loss 0.227345, acc 0.890625\n",
      "2018-05-04T18:07:18.107644: step 14350, loss 0.272051, acc 0.90625\n",
      "2018-05-04T18:07:19.141895: step 14351, loss 0.242884, acc 0.921875\n",
      "2018-05-04T18:07:20.136899: step 14352, loss 0.2952, acc 0.84375\n",
      "2018-05-04T18:07:21.137839: step 14353, loss 0.276867, acc 0.890625\n",
      "2018-05-04T18:07:22.132485: step 14354, loss 0.277464, acc 0.875\n",
      "2018-05-04T18:07:23.118330: step 14355, loss 0.297673, acc 0.875\n",
      "2018-05-04T18:07:24.107775: step 14356, loss 0.247571, acc 0.921875\n",
      "2018-05-04T18:07:25.081968: step 14357, loss 0.335612, acc 0.859375\n",
      "2018-05-04T18:07:26.060633: step 14358, loss 0.473981, acc 0.84375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T18:07:27.139242: step 14359, loss 0.16815, acc 0.953125\n",
      "2018-05-04T18:07:28.113205: step 14360, loss 0.372099, acc 0.84375\n",
      "2018-05-04T18:07:29.102384: step 14361, loss 0.273698, acc 0.875\n",
      "2018-05-04T18:07:30.085826: step 14362, loss 0.296607, acc 0.828125\n",
      "2018-05-04T18:07:31.082143: step 14363, loss 0.24101, acc 0.921875\n",
      "2018-05-04T18:07:32.080494: step 14364, loss 0.34897, acc 0.890625\n",
      "2018-05-04T18:07:33.103986: step 14365, loss 0.32099, acc 0.875\n",
      "2018-05-04T18:07:34.241981: step 14366, loss 0.242501, acc 0.90625\n",
      "2018-05-04T18:07:35.347161: step 14367, loss 0.322079, acc 0.8125\n",
      "2018-05-04T18:07:36.444487: step 14368, loss 0.387397, acc 0.84375\n",
      "2018-05-04T18:07:37.428944: step 14369, loss 0.207184, acc 0.921875\n",
      "2018-05-04T18:07:38.422020: step 14370, loss 0.351027, acc 0.890625\n",
      "2018-05-04T18:07:39.385210: step 14371, loss 0.291909, acc 0.890625\n",
      "2018-05-04T18:07:40.349192: step 14372, loss 0.417838, acc 0.8125\n",
      "2018-05-04T18:07:41.330890: step 14373, loss 0.133082, acc 0.953125\n",
      "2018-05-04T18:07:42.323963: step 14374, loss 0.263115, acc 0.890625\n",
      "2018-05-04T18:07:43.299368: step 14375, loss 0.239113, acc 0.890625\n",
      "2018-05-04T18:07:44.280810: step 14376, loss 0.164117, acc 0.9375\n",
      "2018-05-04T18:07:45.254816: step 14377, loss 0.204287, acc 0.953125\n",
      "2018-05-04T18:07:46.225170: step 14378, loss 0.286851, acc 0.84375\n",
      "2018-05-04T18:07:47.209445: step 14379, loss 0.228663, acc 0.921875\n",
      "2018-05-04T18:07:48.229870: step 14380, loss 0.234985, acc 0.890625\n",
      "2018-05-04T18:07:49.266074: step 14381, loss 0.201369, acc 0.890625\n",
      "2018-05-04T18:07:50.250108: step 14382, loss 0.254552, acc 0.890625\n",
      "2018-05-04T18:07:51.233657: step 14383, loss 0.334737, acc 0.84375\n",
      "2018-05-04T18:07:52.317596: step 14384, loss 0.350452, acc 0.828125\n",
      "2018-05-04T18:07:53.286448: step 14385, loss 0.256395, acc 0.890625\n",
      "2018-05-04T18:07:54.287528: step 14386, loss 0.140234, acc 0.9375\n",
      "2018-05-04T18:07:55.242289: step 14387, loss 0.194339, acc 0.9375\n",
      "2018-05-04T18:07:56.220239: step 14388, loss 0.250189, acc 0.859375\n",
      "2018-05-04T18:07:57.173160: step 14389, loss 0.264075, acc 0.890625\n",
      "2018-05-04T18:07:58.153031: step 14390, loss 0.326874, acc 0.859375\n",
      "2018-05-04T18:07:59.133559: step 14391, loss 0.345837, acc 0.890625\n",
      "2018-05-04T18:08:00.081846: step 14392, loss 0.263677, acc 0.921875\n",
      "2018-05-04T18:08:01.040506: step 14393, loss 0.270684, acc 0.921875\n",
      "2018-05-04T18:08:02.006646: step 14394, loss 0.23029, acc 0.921875\n",
      "2018-05-04T18:08:03.001115: step 14395, loss 0.16116, acc 0.96875\n",
      "2018-05-04T18:08:03.986303: step 14396, loss 0.304655, acc 0.84375\n",
      "2018-05-04T18:08:04.987403: step 14397, loss 0.197292, acc 0.921875\n",
      "2018-05-04T18:08:05.943009: step 14398, loss 0.266639, acc 0.921875\n",
      "2018-05-04T18:08:06.896233: step 14399, loss 0.364303, acc 0.875\n",
      "2018-05-04T18:08:07.871086: step 14400, loss 0.220346, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T18:08:10.633071: step 14400, loss 0.211515, acc 0.926\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-14400\n",
      "\n",
      "2018-05-04T18:08:11.742571: step 14401, loss 0.257105, acc 0.890625\n",
      "2018-05-04T18:08:12.821553: step 14402, loss 0.254798, acc 0.890625\n",
      "2018-05-04T18:08:13.835985: step 14403, loss 0.181577, acc 0.953125\n",
      "2018-05-04T18:08:14.894783: step 14404, loss 0.344742, acc 0.90625\n",
      "2018-05-04T18:08:16.009218: step 14405, loss 0.207826, acc 0.921875\n",
      "2018-05-04T18:08:17.099728: step 14406, loss 0.26262, acc 0.890625\n",
      "2018-05-04T18:08:18.117652: step 14407, loss 0.24161, acc 0.890625\n",
      "2018-05-04T18:08:19.149632: step 14408, loss 0.242995, acc 0.921875\n",
      "2018-05-04T18:08:20.183185: step 14409, loss 0.196595, acc 0.953125\n",
      "2018-05-04T18:08:21.187344: step 14410, loss 0.379413, acc 0.859375\n",
      "2018-05-04T18:08:22.211869: step 14411, loss 0.36516, acc 0.875\n",
      "2018-05-04T18:08:23.222639: step 14412, loss 0.283991, acc 0.890625\n",
      "2018-05-04T18:08:24.292760: step 14413, loss 0.249718, acc 0.921875\n",
      "2018-05-04T18:08:25.279672: step 14414, loss 0.320783, acc 0.859375\n",
      "2018-05-04T18:08:26.357002: step 14415, loss 0.306011, acc 0.84375\n",
      "2018-05-04T18:08:27.401716: step 14416, loss 0.19998, acc 0.90625\n",
      "2018-05-04T18:08:28.385333: step 14417, loss 0.261001, acc 0.890625\n",
      "2018-05-04T18:08:29.386329: step 14418, loss 0.300729, acc 0.90625\n",
      "2018-05-04T18:08:30.389711: step 14419, loss 0.252525, acc 0.890625\n",
      "2018-05-04T18:08:31.460872: step 14420, loss 0.333162, acc 0.875\n",
      "2018-05-04T18:08:32.510677: step 14421, loss 0.188376, acc 0.9375\n",
      "2018-05-04T18:08:33.634637: step 14422, loss 0.294035, acc 0.84375\n",
      "2018-05-04T18:08:34.656569: step 14423, loss 0.363996, acc 0.828125\n",
      "2018-05-04T18:08:35.663847: step 14424, loss 0.153279, acc 0.96875\n",
      "2018-05-04T18:08:36.644615: step 14425, loss 0.1514, acc 0.9375\n",
      "2018-05-04T18:08:37.680392: step 14426, loss 0.238142, acc 0.875\n",
      "2018-05-04T18:08:38.683825: step 14427, loss 0.244111, acc 0.890625\n",
      "2018-05-04T18:08:39.681126: step 14428, loss 0.239834, acc 0.921875\n",
      "2018-05-04T18:08:40.663496: step 14429, loss 0.445986, acc 0.828125\n",
      "2018-05-04T18:08:41.696908: step 14430, loss 0.349915, acc 0.859375\n",
      "2018-05-04T18:08:42.778428: step 14431, loss 0.318347, acc 0.859375\n",
      "2018-05-04T18:08:43.751246: step 14432, loss 0.347906, acc 0.921875\n",
      "2018-05-04T18:08:44.716022: step 14433, loss 0.249052, acc 0.90625\n",
      "2018-05-04T18:08:45.716730: step 14434, loss 0.172733, acc 0.9375\n",
      "2018-05-04T18:08:46.731656: step 14435, loss 0.324655, acc 0.890625\n",
      "2018-05-04T18:08:47.752173: step 14436, loss 0.322575, acc 0.90625\n",
      "2018-05-04T18:08:48.757552: step 14437, loss 0.211475, acc 0.9375\n",
      "2018-05-04T18:08:49.774209: step 14438, loss 0.120173, acc 0.984375\n",
      "2018-05-04T18:08:50.772404: step 14439, loss 0.185131, acc 0.953125\n",
      "2018-05-04T18:08:51.800841: step 14440, loss 0.251603, acc 0.890625\n",
      "2018-05-04T18:08:52.795604: step 14441, loss 0.246001, acc 0.875\n",
      "2018-05-04T18:08:53.800233: step 14442, loss 0.39575, acc 0.828125\n",
      "2018-05-04T18:08:54.866247: step 14443, loss 0.29762, acc 0.875\n",
      "2018-05-04T18:08:55.909232: step 14444, loss 0.285496, acc 0.90625\n",
      "2018-05-04T18:08:56.894287: step 14445, loss 0.21783, acc 0.90625\n",
      "2018-05-04T18:08:57.893726: step 14446, loss 0.476638, acc 0.8125\n",
      "2018-05-04T18:08:58.881224: step 14447, loss 0.310169, acc 0.90625\n",
      "2018-05-04T18:08:59.882902: step 14448, loss 0.201768, acc 0.9375\n",
      "2018-05-04T18:09:00.874679: step 14449, loss 0.257474, acc 0.90625\n",
      "2018-05-04T18:09:01.876201: step 14450, loss 0.23605, acc 0.90625\n",
      "2018-05-04T18:09:02.860417: step 14451, loss 0.28978, acc 0.875\n",
      "2018-05-04T18:09:03.922842: step 14452, loss 0.256265, acc 0.890625\n",
      "2018-05-04T18:09:04.903117: step 14453, loss 0.215283, acc 0.90625\n",
      "2018-05-04T18:09:05.876089: step 14454, loss 0.108535, acc 0.96875\n",
      "2018-05-04T18:09:06.864873: step 14455, loss 0.130887, acc 0.953125\n",
      "2018-05-04T18:09:07.866732: step 14456, loss 0.292945, acc 0.859375\n",
      "2018-05-04T18:09:08.847530: step 14457, loss 0.271513, acc 0.9375\n",
      "2018-05-04T18:09:09.863603: step 14458, loss 0.148886, acc 0.953125\n",
      "2018-05-04T18:09:10.944515: step 14459, loss 0.57054, acc 0.8125\n",
      "2018-05-04T18:09:11.923967: step 14460, loss 0.203342, acc 0.953125\n",
      "2018-05-04T18:09:12.912811: step 14461, loss 0.293196, acc 0.890625\n",
      "2018-05-04T18:09:13.907008: step 14462, loss 0.158916, acc 0.9375\n",
      "2018-05-04T18:09:14.943251: step 14463, loss 0.259709, acc 0.890625\n",
      "2018-05-04T18:09:15.918227: step 14464, loss 0.253911, acc 0.90625\n",
      "2018-05-04T18:09:16.892113: step 14465, loss 0.326076, acc 0.84375\n",
      "2018-05-04T18:09:17.931334: step 14466, loss 0.243086, acc 0.890625\n",
      "2018-05-04T18:09:18.982307: step 14467, loss 0.245853, acc 0.9375\n",
      "2018-05-04T18:09:20.042015: step 14468, loss 0.217667, acc 0.9375\n",
      "2018-05-04T18:09:20.994753: step 14469, loss 0.216863, acc 0.921875\n",
      "2018-05-04T18:09:21.975100: step 14470, loss 0.202964, acc 0.921875\n",
      "2018-05-04T18:09:23.047894: step 14471, loss 0.276615, acc 0.859375\n",
      "2018-05-04T18:09:24.022065: step 14472, loss 0.283745, acc 0.90625\n",
      "2018-05-04T18:09:24.977394: step 14473, loss 0.232222, acc 0.921875\n",
      "2018-05-04T18:09:25.947181: step 14474, loss 0.45335, acc 0.8125\n",
      "2018-05-04T18:09:26.908202: step 14475, loss 0.269526, acc 0.890625\n",
      "2018-05-04T18:09:27.903502: step 14476, loss 0.354392, acc 0.875\n",
      "2018-05-04T18:09:28.880007: step 14477, loss 0.358187, acc 0.84375\n",
      "2018-05-04T18:09:29.858401: step 14478, loss 0.231239, acc 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T18:09:30.830622: step 14479, loss 0.267385, acc 0.875\n",
      "2018-05-04T18:09:31.821866: step 14480, loss 0.259958, acc 0.859375\n",
      "2018-05-04T18:09:32.797165: step 14481, loss 0.255077, acc 0.890625\n",
      "2018-05-04T18:09:33.793005: step 14482, loss 0.238166, acc 0.875\n",
      "2018-05-04T18:09:34.769248: step 14483, loss 0.401638, acc 0.859375\n",
      "2018-05-04T18:09:35.801207: step 14484, loss 0.24806, acc 0.875\n",
      "2018-05-04T18:09:36.825346: step 14485, loss 0.282873, acc 0.890625\n",
      "2018-05-04T18:09:37.790930: step 14486, loss 0.28823, acc 0.90625\n",
      "2018-05-04T18:09:38.771742: step 14487, loss 0.294102, acc 0.84375\n",
      "2018-05-04T18:09:39.744188: step 14488, loss 0.31088, acc 0.890625\n",
      "2018-05-04T18:09:40.714644: step 14489, loss 0.190597, acc 0.90625\n",
      "2018-05-04T18:09:41.710171: step 14490, loss 0.14858, acc 0.96875\n",
      "2018-05-04T18:09:42.707409: step 14491, loss 0.378788, acc 0.8125\n",
      "2018-05-04T18:09:43.711515: step 14492, loss 0.299489, acc 0.859375\n",
      "2018-05-04T18:09:44.673785: step 14493, loss 0.223612, acc 0.921875\n",
      "2018-05-04T18:09:45.634794: step 14494, loss 0.332667, acc 0.921875\n",
      "2018-05-04T18:09:46.596944: step 14495, loss 0.344574, acc 0.859375\n",
      "2018-05-04T18:09:47.580158: step 14496, loss 0.230679, acc 0.921875\n",
      "2018-05-04T18:09:48.538578: step 14497, loss 0.291378, acc 0.890625\n",
      "2018-05-04T18:09:49.503951: step 14498, loss 0.131496, acc 0.953125\n",
      "2018-05-04T18:09:50.468856: step 14499, loss 0.294952, acc 0.84375\n",
      "2018-05-04T18:09:51.449848: step 14500, loss 0.177563, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T18:09:53.940972: step 14500, loss 0.222924, acc 0.934\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-14500\n",
      "\n",
      "2018-05-04T18:09:55.050229: step 14501, loss 0.194022, acc 0.921875\n",
      "2018-05-04T18:09:56.077613: step 14502, loss 0.401287, acc 0.875\n",
      "2018-05-04T18:09:57.137010: step 14503, loss 0.371755, acc 0.890625\n",
      "2018-05-04T18:09:58.251752: step 14504, loss 0.273414, acc 0.890625\n",
      "2018-05-04T18:09:59.323702: step 14505, loss 0.350986, acc 0.875\n",
      "2018-05-04T18:10:00.382147: step 14506, loss 0.242644, acc 0.921875\n",
      "2018-05-04T18:10:01.446089: step 14507, loss 0.353347, acc 0.859375\n",
      "2018-05-04T18:10:02.490319: step 14508, loss 0.369501, acc 0.8125\n",
      "2018-05-04T18:10:03.554871: step 14509, loss 0.300587, acc 0.890625\n",
      "2018-05-04T18:10:04.621735: step 14510, loss 0.229748, acc 0.859375\n",
      "2018-05-04T18:10:05.614391: step 14511, loss 0.315374, acc 0.84375\n",
      "2018-05-04T18:10:06.567893: step 14512, loss 0.184431, acc 0.9375\n",
      "2018-05-04T18:10:07.556941: step 14513, loss 0.240917, acc 0.875\n",
      "2018-05-04T18:10:08.545585: step 14514, loss 0.257351, acc 0.90625\n",
      "2018-05-04T18:10:09.560346: step 14515, loss 0.211843, acc 0.9375\n",
      "2018-05-04T18:10:10.558438: step 14516, loss 0.305668, acc 0.921875\n",
      "2018-05-04T18:10:11.550579: step 14517, loss 0.202966, acc 0.9375\n",
      "2018-05-04T18:10:12.544185: step 14518, loss 0.230168, acc 0.90625\n",
      "2018-05-04T18:10:13.527353: step 14519, loss 0.229151, acc 0.890625\n",
      "2018-05-04T18:10:14.509742: step 14520, loss 0.32516, acc 0.84375\n",
      "2018-05-04T18:10:15.480201: step 14521, loss 0.32788, acc 0.875\n",
      "2018-05-04T18:10:16.515166: step 14522, loss 0.322884, acc 0.828125\n",
      "2018-05-04T18:10:17.493088: step 14523, loss 0.163997, acc 0.953125\n",
      "2018-05-04T18:10:18.480727: step 14524, loss 0.317477, acc 0.890625\n",
      "2018-05-04T18:10:19.495720: step 14525, loss 0.366551, acc 0.875\n",
      "2018-05-04T18:10:20.513816: step 14526, loss 0.386302, acc 0.828125\n",
      "2018-05-04T18:10:21.518405: step 14527, loss 0.403945, acc 0.84375\n",
      "2018-05-04T18:10:22.509770: step 14528, loss 0.286361, acc 0.890625\n",
      "2018-05-04T18:10:23.525194: step 14529, loss 0.353258, acc 0.875\n",
      "2018-05-04T18:10:24.545692: step 14530, loss 0.211204, acc 0.90625\n",
      "2018-05-04T18:10:25.554698: step 14531, loss 0.366924, acc 0.875\n",
      "2018-05-04T18:10:26.548741: step 14532, loss 0.273187, acc 0.84375\n",
      "2018-05-04T18:10:27.537204: step 14533, loss 0.37527, acc 0.8125\n",
      "2018-05-04T18:10:28.534374: step 14534, loss 0.228356, acc 0.9375\n",
      "2018-05-04T18:10:29.529182: step 14535, loss 0.158948, acc 0.984375\n",
      "2018-05-04T18:10:30.515386: step 14536, loss 0.181685, acc 0.9375\n",
      "2018-05-04T18:10:31.518865: step 14537, loss 0.434587, acc 0.828125\n",
      "2018-05-04T18:10:32.513343: step 14538, loss 0.322238, acc 0.875\n",
      "2018-05-04T18:10:33.549388: step 14539, loss 0.273165, acc 0.921875\n",
      "2018-05-04T18:10:34.631044: step 14540, loss 0.177026, acc 0.90625\n",
      "2018-05-04T18:10:35.660394: step 14541, loss 0.24177, acc 0.90625\n",
      "2018-05-04T18:10:36.679827: step 14542, loss 0.182675, acc 0.921875\n",
      "2018-05-04T18:10:37.685830: step 14543, loss 0.29337, acc 0.84375\n",
      "2018-05-04T18:10:38.673211: step 14544, loss 0.288054, acc 0.875\n",
      "2018-05-04T18:10:39.654962: step 14545, loss 0.30148, acc 0.875\n",
      "2018-05-04T18:10:40.681092: step 14546, loss 0.201096, acc 0.921875\n",
      "2018-05-04T18:10:41.727930: step 14547, loss 0.126491, acc 1\n",
      "2018-05-04T18:10:42.703959: step 14548, loss 0.283819, acc 0.90625\n",
      "2018-05-04T18:10:43.705695: step 14549, loss 0.19347, acc 0.921875\n",
      "2018-05-04T18:10:44.720322: step 14550, loss 0.187858, acc 0.921875\n",
      "2018-05-04T18:10:45.778480: step 14551, loss 0.214422, acc 0.921875\n",
      "2018-05-04T18:10:46.758804: step 14552, loss 0.27772, acc 0.890625\n",
      "2018-05-04T18:10:47.720803: step 14553, loss 0.260566, acc 0.859375\n",
      "2018-05-04T18:10:48.718950: step 14554, loss 0.330163, acc 0.921875\n",
      "2018-05-04T18:10:49.699822: step 14555, loss 0.346482, acc 0.859375\n",
      "2018-05-04T18:10:50.673385: step 14556, loss 0.305006, acc 0.875\n",
      "2018-05-04T18:10:51.645119: step 14557, loss 0.269032, acc 0.890625\n",
      "2018-05-04T18:10:52.644780: step 14558, loss 0.239773, acc 0.921875\n",
      "2018-05-04T18:10:53.699483: step 14559, loss 0.258538, acc 0.890625\n",
      "2018-05-04T18:10:54.651767: step 14560, loss 0.252445, acc 0.9375\n",
      "2018-05-04T18:10:55.610255: step 14561, loss 0.176325, acc 0.9375\n",
      "2018-05-04T18:10:56.564275: step 14562, loss 0.291843, acc 0.90625\n",
      "2018-05-04T18:10:57.545821: step 14563, loss 0.321656, acc 0.84375\n",
      "2018-05-04T18:10:58.526682: step 14564, loss 0.41852, acc 0.875\n",
      "2018-05-04T18:10:59.513182: step 14565, loss 0.267119, acc 0.875\n",
      "2018-05-04T18:11:00.502132: step 14566, loss 0.195446, acc 0.921875\n",
      "2018-05-04T18:11:01.493407: step 14567, loss 0.342954, acc 0.859375\n",
      "2018-05-04T18:11:02.474203: step 14568, loss 0.23814, acc 0.90625\n",
      "2018-05-04T18:11:03.447743: step 14569, loss 0.240074, acc 0.890625\n",
      "2018-05-04T18:11:04.432988: step 14570, loss 0.297732, acc 0.875\n",
      "2018-05-04T18:11:05.406375: step 14571, loss 0.399518, acc 0.84375\n",
      "2018-05-04T18:11:06.384355: step 14572, loss 0.242468, acc 0.90625\n",
      "2018-05-04T18:11:07.351891: step 14573, loss 0.245491, acc 0.890625\n",
      "2018-05-04T18:11:08.323557: step 14574, loss 0.180776, acc 0.953125\n",
      "2018-05-04T18:11:09.302283: step 14575, loss 0.248788, acc 0.890625\n",
      "2018-05-04T18:11:10.269302: step 14576, loss 0.207868, acc 0.890625\n",
      "2018-05-04T18:11:11.231919: step 14577, loss 0.23985, acc 0.90625\n",
      "2018-05-04T18:11:12.200968: step 14578, loss 0.479277, acc 0.84375\n",
      "2018-05-04T18:11:13.197537: step 14579, loss 0.246708, acc 0.84375\n",
      "2018-05-04T18:11:14.185044: step 14580, loss 0.314657, acc 0.84375\n",
      "2018-05-04T18:11:15.150610: step 14581, loss 0.232141, acc 0.890625\n",
      "2018-05-04T18:11:16.135030: step 14582, loss 0.20329, acc 0.921875\n",
      "2018-05-04T18:11:17.138877: step 14583, loss 0.35229, acc 0.90625\n",
      "2018-05-04T18:11:18.105240: step 14584, loss 0.175685, acc 0.953125\n",
      "2018-05-04T18:11:19.056826: step 14585, loss 0.231098, acc 0.875\n",
      "2018-05-04T18:11:20.029131: step 14586, loss 0.252773, acc 0.875\n",
      "2018-05-04T18:11:21.011281: step 14587, loss 0.384206, acc 0.859375\n",
      "2018-05-04T18:11:22.096181: step 14588, loss 0.236609, acc 0.875\n",
      "2018-05-04T18:11:23.173560: step 14589, loss 0.220944, acc 0.875\n",
      "2018-05-04T18:11:24.163758: step 14590, loss 0.198758, acc 0.875\n",
      "2018-05-04T18:11:25.125118: step 14591, loss 0.405322, acc 0.8125\n",
      "2018-05-04T18:11:26.104244: step 14592, loss 0.176751, acc 0.96875\n",
      "2018-05-04T18:11:27.055594: step 14593, loss 0.338471, acc 0.8125\n",
      "2018-05-04T18:11:28.024090: step 14594, loss 0.298452, acc 0.90625\n",
      "2018-05-04T18:11:28.996344: step 14595, loss 0.138793, acc 0.96875\n",
      "2018-05-04T18:11:29.974013: step 14596, loss 0.226589, acc 0.90625\n",
      "2018-05-04T18:11:30.952603: step 14597, loss 0.252478, acc 0.921875\n",
      "2018-05-04T18:11:31.916806: step 14598, loss 0.316577, acc 0.859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T18:11:32.903461: step 14599, loss 0.237513, acc 0.90625\n",
      "2018-05-04T18:11:33.921197: step 14600, loss 0.195248, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T18:11:36.484258: step 14600, loss 0.231289, acc 0.922\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-14600\n",
      "\n",
      "2018-05-04T18:11:37.580498: step 14601, loss 0.258723, acc 0.90625\n",
      "2018-05-04T18:11:38.593195: step 14602, loss 0.150756, acc 0.9375\n",
      "2018-05-04T18:11:39.605446: step 14603, loss 0.170756, acc 0.921875\n",
      "2018-05-04T18:11:40.629478: step 14604, loss 0.10552, acc 1\n",
      "2018-05-04T18:11:41.667691: step 14605, loss 0.342164, acc 0.875\n",
      "2018-05-04T18:11:42.793060: step 14606, loss 0.244209, acc 0.90625\n",
      "2018-05-04T18:11:43.845213: step 14607, loss 0.231611, acc 0.921875\n",
      "2018-05-04T18:11:44.912251: step 14608, loss 0.201212, acc 0.921875\n",
      "2018-05-04T18:11:45.923194: step 14609, loss 0.486819, acc 0.828125\n",
      "2018-05-04T18:11:46.952281: step 14610, loss 0.178111, acc 0.96875\n",
      "2018-05-04T18:11:47.937709: step 14611, loss 0.327291, acc 0.875\n",
      "2018-05-04T18:11:48.952649: step 14612, loss 0.342301, acc 0.859375\n",
      "2018-05-04T18:11:49.985642: step 14613, loss 0.395244, acc 0.875\n",
      "2018-05-04T18:11:50.986509: step 14614, loss 0.207545, acc 0.890625\n",
      "2018-05-04T18:11:52.013375: step 14615, loss 0.290464, acc 0.84375\n",
      "2018-05-04T18:11:53.008719: step 14616, loss 0.203572, acc 0.90625\n",
      "2018-05-04T18:11:54.104116: step 14617, loss 0.365318, acc 0.859375\n",
      "2018-05-04T18:11:55.116540: step 14618, loss 0.251611, acc 0.890625\n",
      "2018-05-04T18:11:56.167686: step 14619, loss 0.159941, acc 0.96875\n",
      "2018-05-04T18:11:57.194118: step 14620, loss 0.318392, acc 0.890625\n",
      "2018-05-04T18:11:58.181901: step 14621, loss 0.357721, acc 0.859375\n",
      "2018-05-04T18:11:59.163003: step 14622, loss 0.270532, acc 0.90625\n",
      "2018-05-04T18:12:00.159378: step 14623, loss 0.303155, acc 0.875\n",
      "2018-05-04T18:12:01.165755: step 14624, loss 0.234037, acc 0.90625\n",
      "2018-05-04T18:12:02.179495: step 14625, loss 0.168696, acc 0.953125\n",
      "2018-05-04T18:12:03.189929: step 14626, loss 0.189376, acc 0.953125\n",
      "2018-05-04T18:12:04.180454: step 14627, loss 0.267886, acc 0.859375\n",
      "2018-05-04T18:12:05.273369: step 14628, loss 0.21955, acc 0.875\n",
      "2018-05-04T18:12:06.285282: step 14629, loss 0.143064, acc 0.953125\n",
      "2018-05-04T18:12:07.275101: step 14630, loss 0.327838, acc 0.890625\n",
      "2018-05-04T18:12:08.262735: step 14631, loss 0.299838, acc 0.890625\n",
      "2018-05-04T18:12:09.238816: step 14632, loss 0.289697, acc 0.890625\n",
      "2018-05-04T18:12:10.253049: step 14633, loss 0.272796, acc 0.875\n",
      "2018-05-04T18:12:11.262703: step 14634, loss 0.318305, acc 0.84375\n",
      "2018-05-04T18:12:12.277501: step 14635, loss 0.130384, acc 0.984375\n",
      "2018-05-04T18:12:13.267339: step 14636, loss 0.282951, acc 0.890625\n",
      "2018-05-04T18:12:14.266467: step 14637, loss 0.299126, acc 0.890625\n",
      "2018-05-04T18:12:15.266987: step 14638, loss 0.352954, acc 0.859375\n",
      "2018-05-04T18:12:16.246483: step 14639, loss 0.254646, acc 0.9375\n",
      "2018-05-04T18:12:17.277027: step 14640, loss 0.264949, acc 0.859375\n",
      "2018-05-04T18:12:18.341880: step 14641, loss 0.250978, acc 0.90625\n",
      "2018-05-04T18:12:19.324189: step 14642, loss 0.262078, acc 0.875\n",
      "2018-05-04T18:12:20.317855: step 14643, loss 0.307176, acc 0.875\n",
      "2018-05-04T18:12:21.300761: step 14644, loss 0.420031, acc 0.8125\n",
      "2018-05-04T18:12:22.343576: step 14645, loss 0.355604, acc 0.8125\n",
      "2018-05-04T18:12:23.368600: step 14646, loss 0.319702, acc 0.875\n",
      "2018-05-04T18:12:24.458609: step 14647, loss 0.269268, acc 0.84375\n",
      "2018-05-04T18:12:25.430463: step 14648, loss 0.350014, acc 0.890625\n",
      "2018-05-04T18:12:26.422824: step 14649, loss 0.214821, acc 0.921875\n",
      "2018-05-04T18:12:27.405412: step 14650, loss 0.242491, acc 0.90625\n",
      "2018-05-04T18:12:28.451201: step 14651, loss 0.239034, acc 0.90625\n",
      "2018-05-04T18:12:29.440136: step 14652, loss 0.271295, acc 0.90625\n",
      "2018-05-04T18:12:30.419551: step 14653, loss 0.209864, acc 0.921875\n",
      "2018-05-04T18:12:31.404479: step 14654, loss 0.274801, acc 0.90625\n",
      "2018-05-04T18:12:32.391372: step 14655, loss 0.241622, acc 0.90625\n",
      "2018-05-04T18:12:33.391835: step 14656, loss 0.24599, acc 0.921875\n",
      "2018-05-04T18:12:34.390551: step 14657, loss 0.200493, acc 0.890625\n",
      "2018-05-04T18:12:35.372420: step 14658, loss 0.281524, acc 0.859375\n",
      "2018-05-04T18:12:36.355831: step 14659, loss 0.319211, acc 0.875\n",
      "2018-05-04T18:12:37.350961: step 14660, loss 0.28467, acc 0.84375\n",
      "2018-05-04T18:12:38.314533: step 14661, loss 0.266638, acc 0.890625\n",
      "2018-05-04T18:12:39.389652: step 14662, loss 0.276556, acc 0.875\n",
      "2018-05-04T18:12:40.366369: step 14663, loss 0.335646, acc 0.8125\n",
      "2018-05-04T18:12:41.346564: step 14664, loss 0.15269, acc 0.9375\n",
      "2018-05-04T18:12:42.375084: step 14665, loss 0.18267, acc 0.9375\n",
      "2018-05-04T18:12:43.360948: step 14666, loss 0.228592, acc 0.90625\n",
      "2018-05-04T18:12:44.429404: step 14667, loss 0.229585, acc 0.875\n",
      "2018-05-04T18:12:45.392433: step 14668, loss 0.296301, acc 0.875\n",
      "2018-05-04T18:12:46.371812: step 14669, loss 0.355331, acc 0.890625\n",
      "2018-05-04T18:12:47.350812: step 14670, loss 0.332171, acc 0.828125\n",
      "2018-05-04T18:12:48.330061: step 14671, loss 0.307874, acc 0.84375\n",
      "2018-05-04T18:12:49.328120: step 14672, loss 0.404167, acc 0.796875\n",
      "2018-05-04T18:12:50.276033: step 14673, loss 0.341244, acc 0.875\n",
      "2018-05-04T18:12:51.227429: step 14674, loss 0.353069, acc 0.828125\n",
      "2018-05-04T18:12:52.209486: step 14675, loss 0.337597, acc 0.859375\n",
      "2018-05-04T18:12:53.191777: step 14676, loss 0.266601, acc 0.84375\n",
      "2018-05-04T18:12:54.168547: step 14677, loss 0.234337, acc 0.90625\n",
      "2018-05-04T18:12:55.146767: step 14678, loss 0.159532, acc 0.9375\n",
      "2018-05-04T18:12:56.121708: step 14679, loss 0.135581, acc 0.953125\n",
      "2018-05-04T18:12:57.096429: step 14680, loss 0.262627, acc 0.890625\n",
      "2018-05-04T18:12:58.063387: step 14681, loss 0.262456, acc 0.90625\n",
      "2018-05-04T18:12:59.038534: step 14682, loss 0.23799, acc 0.890625\n",
      "2018-05-04T18:13:00.016945: step 14683, loss 0.27419, acc 0.90625\n",
      "2018-05-04T18:13:01.016420: step 14684, loss 0.1672, acc 0.9375\n",
      "2018-05-04T18:13:02.069381: step 14685, loss 0.195362, acc 0.90625\n",
      "2018-05-04T18:13:03.041820: step 14686, loss 0.170665, acc 0.921875\n",
      "2018-05-04T18:13:04.022883: step 14687, loss 0.209668, acc 0.875\n",
      "2018-05-04T18:13:05.038330: step 14688, loss 0.359763, acc 0.84375\n",
      "2018-05-04T18:13:06.016927: step 14689, loss 0.277343, acc 0.90625\n",
      "2018-05-04T18:13:06.993285: step 14690, loss 0.312044, acc 0.84375\n",
      "2018-05-04T18:13:07.972947: step 14691, loss 0.273956, acc 0.875\n",
      "2018-05-04T18:13:08.939473: step 14692, loss 0.192458, acc 0.953125\n",
      "2018-05-04T18:13:09.910182: step 14693, loss 0.323209, acc 0.859375\n",
      "2018-05-04T18:13:10.878105: step 14694, loss 0.248903, acc 0.890625\n",
      "2018-05-04T18:13:11.860997: step 14695, loss 0.318582, acc 0.890625\n",
      "2018-05-04T18:13:12.825251: step 14696, loss 0.185671, acc 0.90625\n",
      "2018-05-04T18:13:13.807627: step 14697, loss 0.251128, acc 0.875\n",
      "2018-05-04T18:13:14.761146: step 14698, loss 0.206009, acc 0.921875\n",
      "2018-05-04T18:13:15.718499: step 14699, loss 0.200508, acc 0.953125\n",
      "2018-05-04T18:13:16.703302: step 14700, loss 0.225026, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T18:13:19.026059: step 14700, loss 0.21547, acc 0.93\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-14700\n",
      "\n",
      "2018-05-04T18:13:20.154766: step 14701, loss 0.251486, acc 0.890625\n",
      "2018-05-04T18:13:21.179669: step 14702, loss 0.29521, acc 0.84375\n",
      "2018-05-04T18:13:22.223956: step 14703, loss 0.273461, acc 0.921875\n",
      "2018-05-04T18:13:23.276142: step 14704, loss 0.245161, acc 0.875\n",
      "2018-05-04T18:13:24.359516: step 14705, loss 0.217717, acc 0.90625\n",
      "2018-05-04T18:13:25.397719: step 14706, loss 0.38404, acc 0.8125\n",
      "2018-05-04T18:13:26.463474: step 14707, loss 0.20905, acc 0.9375\n",
      "2018-05-04T18:13:27.508175: step 14708, loss 0.152496, acc 0.953125\n",
      "2018-05-04T18:13:28.543855: step 14709, loss 0.231659, acc 0.90625\n",
      "2018-05-04T18:13:29.573610: step 14710, loss 0.183168, acc 0.890625\n",
      "2018-05-04T18:13:30.632212: step 14711, loss 0.233356, acc 0.90625\n",
      "2018-05-04T18:13:31.636722: step 14712, loss 0.219794, acc 0.90625\n",
      "2018-05-04T18:13:32.659172: step 14713, loss 0.246888, acc 0.890625\n",
      "2018-05-04T18:13:33.684507: step 14714, loss 0.188854, acc 0.953125\n",
      "2018-05-04T18:13:34.737431: step 14715, loss 0.33147, acc 0.859375\n",
      "2018-05-04T18:13:35.789811: step 14716, loss 0.239219, acc 0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T18:13:36.835274: step 14717, loss 0.293265, acc 0.890625\n",
      "2018-05-04T18:13:37.836982: step 14718, loss 0.437, acc 0.828125\n",
      "2018-05-04T18:13:38.829873: step 14719, loss 0.162572, acc 0.9375\n",
      "2018-05-04T18:13:39.857370: step 14720, loss 0.363638, acc 0.84375\n",
      "2018-05-04T18:13:40.874219: step 14721, loss 0.295718, acc 0.9375\n",
      "2018-05-04T18:13:41.876745: step 14722, loss 0.28129, acc 0.90625\n",
      "2018-05-04T18:13:42.892302: step 14723, loss 0.292712, acc 0.828125\n",
      "2018-05-04T18:13:43.918537: step 14724, loss 0.156394, acc 0.953125\n",
      "2018-05-04T18:13:44.961574: step 14725, loss 0.471299, acc 0.765625\n",
      "2018-05-04T18:13:45.959830: step 14726, loss 0.167025, acc 0.9375\n",
      "2018-05-04T18:13:46.937463: step 14727, loss 0.235958, acc 0.84375\n",
      "2018-05-04T18:13:47.954345: step 14728, loss 0.238726, acc 0.875\n",
      "2018-05-04T18:13:49.039112: step 14729, loss 0.168837, acc 0.921875\n",
      "2018-05-04T18:13:49.996524: step 14730, loss 0.313366, acc 0.890625\n",
      "2018-05-04T18:13:51.102724: step 14731, loss 0.298982, acc 0.828125\n",
      "2018-05-04T18:13:52.137663: step 14732, loss 0.301604, acc 0.859375\n",
      "2018-05-04T18:13:53.102087: step 14733, loss 0.27108, acc 0.90625\n",
      "2018-05-04T18:13:54.093344: step 14734, loss 0.412114, acc 0.890625\n",
      "2018-05-04T18:13:55.096454: step 14735, loss 0.224394, acc 0.921875\n",
      "2018-05-04T18:13:56.094708: step 14736, loss 0.205597, acc 0.953125\n",
      "2018-05-04T18:13:57.091410: step 14737, loss 0.413494, acc 0.828125\n",
      "2018-05-04T18:13:58.075515: step 14738, loss 0.174185, acc 0.921875\n",
      "2018-05-04T18:13:59.094004: step 14739, loss 0.360093, acc 0.84375\n",
      "2018-05-04T18:14:00.097204: step 14740, loss 0.274767, acc 0.859375\n",
      "2018-05-04T18:14:01.117481: step 14741, loss 0.255708, acc 0.90625\n",
      "2018-05-04T18:14:02.104172: step 14742, loss 0.320439, acc 0.875\n",
      "2018-05-04T18:14:03.096457: step 14743, loss 0.342542, acc 0.828125\n",
      "2018-05-04T18:14:04.094774: step 14744, loss 0.356883, acc 0.84375\n",
      "2018-05-04T18:14:05.059850: step 14745, loss 0.404511, acc 0.859375\n",
      "2018-05-04T18:14:06.050975: step 14746, loss 0.284919, acc 0.875\n",
      "2018-05-04T18:14:07.069609: step 14747, loss 0.289472, acc 0.859375\n",
      "2018-05-04T18:14:08.067125: step 14748, loss 0.167613, acc 0.921875\n",
      "2018-05-04T18:14:09.085593: step 14749, loss 0.346875, acc 0.828125\n",
      "2018-05-04T18:14:10.102622: step 14750, loss 0.325195, acc 0.84375\n",
      "2018-05-04T18:14:11.067879: step 14751, loss 0.337663, acc 0.890625\n",
      "2018-05-04T18:14:12.075556: step 14752, loss 0.379649, acc 0.828125\n",
      "2018-05-04T18:14:13.077054: step 14753, loss 0.367961, acc 0.890625\n",
      "2018-05-04T18:14:14.140847: step 14754, loss 0.40006, acc 0.84375\n",
      "2018-05-04T18:14:15.115852: step 14755, loss 0.334577, acc 0.859375\n",
      "2018-05-04T18:14:16.077851: step 14756, loss 0.240839, acc 0.921875\n",
      "2018-05-04T18:14:17.069068: step 14757, loss 0.199234, acc 0.9375\n",
      "2018-05-04T18:14:18.057063: step 14758, loss 0.225751, acc 0.921875\n",
      "2018-05-04T18:14:19.103640: step 14759, loss 0.252136, acc 0.875\n",
      "2018-05-04T18:14:20.061672: step 14760, loss 0.283191, acc 0.875\n",
      "2018-05-04T18:14:21.040016: step 14761, loss 0.154597, acc 0.96875\n",
      "2018-05-04T18:14:22.000819: step 14762, loss 0.356901, acc 0.859375\n",
      "2018-05-04T18:14:22.976781: step 14763, loss 0.280381, acc 0.890625\n",
      "2018-05-04T18:14:24.050181: step 14764, loss 0.204112, acc 0.953125\n",
      "2018-05-04T18:14:25.044927: step 14765, loss 0.287176, acc 0.890625\n",
      "2018-05-04T18:14:26.026012: step 14766, loss 0.242438, acc 0.875\n",
      "2018-05-04T18:14:27.014664: step 14767, loss 0.20665, acc 0.9375\n",
      "2018-05-04T18:14:27.986284: step 14768, loss 0.221158, acc 0.890625\n",
      "2018-05-04T18:14:28.955485: step 14769, loss 0.283228, acc 0.84375\n",
      "2018-05-04T18:14:29.954031: step 14770, loss 0.367202, acc 0.875\n",
      "2018-05-04T18:14:30.945342: step 14771, loss 0.387968, acc 0.84375\n",
      "2018-05-04T18:14:31.919520: step 14772, loss 0.307734, acc 0.875\n",
      "2018-05-04T18:14:32.940520: step 14773, loss 0.264553, acc 0.921875\n",
      "2018-05-04T18:14:33.927252: step 14774, loss 0.302146, acc 0.90625\n",
      "2018-05-04T18:14:34.956484: step 14775, loss 0.198303, acc 0.875\n",
      "2018-05-04T18:14:35.905413: step 14776, loss 0.324137, acc 0.84375\n",
      "2018-05-04T18:14:36.968901: step 14777, loss 0.393395, acc 0.84375\n",
      "2018-05-04T18:14:37.957380: step 14778, loss 0.26497, acc 0.859375\n",
      "2018-05-04T18:14:38.935894: step 14779, loss 0.254808, acc 0.875\n",
      "2018-05-04T18:14:39.924587: step 14780, loss 0.23733, acc 0.875\n",
      "2018-05-04T18:14:40.896926: step 14781, loss 0.206452, acc 0.921875\n",
      "2018-05-04T18:14:41.946357: step 14782, loss 0.283284, acc 0.875\n",
      "2018-05-04T18:14:42.884255: step 14783, loss 0.320151, acc 0.84375\n",
      "2018-05-04T18:14:43.843246: step 14784, loss 0.215583, acc 0.90625\n",
      "2018-05-04T18:14:44.825488: step 14785, loss 0.313021, acc 0.859375\n",
      "2018-05-04T18:14:45.800074: step 14786, loss 0.31625, acc 0.875\n",
      "2018-05-04T18:14:46.874373: step 14787, loss 0.250952, acc 0.90625\n",
      "2018-05-04T18:14:47.831688: step 14788, loss 0.342406, acc 0.828125\n",
      "2018-05-04T18:14:48.781373: step 14789, loss 0.261482, acc 0.875\n",
      "2018-05-04T18:14:49.747919: step 14790, loss 0.221833, acc 0.953125\n",
      "2018-05-04T18:14:50.787980: step 14791, loss 0.178512, acc 0.9375\n",
      "2018-05-04T18:14:51.770876: step 14792, loss 0.238672, acc 0.90625\n",
      "2018-05-04T18:14:52.775674: step 14793, loss 0.134118, acc 0.953125\n",
      "2018-05-04T18:14:53.759759: step 14794, loss 0.189842, acc 0.90625\n",
      "2018-05-04T18:14:54.802502: step 14795, loss 0.234022, acc 0.890625\n",
      "2018-05-04T18:14:55.780572: step 14796, loss 0.320891, acc 0.875\n",
      "2018-05-04T18:14:56.783207: step 14797, loss 0.325413, acc 0.890625\n",
      "2018-05-04T18:14:57.752929: step 14798, loss 0.266908, acc 0.90625\n",
      "2018-05-04T18:14:58.715761: step 14799, loss 0.277091, acc 0.875\n",
      "2018-05-04T18:14:59.692700: step 14800, loss 0.329543, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T18:15:02.126226: step 14800, loss 0.226132, acc 0.928\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-14800\n",
      "\n",
      "2018-05-04T18:15:03.365286: step 14801, loss 0.343376, acc 0.90625\n",
      "2018-05-04T18:15:04.402299: step 14802, loss 0.196906, acc 0.921875\n",
      "2018-05-04T18:15:05.453627: step 14803, loss 0.189985, acc 0.953125\n",
      "2018-05-04T18:15:06.460725: step 14804, loss 0.360902, acc 0.875\n",
      "2018-05-04T18:15:07.514858: step 14805, loss 0.204194, acc 0.90625\n",
      "2018-05-04T18:15:08.538073: step 14806, loss 0.224897, acc 0.90625\n",
      "2018-05-04T18:15:09.617656: step 14807, loss 0.361052, acc 0.84375\n",
      "2018-05-04T18:15:10.613003: step 14808, loss 0.337192, acc 0.875\n",
      "2018-05-04T18:15:11.605334: step 14809, loss 0.162162, acc 0.9375\n",
      "2018-05-04T18:15:12.666148: step 14810, loss 0.254092, acc 0.921875\n",
      "2018-05-04T18:15:13.746763: step 14811, loss 0.233882, acc 0.90625\n",
      "2018-05-04T18:15:14.724884: step 14812, loss 0.315689, acc 0.875\n",
      "2018-05-04T18:15:15.726527: step 14813, loss 0.254861, acc 0.890625\n",
      "2018-05-04T18:15:16.747826: step 14814, loss 0.327903, acc 0.875\n",
      "2018-05-04T18:15:17.822534: step 14815, loss 0.271458, acc 0.90625\n",
      "2018-05-04T18:15:18.855474: step 14816, loss 0.266702, acc 0.921875\n",
      "2018-05-04T18:15:19.928670: step 14817, loss 0.322899, acc 0.875\n",
      "2018-05-04T18:15:20.912202: step 14818, loss 0.20977, acc 0.921875\n",
      "2018-05-04T18:15:21.899989: step 14819, loss 0.249569, acc 0.859375\n",
      "2018-05-04T18:15:22.967950: step 14820, loss 0.176195, acc 0.9375\n",
      "2018-05-04T18:15:23.960351: step 14821, loss 0.21467, acc 0.90625\n",
      "2018-05-04T18:15:24.925073: step 14822, loss 0.236176, acc 0.921875\n",
      "2018-05-04T18:15:25.901769: step 14823, loss 0.214083, acc 0.90625\n",
      "2018-05-04T18:15:26.889323: step 14824, loss 0.2868, acc 0.890625\n",
      "2018-05-04T18:15:27.907806: step 14825, loss 0.290653, acc 0.890625\n",
      "2018-05-04T18:15:28.917847: step 14826, loss 0.526557, acc 0.828125\n",
      "2018-05-04T18:15:29.944387: step 14827, loss 0.352586, acc 0.828125\n",
      "2018-05-04T18:15:31.028695: step 14828, loss 0.283193, acc 0.859375\n",
      "2018-05-04T18:15:32.044850: step 14829, loss 0.298395, acc 0.859375\n",
      "2018-05-04T18:15:33.011796: step 14830, loss 0.17564, acc 0.9375\n",
      "2018-05-04T18:15:34.043599: step 14831, loss 0.294844, acc 0.859375\n",
      "2018-05-04T18:15:35.069799: step 14832, loss 0.259087, acc 0.90625\n",
      "2018-05-04T18:15:36.084988: step 14833, loss 0.179064, acc 0.921875\n",
      "2018-05-04T18:15:37.094654: step 14834, loss 0.188483, acc 0.90625\n",
      "2018-05-04T18:15:38.096815: step 14835, loss 0.207105, acc 0.90625\n",
      "2018-05-04T18:15:39.105359: step 14836, loss 0.208805, acc 0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T18:15:40.175546: step 14837, loss 0.249531, acc 0.90625\n",
      "2018-05-04T18:15:41.168787: step 14838, loss 0.412387, acc 0.8125\n",
      "2018-05-04T18:15:42.118768: step 14839, loss 0.292315, acc 0.890625\n",
      "2018-05-04T18:15:43.102222: step 14840, loss 0.347474, acc 0.859375\n",
      "2018-05-04T18:15:44.083577: step 14841, loss 0.387725, acc 0.78125\n",
      "2018-05-04T18:15:45.071114: step 14842, loss 0.267207, acc 0.875\n",
      "2018-05-04T18:15:46.088821: step 14843, loss 0.287562, acc 0.875\n",
      "2018-05-04T18:15:47.156449: step 14844, loss 0.216288, acc 0.953125\n",
      "2018-05-04T18:15:48.164972: step 14845, loss 0.281362, acc 0.90625\n",
      "2018-05-04T18:15:49.151047: step 14846, loss 0.265658, acc 0.859375\n",
      "2018-05-04T18:15:50.106610: step 14847, loss 0.237637, acc 0.90625\n",
      "2018-05-04T18:15:51.097641: step 14848, loss 0.384737, acc 0.84375\n",
      "2018-05-04T18:15:52.176251: step 14849, loss 0.138472, acc 0.9375\n",
      "2018-05-04T18:15:53.192333: step 14850, loss 0.146082, acc 0.953125\n",
      "2018-05-04T18:15:54.216091: step 14851, loss 0.14557, acc 0.96875\n",
      "2018-05-04T18:15:55.257492: step 14852, loss 0.278212, acc 0.875\n",
      "2018-05-04T18:15:56.221259: step 14853, loss 0.243734, acc 0.90625\n",
      "2018-05-04T18:15:57.173634: step 14854, loss 0.201248, acc 0.9375\n",
      "2018-05-04T18:15:58.119862: step 14855, loss 0.273652, acc 0.875\n",
      "2018-05-04T18:15:59.106336: step 14856, loss 0.207137, acc 0.890625\n",
      "2018-05-04T18:16:00.115887: step 14857, loss 0.246161, acc 0.921875\n",
      "2018-05-04T18:16:01.244845: step 14858, loss 0.296286, acc 0.875\n",
      "2018-05-04T18:16:02.226514: step 14859, loss 0.39447, acc 0.8125\n",
      "2018-05-04T18:16:03.222811: step 14860, loss 0.282776, acc 0.875\n",
      "2018-05-04T18:16:04.200016: step 14861, loss 0.25335, acc 0.90625\n",
      "2018-05-04T18:16:05.200326: step 14862, loss 0.28625, acc 0.890625\n",
      "2018-05-04T18:16:06.168275: step 14863, loss 0.340729, acc 0.875\n",
      "2018-05-04T18:16:07.139030: step 14864, loss 0.257622, acc 0.875\n",
      "2018-05-04T18:16:08.205725: step 14865, loss 0.234233, acc 0.84375\n",
      "2018-05-04T18:16:09.196197: step 14866, loss 0.279124, acc 0.859375\n",
      "2018-05-04T18:16:10.212571: step 14867, loss 0.237951, acc 0.90625\n",
      "2018-05-04T18:16:11.180791: step 14868, loss 0.362122, acc 0.84375\n",
      "2018-05-04T18:16:12.129385: step 14869, loss 0.240587, acc 0.90625\n",
      "2018-05-04T18:16:13.120447: step 14870, loss 0.321297, acc 0.875\n",
      "2018-05-04T18:16:14.115741: step 14871, loss 0.161654, acc 0.90625\n",
      "2018-05-04T18:16:15.150215: step 14872, loss 0.297494, acc 0.84375\n",
      "2018-05-04T18:16:16.138226: step 14873, loss 0.195481, acc 0.921875\n",
      "2018-05-04T18:16:17.149090: step 14874, loss 0.395406, acc 0.828125\n",
      "2018-05-04T18:16:18.129138: step 14875, loss 0.219836, acc 0.953125\n",
      "2018-05-04T18:16:19.145824: step 14876, loss 0.194202, acc 0.921875\n",
      "2018-05-04T18:16:20.117581: step 14877, loss 0.258271, acc 0.875\n",
      "2018-05-04T18:16:21.093069: step 14878, loss 0.220749, acc 0.90625\n",
      "2018-05-04T18:16:22.111431: step 14879, loss 0.208921, acc 0.90625\n",
      "2018-05-04T18:16:23.086046: step 14880, loss 0.333301, acc 0.8125\n",
      "2018-05-04T18:16:24.069380: step 14881, loss 0.269328, acc 0.890625\n",
      "2018-05-04T18:16:25.033882: step 14882, loss 0.280596, acc 0.890625\n",
      "2018-05-04T18:16:26.024193: step 14883, loss 0.360407, acc 0.84375\n",
      "2018-05-04T18:16:26.990658: step 14884, loss 0.279289, acc 0.90625\n",
      "2018-05-04T18:16:28.034283: step 14885, loss 0.194192, acc 0.921875\n",
      "2018-05-04T18:16:29.034987: step 14886, loss 0.243515, acc 0.921875\n",
      "2018-05-04T18:16:30.008533: step 14887, loss 0.340654, acc 0.8125\n",
      "2018-05-04T18:16:30.996631: step 14888, loss 0.259128, acc 0.90625\n",
      "2018-05-04T18:16:31.972591: step 14889, loss 0.224842, acc 0.890625\n",
      "2018-05-04T18:16:33.007990: step 14890, loss 0.226182, acc 0.890625\n",
      "2018-05-04T18:16:34.081307: step 14891, loss 0.287312, acc 0.875\n",
      "2018-05-04T18:16:35.197964: step 14892, loss 0.222341, acc 0.90625\n",
      "2018-05-04T18:16:36.243039: step 14893, loss 0.263747, acc 0.890625\n",
      "2018-05-04T18:16:37.270115: step 14894, loss 0.355439, acc 0.828125\n",
      "2018-05-04T18:16:38.245622: step 14895, loss 0.388109, acc 0.84375\n",
      "2018-05-04T18:16:39.205057: step 14896, loss 0.385663, acc 0.8125\n",
      "2018-05-04T18:16:40.187136: step 14897, loss 0.262321, acc 0.875\n",
      "2018-05-04T18:16:41.166915: step 14898, loss 0.351165, acc 0.90625\n",
      "2018-05-04T18:16:42.178891: step 14899, loss 0.206382, acc 0.90625\n",
      "2018-05-04T18:16:43.225438: step 14900, loss 0.252985, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T18:16:45.559036: step 14900, loss 0.226699, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-14900\n",
      "\n",
      "2018-05-04T18:16:46.676483: step 14901, loss 0.253231, acc 0.890625\n",
      "2018-05-04T18:16:47.717968: step 14902, loss 0.343746, acc 0.859375\n",
      "2018-05-04T18:16:48.804929: step 14903, loss 0.251804, acc 0.890625\n",
      "2018-05-04T18:16:49.836323: step 14904, loss 0.278523, acc 0.875\n",
      "2018-05-04T18:16:50.881086: step 14905, loss 0.179413, acc 0.921875\n",
      "2018-05-04T18:16:51.952983: step 14906, loss 0.160763, acc 0.953125\n",
      "2018-05-04T18:16:52.971401: step 14907, loss 0.262039, acc 0.9375\n",
      "2018-05-04T18:16:53.973840: step 14908, loss 0.246251, acc 0.953125\n",
      "2018-05-04T18:16:54.938252: step 14909, loss 0.252931, acc 0.875\n",
      "2018-05-04T18:16:56.024095: step 14910, loss 0.374904, acc 0.84375\n",
      "2018-05-04T18:16:57.109063: step 14911, loss 0.280185, acc 0.890625\n",
      "2018-05-04T18:16:58.111667: step 14912, loss 0.253699, acc 0.875\n",
      "2018-05-04T18:16:59.107925: step 14913, loss 0.290022, acc 0.890625\n",
      "2018-05-04T18:17:00.161864: step 14914, loss 0.33567, acc 0.859375\n",
      "2018-05-04T18:17:01.128974: step 14915, loss 0.2674, acc 0.859375\n",
      "2018-05-04T18:17:02.136267: step 14916, loss 0.294162, acc 0.890625\n",
      "2018-05-04T18:17:03.134187: step 14917, loss 0.282842, acc 0.875\n",
      "2018-05-04T18:17:04.147887: step 14918, loss 0.298704, acc 0.828125\n",
      "2018-05-04T18:17:05.211988: step 14919, loss 0.303047, acc 0.859375\n",
      "2018-05-04T18:17:06.238859: step 14920, loss 0.295434, acc 0.921875\n",
      "2018-05-04T18:17:07.340620: step 14921, loss 0.324344, acc 0.90625\n",
      "2018-05-04T18:17:08.337664: step 14922, loss 0.324575, acc 0.875\n",
      "2018-05-04T18:17:09.333843: step 14923, loss 0.246332, acc 0.859375\n",
      "2018-05-04T18:17:10.314439: step 14924, loss 0.202093, acc 0.921875\n",
      "2018-05-04T18:17:11.355450: step 14925, loss 0.358983, acc 0.859375\n",
      "2018-05-04T18:17:12.330401: step 14926, loss 0.197425, acc 0.921875\n",
      "2018-05-04T18:17:13.327939: step 14927, loss 0.219985, acc 0.90625\n",
      "2018-05-04T18:17:14.325233: step 14928, loss 0.337844, acc 0.859375\n",
      "2018-05-04T18:17:15.331176: step 14929, loss 0.200678, acc 0.921875\n",
      "2018-05-04T18:17:16.369750: step 14930, loss 0.172732, acc 0.953125\n",
      "2018-05-04T18:17:17.409882: step 14931, loss 0.152458, acc 0.9375\n",
      "2018-05-04T18:17:18.384997: step 14932, loss 0.213046, acc 0.953125\n",
      "2018-05-04T18:17:19.366065: step 14933, loss 0.321404, acc 0.84375\n",
      "2018-05-04T18:17:20.372667: step 14934, loss 0.118363, acc 0.96875\n",
      "2018-05-04T18:17:21.364603: step 14935, loss 0.278501, acc 0.875\n",
      "2018-05-04T18:17:22.399485: step 14936, loss 0.358884, acc 0.84375\n",
      "2018-05-04T18:17:23.403287: step 14937, loss 0.246468, acc 0.875\n",
      "2018-05-04T18:17:24.450836: step 14938, loss 0.197781, acc 0.90625\n",
      "2018-05-04T18:17:25.443129: step 14939, loss 0.245054, acc 0.875\n",
      "2018-05-04T18:17:26.434653: step 14940, loss 0.131301, acc 0.953125\n",
      "2018-05-04T18:17:27.435266: step 14941, loss 0.230274, acc 0.90625\n",
      "2018-05-04T18:17:28.418547: step 14942, loss 0.26182, acc 0.875\n",
      "2018-05-04T18:17:29.415732: step 14943, loss 0.306459, acc 0.890625\n",
      "2018-05-04T18:17:30.515856: step 14944, loss 0.267231, acc 0.859375\n",
      "2018-05-04T18:17:31.534492: step 14945, loss 0.128344, acc 0.984375\n",
      "2018-05-04T18:17:32.509770: step 14946, loss 0.303722, acc 0.84375\n",
      "2018-05-04T18:17:33.489516: step 14947, loss 0.211692, acc 0.921875\n",
      "2018-05-04T18:17:34.471267: step 14948, loss 0.288101, acc 0.875\n",
      "2018-05-04T18:17:35.533965: step 14949, loss 0.316667, acc 0.859375\n",
      "2018-05-04T18:17:36.574583: step 14950, loss 0.218585, acc 0.921875\n",
      "2018-05-04T18:17:37.565984: step 14951, loss 0.336921, acc 0.890625\n",
      "2018-05-04T18:17:38.581327: step 14952, loss 0.411649, acc 0.875\n",
      "2018-05-04T18:17:39.559749: step 14953, loss 0.261725, acc 0.890625\n",
      "2018-05-04T18:17:40.565723: step 14954, loss 0.285172, acc 0.875\n",
      "2018-05-04T18:17:41.578467: step 14955, loss 0.184069, acc 0.921875\n",
      "2018-05-04T18:17:42.602905: step 14956, loss 0.244401, acc 0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T18:17:43.665778: step 14957, loss 0.225273, acc 0.921875\n",
      "2018-05-04T18:17:44.624028: step 14958, loss 0.287437, acc 0.828125\n",
      "2018-05-04T18:17:45.587879: step 14959, loss 0.198659, acc 0.921875\n",
      "2018-05-04T18:17:46.581883: step 14960, loss 0.11836, acc 0.984375\n",
      "2018-05-04T18:17:47.574921: step 14961, loss 0.36173, acc 0.828125\n",
      "2018-05-04T18:17:48.582824: step 14962, loss 0.225569, acc 0.921875\n",
      "2018-05-04T18:17:49.562010: step 14963, loss 0.3811, acc 0.84375\n",
      "2018-05-04T18:17:50.554579: step 14964, loss 0.29178, acc 0.890625\n",
      "2018-05-04T18:17:51.594586: step 14965, loss 0.228976, acc 0.921875\n",
      "2018-05-04T18:17:52.574410: step 14966, loss 0.285864, acc 0.890625\n",
      "2018-05-04T18:17:53.528978: step 14967, loss 0.129875, acc 0.96875\n",
      "2018-05-04T18:17:54.487255: step 14968, loss 0.256677, acc 0.875\n",
      "2018-05-04T18:17:55.472036: step 14969, loss 0.216438, acc 0.890625\n",
      "2018-05-04T18:17:56.446604: step 14970, loss 0.256293, acc 0.875\n",
      "2018-05-04T18:17:57.427988: step 14971, loss 0.120066, acc 0.96875\n",
      "2018-05-04T18:17:58.411663: step 14972, loss 0.14116, acc 0.96875\n",
      "2018-05-04T18:17:59.400694: step 14973, loss 0.217627, acc 0.921875\n",
      "2018-05-04T18:18:00.383840: step 14974, loss 0.200519, acc 0.90625\n",
      "2018-05-04T18:18:01.378125: step 14975, loss 0.314193, acc 0.875\n",
      "2018-05-04T18:18:02.367725: step 14976, loss 0.200834, acc 0.921875\n",
      "2018-05-04T18:18:03.333094: step 14977, loss 0.246586, acc 0.875\n",
      "2018-05-04T18:18:04.329624: step 14978, loss 0.375302, acc 0.875\n",
      "2018-05-04T18:18:05.302390: step 14979, loss 0.253406, acc 0.890625\n",
      "2018-05-04T18:18:06.252292: step 14980, loss 0.178305, acc 0.921875\n",
      "2018-05-04T18:18:07.230818: step 14981, loss 0.32269, acc 0.890625\n",
      "2018-05-04T18:18:08.228892: step 14982, loss 0.22539, acc 0.90625\n",
      "2018-05-04T18:18:09.253776: step 14983, loss 0.25739, acc 0.921875\n",
      "2018-05-04T18:18:10.260648: step 14984, loss 0.30186, acc 0.84375\n",
      "2018-05-04T18:18:11.340797: step 14985, loss 0.151104, acc 0.953125\n",
      "2018-05-04T18:18:12.382763: step 14986, loss 0.350963, acc 0.84375\n",
      "2018-05-04T18:18:13.367439: step 14987, loss 0.323257, acc 0.890625\n",
      "2018-05-04T18:18:14.330725: step 14988, loss 0.257377, acc 0.90625\n",
      "2018-05-04T18:18:15.293170: step 14989, loss 0.215177, acc 0.921875\n",
      "2018-05-04T18:18:16.257380: step 14990, loss 0.235747, acc 0.9375\n",
      "2018-05-04T18:18:17.253965: step 14991, loss 0.301054, acc 0.859375\n",
      "2018-05-04T18:18:18.197992: step 14992, loss 0.292973, acc 0.890625\n",
      "2018-05-04T18:18:19.282754: step 14993, loss 0.35708, acc 0.84375\n",
      "2018-05-04T18:18:20.247513: step 14994, loss 0.220699, acc 0.890625\n",
      "2018-05-04T18:18:21.198159: step 14995, loss 0.180304, acc 0.96875\n",
      "2018-05-04T18:18:22.149169: step 14996, loss 0.2824, acc 0.875\n",
      "2018-05-04T18:18:23.126542: step 14997, loss 0.268201, acc 0.890625\n",
      "2018-05-04T18:18:24.115137: step 14998, loss 0.189025, acc 0.9375\n",
      "2018-05-04T18:18:25.076070: step 14999, loss 0.283156, acc 0.890625\n",
      "2018-05-04T18:18:26.062521: step 15000, loss 0.287479, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T18:18:28.556642: step 15000, loss 0.216786, acc 0.93\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-15000\n",
      "\n",
      "2018-05-04T18:18:29.659102: step 15001, loss 0.242961, acc 0.890625\n",
      "2018-05-04T18:18:30.708741: step 15002, loss 0.293255, acc 0.90625\n",
      "2018-05-04T18:18:31.777544: step 15003, loss 0.320129, acc 0.875\n",
      "2018-05-04T18:18:32.841393: step 15004, loss 0.395384, acc 0.78125\n",
      "2018-05-04T18:18:33.906477: step 15005, loss 0.245686, acc 0.90625\n",
      "2018-05-04T18:18:34.925316: step 15006, loss 0.328495, acc 0.84375\n",
      "2018-05-04T18:18:35.924107: step 15007, loss 0.255983, acc 0.921875\n",
      "2018-05-04T18:18:36.947218: step 15008, loss 0.305693, acc 0.90625\n",
      "2018-05-04T18:18:37.956400: step 15009, loss 0.249549, acc 0.890625\n",
      "2018-05-04T18:18:38.948739: step 15010, loss 0.233645, acc 0.921875\n",
      "2018-05-04T18:18:39.905094: step 15011, loss 0.370898, acc 0.859375\n",
      "2018-05-04T18:18:40.909191: step 15012, loss 0.349359, acc 0.84375\n",
      "2018-05-04T18:18:41.904947: step 15013, loss 0.173656, acc 0.953125\n",
      "2018-05-04T18:18:42.923560: step 15014, loss 0.292891, acc 0.875\n",
      "2018-05-04T18:18:43.916243: step 15015, loss 0.273357, acc 0.890625\n",
      "2018-05-04T18:18:44.921803: step 15016, loss 0.229263, acc 0.875\n",
      "2018-05-04T18:18:45.935936: step 15017, loss 0.221404, acc 0.90625\n",
      "2018-05-04T18:18:46.908665: step 15018, loss 0.288211, acc 0.84375\n",
      "2018-05-04T18:18:47.900612: step 15019, loss 0.151164, acc 0.9375\n",
      "2018-05-04T18:18:48.977078: step 15020, loss 0.19828, acc 0.9375\n",
      "2018-05-04T18:18:49.937776: step 15021, loss 0.36084, acc 0.8125\n",
      "2018-05-04T18:18:50.927067: step 15022, loss 0.25922, acc 0.875\n",
      "2018-05-04T18:18:51.936715: step 15023, loss 0.222064, acc 0.9375\n",
      "2018-05-04T18:18:52.958442: step 15024, loss 0.231534, acc 0.875\n",
      "2018-05-04T18:18:54.028026: step 15025, loss 0.365541, acc 0.75\n",
      "2018-05-04T18:18:55.014797: step 15026, loss 0.358244, acc 0.796875\n",
      "2018-05-04T18:18:56.028181: step 15027, loss 0.276794, acc 0.890625\n",
      "2018-05-04T18:18:57.086832: step 15028, loss 0.175324, acc 0.90625\n",
      "2018-05-04T18:18:58.084974: step 15029, loss 0.300821, acc 0.84375\n",
      "2018-05-04T18:18:59.061367: step 15030, loss 0.252929, acc 0.9375\n",
      "2018-05-04T18:19:00.038401: step 15031, loss 0.216977, acc 0.921875\n",
      "2018-05-04T18:19:01.029802: step 15032, loss 0.219262, acc 0.90625\n",
      "2018-05-04T18:19:02.117802: step 15033, loss 0.265937, acc 0.875\n",
      "2018-05-04T18:19:03.109559: step 15034, loss 0.310685, acc 0.890625\n",
      "2018-05-04T18:19:04.100516: step 15035, loss 0.301943, acc 0.859375\n",
      "2018-05-04T18:19:05.109069: step 15036, loss 0.251884, acc 0.90625\n",
      "2018-05-04T18:19:06.101623: step 15037, loss 0.172352, acc 0.921875\n",
      "2018-05-04T18:19:07.114603: step 15038, loss 0.304238, acc 0.84375\n",
      "2018-05-04T18:19:08.100664: step 15039, loss 0.250416, acc 0.859375\n",
      "2018-05-04T18:19:09.159186: step 15040, loss 0.26956, acc 0.921875\n",
      "2018-05-04T18:19:10.192132: step 15041, loss 0.269463, acc 0.84375\n",
      "2018-05-04T18:19:11.211119: step 15042, loss 0.255875, acc 0.90625\n",
      "2018-05-04T18:19:12.200873: step 15043, loss 0.386513, acc 0.796875\n",
      "2018-05-04T18:19:13.220840: step 15044, loss 0.240734, acc 0.875\n",
      "2018-05-04T18:19:14.216956: step 15045, loss 0.278171, acc 0.890625\n",
      "2018-05-04T18:19:15.230074: step 15046, loss 0.369975, acc 0.859375\n",
      "2018-05-04T18:19:16.316110: step 15047, loss 0.334014, acc 0.859375\n",
      "2018-05-04T18:19:17.360697: step 15048, loss 0.27463, acc 0.875\n",
      "2018-05-04T18:19:18.416757: step 15049, loss 0.188864, acc 0.953125\n",
      "2018-05-04T18:19:19.392539: step 15050, loss 0.313756, acc 0.84375\n",
      "2018-05-04T18:19:20.372128: step 15051, loss 0.180671, acc 0.921875\n",
      "2018-05-04T18:19:21.392666: step 15052, loss 0.329102, acc 0.828125\n",
      "2018-05-04T18:19:22.355407: step 15053, loss 0.288145, acc 0.84375\n",
      "2018-05-04T18:19:23.359277: step 15054, loss 0.313631, acc 0.859375\n",
      "2018-05-04T18:19:24.440277: step 15055, loss 0.313919, acc 0.90625\n",
      "2018-05-04T18:19:25.425329: step 15056, loss 0.245413, acc 0.921875\n",
      "2018-05-04T18:19:26.384352: step 15057, loss 0.320098, acc 0.859375\n",
      "2018-05-04T18:19:27.363684: step 15058, loss 0.289457, acc 0.90625\n",
      "2018-05-04T18:19:28.350475: step 15059, loss 0.114681, acc 0.984375\n",
      "2018-05-04T18:19:29.350636: step 15060, loss 0.288295, acc 0.921875\n",
      "2018-05-04T18:19:30.329579: step 15061, loss 0.200281, acc 0.921875\n",
      "2018-05-04T18:19:31.327399: step 15062, loss 0.351223, acc 0.84375\n",
      "2018-05-04T18:19:32.328819: step 15063, loss 0.280832, acc 0.890625\n",
      "2018-05-04T18:19:33.372622: step 15064, loss 0.363838, acc 0.875\n",
      "2018-05-04T18:19:34.410158: step 15065, loss 0.417875, acc 0.859375\n",
      "2018-05-04T18:19:35.489427: step 15066, loss 0.275356, acc 0.875\n",
      "2018-05-04T18:19:36.508935: step 15067, loss 0.394408, acc 0.890625\n",
      "2018-05-04T18:19:37.519281: step 15068, loss 0.309327, acc 0.875\n",
      "2018-05-04T18:19:38.520747: step 15069, loss 0.274777, acc 0.859375\n",
      "2018-05-04T18:19:39.519791: step 15070, loss 0.384142, acc 0.875\n",
      "2018-05-04T18:19:40.501682: step 15071, loss 0.257582, acc 0.859375\n",
      "2018-05-04T18:19:41.477010: step 15072, loss 0.14567, acc 0.953125\n",
      "2018-05-04T18:19:42.524422: step 15073, loss 0.280581, acc 0.90625\n",
      "2018-05-04T18:19:43.537206: step 15074, loss 0.472183, acc 0.765625\n",
      "2018-05-04T18:19:44.517520: step 15075, loss 0.317713, acc 0.8125\n",
      "2018-05-04T18:19:45.506553: step 15076, loss 0.324557, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T18:19:46.488551: step 15077, loss 0.197612, acc 0.9375\n",
      "2018-05-04T18:19:47.478653: step 15078, loss 0.353045, acc 0.8125\n",
      "2018-05-04T18:19:48.463336: step 15079, loss 0.307955, acc 0.890625\n",
      "2018-05-04T18:19:49.464182: step 15080, loss 0.214259, acc 0.9375\n",
      "2018-05-04T18:19:50.444761: step 15081, loss 0.216659, acc 0.9375\n",
      "2018-05-04T18:19:51.427447: step 15082, loss 0.313721, acc 0.890625\n",
      "2018-05-04T18:19:52.405298: step 15083, loss 0.337615, acc 0.875\n",
      "2018-05-04T18:19:53.385092: step 15084, loss 0.177929, acc 0.953125\n",
      "2018-05-04T18:19:54.374922: step 15085, loss 0.326069, acc 0.84375\n",
      "2018-05-04T18:19:55.395328: step 15086, loss 0.172314, acc 0.953125\n",
      "2018-05-04T18:19:56.371917: step 15087, loss 0.189317, acc 0.90625\n",
      "2018-05-04T18:19:57.356263: step 15088, loss 0.228093, acc 0.90625\n",
      "2018-05-04T18:19:58.331479: step 15089, loss 0.317691, acc 0.875\n",
      "2018-05-04T18:19:59.325875: step 15090, loss 0.21156, acc 0.890625\n",
      "2018-05-04T18:20:00.279713: step 15091, loss 0.266714, acc 0.90625\n",
      "2018-05-04T18:20:01.254181: step 15092, loss 0.215056, acc 0.9375\n",
      "2018-05-04T18:20:02.221758: step 15093, loss 0.174186, acc 0.921875\n",
      "2018-05-04T18:20:03.204885: step 15094, loss 0.274825, acc 0.90625\n",
      "2018-05-04T18:20:04.183169: step 15095, loss 0.348749, acc 0.875\n",
      "2018-05-04T18:20:05.138478: step 15096, loss 0.29908, acc 0.90625\n",
      "2018-05-04T18:20:06.117622: step 15097, loss 0.228998, acc 0.890625\n",
      "2018-05-04T18:20:07.094107: step 15098, loss 0.485522, acc 0.859375\n",
      "2018-05-04T18:20:08.071037: step 15099, loss 0.175285, acc 0.921875\n",
      "2018-05-04T18:20:09.046265: step 15100, loss 0.138404, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T18:20:11.620034: step 15100, loss 0.2277, acc 0.926\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-15100\n",
      "\n",
      "2018-05-04T18:20:12.696070: step 15101, loss 0.200805, acc 0.9375\n",
      "2018-05-04T18:20:13.726382: step 15102, loss 0.354894, acc 0.859375\n",
      "2018-05-04T18:20:14.720483: step 15103, loss 0.170253, acc 0.9375\n",
      "2018-05-04T18:20:15.778701: step 15104, loss 0.191492, acc 0.9375\n",
      "2018-05-04T18:20:16.839066: step 15105, loss 0.261688, acc 0.859375\n",
      "2018-05-04T18:20:17.890481: step 15106, loss 0.210646, acc 0.953125\n",
      "2018-05-04T18:20:18.936482: step 15107, loss 0.239868, acc 0.90625\n",
      "2018-05-04T18:20:19.945071: step 15108, loss 0.273255, acc 0.90625\n",
      "2018-05-04T18:20:20.991434: step 15109, loss 0.145491, acc 0.953125\n",
      "2018-05-04T18:20:22.012840: step 15110, loss 0.258, acc 0.921875\n",
      "2018-05-04T18:20:23.049972: step 15111, loss 0.345965, acc 0.828125\n",
      "2018-05-04T18:20:24.098846: step 15112, loss 0.379608, acc 0.875\n",
      "2018-05-04T18:20:25.062137: step 15113, loss 0.212717, acc 0.921875\n",
      "2018-05-04T18:20:26.045158: step 15114, loss 0.157071, acc 0.953125\n",
      "2018-05-04T18:20:27.042045: step 15115, loss 0.297852, acc 0.859375\n",
      "2018-05-04T18:20:28.078394: step 15116, loss 0.298008, acc 0.875\n",
      "2018-05-04T18:20:29.097893: step 15117, loss 0.277506, acc 0.90625\n",
      "2018-05-04T18:20:30.107597: step 15118, loss 0.340791, acc 0.84375\n",
      "2018-05-04T18:20:31.135980: step 15119, loss 0.442328, acc 0.84375\n",
      "2018-05-04T18:20:32.200706: step 15120, loss 0.244989, acc 0.90625\n",
      "2018-05-04T18:20:33.202665: step 15121, loss 0.337674, acc 0.828125\n",
      "2018-05-04T18:20:34.200088: step 15122, loss 0.354769, acc 0.828125\n",
      "2018-05-04T18:20:35.181468: step 15123, loss 0.280865, acc 0.90625\n",
      "2018-05-04T18:20:36.158321: step 15124, loss 0.246024, acc 0.890625\n",
      "2018-05-04T18:20:37.191225: step 15125, loss 0.402593, acc 0.875\n",
      "2018-05-04T18:20:38.280728: step 15126, loss 0.200846, acc 0.90625\n",
      "2018-05-04T18:20:39.399605: step 15127, loss 0.145553, acc 0.953125\n",
      "2018-05-04T18:20:40.383568: step 15128, loss 0.258815, acc 0.90625\n",
      "2018-05-04T18:20:41.356244: step 15129, loss 0.181155, acc 0.9375\n",
      "2018-05-04T18:20:42.365145: step 15130, loss 0.230806, acc 0.90625\n",
      "2018-05-04T18:20:43.456790: step 15131, loss 0.298533, acc 0.875\n",
      "2018-05-04T18:20:44.475154: step 15132, loss 0.420417, acc 0.796875\n",
      "2018-05-04T18:20:45.486397: step 15133, loss 0.235776, acc 0.890625\n",
      "2018-05-04T18:20:46.493197: step 15134, loss 0.316949, acc 0.890625\n",
      "2018-05-04T18:20:47.473396: step 15135, loss 0.435332, acc 0.890625\n",
      "2018-05-04T18:20:48.472572: step 15136, loss 0.23514, acc 0.90625\n",
      "2018-05-04T18:20:49.485362: step 15137, loss 0.223974, acc 0.890625\n",
      "2018-05-04T18:20:50.510789: step 15138, loss 0.216557, acc 0.890625\n",
      "2018-05-04T18:20:51.511948: step 15139, loss 0.401671, acc 0.8125\n",
      "2018-05-04T18:20:52.530522: step 15140, loss 0.306232, acc 0.90625\n",
      "2018-05-04T18:20:53.526751: step 15141, loss 0.298606, acc 0.890625\n",
      "2018-05-04T18:20:54.630827: step 15142, loss 0.372466, acc 0.84375\n",
      "2018-05-04T18:20:55.636145: step 15143, loss 0.146106, acc 0.953125\n",
      "2018-05-04T18:20:56.608506: step 15144, loss 0.221609, acc 0.875\n",
      "2018-05-04T18:20:57.583616: step 15145, loss 0.182168, acc 0.953125\n",
      "2018-05-04T18:20:58.593301: step 15146, loss 0.261539, acc 0.875\n",
      "2018-05-04T18:20:59.611141: step 15147, loss 0.246393, acc 0.90625\n",
      "2018-05-04T18:21:00.621719: step 15148, loss 0.302981, acc 0.859375\n",
      "2018-05-04T18:21:01.619365: step 15149, loss 0.305513, acc 0.90625\n",
      "2018-05-04T18:21:02.601496: step 15150, loss 0.276902, acc 0.875\n",
      "2018-05-04T18:21:03.603082: step 15151, loss 0.242489, acc 0.875\n",
      "2018-05-04T18:21:04.608636: step 15152, loss 0.178044, acc 0.921875\n",
      "2018-05-04T18:21:05.608680: step 15153, loss 0.35633, acc 0.859375\n",
      "2018-05-04T18:21:06.588847: step 15154, loss 0.237011, acc 0.859375\n",
      "2018-05-04T18:21:07.564500: step 15155, loss 0.286985, acc 0.875\n",
      "2018-05-04T18:21:08.549446: step 15156, loss 0.261018, acc 0.875\n",
      "2018-05-04T18:21:09.550190: step 15157, loss 0.153691, acc 0.953125\n",
      "2018-05-04T18:21:10.532912: step 15158, loss 0.293721, acc 0.890625\n",
      "2018-05-04T18:21:11.535936: step 15159, loss 0.297339, acc 0.890625\n",
      "2018-05-04T18:21:12.530855: step 15160, loss 0.183506, acc 0.890625\n",
      "2018-05-04T18:21:13.523418: step 15161, loss 0.303167, acc 0.890625\n",
      "2018-05-04T18:21:14.507405: step 15162, loss 0.268795, acc 0.90625\n",
      "2018-05-04T18:21:15.520254: step 15163, loss 0.336473, acc 0.890625\n",
      "2018-05-04T18:21:16.532190: step 15164, loss 0.260392, acc 0.84375\n",
      "2018-05-04T18:21:17.563988: step 15165, loss 0.331289, acc 0.8125\n",
      "2018-05-04T18:21:18.548641: step 15166, loss 0.38423, acc 0.84375\n",
      "2018-05-04T18:21:19.517479: step 15167, loss 0.230732, acc 0.890625\n",
      "2018-05-04T18:21:20.570407: step 15168, loss 0.302103, acc 0.875\n",
      "2018-05-04T18:21:21.625726: step 15169, loss 0.162476, acc 0.9375\n",
      "2018-05-04T18:21:22.655403: step 15170, loss 0.252428, acc 0.859375\n",
      "2018-05-04T18:21:23.633467: step 15171, loss 0.273075, acc 0.921875\n",
      "2018-05-04T18:21:24.614129: step 15172, loss 0.319586, acc 0.875\n",
      "2018-05-04T18:21:25.590847: step 15173, loss 0.158049, acc 0.953125\n",
      "2018-05-04T18:21:26.569242: step 15174, loss 0.314442, acc 0.84375\n",
      "2018-05-04T18:21:27.552191: step 15175, loss 0.23581, acc 0.90625\n",
      "2018-05-04T18:21:28.550506: step 15176, loss 0.284168, acc 0.890625\n",
      "2018-05-04T18:21:29.537530: step 15177, loss 0.274823, acc 0.90625\n",
      "2018-05-04T18:21:30.525774: step 15178, loss 0.187315, acc 0.921875\n",
      "2018-05-04T18:21:31.575786: step 15179, loss 0.299492, acc 0.859375\n",
      "2018-05-04T18:21:32.526175: step 15180, loss 0.458184, acc 0.78125\n",
      "2018-05-04T18:21:33.478180: step 15181, loss 0.238357, acc 0.9375\n",
      "2018-05-04T18:21:34.472857: step 15182, loss 0.372701, acc 0.875\n",
      "2018-05-04T18:21:35.455462: step 15183, loss 0.228821, acc 0.953125\n",
      "2018-05-04T18:21:36.442541: step 15184, loss 0.194804, acc 0.890625\n",
      "2018-05-04T18:21:37.440451: step 15185, loss 0.277385, acc 0.890625\n",
      "2018-05-04T18:21:38.405386: step 15186, loss 0.143545, acc 0.953125\n",
      "2018-05-04T18:21:39.376153: step 15187, loss 0.242249, acc 0.859375\n",
      "2018-05-04T18:21:40.442644: step 15188, loss 0.286921, acc 0.859375\n",
      "2018-05-04T18:21:41.399837: step 15189, loss 0.311436, acc 0.875\n",
      "2018-05-04T18:21:42.371292: step 15190, loss 0.260498, acc 0.90625\n",
      "2018-05-04T18:21:43.436918: step 15191, loss 0.365981, acc 0.890625\n",
      "2018-05-04T18:21:44.390119: step 15192, loss 0.442762, acc 0.8125\n",
      "2018-05-04T18:21:45.420289: step 15193, loss 0.385456, acc 0.84375\n",
      "2018-05-04T18:21:46.432130: step 15194, loss 0.457941, acc 0.8125\n",
      "2018-05-04T18:21:47.433795: step 15195, loss 0.221238, acc 0.921875\n",
      "2018-05-04T18:21:48.409381: step 15196, loss 0.187442, acc 0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T18:21:49.383583: step 15197, loss 0.377458, acc 0.890625\n",
      "2018-05-04T18:21:50.343056: step 15198, loss 0.403577, acc 0.828125\n",
      "2018-05-04T18:21:51.306704: step 15199, loss 0.314871, acc 0.859375\n",
      "2018-05-04T18:21:52.264558: step 15200, loss 0.363998, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T18:21:54.858610: step 15200, loss 0.227582, acc 0.918\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-15200\n",
      "\n",
      "2018-05-04T18:21:55.923586: step 15201, loss 0.417565, acc 0.828125\n",
      "2018-05-04T18:21:56.907831: step 15202, loss 0.330709, acc 0.828125\n",
      "2018-05-04T18:21:57.935410: step 15203, loss 0.296072, acc 0.828125\n",
      "2018-05-04T18:21:58.951237: step 15204, loss 0.276533, acc 0.890625\n",
      "2018-05-04T18:21:59.988258: step 15205, loss 0.263856, acc 0.921875\n",
      "2018-05-04T18:22:01.045700: step 15206, loss 0.147482, acc 0.984375\n",
      "2018-05-04T18:22:02.083392: step 15207, loss 0.360872, acc 0.875\n",
      "2018-05-04T18:22:03.187750: step 15208, loss 0.343047, acc 0.828125\n",
      "2018-05-04T18:22:04.259484: step 15209, loss 0.255517, acc 0.890625\n",
      "2018-05-04T18:22:05.280506: step 15210, loss 0.280418, acc 0.859375\n",
      "2018-05-04T18:22:06.292853: step 15211, loss 0.300725, acc 0.859375\n",
      "2018-05-04T18:22:07.281765: step 15212, loss 0.294569, acc 0.859375\n",
      "2018-05-04T18:22:08.284944: step 15213, loss 0.192207, acc 0.9375\n",
      "2018-05-04T18:22:09.260642: step 15214, loss 0.238725, acc 0.859375\n",
      "2018-05-04T18:22:10.269919: step 15215, loss 0.26965, acc 0.921875\n",
      "2018-05-04T18:22:11.258589: step 15216, loss 0.293106, acc 0.890625\n",
      "2018-05-04T18:22:12.244362: step 15217, loss 0.309024, acc 0.828125\n",
      "2018-05-04T18:22:13.316724: step 15218, loss 0.306429, acc 0.859375\n",
      "2018-05-04T18:22:14.302762: step 15219, loss 0.26373, acc 0.921875\n",
      "2018-05-04T18:22:15.257670: step 15220, loss 0.270737, acc 0.890625\n",
      "2018-05-04T18:22:16.251773: step 15221, loss 0.351361, acc 0.859375\n",
      "2018-05-04T18:22:17.277557: step 15222, loss 0.294648, acc 0.828125\n",
      "2018-05-04T18:22:18.238864: step 15223, loss 0.269129, acc 0.84375\n",
      "2018-05-04T18:22:19.212304: step 15224, loss 0.282818, acc 0.90625\n",
      "2018-05-04T18:22:20.230247: step 15225, loss 0.329419, acc 0.828125\n",
      "2018-05-04T18:22:21.230392: step 15226, loss 0.155974, acc 0.921875\n",
      "2018-05-04T18:22:22.195848: step 15227, loss 0.186669, acc 0.953125\n",
      "2018-05-04T18:22:23.148673: step 15228, loss 0.183881, acc 0.9375\n",
      "2018-05-04T18:22:24.159422: step 15229, loss 0.206972, acc 0.953125\n",
      "2018-05-04T18:22:25.169797: step 15230, loss 0.210656, acc 0.921875\n",
      "2018-05-04T18:22:26.220486: step 15231, loss 0.201994, acc 0.90625\n",
      "2018-05-04T18:22:27.239441: step 15232, loss 0.275421, acc 0.9375\n",
      "2018-05-04T18:22:28.222391: step 15233, loss 0.352836, acc 0.875\n",
      "2018-05-04T18:22:29.186631: step 15234, loss 0.305072, acc 0.921875\n",
      "2018-05-04T18:22:30.158679: step 15235, loss 0.254796, acc 0.9375\n",
      "2018-05-04T18:22:31.124990: step 15236, loss 0.352883, acc 0.796875\n",
      "2018-05-04T18:22:32.136129: step 15237, loss 0.286529, acc 0.875\n",
      "2018-05-04T18:22:33.190632: step 15238, loss 0.23596, acc 0.90625\n",
      "2018-05-04T18:22:34.238822: step 15239, loss 0.204129, acc 0.953125\n",
      "2018-05-04T18:22:35.283382: step 15240, loss 0.198277, acc 0.921875\n",
      "2018-05-04T18:22:36.320050: step 15241, loss 0.141285, acc 0.921875\n",
      "2018-05-04T18:22:37.384028: step 15242, loss 0.413481, acc 0.8125\n",
      "2018-05-04T18:22:38.393623: step 15243, loss 0.35327, acc 0.859375\n",
      "2018-05-04T18:22:39.418583: step 15244, loss 0.24166, acc 0.84375\n",
      "2018-05-04T18:22:40.431881: step 15245, loss 0.331131, acc 0.84375\n",
      "2018-05-04T18:22:41.419150: step 15246, loss 0.262774, acc 0.875\n",
      "2018-05-04T18:22:42.438702: step 15247, loss 0.277994, acc 0.828125\n",
      "2018-05-04T18:22:43.429551: step 15248, loss 0.247111, acc 0.9375\n",
      "2018-05-04T18:22:44.410296: step 15249, loss 0.214299, acc 0.9375\n",
      "2018-05-04T18:22:45.359551: step 15250, loss 0.313437, acc 0.84375\n",
      "2018-05-04T18:22:46.411222: step 15251, loss 0.263434, acc 0.828125\n",
      "2018-05-04T18:22:47.409746: step 15252, loss 0.289453, acc 0.875\n",
      "2018-05-04T18:22:48.489906: step 15253, loss 0.346238, acc 0.84375\n",
      "2018-05-04T18:22:49.473153: step 15254, loss 0.231396, acc 0.90625\n",
      "2018-05-04T18:22:50.431204: step 15255, loss 0.353941, acc 0.859375\n",
      "2018-05-04T18:22:51.441708: step 15256, loss 0.283897, acc 0.90625\n",
      "2018-05-04T18:22:52.443395: step 15257, loss 0.339408, acc 0.84375\n",
      "2018-05-04T18:22:53.439999: step 15258, loss 0.211567, acc 0.953125\n",
      "2018-05-04T18:22:54.460782: step 15259, loss 0.252235, acc 0.890625\n",
      "2018-05-04T18:22:55.460956: step 15260, loss 0.270678, acc 0.890625\n",
      "2018-05-04T18:22:56.485329: step 15261, loss 0.428802, acc 0.765625\n",
      "2018-05-04T18:22:57.449845: step 15262, loss 0.318892, acc 0.859375\n",
      "2018-05-04T18:22:58.424214: step 15263, loss 0.185805, acc 0.953125\n",
      "2018-05-04T18:22:59.413910: step 15264, loss 0.538715, acc 0.765625\n",
      "2018-05-04T18:23:00.394247: step 15265, loss 0.278175, acc 0.890625\n",
      "2018-05-04T18:23:01.364850: step 15266, loss 0.401817, acc 0.859375\n",
      "2018-05-04T18:23:02.347634: step 15267, loss 0.290874, acc 0.890625\n",
      "2018-05-04T18:23:03.336695: step 15268, loss 0.31447, acc 0.84375\n",
      "2018-05-04T18:23:04.333722: step 15269, loss 0.45258, acc 0.796875\n",
      "2018-05-04T18:23:05.387803: step 15270, loss 0.409109, acc 0.796875\n",
      "2018-05-04T18:23:06.414210: step 15271, loss 0.163739, acc 0.921875\n",
      "2018-05-04T18:23:07.363092: step 15272, loss 0.201172, acc 0.90625\n",
      "2018-05-04T18:23:08.311868: step 15273, loss 0.405044, acc 0.828125\n",
      "2018-05-04T18:23:09.295308: step 15274, loss 0.296954, acc 0.875\n",
      "2018-05-04T18:23:10.272646: step 15275, loss 0.348945, acc 0.828125\n",
      "2018-05-04T18:23:11.323178: step 15276, loss 0.349516, acc 0.859375\n",
      "2018-05-04T18:23:12.299351: step 15277, loss 0.444705, acc 0.828125\n",
      "2018-05-04T18:23:13.286366: step 15278, loss 0.254085, acc 0.90625\n",
      "2018-05-04T18:23:14.295363: step 15279, loss 0.324916, acc 0.84375\n",
      "2018-05-04T18:23:15.295053: step 15280, loss 0.279354, acc 0.890625\n",
      "2018-05-04T18:23:16.269759: step 15281, loss 0.323351, acc 0.875\n",
      "2018-05-04T18:23:17.351164: step 15282, loss 0.182835, acc 0.9375\n",
      "2018-05-04T18:23:18.276390: step 15283, loss 0.239842, acc 0.921875\n",
      "2018-05-04T18:23:19.271201: step 15284, loss 0.200005, acc 0.921875\n",
      "2018-05-04T18:23:20.235780: step 15285, loss 0.251866, acc 0.921875\n",
      "2018-05-04T18:23:21.224196: step 15286, loss 0.248201, acc 0.921875\n",
      "2018-05-04T18:23:22.192879: step 15287, loss 0.262932, acc 0.875\n",
      "2018-05-04T18:23:23.238996: step 15288, loss 0.140465, acc 0.984375\n",
      "2018-05-04T18:23:24.232627: step 15289, loss 0.21036, acc 0.921875\n",
      "2018-05-04T18:23:25.181260: step 15290, loss 0.230303, acc 0.921875\n",
      "2018-05-04T18:23:26.121057: step 15291, loss 0.213832, acc 0.90625\n",
      "2018-05-04T18:23:27.073434: step 15292, loss 0.188196, acc 0.90625\n",
      "2018-05-04T18:23:28.128475: step 15293, loss 0.228285, acc 0.90625\n",
      "2018-05-04T18:23:29.110145: step 15294, loss 0.231155, acc 0.890625\n",
      "2018-05-04T18:23:30.108867: step 15295, loss 0.258824, acc 0.875\n",
      "2018-05-04T18:23:31.202273: step 15296, loss 0.235034, acc 0.890625\n",
      "2018-05-04T18:23:32.201530: step 15297, loss 0.240184, acc 0.890625\n",
      "2018-05-04T18:23:33.152711: step 15298, loss 0.366127, acc 0.875\n",
      "2018-05-04T18:23:34.120507: step 15299, loss 0.191702, acc 0.9375\n",
      "2018-05-04T18:23:35.075955: step 15300, loss 0.302811, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T18:23:37.208793: step 15300, loss 0.211894, acc 0.934\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-15300\n",
      "\n",
      "2018-05-04T18:23:38.288706: step 15301, loss 0.173338, acc 0.953125\n",
      "2018-05-04T18:23:39.262170: step 15302, loss 0.245723, acc 0.890625\n",
      "2018-05-04T18:23:40.306323: step 15303, loss 0.278699, acc 0.875\n",
      "2018-05-04T18:23:41.271314: step 15304, loss 0.132746, acc 0.953125\n",
      "2018-05-04T18:23:42.247731: step 15305, loss 0.17623, acc 0.9375\n",
      "2018-05-04T18:23:43.195954: step 15306, loss 0.29043, acc 0.875\n",
      "2018-05-04T18:23:44.244280: step 15307, loss 0.187457, acc 0.921875\n",
      "2018-05-04T18:23:45.189009: step 15308, loss 0.29657, acc 0.875\n",
      "2018-05-04T18:23:46.144492: step 15309, loss 0.335355, acc 0.890625\n",
      "2018-05-04T18:23:47.121261: step 15310, loss 0.375439, acc 0.90625\n",
      "2018-05-04T18:23:48.087418: step 15311, loss 0.371582, acc 0.890625\n",
      "2018-05-04T18:23:49.119992: step 15312, loss 0.131936, acc 0.96875\n",
      "2018-05-04T18:23:50.080398: step 15313, loss 0.253196, acc 0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T18:23:51.059681: step 15314, loss 0.277099, acc 0.875\n",
      "2018-05-04T18:23:52.051334: step 15315, loss 0.166491, acc 0.921875\n",
      "2018-05-04T18:23:53.011367: step 15316, loss 0.247767, acc 0.90625\n",
      "2018-05-04T18:23:53.983923: step 15317, loss 0.264231, acc 0.890625\n",
      "2018-05-04T18:23:54.957153: step 15318, loss 0.232403, acc 0.921875\n",
      "2018-05-04T18:23:55.993867: step 15319, loss 0.366861, acc 0.890625\n",
      "2018-05-04T18:23:56.943911: step 15320, loss 0.450177, acc 0.828125\n",
      "2018-05-04T18:23:57.910031: step 15321, loss 0.272563, acc 0.84375\n",
      "2018-05-04T18:23:58.890593: step 15322, loss 0.384963, acc 0.890625\n",
      "2018-05-04T18:23:59.929714: step 15323, loss 0.474924, acc 0.859375\n",
      "2018-05-04T18:24:00.891345: step 15324, loss 0.241112, acc 0.921875\n",
      "2018-05-04T18:24:01.895308: step 15325, loss 0.328593, acc 0.78125\n",
      "2018-05-04T18:24:02.840267: step 15326, loss 0.085274, acc 0.984375\n",
      "2018-05-04T18:24:03.817797: step 15327, loss 0.430077, acc 0.796875\n",
      "2018-05-04T18:24:04.769216: step 15328, loss 0.165555, acc 0.9375\n",
      "2018-05-04T18:24:05.752255: step 15329, loss 0.241982, acc 0.90625\n",
      "2018-05-04T18:24:06.723475: step 15330, loss 0.34774, acc 0.8125\n",
      "2018-05-04T18:24:07.682293: step 15331, loss 0.256801, acc 0.9375\n",
      "2018-05-04T18:24:08.633897: step 15332, loss 0.284476, acc 0.84375\n",
      "2018-05-04T18:24:09.603028: step 15333, loss 0.410249, acc 0.859375\n",
      "2018-05-04T18:24:10.573816: step 15334, loss 0.325208, acc 0.796875\n",
      "2018-05-04T18:24:11.551159: step 15335, loss 0.242415, acc 0.921875\n",
      "2018-05-04T18:24:12.615899: step 15336, loss 0.27016, acc 0.875\n",
      "2018-05-04T18:24:13.574436: step 15337, loss 0.178748, acc 0.953125\n",
      "2018-05-04T18:24:14.535096: step 15338, loss 0.34242, acc 0.875\n",
      "2018-05-04T18:24:15.581889: step 15339, loss 0.313496, acc 0.90625\n",
      "2018-05-04T18:24:16.532705: step 15340, loss 0.357337, acc 0.828125\n",
      "2018-05-04T18:24:17.500820: step 15341, loss 0.30739, acc 0.890625\n",
      "2018-05-04T18:24:18.465375: step 15342, loss 0.303551, acc 0.875\n",
      "2018-05-04T18:24:19.432766: step 15343, loss 0.306689, acc 0.859375\n",
      "2018-05-04T18:24:20.405270: step 15344, loss 0.326468, acc 0.90625\n",
      "2018-05-04T18:24:21.410995: step 15345, loss 0.190053, acc 0.921875\n",
      "2018-05-04T18:24:22.369853: step 15346, loss 0.215259, acc 0.921875\n",
      "2018-05-04T18:24:23.362588: step 15347, loss 0.303986, acc 0.828125\n",
      "2018-05-04T18:24:24.324593: step 15348, loss 0.15771, acc 0.9375\n",
      "2018-05-04T18:24:25.295524: step 15349, loss 0.314703, acc 0.875\n",
      "2018-05-04T18:24:26.284754: step 15350, loss 0.256051, acc 0.875\n",
      "2018-05-04T18:24:27.256786: step 15351, loss 0.305201, acc 0.8125\n",
      "2018-05-04T18:24:28.215300: step 15352, loss 0.231387, acc 0.875\n",
      "2018-05-04T18:24:29.162864: step 15353, loss 0.321525, acc 0.875\n",
      "2018-05-04T18:24:30.109991: step 15354, loss 0.292392, acc 0.90625\n",
      "2018-05-04T18:24:31.074004: step 15355, loss 0.195739, acc 0.921875\n",
      "2018-05-04T18:24:32.060995: step 15356, loss 0.246322, acc 0.90625\n",
      "2018-05-04T18:24:33.065843: step 15357, loss 0.201598, acc 0.96875\n",
      "2018-05-04T18:24:34.024833: step 15358, loss 0.307415, acc 0.875\n",
      "2018-05-04T18:24:34.956356: step 15359, loss 0.176362, acc 0.9375\n",
      "2018-05-04T18:24:35.923587: step 15360, loss 0.369106, acc 0.875\n",
      "2018-05-04T18:24:36.881270: step 15361, loss 0.171472, acc 0.9375\n",
      "2018-05-04T18:24:37.834073: step 15362, loss 0.157238, acc 0.96875\n",
      "2018-05-04T18:24:38.797734: step 15363, loss 0.36868, acc 0.875\n",
      "2018-05-04T18:24:39.767371: step 15364, loss 0.28522, acc 0.890625\n",
      "2018-05-04T18:24:40.768726: step 15365, loss 0.447603, acc 0.828125\n",
      "2018-05-04T18:24:41.791348: step 15366, loss 0.229963, acc 0.9375\n",
      "2018-05-04T18:24:42.769218: step 15367, loss 0.3159, acc 0.890625\n",
      "2018-05-04T18:24:43.726185: step 15368, loss 0.340165, acc 0.875\n",
      "2018-05-04T18:24:44.689486: step 15369, loss 0.181587, acc 0.9375\n",
      "2018-05-04T18:24:45.654784: step 15370, loss 0.141501, acc 0.9375\n",
      "2018-05-04T18:24:46.611807: step 15371, loss 0.217768, acc 0.96875\n",
      "2018-05-04T18:24:47.573632: step 15372, loss 0.189443, acc 0.9375\n",
      "2018-05-04T18:24:48.589936: step 15373, loss 0.230873, acc 0.921875\n",
      "2018-05-04T18:24:49.550327: step 15374, loss 0.326081, acc 0.90625\n",
      "2018-05-04T18:24:50.499058: step 15375, loss 0.287388, acc 0.9375\n",
      "2018-05-04T18:24:51.448368: step 15376, loss 0.234096, acc 0.875\n",
      "2018-05-04T18:24:52.503348: step 15377, loss 0.241805, acc 0.90625\n",
      "2018-05-04T18:24:53.528701: step 15378, loss 0.33076, acc 0.875\n",
      "2018-05-04T18:24:54.565784: step 15379, loss 0.243203, acc 0.890625\n",
      "2018-05-04T18:24:55.489460: step 15380, loss 0.318818, acc 0.890625\n",
      "2018-05-04T18:24:56.409956: step 15381, loss 0.320392, acc 0.84375\n",
      "2018-05-04T18:24:57.356945: step 15382, loss 0.240383, acc 0.90625\n",
      "2018-05-04T18:24:58.381896: step 15383, loss 0.356727, acc 0.875\n",
      "2018-05-04T18:24:59.351834: step 15384, loss 0.186288, acc 0.921875\n",
      "2018-05-04T18:25:00.374670: step 15385, loss 0.221091, acc 0.890625\n",
      "2018-05-04T18:25:01.369431: step 15386, loss 0.291817, acc 0.921875\n",
      "2018-05-04T18:25:02.409841: step 15387, loss 0.267231, acc 0.890625\n",
      "2018-05-04T18:25:03.377419: step 15388, loss 0.299492, acc 0.84375\n",
      "2018-05-04T18:25:04.428746: step 15389, loss 0.394251, acc 0.828125\n",
      "2018-05-04T18:25:05.442848: step 15390, loss 0.286982, acc 0.828125\n",
      "2018-05-04T18:25:06.466802: step 15391, loss 0.388454, acc 0.859375\n",
      "2018-05-04T18:25:07.487529: step 15392, loss 0.240983, acc 0.90625\n",
      "2018-05-04T18:25:08.428072: step 15393, loss 0.183274, acc 0.90625\n",
      "2018-05-04T18:25:09.456944: step 15394, loss 0.236585, acc 0.90625\n",
      "2018-05-04T18:25:10.461804: step 15395, loss 0.236793, acc 0.890625\n",
      "2018-05-04T18:25:11.405248: step 15396, loss 0.23955, acc 0.90625\n",
      "2018-05-04T18:25:12.314087: step 15397, loss 0.18599, acc 0.921875\n",
      "2018-05-04T18:25:13.246783: step 15398, loss 0.290773, acc 0.90625\n",
      "2018-05-04T18:25:14.228218: step 15399, loss 0.271632, acc 0.875\n",
      "2018-05-04T18:25:15.255642: step 15400, loss 0.191822, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T18:25:17.841117: step 15400, loss 0.25181, acc 0.918\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-15400\n",
      "\n",
      "2018-05-04T18:25:18.920272: step 15401, loss 0.241342, acc 0.875\n",
      "2018-05-04T18:25:19.946661: step 15402, loss 0.312414, acc 0.875\n",
      "2018-05-04T18:25:20.956306: step 15403, loss 0.299635, acc 0.828125\n",
      "2018-05-04T18:25:22.028446: step 15404, loss 0.251717, acc 0.890625\n",
      "2018-05-04T18:25:23.060401: step 15405, loss 0.287743, acc 0.84375\n",
      "2018-05-04T18:25:24.107198: step 15406, loss 0.210452, acc 0.9375\n",
      "2018-05-04T18:25:25.175005: step 15407, loss 0.251226, acc 0.90625\n",
      "2018-05-04T18:25:26.246020: step 15408, loss 0.244427, acc 0.921875\n",
      "2018-05-04T18:25:27.259554: step 15409, loss 0.345294, acc 0.859375\n",
      "2018-05-04T18:25:28.291002: step 15410, loss 0.264712, acc 0.890625\n",
      "2018-05-04T18:25:29.261863: step 15411, loss 0.362223, acc 0.875\n",
      "2018-05-04T18:25:30.338766: step 15412, loss 0.238035, acc 0.875\n",
      "2018-05-04T18:25:31.320405: step 15413, loss 0.414558, acc 0.859375\n",
      "2018-05-04T18:25:32.321079: step 15414, loss 0.236169, acc 0.9375\n",
      "2018-05-04T18:25:33.358434: step 15415, loss 0.232539, acc 0.90625\n",
      "2018-05-04T18:25:34.405706: step 15416, loss 0.297714, acc 0.8125\n",
      "2018-05-04T18:25:35.472490: step 15417, loss 0.2397, acc 0.90625\n",
      "2018-05-04T18:25:36.549784: step 15418, loss 0.259366, acc 0.90625\n",
      "2018-05-04T18:25:37.562708: step 15419, loss 0.36099, acc 0.828125\n",
      "2018-05-04T18:25:38.569435: step 15420, loss 0.227877, acc 0.875\n",
      "2018-05-04T18:25:39.583083: step 15421, loss 0.224708, acc 0.90625\n",
      "2018-05-04T18:25:40.585726: step 15422, loss 0.344494, acc 0.84375\n",
      "2018-05-04T18:25:41.577499: step 15423, loss 0.2944, acc 0.84375\n",
      "2018-05-04T18:25:42.575422: step 15424, loss 0.259611, acc 0.859375\n",
      "2018-05-04T18:25:43.600860: step 15425, loss 0.170041, acc 0.953125\n",
      "2018-05-04T18:25:44.616892: step 15426, loss 0.252428, acc 0.90625\n",
      "2018-05-04T18:25:45.614718: step 15427, loss 0.23031, acc 0.921875\n",
      "2018-05-04T18:25:46.629384: step 15428, loss 0.264895, acc 0.921875\n",
      "2018-05-04T18:25:47.620971: step 15429, loss 0.286676, acc 0.875\n",
      "2018-05-04T18:25:48.599079: step 15430, loss 0.284738, acc 0.921875\n",
      "2018-05-04T18:25:49.596875: step 15431, loss 0.273357, acc 0.859375\n",
      "2018-05-04T18:25:50.596839: step 15432, loss 0.351979, acc 0.828125\n",
      "2018-05-04T18:25:51.636629: step 15433, loss 0.175464, acc 0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T18:25:52.630008: step 15434, loss 0.2426, acc 0.90625\n",
      "2018-05-04T18:25:53.653496: step 15435, loss 0.305871, acc 0.875\n",
      "2018-05-04T18:25:54.671137: step 15436, loss 0.243093, acc 0.875\n",
      "2018-05-04T18:25:55.670759: step 15437, loss 0.37079, acc 0.828125\n",
      "2018-05-04T18:25:56.665842: step 15438, loss 0.242575, acc 0.921875\n",
      "2018-05-04T18:25:57.655082: step 15439, loss 0.4397, acc 0.859375\n",
      "2018-05-04T18:25:58.645435: step 15440, loss 0.29759, acc 0.921875\n",
      "2018-05-04T18:25:59.609023: step 15441, loss 0.212658, acc 0.921875\n",
      "2018-05-04T18:26:00.609786: step 15442, loss 0.219744, acc 0.875\n",
      "2018-05-04T18:26:01.598095: step 15443, loss 0.273062, acc 0.828125\n",
      "2018-05-04T18:26:02.586835: step 15444, loss 0.22359, acc 0.9375\n",
      "2018-05-04T18:26:03.593091: step 15445, loss 0.291855, acc 0.875\n",
      "2018-05-04T18:26:04.609238: step 15446, loss 0.366125, acc 0.84375\n",
      "2018-05-04T18:26:05.601040: step 15447, loss 0.221076, acc 0.9375\n",
      "2018-05-04T18:26:06.616454: step 15448, loss 0.270065, acc 0.890625\n",
      "2018-05-04T18:26:07.622032: step 15449, loss 0.24967, acc 0.890625\n",
      "2018-05-04T18:26:08.675937: step 15450, loss 0.282074, acc 0.921875\n",
      "2018-05-04T18:26:09.729029: step 15451, loss 0.217426, acc 0.90625\n",
      "2018-05-04T18:26:10.755941: step 15452, loss 0.242531, acc 0.890625\n",
      "2018-05-04T18:26:11.791520: step 15453, loss 0.33864, acc 0.875\n",
      "2018-05-04T18:26:12.755969: step 15454, loss 0.268407, acc 0.890625\n",
      "2018-05-04T18:26:13.766183: step 15455, loss 0.260866, acc 0.890625\n",
      "2018-05-04T18:26:14.754927: step 15456, loss 0.269019, acc 0.859375\n",
      "2018-05-04T18:26:15.738295: step 15457, loss 0.291278, acc 0.859375\n",
      "2018-05-04T18:26:16.731778: step 15458, loss 0.291942, acc 0.890625\n",
      "2018-05-04T18:26:17.708477: step 15459, loss 0.236517, acc 0.90625\n",
      "2018-05-04T18:26:18.687740: step 15460, loss 0.407731, acc 0.765625\n",
      "2018-05-04T18:26:19.655689: step 15461, loss 0.300276, acc 0.90625\n",
      "2018-05-04T18:26:20.651343: step 15462, loss 0.278414, acc 0.890625\n",
      "2018-05-04T18:26:21.638769: step 15463, loss 0.229671, acc 0.90625\n",
      "2018-05-04T18:26:22.623654: step 15464, loss 0.311541, acc 0.890625\n",
      "2018-05-04T18:26:23.625444: step 15465, loss 0.294787, acc 0.859375\n",
      "2018-05-04T18:26:24.580895: step 15466, loss 0.27757, acc 0.875\n",
      "2018-05-04T18:26:25.590289: step 15467, loss 0.264489, acc 0.875\n",
      "2018-05-04T18:26:26.562852: step 15468, loss 0.215301, acc 0.9375\n",
      "2018-05-04T18:26:27.551452: step 15469, loss 0.166701, acc 0.9375\n",
      "2018-05-04T18:26:28.520777: step 15470, loss 0.23879, acc 0.921875\n",
      "2018-05-04T18:26:29.513498: step 15471, loss 0.254083, acc 0.9375\n",
      "2018-05-04T18:26:30.567860: step 15472, loss 0.214972, acc 0.90625\n",
      "2018-05-04T18:26:31.537232: step 15473, loss 0.238953, acc 0.921875\n",
      "2018-05-04T18:26:32.561420: step 15474, loss 0.33385, acc 0.859375\n",
      "2018-05-04T18:26:33.530976: step 15475, loss 0.229701, acc 0.9375\n",
      "2018-05-04T18:26:34.522835: step 15476, loss 0.25877, acc 0.90625\n",
      "2018-05-04T18:26:35.511589: step 15477, loss 0.415053, acc 0.859375\n",
      "2018-05-04T18:26:36.495225: step 15478, loss 0.169843, acc 0.9375\n",
      "2018-05-04T18:26:37.476508: step 15479, loss 0.305407, acc 0.875\n",
      "2018-05-04T18:26:38.480185: step 15480, loss 0.30614, acc 0.921875\n",
      "2018-05-04T18:26:39.490475: step 15481, loss 0.207931, acc 0.890625\n",
      "2018-05-04T18:26:40.441458: step 15482, loss 0.178085, acc 0.9375\n",
      "2018-05-04T18:26:41.399048: step 15483, loss 0.486347, acc 0.84375\n",
      "2018-05-04T18:26:42.440457: step 15484, loss 0.324834, acc 0.859375\n",
      "2018-05-04T18:26:43.456029: step 15485, loss 0.149615, acc 0.921875\n",
      "2018-05-04T18:26:44.542078: step 15486, loss 0.175598, acc 0.9375\n",
      "2018-05-04T18:26:45.601626: step 15487, loss 0.321412, acc 0.875\n",
      "2018-05-04T18:26:46.780046: step 15488, loss 0.381445, acc 0.828125\n",
      "2018-05-04T18:26:47.855700: step 15489, loss 0.267022, acc 0.9375\n",
      "2018-05-04T18:26:48.896666: step 15490, loss 0.280603, acc 0.953125\n",
      "2018-05-04T18:26:49.927364: step 15491, loss 0.281261, acc 0.875\n",
      "2018-05-04T18:26:50.947181: step 15492, loss 0.24017, acc 0.90625\n",
      "2018-05-04T18:26:52.003739: step 15493, loss 0.311722, acc 0.890625\n",
      "2018-05-04T18:26:53.145963: step 15494, loss 0.177872, acc 0.953125\n",
      "2018-05-04T18:26:54.233601: step 15495, loss 0.169326, acc 0.953125\n",
      "2018-05-04T18:26:55.387522: step 15496, loss 0.255457, acc 0.859375\n",
      "2018-05-04T18:26:56.551724: step 15497, loss 0.333514, acc 0.875\n",
      "2018-05-04T18:26:57.728252: step 15498, loss 0.33091, acc 0.859375\n",
      "2018-05-04T18:26:58.881444: step 15499, loss 0.255521, acc 0.859375\n",
      "2018-05-04T18:27:00.151269: step 15500, loss 0.163337, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T18:27:04.379259: step 15500, loss 0.217408, acc 0.932\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-15500\n",
      "\n",
      "2018-05-04T18:27:05.491160: step 15501, loss 0.197996, acc 0.90625\n",
      "2018-05-04T18:27:06.473705: step 15502, loss 0.216375, acc 0.875\n",
      "2018-05-04T18:27:07.467851: step 15503, loss 0.257845, acc 0.890625\n",
      "2018-05-04T18:27:08.492507: step 15504, loss 0.282393, acc 0.875\n",
      "2018-05-04T18:27:09.586161: step 15505, loss 0.255361, acc 0.90625\n",
      "2018-05-04T18:27:10.669384: step 15506, loss 0.431734, acc 0.8125\n",
      "2018-05-04T18:27:11.731930: step 15507, loss 0.119062, acc 0.9375\n",
      "2018-05-04T18:27:12.805992: step 15508, loss 0.225511, acc 0.921875\n",
      "2018-05-04T18:27:13.979988: step 15509, loss 0.28047, acc 0.875\n",
      "2018-05-04T18:27:15.060119: step 15510, loss 0.268276, acc 0.921875\n",
      "2018-05-04T18:27:16.105404: step 15511, loss 0.201373, acc 0.921875\n",
      "2018-05-04T18:27:17.163780: step 15512, loss 0.251804, acc 0.890625\n",
      "2018-05-04T18:27:18.131430: step 15513, loss 0.369584, acc 0.828125\n",
      "2018-05-04T18:27:19.143475: step 15514, loss 0.2608, acc 0.9375\n",
      "2018-05-04T18:27:20.158314: step 15515, loss 0.279503, acc 0.84375\n",
      "2018-05-04T18:27:21.181513: step 15516, loss 0.205294, acc 0.921875\n",
      "2018-05-04T18:27:22.219243: step 15517, loss 0.258837, acc 0.875\n",
      "2018-05-04T18:27:23.220554: step 15518, loss 0.180992, acc 0.953125\n",
      "2018-05-04T18:27:24.210945: step 15519, loss 0.175088, acc 0.96875\n",
      "2018-05-04T18:27:25.172109: step 15520, loss 0.309836, acc 0.875\n",
      "2018-05-04T18:27:26.155507: step 15521, loss 0.324054, acc 0.890625\n",
      "2018-05-04T18:27:27.154894: step 15522, loss 0.528593, acc 0.765625\n",
      "2018-05-04T18:27:28.148952: step 15523, loss 0.277224, acc 0.890625\n",
      "2018-05-04T18:27:29.159354: step 15524, loss 0.382887, acc 0.890625\n",
      "2018-05-04T18:27:30.169356: step 15525, loss 0.18027, acc 0.9375\n",
      "2018-05-04T18:27:31.151995: step 15526, loss 0.272124, acc 0.921875\n",
      "2018-05-04T18:27:32.137176: step 15527, loss 0.209244, acc 0.921875\n",
      "2018-05-04T18:27:33.127289: step 15528, loss 0.347797, acc 0.859375\n",
      "2018-05-04T18:27:34.119396: step 15529, loss 0.357844, acc 0.765625\n",
      "2018-05-04T18:27:35.162408: step 15530, loss 0.29523, acc 0.875\n",
      "2018-05-04T18:27:36.149753: step 15531, loss 0.155893, acc 0.9375\n",
      "2018-05-04T18:27:37.195777: step 15532, loss 0.175791, acc 0.921875\n",
      "2018-05-04T18:27:38.196911: step 15533, loss 0.177536, acc 0.921875\n",
      "2018-05-04T18:27:39.280875: step 15534, loss 0.266738, acc 0.875\n",
      "2018-05-04T18:27:40.272099: step 15535, loss 0.300209, acc 0.859375\n",
      "2018-05-04T18:27:41.287035: step 15536, loss 0.11472, acc 1\n",
      "2018-05-04T18:27:42.281585: step 15537, loss 0.171993, acc 0.921875\n",
      "2018-05-04T18:27:43.269590: step 15538, loss 0.398216, acc 0.75\n",
      "2018-05-04T18:27:44.271746: step 15539, loss 0.183025, acc 0.9375\n",
      "2018-05-04T18:27:45.347841: step 15540, loss 0.261295, acc 0.84375\n",
      "2018-05-04T18:27:46.334593: step 15541, loss 0.184838, acc 0.953125\n",
      "2018-05-04T18:27:47.321214: step 15542, loss 0.368309, acc 0.90625\n",
      "2018-05-04T18:27:48.295469: step 15543, loss 0.225222, acc 0.90625\n",
      "2018-05-04T18:27:49.294024: step 15544, loss 0.377035, acc 0.875\n",
      "2018-05-04T18:27:50.295489: step 15545, loss 0.264146, acc 0.828125\n",
      "2018-05-04T18:27:51.294208: step 15546, loss 0.2337, acc 0.90625\n",
      "2018-05-04T18:27:52.309946: step 15547, loss 0.39923, acc 0.859375\n",
      "2018-05-04T18:27:53.322047: step 15548, loss 0.330048, acc 0.84375\n",
      "2018-05-04T18:27:54.303802: step 15549, loss 0.293482, acc 0.859375\n",
      "2018-05-04T18:27:55.281891: step 15550, loss 0.260884, acc 0.9375\n",
      "2018-05-04T18:27:56.277841: step 15551, loss 0.141838, acc 0.96875\n",
      "2018-05-04T18:27:57.272463: step 15552, loss 0.286959, acc 0.859375\n",
      "2018-05-04T18:27:58.305288: step 15553, loss 0.422155, acc 0.84375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T18:27:59.286094: step 15554, loss 0.27997, acc 0.921875\n",
      "2018-05-04T18:28:00.268127: step 15555, loss 0.312162, acc 0.90625\n",
      "2018-05-04T18:28:01.288505: step 15556, loss 0.222521, acc 0.890625\n",
      "2018-05-04T18:28:02.322857: step 15557, loss 0.199341, acc 0.9375\n",
      "2018-05-04T18:28:03.333208: step 15558, loss 0.31067, acc 0.84375\n",
      "2018-05-04T18:28:04.340499: step 15559, loss 0.165048, acc 0.9375\n",
      "2018-05-04T18:28:05.316434: step 15560, loss 0.354941, acc 0.890625\n",
      "2018-05-04T18:28:06.301307: step 15561, loss 0.289658, acc 0.890625\n",
      "2018-05-04T18:28:07.305392: step 15562, loss 0.278448, acc 0.875\n",
      "2018-05-04T18:28:08.276761: step 15563, loss 0.38687, acc 0.84375\n",
      "2018-05-04T18:28:09.328515: step 15564, loss 0.405372, acc 0.828125\n",
      "2018-05-04T18:28:10.305241: step 15565, loss 0.167513, acc 0.96875\n",
      "2018-05-04T18:28:11.269417: step 15566, loss 0.16551, acc 0.953125\n",
      "2018-05-04T18:28:12.244310: step 15567, loss 0.186932, acc 0.9375\n",
      "2018-05-04T18:28:13.220132: step 15568, loss 0.355336, acc 0.828125\n",
      "2018-05-04T18:28:14.230211: step 15569, loss 0.227945, acc 0.875\n",
      "2018-05-04T18:28:15.207128: step 15570, loss 0.358289, acc 0.890625\n",
      "2018-05-04T18:28:16.174208: step 15571, loss 0.16416, acc 0.953125\n",
      "2018-05-04T18:28:17.161109: step 15572, loss 0.290806, acc 0.875\n",
      "2018-05-04T18:28:18.154864: step 15573, loss 0.389182, acc 0.796875\n",
      "2018-05-04T18:28:19.140316: step 15574, loss 0.209657, acc 0.90625\n",
      "2018-05-04T18:28:20.113501: step 15575, loss 0.220355, acc 0.90625\n",
      "2018-05-04T18:28:21.092053: step 15576, loss 0.285204, acc 0.90625\n",
      "2018-05-04T18:28:22.066983: step 15577, loss 0.168037, acc 0.9375\n",
      "2018-05-04T18:28:23.048295: step 15578, loss 0.271492, acc 0.875\n",
      "2018-05-04T18:28:24.030086: step 15579, loss 0.236, acc 0.90625\n",
      "2018-05-04T18:28:25.010367: step 15580, loss 0.226786, acc 0.890625\n",
      "2018-05-04T18:28:25.980833: step 15581, loss 0.336925, acc 0.875\n",
      "2018-05-04T18:28:27.003538: step 15582, loss 0.34699, acc 0.90625\n",
      "2018-05-04T18:28:27.987099: step 15583, loss 0.286293, acc 0.875\n",
      "2018-05-04T18:28:28.953301: step 15584, loss 0.321785, acc 0.859375\n",
      "2018-05-04T18:28:30.102270: step 15585, loss 0.322643, acc 0.859375\n",
      "2018-05-04T18:28:31.082072: step 15586, loss 0.427485, acc 0.84375\n",
      "2018-05-04T18:28:32.065845: step 15587, loss 0.18453, acc 0.953125\n",
      "2018-05-04T18:28:33.088920: step 15588, loss 0.168391, acc 0.96875\n",
      "2018-05-04T18:28:34.128504: step 15589, loss 0.255596, acc 0.90625\n",
      "2018-05-04T18:28:35.148664: step 15590, loss 0.22161, acc 0.90625\n",
      "2018-05-04T18:28:36.176153: step 15591, loss 0.29305, acc 0.875\n",
      "2018-05-04T18:28:37.186525: step 15592, loss 0.161138, acc 0.96875\n",
      "2018-05-04T18:28:38.170162: step 15593, loss 0.259652, acc 0.90625\n",
      "2018-05-04T18:28:39.137247: step 15594, loss 0.431157, acc 0.8125\n",
      "2018-05-04T18:28:40.096795: step 15595, loss 0.25491, acc 0.921875\n",
      "2018-05-04T18:28:41.073057: step 15596, loss 0.176747, acc 0.953125\n",
      "2018-05-04T18:28:42.125290: step 15597, loss 0.317155, acc 0.859375\n",
      "2018-05-04T18:28:43.102147: step 15598, loss 0.257445, acc 0.890625\n",
      "2018-05-04T18:28:44.085059: step 15599, loss 0.215312, acc 0.90625\n",
      "2018-05-04T18:28:45.054478: step 15600, loss 0.246259, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T18:28:47.155397: step 15600, loss 0.21582, acc 0.934\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-15600\n",
      "\n",
      "2018-05-04T18:28:48.194660: step 15601, loss 0.183141, acc 0.953125\n",
      "2018-05-04T18:28:49.167778: step 15602, loss 0.299332, acc 0.84375\n",
      "2018-05-04T18:28:50.277967: step 15603, loss 0.240394, acc 0.921875\n",
      "2018-05-04T18:28:51.288470: step 15604, loss 0.22035, acc 0.90625\n",
      "2018-05-04T18:28:52.221548: step 15605, loss 0.290865, acc 0.875\n",
      "2018-05-04T18:28:53.181976: step 15606, loss 0.146731, acc 0.953125\n",
      "2018-05-04T18:28:54.180347: step 15607, loss 0.363319, acc 0.875\n",
      "2018-05-04T18:28:55.190453: step 15608, loss 0.200101, acc 0.953125\n",
      "2018-05-04T18:28:56.165355: step 15609, loss 0.236436, acc 0.90625\n",
      "2018-05-04T18:28:57.136863: step 15610, loss 0.378398, acc 0.84375\n",
      "2018-05-04T18:28:58.118207: step 15611, loss 0.286371, acc 0.859375\n",
      "2018-05-04T18:28:59.079433: step 15612, loss 0.260177, acc 0.875\n",
      "2018-05-04T18:29:00.047619: step 15613, loss 0.294341, acc 0.828125\n",
      "2018-05-04T18:29:01.005194: step 15614, loss 0.314361, acc 0.84375\n",
      "2018-05-04T18:29:01.978942: step 15615, loss 0.294445, acc 0.828125\n",
      "2018-05-04T18:29:02.966031: step 15616, loss 0.164708, acc 0.921875\n",
      "2018-05-04T18:29:03.942289: step 15617, loss 0.332117, acc 0.828125\n",
      "2018-05-04T18:29:04.151038: step 15618, loss 0.0456773, acc 1\n",
      "2018-05-04T18:29:06.004848: step 15619, loss 0.232857, acc 0.859375\n",
      "2018-05-04T18:29:06.988792: step 15620, loss 0.160669, acc 0.953125\n",
      "2018-05-04T18:29:07.993206: step 15621, loss 0.318263, acc 0.84375\n",
      "2018-05-04T18:29:08.915274: step 15622, loss 0.291468, acc 0.890625\n",
      "2018-05-04T18:29:09.906794: step 15623, loss 0.222273, acc 0.9375\n",
      "2018-05-04T18:29:10.926093: step 15624, loss 0.285348, acc 0.875\n",
      "2018-05-04T18:29:11.908963: step 15625, loss 0.234188, acc 0.921875\n",
      "2018-05-04T18:29:12.912322: step 15626, loss 0.290236, acc 0.890625\n",
      "2018-05-04T18:29:13.930637: step 15627, loss 0.311345, acc 0.84375\n",
      "2018-05-04T18:29:14.858858: step 15628, loss 0.238329, acc 0.921875\n",
      "2018-05-04T18:29:15.865825: step 15629, loss 0.207713, acc 0.90625\n",
      "2018-05-04T18:29:16.845501: step 15630, loss 0.284919, acc 0.90625\n",
      "2018-05-04T18:29:17.884671: step 15631, loss 0.265191, acc 0.875\n",
      "2018-05-04T18:29:18.813648: step 15632, loss 0.228694, acc 0.90625\n",
      "2018-05-04T18:29:19.746829: step 15633, loss 0.279023, acc 0.90625\n",
      "2018-05-04T18:29:20.712136: step 15634, loss 0.247267, acc 0.890625\n",
      "2018-05-04T18:29:21.675168: step 15635, loss 0.194743, acc 0.90625\n",
      "2018-05-04T18:29:22.688755: step 15636, loss 0.255274, acc 0.890625\n",
      "2018-05-04T18:29:23.728135: step 15637, loss 0.265003, acc 0.921875\n",
      "2018-05-04T18:29:24.679784: step 15638, loss 0.279099, acc 0.90625\n",
      "2018-05-04T18:29:25.692879: step 15639, loss 0.264719, acc 0.890625\n",
      "2018-05-04T18:29:26.722911: step 15640, loss 0.17734, acc 0.9375\n",
      "2018-05-04T18:29:27.660128: step 15641, loss 0.347348, acc 0.84375\n",
      "2018-05-04T18:29:28.600571: step 15642, loss 0.235617, acc 0.890625\n",
      "2018-05-04T18:29:29.559212: step 15643, loss 0.19916, acc 0.921875\n",
      "2018-05-04T18:29:30.590705: step 15644, loss 0.303274, acc 0.90625\n",
      "2018-05-04T18:29:31.575903: step 15645, loss 0.43791, acc 0.859375\n",
      "2018-05-04T18:29:32.504553: step 15646, loss 0.146463, acc 0.953125\n",
      "2018-05-04T18:29:33.597329: step 15647, loss 0.192892, acc 0.921875\n",
      "2018-05-04T18:29:34.580069: step 15648, loss 0.298721, acc 0.875\n",
      "2018-05-04T18:29:35.595173: step 15649, loss 0.233702, acc 0.890625\n",
      "2018-05-04T18:29:36.624447: step 15650, loss 0.406663, acc 0.90625\n",
      "2018-05-04T18:29:37.648339: step 15651, loss 0.128605, acc 0.96875\n",
      "2018-05-04T18:29:38.635008: step 15652, loss 0.34829, acc 0.828125\n",
      "2018-05-04T18:29:39.699704: step 15653, loss 0.241419, acc 0.90625\n",
      "2018-05-04T18:29:40.625289: step 15654, loss 0.186999, acc 0.921875\n",
      "2018-05-04T18:29:41.555748: step 15655, loss 0.371628, acc 0.875\n",
      "2018-05-04T18:29:42.558044: step 15656, loss 0.268183, acc 0.875\n",
      "2018-05-04T18:29:43.532100: step 15657, loss 0.294782, acc 0.875\n",
      "2018-05-04T18:29:44.486097: step 15658, loss 0.333793, acc 0.828125\n",
      "2018-05-04T18:29:45.520355: step 15659, loss 0.203122, acc 0.921875\n",
      "2018-05-04T18:29:46.513956: step 15660, loss 0.274154, acc 0.875\n",
      "2018-05-04T18:29:47.529463: step 15661, loss 0.3054, acc 0.859375\n",
      "2018-05-04T18:29:48.533699: step 15662, loss 0.219431, acc 0.890625\n",
      "2018-05-04T18:29:49.571778: step 15663, loss 0.202375, acc 0.9375\n",
      "2018-05-04T18:29:50.591062: step 15664, loss 0.212755, acc 0.90625\n",
      "2018-05-04T18:29:51.596495: step 15665, loss 0.356238, acc 0.875\n",
      "2018-05-04T18:29:52.607097: step 15666, loss 0.249508, acc 0.953125\n",
      "2018-05-04T18:29:53.668133: step 15667, loss 0.260276, acc 0.875\n",
      "2018-05-04T18:29:54.590607: step 15668, loss 0.313205, acc 0.875\n",
      "2018-05-04T18:29:55.592840: step 15669, loss 0.429968, acc 0.84375\n",
      "2018-05-04T18:29:56.615821: step 15670, loss 0.27292, acc 0.921875\n",
      "2018-05-04T18:29:57.621376: step 15671, loss 0.273579, acc 0.875\n",
      "2018-05-04T18:29:58.639773: step 15672, loss 0.303549, acc 0.90625\n",
      "2018-05-04T18:29:59.580237: step 15673, loss 0.4437, acc 0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T18:30:00.596094: step 15674, loss 0.372333, acc 0.890625\n",
      "2018-05-04T18:30:01.620940: step 15675, loss 0.145648, acc 0.953125\n",
      "2018-05-04T18:30:02.664385: step 15676, loss 0.174265, acc 0.9375\n",
      "2018-05-04T18:30:03.669383: step 15677, loss 0.351804, acc 0.78125\n",
      "2018-05-04T18:30:04.583999: step 15678, loss 0.357122, acc 0.875\n",
      "2018-05-04T18:30:05.612896: step 15679, loss 0.354861, acc 0.828125\n",
      "2018-05-04T18:30:06.624761: step 15680, loss 0.258369, acc 0.921875\n",
      "2018-05-04T18:30:07.644548: step 15681, loss 0.371742, acc 0.84375\n",
      "2018-05-04T18:30:08.654121: step 15682, loss 0.215651, acc 0.921875\n",
      "2018-05-04T18:30:09.625295: step 15683, loss 0.341779, acc 0.828125\n",
      "2018-05-04T18:30:10.549222: step 15684, loss 0.275903, acc 0.875\n",
      "2018-05-04T18:30:11.586660: step 15685, loss 0.30326, acc 0.875\n",
      "2018-05-04T18:30:12.608954: step 15686, loss 0.281828, acc 0.890625\n",
      "2018-05-04T18:30:13.650715: step 15687, loss 0.262883, acc 0.859375\n",
      "2018-05-04T18:30:14.694448: step 15688, loss 0.215975, acc 0.90625\n",
      "2018-05-04T18:30:15.734075: step 15689, loss 0.203332, acc 0.90625\n",
      "2018-05-04T18:30:16.742981: step 15690, loss 0.333207, acc 0.875\n",
      "2018-05-04T18:30:17.748111: step 15691, loss 0.267091, acc 0.875\n",
      "2018-05-04T18:30:18.744851: step 15692, loss 0.422866, acc 0.84375\n",
      "2018-05-04T18:30:19.766644: step 15693, loss 0.269407, acc 0.828125\n",
      "2018-05-04T18:30:20.791757: step 15694, loss 0.172166, acc 0.9375\n",
      "2018-05-04T18:30:21.838339: step 15695, loss 0.285923, acc 0.890625\n",
      "2018-05-04T18:30:22.843336: step 15696, loss 0.302425, acc 0.859375\n",
      "2018-05-04T18:30:23.854984: step 15697, loss 0.173338, acc 0.90625\n",
      "2018-05-04T18:30:24.858010: step 15698, loss 0.254697, acc 0.90625\n",
      "2018-05-04T18:30:25.871363: step 15699, loss 0.256296, acc 0.90625\n",
      "2018-05-04T18:30:26.874966: step 15700, loss 0.333599, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T18:30:29.400049: step 15700, loss 0.241468, acc 0.914\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-15700\n",
      "\n",
      "2018-05-04T18:30:30.469799: step 15701, loss 0.430263, acc 0.8125\n",
      "2018-05-04T18:30:31.467825: step 15702, loss 0.162118, acc 0.953125\n",
      "2018-05-04T18:30:32.481795: step 15703, loss 0.128542, acc 0.96875\n",
      "2018-05-04T18:30:33.503156: step 15704, loss 0.540837, acc 0.828125\n",
      "2018-05-04T18:30:34.497490: step 15705, loss 0.199548, acc 0.9375\n",
      "2018-05-04T18:30:35.504380: step 15706, loss 0.316301, acc 0.875\n",
      "2018-05-04T18:30:36.516992: step 15707, loss 0.392061, acc 0.875\n",
      "2018-05-04T18:30:37.535121: step 15708, loss 0.421353, acc 0.828125\n",
      "2018-05-04T18:30:38.552706: step 15709, loss 0.327262, acc 0.875\n",
      "2018-05-04T18:30:39.568287: step 15710, loss 0.188543, acc 0.9375\n",
      "2018-05-04T18:30:40.594103: step 15711, loss 0.174906, acc 0.953125\n",
      "2018-05-04T18:30:41.577258: step 15712, loss 0.467722, acc 0.765625\n",
      "2018-05-04T18:30:42.603334: step 15713, loss 0.394877, acc 0.84375\n",
      "2018-05-04T18:30:43.607023: step 15714, loss 0.353785, acc 0.890625\n",
      "2018-05-04T18:30:44.594343: step 15715, loss 0.377986, acc 0.8125\n",
      "2018-05-04T18:30:45.572382: step 15716, loss 0.417885, acc 0.84375\n",
      "2018-05-04T18:30:46.558324: step 15717, loss 0.19866, acc 0.875\n",
      "2018-05-04T18:30:47.549601: step 15718, loss 0.275975, acc 0.828125\n",
      "2018-05-04T18:30:48.615483: step 15719, loss 0.281383, acc 0.875\n",
      "2018-05-04T18:30:49.603374: step 15720, loss 0.2754, acc 0.890625\n",
      "2018-05-04T18:30:50.574907: step 15721, loss 0.143041, acc 0.953125\n",
      "2018-05-04T18:30:51.553476: step 15722, loss 0.22393, acc 0.875\n",
      "2018-05-04T18:30:52.534109: step 15723, loss 0.1759, acc 0.9375\n",
      "2018-05-04T18:30:53.483329: step 15724, loss 0.287909, acc 0.859375\n",
      "2018-05-04T18:30:54.435846: step 15725, loss 0.34039, acc 0.828125\n",
      "2018-05-04T18:30:55.400267: step 15726, loss 0.269667, acc 0.84375\n",
      "2018-05-04T18:30:56.377975: step 15727, loss 0.333387, acc 0.875\n",
      "2018-05-04T18:30:57.364204: step 15728, loss 0.366474, acc 0.859375\n",
      "2018-05-04T18:30:58.416171: step 15729, loss 0.315413, acc 0.828125\n",
      "2018-05-04T18:30:59.379660: step 15730, loss 0.269792, acc 0.90625\n",
      "2018-05-04T18:31:00.306015: step 15731, loss 0.253985, acc 0.875\n",
      "2018-05-04T18:31:01.260748: step 15732, loss 0.226531, acc 0.9375\n",
      "2018-05-04T18:31:02.208892: step 15733, loss 0.169809, acc 0.9375\n",
      "2018-05-04T18:31:03.236660: step 15734, loss 0.217209, acc 0.90625\n",
      "2018-05-04T18:31:04.340511: step 15735, loss 0.235636, acc 0.921875\n",
      "2018-05-04T18:31:05.303015: step 15736, loss 0.192363, acc 0.890625\n",
      "2018-05-04T18:31:06.269712: step 15737, loss 0.269417, acc 0.875\n",
      "2018-05-04T18:31:07.233855: step 15738, loss 0.195724, acc 0.9375\n",
      "2018-05-04T18:31:08.212252: step 15739, loss 0.378999, acc 0.84375\n",
      "2018-05-04T18:31:09.246190: step 15740, loss 0.286234, acc 0.828125\n",
      "2018-05-04T18:31:10.210355: step 15741, loss 0.291442, acc 0.875\n",
      "2018-05-04T18:31:11.193925: step 15742, loss 0.331585, acc 0.84375\n",
      "2018-05-04T18:31:12.197199: step 15743, loss 0.231238, acc 0.9375\n",
      "2018-05-04T18:31:13.175079: step 15744, loss 0.269192, acc 0.890625\n",
      "2018-05-04T18:31:14.240869: step 15745, loss 0.203341, acc 0.921875\n",
      "2018-05-04T18:31:15.282295: step 15746, loss 0.24583, acc 0.875\n",
      "2018-05-04T18:31:16.239880: step 15747, loss 0.312201, acc 0.859375\n",
      "2018-05-04T18:31:17.225677: step 15748, loss 0.373418, acc 0.84375\n",
      "2018-05-04T18:31:18.194733: step 15749, loss 0.333536, acc 0.890625\n",
      "2018-05-04T18:31:19.181363: step 15750, loss 0.313758, acc 0.890625\n",
      "2018-05-04T18:31:20.174223: step 15751, loss 0.248524, acc 0.890625\n",
      "2018-05-04T18:31:21.152168: step 15752, loss 0.214498, acc 0.90625\n",
      "2018-05-04T18:31:22.126516: step 15753, loss 0.240281, acc 0.890625\n",
      "2018-05-04T18:31:23.110485: step 15754, loss 0.312416, acc 0.84375\n",
      "2018-05-04T18:31:24.142897: step 15755, loss 0.282977, acc 0.859375\n",
      "2018-05-04T18:31:25.218787: step 15756, loss 0.264548, acc 0.890625\n",
      "2018-05-04T18:31:26.178259: step 15757, loss 0.250149, acc 0.875\n",
      "2018-05-04T18:31:27.224465: step 15758, loss 0.30423, acc 0.859375\n",
      "2018-05-04T18:31:28.197552: step 15759, loss 0.333893, acc 0.828125\n",
      "2018-05-04T18:31:29.174084: step 15760, loss 0.35852, acc 0.859375\n",
      "2018-05-04T18:31:30.155031: step 15761, loss 0.265259, acc 0.90625\n",
      "2018-05-04T18:31:31.268964: step 15762, loss 0.215511, acc 0.90625\n",
      "2018-05-04T18:31:32.320174: step 15763, loss 0.236936, acc 0.921875\n",
      "2018-05-04T18:31:33.318400: step 15764, loss 0.280711, acc 0.9375\n",
      "2018-05-04T18:31:34.336542: step 15765, loss 0.306622, acc 0.859375\n",
      "2018-05-04T18:31:35.442451: step 15766, loss 0.331525, acc 0.84375\n",
      "2018-05-04T18:31:36.470120: step 15767, loss 0.278385, acc 0.9375\n",
      "2018-05-04T18:31:37.491675: step 15768, loss 0.174325, acc 0.9375\n",
      "2018-05-04T18:31:38.504455: step 15769, loss 0.301847, acc 0.90625\n",
      "2018-05-04T18:31:39.574976: step 15770, loss 0.183377, acc 0.90625\n",
      "2018-05-04T18:31:40.555786: step 15771, loss 0.244184, acc 0.875\n",
      "2018-05-04T18:31:41.538708: step 15772, loss 0.252887, acc 0.90625\n",
      "2018-05-04T18:31:42.528161: step 15773, loss 0.236705, acc 0.953125\n",
      "2018-05-04T18:31:43.507905: step 15774, loss 0.330782, acc 0.828125\n",
      "2018-05-04T18:31:44.547406: step 15775, loss 0.334109, acc 0.84375\n",
      "2018-05-04T18:31:45.500759: step 15776, loss 0.130938, acc 0.953125\n",
      "2018-05-04T18:31:46.448392: step 15777, loss 0.310343, acc 0.90625\n",
      "2018-05-04T18:31:47.407091: step 15778, loss 0.358431, acc 0.859375\n",
      "2018-05-04T18:31:48.372583: step 15779, loss 0.224359, acc 0.921875\n",
      "2018-05-04T18:31:49.380951: step 15780, loss 0.247166, acc 0.875\n",
      "2018-05-04T18:31:50.366845: step 15781, loss 0.195009, acc 0.9375\n",
      "2018-05-04T18:31:51.327632: step 15782, loss 0.193047, acc 0.90625\n",
      "2018-05-04T18:31:52.301325: step 15783, loss 0.344269, acc 0.875\n",
      "2018-05-04T18:31:53.263585: step 15784, loss 0.259969, acc 0.90625\n",
      "2018-05-04T18:31:54.228336: step 15785, loss 0.229592, acc 0.859375\n",
      "2018-05-04T18:31:55.191943: step 15786, loss 0.298457, acc 0.859375\n",
      "2018-05-04T18:31:56.155963: step 15787, loss 0.297148, acc 0.875\n",
      "2018-05-04T18:31:57.134838: step 15788, loss 0.205813, acc 0.9375\n",
      "2018-05-04T18:31:58.104705: step 15789, loss 0.212275, acc 0.90625\n",
      "2018-05-04T18:31:59.074528: step 15790, loss 0.243606, acc 0.90625\n",
      "2018-05-04T18:32:00.056080: step 15791, loss 0.473661, acc 0.796875\n",
      "2018-05-04T18:32:01.023506: step 15792, loss 0.252422, acc 0.890625\n",
      "2018-05-04T18:32:01.976078: step 15793, loss 0.288592, acc 0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T18:32:02.943701: step 15794, loss 0.306671, acc 0.859375\n",
      "2018-05-04T18:32:03.919439: step 15795, loss 0.262988, acc 0.921875\n",
      "2018-05-04T18:32:04.906221: step 15796, loss 0.219593, acc 0.921875\n",
      "2018-05-04T18:32:05.880821: step 15797, loss 0.255785, acc 0.890625\n",
      "2018-05-04T18:32:06.881912: step 15798, loss 0.280853, acc 0.9375\n",
      "2018-05-04T18:32:07.852870: step 15799, loss 0.449578, acc 0.875\n",
      "2018-05-04T18:32:08.823673: step 15800, loss 0.21666, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T18:32:11.114841: step 15800, loss 0.230821, acc 0.928\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-15800\n",
      "\n",
      "2018-05-04T18:32:12.205097: step 15801, loss 0.263816, acc 0.890625\n",
      "2018-05-04T18:32:13.220749: step 15802, loss 0.383239, acc 0.84375\n",
      "2018-05-04T18:32:14.237338: step 15803, loss 0.270884, acc 0.921875\n",
      "2018-05-04T18:32:15.256433: step 15804, loss 0.320469, acc 0.859375\n",
      "2018-05-04T18:32:16.270013: step 15805, loss 0.233758, acc 0.921875\n",
      "2018-05-04T18:32:17.286742: step 15806, loss 0.309986, acc 0.875\n",
      "2018-05-04T18:32:18.295995: step 15807, loss 0.215771, acc 0.9375\n",
      "2018-05-04T18:32:19.295362: step 15808, loss 0.206791, acc 0.875\n",
      "2018-05-04T18:32:20.257417: step 15809, loss 0.324589, acc 0.875\n",
      "2018-05-04T18:32:21.235842: step 15810, loss 0.303661, acc 0.84375\n",
      "2018-05-04T18:32:22.193747: step 15811, loss 0.301843, acc 0.890625\n",
      "2018-05-04T18:32:23.148012: step 15812, loss 0.141497, acc 0.96875\n",
      "2018-05-04T18:32:24.107864: step 15813, loss 0.207366, acc 0.90625\n",
      "2018-05-04T18:32:25.072286: step 15814, loss 0.24041, acc 0.90625\n",
      "2018-05-04T18:32:26.049718: step 15815, loss 0.291642, acc 0.921875\n",
      "2018-05-04T18:32:27.061567: step 15816, loss 0.206146, acc 0.90625\n",
      "2018-05-04T18:32:28.071483: step 15817, loss 0.238206, acc 0.953125\n",
      "2018-05-04T18:32:29.047458: step 15818, loss 0.196941, acc 0.9375\n",
      "2018-05-04T18:32:30.088551: step 15819, loss 0.265087, acc 0.875\n",
      "2018-05-04T18:32:31.143709: step 15820, loss 0.229795, acc 0.890625\n",
      "2018-05-04T18:32:32.187849: step 15821, loss 0.181703, acc 0.921875\n",
      "2018-05-04T18:32:33.225557: step 15822, loss 0.325611, acc 0.890625\n",
      "2018-05-04T18:32:34.165233: step 15823, loss 0.305994, acc 0.859375\n",
      "2018-05-04T18:32:35.101650: step 15824, loss 0.265831, acc 0.90625\n",
      "2018-05-04T18:32:36.071181: step 15825, loss 0.32358, acc 0.84375\n",
      "2018-05-04T18:32:37.004219: step 15826, loss 0.227036, acc 0.90625\n",
      "2018-05-04T18:32:38.058963: step 15827, loss 0.223253, acc 0.921875\n",
      "2018-05-04T18:32:39.060005: step 15828, loss 0.298146, acc 0.828125\n",
      "2018-05-04T18:32:40.109920: step 15829, loss 0.479359, acc 0.84375\n",
      "2018-05-04T18:32:41.201079: step 15830, loss 0.211748, acc 0.90625\n",
      "2018-05-04T18:32:42.154734: step 15831, loss 0.393648, acc 0.859375\n",
      "2018-05-04T18:32:43.118536: step 15832, loss 0.349364, acc 0.84375\n",
      "2018-05-04T18:32:44.146013: step 15833, loss 0.209087, acc 0.9375\n",
      "2018-05-04T18:32:45.078405: step 15834, loss 0.28953, acc 0.84375\n",
      "2018-05-04T18:32:46.035079: step 15835, loss 0.337189, acc 0.859375\n",
      "2018-05-04T18:32:46.984481: step 15836, loss 0.249659, acc 0.890625\n",
      "2018-05-04T18:32:47.945408: step 15837, loss 0.218333, acc 0.9375\n",
      "2018-05-04T18:32:48.917531: step 15838, loss 0.308387, acc 0.875\n",
      "2018-05-04T18:32:49.954866: step 15839, loss 0.0929294, acc 1\n",
      "2018-05-04T18:32:51.012591: step 15840, loss 0.289445, acc 0.875\n",
      "2018-05-04T18:32:51.970639: step 15841, loss 0.336712, acc 0.859375\n",
      "2018-05-04T18:32:52.969625: step 15842, loss 0.27776, acc 0.90625\n",
      "2018-05-04T18:32:53.936418: step 15843, loss 0.149844, acc 0.9375\n",
      "2018-05-04T18:32:55.010185: step 15844, loss 0.289663, acc 0.890625\n",
      "2018-05-04T18:32:55.975177: step 15845, loss 0.294665, acc 0.90625\n",
      "2018-05-04T18:32:56.940135: step 15846, loss 0.259823, acc 0.9375\n",
      "2018-05-04T18:32:57.906847: step 15847, loss 0.165669, acc 0.921875\n",
      "2018-05-04T18:32:58.867552: step 15848, loss 0.310354, acc 0.890625\n",
      "2018-05-04T18:32:59.820726: step 15849, loss 0.150186, acc 0.953125\n",
      "2018-05-04T18:33:00.820307: step 15850, loss 0.276335, acc 0.875\n",
      "2018-05-04T18:33:01.798212: step 15851, loss 0.149837, acc 0.9375\n",
      "2018-05-04T18:33:02.769343: step 15852, loss 0.153338, acc 0.9375\n",
      "2018-05-04T18:33:03.753084: step 15853, loss 0.211831, acc 0.90625\n",
      "2018-05-04T18:33:04.814998: step 15854, loss 0.254717, acc 0.890625\n",
      "2018-05-04T18:33:05.785363: step 15855, loss 0.282039, acc 0.890625\n",
      "2018-05-04T18:33:06.783411: step 15856, loss 0.26246, acc 0.875\n",
      "2018-05-04T18:33:07.748567: step 15857, loss 0.207106, acc 0.90625\n",
      "2018-05-04T18:33:08.785676: step 15858, loss 0.101712, acc 0.984375\n",
      "2018-05-04T18:33:09.861850: step 15859, loss 0.418516, acc 0.796875\n",
      "2018-05-04T18:33:10.840782: step 15860, loss 0.328759, acc 0.84375\n",
      "2018-05-04T18:33:11.934202: step 15861, loss 0.154786, acc 0.953125\n",
      "2018-05-04T18:33:12.929955: step 15862, loss 0.305248, acc 0.859375\n",
      "2018-05-04T18:33:13.898675: step 15863, loss 0.305742, acc 0.828125\n",
      "2018-05-04T18:33:14.852205: step 15864, loss 0.275721, acc 0.875\n",
      "2018-05-04T18:33:15.818800: step 15865, loss 0.113956, acc 0.96875\n",
      "2018-05-04T18:33:16.810131: step 15866, loss 0.364764, acc 0.859375\n",
      "2018-05-04T18:33:17.805993: step 15867, loss 0.338901, acc 0.875\n",
      "2018-05-04T18:33:18.795417: step 15868, loss 0.257602, acc 0.90625\n",
      "2018-05-04T18:33:19.767812: step 15869, loss 0.328798, acc 0.859375\n",
      "2018-05-04T18:33:20.752881: step 15870, loss 0.134287, acc 0.96875\n",
      "2018-05-04T18:33:21.745154: step 15871, loss 0.287604, acc 0.890625\n",
      "2018-05-04T18:33:22.715603: step 15872, loss 0.185421, acc 0.953125\n",
      "2018-05-04T18:33:23.684136: step 15873, loss 0.252089, acc 0.90625\n",
      "2018-05-04T18:33:24.695300: step 15874, loss 0.333494, acc 0.828125\n",
      "2018-05-04T18:33:25.692519: step 15875, loss 0.291175, acc 0.859375\n",
      "2018-05-04T18:33:26.682972: step 15876, loss 0.156547, acc 0.984375\n",
      "2018-05-04T18:33:27.677127: step 15877, loss 0.214252, acc 0.90625\n",
      "2018-05-04T18:33:28.673088: step 15878, loss 0.26263, acc 0.953125\n",
      "2018-05-04T18:33:29.626914: step 15879, loss 0.238074, acc 0.890625\n",
      "2018-05-04T18:33:30.594145: step 15880, loss 0.123659, acc 0.953125\n",
      "2018-05-04T18:33:31.620741: step 15881, loss 0.221347, acc 0.890625\n",
      "2018-05-04T18:33:32.611826: step 15882, loss 0.348098, acc 0.890625\n",
      "2018-05-04T18:33:33.572951: step 15883, loss 0.254407, acc 0.875\n",
      "2018-05-04T18:33:34.546582: step 15884, loss 0.224513, acc 0.90625\n",
      "2018-05-04T18:33:35.512626: step 15885, loss 0.259692, acc 0.875\n",
      "2018-05-04T18:33:36.492544: step 15886, loss 0.242174, acc 0.890625\n",
      "2018-05-04T18:33:37.451852: step 15887, loss 0.231311, acc 0.953125\n",
      "2018-05-04T18:33:38.406341: step 15888, loss 0.432009, acc 0.828125\n",
      "2018-05-04T18:33:39.387405: step 15889, loss 0.295195, acc 0.90625\n",
      "2018-05-04T18:33:40.407537: step 15890, loss 0.351998, acc 0.90625\n",
      "2018-05-04T18:33:41.418265: step 15891, loss 0.236981, acc 0.921875\n",
      "2018-05-04T18:33:42.384921: step 15892, loss 0.2762, acc 0.890625\n",
      "2018-05-04T18:33:43.369834: step 15893, loss 0.155017, acc 0.984375\n",
      "2018-05-04T18:33:44.348683: step 15894, loss 0.285271, acc 0.875\n",
      "2018-05-04T18:33:45.323107: step 15895, loss 0.201092, acc 0.953125\n",
      "2018-05-04T18:33:46.284227: step 15896, loss 0.296537, acc 0.875\n",
      "2018-05-04T18:33:47.227128: step 15897, loss 0.331196, acc 0.859375\n",
      "2018-05-04T18:33:48.250956: step 15898, loss 0.319922, acc 0.84375\n",
      "2018-05-04T18:33:49.183007: step 15899, loss 0.2789, acc 0.875\n",
      "2018-05-04T18:33:50.135697: step 15900, loss 0.196556, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T18:33:53.264860: step 15900, loss 0.226228, acc 0.912\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-15900\n",
      "\n",
      "2018-05-04T18:33:54.357678: step 15901, loss 0.326264, acc 0.875\n",
      "2018-05-04T18:33:55.330392: step 15902, loss 0.164057, acc 0.9375\n",
      "2018-05-04T18:33:56.328308: step 15903, loss 0.256867, acc 0.890625\n",
      "2018-05-04T18:33:57.368372: step 15904, loss 0.336139, acc 0.859375\n",
      "2018-05-04T18:33:58.373239: step 15905, loss 0.316069, acc 0.890625\n",
      "2018-05-04T18:33:59.428443: step 15906, loss 0.361302, acc 0.828125\n",
      "2018-05-04T18:34:00.459611: step 15907, loss 0.212502, acc 0.9375\n",
      "2018-05-04T18:34:01.506655: step 15908, loss 0.320379, acc 0.859375\n",
      "2018-05-04T18:34:02.449885: step 15909, loss 0.267123, acc 0.890625\n",
      "2018-05-04T18:34:03.440883: step 15910, loss 0.183127, acc 0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T18:34:04.419186: step 15911, loss 0.273534, acc 0.890625\n",
      "2018-05-04T18:34:05.393436: step 15912, loss 0.309675, acc 0.875\n",
      "2018-05-04T18:34:06.399968: step 15913, loss 0.199503, acc 0.9375\n",
      "2018-05-04T18:34:07.389659: step 15914, loss 0.218666, acc 0.90625\n",
      "2018-05-04T18:34:08.409984: step 15915, loss 0.215364, acc 0.90625\n",
      "2018-05-04T18:34:09.379083: step 15916, loss 0.188432, acc 0.9375\n",
      "2018-05-04T18:34:10.361893: step 15917, loss 0.326465, acc 0.84375\n",
      "2018-05-04T18:34:11.346377: step 15918, loss 0.313062, acc 0.890625\n",
      "2018-05-04T18:34:12.337310: step 15919, loss 0.284703, acc 0.875\n",
      "2018-05-04T18:34:13.288585: step 15920, loss 0.242091, acc 0.875\n",
      "2018-05-04T18:34:14.247167: step 15921, loss 0.281432, acc 0.921875\n",
      "2018-05-04T18:34:15.191824: step 15922, loss 0.272924, acc 0.890625\n",
      "2018-05-04T18:34:16.276769: step 15923, loss 0.354789, acc 0.859375\n",
      "2018-05-04T18:34:17.238972: step 15924, loss 0.219708, acc 0.9375\n",
      "2018-05-04T18:34:18.184925: step 15925, loss 0.279041, acc 0.890625\n",
      "2018-05-04T18:34:19.146559: step 15926, loss 0.174319, acc 0.90625\n",
      "2018-05-04T18:34:20.111739: step 15927, loss 0.218207, acc 0.921875\n",
      "2018-05-04T18:34:21.079273: step 15928, loss 0.35872, acc 0.84375\n",
      "2018-05-04T18:34:22.108766: step 15929, loss 0.278316, acc 0.90625\n",
      "2018-05-04T18:34:23.079740: step 15930, loss 0.219238, acc 0.890625\n",
      "2018-05-04T18:34:24.137520: step 15931, loss 0.248027, acc 0.859375\n",
      "2018-05-04T18:34:25.084356: step 15932, loss 0.134801, acc 0.96875\n",
      "2018-05-04T18:34:26.046974: step 15933, loss 0.295221, acc 0.890625\n",
      "2018-05-04T18:34:26.994435: step 15934, loss 0.224023, acc 0.890625\n",
      "2018-05-04T18:34:27.968781: step 15935, loss 0.169891, acc 0.921875\n",
      "2018-05-04T18:34:28.946406: step 15936, loss 0.305649, acc 0.890625\n",
      "2018-05-04T18:34:29.979172: step 15937, loss 0.258741, acc 0.890625\n",
      "2018-05-04T18:34:30.909561: step 15938, loss 0.170609, acc 0.953125\n",
      "2018-05-04T18:34:31.876347: step 15939, loss 0.262587, acc 0.890625\n",
      "2018-05-04T18:34:32.850674: step 15940, loss 0.158147, acc 0.921875\n",
      "2018-05-04T18:34:33.885893: step 15941, loss 0.316841, acc 0.921875\n",
      "2018-05-04T18:34:35.019217: step 15942, loss 0.342402, acc 0.828125\n",
      "2018-05-04T18:34:36.133074: step 15943, loss 0.271951, acc 0.890625\n",
      "2018-05-04T18:34:37.145005: step 15944, loss 0.347947, acc 0.8125\n",
      "2018-05-04T18:34:38.133180: step 15945, loss 0.255338, acc 0.90625\n",
      "2018-05-04T18:34:39.084347: step 15946, loss 0.236446, acc 0.890625\n",
      "2018-05-04T18:34:40.028480: step 15947, loss 0.239872, acc 0.875\n",
      "2018-05-04T18:34:41.018856: step 15948, loss 0.332773, acc 0.90625\n",
      "2018-05-04T18:34:42.087016: step 15949, loss 0.316588, acc 0.84375\n",
      "2018-05-04T18:34:43.115378: step 15950, loss 0.303734, acc 0.828125\n",
      "2018-05-04T18:34:44.136657: step 15951, loss 0.435, acc 0.8125\n",
      "2018-05-04T18:34:45.083981: step 15952, loss 0.339909, acc 0.8125\n",
      "2018-05-04T18:34:46.047116: step 15953, loss 0.231192, acc 0.890625\n",
      "2018-05-04T18:34:47.071708: step 15954, loss 0.281424, acc 0.875\n",
      "2018-05-04T18:34:48.052891: step 15955, loss 0.290248, acc 0.890625\n",
      "2018-05-04T18:34:49.027687: step 15956, loss 0.1859, acc 0.921875\n",
      "2018-05-04T18:34:49.995160: step 15957, loss 0.267225, acc 0.890625\n",
      "2018-05-04T18:34:50.981759: step 15958, loss 0.409206, acc 0.796875\n",
      "2018-05-04T18:34:51.991253: step 15959, loss 0.225454, acc 0.90625\n",
      "2018-05-04T18:34:52.947896: step 15960, loss 0.433308, acc 0.8125\n",
      "2018-05-04T18:34:53.917831: step 15961, loss 0.278283, acc 0.890625\n",
      "2018-05-04T18:34:54.862903: step 15962, loss 0.15598, acc 0.953125\n",
      "2018-05-04T18:34:55.820660: step 15963, loss 0.370949, acc 0.890625\n",
      "2018-05-04T18:34:56.801556: step 15964, loss 0.280116, acc 0.890625\n",
      "2018-05-04T18:34:57.785847: step 15965, loss 0.28883, acc 0.859375\n",
      "2018-05-04T18:34:58.756425: step 15966, loss 0.310241, acc 0.875\n",
      "2018-05-04T18:34:59.739103: step 15967, loss 0.208677, acc 0.9375\n",
      "2018-05-04T18:35:00.737409: step 15968, loss 0.194715, acc 0.90625\n",
      "2018-05-04T18:35:01.734924: step 15969, loss 0.285606, acc 0.8125\n",
      "2018-05-04T18:35:02.730376: step 15970, loss 0.285723, acc 0.890625\n",
      "2018-05-04T18:35:03.674128: step 15971, loss 0.256966, acc 0.9375\n",
      "2018-05-04T18:35:04.636515: step 15972, loss 0.187817, acc 0.953125\n",
      "2018-05-04T18:35:05.662944: step 15973, loss 0.273485, acc 0.890625\n",
      "2018-05-04T18:35:06.629396: step 15974, loss 0.227101, acc 0.90625\n",
      "2018-05-04T18:35:07.605946: step 15975, loss 0.326876, acc 0.84375\n",
      "2018-05-04T18:35:08.570718: step 15976, loss 0.217219, acc 0.921875\n",
      "2018-05-04T18:35:09.547473: step 15977, loss 0.358021, acc 0.828125\n",
      "2018-05-04T18:35:10.523378: step 15978, loss 0.28962, acc 0.875\n",
      "2018-05-04T18:35:11.554023: step 15979, loss 0.280314, acc 0.859375\n",
      "2018-05-04T18:35:12.560067: step 15980, loss 0.290208, acc 0.875\n",
      "2018-05-04T18:35:13.522198: step 15981, loss 0.367646, acc 0.859375\n",
      "2018-05-04T18:35:14.568327: step 15982, loss 0.246133, acc 0.90625\n",
      "2018-05-04T18:35:15.596529: step 15983, loss 0.19904, acc 0.953125\n",
      "2018-05-04T18:35:16.542267: step 15984, loss 0.339942, acc 0.890625\n",
      "2018-05-04T18:35:17.531212: step 15985, loss 0.183733, acc 0.9375\n",
      "2018-05-04T18:35:18.483813: step 15986, loss 0.244356, acc 0.90625\n",
      "2018-05-04T18:35:19.447822: step 15987, loss 0.391657, acc 0.8125\n",
      "2018-05-04T18:35:20.501895: step 15988, loss 0.227827, acc 0.90625\n",
      "2018-05-04T18:35:21.473032: step 15989, loss 0.297223, acc 0.875\n",
      "2018-05-04T18:35:22.522596: step 15990, loss 0.281517, acc 0.921875\n",
      "2018-05-04T18:35:23.485573: step 15991, loss 0.170585, acc 0.9375\n",
      "2018-05-04T18:35:24.441016: step 15992, loss 0.258431, acc 0.875\n",
      "2018-05-04T18:35:25.405151: step 15993, loss 0.244096, acc 0.890625\n",
      "2018-05-04T18:35:26.362384: step 15994, loss 0.326218, acc 0.890625\n",
      "2018-05-04T18:35:27.426389: step 15995, loss 0.211981, acc 0.875\n",
      "2018-05-04T18:35:28.385088: step 15996, loss 0.264553, acc 0.859375\n",
      "2018-05-04T18:35:29.349222: step 15997, loss 0.228058, acc 0.921875\n",
      "2018-05-04T18:35:30.320382: step 15998, loss 0.249551, acc 0.890625\n",
      "2018-05-04T18:35:31.294449: step 15999, loss 0.278068, acc 0.921875\n",
      "2018-05-04T18:35:32.313016: step 16000, loss 0.257765, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T18:35:34.440546: step 16000, loss 0.240404, acc 0.922\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-16000\n",
      "\n",
      "2018-05-04T18:35:35.519004: step 16001, loss 0.241734, acc 0.90625\n",
      "2018-05-04T18:35:36.495394: step 16002, loss 0.283622, acc 0.859375\n",
      "2018-05-04T18:35:37.460602: step 16003, loss 0.234754, acc 0.90625\n",
      "2018-05-04T18:35:38.424532: step 16004, loss 0.325664, acc 0.875\n",
      "2018-05-04T18:35:39.409344: step 16005, loss 0.303607, acc 0.90625\n",
      "2018-05-04T18:35:40.395475: step 16006, loss 0.36272, acc 0.859375\n",
      "2018-05-04T18:35:41.384433: step 16007, loss 0.247467, acc 0.859375\n",
      "2018-05-04T18:35:42.404883: step 16008, loss 0.211799, acc 0.9375\n",
      "2018-05-04T18:35:43.423917: step 16009, loss 0.293566, acc 0.890625\n",
      "2018-05-04T18:35:44.403094: step 16010, loss 0.21407, acc 0.90625\n",
      "2018-05-04T18:35:45.385875: step 16011, loss 0.280973, acc 0.859375\n",
      "2018-05-04T18:35:46.351450: step 16012, loss 0.334334, acc 0.859375\n",
      "2018-05-04T18:35:47.326557: step 16013, loss 0.371088, acc 0.859375\n",
      "2018-05-04T18:35:48.299606: step 16014, loss 0.329043, acc 0.890625\n",
      "2018-05-04T18:35:49.272875: step 16015, loss 0.208447, acc 0.90625\n",
      "2018-05-04T18:35:50.244897: step 16016, loss 0.19728, acc 0.921875\n",
      "2018-05-04T18:35:51.196442: step 16017, loss 0.393186, acc 0.84375\n",
      "2018-05-04T18:35:52.170055: step 16018, loss 0.214174, acc 0.921875\n",
      "2018-05-04T18:35:53.152484: step 16019, loss 0.176081, acc 0.9375\n",
      "2018-05-04T18:35:54.147527: step 16020, loss 0.305819, acc 0.890625\n",
      "2018-05-04T18:35:55.106549: step 16021, loss 0.210043, acc 0.90625\n",
      "2018-05-04T18:35:56.074303: step 16022, loss 0.153039, acc 0.953125\n",
      "2018-05-04T18:35:57.044178: step 16023, loss 0.355669, acc 0.90625\n",
      "2018-05-04T18:35:58.002803: step 16024, loss 0.186618, acc 0.921875\n",
      "2018-05-04T18:35:58.948935: step 16025, loss 0.273836, acc 0.859375\n",
      "2018-05-04T18:35:59.908573: step 16026, loss 0.258813, acc 0.921875\n",
      "2018-05-04T18:36:00.878274: step 16027, loss 0.257303, acc 0.9375\n",
      "2018-05-04T18:36:01.873410: step 16028, loss 0.330772, acc 0.859375\n",
      "2018-05-04T18:36:02.835039: step 16029, loss 0.215385, acc 0.96875\n",
      "2018-05-04T18:36:03.800811: step 16030, loss 0.23888, acc 0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T18:36:04.767771: step 16031, loss 0.199936, acc 0.9375\n",
      "2018-05-04T18:36:05.751516: step 16032, loss 0.277845, acc 0.90625\n",
      "2018-05-04T18:36:06.701761: step 16033, loss 0.36833, acc 0.875\n",
      "2018-05-04T18:36:07.636783: step 16034, loss 0.247147, acc 0.890625\n",
      "2018-05-04T18:36:08.570988: step 16035, loss 0.308196, acc 0.84375\n",
      "2018-05-04T18:36:09.545663: step 16036, loss 0.249101, acc 0.953125\n",
      "2018-05-04T18:36:10.530926: step 16037, loss 0.259012, acc 0.90625\n",
      "2018-05-04T18:36:11.502955: step 16038, loss 0.227417, acc 0.890625\n",
      "2018-05-04T18:36:12.523042: step 16039, loss 0.175099, acc 0.9375\n",
      "2018-05-04T18:36:13.472289: step 16040, loss 0.259693, acc 0.859375\n",
      "2018-05-04T18:36:14.455922: step 16041, loss 0.182956, acc 0.953125\n",
      "2018-05-04T18:36:15.387303: step 16042, loss 0.296583, acc 0.90625\n",
      "2018-05-04T18:36:16.332583: step 16043, loss 0.171362, acc 0.921875\n",
      "2018-05-04T18:36:17.275010: step 16044, loss 0.286718, acc 0.890625\n",
      "2018-05-04T18:36:18.231411: step 16045, loss 0.303104, acc 0.875\n",
      "2018-05-04T18:36:19.189084: step 16046, loss 0.300698, acc 0.859375\n",
      "2018-05-04T18:36:20.140003: step 16047, loss 0.291496, acc 0.890625\n",
      "2018-05-04T18:36:21.106085: step 16048, loss 0.174352, acc 0.9375\n",
      "2018-05-04T18:36:22.095164: step 16049, loss 0.187789, acc 0.9375\n",
      "2018-05-04T18:36:23.056802: step 16050, loss 0.248612, acc 0.890625\n",
      "2018-05-04T18:36:24.023359: step 16051, loss 0.288822, acc 0.875\n",
      "2018-05-04T18:36:24.964080: step 16052, loss 0.201964, acc 0.921875\n",
      "2018-05-04T18:36:25.922237: step 16053, loss 0.176596, acc 0.953125\n",
      "2018-05-04T18:36:26.853065: step 16054, loss 0.301155, acc 0.890625\n",
      "2018-05-04T18:36:27.862721: step 16055, loss 0.373261, acc 0.84375\n",
      "2018-05-04T18:36:28.817505: step 16056, loss 0.327661, acc 0.90625\n",
      "2018-05-04T18:36:29.760152: step 16057, loss 0.280808, acc 0.828125\n",
      "2018-05-04T18:36:30.704648: step 16058, loss 0.38799, acc 0.84375\n",
      "2018-05-04T18:36:31.663822: step 16059, loss 0.38333, acc 0.875\n",
      "2018-05-04T18:36:32.613632: step 16060, loss 0.215539, acc 0.921875\n",
      "2018-05-04T18:36:33.544330: step 16061, loss 0.254612, acc 0.921875\n",
      "2018-05-04T18:36:34.535441: step 16062, loss 0.309712, acc 0.875\n",
      "2018-05-04T18:36:35.514976: step 16063, loss 0.196138, acc 0.921875\n",
      "2018-05-04T18:36:36.523480: step 16064, loss 0.323302, acc 0.875\n",
      "2018-05-04T18:36:37.457334: step 16065, loss 0.262298, acc 0.90625\n",
      "2018-05-04T18:36:38.402381: step 16066, loss 0.392741, acc 0.859375\n",
      "2018-05-04T18:36:39.394305: step 16067, loss 0.361753, acc 0.90625\n",
      "2018-05-04T18:36:40.316511: step 16068, loss 0.177278, acc 0.9375\n",
      "2018-05-04T18:36:41.263887: step 16069, loss 0.183474, acc 0.890625\n",
      "2018-05-04T18:36:42.311413: step 16070, loss 0.152746, acc 0.9375\n",
      "2018-05-04T18:36:43.254611: step 16071, loss 0.261788, acc 0.90625\n",
      "2018-05-04T18:36:44.191901: step 16072, loss 0.190647, acc 0.9375\n",
      "2018-05-04T18:36:45.154258: step 16073, loss 0.221468, acc 0.9375\n",
      "2018-05-04T18:36:46.109666: step 16074, loss 0.257665, acc 0.921875\n",
      "2018-05-04T18:36:47.171723: step 16075, loss 0.178345, acc 0.953125\n",
      "2018-05-04T18:36:48.103366: step 16076, loss 0.289794, acc 0.90625\n",
      "2018-05-04T18:36:49.119502: step 16077, loss 0.216648, acc 0.90625\n",
      "2018-05-04T18:36:50.053519: step 16078, loss 0.196371, acc 0.9375\n",
      "2018-05-04T18:36:51.080235: step 16079, loss 0.264127, acc 0.890625\n",
      "2018-05-04T18:36:52.020920: step 16080, loss 0.202428, acc 0.90625\n",
      "2018-05-04T18:36:52.961131: step 16081, loss 0.351448, acc 0.859375\n",
      "2018-05-04T18:36:53.902512: step 16082, loss 0.297434, acc 0.890625\n",
      "2018-05-04T18:36:54.839475: step 16083, loss 0.402693, acc 0.8125\n",
      "2018-05-04T18:36:55.779523: step 16084, loss 0.224022, acc 0.921875\n",
      "2018-05-04T18:36:56.746380: step 16085, loss 0.135587, acc 0.953125\n",
      "2018-05-04T18:36:57.715340: step 16086, loss 0.322622, acc 0.90625\n",
      "2018-05-04T18:36:58.685686: step 16087, loss 0.268437, acc 0.921875\n",
      "2018-05-04T18:36:59.689869: step 16088, loss 0.179855, acc 0.953125\n",
      "2018-05-04T18:37:00.624654: step 16089, loss 0.203731, acc 0.9375\n",
      "2018-05-04T18:37:01.663848: step 16090, loss 0.197452, acc 0.921875\n",
      "2018-05-04T18:37:02.743184: step 16091, loss 0.311037, acc 0.859375\n",
      "2018-05-04T18:37:03.684557: step 16092, loss 0.36674, acc 0.859375\n",
      "2018-05-04T18:37:04.701877: step 16093, loss 0.272755, acc 0.875\n",
      "2018-05-04T18:37:05.628642: step 16094, loss 0.546367, acc 0.8125\n",
      "2018-05-04T18:37:06.563810: step 16095, loss 0.279956, acc 0.890625\n",
      "2018-05-04T18:37:07.537108: step 16096, loss 0.269243, acc 0.875\n",
      "2018-05-04T18:37:08.511056: step 16097, loss 0.352942, acc 0.875\n",
      "2018-05-04T18:37:09.477047: step 16098, loss 0.143085, acc 0.96875\n",
      "2018-05-04T18:37:10.500019: step 16099, loss 0.330835, acc 0.859375\n",
      "2018-05-04T18:37:11.571206: step 16100, loss 0.174587, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T18:37:13.662220: step 16100, loss 0.219352, acc 0.93\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-16100\n",
      "\n",
      "2018-05-04T18:37:14.698986: step 16101, loss 0.231812, acc 0.921875\n",
      "2018-05-04T18:37:15.663129: step 16102, loss 0.283368, acc 0.921875\n",
      "2018-05-04T18:37:16.633545: step 16103, loss 0.335034, acc 0.84375\n",
      "2018-05-04T18:37:17.631605: step 16104, loss 0.254943, acc 0.90625\n",
      "2018-05-04T18:37:18.649735: step 16105, loss 0.26743, acc 0.921875\n",
      "2018-05-04T18:37:19.660686: step 16106, loss 0.331119, acc 0.875\n",
      "2018-05-04T18:37:20.627960: step 16107, loss 0.281723, acc 0.890625\n",
      "2018-05-04T18:37:21.568956: step 16108, loss 0.254049, acc 0.90625\n",
      "2018-05-04T18:37:22.509908: step 16109, loss 0.299384, acc 0.890625\n",
      "2018-05-04T18:37:23.451112: step 16110, loss 0.207108, acc 0.921875\n",
      "2018-05-04T18:37:24.477960: step 16111, loss 0.371867, acc 0.859375\n",
      "2018-05-04T18:37:25.415374: step 16112, loss 0.402763, acc 0.875\n",
      "2018-05-04T18:37:26.354381: step 16113, loss 0.306706, acc 0.890625\n",
      "2018-05-04T18:37:27.370489: step 16114, loss 0.197377, acc 0.890625\n",
      "2018-05-04T18:37:28.314083: step 16115, loss 0.269816, acc 0.875\n",
      "2018-05-04T18:37:29.242447: step 16116, loss 0.313981, acc 0.890625\n",
      "2018-05-04T18:37:30.209431: step 16117, loss 0.362509, acc 0.859375\n",
      "2018-05-04T18:37:31.202643: step 16118, loss 0.283653, acc 0.875\n",
      "2018-05-04T18:37:32.263911: step 16119, loss 0.298319, acc 0.890625\n",
      "2018-05-04T18:37:33.252204: step 16120, loss 0.273027, acc 0.9375\n",
      "2018-05-04T18:37:34.338971: step 16121, loss 0.283339, acc 0.921875\n",
      "2018-05-04T18:37:35.421247: step 16122, loss 0.266981, acc 0.859375\n",
      "2018-05-04T18:37:36.497179: step 16123, loss 0.372951, acc 0.828125\n",
      "2018-05-04T18:37:37.450887: step 16124, loss 0.288704, acc 0.890625\n",
      "2018-05-04T18:37:38.486508: step 16125, loss 0.335843, acc 0.84375\n",
      "2018-05-04T18:37:39.429246: step 16126, loss 0.203083, acc 0.953125\n",
      "2018-05-04T18:37:40.455964: step 16127, loss 0.232161, acc 0.90625\n",
      "2018-05-04T18:37:41.397959: step 16128, loss 0.204698, acc 0.921875\n",
      "2018-05-04T18:37:42.432183: step 16129, loss 0.376397, acc 0.78125\n",
      "2018-05-04T18:37:43.420599: step 16130, loss 0.2259, acc 0.90625\n",
      "2018-05-04T18:37:44.344589: step 16131, loss 0.170212, acc 0.953125\n",
      "2018-05-04T18:37:45.379997: step 16132, loss 0.304012, acc 0.875\n",
      "2018-05-04T18:37:46.409133: step 16133, loss 0.237966, acc 0.890625\n",
      "2018-05-04T18:37:47.390601: step 16134, loss 0.336182, acc 0.890625\n",
      "2018-05-04T18:37:48.414683: step 16135, loss 0.324068, acc 0.8125\n",
      "2018-05-04T18:37:49.360816: step 16136, loss 0.33306, acc 0.828125\n",
      "2018-05-04T18:37:50.380209: step 16137, loss 0.293394, acc 0.921875\n",
      "2018-05-04T18:37:51.431552: step 16138, loss 0.262409, acc 0.875\n",
      "2018-05-04T18:37:52.471932: step 16139, loss 0.234205, acc 0.890625\n",
      "2018-05-04T18:37:53.463087: step 16140, loss 0.234408, acc 0.90625\n",
      "2018-05-04T18:37:54.492114: step 16141, loss 0.232468, acc 0.921875\n",
      "2018-05-04T18:37:55.425832: step 16142, loss 0.353878, acc 0.875\n",
      "2018-05-04T18:37:56.437642: step 16143, loss 0.252112, acc 0.84375\n",
      "2018-05-04T18:37:57.367941: step 16144, loss 0.336514, acc 0.8125\n",
      "2018-05-04T18:37:58.365502: step 16145, loss 0.225099, acc 0.921875\n",
      "2018-05-04T18:37:59.302374: step 16146, loss 0.323732, acc 0.84375\n",
      "2018-05-04T18:38:00.232136: step 16147, loss 0.193625, acc 0.921875\n",
      "2018-05-04T18:38:01.172578: step 16148, loss 0.310299, acc 0.90625\n",
      "2018-05-04T18:38:02.106599: step 16149, loss 0.293389, acc 0.859375\n",
      "2018-05-04T18:38:03.059255: step 16150, loss 0.261645, acc 0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T18:38:04.108573: step 16151, loss 0.169674, acc 0.953125\n",
      "2018-05-04T18:38:05.067670: step 16152, loss 0.215326, acc 0.90625\n",
      "2018-05-04T18:38:06.098241: step 16153, loss 0.302678, acc 0.84375\n",
      "2018-05-04T18:38:07.032768: step 16154, loss 0.164785, acc 0.90625\n",
      "2018-05-04T18:38:08.036569: step 16155, loss 0.116204, acc 0.984375\n",
      "2018-05-04T18:38:09.061005: step 16156, loss 0.273709, acc 0.921875\n",
      "2018-05-04T18:38:10.040529: step 16157, loss 0.219824, acc 0.90625\n",
      "2018-05-04T18:38:11.069701: step 16158, loss 0.405145, acc 0.828125\n",
      "2018-05-04T18:38:12.055277: step 16159, loss 0.210457, acc 0.921875\n",
      "2018-05-04T18:38:13.087677: step 16160, loss 0.218768, acc 0.9375\n",
      "2018-05-04T18:38:14.034967: step 16161, loss 0.292647, acc 0.828125\n",
      "2018-05-04T18:38:15.070511: step 16162, loss 0.214806, acc 0.9375\n",
      "2018-05-04T18:38:16.085486: step 16163, loss 0.336314, acc 0.890625\n",
      "2018-05-04T18:38:17.077111: step 16164, loss 0.25494, acc 0.953125\n",
      "2018-05-04T18:38:18.071963: step 16165, loss 0.274007, acc 0.90625\n",
      "2018-05-04T18:38:19.017603: step 16166, loss 0.205622, acc 0.953125\n",
      "2018-05-04T18:38:20.032851: step 16167, loss 0.5012, acc 0.8125\n",
      "2018-05-04T18:38:20.988724: step 16168, loss 0.173613, acc 0.921875\n",
      "2018-05-04T18:38:22.029160: step 16169, loss 0.299242, acc 0.859375\n",
      "2018-05-04T18:38:23.023422: step 16170, loss 0.257105, acc 0.875\n",
      "2018-05-04T18:38:24.042696: step 16171, loss 0.148813, acc 0.9375\n",
      "2018-05-04T18:38:25.067875: step 16172, loss 0.294666, acc 0.921875\n",
      "2018-05-04T18:38:26.064427: step 16173, loss 0.168397, acc 0.921875\n",
      "2018-05-04T18:38:27.088329: step 16174, loss 0.283214, acc 0.90625\n",
      "2018-05-04T18:38:28.094478: step 16175, loss 0.230572, acc 0.90625\n",
      "2018-05-04T18:38:29.105459: step 16176, loss 0.268482, acc 0.890625\n",
      "2018-05-04T18:38:30.112239: step 16177, loss 0.209983, acc 0.890625\n",
      "2018-05-04T18:38:31.107988: step 16178, loss 0.248304, acc 0.890625\n",
      "2018-05-04T18:38:32.159816: step 16179, loss 0.22656, acc 0.90625\n",
      "2018-05-04T18:38:33.177654: step 16180, loss 0.282362, acc 0.890625\n",
      "2018-05-04T18:38:34.169544: step 16181, loss 0.433336, acc 0.78125\n",
      "2018-05-04T18:38:35.173820: step 16182, loss 0.343781, acc 0.875\n",
      "2018-05-04T18:38:36.173762: step 16183, loss 0.308881, acc 0.890625\n",
      "2018-05-04T18:38:37.168850: step 16184, loss 0.251606, acc 0.90625\n",
      "2018-05-04T18:38:38.183864: step 16185, loss 0.181129, acc 0.953125\n",
      "2018-05-04T18:38:39.104068: step 16186, loss 0.17764, acc 0.953125\n",
      "2018-05-04T18:38:40.107436: step 16187, loss 0.139378, acc 0.96875\n",
      "2018-05-04T18:38:41.104093: step 16188, loss 0.273603, acc 0.890625\n",
      "2018-05-04T18:38:42.129555: step 16189, loss 0.223243, acc 0.890625\n",
      "2018-05-04T18:38:43.182494: step 16190, loss 0.312277, acc 0.875\n",
      "2018-05-04T18:38:44.119199: step 16191, loss 0.218615, acc 0.90625\n",
      "2018-05-04T18:38:45.119591: step 16192, loss 0.319999, acc 0.90625\n",
      "2018-05-04T18:38:46.122666: step 16193, loss 0.16572, acc 0.953125\n",
      "2018-05-04T18:38:47.131546: step 16194, loss 0.207566, acc 0.953125\n",
      "2018-05-04T18:38:48.086398: step 16195, loss 0.176, acc 0.9375\n",
      "2018-05-04T18:38:49.106096: step 16196, loss 0.331225, acc 0.875\n",
      "2018-05-04T18:38:50.112371: step 16197, loss 0.313145, acc 0.890625\n",
      "2018-05-04T18:38:51.048648: step 16198, loss 0.223299, acc 0.921875\n",
      "2018-05-04T18:38:52.056856: step 16199, loss 0.234332, acc 0.921875\n",
      "2018-05-04T18:38:53.058585: step 16200, loss 0.309287, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T18:38:56.200941: step 16200, loss 0.210464, acc 0.936\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-16200\n",
      "\n",
      "2018-05-04T18:38:57.253393: step 16201, loss 0.255383, acc 0.921875\n",
      "2018-05-04T18:38:58.244377: step 16202, loss 0.245215, acc 0.921875\n",
      "2018-05-04T18:38:59.250495: step 16203, loss 0.286737, acc 0.90625\n",
      "2018-05-04T18:39:00.251501: step 16204, loss 0.15499, acc 0.9375\n",
      "2018-05-04T18:39:01.294172: step 16205, loss 0.324211, acc 0.84375\n",
      "2018-05-04T18:39:02.337728: step 16206, loss 0.244773, acc 0.890625\n",
      "2018-05-04T18:39:03.343108: step 16207, loss 0.204034, acc 0.90625\n",
      "2018-05-04T18:39:04.343141: step 16208, loss 0.266183, acc 0.859375\n",
      "2018-05-04T18:39:05.345123: step 16209, loss 0.15602, acc 0.9375\n",
      "2018-05-04T18:39:06.374155: step 16210, loss 0.297974, acc 0.890625\n",
      "2018-05-04T18:39:07.326654: step 16211, loss 0.334574, acc 0.828125\n",
      "2018-05-04T18:39:08.307076: step 16212, loss 0.167682, acc 0.921875\n",
      "2018-05-04T18:39:09.295024: step 16213, loss 0.16527, acc 0.9375\n",
      "2018-05-04T18:39:10.248167: step 16214, loss 0.316389, acc 0.875\n",
      "2018-05-04T18:39:11.230211: step 16215, loss 0.223194, acc 0.9375\n",
      "2018-05-04T18:39:12.212897: step 16216, loss 0.319539, acc 0.859375\n",
      "2018-05-04T18:39:13.274928: step 16217, loss 0.292123, acc 0.90625\n",
      "2018-05-04T18:39:14.235312: step 16218, loss 0.31725, acc 0.90625\n",
      "2018-05-04T18:39:15.199910: step 16219, loss 0.240624, acc 0.921875\n",
      "2018-05-04T18:39:16.180802: step 16220, loss 0.237666, acc 0.90625\n",
      "2018-05-04T18:39:17.147484: step 16221, loss 0.231176, acc 0.921875\n",
      "2018-05-04T18:39:18.195112: step 16222, loss 0.234737, acc 0.890625\n",
      "2018-05-04T18:39:19.161054: step 16223, loss 0.376034, acc 0.90625\n",
      "2018-05-04T18:39:20.137471: step 16224, loss 0.263844, acc 0.890625\n",
      "2018-05-04T18:39:21.062877: step 16225, loss 0.226364, acc 0.921875\n",
      "2018-05-04T18:39:22.086547: step 16226, loss 0.20566, acc 0.890625\n",
      "2018-05-04T18:39:23.043614: step 16227, loss 0.251891, acc 0.890625\n",
      "2018-05-04T18:39:23.981961: step 16228, loss 0.223364, acc 0.9375\n",
      "2018-05-04T18:39:24.934512: step 16229, loss 0.435257, acc 0.8125\n",
      "2018-05-04T18:39:25.922196: step 16230, loss 0.250226, acc 0.875\n",
      "2018-05-04T18:39:26.897803: step 16231, loss 0.337346, acc 0.859375\n",
      "2018-05-04T18:39:27.921738: step 16232, loss 0.316282, acc 0.90625\n",
      "2018-05-04T18:39:28.887460: step 16233, loss 0.232872, acc 0.921875\n",
      "2018-05-04T18:39:29.845008: step 16234, loss 0.255502, acc 0.953125\n",
      "2018-05-04T18:39:30.800854: step 16235, loss 0.309206, acc 0.90625\n",
      "2018-05-04T18:39:31.772404: step 16236, loss 0.294432, acc 0.84375\n",
      "2018-05-04T18:39:32.723900: step 16237, loss 0.221841, acc 0.9375\n",
      "2018-05-04T18:39:33.700822: step 16238, loss 0.328699, acc 0.859375\n",
      "2018-05-04T18:39:34.674451: step 16239, loss 0.161186, acc 0.953125\n",
      "2018-05-04T18:39:35.667573: step 16240, loss 0.307192, acc 0.875\n",
      "2018-05-04T18:39:36.658004: step 16241, loss 0.263373, acc 0.890625\n",
      "2018-05-04T18:39:37.711165: step 16242, loss 0.33254, acc 0.84375\n",
      "2018-05-04T18:39:38.670381: step 16243, loss 0.2634, acc 0.875\n",
      "2018-05-04T18:39:39.606908: step 16244, loss 0.208484, acc 0.90625\n",
      "2018-05-04T18:39:40.534728: step 16245, loss 0.247377, acc 0.875\n",
      "2018-05-04T18:39:41.476126: step 16246, loss 0.325687, acc 0.828125\n",
      "2018-05-04T18:39:42.433584: step 16247, loss 0.165019, acc 0.9375\n",
      "2018-05-04T18:39:43.405173: step 16248, loss 0.289508, acc 0.890625\n",
      "2018-05-04T18:39:44.355243: step 16249, loss 0.396422, acc 0.796875\n",
      "2018-05-04T18:39:45.334290: step 16250, loss 0.173549, acc 0.921875\n",
      "2018-05-04T18:39:46.288891: step 16251, loss 0.26128, acc 0.859375\n",
      "2018-05-04T18:39:47.248435: step 16252, loss 0.38374, acc 0.828125\n",
      "2018-05-04T18:39:48.227315: step 16253, loss 0.460066, acc 0.84375\n",
      "2018-05-04T18:39:49.210393: step 16254, loss 0.219961, acc 0.90625\n",
      "2018-05-04T18:39:50.162211: step 16255, loss 0.328391, acc 0.875\n",
      "2018-05-04T18:39:51.144047: step 16256, loss 0.343887, acc 0.84375\n",
      "2018-05-04T18:39:52.101622: step 16257, loss 0.157105, acc 0.9375\n",
      "2018-05-04T18:39:53.051398: step 16258, loss 0.212367, acc 0.890625\n",
      "2018-05-04T18:39:54.017631: step 16259, loss 0.203516, acc 0.90625\n",
      "2018-05-04T18:39:54.997872: step 16260, loss 0.314199, acc 0.890625\n",
      "2018-05-04T18:39:55.982814: step 16261, loss 0.363816, acc 0.875\n",
      "2018-05-04T18:39:56.965007: step 16262, loss 0.224406, acc 0.890625\n",
      "2018-05-04T18:39:57.925501: step 16263, loss 0.235149, acc 0.921875\n",
      "2018-05-04T18:39:58.879550: step 16264, loss 0.18239, acc 0.9375\n",
      "2018-05-04T18:39:59.832143: step 16265, loss 0.196272, acc 0.921875\n",
      "2018-05-04T18:40:00.896282: step 16266, loss 0.164912, acc 0.9375\n",
      "2018-05-04T18:40:01.856662: step 16267, loss 0.216071, acc 0.921875\n",
      "2018-05-04T18:40:02.888717: step 16268, loss 0.243387, acc 0.890625\n",
      "2018-05-04T18:40:03.865968: step 16269, loss 0.253024, acc 0.90625\n",
      "2018-05-04T18:40:04.832876: step 16270, loss 0.302833, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T18:40:05.821418: step 16271, loss 0.274222, acc 0.890625\n",
      "2018-05-04T18:40:06.801493: step 16272, loss 0.192881, acc 0.921875\n",
      "2018-05-04T18:40:07.763439: step 16273, loss 0.289093, acc 0.890625\n",
      "2018-05-04T18:40:08.740771: step 16274, loss 0.284462, acc 0.9375\n",
      "2018-05-04T18:40:09.704789: step 16275, loss 0.355494, acc 0.890625\n",
      "2018-05-04T18:40:10.692128: step 16276, loss 0.184095, acc 0.921875\n",
      "2018-05-04T18:40:11.696340: step 16277, loss 0.216097, acc 0.90625\n",
      "2018-05-04T18:40:12.644059: step 16278, loss 0.33435, acc 0.890625\n",
      "2018-05-04T18:40:13.611384: step 16279, loss 0.319549, acc 0.84375\n",
      "2018-05-04T18:40:14.581024: step 16280, loss 0.233541, acc 0.921875\n",
      "2018-05-04T18:40:15.543546: step 16281, loss 0.317658, acc 0.875\n",
      "2018-05-04T18:40:16.531772: step 16282, loss 0.490407, acc 0.78125\n",
      "2018-05-04T18:40:17.526789: step 16283, loss 0.181301, acc 0.9375\n",
      "2018-05-04T18:40:18.497752: step 16284, loss 0.295583, acc 0.90625\n",
      "2018-05-04T18:40:19.473232: step 16285, loss 0.365385, acc 0.875\n",
      "2018-05-04T18:40:20.430930: step 16286, loss 0.299497, acc 0.875\n",
      "2018-05-04T18:40:21.381470: step 16287, loss 0.216419, acc 0.921875\n",
      "2018-05-04T18:40:22.426896: step 16288, loss 0.234914, acc 0.890625\n",
      "2018-05-04T18:40:23.373043: step 16289, loss 0.305782, acc 0.890625\n",
      "2018-05-04T18:40:24.321792: step 16290, loss 0.311535, acc 0.859375\n",
      "2018-05-04T18:40:25.286344: step 16291, loss 0.195916, acc 0.921875\n",
      "2018-05-04T18:40:26.281869: step 16292, loss 0.307205, acc 0.90625\n",
      "2018-05-04T18:40:27.277317: step 16293, loss 0.224924, acc 0.921875\n",
      "2018-05-04T18:40:28.253845: step 16294, loss 0.319747, acc 0.859375\n",
      "2018-05-04T18:40:29.230108: step 16295, loss 0.22034, acc 0.890625\n",
      "2018-05-04T18:40:30.203866: step 16296, loss 0.413513, acc 0.765625\n",
      "2018-05-04T18:40:31.173905: step 16297, loss 0.225911, acc 0.90625\n",
      "2018-05-04T18:40:32.174928: step 16298, loss 0.222385, acc 0.875\n",
      "2018-05-04T18:40:33.202467: step 16299, loss 0.236483, acc 0.875\n",
      "2018-05-04T18:40:34.228336: step 16300, loss 0.272819, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T18:40:36.884465: step 16300, loss 0.227226, acc 0.926\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-16300\n",
      "\n",
      "2018-05-04T18:40:37.947161: step 16301, loss 0.272854, acc 0.875\n",
      "2018-05-04T18:40:38.974050: step 16302, loss 0.171269, acc 0.921875\n",
      "2018-05-04T18:40:40.076297: step 16303, loss 0.45702, acc 0.84375\n",
      "2018-05-04T18:40:41.080620: step 16304, loss 0.312743, acc 0.875\n",
      "2018-05-04T18:40:42.087058: step 16305, loss 0.346229, acc 0.875\n",
      "2018-05-04T18:40:43.087391: step 16306, loss 0.220529, acc 0.90625\n",
      "2018-05-04T18:40:44.168537: step 16307, loss 0.281852, acc 0.875\n",
      "2018-05-04T18:40:45.126884: step 16308, loss 0.224413, acc 0.9375\n",
      "2018-05-04T18:40:46.091262: step 16309, loss 0.272981, acc 0.90625\n",
      "2018-05-04T18:40:47.069026: step 16310, loss 0.22119, acc 0.890625\n",
      "2018-05-04T18:40:48.042864: step 16311, loss 0.298501, acc 0.90625\n",
      "2018-05-04T18:40:48.996126: step 16312, loss 0.3001, acc 0.890625\n",
      "2018-05-04T18:40:49.940828: step 16313, loss 0.311953, acc 0.890625\n",
      "2018-05-04T18:40:50.930275: step 16314, loss 0.27429, acc 0.875\n",
      "2018-05-04T18:40:51.965568: step 16315, loss 0.228768, acc 0.890625\n",
      "2018-05-04T18:40:52.963758: step 16316, loss 0.1805, acc 0.953125\n",
      "2018-05-04T18:40:53.971240: step 16317, loss 0.279738, acc 0.90625\n",
      "2018-05-04T18:40:54.932510: step 16318, loss 0.120662, acc 0.9375\n",
      "2018-05-04T18:40:55.888609: step 16319, loss 0.258563, acc 0.875\n",
      "2018-05-04T18:40:56.858355: step 16320, loss 0.286461, acc 0.90625\n",
      "2018-05-04T18:40:57.818656: step 16321, loss 0.229915, acc 0.921875\n",
      "2018-05-04T18:40:58.837584: step 16322, loss 0.197881, acc 0.9375\n",
      "2018-05-04T18:40:59.779199: step 16323, loss 0.170049, acc 0.921875\n",
      "2018-05-04T18:41:00.830363: step 16324, loss 0.14607, acc 0.953125\n",
      "2018-05-04T18:41:01.795245: step 16325, loss 0.250643, acc 0.875\n",
      "2018-05-04T18:41:02.756673: step 16326, loss 0.154775, acc 0.953125\n",
      "2018-05-04T18:41:03.715253: step 16327, loss 0.129371, acc 0.9375\n",
      "2018-05-04T18:41:04.688328: step 16328, loss 0.240709, acc 0.921875\n",
      "2018-05-04T18:41:05.661019: step 16329, loss 0.221511, acc 0.9375\n",
      "2018-05-04T18:41:06.661292: step 16330, loss 0.129973, acc 0.96875\n",
      "2018-05-04T18:41:07.643805: step 16331, loss 0.176431, acc 0.921875\n",
      "2018-05-04T18:41:08.624706: step 16332, loss 0.361308, acc 0.828125\n",
      "2018-05-04T18:41:09.599803: step 16333, loss 0.274937, acc 0.90625\n",
      "2018-05-04T18:41:10.585563: step 16334, loss 0.360423, acc 0.859375\n",
      "2018-05-04T18:41:11.541550: step 16335, loss 0.253843, acc 0.90625\n",
      "2018-05-04T18:41:12.510142: step 16336, loss 0.274916, acc 0.921875\n",
      "2018-05-04T18:41:13.471323: step 16337, loss 0.242736, acc 0.90625\n",
      "2018-05-04T18:41:14.438427: step 16338, loss 0.317277, acc 0.875\n",
      "2018-05-04T18:41:15.395505: step 16339, loss 0.244775, acc 0.90625\n",
      "2018-05-04T18:41:16.359235: step 16340, loss 0.347327, acc 0.828125\n",
      "2018-05-04T18:41:17.450837: step 16341, loss 0.51701, acc 0.75\n",
      "2018-05-04T18:41:18.395315: step 16342, loss 0.257233, acc 0.921875\n",
      "2018-05-04T18:41:19.353760: step 16343, loss 0.183722, acc 0.953125\n",
      "2018-05-04T18:41:20.310873: step 16344, loss 0.156969, acc 0.9375\n",
      "2018-05-04T18:41:21.288856: step 16345, loss 0.195454, acc 0.9375\n",
      "2018-05-04T18:41:22.268569: step 16346, loss 0.273963, acc 0.890625\n",
      "2018-05-04T18:41:23.249912: step 16347, loss 0.301094, acc 0.890625\n",
      "2018-05-04T18:41:24.270096: step 16348, loss 0.295079, acc 0.890625\n",
      "2018-05-04T18:41:25.239739: step 16349, loss 0.333588, acc 0.859375\n",
      "2018-05-04T18:41:26.273410: step 16350, loss 0.217351, acc 0.921875\n",
      "2018-05-04T18:41:27.314382: step 16351, loss 0.286107, acc 0.90625\n",
      "2018-05-04T18:41:28.280651: step 16352, loss 0.333458, acc 0.90625\n",
      "2018-05-04T18:41:29.258079: step 16353, loss 0.315069, acc 0.890625\n",
      "2018-05-04T18:41:30.267769: step 16354, loss 0.203532, acc 0.875\n",
      "2018-05-04T18:41:31.257977: step 16355, loss 0.268389, acc 0.890625\n",
      "2018-05-04T18:41:32.263610: step 16356, loss 0.278325, acc 0.890625\n",
      "2018-05-04T18:41:33.242449: step 16357, loss 0.353615, acc 0.796875\n",
      "2018-05-04T18:41:34.291134: step 16358, loss 0.213451, acc 0.921875\n",
      "2018-05-04T18:41:35.268248: step 16359, loss 0.232451, acc 0.9375\n",
      "2018-05-04T18:41:36.243609: step 16360, loss 0.318045, acc 0.875\n",
      "2018-05-04T18:41:37.224896: step 16361, loss 0.24942, acc 0.890625\n",
      "2018-05-04T18:41:38.200750: step 16362, loss 0.369898, acc 0.875\n",
      "2018-05-04T18:41:39.166435: step 16363, loss 0.169544, acc 0.9375\n",
      "2018-05-04T18:41:40.124747: step 16364, loss 0.226852, acc 0.90625\n",
      "2018-05-04T18:41:41.097444: step 16365, loss 0.191642, acc 0.9375\n",
      "2018-05-04T18:41:42.058349: step 16366, loss 0.262212, acc 0.9375\n",
      "2018-05-04T18:41:43.035684: step 16367, loss 0.25261, acc 0.90625\n",
      "2018-05-04T18:41:44.049891: step 16368, loss 0.252898, acc 0.90625\n",
      "2018-05-04T18:41:45.107270: step 16369, loss 0.285712, acc 0.859375\n",
      "2018-05-04T18:41:46.053703: step 16370, loss 0.284104, acc 0.921875\n",
      "2018-05-04T18:41:47.088677: step 16371, loss 0.280332, acc 0.90625\n",
      "2018-05-04T18:41:48.136526: step 16372, loss 0.283646, acc 0.890625\n",
      "2018-05-04T18:41:49.090667: step 16373, loss 0.343449, acc 0.84375\n",
      "2018-05-04T18:41:50.045212: step 16374, loss 0.263507, acc 0.890625\n",
      "2018-05-04T18:41:50.989047: step 16375, loss 0.345137, acc 0.890625\n",
      "2018-05-04T18:41:52.002642: step 16376, loss 0.313158, acc 0.875\n",
      "2018-05-04T18:41:52.951002: step 16377, loss 0.119809, acc 0.984375\n",
      "2018-05-04T18:41:53.921907: step 16378, loss 0.286834, acc 0.859375\n",
      "2018-05-04T18:41:54.892615: step 16379, loss 0.213774, acc 0.9375\n",
      "2018-05-04T18:41:55.890704: step 16380, loss 0.169276, acc 0.953125\n",
      "2018-05-04T18:41:56.870862: step 16381, loss 0.244611, acc 0.921875\n",
      "2018-05-04T18:41:57.847822: step 16382, loss 0.324241, acc 0.859375\n",
      "2018-05-04T18:41:58.829819: step 16383, loss 0.240674, acc 0.890625\n",
      "2018-05-04T18:41:59.857769: step 16384, loss 0.323116, acc 0.859375\n",
      "2018-05-04T18:42:00.819019: step 16385, loss 0.219843, acc 0.9375\n",
      "2018-05-04T18:42:01.786203: step 16386, loss 0.183424, acc 0.9375\n",
      "2018-05-04T18:42:02.733871: step 16387, loss 0.314591, acc 0.875\n",
      "2018-05-04T18:42:03.684443: step 16388, loss 0.222494, acc 0.859375\n",
      "2018-05-04T18:42:04.639397: step 16389, loss 0.304932, acc 0.90625\n",
      "2018-05-04T18:42:05.595972: step 16390, loss 0.20724, acc 0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T18:42:06.558529: step 16391, loss 0.266679, acc 0.9375\n",
      "2018-05-04T18:42:07.529426: step 16392, loss 0.298495, acc 0.8125\n",
      "2018-05-04T18:42:08.506199: step 16393, loss 0.386442, acc 0.84375\n",
      "2018-05-04T18:42:09.490546: step 16394, loss 0.172521, acc 0.921875\n",
      "2018-05-04T18:42:10.455280: step 16395, loss 0.322603, acc 0.875\n",
      "2018-05-04T18:42:11.406165: step 16396, loss 0.232691, acc 0.921875\n",
      "2018-05-04T18:42:12.420465: step 16397, loss 0.213062, acc 0.9375\n",
      "2018-05-04T18:42:13.374383: step 16398, loss 0.229273, acc 0.9375\n",
      "2018-05-04T18:42:14.322291: step 16399, loss 0.182423, acc 0.9375\n",
      "2018-05-04T18:42:15.290875: step 16400, loss 0.198594, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T18:42:17.421288: step 16400, loss 0.228189, acc 0.928\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-16400\n",
      "\n",
      "2018-05-04T18:42:18.471357: step 16401, loss 0.261416, acc 0.90625\n",
      "2018-05-04T18:42:19.441767: step 16402, loss 0.257536, acc 0.890625\n",
      "2018-05-04T18:42:20.422256: step 16403, loss 0.235937, acc 0.90625\n",
      "2018-05-04T18:42:21.468751: step 16404, loss 0.246194, acc 0.90625\n",
      "2018-05-04T18:42:22.414371: step 16405, loss 0.173688, acc 0.953125\n",
      "2018-05-04T18:42:23.362979: step 16406, loss 0.178286, acc 0.953125\n",
      "2018-05-04T18:42:24.315639: step 16407, loss 0.286543, acc 0.859375\n",
      "2018-05-04T18:42:25.251721: step 16408, loss 0.278552, acc 0.8125\n",
      "2018-05-04T18:42:26.236029: step 16409, loss 0.238216, acc 0.890625\n",
      "2018-05-04T18:42:27.178643: step 16410, loss 0.234007, acc 0.90625\n",
      "2018-05-04T18:42:28.155458: step 16411, loss 0.25061, acc 0.921875\n",
      "2018-05-04T18:42:29.119069: step 16412, loss 0.26535, acc 0.90625\n",
      "2018-05-04T18:42:30.171968: step 16413, loss 0.379133, acc 0.859375\n",
      "2018-05-04T18:42:31.125019: step 16414, loss 0.424668, acc 0.859375\n",
      "2018-05-04T18:42:32.083414: step 16415, loss 0.221151, acc 0.890625\n",
      "2018-05-04T18:42:33.074445: step 16416, loss 0.26863, acc 0.875\n",
      "2018-05-04T18:42:34.048384: step 16417, loss 0.266705, acc 0.859375\n",
      "2018-05-04T18:42:35.007938: step 16418, loss 0.294582, acc 0.84375\n",
      "2018-05-04T18:42:35.965468: step 16419, loss 0.261089, acc 0.921875\n",
      "2018-05-04T18:42:37.002676: step 16420, loss 0.258454, acc 0.9375\n",
      "2018-05-04T18:42:37.941145: step 16421, loss 0.231001, acc 0.90625\n",
      "2018-05-04T18:42:38.970617: step 16422, loss 0.224661, acc 0.9375\n",
      "2018-05-04T18:42:39.921793: step 16423, loss 0.219753, acc 0.890625\n",
      "2018-05-04T18:42:40.884572: step 16424, loss 0.219849, acc 0.9375\n",
      "2018-05-04T18:42:41.859627: step 16425, loss 0.200727, acc 0.953125\n",
      "2018-05-04T18:42:42.793206: step 16426, loss 0.495532, acc 0.765625\n",
      "2018-05-04T18:42:43.741371: step 16427, loss 0.334656, acc 0.859375\n",
      "2018-05-04T18:42:44.695056: step 16428, loss 0.287337, acc 0.921875\n",
      "2018-05-04T18:42:45.669309: step 16429, loss 0.156618, acc 0.921875\n",
      "2018-05-04T18:42:46.637202: step 16430, loss 0.241354, acc 0.875\n",
      "2018-05-04T18:42:47.613545: step 16431, loss 0.256276, acc 0.90625\n",
      "2018-05-04T18:42:48.553761: step 16432, loss 0.266269, acc 0.859375\n",
      "2018-05-04T18:42:49.510371: step 16433, loss 0.239676, acc 0.890625\n",
      "2018-05-04T18:42:50.456746: step 16434, loss 0.290746, acc 0.890625\n",
      "2018-05-04T18:42:51.403744: step 16435, loss 0.344816, acc 0.859375\n",
      "2018-05-04T18:42:52.354977: step 16436, loss 0.18497, acc 0.9375\n",
      "2018-05-04T18:42:53.307853: step 16437, loss 0.31079, acc 0.90625\n",
      "2018-05-04T18:42:54.271400: step 16438, loss 0.17157, acc 0.953125\n",
      "2018-05-04T18:42:55.333296: step 16439, loss 0.195713, acc 0.890625\n",
      "2018-05-04T18:42:56.287770: step 16440, loss 0.380939, acc 0.90625\n",
      "2018-05-04T18:42:57.260643: step 16441, loss 0.233089, acc 0.90625\n",
      "2018-05-04T18:42:58.213600: step 16442, loss 0.344615, acc 0.875\n",
      "2018-05-04T18:42:59.171119: step 16443, loss 0.215083, acc 0.921875\n",
      "2018-05-04T18:43:00.114734: step 16444, loss 0.270685, acc 0.90625\n",
      "2018-05-04T18:43:01.085854: step 16445, loss 0.282083, acc 0.90625\n",
      "2018-05-04T18:43:02.047157: step 16446, loss 0.307278, acc 0.875\n",
      "2018-05-04T18:43:03.033626: step 16447, loss 0.235092, acc 0.90625\n",
      "2018-05-04T18:43:03.984565: step 16448, loss 0.129188, acc 0.96875\n",
      "2018-05-04T18:43:04.992796: step 16449, loss 0.38138, acc 0.828125\n",
      "2018-05-04T18:43:05.944815: step 16450, loss 0.240806, acc 0.9375\n",
      "2018-05-04T18:43:06.897033: step 16451, loss 0.261255, acc 0.890625\n",
      "2018-05-04T18:43:07.841405: step 16452, loss 0.363309, acc 0.859375\n",
      "2018-05-04T18:43:08.784448: step 16453, loss 0.228673, acc 0.9375\n",
      "2018-05-04T18:43:09.723896: step 16454, loss 0.287745, acc 0.875\n",
      "2018-05-04T18:43:10.675354: step 16455, loss 0.208746, acc 0.890625\n",
      "2018-05-04T18:43:11.628096: step 16456, loss 0.326657, acc 0.875\n",
      "2018-05-04T18:43:12.577567: step 16457, loss 0.26376, acc 0.875\n",
      "2018-05-04T18:43:13.542413: step 16458, loss 0.211242, acc 0.9375\n",
      "2018-05-04T18:43:14.555435: step 16459, loss 0.333475, acc 0.90625\n",
      "2018-05-04T18:43:15.558675: step 16460, loss 0.365105, acc 0.859375\n",
      "2018-05-04T18:43:16.517884: step 16461, loss 0.358626, acc 0.8125\n",
      "2018-05-04T18:43:17.512956: step 16462, loss 0.308601, acc 0.875\n",
      "2018-05-04T18:43:18.446308: step 16463, loss 0.192844, acc 0.921875\n",
      "2018-05-04T18:43:19.394972: step 16464, loss 0.275663, acc 0.921875\n",
      "2018-05-04T18:43:20.357645: step 16465, loss 0.173433, acc 0.953125\n",
      "2018-05-04T18:43:21.322726: step 16466, loss 0.237952, acc 0.921875\n",
      "2018-05-04T18:43:22.268230: step 16467, loss 0.244003, acc 0.875\n",
      "2018-05-04T18:43:23.211539: step 16468, loss 0.227078, acc 0.90625\n",
      "2018-05-04T18:43:24.164800: step 16469, loss 0.303184, acc 0.90625\n",
      "2018-05-04T18:43:25.108178: step 16470, loss 0.183597, acc 0.9375\n",
      "2018-05-04T18:43:26.062853: step 16471, loss 0.278462, acc 0.875\n",
      "2018-05-04T18:43:27.001897: step 16472, loss 0.260729, acc 0.890625\n",
      "2018-05-04T18:43:27.934808: step 16473, loss 0.256748, acc 0.875\n",
      "2018-05-04T18:43:28.892736: step 16474, loss 0.326963, acc 0.859375\n",
      "2018-05-04T18:43:29.853795: step 16475, loss 0.346916, acc 0.875\n",
      "2018-05-04T18:43:30.883454: step 16476, loss 0.230948, acc 0.9375\n",
      "2018-05-04T18:43:31.814969: step 16477, loss 0.157859, acc 0.90625\n",
      "2018-05-04T18:43:32.787390: step 16478, loss 0.142662, acc 0.953125\n",
      "2018-05-04T18:43:33.795384: step 16479, loss 0.275042, acc 0.875\n",
      "2018-05-04T18:43:34.928699: step 16480, loss 0.288053, acc 0.890625\n",
      "2018-05-04T18:43:36.089043: step 16481, loss 0.318169, acc 0.859375\n",
      "2018-05-04T18:43:37.130705: step 16482, loss 0.287149, acc 0.875\n",
      "2018-05-04T18:43:38.075865: step 16483, loss 0.432078, acc 0.828125\n",
      "2018-05-04T18:43:39.003407: step 16484, loss 0.237792, acc 0.890625\n",
      "2018-05-04T18:43:39.932667: step 16485, loss 0.219387, acc 0.921875\n",
      "2018-05-04T18:43:40.924224: step 16486, loss 0.18106, acc 0.9375\n",
      "2018-05-04T18:43:41.912494: step 16487, loss 0.335442, acc 0.859375\n",
      "2018-05-04T18:43:42.888371: step 16488, loss 0.231552, acc 0.90625\n",
      "2018-05-04T18:43:43.853580: step 16489, loss 0.30095, acc 0.875\n",
      "2018-05-04T18:43:44.842570: step 16490, loss 0.412353, acc 0.859375\n",
      "2018-05-04T18:43:45.897452: step 16491, loss 0.257491, acc 0.84375\n",
      "2018-05-04T18:43:46.832130: step 16492, loss 0.0868156, acc 0.984375\n",
      "2018-05-04T18:43:47.867422: step 16493, loss 0.197256, acc 0.890625\n",
      "2018-05-04T18:43:48.796350: step 16494, loss 0.271115, acc 0.859375\n",
      "2018-05-04T18:43:49.722751: step 16495, loss 0.218263, acc 0.90625\n",
      "2018-05-04T18:43:50.652521: step 16496, loss 0.355525, acc 0.875\n",
      "2018-05-04T18:43:51.601007: step 16497, loss 0.213927, acc 0.921875\n",
      "2018-05-04T18:43:52.567110: step 16498, loss 0.233015, acc 0.890625\n",
      "2018-05-04T18:43:53.539025: step 16499, loss 0.360308, acc 0.875\n",
      "2018-05-04T18:43:54.505905: step 16500, loss 0.458244, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T18:43:56.803639: step 16500, loss 0.23468, acc 0.922\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-16500\n",
      "\n",
      "2018-05-04T18:43:57.900324: step 16501, loss 0.320272, acc 0.828125\n",
      "2018-05-04T18:43:58.916502: step 16502, loss 0.179223, acc 0.921875\n",
      "2018-05-04T18:44:00.027523: step 16503, loss 0.204752, acc 0.921875\n",
      "2018-05-04T18:44:01.045552: step 16504, loss 0.213813, acc 0.9375\n",
      "2018-05-04T18:44:02.079751: step 16505, loss 0.178186, acc 0.921875\n",
      "2018-05-04T18:44:03.109398: step 16506, loss 0.255928, acc 0.921875\n",
      "2018-05-04T18:44:04.138001: step 16507, loss 0.261434, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T18:44:05.166260: step 16508, loss 0.314214, acc 0.859375\n",
      "2018-05-04T18:44:06.142053: step 16509, loss 0.243683, acc 0.90625\n",
      "2018-05-04T18:44:07.197330: step 16510, loss 0.322079, acc 0.875\n",
      "2018-05-04T18:44:08.134901: step 16511, loss 0.303237, acc 0.859375\n",
      "2018-05-04T18:44:09.099956: step 16512, loss 0.22069, acc 0.90625\n",
      "2018-05-04T18:44:10.090626: step 16513, loss 0.21222, acc 0.90625\n",
      "2018-05-04T18:44:11.056763: step 16514, loss 0.253216, acc 0.90625\n",
      "2018-05-04T18:44:12.015288: step 16515, loss 0.176333, acc 0.953125\n",
      "2018-05-04T18:44:13.075713: step 16516, loss 0.234618, acc 0.890625\n",
      "2018-05-04T18:44:14.045677: step 16517, loss 0.259367, acc 0.90625\n",
      "2018-05-04T18:44:15.053452: step 16518, loss 0.266788, acc 0.859375\n",
      "2018-05-04T18:44:16.114282: step 16519, loss 0.330138, acc 0.859375\n",
      "2018-05-04T18:44:17.067925: step 16520, loss 0.276498, acc 0.9375\n",
      "2018-05-04T18:44:17.994676: step 16521, loss 0.248974, acc 0.90625\n",
      "2018-05-04T18:44:18.949694: step 16522, loss 0.239026, acc 0.90625\n",
      "2018-05-04T18:44:19.913044: step 16523, loss 0.284793, acc 0.875\n",
      "2018-05-04T18:44:20.868909: step 16524, loss 0.263854, acc 0.90625\n",
      "2018-05-04T18:44:21.845940: step 16525, loss 0.442155, acc 0.734375\n",
      "2018-05-04T18:44:22.829150: step 16526, loss 0.26553, acc 0.9375\n",
      "2018-05-04T18:44:23.827655: step 16527, loss 0.240117, acc 0.921875\n",
      "2018-05-04T18:44:24.796018: step 16528, loss 0.208008, acc 0.921875\n",
      "2018-05-04T18:44:25.796324: step 16529, loss 0.173643, acc 0.921875\n",
      "2018-05-04T18:44:26.783684: step 16530, loss 0.22345, acc 0.9375\n",
      "2018-05-04T18:44:27.745758: step 16531, loss 0.256079, acc 0.875\n",
      "2018-05-04T18:44:28.720866: step 16532, loss 0.300333, acc 0.875\n",
      "2018-05-04T18:44:29.750637: step 16533, loss 0.370518, acc 0.828125\n",
      "2018-05-04T18:44:30.749483: step 16534, loss 0.215996, acc 0.90625\n",
      "2018-05-04T18:44:31.690779: step 16535, loss 0.347408, acc 0.796875\n",
      "2018-05-04T18:44:32.638480: step 16536, loss 0.348567, acc 0.890625\n",
      "2018-05-04T18:44:33.599075: step 16537, loss 0.267536, acc 0.875\n",
      "2018-05-04T18:44:34.692475: step 16538, loss 0.171714, acc 0.921875\n",
      "2018-05-04T18:44:35.739424: step 16539, loss 0.289715, acc 0.859375\n",
      "2018-05-04T18:44:36.695581: step 16540, loss 0.112068, acc 0.984375\n",
      "2018-05-04T18:44:37.647071: step 16541, loss 0.27658, acc 0.859375\n",
      "2018-05-04T18:44:38.603032: step 16542, loss 0.329739, acc 0.875\n",
      "2018-05-04T18:44:39.548369: step 16543, loss 0.183616, acc 0.9375\n",
      "2018-05-04T18:44:40.598091: step 16544, loss 0.381244, acc 0.859375\n",
      "2018-05-04T18:44:41.566681: step 16545, loss 0.329085, acc 0.84375\n",
      "2018-05-04T18:44:42.528096: step 16546, loss 0.184249, acc 0.921875\n",
      "2018-05-04T18:44:43.514052: step 16547, loss 0.201881, acc 0.9375\n",
      "2018-05-04T18:44:44.509849: step 16548, loss 0.431275, acc 0.84375\n",
      "2018-05-04T18:44:45.558228: step 16549, loss 0.372958, acc 0.875\n",
      "2018-05-04T18:44:46.522896: step 16550, loss 0.217712, acc 0.90625\n",
      "2018-05-04T18:44:47.497799: step 16551, loss 0.317089, acc 0.890625\n",
      "2018-05-04T18:44:48.528465: step 16552, loss 0.251009, acc 0.859375\n",
      "2018-05-04T18:44:49.494644: step 16553, loss 0.206526, acc 0.9375\n",
      "2018-05-04T18:44:50.481844: step 16554, loss 0.133802, acc 0.9375\n",
      "2018-05-04T18:44:51.520030: step 16555, loss 0.318273, acc 0.875\n",
      "2018-05-04T18:44:52.524640: step 16556, loss 0.138771, acc 0.96875\n",
      "2018-05-04T18:44:53.518108: step 16557, loss 0.256715, acc 0.890625\n",
      "2018-05-04T18:44:54.510332: step 16558, loss 0.252961, acc 0.890625\n",
      "2018-05-04T18:44:55.550116: step 16559, loss 0.15013, acc 0.96875\n",
      "2018-05-04T18:44:56.550675: step 16560, loss 0.191106, acc 0.90625\n",
      "2018-05-04T18:44:57.500342: step 16561, loss 0.252192, acc 0.84375\n",
      "2018-05-04T18:44:58.470073: step 16562, loss 0.165902, acc 0.953125\n",
      "2018-05-04T18:44:59.436564: step 16563, loss 0.34593, acc 0.890625\n",
      "2018-05-04T18:45:00.418539: step 16564, loss 0.381778, acc 0.84375\n",
      "2018-05-04T18:45:01.483324: step 16565, loss 0.27417, acc 0.84375\n",
      "2018-05-04T18:45:02.496296: step 16566, loss 0.306267, acc 0.875\n",
      "2018-05-04T18:45:03.460366: step 16567, loss 0.2521, acc 0.90625\n",
      "2018-05-04T18:45:04.431273: step 16568, loss 0.218456, acc 0.921875\n",
      "2018-05-04T18:45:05.398364: step 16569, loss 0.269172, acc 0.90625\n",
      "2018-05-04T18:45:06.350204: step 16570, loss 0.457363, acc 0.8125\n",
      "2018-05-04T18:45:07.312959: step 16571, loss 0.292655, acc 0.90625\n",
      "2018-05-04T18:45:08.268100: step 16572, loss 0.293495, acc 0.859375\n",
      "2018-05-04T18:45:09.237187: step 16573, loss 0.198771, acc 0.921875\n",
      "2018-05-04T18:45:10.168416: step 16574, loss 0.294848, acc 0.90625\n",
      "2018-05-04T18:45:11.144757: step 16575, loss 0.477145, acc 0.8125\n",
      "2018-05-04T18:45:12.127415: step 16576, loss 0.341285, acc 0.90625\n",
      "2018-05-04T18:45:13.115560: step 16577, loss 0.321741, acc 0.84375\n",
      "2018-05-04T18:45:14.093844: step 16578, loss 0.194713, acc 0.921875\n",
      "2018-05-04T18:45:15.072103: step 16579, loss 0.299363, acc 0.859375\n",
      "2018-05-04T18:45:16.043402: step 16580, loss 0.323301, acc 0.828125\n",
      "2018-05-04T18:45:17.009133: step 16581, loss 0.24002, acc 0.875\n",
      "2018-05-04T18:45:17.984417: step 16582, loss 0.353695, acc 0.875\n",
      "2018-05-04T18:45:18.948353: step 16583, loss 0.154172, acc 0.953125\n",
      "2018-05-04T18:45:19.996558: step 16584, loss 0.188501, acc 0.9375\n",
      "2018-05-04T18:45:20.955740: step 16585, loss 0.338325, acc 0.828125\n",
      "2018-05-04T18:45:22.007110: step 16586, loss 0.216929, acc 0.921875\n",
      "2018-05-04T18:45:22.973801: step 16587, loss 0.233895, acc 0.875\n",
      "2018-05-04T18:45:23.928606: step 16588, loss 0.323076, acc 0.90625\n",
      "2018-05-04T18:45:24.866454: step 16589, loss 0.294377, acc 0.890625\n",
      "2018-05-04T18:45:25.826243: step 16590, loss 0.317444, acc 0.828125\n",
      "2018-05-04T18:45:26.765555: step 16591, loss 0.249758, acc 0.875\n",
      "2018-05-04T18:45:27.704289: step 16592, loss 0.203012, acc 0.890625\n",
      "2018-05-04T18:45:28.661137: step 16593, loss 0.425377, acc 0.78125\n",
      "2018-05-04T18:45:29.614740: step 16594, loss 0.207536, acc 0.875\n",
      "2018-05-04T18:45:30.565343: step 16595, loss 0.237192, acc 0.890625\n",
      "2018-05-04T18:45:31.527042: step 16596, loss 0.260192, acc 0.875\n",
      "2018-05-04T18:45:32.543506: step 16597, loss 0.163038, acc 0.9375\n",
      "2018-05-04T18:45:33.500323: step 16598, loss 0.294498, acc 0.84375\n",
      "2018-05-04T18:45:34.493821: step 16599, loss 0.312818, acc 0.890625\n",
      "2018-05-04T18:45:35.457845: step 16600, loss 0.255063, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T18:45:37.806972: step 16600, loss 0.229401, acc 0.922\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-16600\n",
      "\n",
      "2018-05-04T18:45:38.895888: step 16601, loss 0.218715, acc 0.921875\n",
      "2018-05-04T18:45:39.884929: step 16602, loss 0.290397, acc 0.875\n",
      "2018-05-04T18:45:40.927421: step 16603, loss 0.342117, acc 0.828125\n",
      "2018-05-04T18:45:41.935926: step 16604, loss 0.285393, acc 0.875\n",
      "2018-05-04T18:45:42.952794: step 16605, loss 0.212435, acc 0.9375\n",
      "2018-05-04T18:45:44.034386: step 16606, loss 0.284448, acc 0.890625\n",
      "2018-05-04T18:45:45.010534: step 16607, loss 0.243266, acc 0.890625\n",
      "2018-05-04T18:45:45.996162: step 16608, loss 0.26346, acc 0.84375\n",
      "2018-05-04T18:45:47.067264: step 16609, loss 0.202809, acc 0.921875\n",
      "2018-05-04T18:45:48.044704: step 16610, loss 0.233339, acc 0.875\n",
      "2018-05-04T18:45:49.020600: step 16611, loss 0.29698, acc 0.859375\n",
      "2018-05-04T18:45:49.991743: step 16612, loss 0.274989, acc 0.890625\n",
      "2018-05-04T18:45:50.934486: step 16613, loss 0.162314, acc 0.9375\n",
      "2018-05-04T18:45:51.995584: step 16614, loss 0.209709, acc 0.890625\n",
      "2018-05-04T18:45:52.979742: step 16615, loss 0.262547, acc 0.859375\n",
      "2018-05-04T18:45:53.968097: step 16616, loss 0.32788, acc 0.828125\n",
      "2018-05-04T18:45:54.942947: step 16617, loss 0.243156, acc 0.890625\n",
      "2018-05-04T18:45:55.913546: step 16618, loss 0.263043, acc 0.90625\n",
      "2018-05-04T18:45:56.883955: step 16619, loss 0.202645, acc 0.90625\n",
      "2018-05-04T18:45:57.842915: step 16620, loss 0.296401, acc 0.875\n",
      "2018-05-04T18:45:58.810613: step 16621, loss 0.25277, acc 0.90625\n",
      "2018-05-04T18:45:59.789968: step 16622, loss 0.428987, acc 0.8125\n",
      "2018-05-04T18:46:00.822894: step 16623, loss 0.171259, acc 0.921875\n",
      "2018-05-04T18:46:01.842088: step 16624, loss 0.236982, acc 0.890625\n",
      "2018-05-04T18:46:02.877704: step 16625, loss 0.497229, acc 0.890625\n",
      "2018-05-04T18:46:03.934557: step 16626, loss 0.154849, acc 0.9375\n",
      "2018-05-04T18:46:04.928747: step 16627, loss 0.155708, acc 0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T18:46:05.906532: step 16628, loss 0.224964, acc 0.859375\n",
      "2018-05-04T18:46:06.872898: step 16629, loss 0.141928, acc 0.953125\n",
      "2018-05-04T18:46:07.844038: step 16630, loss 0.315458, acc 0.875\n",
      "2018-05-04T18:46:08.797098: step 16631, loss 0.409054, acc 0.828125\n",
      "2018-05-04T18:46:09.773050: step 16632, loss 0.146831, acc 0.953125\n",
      "2018-05-04T18:46:10.760423: step 16633, loss 0.192265, acc 0.921875\n",
      "2018-05-04T18:46:11.719533: step 16634, loss 0.388989, acc 0.84375\n",
      "2018-05-04T18:46:12.674206: step 16635, loss 0.288363, acc 0.890625\n",
      "2018-05-04T18:46:13.651047: step 16636, loss 0.283508, acc 0.875\n",
      "2018-05-04T18:46:14.608518: step 16637, loss 0.34073, acc 0.859375\n",
      "2018-05-04T18:46:15.608924: step 16638, loss 0.272894, acc 0.875\n",
      "2018-05-04T18:46:16.587311: step 16639, loss 0.24976, acc 0.890625\n",
      "2018-05-04T18:46:17.585969: step 16640, loss 0.149478, acc 0.9375\n",
      "2018-05-04T18:46:18.614902: step 16641, loss 0.167916, acc 0.9375\n",
      "2018-05-04T18:46:19.682739: step 16642, loss 0.25296, acc 0.859375\n",
      "2018-05-04T18:46:20.645899: step 16643, loss 0.235906, acc 0.875\n",
      "2018-05-04T18:46:21.616020: step 16644, loss 0.263096, acc 0.890625\n",
      "2018-05-04T18:46:22.586363: step 16645, loss 0.306598, acc 0.84375\n",
      "2018-05-04T18:46:23.587428: step 16646, loss 0.183026, acc 0.9375\n",
      "2018-05-04T18:46:24.575609: step 16647, loss 0.267926, acc 0.84375\n",
      "2018-05-04T18:46:25.572519: step 16648, loss 0.195563, acc 0.953125\n",
      "2018-05-04T18:46:26.563764: step 16649, loss 0.100808, acc 0.984375\n",
      "2018-05-04T18:46:27.540011: step 16650, loss 0.282806, acc 0.921875\n",
      "2018-05-04T18:46:28.607624: step 16651, loss 0.375233, acc 0.859375\n",
      "2018-05-04T18:46:29.560532: step 16652, loss 0.354239, acc 0.875\n",
      "2018-05-04T18:46:30.518863: step 16653, loss 0.218664, acc 0.90625\n",
      "2018-05-04T18:46:31.501976: step 16654, loss 0.287812, acc 0.90625\n",
      "2018-05-04T18:46:32.465289: step 16655, loss 0.231505, acc 0.90625\n",
      "2018-05-04T18:46:33.492331: step 16656, loss 0.194518, acc 0.921875\n",
      "2018-05-04T18:46:34.536657: step 16657, loss 0.1558, acc 0.9375\n",
      "2018-05-04T18:46:35.582719: step 16658, loss 0.186294, acc 0.9375\n",
      "2018-05-04T18:46:36.611329: step 16659, loss 0.352957, acc 0.90625\n",
      "2018-05-04T18:46:37.609638: step 16660, loss 0.329534, acc 0.890625\n",
      "2018-05-04T18:46:38.599007: step 16661, loss 0.210034, acc 0.890625\n",
      "2018-05-04T18:46:39.577659: step 16662, loss 0.448317, acc 0.8125\n",
      "2018-05-04T18:46:40.620718: step 16663, loss 0.141167, acc 0.96875\n",
      "2018-05-04T18:46:41.583452: step 16664, loss 0.378197, acc 0.859375\n",
      "2018-05-04T18:46:42.537717: step 16665, loss 0.202928, acc 0.890625\n",
      "2018-05-04T18:46:43.534921: step 16666, loss 0.222402, acc 0.90625\n",
      "2018-05-04T18:46:44.487081: step 16667, loss 0.382203, acc 0.859375\n",
      "2018-05-04T18:46:45.460850: step 16668, loss 0.283269, acc 0.9375\n",
      "2018-05-04T18:46:46.424016: step 16669, loss 0.338158, acc 0.859375\n",
      "2018-05-04T18:46:47.393908: step 16670, loss 0.377661, acc 0.78125\n",
      "2018-05-04T18:46:48.354049: step 16671, loss 0.274767, acc 0.859375\n",
      "2018-05-04T18:46:49.409801: step 16672, loss 0.314551, acc 0.8125\n",
      "2018-05-04T18:46:50.389777: step 16673, loss 0.234014, acc 0.90625\n",
      "2018-05-04T18:46:51.373079: step 16674, loss 0.20313, acc 0.921875\n",
      "2018-05-04T18:46:52.365299: step 16675, loss 0.384821, acc 0.84375\n",
      "2018-05-04T18:46:53.349257: step 16676, loss 0.237217, acc 0.90625\n",
      "2018-05-04T18:46:54.333738: step 16677, loss 0.189687, acc 0.90625\n",
      "2018-05-04T18:46:55.292732: step 16678, loss 0.306312, acc 0.828125\n",
      "2018-05-04T18:46:56.240123: step 16679, loss 0.232213, acc 0.890625\n",
      "2018-05-04T18:46:57.193944: step 16680, loss 0.323172, acc 0.90625\n",
      "2018-05-04T18:46:58.171047: step 16681, loss 0.221361, acc 0.90625\n",
      "2018-05-04T18:46:59.155386: step 16682, loss 0.363522, acc 0.875\n",
      "2018-05-04T18:47:00.166280: step 16683, loss 0.430522, acc 0.875\n",
      "2018-05-04T18:47:01.108771: step 16684, loss 0.222828, acc 0.9375\n",
      "2018-05-04T18:47:02.054561: step 16685, loss 0.36076, acc 0.890625\n",
      "2018-05-04T18:47:03.042440: step 16686, loss 0.384139, acc 0.84375\n",
      "2018-05-04T18:47:04.035723: step 16687, loss 0.275907, acc 0.890625\n",
      "2018-05-04T18:47:05.090464: step 16688, loss 0.393849, acc 0.796875\n",
      "2018-05-04T18:47:06.053459: step 16689, loss 0.340304, acc 0.890625\n",
      "2018-05-04T18:47:07.007538: step 16690, loss 0.301429, acc 0.859375\n",
      "2018-05-04T18:47:07.959696: step 16691, loss 0.188717, acc 0.921875\n",
      "2018-05-04T18:47:08.915569: step 16692, loss 0.156738, acc 0.96875\n",
      "2018-05-04T18:47:09.872043: step 16693, loss 0.299041, acc 0.8125\n",
      "2018-05-04T18:47:10.862044: step 16694, loss 0.257037, acc 0.890625\n",
      "2018-05-04T18:47:11.866365: step 16695, loss 0.218596, acc 0.921875\n",
      "2018-05-04T18:47:12.825339: step 16696, loss 0.337641, acc 0.84375\n",
      "2018-05-04T18:47:13.835873: step 16697, loss 0.43403, acc 0.859375\n",
      "2018-05-04T18:47:14.823012: step 16698, loss 0.357601, acc 0.84375\n",
      "2018-05-04T18:47:15.814347: step 16699, loss 0.440616, acc 0.84375\n",
      "2018-05-04T18:47:16.760913: step 16700, loss 0.142888, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T18:47:19.215552: step 16700, loss 0.226915, acc 0.932\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-16700\n",
      "\n",
      "2018-05-04T18:47:20.321331: step 16701, loss 0.235019, acc 0.921875\n",
      "2018-05-04T18:47:21.333602: step 16702, loss 0.215829, acc 0.921875\n",
      "2018-05-04T18:47:22.366591: step 16703, loss 0.180599, acc 0.9375\n",
      "2018-05-04T18:47:23.387071: step 16704, loss 0.258486, acc 0.859375\n",
      "2018-05-04T18:47:24.398059: step 16705, loss 0.193835, acc 0.90625\n",
      "2018-05-04T18:47:25.399612: step 16706, loss 0.165908, acc 0.921875\n",
      "2018-05-04T18:47:26.422684: step 16707, loss 0.319173, acc 0.84375\n",
      "2018-05-04T18:47:27.488510: step 16708, loss 0.19653, acc 0.90625\n",
      "2018-05-04T18:47:28.576120: step 16709, loss 0.16431, acc 0.96875\n",
      "2018-05-04T18:47:29.549797: step 16710, loss 0.276887, acc 0.921875\n",
      "2018-05-04T18:47:30.536075: step 16711, loss 0.193016, acc 0.96875\n",
      "2018-05-04T18:47:31.558315: step 16712, loss 0.370621, acc 0.828125\n",
      "2018-05-04T18:47:32.574249: step 16713, loss 0.223677, acc 0.90625\n",
      "2018-05-04T18:47:33.559976: step 16714, loss 0.293041, acc 0.875\n",
      "2018-05-04T18:47:34.600580: step 16715, loss 0.174554, acc 0.90625\n",
      "2018-05-04T18:47:35.648172: step 16716, loss 0.221395, acc 0.9375\n",
      "2018-05-04T18:47:36.636798: step 16717, loss 0.402551, acc 0.828125\n",
      "2018-05-04T18:47:37.577329: step 16718, loss 0.14058, acc 0.953125\n",
      "2018-05-04T18:47:38.548186: step 16719, loss 0.295159, acc 0.90625\n",
      "2018-05-04T18:47:39.513555: step 16720, loss 0.275025, acc 0.875\n",
      "2018-05-04T18:47:40.520249: step 16721, loss 0.300182, acc 0.875\n",
      "2018-05-04T18:47:41.528872: step 16722, loss 0.192937, acc 0.90625\n",
      "2018-05-04T18:47:42.519432: step 16723, loss 0.106325, acc 0.96875\n",
      "2018-05-04T18:47:43.516295: step 16724, loss 0.149744, acc 0.9375\n",
      "2018-05-04T18:47:44.501800: step 16725, loss 0.252062, acc 0.90625\n",
      "2018-05-04T18:47:45.513032: step 16726, loss 0.329747, acc 0.875\n",
      "2018-05-04T18:47:46.478729: step 16727, loss 0.295074, acc 0.875\n",
      "2018-05-04T18:47:47.457245: step 16728, loss 0.212556, acc 0.90625\n",
      "2018-05-04T18:47:48.411440: step 16729, loss 0.185535, acc 0.921875\n",
      "2018-05-04T18:47:49.368484: step 16730, loss 0.207015, acc 0.90625\n",
      "2018-05-04T18:47:50.342115: step 16731, loss 0.265076, acc 0.921875\n",
      "2018-05-04T18:47:51.311400: step 16732, loss 0.145427, acc 0.9375\n",
      "2018-05-04T18:47:52.359174: step 16733, loss 0.172292, acc 0.9375\n",
      "2018-05-04T18:47:53.339198: step 16734, loss 0.279597, acc 0.875\n",
      "2018-05-04T18:47:54.355644: step 16735, loss 0.22366, acc 0.90625\n",
      "2018-05-04T18:47:55.318996: step 16736, loss 0.305869, acc 0.828125\n",
      "2018-05-04T18:47:56.292706: step 16737, loss 0.285661, acc 0.890625\n",
      "2018-05-04T18:47:57.262644: step 16738, loss 0.20182, acc 0.953125\n",
      "2018-05-04T18:47:58.235538: step 16739, loss 0.208761, acc 0.890625\n",
      "2018-05-04T18:47:59.218466: step 16740, loss 0.377995, acc 0.859375\n",
      "2018-05-04T18:48:00.183446: step 16741, loss 0.21001, acc 0.921875\n",
      "2018-05-04T18:48:01.161716: step 16742, loss 0.149022, acc 0.953125\n",
      "2018-05-04T18:48:02.155027: step 16743, loss 0.297076, acc 0.875\n",
      "2018-05-04T18:48:03.129095: step 16744, loss 0.197517, acc 0.9375\n",
      "2018-05-04T18:48:04.113232: step 16745, loss 0.522924, acc 0.859375\n",
      "2018-05-04T18:48:05.126754: step 16746, loss 0.253143, acc 0.859375\n",
      "2018-05-04T18:48:06.121824: step 16747, loss 0.365733, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T18:48:07.120700: step 16748, loss 0.312979, acc 0.890625\n",
      "2018-05-04T18:48:08.115868: step 16749, loss 0.204959, acc 0.890625\n",
      "2018-05-04T18:48:09.127810: step 16750, loss 0.242732, acc 0.90625\n",
      "2018-05-04T18:48:10.091538: step 16751, loss 0.195588, acc 0.9375\n",
      "2018-05-04T18:48:11.056894: step 16752, loss 0.358675, acc 0.828125\n",
      "2018-05-04T18:48:12.035091: step 16753, loss 0.277085, acc 0.890625\n",
      "2018-05-04T18:48:13.109612: step 16754, loss 0.306801, acc 0.921875\n",
      "2018-05-04T18:48:14.103928: step 16755, loss 0.351392, acc 0.828125\n",
      "2018-05-04T18:48:15.137200: step 16756, loss 0.185122, acc 0.953125\n",
      "2018-05-04T18:48:16.091633: step 16757, loss 0.235484, acc 0.890625\n",
      "2018-05-04T18:48:17.136491: step 16758, loss 0.260023, acc 0.859375\n",
      "2018-05-04T18:48:18.076971: step 16759, loss 0.411471, acc 0.875\n",
      "2018-05-04T18:48:19.026116: step 16760, loss 0.353278, acc 0.890625\n",
      "2018-05-04T18:48:19.985466: step 16761, loss 0.158149, acc 0.9375\n",
      "2018-05-04T18:48:20.955211: step 16762, loss 0.266618, acc 0.921875\n",
      "2018-05-04T18:48:21.941323: step 16763, loss 0.179498, acc 0.953125\n",
      "2018-05-04T18:48:22.991707: step 16764, loss 0.299626, acc 0.90625\n",
      "2018-05-04T18:48:24.009723: step 16765, loss 0.287983, acc 0.84375\n",
      "2018-05-04T18:48:24.961615: step 16766, loss 0.201798, acc 0.9375\n",
      "2018-05-04T18:48:25.916412: step 16767, loss 0.137214, acc 0.96875\n",
      "2018-05-04T18:48:26.947087: step 16768, loss 0.196191, acc 0.921875\n",
      "2018-05-04T18:48:27.913433: step 16769, loss 0.281356, acc 0.859375\n",
      "2018-05-04T18:48:28.870922: step 16770, loss 0.29732, acc 0.890625\n",
      "2018-05-04T18:48:29.911873: step 16771, loss 0.279469, acc 0.890625\n",
      "2018-05-04T18:48:30.863352: step 16772, loss 0.255514, acc 0.890625\n",
      "2018-05-04T18:48:31.873258: step 16773, loss 0.291412, acc 0.84375\n",
      "2018-05-04T18:48:32.883618: step 16774, loss 0.162635, acc 0.953125\n",
      "2018-05-04T18:48:33.845975: step 16775, loss 0.250793, acc 0.875\n",
      "2018-05-04T18:48:34.858183: step 16776, loss 0.256161, acc 0.859375\n",
      "2018-05-04T18:48:35.860987: step 16777, loss 0.241633, acc 0.890625\n",
      "2018-05-04T18:48:36.826563: step 16778, loss 0.248617, acc 0.875\n",
      "2018-05-04T18:48:37.879108: step 16779, loss 0.305118, acc 0.90625\n",
      "2018-05-04T18:48:38.923675: step 16780, loss 0.421497, acc 0.765625\n",
      "2018-05-04T18:48:39.885601: step 16781, loss 0.204399, acc 0.90625\n",
      "2018-05-04T18:48:40.849006: step 16782, loss 0.327534, acc 0.9375\n",
      "2018-05-04T18:48:41.830613: step 16783, loss 0.204382, acc 0.90625\n",
      "2018-05-04T18:48:42.802793: step 16784, loss 0.280842, acc 0.875\n",
      "2018-05-04T18:48:43.770669: step 16785, loss 0.222903, acc 0.921875\n",
      "2018-05-04T18:48:44.749156: step 16786, loss 0.346122, acc 0.890625\n",
      "2018-05-04T18:48:45.710795: step 16787, loss 0.179561, acc 0.921875\n",
      "2018-05-04T18:48:46.681057: step 16788, loss 0.243987, acc 0.890625\n",
      "2018-05-04T18:48:47.643777: step 16789, loss 0.216711, acc 0.890625\n",
      "2018-05-04T18:48:48.584613: step 16790, loss 0.147375, acc 0.96875\n",
      "2018-05-04T18:48:49.543150: step 16791, loss 0.291672, acc 0.84375\n",
      "2018-05-04T18:48:50.494050: step 16792, loss 0.191318, acc 0.90625\n",
      "2018-05-04T18:48:51.471414: step 16793, loss 0.197239, acc 0.90625\n",
      "2018-05-04T18:48:52.442592: step 16794, loss 0.148264, acc 0.9375\n",
      "2018-05-04T18:48:53.419730: step 16795, loss 0.235752, acc 0.90625\n",
      "2018-05-04T18:48:54.381361: step 16796, loss 0.333899, acc 0.84375\n",
      "2018-05-04T18:48:55.336653: step 16797, loss 0.157236, acc 0.96875\n",
      "2018-05-04T18:48:56.332226: step 16798, loss 0.19343, acc 0.953125\n",
      "2018-05-04T18:48:57.303655: step 16799, loss 0.283317, acc 0.875\n",
      "2018-05-04T18:48:58.385591: step 16800, loss 0.308883, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T18:49:00.538991: step 16800, loss 0.225864, acc 0.916\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-16800\n",
      "\n",
      "2018-05-04T18:49:01.582419: step 16801, loss 0.246382, acc 0.890625\n",
      "2018-05-04T18:49:02.566751: step 16802, loss 0.19432, acc 0.9375\n",
      "2018-05-04T18:49:03.535374: step 16803, loss 0.227248, acc 0.90625\n",
      "2018-05-04T18:49:04.594033: step 16804, loss 0.29586, acc 0.890625\n",
      "2018-05-04T18:49:05.534896: step 16805, loss 0.212069, acc 0.90625\n",
      "2018-05-04T18:49:06.494083: step 16806, loss 0.208467, acc 0.90625\n",
      "2018-05-04T18:49:07.457585: step 16807, loss 0.38466, acc 0.78125\n",
      "2018-05-04T18:49:08.412770: step 16808, loss 0.239606, acc 0.890625\n",
      "2018-05-04T18:49:09.391766: step 16809, loss 0.185418, acc 0.9375\n",
      "2018-05-04T18:49:10.361066: step 16810, loss 0.181581, acc 0.953125\n",
      "2018-05-04T18:49:11.332228: step 16811, loss 0.185426, acc 0.921875\n",
      "2018-05-04T18:49:12.287184: step 16812, loss 0.208976, acc 0.9375\n",
      "2018-05-04T18:49:13.256983: step 16813, loss 0.327229, acc 0.859375\n",
      "2018-05-04T18:49:14.255025: step 16814, loss 0.143672, acc 0.953125\n",
      "2018-05-04T18:49:15.230059: step 16815, loss 0.26726, acc 0.828125\n",
      "2018-05-04T18:49:16.196738: step 16816, loss 0.277854, acc 0.890625\n",
      "2018-05-04T18:49:17.155633: step 16817, loss 0.200536, acc 0.90625\n",
      "2018-05-04T18:49:18.174102: step 16818, loss 0.326073, acc 0.890625\n",
      "2018-05-04T18:49:19.110489: step 16819, loss 0.152477, acc 0.953125\n",
      "2018-05-04T18:49:20.134877: step 16820, loss 0.14089, acc 0.953125\n",
      "2018-05-04T18:49:21.080754: step 16821, loss 0.280869, acc 0.921875\n",
      "2018-05-04T18:49:22.023498: step 16822, loss 0.221986, acc 0.90625\n",
      "2018-05-04T18:49:22.972058: step 16823, loss 0.299439, acc 0.890625\n",
      "2018-05-04T18:49:23.925157: step 16824, loss 0.437253, acc 0.859375\n",
      "2018-05-04T18:49:24.896123: step 16825, loss 0.240909, acc 0.9375\n",
      "2018-05-04T18:49:25.868039: step 16826, loss 0.209254, acc 0.921875\n",
      "2018-05-04T18:49:26.832511: step 16827, loss 0.339098, acc 0.875\n",
      "2018-05-04T18:49:27.806807: step 16828, loss 0.205435, acc 0.890625\n",
      "2018-05-04T18:49:28.757570: step 16829, loss 0.253377, acc 0.875\n",
      "2018-05-04T18:49:29.700160: step 16830, loss 0.272111, acc 0.90625\n",
      "2018-05-04T18:49:30.634243: step 16831, loss 0.163367, acc 0.96875\n",
      "2018-05-04T18:49:31.579081: step 16832, loss 0.254659, acc 0.875\n",
      "2018-05-04T18:49:32.525530: step 16833, loss 0.369902, acc 0.859375\n",
      "2018-05-04T18:49:33.559254: step 16834, loss 0.214626, acc 0.890625\n",
      "2018-05-04T18:49:34.579459: step 16835, loss 0.300805, acc 0.859375\n",
      "2018-05-04T18:49:35.593685: step 16836, loss 0.257869, acc 0.90625\n",
      "2018-05-04T18:49:36.602823: step 16837, loss 0.349356, acc 0.8125\n",
      "2018-05-04T18:49:37.594940: step 16838, loss 0.222371, acc 0.90625\n",
      "2018-05-04T18:49:38.606024: step 16839, loss 0.324807, acc 0.875\n",
      "2018-05-04T18:49:39.572631: step 16840, loss 0.297576, acc 0.875\n",
      "2018-05-04T18:49:40.567699: step 16841, loss 0.329941, acc 0.875\n",
      "2018-05-04T18:49:41.542664: step 16842, loss 0.131194, acc 0.9375\n",
      "2018-05-04T18:49:42.486465: step 16843, loss 0.364353, acc 0.859375\n",
      "2018-05-04T18:49:43.442551: step 16844, loss 0.2494, acc 0.921875\n",
      "2018-05-04T18:49:44.376365: step 16845, loss 0.157426, acc 0.96875\n",
      "2018-05-04T18:49:45.337999: step 16846, loss 0.257665, acc 0.90625\n",
      "2018-05-04T18:49:46.317163: step 16847, loss 0.26275, acc 0.84375\n",
      "2018-05-04T18:49:47.281143: step 16848, loss 0.324283, acc 0.84375\n",
      "2018-05-04T18:49:48.233768: step 16849, loss 0.378001, acc 0.859375\n",
      "2018-05-04T18:49:49.181683: step 16850, loss 0.218089, acc 0.9375\n",
      "2018-05-04T18:49:50.187962: step 16851, loss 0.162042, acc 0.953125\n",
      "2018-05-04T18:49:51.129886: step 16852, loss 0.307988, acc 0.890625\n",
      "2018-05-04T18:49:52.074339: step 16853, loss 0.223522, acc 0.90625\n",
      "2018-05-04T18:49:53.019103: step 16854, loss 0.141447, acc 0.953125\n",
      "2018-05-04T18:49:53.970502: step 16855, loss 0.303994, acc 0.859375\n",
      "2018-05-04T18:49:54.907042: step 16856, loss 0.377142, acc 0.84375\n",
      "2018-05-04T18:49:55.870625: step 16857, loss 0.15953, acc 0.96875\n",
      "2018-05-04T18:49:56.850895: step 16858, loss 0.179634, acc 0.953125\n",
      "2018-05-04T18:49:57.809881: step 16859, loss 0.272119, acc 0.890625\n",
      "2018-05-04T18:49:58.821593: step 16860, loss 0.245208, acc 0.921875\n",
      "2018-05-04T18:49:59.858261: step 16861, loss 0.302711, acc 0.875\n",
      "2018-05-04T18:50:00.803968: step 16862, loss 0.282513, acc 0.84375\n",
      "2018-05-04T18:50:01.755727: step 16863, loss 0.191406, acc 0.9375\n",
      "2018-05-04T18:50:02.695804: step 16864, loss 0.293222, acc 0.859375\n",
      "2018-05-04T18:50:03.673863: step 16865, loss 0.253245, acc 0.890625\n",
      "2018-05-04T18:50:04.633821: step 16866, loss 0.130739, acc 0.953125\n",
      "2018-05-04T18:50:05.615842: step 16867, loss 0.254059, acc 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T18:50:06.573030: step 16868, loss 0.185302, acc 0.90625\n",
      "2018-05-04T18:50:07.523966: step 16869, loss 0.313707, acc 0.890625\n",
      "2018-05-04T18:50:08.468426: step 16870, loss 0.248944, acc 0.921875\n",
      "2018-05-04T18:50:09.428170: step 16871, loss 0.173664, acc 0.921875\n",
      "2018-05-04T18:50:10.367572: step 16872, loss 0.319016, acc 0.90625\n",
      "2018-05-04T18:50:11.337702: step 16873, loss 0.24351, acc 0.90625\n",
      "2018-05-04T18:50:12.283666: step 16874, loss 0.170584, acc 0.9375\n",
      "2018-05-04T18:50:13.231133: step 16875, loss 0.162057, acc 0.921875\n",
      "2018-05-04T18:50:14.191849: step 16876, loss 0.206411, acc 0.921875\n",
      "2018-05-04T18:50:15.223302: step 16877, loss 0.350431, acc 0.890625\n",
      "2018-05-04T18:50:16.182266: step 16878, loss 0.482708, acc 0.796875\n",
      "2018-05-04T18:50:17.125586: step 16879, loss 0.262447, acc 0.90625\n",
      "2018-05-04T18:50:18.067356: step 16880, loss 0.194759, acc 0.953125\n",
      "2018-05-04T18:50:19.100947: step 16881, loss 0.226169, acc 0.921875\n",
      "2018-05-04T18:50:20.082180: step 16882, loss 0.311972, acc 0.90625\n",
      "2018-05-04T18:50:21.054924: step 16883, loss 0.136138, acc 0.96875\n",
      "2018-05-04T18:50:22.023008: step 16884, loss 0.133902, acc 0.96875\n",
      "2018-05-04T18:50:22.974626: step 16885, loss 0.203437, acc 0.921875\n",
      "2018-05-04T18:50:23.976660: step 16886, loss 0.203908, acc 0.953125\n",
      "2018-05-04T18:50:24.918135: step 16887, loss 0.243454, acc 0.90625\n",
      "2018-05-04T18:50:25.895399: step 16888, loss 0.130032, acc 0.9375\n",
      "2018-05-04T18:50:26.851523: step 16889, loss 0.293946, acc 0.875\n",
      "2018-05-04T18:50:27.873532: step 16890, loss 0.244976, acc 0.84375\n",
      "2018-05-04T18:50:28.812340: step 16891, loss 0.269123, acc 0.859375\n",
      "2018-05-04T18:50:29.759766: step 16892, loss 0.13798, acc 0.984375\n",
      "2018-05-04T18:50:30.702481: step 16893, loss 0.320016, acc 0.890625\n",
      "2018-05-04T18:50:31.708815: step 16894, loss 0.303773, acc 0.921875\n",
      "2018-05-04T18:50:32.651231: step 16895, loss 0.183462, acc 0.9375\n",
      "2018-05-04T18:50:33.584468: step 16896, loss 0.266017, acc 0.90625\n",
      "2018-05-04T18:50:34.547069: step 16897, loss 0.176941, acc 0.9375\n",
      "2018-05-04T18:50:35.494954: step 16898, loss 0.164409, acc 0.921875\n",
      "2018-05-04T18:50:36.454642: step 16899, loss 0.185213, acc 0.921875\n",
      "2018-05-04T18:50:37.417604: step 16900, loss 0.368602, acc 0.828125\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T18:50:39.748760: step 16900, loss 0.230762, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-16900\n",
      "\n",
      "2018-05-04T18:50:40.829928: step 16901, loss 0.346293, acc 0.84375\n",
      "2018-05-04T18:50:41.924994: step 16902, loss 0.273222, acc 0.890625\n",
      "2018-05-04T18:50:42.965398: step 16903, loss 0.310292, acc 0.90625\n",
      "2018-05-04T18:50:44.006209: step 16904, loss 0.118574, acc 0.953125\n",
      "2018-05-04T18:50:45.014203: step 16905, loss 0.187923, acc 0.90625\n",
      "2018-05-04T18:50:46.042120: step 16906, loss 0.239373, acc 0.875\n",
      "2018-05-04T18:50:47.076049: step 16907, loss 0.181787, acc 0.9375\n",
      "2018-05-04T18:50:48.137371: step 16908, loss 0.166842, acc 0.9375\n",
      "2018-05-04T18:50:49.121970: step 16909, loss 0.239486, acc 0.875\n",
      "2018-05-04T18:50:50.077819: step 16910, loss 0.16303, acc 0.921875\n",
      "2018-05-04T18:50:51.051404: step 16911, loss 0.294457, acc 0.875\n",
      "2018-05-04T18:50:52.013966: step 16912, loss 0.189113, acc 0.921875\n",
      "2018-05-04T18:50:53.049968: step 16913, loss 0.214425, acc 0.921875\n",
      "2018-05-04T18:50:54.022533: step 16914, loss 0.341035, acc 0.875\n",
      "2018-05-04T18:50:55.077496: step 16915, loss 0.104747, acc 0.96875\n",
      "2018-05-04T18:50:56.040615: step 16916, loss 0.163467, acc 0.921875\n",
      "2018-05-04T18:50:57.006854: step 16917, loss 0.256565, acc 0.875\n",
      "2018-05-04T18:50:57.999034: step 16918, loss 0.228639, acc 0.921875\n",
      "2018-05-04T18:50:58.976330: step 16919, loss 0.257209, acc 0.921875\n",
      "2018-05-04T18:50:59.996105: step 16920, loss 0.320759, acc 0.875\n",
      "2018-05-04T18:51:00.970337: step 16921, loss 0.152298, acc 0.953125\n",
      "2018-05-04T18:51:01.912756: step 16922, loss 0.248415, acc 0.90625\n",
      "2018-05-04T18:51:02.914369: step 16923, loss 0.0961799, acc 0.96875\n",
      "2018-05-04T18:51:03.884356: step 16924, loss 0.296497, acc 0.890625\n",
      "2018-05-04T18:51:04.830435: step 16925, loss 0.309305, acc 0.90625\n",
      "2018-05-04T18:51:05.823609: step 16926, loss 0.284982, acc 0.84375\n",
      "2018-05-04T18:51:06.846717: step 16927, loss 0.252651, acc 0.90625\n",
      "2018-05-04T18:51:07.823737: step 16928, loss 0.303145, acc 0.859375\n",
      "2018-05-04T18:51:08.795448: step 16929, loss 0.310853, acc 0.90625\n",
      "2018-05-04T18:51:09.769846: step 16930, loss 0.269313, acc 0.84375\n",
      "2018-05-04T18:51:10.746293: step 16931, loss 0.226424, acc 0.890625\n",
      "2018-05-04T18:51:11.728992: step 16932, loss 0.279514, acc 0.921875\n",
      "2018-05-04T18:51:12.705005: step 16933, loss 0.447038, acc 0.875\n",
      "2018-05-04T18:51:13.703039: step 16934, loss 0.213978, acc 0.90625\n",
      "2018-05-04T18:51:14.684644: step 16935, loss 0.181715, acc 0.921875\n",
      "2018-05-04T18:51:15.645086: step 16936, loss 0.119668, acc 0.96875\n",
      "2018-05-04T18:51:16.646310: step 16937, loss 0.315156, acc 0.859375\n",
      "2018-05-04T18:51:17.676494: step 16938, loss 0.298263, acc 0.875\n",
      "2018-05-04T18:51:18.661759: step 16939, loss 0.247989, acc 0.90625\n",
      "2018-05-04T18:51:19.735563: step 16940, loss 0.195783, acc 0.921875\n",
      "2018-05-04T18:51:20.711349: step 16941, loss 0.243557, acc 0.890625\n",
      "2018-05-04T18:51:21.675906: step 16942, loss 0.494616, acc 0.84375\n",
      "2018-05-04T18:51:22.658755: step 16943, loss 0.294941, acc 0.875\n",
      "2018-05-04T18:51:23.701775: step 16944, loss 0.227262, acc 0.9375\n",
      "2018-05-04T18:51:24.705647: step 16945, loss 0.315157, acc 0.84375\n",
      "2018-05-04T18:51:25.691849: step 16946, loss 0.305127, acc 0.875\n",
      "2018-05-04T18:51:26.713809: step 16947, loss 0.28272, acc 0.859375\n",
      "2018-05-04T18:51:27.695400: step 16948, loss 0.169459, acc 0.953125\n",
      "2018-05-04T18:51:28.634216: step 16949, loss 0.160853, acc 0.953125\n",
      "2018-05-04T18:51:29.592637: step 16950, loss 0.15779, acc 0.953125\n",
      "2018-05-04T18:51:30.561614: step 16951, loss 0.178941, acc 0.953125\n",
      "2018-05-04T18:51:31.614121: step 16952, loss 0.288995, acc 0.921875\n",
      "2018-05-04T18:51:32.608873: step 16953, loss 0.453007, acc 0.828125\n",
      "2018-05-04T18:51:33.603074: step 16954, loss 0.204131, acc 0.90625\n",
      "2018-05-04T18:51:34.576204: step 16955, loss 0.236705, acc 0.921875\n",
      "2018-05-04T18:51:35.645704: step 16956, loss 0.321606, acc 0.859375\n",
      "2018-05-04T18:51:36.612917: step 16957, loss 0.241266, acc 0.875\n",
      "2018-05-04T18:51:37.558182: step 16958, loss 0.180088, acc 0.9375\n",
      "2018-05-04T18:51:38.521317: step 16959, loss 0.238048, acc 0.90625\n",
      "2018-05-04T18:51:39.468203: step 16960, loss 0.187708, acc 0.921875\n",
      "2018-05-04T18:51:40.408623: step 16961, loss 0.318261, acc 0.875\n",
      "2018-05-04T18:51:41.372899: step 16962, loss 0.312658, acc 0.859375\n",
      "2018-05-04T18:51:42.334505: step 16963, loss 0.24806, acc 0.90625\n",
      "2018-05-04T18:51:43.292049: step 16964, loss 0.241895, acc 0.875\n",
      "2018-05-04T18:51:44.302185: step 16965, loss 0.177316, acc 0.953125\n",
      "2018-05-04T18:51:45.289384: step 16966, loss 0.275636, acc 0.890625\n",
      "2018-05-04T18:51:46.273958: step 16967, loss 0.379478, acc 0.84375\n",
      "2018-05-04T18:51:47.248492: step 16968, loss 0.328755, acc 0.890625\n",
      "2018-05-04T18:51:48.228603: step 16969, loss 0.249156, acc 0.890625\n",
      "2018-05-04T18:51:49.222963: step 16970, loss 0.144576, acc 0.9375\n",
      "2018-05-04T18:51:50.220807: step 16971, loss 0.383414, acc 0.828125\n",
      "2018-05-04T18:51:51.186143: step 16972, loss 0.227853, acc 0.921875\n",
      "2018-05-04T18:51:52.142464: step 16973, loss 0.288666, acc 0.9375\n",
      "2018-05-04T18:51:53.098578: step 16974, loss 0.309587, acc 0.890625\n",
      "2018-05-04T18:51:54.065562: step 16975, loss 0.210619, acc 0.9375\n",
      "2018-05-04T18:51:55.015613: step 16976, loss 0.253889, acc 0.859375\n",
      "2018-05-04T18:51:55.957951: step 16977, loss 0.152565, acc 0.9375\n",
      "2018-05-04T18:51:56.917521: step 16978, loss 0.192044, acc 0.90625\n",
      "2018-05-04T18:51:57.894172: step 16979, loss 0.204295, acc 0.890625\n",
      "2018-05-04T18:51:58.842320: step 16980, loss 0.310896, acc 0.828125\n",
      "2018-05-04T18:51:59.870428: step 16981, loss 0.187111, acc 0.90625\n",
      "2018-05-04T18:52:00.826225: step 16982, loss 0.248431, acc 0.90625\n",
      "2018-05-04T18:52:01.795865: step 16983, loss 0.157729, acc 0.9375\n",
      "2018-05-04T18:52:02.747012: step 16984, loss 0.18268, acc 0.921875\n",
      "2018-05-04T18:52:03.714543: step 16985, loss 0.19602, acc 0.9375\n",
      "2018-05-04T18:52:04.694751: step 16986, loss 0.19227, acc 0.9375\n",
      "2018-05-04T18:52:05.666887: step 16987, loss 0.201201, acc 0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T18:52:06.631976: step 16988, loss 0.206121, acc 0.90625\n",
      "2018-05-04T18:52:07.585882: step 16989, loss 0.189151, acc 0.921875\n",
      "2018-05-04T18:52:08.611007: step 16990, loss 0.312548, acc 0.859375\n",
      "2018-05-04T18:52:09.565803: step 16991, loss 0.303594, acc 0.859375\n",
      "2018-05-04T18:52:10.539426: step 16992, loss 0.274953, acc 0.890625\n",
      "2018-05-04T18:52:11.502293: step 16993, loss 0.263797, acc 0.875\n",
      "2018-05-04T18:52:12.464477: step 16994, loss 0.382678, acc 0.828125\n",
      "2018-05-04T18:52:13.424398: step 16995, loss 0.266245, acc 0.84375\n",
      "2018-05-04T18:52:14.389570: step 16996, loss 0.201454, acc 0.921875\n",
      "2018-05-04T18:52:15.406938: step 16997, loss 0.146391, acc 0.9375\n",
      "2018-05-04T18:52:16.364584: step 16998, loss 0.263794, acc 0.90625\n",
      "2018-05-04T18:52:17.327473: step 16999, loss 0.249268, acc 0.890625\n",
      "2018-05-04T18:52:18.272761: step 17000, loss 0.243341, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T18:52:20.642387: step 17000, loss 0.209211, acc 0.928\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-17000\n",
      "\n",
      "2018-05-04T18:52:21.701821: step 17001, loss 0.357418, acc 0.84375\n",
      "2018-05-04T18:52:22.692631: step 17002, loss 0.256866, acc 0.890625\n",
      "2018-05-04T18:52:23.674528: step 17003, loss 0.412957, acc 0.859375\n",
      "2018-05-04T18:52:24.695270: step 17004, loss 0.203683, acc 0.921875\n",
      "2018-05-04T18:52:25.694547: step 17005, loss 0.26698, acc 0.84375\n",
      "2018-05-04T18:52:26.680905: step 17006, loss 0.315773, acc 0.84375\n",
      "2018-05-04T18:52:27.653822: step 17007, loss 0.296618, acc 0.890625\n",
      "2018-05-04T18:52:28.647280: step 17008, loss 0.301219, acc 0.859375\n",
      "2018-05-04T18:52:29.627201: step 17009, loss 0.198368, acc 0.921875\n",
      "2018-05-04T18:52:30.619765: step 17010, loss 0.311769, acc 0.890625\n",
      "2018-05-04T18:52:31.639528: step 17011, loss 0.220175, acc 0.90625\n",
      "2018-05-04T18:52:32.605998: step 17012, loss 0.187424, acc 0.953125\n",
      "2018-05-04T18:52:33.626163: step 17013, loss 0.304415, acc 0.859375\n",
      "2018-05-04T18:52:34.668455: step 17014, loss 0.311784, acc 0.859375\n",
      "2018-05-04T18:52:35.703104: step 17015, loss 0.170776, acc 0.953125\n",
      "2018-05-04T18:52:36.724501: step 17016, loss 0.152292, acc 0.9375\n",
      "2018-05-04T18:52:37.803245: step 17017, loss 0.136907, acc 0.953125\n",
      "2018-05-04T18:52:38.824225: step 17018, loss 0.197369, acc 0.921875\n",
      "2018-05-04T18:52:39.837950: step 17019, loss 0.241747, acc 0.90625\n",
      "2018-05-04T18:52:40.794477: step 17020, loss 0.254875, acc 0.890625\n",
      "2018-05-04T18:52:41.735243: step 17021, loss 0.234914, acc 0.890625\n",
      "2018-05-04T18:52:42.770805: step 17022, loss 0.239759, acc 0.921875\n",
      "2018-05-04T18:52:43.749978: step 17023, loss 0.385637, acc 0.875\n",
      "2018-05-04T18:52:44.707011: step 17024, loss 0.252003, acc 0.90625\n",
      "2018-05-04T18:52:45.681954: step 17025, loss 0.288349, acc 0.859375\n",
      "2018-05-04T18:52:46.770526: step 17026, loss 0.244342, acc 0.90625\n",
      "2018-05-04T18:52:47.843748: step 17027, loss 0.248236, acc 0.90625\n",
      "2018-05-04T18:52:48.891791: step 17028, loss 0.175538, acc 0.921875\n",
      "2018-05-04T18:52:49.866583: step 17029, loss 0.229408, acc 0.890625\n",
      "2018-05-04T18:52:50.808849: step 17030, loss 0.316218, acc 0.859375\n",
      "2018-05-04T18:52:51.782563: step 17031, loss 0.342374, acc 0.859375\n",
      "2018-05-04T18:52:52.899882: step 17032, loss 0.16389, acc 0.9375\n",
      "2018-05-04T18:52:53.900830: step 17033, loss 0.278906, acc 0.875\n",
      "2018-05-04T18:52:54.903951: step 17034, loss 0.277888, acc 0.890625\n",
      "2018-05-04T18:52:55.887121: step 17035, loss 0.230665, acc 0.890625\n",
      "2018-05-04T18:52:56.892928: step 17036, loss 0.232479, acc 0.90625\n",
      "2018-05-04T18:52:57.886325: step 17037, loss 0.213418, acc 0.890625\n",
      "2018-05-04T18:52:58.949644: step 17038, loss 0.289157, acc 0.890625\n",
      "2018-05-04T18:53:00.005979: step 17039, loss 0.284968, acc 0.875\n",
      "2018-05-04T18:53:00.968095: step 17040, loss 0.564001, acc 0.84375\n",
      "2018-05-04T18:53:01.953342: step 17041, loss 0.181222, acc 0.9375\n",
      "2018-05-04T18:53:03.003468: step 17042, loss 0.357075, acc 0.90625\n",
      "2018-05-04T18:53:03.977027: step 17043, loss 0.196922, acc 0.9375\n",
      "2018-05-04T18:53:05.043833: step 17044, loss 0.166374, acc 0.953125\n",
      "2018-05-04T18:53:06.107443: step 17045, loss 0.207626, acc 0.90625\n",
      "2018-05-04T18:53:07.097255: step 17046, loss 0.285176, acc 0.90625\n",
      "2018-05-04T18:53:08.094965: step 17047, loss 0.186846, acc 0.9375\n",
      "2018-05-04T18:53:09.069691: step 17048, loss 0.285155, acc 0.875\n",
      "2018-05-04T18:53:10.026348: step 17049, loss 0.298092, acc 0.921875\n",
      "2018-05-04T18:53:10.980942: step 17050, loss 0.152728, acc 0.953125\n",
      "2018-05-04T18:53:11.946160: step 17051, loss 0.279124, acc 0.875\n",
      "2018-05-04T18:53:12.928187: step 17052, loss 0.233995, acc 0.90625\n",
      "2018-05-04T18:53:13.905821: step 17053, loss 0.298721, acc 0.890625\n",
      "2018-05-04T18:53:14.921529: step 17054, loss 0.323074, acc 0.859375\n",
      "2018-05-04T18:53:15.902375: step 17055, loss 0.285876, acc 0.921875\n",
      "2018-05-04T18:53:16.903682: step 17056, loss 0.26416, acc 0.875\n",
      "2018-05-04T18:53:17.930751: step 17057, loss 0.223657, acc 0.90625\n",
      "2018-05-04T18:53:18.913041: step 17058, loss 0.145171, acc 0.953125\n",
      "2018-05-04T18:53:19.880745: step 17059, loss 0.202789, acc 0.921875\n",
      "2018-05-04T18:53:20.837222: step 17060, loss 0.203376, acc 0.9375\n",
      "2018-05-04T18:53:21.806731: step 17061, loss 0.359279, acc 0.890625\n",
      "2018-05-04T18:53:22.767869: step 17062, loss 0.324436, acc 0.890625\n",
      "2018-05-04T18:53:23.726788: step 17063, loss 0.320212, acc 0.890625\n",
      "2018-05-04T18:53:24.665916: step 17064, loss 0.247723, acc 0.859375\n",
      "2018-05-04T18:53:25.622477: step 17065, loss 0.358087, acc 0.859375\n",
      "2018-05-04T18:53:26.596973: step 17066, loss 0.315224, acc 0.84375\n",
      "2018-05-04T18:53:27.597237: step 17067, loss 0.294504, acc 0.84375\n",
      "2018-05-04T18:53:28.563166: step 17068, loss 0.288122, acc 0.859375\n",
      "2018-05-04T18:53:29.513732: step 17069, loss 0.464936, acc 0.8125\n",
      "2018-05-04T18:53:30.484724: step 17070, loss 0.316578, acc 0.828125\n",
      "2018-05-04T18:53:31.435003: step 17071, loss 0.171219, acc 0.9375\n",
      "2018-05-04T18:53:32.463135: step 17072, loss 0.263891, acc 0.90625\n",
      "2018-05-04T18:53:33.505278: step 17073, loss 0.31246, acc 0.90625\n",
      "2018-05-04T18:53:34.476593: step 17074, loss 0.248312, acc 0.875\n",
      "2018-05-04T18:53:35.440605: step 17075, loss 0.29961, acc 0.921875\n",
      "2018-05-04T18:53:36.390890: step 17076, loss 0.209712, acc 0.90625\n",
      "2018-05-04T18:53:37.344706: step 17077, loss 0.219806, acc 0.890625\n",
      "2018-05-04T18:53:38.311424: step 17078, loss 0.290021, acc 0.875\n",
      "2018-05-04T18:53:39.255922: step 17079, loss 0.340558, acc 0.859375\n",
      "2018-05-04T18:53:40.216119: step 17080, loss 0.23573, acc 0.90625\n",
      "2018-05-04T18:53:41.160466: step 17081, loss 0.397662, acc 0.796875\n",
      "2018-05-04T18:53:42.140105: step 17082, loss 0.171214, acc 0.984375\n",
      "2018-05-04T18:53:43.111191: step 17083, loss 0.207313, acc 0.921875\n",
      "2018-05-04T18:53:44.070056: step 17084, loss 0.27485, acc 0.90625\n",
      "2018-05-04T18:53:45.027120: step 17085, loss 0.223536, acc 0.921875\n",
      "2018-05-04T18:53:46.000871: step 17086, loss 0.174287, acc 0.953125\n",
      "2018-05-04T18:53:46.996964: step 17087, loss 0.265076, acc 0.90625\n",
      "2018-05-04T18:53:48.039232: step 17088, loss 0.372412, acc 0.84375\n",
      "2018-05-04T18:53:49.059862: step 17089, loss 0.236642, acc 0.90625\n",
      "2018-05-04T18:53:50.016096: step 17090, loss 0.284552, acc 0.875\n",
      "2018-05-04T18:53:50.959617: step 17091, loss 0.307738, acc 0.84375\n",
      "2018-05-04T18:53:51.968807: step 17092, loss 0.249671, acc 0.9375\n",
      "2018-05-04T18:53:52.999471: step 17093, loss 0.21789, acc 0.890625\n",
      "2018-05-04T18:53:53.966853: step 17094, loss 0.184176, acc 0.90625\n",
      "2018-05-04T18:53:54.918218: step 17095, loss 0.309583, acc 0.859375\n",
      "2018-05-04T18:53:55.849042: step 17096, loss 0.210148, acc 0.90625\n",
      "2018-05-04T18:53:56.877714: step 17097, loss 0.349454, acc 0.796875\n",
      "2018-05-04T18:53:57.838153: step 17098, loss 0.300097, acc 0.859375\n",
      "2018-05-04T18:53:58.797613: step 17099, loss 0.157973, acc 0.9375\n",
      "2018-05-04T18:53:59.811972: step 17100, loss 0.142571, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T18:54:01.898523: step 17100, loss 0.213358, acc 0.918\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-17100\n",
      "\n",
      "2018-05-04T18:54:02.939583: step 17101, loss 0.300678, acc 0.84375\n",
      "2018-05-04T18:54:03.896831: step 17102, loss 0.175845, acc 0.9375\n",
      "2018-05-04T18:54:04.855136: step 17103, loss 0.221643, acc 0.921875\n",
      "2018-05-04T18:54:05.811301: step 17104, loss 0.257868, acc 0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T18:54:06.836504: step 17105, loss 0.245966, acc 0.875\n",
      "2018-05-04T18:54:07.767161: step 17106, loss 0.220479, acc 0.921875\n",
      "2018-05-04T18:54:08.722162: step 17107, loss 0.157681, acc 0.96875\n",
      "2018-05-04T18:54:09.745376: step 17108, loss 0.212702, acc 0.9375\n",
      "2018-05-04T18:54:10.687002: step 17109, loss 0.32474, acc 0.859375\n",
      "2018-05-04T18:54:11.651459: step 17110, loss 0.358273, acc 0.796875\n",
      "2018-05-04T18:54:12.609007: step 17111, loss 0.161341, acc 0.953125\n",
      "2018-05-04T18:54:13.601313: step 17112, loss 0.287066, acc 0.859375\n",
      "2018-05-04T18:54:14.565648: step 17113, loss 0.281362, acc 0.890625\n",
      "2018-05-04T18:54:15.550576: step 17114, loss 0.298807, acc 0.875\n",
      "2018-05-04T18:54:16.500294: step 17115, loss 0.206245, acc 0.921875\n",
      "2018-05-04T18:54:17.442515: step 17116, loss 0.149028, acc 0.9375\n",
      "2018-05-04T18:54:18.383834: step 17117, loss 0.500349, acc 0.8125\n",
      "2018-05-04T18:54:19.382093: step 17118, loss 0.175909, acc 0.953125\n",
      "2018-05-04T18:54:20.377798: step 17119, loss 0.374055, acc 0.890625\n",
      "2018-05-04T18:54:21.352868: step 17120, loss 0.20497, acc 0.921875\n",
      "2018-05-04T18:54:22.314499: step 17121, loss 0.371678, acc 0.84375\n",
      "2018-05-04T18:54:23.273479: step 17122, loss 0.211834, acc 0.90625\n",
      "2018-05-04T18:54:24.207994: step 17123, loss 0.280305, acc 0.875\n",
      "2018-05-04T18:54:25.169431: step 17124, loss 0.294387, acc 0.890625\n",
      "2018-05-04T18:54:26.109053: step 17125, loss 0.358935, acc 0.90625\n",
      "2018-05-04T18:54:27.074693: step 17126, loss 0.397796, acc 0.78125\n",
      "2018-05-04T18:54:28.118160: step 17127, loss 0.333133, acc 0.921875\n",
      "2018-05-04T18:54:29.083531: step 17128, loss 0.193315, acc 0.9375\n",
      "2018-05-04T18:54:30.056103: step 17129, loss 0.518543, acc 0.859375\n",
      "2018-05-04T18:54:30.998725: step 17130, loss 0.16016, acc 0.9375\n",
      "2018-05-04T18:54:31.947027: step 17131, loss 0.232401, acc 0.90625\n",
      "2018-05-04T18:54:32.890838: step 17132, loss 0.195997, acc 0.953125\n",
      "2018-05-04T18:54:33.847705: step 17133, loss 0.341519, acc 0.84375\n",
      "2018-05-04T18:54:34.801080: step 17134, loss 0.219186, acc 0.90625\n",
      "2018-05-04T18:54:35.761968: step 17135, loss 0.236868, acc 0.921875\n",
      "2018-05-04T18:54:36.769285: step 17136, loss 0.206905, acc 0.921875\n",
      "2018-05-04T18:54:37.747100: step 17137, loss 0.206351, acc 0.921875\n",
      "2018-05-04T18:54:38.727940: step 17138, loss 0.189692, acc 0.921875\n",
      "2018-05-04T18:54:39.676288: step 17139, loss 0.398892, acc 0.890625\n",
      "2018-05-04T18:54:40.614031: step 17140, loss 0.303994, acc 0.859375\n",
      "2018-05-04T18:54:41.607237: step 17141, loss 0.243303, acc 0.890625\n",
      "2018-05-04T18:54:42.545907: step 17142, loss 0.178647, acc 0.953125\n",
      "2018-05-04T18:54:43.505470: step 17143, loss 0.31447, acc 0.890625\n",
      "2018-05-04T18:54:44.534648: step 17144, loss 0.334997, acc 0.859375\n",
      "2018-05-04T18:54:45.483005: step 17145, loss 0.297052, acc 0.84375\n",
      "2018-05-04T18:54:46.422285: step 17146, loss 0.342491, acc 0.84375\n",
      "2018-05-04T18:54:47.380282: step 17147, loss 0.302571, acc 0.859375\n",
      "2018-05-04T18:54:48.337932: step 17148, loss 0.264736, acc 0.875\n",
      "2018-05-04T18:54:49.320522: step 17149, loss 0.333048, acc 0.84375\n",
      "2018-05-04T18:54:50.314348: step 17150, loss 0.220179, acc 0.9375\n",
      "2018-05-04T18:54:51.292520: step 17151, loss 0.226964, acc 0.890625\n",
      "2018-05-04T18:54:52.320039: step 17152, loss 0.182175, acc 0.9375\n",
      "2018-05-04T18:54:53.254967: step 17153, loss 0.230756, acc 0.921875\n",
      "2018-05-04T18:54:54.187692: step 17154, loss 0.186608, acc 0.890625\n",
      "2018-05-04T18:54:55.118598: step 17155, loss 0.220677, acc 0.890625\n",
      "2018-05-04T18:54:56.048437: step 17156, loss 0.139867, acc 0.921875\n",
      "2018-05-04T18:54:56.983702: step 17157, loss 0.325573, acc 0.859375\n",
      "2018-05-04T18:54:57.958643: step 17158, loss 0.421754, acc 0.875\n",
      "2018-05-04T18:54:58.926821: step 17159, loss 0.274856, acc 0.90625\n",
      "2018-05-04T18:54:59.888124: step 17160, loss 0.322513, acc 0.875\n",
      "2018-05-04T18:55:00.871791: step 17161, loss 0.298825, acc 0.859375\n",
      "2018-05-04T18:55:01.863408: step 17162, loss 0.232691, acc 0.921875\n",
      "2018-05-04T18:55:02.833913: step 17163, loss 0.311872, acc 0.875\n",
      "2018-05-04T18:55:03.802832: step 17164, loss 0.254019, acc 0.921875\n",
      "2018-05-04T18:55:04.790040: step 17165, loss 0.344184, acc 0.875\n",
      "2018-05-04T18:55:05.749417: step 17166, loss 0.229128, acc 0.921875\n",
      "2018-05-04T18:55:06.722083: step 17167, loss 0.165194, acc 0.953125\n",
      "2018-05-04T18:55:07.659672: step 17168, loss 0.316628, acc 0.828125\n",
      "2018-05-04T18:55:08.599903: step 17169, loss 0.309781, acc 0.859375\n",
      "2018-05-04T18:55:09.541073: step 17170, loss 0.259138, acc 0.90625\n",
      "2018-05-04T18:55:10.489032: step 17171, loss 0.238992, acc 0.875\n",
      "2018-05-04T18:55:11.438273: step 17172, loss 0.201012, acc 0.921875\n",
      "2018-05-04T18:55:12.420030: step 17173, loss 0.262197, acc 0.859375\n",
      "2018-05-04T18:55:13.386762: step 17174, loss 0.208807, acc 0.9375\n",
      "2018-05-04T18:55:14.349047: step 17175, loss 0.172812, acc 0.953125\n",
      "2018-05-04T18:55:15.358060: step 17176, loss 0.239056, acc 0.90625\n",
      "2018-05-04T18:55:16.295603: step 17177, loss 0.282198, acc 0.859375\n",
      "2018-05-04T18:55:17.257759: step 17178, loss 0.155631, acc 0.921875\n",
      "2018-05-04T18:55:18.182699: step 17179, loss 0.220203, acc 0.875\n",
      "2018-05-04T18:55:19.162399: step 17180, loss 0.208937, acc 0.921875\n",
      "2018-05-04T18:55:20.197257: step 17181, loss 0.299567, acc 0.875\n",
      "2018-05-04T18:55:21.171278: step 17182, loss 0.284157, acc 0.90625\n",
      "2018-05-04T18:55:22.150975: step 17183, loss 0.274932, acc 0.890625\n",
      "2018-05-04T18:55:23.106789: step 17184, loss 0.31254, acc 0.859375\n",
      "2018-05-04T18:55:24.141634: step 17185, loss 0.13954, acc 0.953125\n",
      "2018-05-04T18:55:25.080568: step 17186, loss 0.287424, acc 0.859375\n",
      "2018-05-04T18:55:26.021930: step 17187, loss 0.271379, acc 0.90625\n",
      "2018-05-04T18:55:26.960579: step 17188, loss 0.351499, acc 0.84375\n",
      "2018-05-04T18:55:27.961514: step 17189, loss 0.283135, acc 0.875\n",
      "2018-05-04T18:55:28.966420: step 17190, loss 0.246127, acc 0.90625\n",
      "2018-05-04T18:55:29.904748: step 17191, loss 0.306481, acc 0.890625\n",
      "2018-05-04T18:55:30.833498: step 17192, loss 0.415079, acc 0.84375\n",
      "2018-05-04T18:55:31.757111: step 17193, loss 0.282872, acc 0.875\n",
      "2018-05-04T18:55:32.728028: step 17194, loss 0.193389, acc 0.921875\n",
      "2018-05-04T18:55:33.741622: step 17195, loss 0.395178, acc 0.84375\n",
      "2018-05-04T18:55:34.831120: step 17196, loss 0.229347, acc 0.90625\n",
      "2018-05-04T18:55:35.932862: step 17197, loss 0.338626, acc 0.875\n",
      "2018-05-04T18:55:37.007530: step 17198, loss 0.28701, acc 0.890625\n",
      "2018-05-04T18:55:38.023454: step 17199, loss 0.241431, acc 0.9375\n",
      "2018-05-04T18:55:39.037000: step 17200, loss 0.301548, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T18:55:41.783028: step 17200, loss 0.215018, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-17200\n",
      "\n",
      "2018-05-04T18:55:42.889171: step 17201, loss 0.224719, acc 0.890625\n",
      "2018-05-04T18:55:43.857650: step 17202, loss 0.286444, acc 0.875\n",
      "2018-05-04T18:55:44.922380: step 17203, loss 0.290075, acc 0.90625\n",
      "2018-05-04T18:55:45.911562: step 17204, loss 0.309997, acc 0.859375\n",
      "2018-05-04T18:55:46.908622: step 17205, loss 0.277258, acc 0.859375\n",
      "2018-05-04T18:55:47.945678: step 17206, loss 0.252866, acc 0.921875\n",
      "2018-05-04T18:55:48.955350: step 17207, loss 0.168366, acc 0.9375\n",
      "2018-05-04T18:55:49.945553: step 17208, loss 0.144718, acc 0.9375\n",
      "2018-05-04T18:55:50.976341: step 17209, loss 0.271087, acc 0.90625\n",
      "2018-05-04T18:55:51.983908: step 17210, loss 0.322504, acc 0.875\n",
      "2018-05-04T18:55:52.995768: step 17211, loss 0.129125, acc 0.96875\n",
      "2018-05-04T18:55:54.005555: step 17212, loss 0.47414, acc 0.84375\n",
      "2018-05-04T18:55:55.006173: step 17213, loss 0.264088, acc 0.90625\n",
      "2018-05-04T18:55:55.986474: step 17214, loss 0.363103, acc 0.796875\n",
      "2018-05-04T18:55:56.956426: step 17215, loss 0.349417, acc 0.84375\n",
      "2018-05-04T18:55:57.905965: step 17216, loss 0.173705, acc 0.953125\n",
      "2018-05-04T18:55:58.900940: step 17217, loss 0.236862, acc 0.921875\n",
      "2018-05-04T18:55:59.945764: step 17218, loss 0.222341, acc 0.90625\n",
      "2018-05-04T18:56:00.922577: step 17219, loss 0.217289, acc 0.890625\n",
      "2018-05-04T18:56:01.866036: step 17220, loss 0.235619, acc 0.875\n",
      "2018-05-04T18:56:02.911506: step 17221, loss 0.376609, acc 0.859375\n",
      "2018-05-04T18:56:03.872440: step 17222, loss 0.260094, acc 0.890625\n",
      "2018-05-04T18:56:04.846277: step 17223, loss 0.281616, acc 0.859375\n",
      "2018-05-04T18:56:05.804508: step 17224, loss 0.218412, acc 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T18:56:06.778615: step 17225, loss 0.199927, acc 0.90625\n",
      "2018-05-04T18:56:07.823128: step 17226, loss 0.202324, acc 0.9375\n",
      "2018-05-04T18:56:08.788090: step 17227, loss 0.210121, acc 0.90625\n",
      "2018-05-04T18:56:09.747898: step 17228, loss 0.271619, acc 0.90625\n",
      "2018-05-04T18:56:10.684617: step 17229, loss 0.268071, acc 0.875\n",
      "2018-05-04T18:56:11.691099: step 17230, loss 0.341115, acc 0.859375\n",
      "2018-05-04T18:56:12.649132: step 17231, loss 0.232393, acc 0.890625\n",
      "2018-05-04T18:56:13.644986: step 17232, loss 0.241374, acc 0.921875\n",
      "2018-05-04T18:56:14.623984: step 17233, loss 0.295533, acc 0.875\n",
      "2018-05-04T18:56:15.611217: step 17234, loss 0.190262, acc 0.921875\n",
      "2018-05-04T18:56:16.585947: step 17235, loss 0.148004, acc 0.9375\n",
      "2018-05-04T18:56:17.530389: step 17236, loss 0.271571, acc 0.890625\n",
      "2018-05-04T18:56:18.488725: step 17237, loss 0.274368, acc 0.90625\n",
      "2018-05-04T18:56:19.447799: step 17238, loss 0.186016, acc 0.9375\n",
      "2018-05-04T18:56:20.414863: step 17239, loss 0.283585, acc 0.84375\n",
      "2018-05-04T18:56:21.417977: step 17240, loss 0.19938, acc 0.921875\n",
      "2018-05-04T18:56:22.402660: step 17241, loss 0.206183, acc 0.90625\n",
      "2018-05-04T18:56:23.395921: step 17242, loss 0.388755, acc 0.84375\n",
      "2018-05-04T18:56:24.371846: step 17243, loss 0.342443, acc 0.828125\n",
      "2018-05-04T18:56:25.342879: step 17244, loss 0.246392, acc 0.875\n",
      "2018-05-04T18:56:26.292046: step 17245, loss 0.329434, acc 0.84375\n",
      "2018-05-04T18:56:27.256129: step 17246, loss 0.452818, acc 0.84375\n",
      "2018-05-04T18:56:28.221302: step 17247, loss 0.349005, acc 0.875\n",
      "2018-05-04T18:56:29.183438: step 17248, loss 0.207237, acc 0.953125\n",
      "2018-05-04T18:56:30.144109: step 17249, loss 0.209298, acc 0.859375\n",
      "2018-05-04T18:56:31.134001: step 17250, loss 0.255311, acc 0.90625\n",
      "2018-05-04T18:56:32.095297: step 17251, loss 0.149065, acc 0.953125\n",
      "2018-05-04T18:56:33.072332: step 17252, loss 0.260653, acc 0.859375\n",
      "2018-05-04T18:56:34.076101: step 17253, loss 0.193443, acc 0.90625\n",
      "2018-05-04T18:56:35.039983: step 17254, loss 0.347934, acc 0.859375\n",
      "2018-05-04T18:56:36.024889: step 17255, loss 0.404849, acc 0.859375\n",
      "2018-05-04T18:56:36.994621: step 17256, loss 0.281409, acc 0.90625\n",
      "2018-05-04T18:56:38.045379: step 17257, loss 0.136339, acc 0.96875\n",
      "2018-05-04T18:56:39.009186: step 17258, loss 0.209874, acc 0.90625\n",
      "2018-05-04T18:56:39.956365: step 17259, loss 0.322488, acc 0.875\n",
      "2018-05-04T18:56:40.917243: step 17260, loss 0.227764, acc 0.921875\n",
      "2018-05-04T18:56:41.982324: step 17261, loss 0.226255, acc 0.90625\n",
      "2018-05-04T18:56:42.943357: step 17262, loss 0.211387, acc 0.921875\n",
      "2018-05-04T18:56:44.002981: step 17263, loss 0.166884, acc 0.921875\n",
      "2018-05-04T18:56:44.940779: step 17264, loss 0.216559, acc 0.890625\n",
      "2018-05-04T18:56:45.899747: step 17265, loss 0.349261, acc 0.828125\n",
      "2018-05-04T18:56:46.864392: step 17266, loss 0.286632, acc 0.921875\n",
      "2018-05-04T18:56:47.815254: step 17267, loss 0.264634, acc 0.859375\n",
      "2018-05-04T18:56:48.837855: step 17268, loss 0.546739, acc 0.765625\n",
      "2018-05-04T18:56:49.792363: step 17269, loss 0.204475, acc 0.875\n",
      "2018-05-04T18:56:50.746155: step 17270, loss 0.243178, acc 0.921875\n",
      "2018-05-04T18:56:51.798911: step 17271, loss 0.31619, acc 0.90625\n",
      "2018-05-04T18:56:52.805393: step 17272, loss 0.272655, acc 0.90625\n",
      "2018-05-04T18:56:53.765344: step 17273, loss 0.259186, acc 0.890625\n",
      "2018-05-04T18:56:54.734691: step 17274, loss 0.294957, acc 0.890625\n",
      "2018-05-04T18:56:55.751395: step 17275, loss 0.3085, acc 0.875\n",
      "2018-05-04T18:56:56.700730: step 17276, loss 0.166779, acc 0.953125\n",
      "2018-05-04T18:56:57.713385: step 17277, loss 0.262603, acc 0.875\n",
      "2018-05-04T18:56:58.670182: step 17278, loss 0.216894, acc 0.90625\n",
      "2018-05-04T18:56:59.622797: step 17279, loss 0.299172, acc 0.875\n",
      "2018-05-04T18:57:00.576802: step 17280, loss 0.308163, acc 0.859375\n",
      "2018-05-04T18:57:01.591020: step 17281, loss 0.288218, acc 0.890625\n",
      "2018-05-04T18:57:02.573940: step 17282, loss 0.304709, acc 0.9375\n",
      "2018-05-04T18:57:03.557304: step 17283, loss 0.263668, acc 0.921875\n",
      "2018-05-04T18:57:04.546297: step 17284, loss 0.26126, acc 0.890625\n",
      "2018-05-04T18:57:05.506032: step 17285, loss 0.261485, acc 0.859375\n",
      "2018-05-04T18:57:06.455530: step 17286, loss 0.217276, acc 0.890625\n",
      "2018-05-04T18:57:07.492631: step 17287, loss 0.168226, acc 0.953125\n",
      "2018-05-04T18:57:08.442524: step 17288, loss 0.279376, acc 0.828125\n",
      "2018-05-04T18:57:09.391912: step 17289, loss 0.318422, acc 0.921875\n",
      "2018-05-04T18:57:10.336311: step 17290, loss 0.284157, acc 0.875\n",
      "2018-05-04T18:57:11.278636: step 17291, loss 0.236261, acc 0.859375\n",
      "2018-05-04T18:57:12.230547: step 17292, loss 0.208431, acc 0.9375\n",
      "2018-05-04T18:57:13.201002: step 17293, loss 0.190674, acc 0.921875\n",
      "2018-05-04T18:57:14.180266: step 17294, loss 0.225288, acc 0.921875\n",
      "2018-05-04T18:57:15.139739: step 17295, loss 0.270663, acc 0.90625\n",
      "2018-05-04T18:57:16.109228: step 17296, loss 0.132885, acc 0.96875\n",
      "2018-05-04T18:57:17.053435: step 17297, loss 0.113605, acc 0.96875\n",
      "2018-05-04T18:57:18.008567: step 17298, loss 0.293841, acc 0.890625\n",
      "2018-05-04T18:57:18.987052: step 17299, loss 0.376824, acc 0.8125\n",
      "2018-05-04T18:57:19.941411: step 17300, loss 0.291226, acc 0.828125\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T18:57:22.154149: step 17300, loss 0.227901, acc 0.92\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-17300\n",
      "\n",
      "2018-05-04T18:57:23.277876: step 17301, loss 0.375022, acc 0.84375\n",
      "2018-05-04T18:57:24.243784: step 17302, loss 0.260283, acc 0.890625\n",
      "2018-05-04T18:57:25.220057: step 17303, loss 0.190866, acc 0.90625\n",
      "2018-05-04T18:57:26.174693: step 17304, loss 0.188116, acc 0.921875\n",
      "2018-05-04T18:57:27.148753: step 17305, loss 0.207927, acc 0.875\n",
      "2018-05-04T18:57:28.149417: step 17306, loss 0.18533, acc 0.9375\n",
      "2018-05-04T18:57:29.109750: step 17307, loss 0.223651, acc 0.921875\n",
      "2018-05-04T18:57:30.038919: step 17308, loss 0.271519, acc 0.890625\n",
      "2018-05-04T18:57:30.988826: step 17309, loss 0.279085, acc 0.875\n",
      "2018-05-04T18:57:31.939851: step 17310, loss 0.317081, acc 0.875\n",
      "2018-05-04T18:57:32.907361: step 17311, loss 0.3274, acc 0.90625\n",
      "2018-05-04T18:57:33.858999: step 17312, loss 0.346848, acc 0.859375\n",
      "2018-05-04T18:57:34.903959: step 17313, loss 0.374353, acc 0.796875\n",
      "2018-05-04T18:57:35.850344: step 17314, loss 0.27975, acc 0.84375\n",
      "2018-05-04T18:57:36.794520: step 17315, loss 0.191591, acc 0.9375\n",
      "2018-05-04T18:57:37.751482: step 17316, loss 0.239595, acc 0.921875\n",
      "2018-05-04T18:57:38.708820: step 17317, loss 0.251512, acc 0.890625\n",
      "2018-05-04T18:57:39.661406: step 17318, loss 0.195877, acc 0.90625\n",
      "2018-05-04T18:57:40.628534: step 17319, loss 0.150132, acc 0.953125\n",
      "2018-05-04T18:57:41.610675: step 17320, loss 0.283556, acc 0.890625\n",
      "2018-05-04T18:57:42.609211: step 17321, loss 0.306968, acc 0.859375\n",
      "2018-05-04T18:57:43.574310: step 17322, loss 0.160729, acc 0.9375\n",
      "2018-05-04T18:57:44.544525: step 17323, loss 0.296792, acc 0.90625\n",
      "2018-05-04T18:57:45.485991: step 17324, loss 0.271519, acc 0.859375\n",
      "2018-05-04T18:57:46.429451: step 17325, loss 0.310819, acc 0.875\n",
      "2018-05-04T18:57:47.385102: step 17326, loss 0.152878, acc 0.9375\n",
      "2018-05-04T18:57:48.331277: step 17327, loss 0.275336, acc 0.90625\n",
      "2018-05-04T18:57:49.287846: step 17328, loss 0.320878, acc 0.890625\n",
      "2018-05-04T18:57:50.246225: step 17329, loss 0.255941, acc 0.9375\n",
      "2018-05-04T18:57:51.205548: step 17330, loss 0.304025, acc 0.890625\n",
      "2018-05-04T18:57:52.153020: step 17331, loss 0.35757, acc 0.859375\n",
      "2018-05-04T18:57:53.098981: step 17332, loss 0.370212, acc 0.875\n",
      "2018-05-04T18:57:54.046084: step 17333, loss 0.346118, acc 0.84375\n",
      "2018-05-04T18:57:54.985121: step 17334, loss 0.140182, acc 0.953125\n",
      "2018-05-04T18:57:55.925565: step 17335, loss 0.315776, acc 0.84375\n",
      "2018-05-04T18:57:56.931834: step 17336, loss 0.282418, acc 0.90625\n",
      "2018-05-04T18:57:57.917521: step 17337, loss 0.115944, acc 0.984375\n",
      "2018-05-04T18:57:58.898981: step 17338, loss 0.228082, acc 0.875\n",
      "2018-05-04T18:57:59.884156: step 17339, loss 0.323943, acc 0.828125\n",
      "2018-05-04T18:58:00.841258: step 17340, loss 0.222063, acc 0.90625\n",
      "2018-05-04T18:58:01.802234: step 17341, loss 0.216647, acc 0.9375\n",
      "2018-05-04T18:58:02.782766: step 17342, loss 0.177403, acc 0.90625\n",
      "2018-05-04T18:58:03.762810: step 17343, loss 0.276582, acc 0.9375\n",
      "2018-05-04T18:58:04.744001: step 17344, loss 0.201959, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T18:58:05.711286: step 17345, loss 0.312288, acc 0.828125\n",
      "2018-05-04T18:58:06.682083: step 17346, loss 0.283364, acc 0.890625\n",
      "2018-05-04T18:58:07.620480: step 17347, loss 0.258896, acc 0.921875\n",
      "2018-05-04T18:58:08.583941: step 17348, loss 0.16478, acc 0.921875\n",
      "2018-05-04T18:58:09.509542: step 17349, loss 0.215524, acc 0.9375\n",
      "2018-05-04T18:58:10.459203: step 17350, loss 0.197987, acc 0.890625\n",
      "2018-05-04T18:58:11.434241: step 17351, loss 0.2846, acc 0.875\n",
      "2018-05-04T18:58:12.374690: step 17352, loss 0.238395, acc 0.890625\n",
      "2018-05-04T18:58:13.352982: step 17353, loss 0.253735, acc 0.890625\n",
      "2018-05-04T18:58:14.331237: step 17354, loss 0.338763, acc 0.890625\n",
      "2018-05-04T18:58:15.289550: step 17355, loss 0.31584, acc 0.875\n",
      "2018-05-04T18:58:16.255646: step 17356, loss 0.3418, acc 0.921875\n",
      "2018-05-04T18:58:17.212815: step 17357, loss 0.184002, acc 0.96875\n",
      "2018-05-04T18:58:18.163743: step 17358, loss 0.379461, acc 0.859375\n",
      "2018-05-04T18:58:19.098385: step 17359, loss 0.345311, acc 0.84375\n",
      "2018-05-04T18:58:20.053757: step 17360, loss 0.277701, acc 0.921875\n",
      "2018-05-04T18:58:21.008186: step 17361, loss 0.274822, acc 0.921875\n",
      "2018-05-04T18:58:21.955403: step 17362, loss 0.391961, acc 0.875\n",
      "2018-05-04T18:58:22.889644: step 17363, loss 0.401115, acc 0.875\n",
      "2018-05-04T18:58:23.861309: step 17364, loss 0.235135, acc 0.890625\n",
      "2018-05-04T18:58:24.865655: step 17365, loss 0.455793, acc 0.8125\n",
      "2018-05-04T18:58:25.811952: step 17366, loss 0.283374, acc 0.859375\n",
      "2018-05-04T18:58:26.780182: step 17367, loss 0.329858, acc 0.859375\n",
      "2018-05-04T18:58:27.761520: step 17368, loss 0.337229, acc 0.84375\n",
      "2018-05-04T18:58:28.740985: step 17369, loss 0.399425, acc 0.828125\n",
      "2018-05-04T18:58:29.723584: step 17370, loss 0.313741, acc 0.828125\n",
      "2018-05-04T18:58:30.705399: step 17371, loss 0.247083, acc 0.921875\n",
      "2018-05-04T18:58:31.636665: step 17372, loss 0.259545, acc 0.890625\n",
      "2018-05-04T18:58:32.573277: step 17373, loss 0.261806, acc 0.875\n",
      "2018-05-04T18:58:33.634664: step 17374, loss 0.348586, acc 0.875\n",
      "2018-05-04T18:58:34.669678: step 17375, loss 0.212091, acc 0.9375\n",
      "2018-05-04T18:58:35.687853: step 17376, loss 0.199059, acc 0.921875\n",
      "2018-05-04T18:58:36.694764: step 17377, loss 0.195887, acc 0.921875\n",
      "2018-05-04T18:58:37.658190: step 17378, loss 0.257609, acc 0.90625\n",
      "2018-05-04T18:58:38.623944: step 17379, loss 0.416733, acc 0.8125\n",
      "2018-05-04T18:58:39.583209: step 17380, loss 0.353741, acc 0.84375\n",
      "2018-05-04T18:58:40.542774: step 17381, loss 0.23231, acc 0.90625\n",
      "2018-05-04T18:58:41.497599: step 17382, loss 0.26229, acc 0.890625\n",
      "2018-05-04T18:58:42.455580: step 17383, loss 0.224453, acc 0.890625\n",
      "2018-05-04T18:58:43.389169: step 17384, loss 0.219894, acc 0.90625\n",
      "2018-05-04T18:58:44.328334: step 17385, loss 0.133324, acc 0.984375\n",
      "2018-05-04T18:58:45.297645: step 17386, loss 0.164177, acc 0.953125\n",
      "2018-05-04T18:58:46.246976: step 17387, loss 0.337507, acc 0.859375\n",
      "2018-05-04T18:58:47.222417: step 17388, loss 0.315333, acc 0.90625\n",
      "2018-05-04T18:58:48.188665: step 17389, loss 0.265563, acc 0.90625\n",
      "2018-05-04T18:58:49.131389: step 17390, loss 0.374382, acc 0.828125\n",
      "2018-05-04T18:58:50.072866: step 17391, loss 0.277085, acc 0.9375\n",
      "2018-05-04T18:58:51.021913: step 17392, loss 0.344899, acc 0.828125\n",
      "2018-05-04T18:58:52.011814: step 17393, loss 0.28919, acc 0.84375\n",
      "2018-05-04T18:58:53.031369: step 17394, loss 0.310154, acc 0.90625\n",
      "2018-05-04T18:58:54.054731: step 17395, loss 0.244764, acc 0.890625\n",
      "2018-05-04T18:58:55.056462: step 17396, loss 0.217076, acc 0.9375\n",
      "2018-05-04T18:58:55.986575: step 17397, loss 0.246627, acc 0.90625\n",
      "2018-05-04T18:58:56.915420: step 17398, loss 0.203489, acc 0.921875\n",
      "2018-05-04T18:58:57.951254: step 17399, loss 0.222306, acc 0.953125\n",
      "2018-05-04T18:58:58.928000: step 17400, loss 0.182325, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T18:59:01.461230: step 17400, loss 0.218359, acc 0.926\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-17400\n",
      "\n",
      "2018-05-04T18:59:02.528683: step 17401, loss 0.333111, acc 0.84375\n",
      "2018-05-04T18:59:03.512739: step 17402, loss 0.210974, acc 0.921875\n",
      "2018-05-04T18:59:04.501233: step 17403, loss 0.302436, acc 0.828125\n",
      "2018-05-04T18:59:05.528325: step 17404, loss 0.222065, acc 0.890625\n",
      "2018-05-04T18:59:06.549171: step 17405, loss 0.297027, acc 0.828125\n",
      "2018-05-04T18:59:07.595329: step 17406, loss 0.218395, acc 0.9375\n",
      "2018-05-04T18:59:08.625025: step 17407, loss 0.143149, acc 0.953125\n",
      "2018-05-04T18:59:09.658341: step 17408, loss 0.380592, acc 0.828125\n",
      "2018-05-04T18:59:10.655652: step 17409, loss 0.315803, acc 0.84375\n",
      "2018-05-04T18:59:11.652413: step 17410, loss 0.221597, acc 0.90625\n",
      "2018-05-04T18:59:12.629889: step 17411, loss 0.229351, acc 0.890625\n",
      "2018-05-04T18:59:13.630398: step 17412, loss 0.241545, acc 0.875\n",
      "2018-05-04T18:59:14.598353: step 17413, loss 0.301886, acc 0.875\n",
      "2018-05-04T18:59:15.574058: step 17414, loss 0.291417, acc 0.90625\n",
      "2018-05-04T18:59:16.550877: step 17415, loss 0.312454, acc 0.859375\n",
      "2018-05-04T18:59:17.569723: step 17416, loss 0.260306, acc 0.828125\n",
      "2018-05-04T18:59:18.639027: step 17417, loss 0.281153, acc 0.890625\n",
      "2018-05-04T18:59:19.685069: step 17418, loss 0.299267, acc 0.828125\n",
      "2018-05-04T18:59:20.652158: step 17419, loss 0.234004, acc 0.9375\n",
      "2018-05-04T18:59:21.605113: step 17420, loss 0.286982, acc 0.875\n",
      "2018-05-04T18:59:22.547155: step 17421, loss 0.193965, acc 0.9375\n",
      "2018-05-04T18:59:23.492987: step 17422, loss 0.309084, acc 0.828125\n",
      "2018-05-04T18:59:24.529268: step 17423, loss 0.205663, acc 0.921875\n",
      "2018-05-04T18:59:25.472951: step 17424, loss 0.12664, acc 0.953125\n",
      "2018-05-04T18:59:26.426082: step 17425, loss 0.296699, acc 0.890625\n",
      "2018-05-04T18:59:27.380428: step 17426, loss 0.329153, acc 0.859375\n",
      "2018-05-04T18:59:28.425524: step 17427, loss 0.183951, acc 0.953125\n",
      "2018-05-04T18:59:29.493617: step 17428, loss 0.251881, acc 0.890625\n",
      "2018-05-04T18:59:30.471337: step 17429, loss 0.306888, acc 0.875\n",
      "2018-05-04T18:59:31.436443: step 17430, loss 0.315782, acc 0.828125\n",
      "2018-05-04T18:59:32.403557: step 17431, loss 0.308033, acc 0.859375\n",
      "2018-05-04T18:59:33.346887: step 17432, loss 0.227061, acc 0.890625\n",
      "2018-05-04T18:59:34.351837: step 17433, loss 0.29894, acc 0.859375\n",
      "2018-05-04T18:59:35.329755: step 17434, loss 0.235291, acc 0.9375\n",
      "2018-05-04T18:59:36.308960: step 17435, loss 0.229584, acc 0.890625\n",
      "2018-05-04T18:59:37.307240: step 17436, loss 0.32427, acc 0.859375\n",
      "2018-05-04T18:59:38.309112: step 17437, loss 0.296513, acc 0.890625\n",
      "2018-05-04T18:59:39.304477: step 17438, loss 0.168074, acc 0.921875\n",
      "2018-05-04T18:59:40.273704: step 17439, loss 0.203302, acc 0.90625\n",
      "2018-05-04T18:59:41.227973: step 17440, loss 0.218969, acc 0.9375\n",
      "2018-05-04T18:59:42.199490: step 17441, loss 0.309779, acc 0.890625\n",
      "2018-05-04T18:59:43.161531: step 17442, loss 0.21376, acc 0.921875\n",
      "2018-05-04T18:59:44.136912: step 17443, loss 0.188355, acc 0.90625\n",
      "2018-05-04T18:59:45.104133: step 17444, loss 0.1987, acc 0.953125\n",
      "2018-05-04T18:59:46.070462: step 17445, loss 0.248072, acc 0.9375\n",
      "2018-05-04T18:59:47.030484: step 17446, loss 0.24979, acc 0.921875\n",
      "2018-05-04T18:59:47.993784: step 17447, loss 0.28746, acc 0.875\n",
      "2018-05-04T18:59:48.934953: step 17448, loss 0.389236, acc 0.84375\n",
      "2018-05-04T18:59:49.949877: step 17449, loss 0.320981, acc 0.84375\n",
      "2018-05-04T18:59:50.939252: step 17450, loss 0.334169, acc 0.875\n",
      "2018-05-04T18:59:52.055783: step 17451, loss 0.172475, acc 0.921875\n",
      "2018-05-04T18:59:53.030446: step 17452, loss 0.229211, acc 0.875\n",
      "2018-05-04T18:59:54.035545: step 17453, loss 0.198749, acc 0.890625\n",
      "2018-05-04T18:59:54.994334: step 17454, loss 0.266985, acc 0.875\n",
      "2018-05-04T18:59:55.960247: step 17455, loss 0.354154, acc 0.84375\n",
      "2018-05-04T18:59:56.926865: step 17456, loss 0.242194, acc 0.90625\n",
      "2018-05-04T18:59:57.887271: step 17457, loss 0.242939, acc 0.875\n",
      "2018-05-04T18:59:58.942856: step 17458, loss 0.25863, acc 0.875\n",
      "2018-05-04T18:59:59.881426: step 17459, loss 0.173879, acc 0.9375\n",
      "2018-05-04T19:00:00.882906: step 17460, loss 0.383601, acc 0.875\n",
      "2018-05-04T19:00:01.889831: step 17461, loss 0.481911, acc 0.8125\n",
      "2018-05-04T19:00:02.959435: step 17462, loss 0.409419, acc 0.8125\n",
      "2018-05-04T19:00:04.021435: step 17463, loss 0.224137, acc 0.890625\n",
      "2018-05-04T19:00:04.955357: step 17464, loss 0.275967, acc 0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T19:00:05.911305: step 17465, loss 0.180709, acc 0.921875\n",
      "2018-05-04T19:00:06.872237: step 17466, loss 0.181028, acc 0.921875\n",
      "2018-05-04T19:00:07.919346: step 17467, loss 0.327239, acc 0.859375\n",
      "2018-05-04T19:00:08.862272: step 17468, loss 0.224542, acc 0.875\n",
      "2018-05-04T19:00:09.810110: step 17469, loss 0.200902, acc 0.90625\n",
      "2018-05-04T19:00:10.752762: step 17470, loss 0.272507, acc 0.875\n",
      "2018-05-04T19:00:11.699882: step 17471, loss 0.20297, acc 0.9375\n",
      "2018-05-04T19:00:12.681722: step 17472, loss 0.24315, acc 0.921875\n",
      "2018-05-04T19:00:13.640906: step 17473, loss 0.236806, acc 0.890625\n",
      "2018-05-04T19:00:14.584383: step 17474, loss 0.292712, acc 0.90625\n",
      "2018-05-04T19:00:15.536624: step 17475, loss 0.19379, acc 0.9375\n",
      "2018-05-04T19:00:16.495680: step 17476, loss 0.285785, acc 0.890625\n",
      "2018-05-04T19:00:17.441657: step 17477, loss 0.25919, acc 0.890625\n",
      "2018-05-04T19:00:18.406133: step 17478, loss 0.186786, acc 0.953125\n",
      "2018-05-04T19:00:19.387710: step 17479, loss 0.317264, acc 0.875\n",
      "2018-05-04T19:00:20.389809: step 17480, loss 0.320668, acc 0.796875\n",
      "2018-05-04T19:00:21.409713: step 17481, loss 0.300887, acc 0.8125\n",
      "2018-05-04T19:00:22.365423: step 17482, loss 0.318706, acc 0.828125\n",
      "2018-05-04T19:00:23.319937: step 17483, loss 0.272313, acc 0.90625\n",
      "2018-05-04T19:00:24.286619: step 17484, loss 0.264418, acc 0.859375\n",
      "2018-05-04T19:00:25.264295: step 17485, loss 0.369302, acc 0.8125\n",
      "2018-05-04T19:00:26.224694: step 17486, loss 0.170646, acc 0.890625\n",
      "2018-05-04T19:00:27.170708: step 17487, loss 0.206157, acc 0.90625\n",
      "2018-05-04T19:00:28.100659: step 17488, loss 0.343584, acc 0.859375\n",
      "2018-05-04T19:00:29.052913: step 17489, loss 0.205051, acc 0.953125\n",
      "2018-05-04T19:00:29.995342: step 17490, loss 0.247829, acc 0.90625\n",
      "2018-05-04T19:00:30.942014: step 17491, loss 0.272317, acc 0.859375\n",
      "2018-05-04T19:00:31.913985: step 17492, loss 0.53568, acc 0.84375\n",
      "2018-05-04T19:00:32.888867: step 17493, loss 0.127824, acc 0.9375\n",
      "2018-05-04T19:00:33.858093: step 17494, loss 0.311279, acc 0.875\n",
      "2018-05-04T19:00:34.803756: step 17495, loss 0.171776, acc 0.9375\n",
      "2018-05-04T19:00:35.752039: step 17496, loss 0.339674, acc 0.828125\n",
      "2018-05-04T19:00:36.735223: step 17497, loss 0.214482, acc 0.890625\n",
      "2018-05-04T19:00:37.675234: step 17498, loss 0.244354, acc 0.90625\n",
      "2018-05-04T19:00:38.637137: step 17499, loss 0.226037, acc 0.90625\n",
      "2018-05-04T19:00:39.594449: step 17500, loss 0.332036, acc 0.828125\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T19:00:41.740283: step 17500, loss 0.216848, acc 0.92\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-17500\n",
      "\n",
      "2018-05-04T19:00:42.777750: step 17501, loss 0.252396, acc 0.90625\n",
      "2018-05-04T19:00:43.758483: step 17502, loss 0.234881, acc 0.890625\n",
      "2018-05-04T19:00:44.723858: step 17503, loss 0.319307, acc 0.890625\n",
      "2018-05-04T19:00:45.690820: step 17504, loss 0.240047, acc 0.890625\n",
      "2018-05-04T19:00:46.642870: step 17505, loss 0.295019, acc 0.890625\n",
      "2018-05-04T19:00:47.581966: step 17506, loss 0.308441, acc 0.859375\n",
      "2018-05-04T19:00:48.532294: step 17507, loss 0.293122, acc 0.859375\n",
      "2018-05-04T19:00:49.482969: step 17508, loss 0.270967, acc 0.875\n",
      "2018-05-04T19:00:50.445916: step 17509, loss 0.303904, acc 0.828125\n",
      "2018-05-04T19:00:51.406279: step 17510, loss 0.169421, acc 0.953125\n",
      "2018-05-04T19:00:52.338090: step 17511, loss 0.281141, acc 0.90625\n",
      "2018-05-04T19:00:53.284360: step 17512, loss 0.251922, acc 0.890625\n",
      "2018-05-04T19:00:54.229046: step 17513, loss 0.352613, acc 0.859375\n",
      "2018-05-04T19:00:55.188556: step 17514, loss 0.172678, acc 0.953125\n",
      "2018-05-04T19:00:56.143361: step 17515, loss 0.337301, acc 0.84375\n",
      "2018-05-04T19:00:57.115692: step 17516, loss 0.139773, acc 0.9375\n",
      "2018-05-04T19:00:58.074056: step 17517, loss 0.2271, acc 0.890625\n",
      "2018-05-04T19:00:59.058988: step 17518, loss 0.220672, acc 0.90625\n",
      "2018-05-04T19:01:00.007609: step 17519, loss 0.384507, acc 0.921875\n",
      "2018-05-04T19:01:00.946316: step 17520, loss 0.306696, acc 0.90625\n",
      "2018-05-04T19:01:01.913689: step 17521, loss 0.279514, acc 0.859375\n",
      "2018-05-04T19:01:02.914822: step 17522, loss 0.269017, acc 0.84375\n",
      "2018-05-04T19:01:03.882079: step 17523, loss 0.199409, acc 0.953125\n",
      "2018-05-04T19:01:04.911943: step 17524, loss 0.210514, acc 0.953125\n",
      "2018-05-04T19:01:05.868262: step 17525, loss 0.25483, acc 0.90625\n",
      "2018-05-04T19:01:06.810537: step 17526, loss 0.205054, acc 0.90625\n",
      "2018-05-04T19:01:07.836142: step 17527, loss 0.282267, acc 0.875\n",
      "2018-05-04T19:01:08.776155: step 17528, loss 0.388775, acc 0.84375\n",
      "2018-05-04T19:01:09.711072: step 17529, loss 0.165315, acc 0.9375\n",
      "2018-05-04T19:01:10.652442: step 17530, loss 0.187704, acc 0.921875\n",
      "2018-05-04T19:01:11.582708: step 17531, loss 0.379991, acc 0.890625\n",
      "2018-05-04T19:01:12.565177: step 17532, loss 0.339924, acc 0.875\n",
      "2018-05-04T19:01:13.529630: step 17533, loss 0.341707, acc 0.890625\n",
      "2018-05-04T19:01:14.488556: step 17534, loss 0.216172, acc 0.9375\n",
      "2018-05-04T19:01:15.449285: step 17535, loss 0.30515, acc 0.859375\n",
      "2018-05-04T19:01:16.390118: step 17536, loss 0.219082, acc 0.90625\n",
      "2018-05-04T19:01:17.366871: step 17537, loss 0.273745, acc 0.859375\n",
      "2018-05-04T19:01:18.303492: step 17538, loss 0.24268, acc 0.875\n",
      "2018-05-04T19:01:19.254079: step 17539, loss 0.18286, acc 0.921875\n",
      "2018-05-04T19:01:20.225038: step 17540, loss 0.278299, acc 0.84375\n",
      "2018-05-04T19:01:21.182181: step 17541, loss 0.214353, acc 0.9375\n",
      "2018-05-04T19:01:22.140660: step 17542, loss 0.319207, acc 0.84375\n",
      "2018-05-04T19:01:23.112816: step 17543, loss 0.20417, acc 0.90625\n",
      "2018-05-04T19:01:24.054453: step 17544, loss 0.212978, acc 0.90625\n",
      "2018-05-04T19:01:25.025196: step 17545, loss 0.350338, acc 0.859375\n",
      "2018-05-04T19:01:26.056659: step 17546, loss 0.253521, acc 0.90625\n",
      "2018-05-04T19:01:26.995070: step 17547, loss 0.257004, acc 0.859375\n",
      "2018-05-04T19:01:27.938499: step 17548, loss 0.321334, acc 0.890625\n",
      "2018-05-04T19:01:28.874262: step 17549, loss 0.212417, acc 0.921875\n",
      "2018-05-04T19:01:29.812555: step 17550, loss 0.342367, acc 0.875\n",
      "2018-05-04T19:01:30.845945: step 17551, loss 0.345921, acc 0.875\n",
      "2018-05-04T19:01:31.830178: step 17552, loss 0.330945, acc 0.890625\n",
      "2018-05-04T19:01:32.788868: step 17553, loss 0.198293, acc 0.9375\n",
      "2018-05-04T19:01:33.883809: step 17554, loss 0.297162, acc 0.859375\n",
      "2018-05-04T19:01:34.928070: step 17555, loss 0.417194, acc 0.875\n",
      "2018-05-04T19:01:36.029802: step 17556, loss 0.268484, acc 0.890625\n",
      "2018-05-04T19:01:37.124508: step 17557, loss 0.313255, acc 0.890625\n",
      "2018-05-04T19:01:38.057642: step 17558, loss 0.275194, acc 0.875\n",
      "2018-05-04T19:01:38.992951: step 17559, loss 0.256947, acc 0.90625\n",
      "2018-05-04T19:01:39.944566: step 17560, loss 0.26597, acc 0.875\n",
      "2018-05-04T19:01:40.909029: step 17561, loss 0.22026, acc 0.890625\n",
      "2018-05-04T19:01:41.875055: step 17562, loss 0.308432, acc 0.875\n",
      "2018-05-04T19:01:42.843870: step 17563, loss 0.33979, acc 0.859375\n",
      "2018-05-04T19:01:43.894961: step 17564, loss 0.232192, acc 0.90625\n",
      "2018-05-04T19:01:44.906004: step 17565, loss 0.223851, acc 0.90625\n",
      "2018-05-04T19:01:45.847356: step 17566, loss 0.241135, acc 0.9375\n",
      "2018-05-04T19:01:46.792633: step 17567, loss 0.300935, acc 0.90625\n",
      "2018-05-04T19:01:47.742758: step 17568, loss 0.310175, acc 0.875\n",
      "2018-05-04T19:01:48.685687: step 17569, loss 0.394903, acc 0.859375\n",
      "2018-05-04T19:01:49.621085: step 17570, loss 0.341402, acc 0.859375\n",
      "2018-05-04T19:01:50.632704: step 17571, loss 0.364591, acc 0.859375\n",
      "2018-05-04T19:01:51.565374: step 17572, loss 0.234425, acc 0.890625\n",
      "2018-05-04T19:01:52.498251: step 17573, loss 0.229094, acc 0.90625\n",
      "2018-05-04T19:01:53.453357: step 17574, loss 0.418035, acc 0.828125\n",
      "2018-05-04T19:01:54.419894: step 17575, loss 0.259495, acc 0.921875\n",
      "2018-05-04T19:01:55.392704: step 17576, loss 0.210948, acc 0.859375\n",
      "2018-05-04T19:01:56.367034: step 17577, loss 0.195338, acc 0.921875\n",
      "2018-05-04T19:01:57.305043: step 17578, loss 0.235488, acc 0.890625\n",
      "2018-05-04T19:01:58.238060: step 17579, loss 0.328526, acc 0.859375\n",
      "2018-05-04T19:01:59.187928: step 17580, loss 0.313047, acc 0.84375\n",
      "2018-05-04T19:02:00.165634: step 17581, loss 0.186036, acc 0.875\n",
      "2018-05-04T19:02:01.131471: step 17582, loss 0.211427, acc 0.890625\n",
      "2018-05-04T19:02:02.089806: step 17583, loss 0.323368, acc 0.890625\n",
      "2018-05-04T19:02:03.021853: step 17584, loss 0.263525, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T19:02:04.055415: step 17585, loss 0.232624, acc 0.890625\n",
      "2018-05-04T19:02:05.092243: step 17586, loss 0.254779, acc 0.90625\n",
      "2018-05-04T19:02:06.125411: step 17587, loss 0.287405, acc 0.875\n",
      "2018-05-04T19:02:07.138832: step 17588, loss 0.297891, acc 0.90625\n",
      "2018-05-04T19:02:08.140019: step 17589, loss 0.345661, acc 0.828125\n",
      "2018-05-04T19:02:09.065732: step 17590, loss 0.335072, acc 0.859375\n",
      "2018-05-04T19:02:10.075207: step 17591, loss 0.359167, acc 0.796875\n",
      "2018-05-04T19:02:10.995310: step 17592, loss 0.146437, acc 0.953125\n",
      "2018-05-04T19:02:11.928107: step 17593, loss 0.250042, acc 0.890625\n",
      "2018-05-04T19:02:12.939653: step 17594, loss 0.232282, acc 0.921875\n",
      "2018-05-04T19:02:13.873281: step 17595, loss 0.128058, acc 0.96875\n",
      "2018-05-04T19:02:14.793386: step 17596, loss 0.347757, acc 0.859375\n",
      "2018-05-04T19:02:15.746096: step 17597, loss 0.173688, acc 0.96875\n",
      "2018-05-04T19:02:16.678270: step 17598, loss 0.314079, acc 0.875\n",
      "2018-05-04T19:02:17.656320: step 17599, loss 0.418269, acc 0.859375\n",
      "2018-05-04T19:02:18.664725: step 17600, loss 0.256263, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T19:02:21.154315: step 17600, loss 0.215214, acc 0.922\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-17600\n",
      "\n",
      "2018-05-04T19:02:22.208294: step 17601, loss 0.18686, acc 0.9375\n",
      "2018-05-04T19:02:23.187795: step 17602, loss 0.281007, acc 0.890625\n",
      "2018-05-04T19:02:24.191957: step 17603, loss 0.255524, acc 0.859375\n",
      "2018-05-04T19:02:25.187145: step 17604, loss 0.302531, acc 0.859375\n",
      "2018-05-04T19:02:26.230897: step 17605, loss 0.330978, acc 0.859375\n",
      "2018-05-04T19:02:27.274258: step 17606, loss 0.197352, acc 0.921875\n",
      "2018-05-04T19:02:28.309468: step 17607, loss 0.160178, acc 0.9375\n",
      "2018-05-04T19:02:29.295320: step 17608, loss 0.223355, acc 0.921875\n",
      "2018-05-04T19:02:30.307536: step 17609, loss 0.294325, acc 0.875\n",
      "2018-05-04T19:02:31.294639: step 17610, loss 0.302427, acc 0.859375\n",
      "2018-05-04T19:02:32.264465: step 17611, loss 0.23088, acc 0.890625\n",
      "2018-05-04T19:02:33.230229: step 17612, loss 0.173317, acc 0.953125\n",
      "2018-05-04T19:02:34.205975: step 17613, loss 0.361193, acc 0.796875\n",
      "2018-05-04T19:02:35.193010: step 17614, loss 0.299591, acc 0.828125\n",
      "2018-05-04T19:02:36.176835: step 17615, loss 0.187093, acc 0.90625\n",
      "2018-05-04T19:02:37.177082: step 17616, loss 0.226423, acc 0.921875\n",
      "2018-05-04T19:02:38.221262: step 17617, loss 0.330204, acc 0.859375\n",
      "2018-05-04T19:02:39.184926: step 17618, loss 0.204312, acc 0.875\n",
      "2018-05-04T19:02:40.159475: step 17619, loss 0.197895, acc 0.921875\n",
      "2018-05-04T19:02:41.206290: step 17620, loss 0.423163, acc 0.828125\n",
      "2018-05-04T19:02:42.171373: step 17621, loss 0.344525, acc 0.828125\n",
      "2018-05-04T19:02:43.143161: step 17622, loss 0.22445, acc 0.859375\n",
      "2018-05-04T19:02:44.076237: step 17623, loss 0.272122, acc 0.890625\n",
      "2018-05-04T19:02:45.108901: step 17624, loss 0.219139, acc 0.90625\n",
      "2018-05-04T19:02:46.057329: step 17625, loss 0.356681, acc 0.828125\n",
      "2018-05-04T19:02:47.003934: step 17626, loss 0.251017, acc 0.875\n",
      "2018-05-04T19:02:47.968365: step 17627, loss 0.342011, acc 0.84375\n",
      "2018-05-04T19:02:48.931937: step 17628, loss 0.363249, acc 0.796875\n",
      "2018-05-04T19:02:49.933146: step 17629, loss 0.222303, acc 0.921875\n",
      "2018-05-04T19:02:50.940919: step 17630, loss 0.346875, acc 0.859375\n",
      "2018-05-04T19:02:51.930815: step 17631, loss 0.418672, acc 0.84375\n",
      "2018-05-04T19:02:52.990966: step 17632, loss 0.262064, acc 0.90625\n",
      "2018-05-04T19:02:53.951308: step 17633, loss 0.258351, acc 0.859375\n",
      "2018-05-04T19:02:54.908137: step 17634, loss 0.174459, acc 0.9375\n",
      "2018-05-04T19:02:55.955735: step 17635, loss 0.416964, acc 0.859375\n",
      "2018-05-04T19:02:56.928292: step 17636, loss 0.2851, acc 0.90625\n",
      "2018-05-04T19:02:57.911043: step 17637, loss 0.212956, acc 0.921875\n",
      "2018-05-04T19:02:58.896478: step 17638, loss 0.162311, acc 0.9375\n",
      "2018-05-04T19:02:59.848079: step 17639, loss 0.242585, acc 0.953125\n",
      "2018-05-04T19:03:00.833185: step 17640, loss 0.461412, acc 0.796875\n",
      "2018-05-04T19:03:01.792586: step 17641, loss 0.266409, acc 0.875\n",
      "2018-05-04T19:03:02.779327: step 17642, loss 0.19139, acc 0.90625\n",
      "2018-05-04T19:03:03.747468: step 17643, loss 0.232717, acc 0.890625\n",
      "2018-05-04T19:03:04.774622: step 17644, loss 0.183126, acc 0.9375\n",
      "2018-05-04T19:03:05.764758: step 17645, loss 0.235616, acc 0.90625\n",
      "2018-05-04T19:03:06.755496: step 17646, loss 0.293482, acc 0.875\n",
      "2018-05-04T19:03:07.731024: step 17647, loss 0.376038, acc 0.78125\n",
      "2018-05-04T19:03:08.716811: step 17648, loss 0.374806, acc 0.828125\n",
      "2018-05-04T19:03:09.689615: step 17649, loss 0.22061, acc 0.90625\n",
      "2018-05-04T19:03:10.679168: step 17650, loss 0.245163, acc 0.90625\n",
      "2018-05-04T19:03:11.653530: step 17651, loss 0.27664, acc 0.890625\n",
      "2018-05-04T19:03:12.609114: step 17652, loss 0.314797, acc 0.859375\n",
      "2018-05-04T19:03:13.573574: step 17653, loss 0.481873, acc 0.765625\n",
      "2018-05-04T19:03:14.543382: step 17654, loss 0.323571, acc 0.875\n",
      "2018-05-04T19:03:15.544123: step 17655, loss 0.343415, acc 0.90625\n",
      "2018-05-04T19:03:16.520213: step 17656, loss 0.173275, acc 0.921875\n",
      "2018-05-04T19:03:17.576606: step 17657, loss 0.202778, acc 0.921875\n",
      "2018-05-04T19:03:18.566785: step 17658, loss 0.285488, acc 0.890625\n",
      "2018-05-04T19:03:19.518152: step 17659, loss 0.295574, acc 0.890625\n",
      "2018-05-04T19:03:20.490678: step 17660, loss 0.317743, acc 0.875\n",
      "2018-05-04T19:03:21.470781: step 17661, loss 0.217892, acc 0.875\n",
      "2018-05-04T19:03:22.460313: step 17662, loss 0.263941, acc 0.890625\n",
      "2018-05-04T19:03:23.455756: step 17663, loss 0.237013, acc 0.953125\n",
      "2018-05-04T19:03:24.424968: step 17664, loss 0.354102, acc 0.828125\n",
      "2018-05-04T19:03:25.378131: step 17665, loss 0.356637, acc 0.828125\n",
      "2018-05-04T19:03:26.349518: step 17666, loss 0.290636, acc 0.90625\n",
      "2018-05-04T19:03:27.313757: step 17667, loss 0.188458, acc 0.921875\n",
      "2018-05-04T19:03:28.265204: step 17668, loss 0.203568, acc 0.90625\n",
      "2018-05-04T19:03:29.230794: step 17669, loss 0.293165, acc 0.890625\n",
      "2018-05-04T19:03:30.208225: step 17670, loss 0.421654, acc 0.828125\n",
      "2018-05-04T19:03:31.289206: step 17671, loss 0.227614, acc 0.9375\n",
      "2018-05-04T19:03:32.312711: step 17672, loss 0.243242, acc 0.875\n",
      "2018-05-04T19:03:33.283341: step 17673, loss 0.256416, acc 0.875\n",
      "2018-05-04T19:03:34.254278: step 17674, loss 0.221238, acc 0.921875\n",
      "2018-05-04T19:03:35.208977: step 17675, loss 0.2893, acc 0.890625\n",
      "2018-05-04T19:03:36.156477: step 17676, loss 0.177813, acc 0.953125\n",
      "2018-05-04T19:03:37.124177: step 17677, loss 0.273413, acc 0.875\n",
      "2018-05-04T19:03:38.146614: step 17678, loss 0.282739, acc 0.875\n",
      "2018-05-04T19:03:39.098157: step 17679, loss 0.252622, acc 0.890625\n",
      "2018-05-04T19:03:40.062942: step 17680, loss 0.228876, acc 0.890625\n",
      "2018-05-04T19:03:41.050199: step 17681, loss 0.342513, acc 0.84375\n",
      "2018-05-04T19:03:42.014441: step 17682, loss 0.353228, acc 0.84375\n",
      "2018-05-04T19:03:43.064638: step 17683, loss 0.306737, acc 0.90625\n",
      "2018-05-04T19:03:44.031963: step 17684, loss 0.394277, acc 0.90625\n",
      "2018-05-04T19:03:44.988276: step 17685, loss 0.291333, acc 0.890625\n",
      "2018-05-04T19:03:45.960495: step 17686, loss 0.321847, acc 0.859375\n",
      "2018-05-04T19:03:46.958956: step 17687, loss 0.328769, acc 0.796875\n",
      "2018-05-04T19:03:47.906187: step 17688, loss 0.280021, acc 0.875\n",
      "2018-05-04T19:03:48.877707: step 17689, loss 0.2379, acc 0.90625\n",
      "2018-05-04T19:03:49.823584: step 17690, loss 0.180344, acc 0.921875\n",
      "2018-05-04T19:03:50.884150: step 17691, loss 0.361567, acc 0.796875\n",
      "2018-05-04T19:03:51.831353: step 17692, loss 0.239194, acc 0.890625\n",
      "2018-05-04T19:03:52.857218: step 17693, loss 0.207667, acc 0.921875\n",
      "2018-05-04T19:03:53.793852: step 17694, loss 0.165205, acc 0.9375\n",
      "2018-05-04T19:03:54.754017: step 17695, loss 0.226938, acc 0.890625\n",
      "2018-05-04T19:03:55.706736: step 17696, loss 0.240338, acc 0.890625\n",
      "2018-05-04T19:03:56.651352: step 17697, loss 0.261362, acc 0.9375\n",
      "2018-05-04T19:03:57.605609: step 17698, loss 0.279691, acc 0.890625\n",
      "2018-05-04T19:03:58.563625: step 17699, loss 0.235355, acc 0.890625\n",
      "2018-05-04T19:03:59.519897: step 17700, loss 0.128156, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T19:04:01.687010: step 17700, loss 0.220039, acc 0.928\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-17700\n",
      "\n",
      "2018-05-04T19:04:02.742634: step 17701, loss 0.307648, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T19:04:03.714780: step 17702, loss 0.242162, acc 0.890625\n",
      "2018-05-04T19:04:04.681671: step 17703, loss 0.217085, acc 0.890625\n",
      "2018-05-04T19:04:05.662038: step 17704, loss 0.197003, acc 0.90625\n",
      "2018-05-04T19:04:06.645326: step 17705, loss 0.304147, acc 0.875\n",
      "2018-05-04T19:04:07.607753: step 17706, loss 0.267889, acc 0.921875\n",
      "2018-05-04T19:04:08.673825: step 17707, loss 0.186906, acc 0.90625\n",
      "2018-05-04T19:04:09.605906: step 17708, loss 0.256853, acc 0.890625\n",
      "2018-05-04T19:04:10.573122: step 17709, loss 0.196772, acc 0.921875\n",
      "2018-05-04T19:04:11.517524: step 17710, loss 0.314692, acc 0.84375\n",
      "2018-05-04T19:04:12.447915: step 17711, loss 0.277318, acc 0.859375\n",
      "2018-05-04T19:04:13.407482: step 17712, loss 0.148764, acc 0.96875\n",
      "2018-05-04T19:04:14.424957: step 17713, loss 0.339824, acc 0.890625\n",
      "2018-05-04T19:04:15.398442: step 17714, loss 0.252901, acc 0.90625\n",
      "2018-05-04T19:04:16.361678: step 17715, loss 0.141415, acc 0.953125\n",
      "2018-05-04T19:04:17.306305: step 17716, loss 0.157563, acc 0.96875\n",
      "2018-05-04T19:04:18.242165: step 17717, loss 0.253687, acc 0.90625\n",
      "2018-05-04T19:04:19.176350: step 17718, loss 0.261191, acc 0.875\n",
      "2018-05-04T19:04:20.117612: step 17719, loss 0.328377, acc 0.875\n",
      "2018-05-04T19:04:21.102186: step 17720, loss 0.261101, acc 0.875\n",
      "2018-05-04T19:04:22.055803: step 17721, loss 0.22817, acc 0.921875\n",
      "2018-05-04T19:04:23.028092: step 17722, loss 0.315772, acc 0.90625\n",
      "2018-05-04T19:04:23.995075: step 17723, loss 0.387773, acc 0.828125\n",
      "2018-05-04T19:04:24.957855: step 17724, loss 0.185716, acc 0.9375\n",
      "2018-05-04T19:04:25.987243: step 17725, loss 0.194877, acc 0.921875\n",
      "2018-05-04T19:04:26.901048: step 17726, loss 0.221096, acc 0.9375\n",
      "2018-05-04T19:04:27.845906: step 17727, loss 0.283496, acc 0.859375\n",
      "2018-05-04T19:04:28.787864: step 17728, loss 0.294547, acc 0.875\n",
      "2018-05-04T19:04:29.828054: step 17729, loss 0.300625, acc 0.890625\n",
      "2018-05-04T19:04:30.765424: step 17730, loss 0.225231, acc 0.90625\n",
      "2018-05-04T19:04:31.696713: step 17731, loss 0.299906, acc 0.859375\n",
      "2018-05-04T19:04:32.640945: step 17732, loss 0.251015, acc 0.890625\n",
      "2018-05-04T19:04:33.668146: step 17733, loss 0.278679, acc 0.875\n",
      "2018-05-04T19:04:34.827405: step 17734, loss 0.285828, acc 0.890625\n",
      "2018-05-04T19:04:35.850059: step 17735, loss 0.307934, acc 0.859375\n",
      "2018-05-04T19:04:36.869509: step 17736, loss 0.168589, acc 0.921875\n",
      "2018-05-04T19:04:37.839716: step 17737, loss 0.21616, acc 0.921875\n",
      "2018-05-04T19:04:38.789559: step 17738, loss 0.183948, acc 0.9375\n",
      "2018-05-04T19:04:39.746158: step 17739, loss 0.261303, acc 0.859375\n",
      "2018-05-04T19:04:40.690438: step 17740, loss 0.171054, acc 0.953125\n",
      "2018-05-04T19:04:41.675873: step 17741, loss 0.210215, acc 0.921875\n",
      "2018-05-04T19:04:42.621000: step 17742, loss 0.142822, acc 0.96875\n",
      "2018-05-04T19:04:43.579205: step 17743, loss 0.304484, acc 0.90625\n",
      "2018-05-04T19:04:44.568245: step 17744, loss 0.269468, acc 0.890625\n",
      "2018-05-04T19:04:45.524283: step 17745, loss 0.243715, acc 0.921875\n",
      "2018-05-04T19:04:46.486963: step 17746, loss 0.287171, acc 0.890625\n",
      "2018-05-04T19:04:47.426308: step 17747, loss 0.239656, acc 0.90625\n",
      "2018-05-04T19:04:48.387819: step 17748, loss 0.367014, acc 0.859375\n",
      "2018-05-04T19:04:49.324988: step 17749, loss 0.306858, acc 0.875\n",
      "2018-05-04T19:04:50.269816: step 17750, loss 0.355741, acc 0.890625\n",
      "2018-05-04T19:04:51.225630: step 17751, loss 0.348167, acc 0.921875\n",
      "2018-05-04T19:04:52.162889: step 17752, loss 0.255745, acc 0.890625\n",
      "2018-05-04T19:04:53.104906: step 17753, loss 0.254727, acc 0.875\n",
      "2018-05-04T19:04:54.066716: step 17754, loss 0.320001, acc 0.84375\n",
      "2018-05-04T19:04:55.026707: step 17755, loss 0.269816, acc 0.90625\n",
      "2018-05-04T19:04:56.040526: step 17756, loss 0.362928, acc 0.84375\n",
      "2018-05-04T19:04:56.971718: step 17757, loss 0.252767, acc 0.90625\n",
      "2018-05-04T19:04:57.939657: step 17758, loss 0.168771, acc 0.96875\n",
      "2018-05-04T19:04:58.899235: step 17759, loss 0.230922, acc 0.90625\n",
      "2018-05-04T19:04:59.851229: step 17760, loss 0.231884, acc 0.90625\n",
      "2018-05-04T19:05:00.797911: step 17761, loss 0.289356, acc 0.859375\n",
      "2018-05-04T19:05:01.782618: step 17762, loss 0.193597, acc 0.921875\n",
      "2018-05-04T19:05:02.815572: step 17763, loss 0.358671, acc 0.84375\n",
      "2018-05-04T19:05:03.845500: step 17764, loss 0.369294, acc 0.890625\n",
      "2018-05-04T19:05:04.794335: step 17765, loss 0.211447, acc 0.90625\n",
      "2018-05-04T19:05:05.749337: step 17766, loss 0.262802, acc 0.90625\n",
      "2018-05-04T19:05:06.693788: step 17767, loss 0.266629, acc 0.921875\n",
      "2018-05-04T19:05:07.625681: step 17768, loss 0.272274, acc 0.890625\n",
      "2018-05-04T19:05:08.555266: step 17769, loss 0.25154, acc 0.90625\n",
      "2018-05-04T19:05:09.492484: step 17770, loss 0.284733, acc 0.859375\n",
      "2018-05-04T19:05:10.467789: step 17771, loss 0.24791, acc 0.859375\n",
      "2018-05-04T19:05:11.438225: step 17772, loss 0.261571, acc 0.875\n",
      "2018-05-04T19:05:12.397085: step 17773, loss 0.306806, acc 0.859375\n",
      "2018-05-04T19:05:13.364004: step 17774, loss 0.468157, acc 0.859375\n",
      "2018-05-04T19:05:14.300563: step 17775, loss 0.205339, acc 0.9375\n",
      "2018-05-04T19:05:15.247218: step 17776, loss 0.236725, acc 0.90625\n",
      "2018-05-04T19:05:16.199272: step 17777, loss 0.171422, acc 0.921875\n",
      "2018-05-04T19:05:17.177880: step 17778, loss 0.208657, acc 0.953125\n",
      "2018-05-04T19:05:18.233191: step 17779, loss 0.345577, acc 0.859375\n",
      "2018-05-04T19:05:19.233232: step 17780, loss 0.271436, acc 0.890625\n",
      "2018-05-04T19:05:20.306688: step 17781, loss 0.27019, acc 0.890625\n",
      "2018-05-04T19:05:21.345353: step 17782, loss 0.139819, acc 0.9375\n",
      "2018-05-04T19:05:22.404570: step 17783, loss 0.212348, acc 0.90625\n",
      "2018-05-04T19:05:23.324116: step 17784, loss 0.264153, acc 0.921875\n",
      "2018-05-04T19:05:24.254531: step 17785, loss 0.356984, acc 0.859375\n",
      "2018-05-04T19:05:25.275014: step 17786, loss 0.198014, acc 0.90625\n",
      "2018-05-04T19:05:26.203279: step 17787, loss 0.259944, acc 0.875\n",
      "2018-05-04T19:05:27.143011: step 17788, loss 0.282564, acc 0.921875\n",
      "2018-05-04T19:05:28.060728: step 17789, loss 0.309587, acc 0.9375\n",
      "2018-05-04T19:05:29.079370: step 17790, loss 0.240943, acc 0.921875\n",
      "2018-05-04T19:05:30.013771: step 17791, loss 0.276281, acc 0.921875\n",
      "2018-05-04T19:05:30.960393: step 17792, loss 0.242807, acc 0.875\n",
      "2018-05-04T19:05:31.971887: step 17793, loss 0.161841, acc 0.953125\n",
      "2018-05-04T19:05:32.913588: step 17794, loss 0.235486, acc 0.90625\n",
      "2018-05-04T19:05:33.862658: step 17795, loss 0.2208, acc 0.90625\n",
      "2018-05-04T19:05:34.799730: step 17796, loss 0.241057, acc 0.890625\n",
      "2018-05-04T19:05:35.762609: step 17797, loss 0.251474, acc 0.859375\n",
      "2018-05-04T19:05:36.716194: step 17798, loss 0.148342, acc 0.953125\n",
      "2018-05-04T19:05:37.677905: step 17799, loss 0.304172, acc 0.890625\n",
      "2018-05-04T19:05:38.647472: step 17800, loss 0.273318, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T19:05:41.671612: step 17800, loss 0.212892, acc 0.928\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-17800\n",
      "\n",
      "2018-05-04T19:05:42.722184: step 17801, loss 0.215549, acc 0.921875\n",
      "2018-05-04T19:05:43.777303: step 17802, loss 0.208738, acc 0.90625\n",
      "2018-05-04T19:05:44.776498: step 17803, loss 0.362866, acc 0.828125\n",
      "2018-05-04T19:05:45.828592: step 17804, loss 0.220058, acc 0.921875\n",
      "2018-05-04T19:05:46.819755: step 17805, loss 0.195934, acc 0.90625\n",
      "2018-05-04T19:05:47.845547: step 17806, loss 0.185017, acc 0.9375\n",
      "2018-05-04T19:05:48.840186: step 17807, loss 0.224126, acc 0.875\n",
      "2018-05-04T19:05:49.835105: step 17808, loss 0.217446, acc 0.890625\n",
      "2018-05-04T19:05:50.806076: step 17809, loss 0.208438, acc 0.921875\n",
      "2018-05-04T19:05:51.817682: step 17810, loss 0.157375, acc 0.921875\n",
      "2018-05-04T19:05:52.875566: step 17811, loss 0.176699, acc 0.953125\n",
      "2018-05-04T19:05:53.848564: step 17812, loss 0.286903, acc 0.828125\n",
      "2018-05-04T19:05:54.810337: step 17813, loss 0.259112, acc 0.859375\n",
      "2018-05-04T19:05:55.784050: step 17814, loss 0.141854, acc 0.9375\n",
      "2018-05-04T19:05:56.748552: step 17815, loss 0.175838, acc 0.9375\n",
      "2018-05-04T19:05:57.712939: step 17816, loss 0.173166, acc 0.90625\n",
      "2018-05-04T19:05:58.695795: step 17817, loss 0.16013, acc 0.953125\n",
      "2018-05-04T19:05:59.750717: step 17818, loss 0.304427, acc 0.875\n",
      "2018-05-04T19:06:00.724143: step 17819, loss 0.16188, acc 0.90625\n",
      "2018-05-04T19:06:01.686393: step 17820, loss 0.18778, acc 0.9375\n",
      "2018-05-04T19:06:02.636372: step 17821, loss 0.119509, acc 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T19:06:03.603542: step 17822, loss 0.331295, acc 0.859375\n",
      "2018-05-04T19:06:04.679740: step 17823, loss 0.199879, acc 0.921875\n",
      "2018-05-04T19:06:05.724613: step 17824, loss 0.254694, acc 0.859375\n",
      "2018-05-04T19:06:06.771266: step 17825, loss 0.288833, acc 0.859375\n",
      "2018-05-04T19:06:07.814864: step 17826, loss 0.423362, acc 0.828125\n",
      "2018-05-04T19:06:08.781232: step 17827, loss 0.141778, acc 0.9375\n",
      "2018-05-04T19:06:09.711096: step 17828, loss 0.279581, acc 0.875\n",
      "2018-05-04T19:06:10.668410: step 17829, loss 0.288366, acc 0.84375\n",
      "2018-05-04T19:06:11.634099: step 17830, loss 0.290369, acc 0.90625\n",
      "2018-05-04T19:06:12.698980: step 17831, loss 0.184122, acc 0.90625\n",
      "2018-05-04T19:06:13.662524: step 17832, loss 0.189402, acc 0.9375\n",
      "2018-05-04T19:06:14.622167: step 17833, loss 0.214531, acc 0.9375\n",
      "2018-05-04T19:06:15.597650: step 17834, loss 0.19866, acc 0.921875\n",
      "2018-05-04T19:06:16.583219: step 17835, loss 0.299232, acc 0.875\n",
      "2018-05-04T19:06:17.566994: step 17836, loss 0.277655, acc 0.875\n",
      "2018-05-04T19:06:18.538814: step 17837, loss 0.323449, acc 0.875\n",
      "2018-05-04T19:06:19.527519: step 17838, loss 0.187156, acc 0.90625\n",
      "2018-05-04T19:06:20.499661: step 17839, loss 0.383875, acc 0.84375\n",
      "2018-05-04T19:06:21.461858: step 17840, loss 0.377255, acc 0.859375\n",
      "2018-05-04T19:06:22.427768: step 17841, loss 0.223811, acc 0.90625\n",
      "2018-05-04T19:06:23.391281: step 17842, loss 0.230005, acc 0.90625\n",
      "2018-05-04T19:06:24.434774: step 17843, loss 0.266643, acc 0.890625\n",
      "2018-05-04T19:06:25.462379: step 17844, loss 0.391294, acc 0.859375\n",
      "2018-05-04T19:06:26.424451: step 17845, loss 0.381972, acc 0.828125\n",
      "2018-05-04T19:06:27.392825: step 17846, loss 0.38275, acc 0.890625\n",
      "2018-05-04T19:06:28.361486: step 17847, loss 0.156619, acc 0.9375\n",
      "2018-05-04T19:06:29.334141: step 17848, loss 0.219041, acc 0.921875\n",
      "2018-05-04T19:06:30.291565: step 17849, loss 0.149784, acc 0.921875\n",
      "2018-05-04T19:06:31.271427: step 17850, loss 0.184095, acc 0.921875\n",
      "2018-05-04T19:06:32.236241: step 17851, loss 0.206626, acc 0.90625\n",
      "2018-05-04T19:06:33.220883: step 17852, loss 0.306939, acc 0.90625\n",
      "2018-05-04T19:06:34.200043: step 17853, loss 0.222011, acc 0.890625\n",
      "2018-05-04T19:06:35.176455: step 17854, loss 0.147064, acc 0.96875\n",
      "2018-05-04T19:06:36.182226: step 17855, loss 0.258545, acc 0.859375\n",
      "2018-05-04T19:06:37.217053: step 17856, loss 0.140571, acc 0.953125\n",
      "2018-05-04T19:06:38.193083: step 17857, loss 0.222098, acc 0.90625\n",
      "2018-05-04T19:06:39.168557: step 17858, loss 0.267451, acc 0.921875\n",
      "2018-05-04T19:06:40.116227: step 17859, loss 0.292504, acc 0.875\n",
      "2018-05-04T19:06:41.086209: step 17860, loss 0.326568, acc 0.859375\n",
      "2018-05-04T19:06:42.086946: step 17861, loss 0.223589, acc 0.890625\n",
      "2018-05-04T19:06:43.075636: step 17862, loss 0.157279, acc 0.9375\n",
      "2018-05-04T19:06:44.030563: step 17863, loss 0.347316, acc 0.90625\n",
      "2018-05-04T19:06:44.992801: step 17864, loss 0.212141, acc 0.90625\n",
      "2018-05-04T19:06:45.999057: step 17865, loss 0.277314, acc 0.875\n",
      "2018-05-04T19:06:47.045851: step 17866, loss 0.330834, acc 0.859375\n",
      "2018-05-04T19:06:48.064651: step 17867, loss 0.167393, acc 0.90625\n",
      "2018-05-04T19:06:49.060932: step 17868, loss 0.333409, acc 0.8125\n",
      "2018-05-04T19:06:50.004162: step 17869, loss 0.256865, acc 0.859375\n",
      "2018-05-04T19:06:51.070921: step 17870, loss 0.370257, acc 0.875\n",
      "2018-05-04T19:06:52.125357: step 17871, loss 0.424121, acc 0.859375\n",
      "2018-05-04T19:06:53.050836: step 17872, loss 0.303089, acc 0.859375\n",
      "2018-05-04T19:06:54.053494: step 17873, loss 0.33536, acc 0.890625\n",
      "2018-05-04T19:06:54.989513: step 17874, loss 0.255095, acc 0.859375\n",
      "2018-05-04T19:06:55.943126: step 17875, loss 0.440127, acc 0.78125\n",
      "2018-05-04T19:06:56.891181: step 17876, loss 0.337726, acc 0.859375\n",
      "2018-05-04T19:06:57.830524: step 17877, loss 0.257571, acc 0.828125\n",
      "2018-05-04T19:06:58.807418: step 17878, loss 0.175094, acc 0.9375\n",
      "2018-05-04T19:06:59.770282: step 17879, loss 0.241917, acc 0.890625\n",
      "2018-05-04T19:07:00.752186: step 17880, loss 0.350576, acc 0.796875\n",
      "2018-05-04T19:07:01.733530: step 17881, loss 0.180674, acc 0.90625\n",
      "2018-05-04T19:07:02.699699: step 17882, loss 0.129012, acc 0.96875\n",
      "2018-05-04T19:07:03.668327: step 17883, loss 0.254115, acc 0.875\n",
      "2018-05-04T19:07:04.671624: step 17884, loss 0.177259, acc 0.96875\n",
      "2018-05-04T19:07:05.607932: step 17885, loss 0.300859, acc 0.859375\n",
      "2018-05-04T19:07:06.560702: step 17886, loss 0.182841, acc 0.9375\n",
      "2018-05-04T19:07:07.511166: step 17887, loss 0.338094, acc 0.875\n",
      "2018-05-04T19:07:08.466243: step 17888, loss 0.177763, acc 0.90625\n",
      "2018-05-04T19:07:09.426237: step 17889, loss 0.27951, acc 0.890625\n",
      "2018-05-04T19:07:10.378120: step 17890, loss 0.239636, acc 0.953125\n",
      "2018-05-04T19:07:11.358408: step 17891, loss 0.262277, acc 0.859375\n",
      "2018-05-04T19:07:12.336547: step 17892, loss 0.373275, acc 0.84375\n",
      "2018-05-04T19:07:13.314556: step 17893, loss 0.335499, acc 0.828125\n",
      "2018-05-04T19:07:14.338808: step 17894, loss 0.174454, acc 0.921875\n",
      "2018-05-04T19:07:15.289086: step 17895, loss 0.160767, acc 0.9375\n",
      "2018-05-04T19:07:16.226153: step 17896, loss 0.294103, acc 0.890625\n",
      "2018-05-04T19:07:17.198325: step 17897, loss 0.272639, acc 0.90625\n",
      "2018-05-04T19:07:18.252049: step 17898, loss 0.286765, acc 0.84375\n",
      "2018-05-04T19:07:19.211782: step 17899, loss 0.246391, acc 0.90625\n",
      "2018-05-04T19:07:20.177722: step 17900, loss 0.297723, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T19:07:22.621989: step 17900, loss 0.24981, acc 0.91\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-17900\n",
      "\n",
      "2018-05-04T19:07:23.710833: step 17901, loss 0.353912, acc 0.859375\n",
      "2018-05-04T19:07:24.741017: step 17902, loss 0.359234, acc 0.84375\n",
      "2018-05-04T19:07:25.739714: step 17903, loss 0.15741, acc 0.9375\n",
      "2018-05-04T19:07:26.736808: step 17904, loss 0.20321, acc 0.90625\n",
      "2018-05-04T19:07:27.751834: step 17905, loss 0.288815, acc 0.875\n",
      "2018-05-04T19:07:28.739573: step 17906, loss 0.242363, acc 0.921875\n",
      "2018-05-04T19:07:29.729310: step 17907, loss 0.409521, acc 0.859375\n",
      "2018-05-04T19:07:30.710319: step 17908, loss 0.250368, acc 0.90625\n",
      "2018-05-04T19:07:31.702724: step 17909, loss 0.276539, acc 0.875\n",
      "2018-05-04T19:07:32.702662: step 17910, loss 0.187805, acc 0.921875\n",
      "2018-05-04T19:07:33.752522: step 17911, loss 0.323722, acc 0.875\n",
      "2018-05-04T19:07:34.768151: step 17912, loss 0.339871, acc 0.796875\n",
      "2018-05-04T19:07:35.809136: step 17913, loss 0.243998, acc 0.9375\n",
      "2018-05-04T19:07:36.861369: step 17914, loss 0.259218, acc 0.9375\n",
      "2018-05-04T19:07:37.955662: step 17915, loss 0.218125, acc 0.9375\n",
      "2018-05-04T19:07:38.930469: step 17916, loss 0.210045, acc 0.953125\n",
      "2018-05-04T19:07:39.903428: step 17917, loss 0.324071, acc 0.875\n",
      "2018-05-04T19:07:40.861502: step 17918, loss 0.193387, acc 0.9375\n",
      "2018-05-04T19:07:41.845213: step 17919, loss 0.189857, acc 0.890625\n",
      "2018-05-04T19:07:42.817165: step 17920, loss 0.184473, acc 0.953125\n",
      "2018-05-04T19:07:43.809132: step 17921, loss 0.186366, acc 0.9375\n",
      "2018-05-04T19:07:44.787291: step 17922, loss 0.336589, acc 0.84375\n",
      "2018-05-04T19:07:45.800574: step 17923, loss 0.208507, acc 0.9375\n",
      "2018-05-04T19:07:46.800789: step 17924, loss 0.243547, acc 0.84375\n",
      "2018-05-04T19:07:47.818593: step 17925, loss 0.303806, acc 0.90625\n",
      "2018-05-04T19:07:48.770516: step 17926, loss 0.266956, acc 0.921875\n",
      "2018-05-04T19:07:49.744250: step 17927, loss 0.300259, acc 0.890625\n",
      "2018-05-04T19:07:50.804706: step 17928, loss 0.394872, acc 0.84375\n",
      "2018-05-04T19:07:51.789163: step 17929, loss 0.234919, acc 0.90625\n",
      "2018-05-04T19:07:52.782084: step 17930, loss 0.222895, acc 0.90625\n",
      "2018-05-04T19:07:53.770587: step 17931, loss 0.313964, acc 0.828125\n",
      "2018-05-04T19:07:54.731265: step 17932, loss 0.333322, acc 0.84375\n",
      "2018-05-04T19:07:55.707672: step 17933, loss 0.188553, acc 0.90625\n",
      "2018-05-04T19:07:56.677436: step 17934, loss 0.224177, acc 0.890625\n",
      "2018-05-04T19:07:57.660082: step 17935, loss 0.206333, acc 0.890625\n",
      "2018-05-04T19:07:58.642391: step 17936, loss 0.191129, acc 0.984375\n",
      "2018-05-04T19:07:59.630535: step 17937, loss 0.226294, acc 0.921875\n",
      "2018-05-04T19:08:00.597795: step 17938, loss 0.200783, acc 0.921875\n",
      "2018-05-04T19:08:01.597755: step 17939, loss 0.218126, acc 0.921875\n",
      "2018-05-04T19:08:02.555307: step 17940, loss 0.195477, acc 0.921875\n",
      "2018-05-04T19:08:03.554509: step 17941, loss 0.232138, acc 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T19:08:04.621890: step 17942, loss 0.210521, acc 0.890625\n",
      "2018-05-04T19:08:05.625715: step 17943, loss 0.210223, acc 0.90625\n",
      "2018-05-04T19:08:06.579881: step 17944, loss 0.423449, acc 0.8125\n",
      "2018-05-04T19:08:07.559828: step 17945, loss 0.293721, acc 0.90625\n",
      "2018-05-04T19:08:08.517101: step 17946, loss 0.256145, acc 0.90625\n",
      "2018-05-04T19:08:09.481259: step 17947, loss 0.266321, acc 0.890625\n",
      "2018-05-04T19:08:10.456880: step 17948, loss 0.225158, acc 0.859375\n",
      "2018-05-04T19:08:11.459149: step 17949, loss 0.310602, acc 0.875\n",
      "2018-05-04T19:08:12.500442: step 17950, loss 0.166102, acc 0.90625\n",
      "2018-05-04T19:08:13.465048: step 17951, loss 0.179819, acc 0.953125\n",
      "2018-05-04T19:08:14.461357: step 17952, loss 0.194485, acc 0.9375\n",
      "2018-05-04T19:08:15.530040: step 17953, loss 0.223573, acc 0.890625\n",
      "2018-05-04T19:08:16.543499: step 17954, loss 0.221936, acc 0.90625\n",
      "2018-05-04T19:08:17.547669: step 17955, loss 0.28023, acc 0.875\n",
      "2018-05-04T19:08:18.524439: step 17956, loss 0.275287, acc 0.875\n",
      "2018-05-04T19:08:19.507807: step 17957, loss 0.283129, acc 0.8125\n",
      "2018-05-04T19:08:20.480106: step 17958, loss 0.320702, acc 0.890625\n",
      "2018-05-04T19:08:21.457211: step 17959, loss 0.249176, acc 0.890625\n",
      "2018-05-04T19:08:22.429459: step 17960, loss 0.366329, acc 0.890625\n",
      "2018-05-04T19:08:23.397992: step 17961, loss 0.216981, acc 0.890625\n",
      "2018-05-04T19:08:24.384807: step 17962, loss 0.350099, acc 0.875\n",
      "2018-05-04T19:08:25.379565: step 17963, loss 0.265142, acc 0.90625\n",
      "2018-05-04T19:08:26.338885: step 17964, loss 0.232545, acc 0.90625\n",
      "2018-05-04T19:08:27.302838: step 17965, loss 0.27551, acc 0.859375\n",
      "2018-05-04T19:08:28.241668: step 17966, loss 0.270242, acc 0.921875\n",
      "2018-05-04T19:08:29.205398: step 17967, loss 0.200653, acc 0.90625\n",
      "2018-05-04T19:08:30.145659: step 17968, loss 0.408979, acc 0.875\n",
      "2018-05-04T19:08:31.099158: step 17969, loss 0.155233, acc 0.953125\n",
      "2018-05-04T19:08:32.040917: step 17970, loss 0.459691, acc 0.828125\n",
      "2018-05-04T19:08:33.024452: step 17971, loss 0.278642, acc 0.90625\n",
      "2018-05-04T19:08:34.091574: step 17972, loss 0.270494, acc 0.890625\n",
      "2018-05-04T19:08:35.094256: step 17973, loss 0.199603, acc 0.890625\n",
      "2018-05-04T19:08:36.048106: step 17974, loss 0.270816, acc 0.890625\n",
      "2018-05-04T19:08:37.009835: step 17975, loss 0.242395, acc 0.90625\n",
      "2018-05-04T19:08:38.001923: step 17976, loss 0.322482, acc 0.9375\n",
      "2018-05-04T19:08:38.997102: step 17977, loss 0.183093, acc 0.9375\n",
      "2018-05-04T19:08:39.992334: step 17978, loss 0.209722, acc 0.90625\n",
      "2018-05-04T19:08:40.964933: step 17979, loss 0.184018, acc 0.90625\n",
      "2018-05-04T19:08:41.903309: step 17980, loss 0.232407, acc 0.921875\n",
      "2018-05-04T19:08:42.857352: step 17981, loss 0.332119, acc 0.875\n",
      "2018-05-04T19:08:43.818922: step 17982, loss 0.242779, acc 0.921875\n",
      "2018-05-04T19:08:44.773717: step 17983, loss 0.234463, acc 0.90625\n",
      "2018-05-04T19:08:45.732024: step 17984, loss 0.231584, acc 0.921875\n",
      "2018-05-04T19:08:46.719366: step 17985, loss 0.316625, acc 0.828125\n",
      "2018-05-04T19:08:47.744737: step 17986, loss 0.36058, acc 0.828125\n",
      "2018-05-04T19:08:48.690671: step 17987, loss 0.433157, acc 0.8125\n",
      "2018-05-04T19:08:49.655228: step 17988, loss 0.211888, acc 0.890625\n",
      "2018-05-04T19:08:50.607696: step 17989, loss 0.233826, acc 0.890625\n",
      "2018-05-04T19:08:51.554483: step 17990, loss 0.146987, acc 0.9375\n",
      "2018-05-04T19:08:52.528916: step 17991, loss 0.176547, acc 0.921875\n",
      "2018-05-04T19:08:53.501177: step 17992, loss 0.259887, acc 0.953125\n",
      "2018-05-04T19:08:54.458267: step 17993, loss 0.333542, acc 0.875\n",
      "2018-05-04T19:08:55.401458: step 17994, loss 0.288143, acc 0.890625\n",
      "2018-05-04T19:08:56.458922: step 17995, loss 0.357178, acc 0.859375\n",
      "2018-05-04T19:08:57.452284: step 17996, loss 0.202708, acc 0.9375\n",
      "2018-05-04T19:08:58.422914: step 17997, loss 0.343242, acc 0.90625\n",
      "2018-05-04T19:08:59.401998: step 17998, loss 0.179595, acc 0.96875\n",
      "2018-05-04T19:09:00.331642: step 17999, loss 0.215556, acc 0.90625\n",
      "2018-05-04T19:09:01.334372: step 18000, loss 0.343874, acc 0.828125\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T19:09:03.442990: step 18000, loss 0.218212, acc 0.928\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-18000\n",
      "\n",
      "2018-05-04T19:09:04.500437: step 18001, loss 0.236979, acc 0.921875\n",
      "2018-05-04T19:09:05.453894: step 18002, loss 0.420109, acc 0.84375\n",
      "2018-05-04T19:09:06.394469: step 18003, loss 0.465452, acc 0.765625\n",
      "2018-05-04T19:09:07.341784: step 18004, loss 0.186149, acc 0.9375\n",
      "2018-05-04T19:09:08.312000: step 18005, loss 0.220123, acc 0.875\n",
      "2018-05-04T19:09:09.357364: step 18006, loss 0.268909, acc 0.90625\n",
      "2018-05-04T19:09:10.308955: step 18007, loss 0.234347, acc 0.90625\n",
      "2018-05-04T19:09:11.243076: step 18008, loss 0.552768, acc 0.78125\n",
      "2018-05-04T19:09:12.182655: step 18009, loss 0.249932, acc 0.828125\n",
      "2018-05-04T19:09:13.124497: step 18010, loss 0.291452, acc 0.859375\n",
      "2018-05-04T19:09:14.065841: step 18011, loss 0.218368, acc 0.875\n",
      "2018-05-04T19:09:14.990187: step 18012, loss 0.230775, acc 0.921875\n",
      "2018-05-04T19:09:15.943241: step 18013, loss 0.29648, acc 0.890625\n",
      "2018-05-04T19:09:16.923567: step 18014, loss 0.225107, acc 0.875\n",
      "2018-05-04T19:09:17.923310: step 18015, loss 0.187685, acc 0.9375\n",
      "2018-05-04T19:09:19.001956: step 18016, loss 0.18394, acc 0.921875\n",
      "2018-05-04T19:09:20.001881: step 18017, loss 0.366229, acc 0.828125\n",
      "2018-05-04T19:09:20.974254: step 18018, loss 0.295459, acc 0.859375\n",
      "2018-05-04T19:09:21.939237: step 18019, loss 0.260397, acc 0.875\n",
      "2018-05-04T19:09:22.908620: step 18020, loss 0.304707, acc 0.90625\n",
      "2018-05-04T19:09:23.876185: step 18021, loss 0.196677, acc 0.890625\n",
      "2018-05-04T19:09:24.839634: step 18022, loss 0.182742, acc 0.953125\n",
      "2018-05-04T19:09:25.796378: step 18023, loss 0.353897, acc 0.84375\n",
      "2018-05-04T19:09:26.736107: step 18024, loss 0.240904, acc 0.890625\n",
      "2018-05-04T19:09:27.679504: step 18025, loss 0.237515, acc 0.921875\n",
      "2018-05-04T19:09:28.625597: step 18026, loss 0.245936, acc 0.90625\n",
      "2018-05-04T19:09:29.563636: step 18027, loss 0.349363, acc 0.859375\n",
      "2018-05-04T19:09:30.541076: step 18028, loss 0.212046, acc 0.921875\n",
      "2018-05-04T19:09:31.508714: step 18029, loss 0.159485, acc 0.96875\n",
      "2018-05-04T19:09:32.475014: step 18030, loss 0.220234, acc 0.921875\n",
      "2018-05-04T19:09:33.458064: step 18031, loss 0.288649, acc 0.890625\n",
      "2018-05-04T19:09:34.393512: step 18032, loss 0.157671, acc 0.9375\n",
      "2018-05-04T19:09:35.339330: step 18033, loss 0.384196, acc 0.859375\n",
      "2018-05-04T19:09:36.302439: step 18034, loss 0.330233, acc 0.890625\n",
      "2018-05-04T19:09:37.271386: step 18035, loss 0.343615, acc 0.84375\n",
      "2018-05-04T19:09:38.235146: step 18036, loss 0.339031, acc 0.859375\n",
      "2018-05-04T19:09:39.195652: step 18037, loss 0.261929, acc 0.890625\n",
      "2018-05-04T19:09:40.203571: step 18038, loss 0.225706, acc 0.890625\n",
      "2018-05-04T19:09:41.152640: step 18039, loss 0.23825, acc 0.875\n",
      "2018-05-04T19:09:42.132293: step 18040, loss 0.204001, acc 0.921875\n",
      "2018-05-04T19:09:43.085913: step 18041, loss 0.233753, acc 0.953125\n",
      "2018-05-04T19:09:44.041008: step 18042, loss 0.304221, acc 0.890625\n",
      "2018-05-04T19:09:44.994627: step 18043, loss 0.216911, acc 0.921875\n",
      "2018-05-04T19:09:45.930340: step 18044, loss 0.268657, acc 0.9375\n",
      "2018-05-04T19:09:46.886328: step 18045, loss 0.271357, acc 0.875\n",
      "2018-05-04T19:09:47.833565: step 18046, loss 0.2475, acc 0.921875\n",
      "2018-05-04T19:09:48.779179: step 18047, loss 0.23459, acc 0.84375\n",
      "2018-05-04T19:09:49.767554: step 18048, loss 0.247804, acc 0.890625\n",
      "2018-05-04T19:09:50.738205: step 18049, loss 0.294524, acc 0.859375\n",
      "2018-05-04T19:09:51.670771: step 18050, loss 0.358396, acc 0.859375\n",
      "2018-05-04T19:09:52.631584: step 18051, loss 0.114218, acc 1\n",
      "2018-05-04T19:09:53.591655: step 18052, loss 0.239925, acc 0.921875\n",
      "2018-05-04T19:09:54.554157: step 18053, loss 0.237251, acc 0.921875\n",
      "2018-05-04T19:09:55.523117: step 18054, loss 0.392009, acc 0.828125\n",
      "2018-05-04T19:09:56.485224: step 18055, loss 0.298544, acc 0.859375\n",
      "2018-05-04T19:09:57.443834: step 18056, loss 0.206143, acc 0.890625\n",
      "2018-05-04T19:09:58.396702: step 18057, loss 0.285155, acc 0.90625\n",
      "2018-05-04T19:09:59.333579: step 18058, loss 0.203507, acc 0.90625\n",
      "2018-05-04T19:10:00.280053: step 18059, loss 0.216899, acc 0.90625\n",
      "2018-05-04T19:10:01.259690: step 18060, loss 0.413681, acc 0.90625\n",
      "2018-05-04T19:10:02.285415: step 18061, loss 0.239801, acc 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T19:10:03.266610: step 18062, loss 0.27917, acc 0.90625\n",
      "2018-05-04T19:10:04.240423: step 18063, loss 0.267195, acc 0.90625\n",
      "2018-05-04T19:10:05.240800: step 18064, loss 0.375765, acc 0.859375\n",
      "2018-05-04T19:10:06.169540: step 18065, loss 0.302122, acc 0.859375\n",
      "2018-05-04T19:10:07.107246: step 18066, loss 0.289525, acc 0.875\n",
      "2018-05-04T19:10:08.067703: step 18067, loss 0.301017, acc 0.859375\n",
      "2018-05-04T19:10:09.035546: step 18068, loss 0.279183, acc 0.90625\n",
      "2018-05-04T19:10:09.990631: step 18069, loss 0.444229, acc 0.875\n",
      "2018-05-04T19:10:10.937631: step 18070, loss 0.308219, acc 0.90625\n",
      "2018-05-04T19:10:11.886985: step 18071, loss 0.156553, acc 0.953125\n",
      "2018-05-04T19:10:12.876081: step 18072, loss 0.171013, acc 0.921875\n",
      "2018-05-04T19:10:13.809779: step 18073, loss 0.297671, acc 0.859375\n",
      "2018-05-04T19:10:14.760020: step 18074, loss 0.23405, acc 0.90625\n",
      "2018-05-04T19:10:15.705837: step 18075, loss 0.198154, acc 0.921875\n",
      "2018-05-04T19:10:16.650308: step 18076, loss 0.254338, acc 0.921875\n",
      "2018-05-04T19:10:17.596354: step 18077, loss 0.422739, acc 0.828125\n",
      "2018-05-04T19:10:18.548085: step 18078, loss 0.245647, acc 0.90625\n",
      "2018-05-04T19:10:19.506369: step 18079, loss 0.208025, acc 0.921875\n",
      "2018-05-04T19:10:20.494656: step 18080, loss 0.331401, acc 0.828125\n",
      "2018-05-04T19:10:21.449944: step 18081, loss 0.257092, acc 0.890625\n",
      "2018-05-04T19:10:22.471946: step 18082, loss 0.200934, acc 0.90625\n",
      "2018-05-04T19:10:23.442482: step 18083, loss 0.170053, acc 0.96875\n",
      "2018-05-04T19:10:24.407220: step 18084, loss 0.156656, acc 0.96875\n",
      "2018-05-04T19:10:25.449119: step 18085, loss 0.158902, acc 0.9375\n",
      "2018-05-04T19:10:26.402024: step 18086, loss 0.355483, acc 0.828125\n",
      "2018-05-04T19:10:27.336016: step 18087, loss 0.306632, acc 0.859375\n",
      "2018-05-04T19:10:28.276659: step 18088, loss 0.373653, acc 0.875\n",
      "2018-05-04T19:10:29.299343: step 18089, loss 0.344863, acc 0.84375\n",
      "2018-05-04T19:10:30.237493: step 18090, loss 0.399749, acc 0.90625\n",
      "2018-05-04T19:10:31.173417: step 18091, loss 0.442575, acc 0.84375\n",
      "2018-05-04T19:10:32.116145: step 18092, loss 0.241842, acc 0.890625\n",
      "2018-05-04T19:10:33.099335: step 18093, loss 0.273125, acc 0.84375\n",
      "2018-05-04T19:10:34.202166: step 18094, loss 0.268928, acc 0.890625\n",
      "2018-05-04T19:10:35.222415: step 18095, loss 0.147119, acc 0.953125\n",
      "2018-05-04T19:10:36.211392: step 18096, loss 0.188053, acc 0.9375\n",
      "2018-05-04T19:10:37.156808: step 18097, loss 0.18982, acc 0.890625\n",
      "2018-05-04T19:10:38.122323: step 18098, loss 0.343536, acc 0.828125\n",
      "2018-05-04T19:10:39.079176: step 18099, loss 0.292745, acc 0.875\n",
      "2018-05-04T19:10:40.028862: step 18100, loss 0.360355, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T19:10:42.714446: step 18100, loss 0.250025, acc 0.908\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-18100\n",
      "\n",
      "2018-05-04T19:10:43.840416: step 18101, loss 0.402864, acc 0.796875\n",
      "2018-05-04T19:10:44.817062: step 18102, loss 0.288192, acc 0.796875\n",
      "2018-05-04T19:10:45.880539: step 18103, loss 0.394855, acc 0.8125\n",
      "2018-05-04T19:10:46.851060: step 18104, loss 0.220091, acc 0.921875\n",
      "2018-05-04T19:10:47.821829: step 18105, loss 0.35629, acc 0.890625\n",
      "2018-05-04T19:10:48.927966: step 18106, loss 0.171722, acc 0.984375\n",
      "2018-05-04T19:10:49.916602: step 18107, loss 0.201605, acc 0.90625\n",
      "2018-05-04T19:10:50.901960: step 18108, loss 0.259174, acc 0.875\n",
      "2018-05-04T19:10:51.932223: step 18109, loss 0.287132, acc 0.921875\n",
      "2018-05-04T19:10:52.891869: step 18110, loss 0.228741, acc 0.9375\n",
      "2018-05-04T19:10:53.889554: step 18111, loss 0.236883, acc 0.90625\n",
      "2018-05-04T19:10:54.925297: step 18112, loss 0.299018, acc 0.8125\n",
      "2018-05-04T19:10:55.905126: step 18113, loss 0.226703, acc 0.90625\n",
      "2018-05-04T19:10:56.890649: step 18114, loss 0.156196, acc 0.9375\n",
      "2018-05-04T19:10:57.840121: step 18115, loss 0.224373, acc 0.921875\n",
      "2018-05-04T19:10:58.799136: step 18116, loss 0.366674, acc 0.84375\n",
      "2018-05-04T19:10:59.765574: step 18117, loss 0.247531, acc 0.921875\n",
      "2018-05-04T19:11:00.750866: step 18118, loss 0.250387, acc 0.921875\n",
      "2018-05-04T19:11:01.715813: step 18119, loss 0.21638, acc 0.890625\n",
      "2018-05-04T19:11:02.775563: step 18120, loss 0.420385, acc 0.84375\n",
      "2018-05-04T19:11:03.754785: step 18121, loss 0.227345, acc 0.921875\n",
      "2018-05-04T19:11:04.741719: step 18122, loss 0.156216, acc 0.9375\n",
      "2018-05-04T19:11:05.707829: step 18123, loss 0.215484, acc 0.9375\n",
      "2018-05-04T19:11:06.682238: step 18124, loss 0.327127, acc 0.875\n",
      "2018-05-04T19:11:07.710297: step 18125, loss 0.241389, acc 0.90625\n",
      "2018-05-04T19:11:08.660535: step 18126, loss 0.175693, acc 0.953125\n",
      "2018-05-04T19:11:09.651707: step 18127, loss 0.262995, acc 0.890625\n",
      "2018-05-04T19:11:10.672718: step 18128, loss 0.335811, acc 0.90625\n",
      "2018-05-04T19:11:11.709270: step 18129, loss 0.293312, acc 0.921875\n",
      "2018-05-04T19:11:12.678392: step 18130, loss 0.211575, acc 0.921875\n",
      "2018-05-04T19:11:13.657188: step 18131, loss 0.192397, acc 0.9375\n",
      "2018-05-04T19:11:14.635683: step 18132, loss 0.26083, acc 0.890625\n",
      "2018-05-04T19:11:15.659764: step 18133, loss 0.373107, acc 0.828125\n",
      "2018-05-04T19:11:16.728327: step 18134, loss 0.197354, acc 0.90625\n",
      "2018-05-04T19:11:17.721849: step 18135, loss 0.277456, acc 0.90625\n",
      "2018-05-04T19:11:18.773676: step 18136, loss 0.291995, acc 0.890625\n",
      "2018-05-04T19:11:19.744584: step 18137, loss 0.267411, acc 0.859375\n",
      "2018-05-04T19:11:20.727929: step 18138, loss 0.252747, acc 0.921875\n",
      "2018-05-04T19:11:21.731618: step 18139, loss 0.207015, acc 0.890625\n",
      "2018-05-04T19:11:22.750605: step 18140, loss 0.31491, acc 0.875\n",
      "2018-05-04T19:11:23.732415: step 18141, loss 0.280072, acc 0.890625\n",
      "2018-05-04T19:11:24.726553: step 18142, loss 0.315647, acc 0.875\n",
      "2018-05-04T19:11:25.695775: step 18143, loss 0.205482, acc 0.859375\n",
      "2018-05-04T19:11:26.679145: step 18144, loss 0.394673, acc 0.84375\n",
      "2018-05-04T19:11:27.665486: step 18145, loss 0.255681, acc 0.921875\n",
      "2018-05-04T19:11:28.630438: step 18146, loss 0.213108, acc 0.9375\n",
      "2018-05-04T19:11:29.662565: step 18147, loss 0.195529, acc 0.953125\n",
      "2018-05-04T19:11:30.630444: step 18148, loss 0.287957, acc 0.875\n",
      "2018-05-04T19:11:31.606109: step 18149, loss 0.30372, acc 0.90625\n",
      "2018-05-04T19:11:32.558446: step 18150, loss 0.236787, acc 0.9375\n",
      "2018-05-04T19:11:33.524065: step 18151, loss 0.33458, acc 0.859375\n",
      "2018-05-04T19:11:34.490332: step 18152, loss 0.244483, acc 0.90625\n",
      "2018-05-04T19:11:35.449568: step 18153, loss 0.205215, acc 0.9375\n",
      "2018-05-04T19:11:36.426938: step 18154, loss 0.222361, acc 0.90625\n",
      "2018-05-04T19:11:37.406474: step 18155, loss 0.245266, acc 0.90625\n",
      "2018-05-04T19:11:38.388991: step 18156, loss 0.265537, acc 0.9375\n",
      "2018-05-04T19:11:39.382325: step 18157, loss 0.26653, acc 0.828125\n",
      "2018-05-04T19:11:40.350954: step 18158, loss 0.218502, acc 0.9375\n",
      "2018-05-04T19:11:41.323904: step 18159, loss 0.152052, acc 0.921875\n",
      "2018-05-04T19:11:42.283790: step 18160, loss 0.166709, acc 0.9375\n",
      "2018-05-04T19:11:43.268739: step 18161, loss 0.279694, acc 0.90625\n",
      "2018-05-04T19:11:44.343122: step 18162, loss 0.190452, acc 0.90625\n",
      "2018-05-04T19:11:45.284103: step 18163, loss 0.262315, acc 0.890625\n",
      "2018-05-04T19:11:46.252679: step 18164, loss 0.346774, acc 0.796875\n",
      "2018-05-04T19:11:47.213769: step 18165, loss 0.370166, acc 0.828125\n",
      "2018-05-04T19:11:48.155321: step 18166, loss 0.331773, acc 0.84375\n",
      "2018-05-04T19:11:49.121556: step 18167, loss 0.351481, acc 0.859375\n",
      "2018-05-04T19:11:50.123893: step 18168, loss 0.298501, acc 0.859375\n",
      "2018-05-04T19:11:51.141647: step 18169, loss 0.21626, acc 0.875\n",
      "2018-05-04T19:11:52.080460: step 18170, loss 0.390629, acc 0.828125\n",
      "2018-05-04T19:11:53.056082: step 18171, loss 0.261336, acc 0.90625\n",
      "2018-05-04T19:11:54.072681: step 18172, loss 0.311889, acc 0.875\n",
      "2018-05-04T19:11:55.020851: step 18173, loss 0.209006, acc 0.9375\n",
      "2018-05-04T19:11:55.971005: step 18174, loss 0.230533, acc 0.90625\n",
      "2018-05-04T19:11:56.994832: step 18175, loss 0.259341, acc 0.90625\n",
      "2018-05-04T19:11:57.932258: step 18176, loss 0.33647, acc 0.875\n",
      "2018-05-04T19:11:58.887798: step 18177, loss 0.274215, acc 0.90625\n",
      "2018-05-04T19:11:59.934767: step 18178, loss 0.235787, acc 0.921875\n",
      "2018-05-04T19:12:00.875170: step 18179, loss 0.229807, acc 0.921875\n",
      "2018-05-04T19:12:01.827162: step 18180, loss 0.239824, acc 0.9375\n",
      "2018-05-04T19:12:02.808962: step 18181, loss 0.182561, acc 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T19:12:03.802264: step 18182, loss 0.223367, acc 0.890625\n",
      "2018-05-04T19:12:04.802622: step 18183, loss 0.365131, acc 0.84375\n",
      "2018-05-04T19:12:05.772552: step 18184, loss 0.22388, acc 0.921875\n",
      "2018-05-04T19:12:06.709190: step 18185, loss 0.203849, acc 0.890625\n",
      "2018-05-04T19:12:07.668000: step 18186, loss 0.18846, acc 0.9375\n",
      "2018-05-04T19:12:08.612333: step 18187, loss 0.325522, acc 0.875\n",
      "2018-05-04T19:12:09.568996: step 18188, loss 0.192781, acc 0.9375\n",
      "2018-05-04T19:12:10.525600: step 18189, loss 0.225405, acc 0.890625\n",
      "2018-05-04T19:12:11.488234: step 18190, loss 0.183451, acc 0.9375\n",
      "2018-05-04T19:12:12.443845: step 18191, loss 0.328806, acc 0.8125\n",
      "2018-05-04T19:12:13.486121: step 18192, loss 0.229021, acc 0.921875\n",
      "2018-05-04T19:12:14.429619: step 18193, loss 0.172091, acc 0.921875\n",
      "2018-05-04T19:12:15.388519: step 18194, loss 0.192303, acc 0.875\n",
      "2018-05-04T19:12:16.336279: step 18195, loss 0.354156, acc 0.890625\n",
      "2018-05-04T19:12:17.288246: step 18196, loss 0.186961, acc 0.90625\n",
      "2018-05-04T19:12:18.214522: step 18197, loss 0.199334, acc 0.90625\n",
      "2018-05-04T19:12:19.172775: step 18198, loss 0.255451, acc 0.90625\n",
      "2018-05-04T19:12:20.138422: step 18199, loss 0.247552, acc 0.9375\n",
      "2018-05-04T19:12:21.229366: step 18200, loss 0.297925, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T19:12:23.423050: step 18200, loss 0.220851, acc 0.926\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-18200\n",
      "\n",
      "2018-05-04T19:12:24.516558: step 18201, loss 0.360827, acc 0.84375\n",
      "2018-05-04T19:12:25.559950: step 18202, loss 0.309659, acc 0.875\n",
      "2018-05-04T19:12:26.508603: step 18203, loss 0.279534, acc 0.875\n",
      "2018-05-04T19:12:27.441066: step 18204, loss 0.399709, acc 0.859375\n",
      "2018-05-04T19:12:28.393861: step 18205, loss 0.20097, acc 0.921875\n",
      "2018-05-04T19:12:29.366241: step 18206, loss 0.135037, acc 0.953125\n",
      "2018-05-04T19:12:30.339648: step 18207, loss 0.357188, acc 0.890625\n",
      "2018-05-04T19:12:31.310361: step 18208, loss 0.272116, acc 0.890625\n",
      "2018-05-04T19:12:32.287735: step 18209, loss 0.181001, acc 0.921875\n",
      "2018-05-04T19:12:33.248401: step 18210, loss 0.256128, acc 0.890625\n",
      "2018-05-04T19:12:34.208804: step 18211, loss 0.233046, acc 0.90625\n",
      "2018-05-04T19:12:35.167201: step 18212, loss 0.256018, acc 0.90625\n",
      "2018-05-04T19:12:36.124161: step 18213, loss 0.319379, acc 0.796875\n",
      "2018-05-04T19:12:37.050598: step 18214, loss 0.331534, acc 0.859375\n",
      "2018-05-04T19:12:38.010189: step 18215, loss 0.175354, acc 0.953125\n",
      "2018-05-04T19:12:38.981699: step 18216, loss 0.274233, acc 0.921875\n",
      "2018-05-04T19:12:39.945316: step 18217, loss 0.255183, acc 0.890625\n",
      "2018-05-04T19:12:40.920113: step 18218, loss 0.281672, acc 0.875\n",
      "2018-05-04T19:12:41.865830: step 18219, loss 0.270524, acc 0.90625\n",
      "2018-05-04T19:12:42.871357: step 18220, loss 0.361095, acc 0.828125\n",
      "2018-05-04T19:12:43.846678: step 18221, loss 0.153331, acc 0.953125\n",
      "2018-05-04T19:12:44.802711: step 18222, loss 0.364563, acc 0.84375\n",
      "2018-05-04T19:12:45.786823: step 18223, loss 0.340243, acc 0.875\n",
      "2018-05-04T19:12:46.745008: step 18224, loss 0.156686, acc 0.96875\n",
      "2018-05-04T19:12:47.705822: step 18225, loss 0.194885, acc 0.953125\n",
      "2018-05-04T19:12:48.670711: step 18226, loss 0.27651, acc 0.875\n",
      "2018-05-04T19:12:49.597088: step 18227, loss 0.256402, acc 0.859375\n",
      "2018-05-04T19:12:50.533510: step 18228, loss 0.167408, acc 0.921875\n",
      "2018-05-04T19:12:51.508770: step 18229, loss 0.233063, acc 0.90625\n",
      "2018-05-04T19:12:52.468552: step 18230, loss 0.318987, acc 0.90625\n",
      "2018-05-04T19:12:53.408279: step 18231, loss 0.357435, acc 0.828125\n",
      "2018-05-04T19:12:54.350384: step 18232, loss 0.303048, acc 0.859375\n",
      "2018-05-04T19:12:55.313018: step 18233, loss 0.161134, acc 0.921875\n",
      "2018-05-04T19:12:56.268138: step 18234, loss 0.246513, acc 0.90625\n",
      "2018-05-04T19:12:57.220037: step 18235, loss 0.241336, acc 0.890625\n",
      "2018-05-04T19:12:58.186216: step 18236, loss 0.26722, acc 0.890625\n",
      "2018-05-04T19:12:59.178160: step 18237, loss 0.21597, acc 0.9375\n",
      "2018-05-04T19:13:00.146794: step 18238, loss 0.265449, acc 0.890625\n",
      "2018-05-04T19:13:01.131873: step 18239, loss 0.501107, acc 0.796875\n",
      "2018-05-04T19:13:02.153671: step 18240, loss 0.195818, acc 0.90625\n",
      "2018-05-04T19:13:03.157951: step 18241, loss 0.174584, acc 0.9375\n",
      "2018-05-04T19:13:04.122836: step 18242, loss 0.298379, acc 0.859375\n",
      "2018-05-04T19:13:05.066425: step 18243, loss 0.142599, acc 0.953125\n",
      "2018-05-04T19:13:06.080547: step 18244, loss 0.173209, acc 0.953125\n",
      "2018-05-04T19:13:07.003487: step 18245, loss 0.375755, acc 0.875\n",
      "2018-05-04T19:13:08.010100: step 18246, loss 0.332481, acc 0.859375\n",
      "2018-05-04T19:13:08.929881: step 18247, loss 0.260393, acc 0.875\n",
      "2018-05-04T19:13:09.874696: step 18248, loss 0.19236, acc 0.9375\n",
      "2018-05-04T19:13:10.828944: step 18249, loss 0.201224, acc 0.90625\n",
      "2018-05-04T19:13:11.764472: step 18250, loss 0.2666, acc 0.890625\n",
      "2018-05-04T19:13:12.703793: step 18251, loss 0.201142, acc 0.921875\n",
      "2018-05-04T19:13:13.645602: step 18252, loss 0.310721, acc 0.890625\n",
      "2018-05-04T19:13:14.615220: step 18253, loss 0.207292, acc 0.921875\n",
      "2018-05-04T19:13:15.592212: step 18254, loss 0.311311, acc 0.875\n",
      "2018-05-04T19:13:16.546422: step 18255, loss 0.273953, acc 0.875\n",
      "2018-05-04T19:13:17.542987: step 18256, loss 0.11097, acc 0.96875\n",
      "2018-05-04T19:13:18.502090: step 18257, loss 0.238628, acc 0.890625\n",
      "2018-05-04T19:13:19.467873: step 18258, loss 0.315635, acc 0.859375\n",
      "2018-05-04T19:13:20.415252: step 18259, loss 0.433244, acc 0.828125\n",
      "2018-05-04T19:13:21.363119: step 18260, loss 0.391467, acc 0.859375\n",
      "2018-05-04T19:13:22.317600: step 18261, loss 0.198998, acc 0.921875\n",
      "2018-05-04T19:13:23.333950: step 18262, loss 0.328511, acc 0.859375\n",
      "2018-05-04T19:13:24.313255: step 18263, loss 0.171059, acc 0.953125\n",
      "2018-05-04T19:13:25.267574: step 18264, loss 0.260058, acc 0.875\n",
      "2018-05-04T19:13:26.253959: step 18265, loss 0.16433, acc 0.953125\n",
      "2018-05-04T19:13:27.192373: step 18266, loss 0.324894, acc 0.859375\n",
      "2018-05-04T19:13:28.117640: step 18267, loss 0.27081, acc 0.859375\n",
      "2018-05-04T19:13:29.091575: step 18268, loss 0.30872, acc 0.875\n",
      "2018-05-04T19:13:30.037716: step 18269, loss 0.226719, acc 0.921875\n",
      "2018-05-04T19:13:30.987574: step 18270, loss 0.20467, acc 0.921875\n",
      "2018-05-04T19:13:31.943359: step 18271, loss 0.307773, acc 0.921875\n",
      "2018-05-04T19:13:32.938647: step 18272, loss 0.266606, acc 0.90625\n",
      "2018-05-04T19:13:33.948744: step 18273, loss 0.383076, acc 0.84375\n",
      "2018-05-04T19:13:35.026504: step 18274, loss 0.414736, acc 0.8125\n",
      "2018-05-04T19:13:36.146660: step 18275, loss 0.261263, acc 0.859375\n",
      "2018-05-04T19:13:37.230089: step 18276, loss 0.22328, acc 0.9375\n",
      "2018-05-04T19:13:38.170758: step 18277, loss 0.147932, acc 0.90625\n",
      "2018-05-04T19:13:39.090780: step 18278, loss 0.198688, acc 0.90625\n",
      "2018-05-04T19:13:40.020604: step 18279, loss 0.143576, acc 0.953125\n",
      "2018-05-04T19:13:40.974016: step 18280, loss 0.235778, acc 0.890625\n",
      "2018-05-04T19:13:41.949342: step 18281, loss 0.305376, acc 0.84375\n",
      "2018-05-04T19:13:42.984899: step 18282, loss 0.217484, acc 0.921875\n",
      "2018-05-04T19:13:43.925975: step 18283, loss 0.228832, acc 0.90625\n",
      "2018-05-04T19:13:44.857864: step 18284, loss 0.253104, acc 0.84375\n",
      "2018-05-04T19:13:45.878223: step 18285, loss 0.22374, acc 0.921875\n",
      "2018-05-04T19:13:46.898882: step 18286, loss 0.259115, acc 0.875\n",
      "2018-05-04T19:13:47.830685: step 18287, loss 0.254237, acc 0.890625\n",
      "2018-05-04T19:13:48.851071: step 18288, loss 0.257872, acc 0.9375\n",
      "2018-05-04T19:13:49.789270: step 18289, loss 0.175493, acc 0.90625\n",
      "2018-05-04T19:13:50.762486: step 18290, loss 0.297216, acc 0.9375\n",
      "2018-05-04T19:13:51.752276: step 18291, loss 0.190119, acc 0.90625\n",
      "2018-05-04T19:13:52.769231: step 18292, loss 0.325996, acc 0.890625\n",
      "2018-05-04T19:13:53.775540: step 18293, loss 0.243947, acc 0.9375\n",
      "2018-05-04T19:13:54.707787: step 18294, loss 0.433233, acc 0.84375\n",
      "2018-05-04T19:13:55.731878: step 18295, loss 0.285244, acc 0.875\n",
      "2018-05-04T19:13:56.656493: step 18296, loss 0.346256, acc 0.890625\n",
      "2018-05-04T19:13:57.602751: step 18297, loss 0.295656, acc 0.90625\n",
      "2018-05-04T19:13:58.549351: step 18298, loss 0.255831, acc 0.875\n",
      "2018-05-04T19:13:59.515502: step 18299, loss 0.152244, acc 0.953125\n",
      "2018-05-04T19:14:00.478176: step 18300, loss 0.20129, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T19:14:03.269056: step 18300, loss 0.218236, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-18300\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T19:14:04.404254: step 18301, loss 0.505245, acc 0.828125\n",
      "2018-05-04T19:14:05.399555: step 18302, loss 0.250595, acc 0.890625\n",
      "2018-05-04T19:14:06.386352: step 18303, loss 0.211708, acc 0.90625\n",
      "2018-05-04T19:14:07.388394: step 18304, loss 0.158458, acc 0.953125\n",
      "2018-05-04T19:14:08.396828: step 18305, loss 0.194877, acc 0.921875\n",
      "2018-05-04T19:14:09.414246: step 18306, loss 0.213421, acc 0.9375\n",
      "2018-05-04T19:14:10.435257: step 18307, loss 0.216243, acc 0.90625\n",
      "2018-05-04T19:14:11.423630: step 18308, loss 0.191638, acc 0.90625\n",
      "2018-05-04T19:14:12.463073: step 18309, loss 0.138959, acc 0.96875\n",
      "2018-05-04T19:14:13.438050: step 18310, loss 0.206796, acc 0.890625\n",
      "2018-05-04T19:14:14.449393: step 18311, loss 0.214408, acc 0.90625\n",
      "2018-05-04T19:14:15.437344: step 18312, loss 0.261596, acc 0.9375\n",
      "2018-05-04T19:14:16.415747: step 18313, loss 0.207188, acc 0.9375\n",
      "2018-05-04T19:14:17.383170: step 18314, loss 0.274791, acc 0.859375\n",
      "2018-05-04T19:14:18.367511: step 18315, loss 0.19972, acc 0.921875\n",
      "2018-05-04T19:14:19.406926: step 18316, loss 0.317562, acc 0.84375\n",
      "2018-05-04T19:14:20.372789: step 18317, loss 0.251323, acc 0.859375\n",
      "2018-05-04T19:14:21.338407: step 18318, loss 0.211701, acc 0.90625\n",
      "2018-05-04T19:14:22.308101: step 18319, loss 0.337974, acc 0.828125\n",
      "2018-05-04T19:14:23.260017: step 18320, loss 0.511746, acc 0.8125\n",
      "2018-05-04T19:14:24.219718: step 18321, loss 0.175949, acc 0.921875\n",
      "2018-05-04T19:14:25.188591: step 18322, loss 0.248354, acc 0.890625\n",
      "2018-05-04T19:14:26.176547: step 18323, loss 0.386831, acc 0.875\n",
      "2018-05-04T19:14:27.153115: step 18324, loss 0.282777, acc 0.921875\n",
      "2018-05-04T19:14:28.142579: step 18325, loss 0.202297, acc 0.90625\n",
      "2018-05-04T19:14:29.177756: step 18326, loss 0.171891, acc 0.953125\n",
      "2018-05-04T19:14:30.138711: step 18327, loss 0.226137, acc 0.890625\n",
      "2018-05-04T19:14:31.197178: step 18328, loss 0.167787, acc 0.9375\n",
      "2018-05-04T19:14:32.148558: step 18329, loss 0.477623, acc 0.859375\n",
      "2018-05-04T19:14:33.195157: step 18330, loss 0.217648, acc 0.9375\n",
      "2018-05-04T19:14:34.146407: step 18331, loss 0.457115, acc 0.796875\n",
      "2018-05-04T19:14:35.110209: step 18332, loss 0.233794, acc 0.890625\n",
      "2018-05-04T19:14:36.075547: step 18333, loss 0.208132, acc 0.921875\n",
      "2018-05-04T19:14:37.042804: step 18334, loss 0.289584, acc 0.890625\n",
      "2018-05-04T19:14:37.984728: step 18335, loss 0.287001, acc 0.84375\n",
      "2018-05-04T19:14:38.943185: step 18336, loss 0.289374, acc 0.890625\n",
      "2018-05-04T19:14:39.977978: step 18337, loss 0.226254, acc 0.90625\n",
      "2018-05-04T19:14:40.943457: step 18338, loss 0.251357, acc 0.875\n",
      "2018-05-04T19:14:41.925779: step 18339, loss 0.159267, acc 0.9375\n",
      "2018-05-04T19:14:42.874577: step 18340, loss 0.291399, acc 0.859375\n",
      "2018-05-04T19:14:43.861511: step 18341, loss 0.174069, acc 0.890625\n",
      "2018-05-04T19:14:44.858502: step 18342, loss 0.34501, acc 0.828125\n",
      "2018-05-04T19:14:45.847615: step 18343, loss 0.220735, acc 0.90625\n",
      "2018-05-04T19:14:46.815438: step 18344, loss 0.245952, acc 0.90625\n",
      "2018-05-04T19:14:47.844909: step 18345, loss 0.291945, acc 0.9375\n",
      "2018-05-04T19:14:48.878065: step 18346, loss 0.290232, acc 0.890625\n",
      "2018-05-04T19:14:49.842352: step 18347, loss 0.207562, acc 0.921875\n",
      "2018-05-04T19:14:50.871271: step 18348, loss 0.156547, acc 0.921875\n",
      "2018-05-04T19:14:51.893910: step 18349, loss 0.260065, acc 0.890625\n",
      "2018-05-04T19:14:52.858523: step 18350, loss 0.171889, acc 0.921875\n",
      "2018-05-04T19:14:53.826374: step 18351, loss 0.226963, acc 0.921875\n",
      "2018-05-04T19:14:54.823266: step 18352, loss 0.273934, acc 0.890625\n",
      "2018-05-04T19:14:55.776181: step 18353, loss 0.162805, acc 0.9375\n",
      "2018-05-04T19:14:56.854851: step 18354, loss 0.368467, acc 0.828125\n",
      "2018-05-04T19:14:57.801966: step 18355, loss 0.124968, acc 0.96875\n",
      "2018-05-04T19:14:58.758306: step 18356, loss 0.324982, acc 0.859375\n",
      "2018-05-04T19:14:59.836028: step 18357, loss 0.193008, acc 0.90625\n",
      "2018-05-04T19:15:00.806740: step 18358, loss 0.451576, acc 0.796875\n",
      "2018-05-04T19:15:01.843441: step 18359, loss 0.236654, acc 0.890625\n",
      "2018-05-04T19:15:02.806780: step 18360, loss 0.296899, acc 0.875\n",
      "2018-05-04T19:15:03.828636: step 18361, loss 0.289535, acc 0.90625\n",
      "2018-05-04T19:15:04.800942: step 18362, loss 0.234704, acc 0.90625\n",
      "2018-05-04T19:15:05.780370: step 18363, loss 0.291057, acc 0.859375\n",
      "2018-05-04T19:15:06.729684: step 18364, loss 0.263099, acc 0.859375\n",
      "2018-05-04T19:15:07.688269: step 18365, loss 0.273035, acc 0.859375\n",
      "2018-05-04T19:15:08.641410: step 18366, loss 0.216435, acc 0.96875\n",
      "2018-05-04T19:15:09.580160: step 18367, loss 0.424859, acc 0.8125\n",
      "2018-05-04T19:15:10.625518: step 18368, loss 0.349837, acc 0.84375\n",
      "2018-05-04T19:15:11.558169: step 18369, loss 0.266048, acc 0.859375\n",
      "2018-05-04T19:15:12.489729: step 18370, loss 0.319541, acc 0.84375\n",
      "2018-05-04T19:15:13.443391: step 18371, loss 0.204239, acc 0.921875\n",
      "2018-05-04T19:15:14.413174: step 18372, loss 0.233679, acc 0.90625\n",
      "2018-05-04T19:15:15.396910: step 18373, loss 0.268925, acc 0.921875\n",
      "2018-05-04T19:15:16.362738: step 18374, loss 0.255534, acc 0.890625\n",
      "2018-05-04T19:15:17.379491: step 18375, loss 0.312232, acc 0.890625\n",
      "2018-05-04T19:15:18.357437: step 18376, loss 0.341413, acc 0.828125\n",
      "2018-05-04T19:15:19.330028: step 18377, loss 0.257189, acc 0.875\n",
      "2018-05-04T19:15:20.323806: step 18378, loss 0.218282, acc 0.921875\n",
      "2018-05-04T19:15:21.356443: step 18379, loss 0.145455, acc 0.984375\n",
      "2018-05-04T19:15:22.315203: step 18380, loss 0.183326, acc 0.9375\n",
      "2018-05-04T19:15:23.269820: step 18381, loss 0.34249, acc 0.84375\n",
      "2018-05-04T19:15:24.238835: step 18382, loss 0.29341, acc 0.859375\n",
      "2018-05-04T19:15:25.214719: step 18383, loss 0.244519, acc 0.890625\n",
      "2018-05-04T19:15:26.190347: step 18384, loss 0.180456, acc 0.921875\n",
      "2018-05-04T19:15:27.165688: step 18385, loss 0.271185, acc 0.84375\n",
      "2018-05-04T19:15:28.126733: step 18386, loss 0.335926, acc 0.890625\n",
      "2018-05-04T19:15:29.079138: step 18387, loss 0.375401, acc 0.796875\n",
      "2018-05-04T19:15:30.018870: step 18388, loss 0.245878, acc 0.90625\n",
      "2018-05-04T19:15:30.960191: step 18389, loss 0.190825, acc 0.921875\n",
      "2018-05-04T19:15:31.936633: step 18390, loss 0.378174, acc 0.859375\n",
      "2018-05-04T19:15:32.910938: step 18391, loss 0.262375, acc 0.9375\n",
      "2018-05-04T19:15:33.933857: step 18392, loss 0.290184, acc 0.84375\n",
      "2018-05-04T19:15:34.878102: step 18393, loss 0.258776, acc 0.953125\n",
      "2018-05-04T19:15:35.842705: step 18394, loss 0.176903, acc 0.953125\n",
      "2018-05-04T19:15:36.812574: step 18395, loss 0.239707, acc 0.90625\n",
      "2018-05-04T19:15:37.787552: step 18396, loss 0.168564, acc 0.921875\n",
      "2018-05-04T19:15:38.759086: step 18397, loss 0.199314, acc 0.90625\n",
      "2018-05-04T19:15:39.717722: step 18398, loss 0.261737, acc 0.90625\n",
      "2018-05-04T19:15:40.667090: step 18399, loss 0.311669, acc 0.875\n",
      "2018-05-04T19:15:41.740160: step 18400, loss 0.254382, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T19:15:43.941240: step 18400, loss 0.210947, acc 0.926\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-18400\n",
      "\n",
      "2018-05-04T19:15:45.036441: step 18401, loss 0.266455, acc 0.875\n",
      "2018-05-04T19:15:45.993765: step 18402, loss 0.218718, acc 0.953125\n",
      "2018-05-04T19:15:46.964725: step 18403, loss 0.193453, acc 0.921875\n",
      "2018-05-04T19:15:47.908871: step 18404, loss 0.12977, acc 0.953125\n",
      "2018-05-04T19:15:48.877888: step 18405, loss 0.203147, acc 0.90625\n",
      "2018-05-04T19:15:49.832402: step 18406, loss 0.285499, acc 0.9375\n",
      "2018-05-04T19:15:50.786332: step 18407, loss 0.213365, acc 0.921875\n",
      "2018-05-04T19:15:51.741553: step 18408, loss 0.342661, acc 0.875\n",
      "2018-05-04T19:15:52.769225: step 18409, loss 0.354785, acc 0.890625\n",
      "2018-05-04T19:15:53.758209: step 18410, loss 0.435607, acc 0.859375\n",
      "2018-05-04T19:15:54.695196: step 18411, loss 0.144021, acc 0.953125\n",
      "2018-05-04T19:15:55.640765: step 18412, loss 0.331598, acc 0.828125\n",
      "2018-05-04T19:15:56.589265: step 18413, loss 0.288104, acc 0.90625\n",
      "2018-05-04T19:15:57.531905: step 18414, loss 0.406015, acc 0.875\n",
      "2018-05-04T19:15:58.490817: step 18415, loss 0.283775, acc 0.890625\n",
      "2018-05-04T19:15:59.448698: step 18416, loss 0.316222, acc 0.875\n",
      "2018-05-04T19:16:00.395004: step 18417, loss 0.316992, acc 0.859375\n",
      "2018-05-04T19:16:01.389526: step 18418, loss 0.251682, acc 0.921875\n",
      "2018-05-04T19:16:02.363148: step 18419, loss 0.24589, acc 0.921875\n",
      "2018-05-04T19:16:03.365323: step 18420, loss 0.213161, acc 0.953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T19:16:04.345530: step 18421, loss 0.282733, acc 0.921875\n",
      "2018-05-04T19:16:05.321181: step 18422, loss 0.221578, acc 0.90625\n",
      "2018-05-04T19:16:06.296779: step 18423, loss 0.170467, acc 0.9375\n",
      "2018-05-04T19:16:07.322502: step 18424, loss 0.229681, acc 0.90625\n",
      "2018-05-04T19:16:08.248495: step 18425, loss 0.357665, acc 0.84375\n",
      "2018-05-04T19:16:09.187565: step 18426, loss 0.213807, acc 0.9375\n",
      "2018-05-04T19:16:10.117444: step 18427, loss 0.266929, acc 0.875\n",
      "2018-05-04T19:16:11.168044: step 18428, loss 0.165553, acc 0.96875\n",
      "2018-05-04T19:16:12.112308: step 18429, loss 0.228598, acc 0.875\n",
      "2018-05-04T19:16:13.053978: step 18430, loss 0.132233, acc 0.953125\n",
      "2018-05-04T19:16:13.993055: step 18431, loss 0.295905, acc 0.890625\n",
      "2018-05-04T19:16:14.940752: step 18432, loss 0.224813, acc 0.890625\n",
      "2018-05-04T19:16:15.876216: step 18433, loss 0.283824, acc 0.90625\n",
      "2018-05-04T19:16:16.842179: step 18434, loss 0.264432, acc 0.921875\n",
      "2018-05-04T19:16:17.812287: step 18435, loss 0.141374, acc 0.9375\n",
      "2018-05-04T19:16:18.787210: step 18436, loss 0.288947, acc 0.84375\n",
      "2018-05-04T19:16:19.751787: step 18437, loss 0.207183, acc 0.9375\n",
      "2018-05-04T19:16:20.722264: step 18438, loss 0.18844, acc 0.90625\n",
      "2018-05-04T19:16:21.660274: step 18439, loss 0.263753, acc 0.84375\n",
      "2018-05-04T19:16:22.612953: step 18440, loss 0.266394, acc 0.921875\n",
      "2018-05-04T19:16:23.539225: step 18441, loss 0.21372, acc 0.890625\n",
      "2018-05-04T19:16:24.497752: step 18442, loss 0.290293, acc 0.875\n",
      "2018-05-04T19:16:25.498624: step 18443, loss 0.173289, acc 0.90625\n",
      "2018-05-04T19:16:26.518587: step 18444, loss 0.427926, acc 0.796875\n",
      "2018-05-04T19:16:27.466365: step 18445, loss 0.279875, acc 0.859375\n",
      "2018-05-04T19:16:28.407495: step 18446, loss 0.133862, acc 0.96875\n",
      "2018-05-04T19:16:29.352195: step 18447, loss 0.270324, acc 0.890625\n",
      "2018-05-04T19:16:30.303535: step 18448, loss 0.245285, acc 0.90625\n",
      "2018-05-04T19:16:31.240412: step 18449, loss 0.252007, acc 0.875\n",
      "2018-05-04T19:16:32.201735: step 18450, loss 0.244523, acc 0.875\n",
      "2018-05-04T19:16:33.202655: step 18451, loss 0.242419, acc 0.921875\n",
      "2018-05-04T19:16:34.227701: step 18452, loss 0.203202, acc 0.953125\n",
      "2018-05-04T19:16:35.225794: step 18453, loss 0.234119, acc 0.921875\n",
      "2018-05-04T19:16:36.252524: step 18454, loss 0.335666, acc 0.859375\n",
      "2018-05-04T19:16:37.294931: step 18455, loss 0.176396, acc 0.90625\n",
      "2018-05-04T19:16:38.303502: step 18456, loss 0.283852, acc 0.875\n",
      "2018-05-04T19:16:39.280452: step 18457, loss 0.264623, acc 0.875\n",
      "2018-05-04T19:16:40.232603: step 18458, loss 0.296386, acc 0.875\n",
      "2018-05-04T19:16:41.211023: step 18459, loss 0.30966, acc 0.859375\n",
      "2018-05-04T19:16:42.132966: step 18460, loss 0.162117, acc 0.9375\n",
      "2018-05-04T19:16:43.146275: step 18461, loss 0.292874, acc 0.890625\n",
      "2018-05-04T19:16:44.070131: step 18462, loss 0.27364, acc 0.875\n",
      "2018-05-04T19:16:45.057612: step 18463, loss 0.325954, acc 0.84375\n",
      "2018-05-04T19:16:46.007220: step 18464, loss 0.258339, acc 0.84375\n",
      "2018-05-04T19:16:47.030846: step 18465, loss 0.30413, acc 0.875\n",
      "2018-05-04T19:16:48.047536: step 18466, loss 0.210628, acc 0.921875\n",
      "2018-05-04T19:16:48.993209: step 18467, loss 0.19091, acc 0.9375\n",
      "2018-05-04T19:16:49.909815: step 18468, loss 0.178823, acc 0.921875\n",
      "2018-05-04T19:16:50.935266: step 18469, loss 0.135965, acc 0.90625\n",
      "2018-05-04T19:16:51.996899: step 18470, loss 0.256054, acc 0.890625\n",
      "2018-05-04T19:16:53.012692: step 18471, loss 0.287034, acc 0.90625\n",
      "2018-05-04T19:16:53.930129: step 18472, loss 0.19284, acc 0.90625\n",
      "2018-05-04T19:16:54.856252: step 18473, loss 0.265153, acc 0.859375\n",
      "2018-05-04T19:16:55.866259: step 18474, loss 0.261159, acc 0.90625\n",
      "2018-05-04T19:16:56.846386: step 18475, loss 0.337693, acc 0.9375\n",
      "2018-05-04T19:16:57.768983: step 18476, loss 0.185563, acc 0.921875\n",
      "2018-05-04T19:16:58.690123: step 18477, loss 0.286723, acc 0.875\n",
      "2018-05-04T19:16:59.710956: step 18478, loss 0.263125, acc 0.875\n",
      "2018-05-04T19:17:00.734834: step 18479, loss 0.372239, acc 0.859375\n",
      "2018-05-04T19:17:01.731710: step 18480, loss 0.270013, acc 0.90625\n",
      "2018-05-04T19:17:02.657718: step 18481, loss 0.265692, acc 0.890625\n",
      "2018-05-04T19:17:03.603590: step 18482, loss 0.19305, acc 0.921875\n",
      "2018-05-04T19:17:04.630529: step 18483, loss 0.27751, acc 0.890625\n",
      "2018-05-04T19:17:05.645526: step 18484, loss 0.162726, acc 0.953125\n",
      "2018-05-04T19:17:06.573095: step 18485, loss 0.471923, acc 0.859375\n",
      "2018-05-04T19:17:07.505116: step 18486, loss 0.388876, acc 0.828125\n",
      "2018-05-04T19:17:08.523699: step 18487, loss 0.292458, acc 0.890625\n",
      "2018-05-04T19:17:09.444567: step 18488, loss 0.256077, acc 0.90625\n",
      "2018-05-04T19:17:10.367379: step 18489, loss 0.293842, acc 0.890625\n",
      "2018-05-04T19:17:11.400323: step 18490, loss 0.214282, acc 0.90625\n",
      "2018-05-04T19:17:12.435887: step 18491, loss 0.20147, acc 0.96875\n",
      "2018-05-04T19:17:13.362162: step 18492, loss 0.281803, acc 0.90625\n",
      "2018-05-04T19:17:14.377797: step 18493, loss 0.168008, acc 0.90625\n",
      "2018-05-04T19:17:15.290949: step 18494, loss 0.334715, acc 0.859375\n",
      "2018-05-04T19:17:16.299997: step 18495, loss 0.27417, acc 0.828125\n",
      "2018-05-04T19:17:17.248974: step 18496, loss 0.194647, acc 0.890625\n",
      "2018-05-04T19:17:18.176871: step 18497, loss 0.234775, acc 0.890625\n",
      "2018-05-04T19:17:19.116853: step 18498, loss 0.322086, acc 0.84375\n",
      "2018-05-04T19:17:20.060108: step 18499, loss 0.201806, acc 0.9375\n",
      "2018-05-04T19:17:21.091226: step 18500, loss 0.230416, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T19:17:24.346023: step 18500, loss 0.223637, acc 0.92\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-18500\n",
      "\n",
      "2018-05-04T19:17:25.401275: step 18501, loss 0.168198, acc 0.953125\n",
      "2018-05-04T19:17:26.382235: step 18502, loss 0.344055, acc 0.84375\n",
      "2018-05-04T19:17:27.442123: step 18503, loss 0.140441, acc 0.96875\n",
      "2018-05-04T19:17:28.435301: step 18504, loss 0.32038, acc 0.859375\n",
      "2018-05-04T19:17:29.428137: step 18505, loss 0.230111, acc 0.90625\n",
      "2018-05-04T19:17:30.434632: step 18506, loss 0.286099, acc 0.875\n",
      "2018-05-04T19:17:31.442061: step 18507, loss 0.207564, acc 0.90625\n",
      "2018-05-04T19:17:32.482406: step 18508, loss 0.190451, acc 0.9375\n",
      "2018-05-04T19:17:33.508131: step 18509, loss 0.26995, acc 0.859375\n",
      "2018-05-04T19:17:34.527702: step 18510, loss 0.197719, acc 0.890625\n",
      "2018-05-04T19:17:35.509272: step 18511, loss 0.1724, acc 0.9375\n",
      "2018-05-04T19:17:36.585646: step 18512, loss 0.373428, acc 0.875\n",
      "2018-05-04T19:17:37.629458: step 18513, loss 0.222157, acc 0.921875\n",
      "2018-05-04T19:17:38.568126: step 18514, loss 0.219742, acc 0.90625\n",
      "2018-05-04T19:17:39.551007: step 18515, loss 0.227159, acc 0.921875\n",
      "2018-05-04T19:17:40.491093: step 18516, loss 0.167115, acc 0.953125\n",
      "2018-05-04T19:17:41.445366: step 18517, loss 0.162774, acc 0.9375\n",
      "2018-05-04T19:17:42.439175: step 18518, loss 0.505679, acc 0.8125\n",
      "2018-05-04T19:17:43.417744: step 18519, loss 0.226964, acc 0.875\n",
      "2018-05-04T19:17:44.386447: step 18520, loss 0.362972, acc 0.84375\n",
      "2018-05-04T19:17:45.339906: step 18521, loss 0.418992, acc 0.828125\n",
      "2018-05-04T19:17:46.298924: step 18522, loss 0.263197, acc 0.90625\n",
      "2018-05-04T19:17:47.269074: step 18523, loss 0.304532, acc 0.859375\n",
      "2018-05-04T19:17:48.228055: step 18524, loss 0.261299, acc 0.890625\n",
      "2018-05-04T19:17:49.201983: step 18525, loss 0.225193, acc 0.875\n",
      "2018-05-04T19:17:50.152562: step 18526, loss 0.361912, acc 0.890625\n",
      "2018-05-04T19:17:51.115914: step 18527, loss 0.207916, acc 0.90625\n",
      "2018-05-04T19:17:52.196700: step 18528, loss 0.196526, acc 0.921875\n",
      "2018-05-04T19:17:53.202443: step 18529, loss 0.175942, acc 0.9375\n",
      "2018-05-04T19:17:54.165756: step 18530, loss 0.25844, acc 0.921875\n",
      "2018-05-04T19:17:55.133940: step 18531, loss 0.307223, acc 0.84375\n",
      "2018-05-04T19:17:56.140925: step 18532, loss 0.315521, acc 0.859375\n",
      "2018-05-04T19:17:57.198354: step 18533, loss 0.247135, acc 0.890625\n",
      "2018-05-04T19:17:58.159798: step 18534, loss 0.333888, acc 0.9375\n",
      "2018-05-04T19:17:59.212417: step 18535, loss 0.317659, acc 0.84375\n",
      "2018-05-04T19:18:00.254289: step 18536, loss 0.270705, acc 0.921875\n",
      "2018-05-04T19:18:01.224840: step 18537, loss 0.235666, acc 0.90625\n",
      "2018-05-04T19:18:02.217584: step 18538, loss 0.25435, acc 0.890625\n",
      "2018-05-04T19:18:03.199839: step 18539, loss 0.320757, acc 0.84375\n",
      "2018-05-04T19:18:04.204875: step 18540, loss 0.191487, acc 0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T19:18:05.207752: step 18541, loss 0.177634, acc 0.9375\n",
      "2018-05-04T19:18:06.209958: step 18542, loss 0.18971, acc 0.96875\n",
      "2018-05-04T19:18:07.183797: step 18543, loss 0.346701, acc 0.8125\n",
      "2018-05-04T19:18:08.150170: step 18544, loss 0.251446, acc 0.90625\n",
      "2018-05-04T19:18:09.116209: step 18545, loss 0.281929, acc 0.921875\n",
      "2018-05-04T19:18:10.081089: step 18546, loss 0.17995, acc 0.9375\n",
      "2018-05-04T19:18:11.141020: step 18547, loss 0.365832, acc 0.796875\n",
      "2018-05-04T19:18:12.089431: step 18548, loss 0.233084, acc 0.90625\n",
      "2018-05-04T19:18:13.065986: step 18549, loss 0.277697, acc 0.875\n",
      "2018-05-04T19:18:14.043813: step 18550, loss 0.174856, acc 0.9375\n",
      "2018-05-04T19:18:15.063740: step 18551, loss 0.142646, acc 0.96875\n",
      "2018-05-04T19:18:16.005654: step 18552, loss 0.41628, acc 0.84375\n",
      "2018-05-04T19:18:17.050018: step 18553, loss 0.157482, acc 0.9375\n",
      "2018-05-04T19:18:18.012851: step 18554, loss 0.262471, acc 0.90625\n",
      "2018-05-04T19:18:19.048378: step 18555, loss 0.205829, acc 0.90625\n",
      "2018-05-04T19:18:20.010657: step 18556, loss 0.374555, acc 0.84375\n",
      "2018-05-04T19:18:20.952581: step 18557, loss 0.283487, acc 0.90625\n",
      "2018-05-04T19:18:21.960237: step 18558, loss 0.179718, acc 0.921875\n",
      "2018-05-04T19:18:22.908088: step 18559, loss 0.204914, acc 0.90625\n",
      "2018-05-04T19:18:23.869833: step 18560, loss 0.438262, acc 0.84375\n",
      "2018-05-04T19:18:24.950208: step 18561, loss 0.194361, acc 0.953125\n",
      "2018-05-04T19:18:26.005431: step 18562, loss 0.150041, acc 0.9375\n",
      "2018-05-04T19:18:26.947242: step 18563, loss 0.332033, acc 0.84375\n",
      "2018-05-04T19:18:27.918806: step 18564, loss 0.278586, acc 0.890625\n",
      "2018-05-04T19:18:28.910032: step 18565, loss 0.338327, acc 0.875\n",
      "2018-05-04T19:18:29.898330: step 18566, loss 0.261585, acc 0.890625\n",
      "2018-05-04T19:18:30.883528: step 18567, loss 0.31196, acc 0.84375\n",
      "2018-05-04T19:18:31.889840: step 18568, loss 0.287672, acc 0.859375\n",
      "2018-05-04T19:18:32.877684: step 18569, loss 0.24025, acc 0.890625\n",
      "2018-05-04T19:18:33.858208: step 18570, loss 0.238529, acc 0.90625\n",
      "2018-05-04T19:18:34.811162: step 18571, loss 0.360701, acc 0.84375\n",
      "2018-05-04T19:18:35.764960: step 18572, loss 0.166407, acc 0.953125\n",
      "2018-05-04T19:18:36.734470: step 18573, loss 0.258605, acc 0.875\n",
      "2018-05-04T19:18:37.714025: step 18574, loss 0.274372, acc 0.859375\n",
      "2018-05-04T19:18:38.688951: step 18575, loss 0.291859, acc 0.90625\n",
      "2018-05-04T19:18:39.648524: step 18576, loss 0.26576, acc 0.890625\n",
      "2018-05-04T19:18:40.594445: step 18577, loss 0.334608, acc 0.828125\n",
      "2018-05-04T19:18:41.558755: step 18578, loss 0.199723, acc 0.921875\n",
      "2018-05-04T19:18:42.561836: step 18579, loss 0.332855, acc 0.921875\n",
      "2018-05-04T19:18:43.539274: step 18580, loss 0.351397, acc 0.84375\n",
      "2018-05-04T19:18:44.524989: step 18581, loss 0.139028, acc 0.96875\n",
      "2018-05-04T19:18:45.501580: step 18582, loss 0.206824, acc 0.953125\n",
      "2018-05-04T19:18:46.449990: step 18583, loss 0.241671, acc 0.875\n",
      "2018-05-04T19:18:47.397569: step 18584, loss 0.277656, acc 0.875\n",
      "2018-05-04T19:18:48.454570: step 18585, loss 0.191336, acc 0.90625\n",
      "2018-05-04T19:18:49.420076: step 18586, loss 0.205684, acc 0.90625\n",
      "2018-05-04T19:18:50.389071: step 18587, loss 0.222507, acc 0.921875\n",
      "2018-05-04T19:18:51.315423: step 18588, loss 0.278648, acc 0.953125\n",
      "2018-05-04T19:18:52.279685: step 18589, loss 0.174779, acc 0.921875\n",
      "2018-05-04T19:18:53.248289: step 18590, loss 0.145654, acc 0.9375\n",
      "2018-05-04T19:18:54.230061: step 18591, loss 0.253491, acc 0.90625\n",
      "2018-05-04T19:18:55.185634: step 18592, loss 0.135775, acc 0.96875\n",
      "2018-05-04T19:18:56.211408: step 18593, loss 0.181304, acc 0.9375\n",
      "2018-05-04T19:18:57.159453: step 18594, loss 0.230246, acc 0.921875\n",
      "2018-05-04T19:18:58.092899: step 18595, loss 0.309191, acc 0.921875\n",
      "2018-05-04T19:18:59.047349: step 18596, loss 0.298011, acc 0.890625\n",
      "2018-05-04T19:19:00.064613: step 18597, loss 0.327466, acc 0.84375\n",
      "2018-05-04T19:19:01.012252: step 18598, loss 0.152388, acc 0.921875\n",
      "2018-05-04T19:19:01.979519: step 18599, loss 0.320748, acc 0.90625\n",
      "2018-05-04T19:19:02.948402: step 18600, loss 0.260489, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T19:19:05.357748: step 18600, loss 0.214468, acc 0.928\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-18600\n",
      "\n",
      "2018-05-04T19:19:06.457287: step 18601, loss 0.180365, acc 0.953125\n",
      "2018-05-04T19:19:07.477355: step 18602, loss 0.326512, acc 0.90625\n",
      "2018-05-04T19:19:08.477721: step 18603, loss 0.330408, acc 0.875\n",
      "2018-05-04T19:19:09.484720: step 18604, loss 0.232115, acc 0.890625\n",
      "2018-05-04T19:19:10.511450: step 18605, loss 0.168385, acc 0.96875\n",
      "2018-05-04T19:19:11.671375: step 18606, loss 0.328289, acc 0.875\n",
      "2018-05-04T19:19:12.660776: step 18607, loss 0.240932, acc 0.890625\n",
      "2018-05-04T19:19:13.634149: step 18608, loss 0.215786, acc 0.90625\n",
      "2018-05-04T19:19:14.588698: step 18609, loss 0.174698, acc 0.953125\n",
      "2018-05-04T19:19:15.557483: step 18610, loss 0.306354, acc 0.875\n",
      "2018-05-04T19:19:16.530125: step 18611, loss 0.28381, acc 0.890625\n",
      "2018-05-04T19:19:17.555697: step 18612, loss 0.399611, acc 0.8125\n",
      "2018-05-04T19:19:18.521026: step 18613, loss 0.262192, acc 0.890625\n",
      "2018-05-04T19:19:19.492297: step 18614, loss 0.326353, acc 0.859375\n",
      "2018-05-04T19:19:20.470169: step 18615, loss 0.389907, acc 0.859375\n",
      "2018-05-04T19:19:21.454686: step 18616, loss 0.205345, acc 0.921875\n",
      "2018-05-04T19:19:22.414160: step 18617, loss 0.2874, acc 0.890625\n",
      "2018-05-04T19:19:23.396850: step 18618, loss 0.315277, acc 0.875\n",
      "2018-05-04T19:19:24.424270: step 18619, loss 0.212475, acc 0.890625\n",
      "2018-05-04T19:19:25.383099: step 18620, loss 0.187729, acc 0.90625\n",
      "2018-05-04T19:19:26.349149: step 18621, loss 0.208899, acc 0.921875\n",
      "2018-05-04T19:19:27.296026: step 18622, loss 0.251183, acc 0.96875\n",
      "2018-05-04T19:19:28.256611: step 18623, loss 0.189953, acc 0.953125\n",
      "2018-05-04T19:19:29.251782: step 18624, loss 0.306468, acc 0.875\n",
      "2018-05-04T19:19:30.230750: step 18625, loss 0.168267, acc 0.9375\n",
      "2018-05-04T19:19:31.199492: step 18626, loss 0.249213, acc 0.875\n",
      "2018-05-04T19:19:32.206914: step 18627, loss 0.180667, acc 0.90625\n",
      "2018-05-04T19:19:33.264768: step 18628, loss 0.243311, acc 0.890625\n",
      "2018-05-04T19:19:34.385525: step 18629, loss 0.335739, acc 0.875\n",
      "2018-05-04T19:19:35.385962: step 18630, loss 0.260312, acc 0.921875\n",
      "2018-05-04T19:19:36.397262: step 18631, loss 0.198155, acc 0.90625\n",
      "2018-05-04T19:19:37.435844: step 18632, loss 0.305945, acc 0.859375\n",
      "2018-05-04T19:19:38.458118: step 18633, loss 0.214191, acc 0.90625\n",
      "2018-05-04T19:19:39.475211: step 18634, loss 0.300726, acc 0.84375\n",
      "2018-05-04T19:19:40.513999: step 18635, loss 0.175736, acc 0.921875\n",
      "2018-05-04T19:19:41.465283: step 18636, loss 0.223991, acc 0.921875\n",
      "2018-05-04T19:19:42.468770: step 18637, loss 0.298866, acc 0.875\n",
      "2018-05-04T19:19:43.417358: step 18638, loss 0.357553, acc 0.875\n",
      "2018-05-04T19:19:44.369371: step 18639, loss 0.373615, acc 0.859375\n",
      "2018-05-04T19:19:45.345519: step 18640, loss 0.358543, acc 0.84375\n",
      "2018-05-04T19:19:46.325190: step 18641, loss 0.206748, acc 0.9375\n",
      "2018-05-04T19:19:47.294769: step 18642, loss 0.294261, acc 0.890625\n",
      "2018-05-04T19:19:48.256556: step 18643, loss 0.372046, acc 0.859375\n",
      "2018-05-04T19:19:49.230919: step 18644, loss 0.272089, acc 0.921875\n",
      "2018-05-04T19:19:50.212852: step 18645, loss 0.330652, acc 0.84375\n",
      "2018-05-04T19:19:51.204595: step 18646, loss 0.291902, acc 0.859375\n",
      "2018-05-04T19:19:52.189590: step 18647, loss 0.377335, acc 0.828125\n",
      "2018-05-04T19:19:53.178198: step 18648, loss 0.225593, acc 0.921875\n",
      "2018-05-04T19:19:54.164540: step 18649, loss 0.292117, acc 0.875\n",
      "2018-05-04T19:19:55.132535: step 18650, loss 0.234092, acc 0.890625\n",
      "2018-05-04T19:19:56.102287: step 18651, loss 0.221348, acc 0.90625\n",
      "2018-05-04T19:19:57.079992: step 18652, loss 0.309225, acc 0.875\n",
      "2018-05-04T19:19:58.033888: step 18653, loss 0.341231, acc 0.859375\n",
      "2018-05-04T19:19:59.017185: step 18654, loss 0.326615, acc 0.828125\n",
      "2018-05-04T19:19:59.970359: step 18655, loss 0.300278, acc 0.8125\n",
      "2018-05-04T19:20:01.045546: step 18656, loss 0.175046, acc 0.921875\n",
      "2018-05-04T19:20:02.021354: step 18657, loss 0.19497, acc 0.875\n",
      "2018-05-04T19:20:02.988522: step 18658, loss 0.316106, acc 0.859375\n",
      "2018-05-04T19:20:03.982606: step 18659, loss 0.271671, acc 0.890625\n",
      "2018-05-04T19:20:04.952525: step 18660, loss 0.232525, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T19:20:05.917424: step 18661, loss 0.268985, acc 0.84375\n",
      "2018-05-04T19:20:06.893312: step 18662, loss 0.151869, acc 0.953125\n",
      "2018-05-04T19:20:07.875519: step 18663, loss 0.245227, acc 0.890625\n",
      "2018-05-04T19:20:08.933972: step 18664, loss 0.179086, acc 0.890625\n",
      "2018-05-04T19:20:09.923189: step 18665, loss 0.221747, acc 0.890625\n",
      "2018-05-04T19:20:10.868008: step 18666, loss 0.30782, acc 0.890625\n",
      "2018-05-04T19:20:11.882134: step 18667, loss 0.179877, acc 0.96875\n",
      "2018-05-04T19:20:12.862681: step 18668, loss 0.274095, acc 0.890625\n",
      "2018-05-04T19:20:13.817086: step 18669, loss 0.229579, acc 0.921875\n",
      "2018-05-04T19:20:14.763940: step 18670, loss 0.229509, acc 0.921875\n",
      "2018-05-04T19:20:15.718378: step 18671, loss 0.213177, acc 0.890625\n",
      "2018-05-04T19:20:16.695550: step 18672, loss 0.194644, acc 0.9375\n",
      "2018-05-04T19:20:17.664462: step 18673, loss 0.332657, acc 0.78125\n",
      "2018-05-04T19:20:18.611432: step 18674, loss 0.409848, acc 0.84375\n",
      "2018-05-04T19:20:19.575781: step 18675, loss 0.26787, acc 0.90625\n",
      "2018-05-04T19:20:20.542646: step 18676, loss 0.129936, acc 0.953125\n",
      "2018-05-04T19:20:21.588056: step 18677, loss 0.370166, acc 0.921875\n",
      "2018-05-04T19:20:22.578597: step 18678, loss 0.18993, acc 0.9375\n",
      "2018-05-04T19:20:23.544891: step 18679, loss 0.182194, acc 0.9375\n",
      "2018-05-04T19:20:24.531759: step 18680, loss 0.220565, acc 0.90625\n",
      "2018-05-04T19:20:25.504765: step 18681, loss 0.239739, acc 0.890625\n",
      "2018-05-04T19:20:26.454267: step 18682, loss 0.298836, acc 0.890625\n",
      "2018-05-04T19:20:27.421792: step 18683, loss 0.197862, acc 0.9375\n",
      "2018-05-04T19:20:28.388880: step 18684, loss 0.226347, acc 0.921875\n",
      "2018-05-04T19:20:29.361623: step 18685, loss 0.404392, acc 0.84375\n",
      "2018-05-04T19:20:30.330645: step 18686, loss 0.452692, acc 0.859375\n",
      "2018-05-04T19:20:31.292426: step 18687, loss 0.316456, acc 0.921875\n",
      "2018-05-04T19:20:32.250927: step 18688, loss 0.287994, acc 0.90625\n",
      "2018-05-04T19:20:33.215384: step 18689, loss 0.24094, acc 0.921875\n",
      "2018-05-04T19:20:34.172941: step 18690, loss 0.1901, acc 0.90625\n",
      "2018-05-04T19:20:35.200362: step 18691, loss 0.173967, acc 0.921875\n",
      "2018-05-04T19:20:36.149688: step 18692, loss 0.357462, acc 0.84375\n",
      "2018-05-04T19:20:37.099509: step 18693, loss 0.211195, acc 0.90625\n",
      "2018-05-04T19:20:38.045706: step 18694, loss 0.293435, acc 0.875\n",
      "2018-05-04T19:20:39.000243: step 18695, loss 0.180788, acc 0.9375\n",
      "2018-05-04T19:20:39.998345: step 18696, loss 0.321738, acc 0.859375\n",
      "2018-05-04T19:20:40.992683: step 18697, loss 0.319157, acc 0.890625\n",
      "2018-05-04T19:20:41.954068: step 18698, loss 0.193111, acc 0.96875\n",
      "2018-05-04T19:20:42.935582: step 18699, loss 0.200823, acc 0.953125\n",
      "2018-05-04T19:20:43.965134: step 18700, loss 0.229268, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T19:20:46.318219: step 18700, loss 0.218622, acc 0.928\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-18700\n",
      "\n",
      "2018-05-04T19:20:47.388947: step 18701, loss 0.327894, acc 0.84375\n",
      "2018-05-04T19:20:48.400827: step 18702, loss 0.251746, acc 0.875\n",
      "2018-05-04T19:20:49.415974: step 18703, loss 0.228175, acc 0.90625\n",
      "2018-05-04T19:20:50.421701: step 18704, loss 0.224532, acc 0.921875\n",
      "2018-05-04T19:20:51.445287: step 18705, loss 0.236512, acc 0.953125\n",
      "2018-05-04T19:20:52.469204: step 18706, loss 0.216421, acc 0.9375\n",
      "2018-05-04T19:20:53.500327: step 18707, loss 0.442244, acc 0.84375\n",
      "2018-05-04T19:20:54.499413: step 18708, loss 0.260681, acc 0.90625\n",
      "2018-05-04T19:20:55.503519: step 18709, loss 0.19604, acc 0.921875\n",
      "2018-05-04T19:20:56.483774: step 18710, loss 0.282074, acc 0.890625\n",
      "2018-05-04T19:20:57.466647: step 18711, loss 0.297218, acc 0.875\n",
      "2018-05-04T19:20:58.462805: step 18712, loss 0.161293, acc 0.953125\n",
      "2018-05-04T19:20:59.469861: step 18713, loss 0.15843, acc 0.9375\n",
      "2018-05-04T19:21:00.499625: step 18714, loss 0.198428, acc 0.90625\n",
      "2018-05-04T19:21:01.504084: step 18715, loss 0.296117, acc 0.859375\n",
      "2018-05-04T19:21:02.504685: step 18716, loss 0.176098, acc 0.9375\n",
      "2018-05-04T19:21:03.546866: step 18717, loss 0.162964, acc 0.9375\n",
      "2018-05-04T19:21:04.539402: step 18718, loss 0.318899, acc 0.90625\n",
      "2018-05-04T19:21:05.552563: step 18719, loss 0.271886, acc 0.90625\n",
      "2018-05-04T19:21:06.551932: step 18720, loss 0.197668, acc 0.953125\n",
      "2018-05-04T19:21:07.600328: step 18721, loss 0.381836, acc 0.921875\n",
      "2018-05-04T19:21:08.648815: step 18722, loss 0.219539, acc 0.859375\n",
      "2018-05-04T19:21:09.607039: step 18723, loss 0.375185, acc 0.890625\n",
      "2018-05-04T19:21:10.576288: step 18724, loss 0.354231, acc 0.890625\n",
      "2018-05-04T19:21:11.592902: step 18725, loss 0.170809, acc 0.921875\n",
      "2018-05-04T19:21:12.594615: step 18726, loss 0.25589, acc 0.921875\n",
      "2018-05-04T19:21:13.574951: step 18727, loss 0.157348, acc 0.953125\n",
      "2018-05-04T19:21:14.552411: step 18728, loss 0.233475, acc 0.9375\n",
      "2018-05-04T19:21:15.517981: step 18729, loss 0.220066, acc 0.9375\n",
      "2018-05-04T19:21:16.496534: step 18730, loss 0.290508, acc 0.90625\n",
      "2018-05-04T19:21:17.515457: step 18731, loss 0.382757, acc 0.890625\n",
      "2018-05-04T19:21:18.510880: step 18732, loss 0.285197, acc 0.875\n",
      "2018-05-04T19:21:19.529481: step 18733, loss 0.233333, acc 0.953125\n",
      "2018-05-04T19:21:20.485617: step 18734, loss 0.348839, acc 0.8125\n",
      "2018-05-04T19:21:21.503754: step 18735, loss 0.237462, acc 0.890625\n",
      "2018-05-04T19:21:22.525763: step 18736, loss 0.282706, acc 0.9375\n",
      "2018-05-04T19:21:23.537008: step 18737, loss 0.302209, acc 0.859375\n",
      "2018-05-04T19:21:24.566835: step 18738, loss 0.348985, acc 0.875\n",
      "2018-05-04T19:21:25.533237: step 18739, loss 0.226567, acc 0.90625\n",
      "2018-05-04T19:21:26.505084: step 18740, loss 0.175272, acc 0.890625\n",
      "2018-05-04T19:21:27.466294: step 18741, loss 0.171924, acc 0.953125\n",
      "2018-05-04T19:21:28.401781: step 18742, loss 0.26502, acc 0.90625\n",
      "2018-05-04T19:21:29.383658: step 18743, loss 0.211085, acc 0.921875\n",
      "2018-05-04T19:21:30.353335: step 18744, loss 0.232461, acc 0.921875\n",
      "2018-05-04T19:21:31.371765: step 18745, loss 0.303442, acc 0.859375\n",
      "2018-05-04T19:21:32.316293: step 18746, loss 0.214572, acc 0.9375\n",
      "2018-05-04T19:21:33.276471: step 18747, loss 0.272221, acc 0.875\n",
      "2018-05-04T19:21:34.293976: step 18748, loss 0.270429, acc 0.90625\n",
      "2018-05-04T19:21:35.297267: step 18749, loss 0.315329, acc 0.890625\n",
      "2018-05-04T19:21:36.286349: step 18750, loss 0.34461, acc 0.84375\n",
      "2018-05-04T19:21:37.240786: step 18751, loss 0.335876, acc 0.875\n",
      "2018-05-04T19:21:38.218905: step 18752, loss 0.179395, acc 0.9375\n",
      "2018-05-04T19:21:39.189252: step 18753, loss 0.152466, acc 0.921875\n",
      "2018-05-04T19:21:40.176334: step 18754, loss 0.258976, acc 0.921875\n",
      "2018-05-04T19:21:41.135913: step 18755, loss 0.474869, acc 0.8125\n",
      "2018-05-04T19:21:42.102974: step 18756, loss 0.222432, acc 0.890625\n",
      "2018-05-04T19:21:43.077898: step 18757, loss 0.345455, acc 0.859375\n",
      "2018-05-04T19:21:44.075012: step 18758, loss 0.229275, acc 0.921875\n",
      "2018-05-04T19:21:45.132173: step 18759, loss 0.454653, acc 0.84375\n",
      "2018-05-04T19:21:46.104086: step 18760, loss 0.322531, acc 0.859375\n",
      "2018-05-04T19:21:47.058696: step 18761, loss 0.405878, acc 0.859375\n",
      "2018-05-04T19:21:48.021450: step 18762, loss 0.255372, acc 0.921875\n",
      "2018-05-04T19:21:48.942204: step 18763, loss 0.180899, acc 0.90625\n",
      "2018-05-04T19:21:49.966093: step 18764, loss 0.226834, acc 0.9375\n",
      "2018-05-04T19:21:50.915990: step 18765, loss 0.212695, acc 0.9375\n",
      "2018-05-04T19:21:51.876767: step 18766, loss 0.1654, acc 0.953125\n",
      "2018-05-04T19:21:52.931871: step 18767, loss 0.191854, acc 0.921875\n",
      "2018-05-04T19:21:53.897938: step 18768, loss 0.30987, acc 0.921875\n",
      "2018-05-04T19:21:54.868312: step 18769, loss 0.223859, acc 0.890625\n",
      "2018-05-04T19:21:55.818700: step 18770, loss 0.379129, acc 0.796875\n",
      "2018-05-04T19:21:56.787471: step 18771, loss 0.366603, acc 0.875\n",
      "2018-05-04T19:21:57.766118: step 18772, loss 0.298618, acc 0.890625\n",
      "2018-05-04T19:21:58.733069: step 18773, loss 0.25982, acc 0.875\n",
      "2018-05-04T19:21:59.687520: step 18774, loss 0.214188, acc 0.90625\n",
      "2018-05-04T19:22:00.660646: step 18775, loss 0.384508, acc 0.890625\n",
      "2018-05-04T19:22:01.640666: step 18776, loss 0.194743, acc 0.921875\n",
      "2018-05-04T19:22:02.601334: step 18777, loss 0.31439, acc 0.828125\n",
      "2018-05-04T19:22:03.550621: step 18778, loss 0.163412, acc 0.921875\n",
      "2018-05-04T19:22:04.521576: step 18779, loss 0.177827, acc 0.953125\n",
      "2018-05-04T19:22:05.495533: step 18780, loss 0.223417, acc 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T19:22:06.441641: step 18781, loss 0.228942, acc 0.921875\n",
      "2018-05-04T19:22:07.398245: step 18782, loss 0.262818, acc 0.890625\n",
      "2018-05-04T19:22:08.347826: step 18783, loss 0.46014, acc 0.828125\n",
      "2018-05-04T19:22:09.311091: step 18784, loss 0.311453, acc 0.875\n",
      "2018-05-04T19:22:10.307763: step 18785, loss 0.177112, acc 0.9375\n",
      "2018-05-04T19:22:11.279939: step 18786, loss 0.22579, acc 0.875\n",
      "2018-05-04T19:22:12.258650: step 18787, loss 0.274798, acc 0.875\n",
      "2018-05-04T19:22:13.262774: step 18788, loss 0.166152, acc 0.953125\n",
      "2018-05-04T19:22:14.227191: step 18789, loss 0.387708, acc 0.859375\n",
      "2018-05-04T19:22:15.174874: step 18790, loss 0.214436, acc 0.921875\n",
      "2018-05-04T19:22:16.113486: step 18791, loss 0.282874, acc 0.875\n",
      "2018-05-04T19:22:17.065429: step 18792, loss 0.348844, acc 0.859375\n",
      "2018-05-04T19:22:18.022244: step 18793, loss 0.315226, acc 0.890625\n",
      "2018-05-04T19:22:18.979307: step 18794, loss 0.22106, acc 0.90625\n",
      "2018-05-04T19:22:19.952006: step 18795, loss 0.326946, acc 0.859375\n",
      "2018-05-04T19:22:20.929249: step 18796, loss 0.34782, acc 0.828125\n",
      "2018-05-04T19:22:21.867901: step 18797, loss 0.317882, acc 0.921875\n",
      "2018-05-04T19:22:22.809891: step 18798, loss 0.260495, acc 0.875\n",
      "2018-05-04T19:22:23.755429: step 18799, loss 0.318734, acc 0.84375\n",
      "2018-05-04T19:22:24.702246: step 18800, loss 0.231965, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T19:22:26.965552: step 18800, loss 0.230058, acc 0.926\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-18800\n",
      "\n",
      "2018-05-04T19:22:28.062995: step 18801, loss 0.313759, acc 0.859375\n",
      "2018-05-04T19:22:29.049804: step 18802, loss 0.198309, acc 0.9375\n",
      "2018-05-04T19:22:30.075813: step 18803, loss 0.27582, acc 0.890625\n",
      "2018-05-04T19:22:31.148980: step 18804, loss 0.236798, acc 0.90625\n",
      "2018-05-04T19:22:32.146980: step 18805, loss 0.290124, acc 0.859375\n",
      "2018-05-04T19:22:33.253321: step 18806, loss 0.235324, acc 0.90625\n",
      "2018-05-04T19:22:34.282661: step 18807, loss 0.193855, acc 0.921875\n",
      "2018-05-04T19:22:35.366367: step 18808, loss 0.154716, acc 0.9375\n",
      "2018-05-04T19:22:36.389447: step 18809, loss 0.289931, acc 0.90625\n",
      "2018-05-04T19:22:37.353003: step 18810, loss 0.180814, acc 0.9375\n",
      "2018-05-04T19:22:38.324856: step 18811, loss 0.300601, acc 0.84375\n",
      "2018-05-04T19:22:39.284982: step 18812, loss 0.245596, acc 0.875\n",
      "2018-05-04T19:22:40.278002: step 18813, loss 0.275367, acc 0.875\n",
      "2018-05-04T19:22:41.265175: step 18814, loss 0.249002, acc 0.90625\n",
      "2018-05-04T19:22:42.246290: step 18815, loss 0.189494, acc 0.921875\n",
      "2018-05-04T19:22:43.206428: step 18816, loss 0.2347, acc 0.890625\n",
      "2018-05-04T19:22:44.204075: step 18817, loss 0.23133, acc 0.921875\n",
      "2018-05-04T19:22:45.233468: step 18818, loss 0.316514, acc 0.875\n",
      "2018-05-04T19:22:46.195070: step 18819, loss 0.162283, acc 0.9375\n",
      "2018-05-04T19:22:47.167610: step 18820, loss 0.394821, acc 0.828125\n",
      "2018-05-04T19:22:48.166404: step 18821, loss 0.195573, acc 0.921875\n",
      "2018-05-04T19:22:49.148999: step 18822, loss 0.225101, acc 0.90625\n",
      "2018-05-04T19:22:50.120892: step 18823, loss 0.317606, acc 0.859375\n",
      "2018-05-04T19:22:51.081797: step 18824, loss 0.17736, acc 0.921875\n",
      "2018-05-04T19:22:52.060068: step 18825, loss 0.314651, acc 0.8125\n",
      "2018-05-04T19:22:53.048391: step 18826, loss 0.172033, acc 0.9375\n",
      "2018-05-04T19:22:54.114359: step 18827, loss 0.185325, acc 0.921875\n",
      "2018-05-04T19:22:55.119225: step 18828, loss 0.238129, acc 0.921875\n",
      "2018-05-04T19:22:56.145051: step 18829, loss 0.274131, acc 0.890625\n",
      "2018-05-04T19:22:57.161032: step 18830, loss 0.224954, acc 0.890625\n",
      "2018-05-04T19:22:58.166132: step 18831, loss 0.281601, acc 0.90625\n",
      "2018-05-04T19:22:59.166447: step 18832, loss 0.275313, acc 0.90625\n",
      "2018-05-04T19:23:00.154572: step 18833, loss 0.25849, acc 0.890625\n",
      "2018-05-04T19:23:01.116716: step 18834, loss 0.175708, acc 0.953125\n",
      "2018-05-04T19:23:02.094598: step 18835, loss 0.324778, acc 0.828125\n",
      "2018-05-04T19:23:03.104387: step 18836, loss 0.235729, acc 0.90625\n",
      "2018-05-04T19:23:04.078317: step 18837, loss 0.2713, acc 0.90625\n",
      "2018-05-04T19:23:05.034928: step 18838, loss 0.25776, acc 0.90625\n",
      "2018-05-04T19:23:05.987564: step 18839, loss 0.186043, acc 0.9375\n",
      "2018-05-04T19:23:06.952043: step 18840, loss 0.246427, acc 0.890625\n",
      "2018-05-04T19:23:07.964136: step 18841, loss 0.414081, acc 0.796875\n",
      "2018-05-04T19:23:08.951350: step 18842, loss 0.200064, acc 0.90625\n",
      "2018-05-04T19:23:09.960809: step 18843, loss 0.279642, acc 0.875\n",
      "2018-05-04T19:23:10.905914: step 18844, loss 0.213866, acc 0.890625\n",
      "2018-05-04T19:23:11.881816: step 18845, loss 0.30168, acc 0.90625\n",
      "2018-05-04T19:23:12.847375: step 18846, loss 0.268435, acc 0.90625\n",
      "2018-05-04T19:23:13.832018: step 18847, loss 0.275905, acc 0.90625\n",
      "2018-05-04T19:23:14.828676: step 18848, loss 0.344126, acc 0.859375\n",
      "2018-05-04T19:23:15.813513: step 18849, loss 0.29483, acc 0.890625\n",
      "2018-05-04T19:23:16.790495: step 18850, loss 0.287454, acc 0.90625\n",
      "2018-05-04T19:23:17.847987: step 18851, loss 0.250542, acc 0.90625\n",
      "2018-05-04T19:23:18.870417: step 18852, loss 0.472681, acc 0.8125\n",
      "2018-05-04T19:23:19.922175: step 18853, loss 0.281164, acc 0.890625\n",
      "2018-05-04T19:23:20.896406: step 18854, loss 0.336869, acc 0.90625\n",
      "2018-05-04T19:23:21.871491: step 18855, loss 0.19307, acc 0.90625\n",
      "2018-05-04T19:23:22.847934: step 18856, loss 0.318211, acc 0.875\n",
      "2018-05-04T19:23:23.811128: step 18857, loss 0.181764, acc 0.921875\n",
      "2018-05-04T19:23:24.786944: step 18858, loss 0.288463, acc 0.859375\n",
      "2018-05-04T19:23:25.743254: step 18859, loss 0.401821, acc 0.84375\n",
      "2018-05-04T19:23:26.693089: step 18860, loss 0.248843, acc 0.9375\n",
      "2018-05-04T19:23:27.657312: step 18861, loss 0.254376, acc 0.859375\n",
      "2018-05-04T19:23:28.637857: step 18862, loss 0.243369, acc 0.921875\n",
      "2018-05-04T19:23:29.620533: step 18863, loss 0.23643, acc 0.859375\n",
      "2018-05-04T19:23:30.590184: step 18864, loss 0.235586, acc 0.921875\n",
      "2018-05-04T19:23:31.537613: step 18865, loss 0.291559, acc 0.90625\n",
      "2018-05-04T19:23:32.515968: step 18866, loss 0.244471, acc 0.90625\n",
      "2018-05-04T19:23:33.462890: step 18867, loss 0.270796, acc 0.890625\n",
      "2018-05-04T19:23:34.424529: step 18868, loss 0.337353, acc 0.875\n",
      "2018-05-04T19:23:35.416290: step 18869, loss 0.350762, acc 0.828125\n",
      "2018-05-04T19:23:36.372920: step 18870, loss 0.271286, acc 0.875\n",
      "2018-05-04T19:23:37.427808: step 18871, loss 0.240451, acc 0.921875\n",
      "2018-05-04T19:23:38.396341: step 18872, loss 0.267257, acc 0.90625\n",
      "2018-05-04T19:23:39.342987: step 18873, loss 0.278712, acc 0.90625\n",
      "2018-05-04T19:23:40.305003: step 18874, loss 0.290752, acc 0.90625\n",
      "2018-05-04T19:23:41.293370: step 18875, loss 0.241413, acc 0.921875\n",
      "2018-05-04T19:23:42.246930: step 18876, loss 0.296485, acc 0.890625\n",
      "2018-05-04T19:23:43.319644: step 18877, loss 0.311311, acc 0.875\n",
      "2018-05-04T19:23:44.290257: step 18878, loss 0.283382, acc 0.890625\n",
      "2018-05-04T19:23:45.264061: step 18879, loss 0.456029, acc 0.734375\n",
      "2018-05-04T19:23:46.234886: step 18880, loss 0.174244, acc 0.953125\n",
      "2018-05-04T19:23:47.188056: step 18881, loss 0.231938, acc 0.90625\n",
      "2018-05-04T19:23:48.124540: step 18882, loss 0.371104, acc 0.859375\n",
      "2018-05-04T19:23:49.072613: step 18883, loss 0.239095, acc 0.9375\n",
      "2018-05-04T19:23:50.025251: step 18884, loss 0.217964, acc 0.921875\n",
      "2018-05-04T19:23:50.994587: step 18885, loss 0.171713, acc 0.9375\n",
      "2018-05-04T19:23:51.935235: step 18886, loss 0.212959, acc 0.921875\n",
      "2018-05-04T19:23:52.881877: step 18887, loss 0.355433, acc 0.859375\n",
      "2018-05-04T19:23:53.824572: step 18888, loss 0.24698, acc 0.90625\n",
      "2018-05-04T19:23:54.819609: step 18889, loss 0.235588, acc 0.921875\n",
      "2018-05-04T19:23:55.813152: step 18890, loss 0.189508, acc 0.90625\n",
      "2018-05-04T19:23:56.755880: step 18891, loss 0.340189, acc 0.875\n",
      "2018-05-04T19:23:57.716209: step 18892, loss 0.26787, acc 0.84375\n",
      "2018-05-04T19:23:58.676204: step 18893, loss 0.17825, acc 0.890625\n",
      "2018-05-04T19:23:59.682281: step 18894, loss 0.219983, acc 0.953125\n",
      "2018-05-04T19:24:00.657792: step 18895, loss 0.268347, acc 0.890625\n",
      "2018-05-04T19:24:01.636689: step 18896, loss 0.309703, acc 0.890625\n",
      "2018-05-04T19:24:02.627171: step 18897, loss 0.103175, acc 0.984375\n",
      "2018-05-04T19:24:03.587792: step 18898, loss 0.260897, acc 0.890625\n",
      "2018-05-04T19:24:04.566234: step 18899, loss 0.196424, acc 0.9375\n",
      "2018-05-04T19:24:05.509705: step 18900, loss 0.309187, acc 0.90625\n",
      "\n",
      "Evaluation:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T19:24:07.938458: step 18900, loss 0.230192, acc 0.918\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-18900\n",
      "\n",
      "2018-05-04T19:24:09.001121: step 18901, loss 0.184782, acc 0.953125\n",
      "2018-05-04T19:24:10.022866: step 18902, loss 0.24116, acc 0.890625\n",
      "2018-05-04T19:24:11.051142: step 18903, loss 0.422271, acc 0.78125\n",
      "2018-05-04T19:24:12.074030: step 18904, loss 0.193421, acc 0.9375\n",
      "2018-05-04T19:24:13.121222: step 18905, loss 0.126419, acc 0.96875\n",
      "2018-05-04T19:24:14.122825: step 18906, loss 0.258462, acc 0.890625\n",
      "2018-05-04T19:24:15.087291: step 18907, loss 0.335849, acc 0.828125\n",
      "2018-05-04T19:24:16.055434: step 18908, loss 0.322927, acc 0.875\n",
      "2018-05-04T19:24:17.047427: step 18909, loss 0.144355, acc 0.984375\n",
      "2018-05-04T19:24:18.033994: step 18910, loss 0.255131, acc 0.859375\n",
      "2018-05-04T19:24:19.056802: step 18911, loss 0.387346, acc 0.84375\n",
      "2018-05-04T19:24:20.072019: step 18912, loss 0.27199, acc 0.921875\n",
      "2018-05-04T19:24:21.060447: step 18913, loss 0.193445, acc 0.921875\n",
      "2018-05-04T19:24:22.040601: step 18914, loss 0.25552, acc 0.921875\n",
      "2018-05-04T19:24:22.992591: step 18915, loss 0.232528, acc 0.921875\n",
      "2018-05-04T19:24:24.059729: step 18916, loss 0.339273, acc 0.859375\n",
      "2018-05-04T19:24:25.044108: step 18917, loss 0.185084, acc 0.9375\n",
      "2018-05-04T19:24:26.002757: step 18918, loss 0.303795, acc 0.828125\n",
      "2018-05-04T19:24:27.053192: step 18919, loss 0.350722, acc 0.921875\n",
      "2018-05-04T19:24:28.093408: step 18920, loss 0.353888, acc 0.890625\n",
      "2018-05-04T19:24:29.066410: step 18921, loss 0.188467, acc 0.921875\n",
      "2018-05-04T19:24:30.019203: step 18922, loss 0.224036, acc 0.875\n",
      "2018-05-04T19:24:31.006250: step 18923, loss 0.218522, acc 0.875\n",
      "2018-05-04T19:24:31.955824: step 18924, loss 0.18652, acc 0.921875\n",
      "2018-05-04T19:24:32.924569: step 18925, loss 0.240486, acc 0.890625\n",
      "2018-05-04T19:24:33.924123: step 18926, loss 0.280963, acc 0.890625\n",
      "2018-05-04T19:24:34.890799: step 18927, loss 0.246745, acc 0.890625\n",
      "2018-05-04T19:24:35.873368: step 18928, loss 0.167801, acc 0.921875\n",
      "2018-05-04T19:24:36.850635: step 18929, loss 0.218033, acc 0.890625\n",
      "2018-05-04T19:24:37.799900: step 18930, loss 0.300894, acc 0.875\n",
      "2018-05-04T19:24:38.784868: step 18931, loss 0.352842, acc 0.859375\n",
      "2018-05-04T19:24:39.760411: step 18932, loss 0.257746, acc 0.921875\n",
      "2018-05-04T19:24:40.808807: step 18933, loss 0.374695, acc 0.84375\n",
      "2018-05-04T19:24:41.920698: step 18934, loss 0.229404, acc 0.921875\n",
      "2018-05-04T19:24:42.923226: step 18935, loss 0.252415, acc 0.90625\n",
      "2018-05-04T19:24:43.914565: step 18936, loss 0.168642, acc 0.921875\n",
      "2018-05-04T19:24:44.895252: step 18937, loss 0.164942, acc 0.9375\n",
      "2018-05-04T19:24:45.885576: step 18938, loss 0.158562, acc 0.96875\n",
      "2018-05-04T19:24:46.880112: step 18939, loss 0.286546, acc 0.9375\n",
      "2018-05-04T19:24:47.944532: step 18940, loss 0.359464, acc 0.875\n",
      "2018-05-04T19:24:48.943921: step 18941, loss 0.244273, acc 0.890625\n",
      "2018-05-04T19:24:49.910138: step 18942, loss 0.272072, acc 0.875\n",
      "2018-05-04T19:24:50.871640: step 18943, loss 0.2704, acc 0.875\n",
      "2018-05-04T19:24:51.859786: step 18944, loss 0.161083, acc 0.921875\n",
      "2018-05-04T19:24:52.854360: step 18945, loss 0.289252, acc 0.828125\n",
      "2018-05-04T19:24:53.852095: step 18946, loss 0.290874, acc 0.890625\n",
      "2018-05-04T19:24:54.852610: step 18947, loss 0.407798, acc 0.890625\n",
      "2018-05-04T19:24:55.852506: step 18948, loss 0.380745, acc 0.84375\n",
      "2018-05-04T19:24:56.869001: step 18949, loss 0.226352, acc 0.90625\n",
      "2018-05-04T19:24:57.837968: step 18950, loss 0.2304, acc 0.890625\n",
      "2018-05-04T19:24:58.894924: step 18951, loss 0.191318, acc 0.90625\n",
      "2018-05-04T19:24:59.872254: step 18952, loss 0.320215, acc 0.84375\n",
      "2018-05-04T19:25:00.842707: step 18953, loss 0.22889, acc 0.9375\n",
      "2018-05-04T19:25:01.802230: step 18954, loss 0.221254, acc 0.90625\n",
      "2018-05-04T19:25:02.769708: step 18955, loss 0.269059, acc 0.875\n",
      "2018-05-04T19:25:03.839922: step 18956, loss 0.325556, acc 0.890625\n",
      "2018-05-04T19:25:04.786438: step 18957, loss 0.199854, acc 0.9375\n",
      "2018-05-04T19:25:05.740987: step 18958, loss 0.207951, acc 0.90625\n",
      "2018-05-04T19:25:06.705691: step 18959, loss 0.171113, acc 0.90625\n",
      "2018-05-04T19:25:07.675933: step 18960, loss 0.189294, acc 0.90625\n",
      "2018-05-04T19:25:08.710572: step 18961, loss 0.168953, acc 0.921875\n",
      "2018-05-04T19:25:09.676230: step 18962, loss 0.272012, acc 0.90625\n",
      "2018-05-04T19:25:10.635748: step 18963, loss 0.256981, acc 0.875\n",
      "2018-05-04T19:25:11.594403: step 18964, loss 0.268578, acc 0.890625\n",
      "2018-05-04T19:25:12.541044: step 18965, loss 0.223455, acc 0.890625\n",
      "2018-05-04T19:25:13.504975: step 18966, loss 0.337167, acc 0.890625\n",
      "2018-05-04T19:25:14.451235: step 18967, loss 0.194958, acc 0.953125\n",
      "2018-05-04T19:25:15.423000: step 18968, loss 0.297374, acc 0.859375\n",
      "2018-05-04T19:25:16.494615: step 18969, loss 0.257862, acc 0.921875\n",
      "2018-05-04T19:25:17.582785: step 18970, loss 0.219817, acc 0.90625\n",
      "2018-05-04T19:25:18.541452: step 18971, loss 0.235014, acc 0.90625\n",
      "2018-05-04T19:25:19.530833: step 18972, loss 0.197858, acc 0.9375\n",
      "2018-05-04T19:25:20.583428: step 18973, loss 0.194377, acc 0.890625\n",
      "2018-05-04T19:25:21.564962: step 18974, loss 0.163664, acc 0.9375\n",
      "2018-05-04T19:25:22.544833: step 18975, loss 0.300306, acc 0.890625\n",
      "2018-05-04T19:25:23.554009: step 18976, loss 0.240799, acc 0.90625\n",
      "2018-05-04T19:25:24.547048: step 18977, loss 0.353528, acc 0.828125\n",
      "2018-05-04T19:25:25.534552: step 18978, loss 0.206744, acc 0.90625\n",
      "2018-05-04T19:25:26.508174: step 18979, loss 0.345732, acc 0.859375\n",
      "2018-05-04T19:25:27.469096: step 18980, loss 0.242016, acc 0.890625\n",
      "2018-05-04T19:25:28.465184: step 18981, loss 0.193784, acc 0.921875\n",
      "2018-05-04T19:25:29.418661: step 18982, loss 0.214669, acc 0.859375\n",
      "2018-05-04T19:25:30.443561: step 18983, loss 0.18254, acc 0.921875\n",
      "2018-05-04T19:25:31.382397: step 18984, loss 0.294788, acc 0.859375\n",
      "2018-05-04T19:25:32.338445: step 18985, loss 0.506138, acc 0.8125\n",
      "2018-05-04T19:25:33.346764: step 18986, loss 0.328603, acc 0.875\n",
      "2018-05-04T19:25:34.367808: step 18987, loss 0.313841, acc 0.90625\n",
      "2018-05-04T19:25:35.395970: step 18988, loss 0.247173, acc 0.875\n",
      "2018-05-04T19:25:36.501660: step 18989, loss 0.177667, acc 0.953125\n",
      "2018-05-04T19:25:37.486235: step 18990, loss 0.289608, acc 0.84375\n",
      "2018-05-04T19:25:38.443453: step 18991, loss 0.281932, acc 0.9375\n",
      "2018-05-04T19:25:39.383165: step 18992, loss 0.299556, acc 0.859375\n",
      "2018-05-04T19:25:40.343955: step 18993, loss 0.310776, acc 0.875\n",
      "2018-05-04T19:25:41.316163: step 18994, loss 0.158171, acc 0.921875\n",
      "2018-05-04T19:25:42.252800: step 18995, loss 0.243148, acc 0.90625\n",
      "2018-05-04T19:25:43.196350: step 18996, loss 0.252399, acc 0.90625\n",
      "2018-05-04T19:25:44.218559: step 18997, loss 0.403117, acc 0.828125\n",
      "2018-05-04T19:25:45.251517: step 18998, loss 0.248376, acc 0.90625\n",
      "2018-05-04T19:25:46.199991: step 18999, loss 0.264575, acc 0.90625\n",
      "2018-05-04T19:25:47.179706: step 19000, loss 0.281248, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T19:25:49.322110: step 19000, loss 0.223119, acc 0.918\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-19000\n",
      "\n",
      "2018-05-04T19:25:50.400730: step 19001, loss 0.331819, acc 0.875\n",
      "2018-05-04T19:25:51.438343: step 19002, loss 0.329999, acc 0.875\n",
      "2018-05-04T19:25:52.412640: step 19003, loss 0.204242, acc 0.921875\n",
      "2018-05-04T19:25:53.384221: step 19004, loss 0.319299, acc 0.890625\n",
      "2018-05-04T19:25:54.369254: step 19005, loss 0.309256, acc 0.875\n",
      "2018-05-04T19:25:55.370525: step 19006, loss 0.344495, acc 0.90625\n",
      "2018-05-04T19:25:56.323448: step 19007, loss 0.276908, acc 0.890625\n",
      "2018-05-04T19:25:57.259641: step 19008, loss 0.256792, acc 0.90625\n",
      "2018-05-04T19:25:58.195913: step 19009, loss 0.311267, acc 0.90625\n",
      "2018-05-04T19:25:59.140987: step 19010, loss 0.239327, acc 0.890625\n",
      "2018-05-04T19:26:00.102552: step 19011, loss 0.193498, acc 0.96875\n",
      "2018-05-04T19:26:01.083751: step 19012, loss 0.191694, acc 0.921875\n",
      "2018-05-04T19:26:02.037009: step 19013, loss 0.169899, acc 0.9375\n",
      "2018-05-04T19:26:02.986265: step 19014, loss 0.323519, acc 0.890625\n",
      "2018-05-04T19:26:03.957997: step 19015, loss 0.197537, acc 0.9375\n",
      "2018-05-04T19:26:04.888338: step 19016, loss 0.195403, acc 0.953125\n",
      "2018-05-04T19:26:05.826132: step 19017, loss 0.191693, acc 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T19:26:06.800574: step 19018, loss 0.367814, acc 0.859375\n",
      "2018-05-04T19:26:07.797864: step 19019, loss 0.144423, acc 0.984375\n",
      "2018-05-04T19:26:08.768676: step 19020, loss 0.203583, acc 0.921875\n",
      "2018-05-04T19:26:09.858877: step 19021, loss 0.262797, acc 0.9375\n",
      "2018-05-04T19:26:10.905390: step 19022, loss 0.361621, acc 0.84375\n",
      "2018-05-04T19:26:11.867308: step 19023, loss 0.188539, acc 0.9375\n",
      "2018-05-04T19:26:12.819736: step 19024, loss 0.151073, acc 0.953125\n",
      "2018-05-04T19:26:13.767145: step 19025, loss 0.318066, acc 0.875\n",
      "2018-05-04T19:26:14.727609: step 19026, loss 0.18826, acc 0.9375\n",
      "2018-05-04T19:26:15.687622: step 19027, loss 0.279071, acc 0.890625\n",
      "2018-05-04T19:26:16.646422: step 19028, loss 0.2747, acc 0.921875\n",
      "2018-05-04T19:26:17.603600: step 19029, loss 0.234291, acc 0.9375\n",
      "2018-05-04T19:26:18.556407: step 19030, loss 0.16178, acc 0.953125\n",
      "2018-05-04T19:26:19.509423: step 19031, loss 0.168072, acc 0.9375\n",
      "2018-05-04T19:26:20.452018: step 19032, loss 0.305484, acc 0.921875\n",
      "2018-05-04T19:26:21.452858: step 19033, loss 0.248486, acc 0.9375\n",
      "2018-05-04T19:26:22.398704: step 19034, loss 0.268819, acc 0.875\n",
      "2018-05-04T19:26:23.337780: step 19035, loss 0.189994, acc 0.90625\n",
      "2018-05-04T19:26:24.316039: step 19036, loss 0.184612, acc 0.921875\n",
      "2018-05-04T19:26:25.260070: step 19037, loss 0.204894, acc 0.921875\n",
      "2018-05-04T19:26:26.187562: step 19038, loss 0.25472, acc 0.84375\n",
      "2018-05-04T19:26:27.120322: step 19039, loss 0.307892, acc 0.875\n",
      "2018-05-04T19:26:28.170648: step 19040, loss 0.250234, acc 0.890625\n",
      "2018-05-04T19:26:29.183871: step 19041, loss 0.202008, acc 0.90625\n",
      "2018-05-04T19:26:30.129055: step 19042, loss 0.33656, acc 0.890625\n",
      "2018-05-04T19:26:31.099658: step 19043, loss 0.399947, acc 0.859375\n",
      "2018-05-04T19:26:32.055947: step 19044, loss 0.240312, acc 0.90625\n",
      "2018-05-04T19:26:33.037034: step 19045, loss 0.349324, acc 0.859375\n",
      "2018-05-04T19:26:34.018161: step 19046, loss 0.214181, acc 0.890625\n",
      "2018-05-04T19:26:34.957693: step 19047, loss 0.312134, acc 0.921875\n",
      "2018-05-04T19:26:35.923122: step 19048, loss 0.498708, acc 0.765625\n",
      "2018-05-04T19:26:36.881195: step 19049, loss 0.221233, acc 0.921875\n",
      "2018-05-04T19:26:37.822281: step 19050, loss 0.300271, acc 0.890625\n",
      "2018-05-04T19:26:38.745110: step 19051, loss 0.174111, acc 0.9375\n",
      "2018-05-04T19:26:39.666380: step 19052, loss 0.159934, acc 0.90625\n",
      "2018-05-04T19:26:40.609817: step 19053, loss 0.172612, acc 0.921875\n",
      "2018-05-04T19:26:41.595864: step 19054, loss 0.101093, acc 0.96875\n",
      "2018-05-04T19:26:42.692317: step 19055, loss 0.151374, acc 0.96875\n",
      "2018-05-04T19:26:43.701389: step 19056, loss 0.318028, acc 0.828125\n",
      "2018-05-04T19:26:44.777703: step 19057, loss 0.225096, acc 0.890625\n",
      "2018-05-04T19:26:45.838303: step 19058, loss 0.41712, acc 0.8125\n",
      "2018-05-04T19:26:46.882220: step 19059, loss 0.179212, acc 0.90625\n",
      "2018-05-04T19:26:47.873067: step 19060, loss 0.339869, acc 0.921875\n",
      "2018-05-04T19:26:48.842235: step 19061, loss 0.216666, acc 0.90625\n",
      "2018-05-04T19:26:49.867517: step 19062, loss 0.255778, acc 0.90625\n",
      "2018-05-04T19:26:50.936913: step 19063, loss 0.198305, acc 0.921875\n",
      "2018-05-04T19:26:51.998321: step 19064, loss 0.258616, acc 0.90625\n",
      "2018-05-04T19:26:53.028266: step 19065, loss 0.208698, acc 0.90625\n",
      "2018-05-04T19:26:53.969706: step 19066, loss 0.350849, acc 0.875\n",
      "2018-05-04T19:26:54.895373: step 19067, loss 0.248532, acc 0.921875\n",
      "2018-05-04T19:26:55.911204: step 19068, loss 0.317987, acc 0.875\n",
      "2018-05-04T19:26:56.841937: step 19069, loss 0.231362, acc 0.90625\n",
      "2018-05-04T19:26:57.777632: step 19070, loss 0.199228, acc 0.921875\n",
      "2018-05-04T19:26:58.744569: step 19071, loss 0.247431, acc 0.921875\n",
      "2018-05-04T19:26:59.698952: step 19072, loss 0.205347, acc 0.9375\n",
      "2018-05-04T19:27:00.693363: step 19073, loss 0.396393, acc 0.890625\n",
      "2018-05-04T19:27:01.626936: step 19074, loss 0.296629, acc 0.921875\n",
      "2018-05-04T19:27:02.564596: step 19075, loss 0.157662, acc 0.953125\n",
      "2018-05-04T19:27:03.520726: step 19076, loss 0.189233, acc 0.9375\n",
      "2018-05-04T19:27:04.490480: step 19077, loss 0.286912, acc 0.90625\n",
      "2018-05-04T19:27:05.441070: step 19078, loss 0.210348, acc 0.90625\n",
      "2018-05-04T19:27:06.366079: step 19079, loss 0.364471, acc 0.8125\n",
      "2018-05-04T19:27:07.388752: step 19080, loss 0.252568, acc 0.890625\n",
      "2018-05-04T19:27:08.313918: step 19081, loss 0.249963, acc 0.921875\n",
      "2018-05-04T19:27:09.257162: step 19082, loss 0.255995, acc 0.921875\n",
      "2018-05-04T19:27:10.227704: step 19083, loss 0.263461, acc 0.859375\n",
      "2018-05-04T19:27:11.236933: step 19084, loss 0.245482, acc 0.90625\n",
      "2018-05-04T19:27:12.234624: step 19085, loss 0.366953, acc 0.875\n",
      "2018-05-04T19:27:13.158093: step 19086, loss 0.191925, acc 0.9375\n",
      "2018-05-04T19:27:14.099129: step 19087, loss 0.281059, acc 0.890625\n",
      "2018-05-04T19:27:15.037735: step 19088, loss 0.296316, acc 0.875\n",
      "2018-05-04T19:27:15.988188: step 19089, loss 0.236445, acc 0.875\n",
      "2018-05-04T19:27:17.019085: step 19090, loss 0.305777, acc 0.890625\n",
      "2018-05-04T19:27:18.053396: step 19091, loss 0.250662, acc 0.890625\n",
      "2018-05-04T19:27:18.980248: step 19092, loss 0.302381, acc 0.875\n",
      "2018-05-04T19:27:19.915844: step 19093, loss 0.199773, acc 0.9375\n",
      "2018-05-04T19:27:20.867071: step 19094, loss 0.220008, acc 0.875\n",
      "2018-05-04T19:27:21.900051: step 19095, loss 0.412645, acc 0.84375\n",
      "2018-05-04T19:27:22.844073: step 19096, loss 0.203027, acc 0.921875\n",
      "2018-05-04T19:27:23.802645: step 19097, loss 0.18472, acc 0.90625\n",
      "2018-05-04T19:27:24.736912: step 19098, loss 0.286442, acc 0.890625\n",
      "2018-05-04T19:27:25.758559: step 19099, loss 0.275452, acc 0.875\n",
      "2018-05-04T19:27:26.690466: step 19100, loss 0.171461, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T19:27:29.832707: step 19100, loss 0.217778, acc 0.918\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-19100\n",
      "\n",
      "2018-05-04T19:27:30.888894: step 19101, loss 0.212251, acc 0.90625\n",
      "2018-05-04T19:27:31.874429: step 19102, loss 0.216624, acc 0.9375\n",
      "2018-05-04T19:27:32.895991: step 19103, loss 0.211785, acc 0.9375\n",
      "2018-05-04T19:27:33.944142: step 19104, loss 0.235877, acc 0.90625\n",
      "2018-05-04T19:27:35.084231: step 19105, loss 0.320145, acc 0.890625\n",
      "2018-05-04T19:27:36.140225: step 19106, loss 0.271242, acc 0.859375\n",
      "2018-05-04T19:27:37.125326: step 19107, loss 0.218759, acc 0.921875\n",
      "2018-05-04T19:27:38.099836: step 19108, loss 0.241999, acc 0.890625\n",
      "2018-05-04T19:27:39.052218: step 19109, loss 0.237329, acc 0.953125\n",
      "2018-05-04T19:27:40.011319: step 19110, loss 0.333644, acc 0.859375\n",
      "2018-05-04T19:27:41.066770: step 19111, loss 0.193182, acc 0.9375\n",
      "2018-05-04T19:27:42.105835: step 19112, loss 0.29112, acc 0.875\n",
      "2018-05-04T19:27:43.064875: step 19113, loss 0.22276, acc 0.921875\n",
      "2018-05-04T19:27:44.013178: step 19114, loss 0.201932, acc 0.9375\n",
      "2018-05-04T19:27:45.058838: step 19115, loss 0.240362, acc 0.875\n",
      "2018-05-04T19:27:46.030351: step 19116, loss 0.216042, acc 0.90625\n",
      "2018-05-04T19:27:47.007671: step 19117, loss 0.124548, acc 0.953125\n",
      "2018-05-04T19:27:47.965168: step 19118, loss 0.281542, acc 0.84375\n",
      "2018-05-04T19:27:48.910526: step 19119, loss 0.204497, acc 0.90625\n",
      "2018-05-04T19:27:49.911729: step 19120, loss 0.231101, acc 0.90625\n",
      "2018-05-04T19:27:50.893753: step 19121, loss 0.34931, acc 0.859375\n",
      "2018-05-04T19:27:51.921788: step 19122, loss 0.222658, acc 0.9375\n",
      "2018-05-04T19:27:52.890947: step 19123, loss 0.195757, acc 0.890625\n",
      "2018-05-04T19:27:53.895032: step 19124, loss 0.244264, acc 0.9375\n",
      "2018-05-04T19:27:54.983479: step 19125, loss 0.213298, acc 0.90625\n",
      "2018-05-04T19:27:56.037740: step 19126, loss 0.241475, acc 0.84375\n",
      "2018-05-04T19:27:56.980766: step 19127, loss 0.258948, acc 0.859375\n",
      "2018-05-04T19:27:57.948204: step 19128, loss 0.120843, acc 0.953125\n",
      "2018-05-04T19:27:58.913879: step 19129, loss 0.21179, acc 0.875\n",
      "2018-05-04T19:27:59.877260: step 19130, loss 0.28104, acc 0.859375\n",
      "2018-05-04T19:28:00.854415: step 19131, loss 0.174825, acc 0.9375\n",
      "2018-05-04T19:28:01.842077: step 19132, loss 0.381471, acc 0.890625\n",
      "2018-05-04T19:28:02.800000: step 19133, loss 0.199938, acc 0.90625\n",
      "2018-05-04T19:28:03.792651: step 19134, loss 0.280835, acc 0.875\n",
      "2018-05-04T19:28:04.855314: step 19135, loss 0.191969, acc 0.953125\n",
      "2018-05-04T19:28:05.900509: step 19136, loss 0.204307, acc 0.921875\n",
      "2018-05-04T19:28:06.866975: step 19137, loss 0.28519, acc 0.859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T19:28:07.865158: step 19138, loss 0.267655, acc 0.875\n",
      "2018-05-04T19:28:08.818242: step 19139, loss 0.160564, acc 0.921875\n",
      "2018-05-04T19:28:09.778866: step 19140, loss 0.191746, acc 0.9375\n",
      "2018-05-04T19:28:10.739197: step 19141, loss 0.275043, acc 0.921875\n",
      "2018-05-04T19:28:11.696085: step 19142, loss 0.216184, acc 0.875\n",
      "2018-05-04T19:28:12.667905: step 19143, loss 0.210835, acc 0.890625\n",
      "2018-05-04T19:28:13.674159: step 19144, loss 0.381813, acc 0.875\n",
      "2018-05-04T19:28:14.690783: step 19145, loss 0.104802, acc 0.96875\n",
      "2018-05-04T19:28:15.667196: step 19146, loss 0.245802, acc 0.9375\n",
      "2018-05-04T19:28:16.663176: step 19147, loss 0.181237, acc 0.9375\n",
      "2018-05-04T19:28:17.667834: step 19148, loss 0.310038, acc 0.875\n",
      "2018-05-04T19:28:18.633066: step 19149, loss 0.226114, acc 0.875\n",
      "2018-05-04T19:28:19.593773: step 19150, loss 0.371983, acc 0.890625\n",
      "2018-05-04T19:28:20.560286: step 19151, loss 0.264387, acc 0.90625\n",
      "2018-05-04T19:28:21.522731: step 19152, loss 0.188691, acc 0.921875\n",
      "2018-05-04T19:28:22.531324: step 19153, loss 0.289869, acc 0.890625\n",
      "2018-05-04T19:28:23.523052: step 19154, loss 0.137056, acc 0.9375\n",
      "2018-05-04T19:28:24.452658: step 19155, loss 0.263478, acc 0.90625\n",
      "2018-05-04T19:28:25.507994: step 19156, loss 0.227546, acc 0.921875\n",
      "2018-05-04T19:28:26.565155: step 19157, loss 0.258551, acc 0.890625\n",
      "2018-05-04T19:28:27.624938: step 19158, loss 0.262975, acc 0.9375\n",
      "2018-05-04T19:28:28.651787: step 19159, loss 0.221039, acc 0.859375\n",
      "2018-05-04T19:28:29.588367: step 19160, loss 0.235275, acc 0.890625\n",
      "2018-05-04T19:28:30.628275: step 19161, loss 0.139889, acc 0.953125\n",
      "2018-05-04T19:28:31.580351: step 19162, loss 0.306435, acc 0.890625\n",
      "2018-05-04T19:28:32.549249: step 19163, loss 0.248363, acc 0.921875\n",
      "2018-05-04T19:28:33.545273: step 19164, loss 0.189924, acc 0.9375\n",
      "2018-05-04T19:28:34.552644: step 19165, loss 0.293336, acc 0.859375\n",
      "2018-05-04T19:28:35.641973: step 19166, loss 0.234802, acc 0.921875\n",
      "2018-05-04T19:28:36.652155: step 19167, loss 0.217448, acc 0.921875\n",
      "2018-05-04T19:28:37.628420: step 19168, loss 0.173322, acc 0.9375\n",
      "2018-05-04T19:28:38.604379: step 19169, loss 0.194062, acc 0.890625\n",
      "2018-05-04T19:28:39.588907: step 19170, loss 0.212598, acc 0.90625\n",
      "2018-05-04T19:28:40.563713: step 19171, loss 0.286399, acc 0.921875\n",
      "2018-05-04T19:28:41.518110: step 19172, loss 0.220228, acc 0.921875\n",
      "2018-05-04T19:28:42.487494: step 19173, loss 0.238328, acc 0.921875\n",
      "2018-05-04T19:28:43.447862: step 19174, loss 0.333962, acc 0.828125\n",
      "2018-05-04T19:28:44.414564: step 19175, loss 0.284867, acc 0.90625\n",
      "2018-05-04T19:28:45.362398: step 19176, loss 0.191657, acc 0.921875\n",
      "2018-05-04T19:28:46.345741: step 19177, loss 0.196387, acc 0.921875\n",
      "2018-05-04T19:28:47.339280: step 19178, loss 0.157813, acc 0.9375\n",
      "2018-05-04T19:28:48.320650: step 19179, loss 0.14333, acc 0.953125\n",
      "2018-05-04T19:28:49.269287: step 19180, loss 0.288866, acc 0.890625\n",
      "2018-05-04T19:28:50.219238: step 19181, loss 0.226572, acc 0.921875\n",
      "2018-05-04T19:28:51.163666: step 19182, loss 0.273386, acc 0.890625\n",
      "2018-05-04T19:28:52.119958: step 19183, loss 0.181448, acc 0.921875\n",
      "2018-05-04T19:28:53.094431: step 19184, loss 0.315656, acc 0.921875\n",
      "2018-05-04T19:28:54.070288: step 19185, loss 0.161641, acc 0.953125\n",
      "2018-05-04T19:28:55.049752: step 19186, loss 0.212644, acc 0.921875\n",
      "2018-05-04T19:28:56.034366: step 19187, loss 0.260643, acc 0.90625\n",
      "2018-05-04T19:28:57.014834: step 19188, loss 0.332616, acc 0.84375\n",
      "2018-05-04T19:28:57.976216: step 19189, loss 0.278883, acc 0.921875\n",
      "2018-05-04T19:28:58.921180: step 19190, loss 0.1516, acc 0.953125\n",
      "2018-05-04T19:28:59.873349: step 19191, loss 0.446901, acc 0.828125\n",
      "2018-05-04T19:29:00.830201: step 19192, loss 0.346258, acc 0.859375\n",
      "2018-05-04T19:29:01.819635: step 19193, loss 0.268288, acc 0.90625\n",
      "2018-05-04T19:29:02.844989: step 19194, loss 0.221822, acc 0.90625\n",
      "2018-05-04T19:29:03.845140: step 19195, loss 0.224118, acc 0.921875\n",
      "2018-05-04T19:29:04.822898: step 19196, loss 0.193821, acc 0.921875\n",
      "2018-05-04T19:29:05.770566: step 19197, loss 0.383602, acc 0.796875\n",
      "2018-05-04T19:29:06.726051: step 19198, loss 0.260512, acc 0.921875\n",
      "2018-05-04T19:29:07.686239: step 19199, loss 0.16201, acc 0.921875\n",
      "2018-05-04T19:29:08.642396: step 19200, loss 0.353542, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T19:29:11.017138: step 19200, loss 0.235021, acc 0.922\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-19200\n",
      "\n",
      "2018-05-04T19:29:12.091119: step 19201, loss 0.280385, acc 0.84375\n",
      "2018-05-04T19:29:13.110543: step 19202, loss 0.254343, acc 0.90625\n",
      "2018-05-04T19:29:14.130497: step 19203, loss 0.186338, acc 0.890625\n",
      "2018-05-04T19:29:15.141956: step 19204, loss 0.140312, acc 0.953125\n",
      "2018-05-04T19:29:16.222196: step 19205, loss 0.31231, acc 0.828125\n",
      "2018-05-04T19:29:17.235066: step 19206, loss 0.129552, acc 0.9375\n",
      "2018-05-04T19:29:18.187877: step 19207, loss 0.301942, acc 0.90625\n",
      "2018-05-04T19:29:19.189242: step 19208, loss 0.194734, acc 0.9375\n",
      "2018-05-04T19:29:20.171501: step 19209, loss 0.22921, acc 0.9375\n",
      "2018-05-04T19:29:21.217391: step 19210, loss 0.392148, acc 0.84375\n",
      "2018-05-04T19:29:22.198401: step 19211, loss 0.239419, acc 0.875\n",
      "2018-05-04T19:29:23.189232: step 19212, loss 0.397454, acc 0.890625\n",
      "2018-05-04T19:29:24.265532: step 19213, loss 0.42412, acc 0.8125\n",
      "2018-05-04T19:29:25.327361: step 19214, loss 0.175602, acc 0.921875\n",
      "2018-05-04T19:29:26.301223: step 19215, loss 0.335369, acc 0.875\n",
      "2018-05-04T19:29:27.284969: step 19216, loss 0.171114, acc 0.921875\n",
      "2018-05-04T19:29:28.265669: step 19217, loss 0.333721, acc 0.828125\n",
      "2018-05-04T19:29:29.226588: step 19218, loss 0.269687, acc 0.90625\n",
      "2018-05-04T19:29:30.194912: step 19219, loss 0.329274, acc 0.84375\n",
      "2018-05-04T19:29:31.200066: step 19220, loss 0.321312, acc 0.875\n",
      "2018-05-04T19:29:32.186710: step 19221, loss 0.348896, acc 0.890625\n",
      "2018-05-04T19:29:33.135191: step 19222, loss 0.344825, acc 0.8125\n",
      "2018-05-04T19:29:34.204323: step 19223, loss 0.271659, acc 0.921875\n",
      "2018-05-04T19:29:35.258587: step 19224, loss 0.427106, acc 0.84375\n",
      "2018-05-04T19:29:36.236910: step 19225, loss 0.332669, acc 0.859375\n",
      "2018-05-04T19:29:37.197984: step 19226, loss 0.260218, acc 0.875\n",
      "2018-05-04T19:29:38.180632: step 19227, loss 0.167365, acc 0.953125\n",
      "2018-05-04T19:29:39.162384: step 19228, loss 0.306051, acc 0.859375\n",
      "2018-05-04T19:29:40.146955: step 19229, loss 0.295734, acc 0.921875\n",
      "2018-05-04T19:29:41.129369: step 19230, loss 0.26109, acc 0.859375\n",
      "2018-05-04T19:29:42.089228: step 19231, loss 0.241061, acc 0.9375\n",
      "2018-05-04T19:29:43.124718: step 19232, loss 0.36572, acc 0.859375\n",
      "2018-05-04T19:29:44.110687: step 19233, loss 0.264896, acc 0.921875\n",
      "2018-05-04T19:29:45.062208: step 19234, loss 0.265579, acc 0.90625\n",
      "2018-05-04T19:29:46.033166: step 19235, loss 0.276296, acc 0.890625\n",
      "2018-05-04T19:29:47.077976: step 19236, loss 0.251176, acc 0.890625\n",
      "2018-05-04T19:29:48.050507: step 19237, loss 0.297923, acc 0.90625\n",
      "2018-05-04T19:29:49.098488: step 19238, loss 0.23025, acc 0.890625\n",
      "2018-05-04T19:29:50.045336: step 19239, loss 0.167998, acc 0.9375\n",
      "2018-05-04T19:29:51.008954: step 19240, loss 0.254301, acc 0.921875\n",
      "2018-05-04T19:29:52.056538: step 19241, loss 0.220218, acc 0.953125\n",
      "2018-05-04T19:29:53.044700: step 19242, loss 0.237962, acc 0.890625\n",
      "2018-05-04T19:29:54.082903: step 19243, loss 0.191025, acc 0.9375\n",
      "2018-05-04T19:29:55.029954: step 19244, loss 0.325099, acc 0.859375\n",
      "2018-05-04T19:29:55.997187: step 19245, loss 0.208321, acc 0.9375\n",
      "2018-05-04T19:29:56.973008: step 19246, loss 0.277952, acc 0.890625\n",
      "2018-05-04T19:29:57.939924: step 19247, loss 0.220058, acc 0.90625\n",
      "2018-05-04T19:29:58.946552: step 19248, loss 0.219546, acc 0.90625\n",
      "2018-05-04T19:29:59.979435: step 19249, loss 0.208719, acc 0.890625\n",
      "2018-05-04T19:30:00.963130: step 19250, loss 0.269235, acc 0.875\n",
      "2018-05-04T19:30:01.931191: step 19251, loss 0.20604, acc 0.90625\n",
      "2018-05-04T19:30:02.907557: step 19252, loss 0.273991, acc 0.890625\n",
      "2018-05-04T19:30:03.897160: step 19253, loss 0.282677, acc 0.875\n",
      "2018-05-04T19:30:04.873006: step 19254, loss 0.299614, acc 0.875\n",
      "2018-05-04T19:30:05.941897: step 19255, loss 0.205873, acc 0.921875\n",
      "2018-05-04T19:30:06.895285: step 19256, loss 0.300328, acc 0.828125\n",
      "2018-05-04T19:30:07.865118: step 19257, loss 0.272278, acc 0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T19:30:08.817140: step 19258, loss 0.274802, acc 0.875\n",
      "2018-05-04T19:30:09.777723: step 19259, loss 0.1417, acc 0.9375\n",
      "2018-05-04T19:30:10.749786: step 19260, loss 0.395444, acc 0.8125\n",
      "2018-05-04T19:30:11.736522: step 19261, loss 0.326294, acc 0.875\n",
      "2018-05-04T19:30:12.729481: step 19262, loss 0.145857, acc 0.953125\n",
      "2018-05-04T19:30:13.735208: step 19263, loss 0.198094, acc 0.921875\n",
      "2018-05-04T19:30:14.686911: step 19264, loss 0.237643, acc 0.9375\n",
      "2018-05-04T19:30:15.663198: step 19265, loss 0.156577, acc 0.953125\n",
      "2018-05-04T19:30:16.623548: step 19266, loss 0.1235, acc 0.953125\n",
      "2018-05-04T19:30:17.612530: step 19267, loss 0.177508, acc 0.90625\n",
      "2018-05-04T19:30:18.677945: step 19268, loss 0.10954, acc 0.96875\n",
      "2018-05-04T19:30:19.641055: step 19269, loss 0.315219, acc 0.84375\n",
      "2018-05-04T19:30:20.588547: step 19270, loss 0.226437, acc 0.921875\n",
      "2018-05-04T19:30:21.549965: step 19271, loss 0.24244, acc 0.859375\n",
      "2018-05-04T19:30:22.532912: step 19272, loss 0.187094, acc 0.921875\n",
      "2018-05-04T19:30:23.513229: step 19273, loss 0.432418, acc 0.859375\n",
      "2018-05-04T19:30:24.480358: step 19274, loss 0.457576, acc 0.828125\n",
      "2018-05-04T19:30:25.426537: step 19275, loss 0.221707, acc 0.890625\n",
      "2018-05-04T19:30:26.376692: step 19276, loss 0.256226, acc 0.90625\n",
      "2018-05-04T19:30:27.336563: step 19277, loss 0.374253, acc 0.859375\n",
      "2018-05-04T19:30:28.288900: step 19278, loss 0.229012, acc 0.90625\n",
      "2018-05-04T19:30:29.287301: step 19279, loss 0.339009, acc 0.875\n",
      "2018-05-04T19:30:30.255352: step 19280, loss 0.203702, acc 0.921875\n",
      "2018-05-04T19:30:31.210474: step 19281, loss 0.335553, acc 0.84375\n",
      "2018-05-04T19:30:32.267015: step 19282, loss 0.395601, acc 0.84375\n",
      "2018-05-04T19:30:33.241240: step 19283, loss 0.121078, acc 0.96875\n",
      "2018-05-04T19:30:34.213191: step 19284, loss 0.289351, acc 0.890625\n",
      "2018-05-04T19:30:35.161878: step 19285, loss 0.257685, acc 0.921875\n",
      "2018-05-04T19:30:36.103095: step 19286, loss 0.245629, acc 0.859375\n",
      "2018-05-04T19:30:37.050103: step 19287, loss 0.299573, acc 0.859375\n",
      "2018-05-04T19:30:38.023818: step 19288, loss 0.25592, acc 0.875\n",
      "2018-05-04T19:30:38.982852: step 19289, loss 0.278156, acc 0.875\n",
      "2018-05-04T19:30:39.950865: step 19290, loss 0.281561, acc 0.859375\n",
      "2018-05-04T19:30:40.887536: step 19291, loss 0.335612, acc 0.84375\n",
      "2018-05-04T19:30:41.929279: step 19292, loss 0.256144, acc 0.90625\n",
      "2018-05-04T19:30:42.888671: step 19293, loss 0.416118, acc 0.84375\n",
      "2018-05-04T19:30:43.852179: step 19294, loss 0.345849, acc 0.84375\n",
      "2018-05-04T19:30:44.795148: step 19295, loss 0.273403, acc 0.84375\n",
      "2018-05-04T19:30:45.751212: step 19296, loss 0.21691, acc 0.875\n",
      "2018-05-04T19:30:46.708691: step 19297, loss 0.168442, acc 0.953125\n",
      "2018-05-04T19:30:47.652158: step 19298, loss 0.265098, acc 0.921875\n",
      "2018-05-04T19:30:48.617376: step 19299, loss 0.209951, acc 0.9375\n",
      "2018-05-04T19:30:49.568934: step 19300, loss 0.272996, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T19:30:51.665519: step 19300, loss 0.271535, acc 0.9\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-19300\n",
      "\n",
      "2018-05-04T19:30:52.795331: step 19301, loss 0.23804, acc 0.890625\n",
      "2018-05-04T19:30:53.751660: step 19302, loss 0.357699, acc 0.828125\n",
      "2018-05-04T19:30:54.699877: step 19303, loss 0.268168, acc 0.90625\n",
      "2018-05-04T19:30:55.646627: step 19304, loss 0.187953, acc 0.921875\n",
      "2018-05-04T19:30:56.601875: step 19305, loss 0.303173, acc 0.84375\n",
      "2018-05-04T19:30:57.555709: step 19306, loss 0.268338, acc 0.921875\n",
      "2018-05-04T19:30:58.521781: step 19307, loss 0.146158, acc 0.953125\n",
      "2018-05-04T19:30:59.482149: step 19308, loss 0.24405, acc 0.890625\n",
      "2018-05-04T19:31:00.446402: step 19309, loss 0.318746, acc 0.875\n",
      "2018-05-04T19:31:01.416748: step 19310, loss 0.233584, acc 0.890625\n",
      "2018-05-04T19:31:02.402486: step 19311, loss 0.258415, acc 0.890625\n",
      "2018-05-04T19:31:03.349639: step 19312, loss 0.342812, acc 0.890625\n",
      "2018-05-04T19:31:04.323746: step 19313, loss 0.195126, acc 0.9375\n",
      "2018-05-04T19:31:05.284009: step 19314, loss 0.232498, acc 0.90625\n",
      "2018-05-04T19:31:06.342669: step 19315, loss 0.235327, acc 0.875\n",
      "2018-05-04T19:31:07.480352: step 19316, loss 0.127579, acc 0.953125\n",
      "2018-05-04T19:31:08.475554: step 19317, loss 0.227214, acc 0.890625\n",
      "2018-05-04T19:31:09.512355: step 19318, loss 0.191674, acc 0.90625\n",
      "2018-05-04T19:31:10.487735: step 19319, loss 0.219418, acc 0.953125\n",
      "2018-05-04T19:31:11.497017: step 19320, loss 0.244047, acc 0.90625\n",
      "2018-05-04T19:31:12.458227: step 19321, loss 0.23392, acc 0.890625\n",
      "2018-05-04T19:31:13.402314: step 19322, loss 0.246168, acc 0.84375\n",
      "2018-05-04T19:31:14.359706: step 19323, loss 0.124025, acc 0.9375\n",
      "2018-05-04T19:31:15.307614: step 19324, loss 0.194432, acc 0.90625\n",
      "2018-05-04T19:31:16.245235: step 19325, loss 0.228467, acc 0.90625\n",
      "2018-05-04T19:31:17.199117: step 19326, loss 0.21395, acc 0.9375\n",
      "2018-05-04T19:31:18.249963: step 19327, loss 0.288345, acc 0.890625\n",
      "2018-05-04T19:31:19.195770: step 19328, loss 0.229989, acc 0.90625\n",
      "2018-05-04T19:31:20.129109: step 19329, loss 0.294618, acc 0.859375\n",
      "2018-05-04T19:31:21.071387: step 19330, loss 0.204684, acc 0.90625\n",
      "2018-05-04T19:31:22.016640: step 19331, loss 0.209053, acc 0.921875\n",
      "2018-05-04T19:31:22.977116: step 19332, loss 0.23472, acc 0.90625\n",
      "2018-05-04T19:31:23.941475: step 19333, loss 0.409961, acc 0.921875\n",
      "2018-05-04T19:31:24.905168: step 19334, loss 0.195116, acc 0.921875\n",
      "2018-05-04T19:31:25.857120: step 19335, loss 0.245944, acc 0.890625\n",
      "2018-05-04T19:31:26.787360: step 19336, loss 0.265123, acc 0.921875\n",
      "2018-05-04T19:31:27.797626: step 19337, loss 0.231676, acc 0.921875\n",
      "2018-05-04T19:31:28.735739: step 19338, loss 0.273322, acc 0.875\n",
      "2018-05-04T19:31:29.714348: step 19339, loss 0.377085, acc 0.875\n",
      "2018-05-04T19:31:30.679311: step 19340, loss 0.254438, acc 0.921875\n",
      "2018-05-04T19:31:31.646042: step 19341, loss 0.345932, acc 0.8125\n",
      "2018-05-04T19:31:32.627963: step 19342, loss 0.295499, acc 0.828125\n",
      "2018-05-04T19:31:33.639482: step 19343, loss 0.31492, acc 0.84375\n",
      "2018-05-04T19:31:34.658439: step 19344, loss 0.249097, acc 0.875\n",
      "2018-05-04T19:31:35.674551: step 19345, loss 0.273072, acc 0.921875\n",
      "2018-05-04T19:31:36.692458: step 19346, loss 0.260455, acc 0.921875\n",
      "2018-05-04T19:31:37.643898: step 19347, loss 0.218943, acc 0.875\n",
      "2018-05-04T19:31:38.585116: step 19348, loss 0.248968, acc 0.890625\n",
      "2018-05-04T19:31:39.516414: step 19349, loss 0.286874, acc 0.890625\n",
      "2018-05-04T19:31:40.455537: step 19350, loss 0.22986, acc 0.890625\n",
      "2018-05-04T19:31:41.422650: step 19351, loss 0.336253, acc 0.859375\n",
      "2018-05-04T19:31:42.385201: step 19352, loss 0.303043, acc 0.890625\n",
      "2018-05-04T19:31:43.355125: step 19353, loss 0.228633, acc 0.90625\n",
      "2018-05-04T19:31:44.309298: step 19354, loss 0.248624, acc 0.90625\n",
      "2018-05-04T19:31:45.240414: step 19355, loss 0.188956, acc 0.921875\n",
      "2018-05-04T19:31:46.198088: step 19356, loss 0.250035, acc 0.90625\n",
      "2018-05-04T19:31:47.137635: step 19357, loss 0.257514, acc 0.859375\n",
      "2018-05-04T19:31:48.103892: step 19358, loss 0.203585, acc 0.90625\n",
      "2018-05-04T19:31:49.126951: step 19359, loss 0.260393, acc 0.90625\n",
      "2018-05-04T19:31:50.064153: step 19360, loss 0.247199, acc 0.890625\n",
      "2018-05-04T19:31:51.086250: step 19361, loss 0.221182, acc 0.921875\n",
      "2018-05-04T19:31:52.112510: step 19362, loss 0.233071, acc 0.953125\n",
      "2018-05-04T19:31:53.039851: step 19363, loss 0.291036, acc 0.859375\n",
      "2018-05-04T19:31:53.964492: step 19364, loss 0.311463, acc 0.859375\n",
      "2018-05-04T19:31:54.893656: step 19365, loss 0.211095, acc 0.921875\n",
      "2018-05-04T19:31:55.837793: step 19366, loss 0.215278, acc 0.90625\n",
      "2018-05-04T19:31:56.805564: step 19367, loss 0.25136, acc 0.90625\n",
      "2018-05-04T19:31:57.777053: step 19368, loss 0.196284, acc 0.90625\n",
      "2018-05-04T19:31:58.750120: step 19369, loss 0.262696, acc 0.921875\n",
      "2018-05-04T19:31:59.696984: step 19370, loss 0.250737, acc 0.921875\n",
      "2018-05-04T19:32:00.629167: step 19371, loss 0.211832, acc 0.90625\n",
      "2018-05-04T19:32:01.572299: step 19372, loss 0.211556, acc 0.921875\n",
      "2018-05-04T19:32:02.555633: step 19373, loss 0.184862, acc 0.921875\n",
      "2018-05-04T19:32:03.516448: step 19374, loss 0.213357, acc 0.9375\n",
      "2018-05-04T19:32:04.494254: step 19375, loss 0.236151, acc 0.859375\n",
      "2018-05-04T19:32:05.422800: step 19376, loss 0.200973, acc 0.9375\n",
      "2018-05-04T19:32:06.355767: step 19377, loss 0.271763, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T19:32:07.307187: step 19378, loss 0.263271, acc 0.921875\n",
      "2018-05-04T19:32:08.321588: step 19379, loss 0.194475, acc 0.921875\n",
      "2018-05-04T19:32:09.255388: step 19380, loss 0.335239, acc 0.890625\n",
      "2018-05-04T19:32:10.205477: step 19381, loss 0.295678, acc 0.90625\n",
      "2018-05-04T19:32:11.139951: step 19382, loss 0.166045, acc 0.9375\n",
      "2018-05-04T19:32:12.213083: step 19383, loss 0.12507, acc 0.9375\n",
      "2018-05-04T19:32:13.180532: step 19384, loss 0.288355, acc 0.90625\n",
      "2018-05-04T19:32:14.140220: step 19385, loss 0.131257, acc 0.921875\n",
      "2018-05-04T19:32:15.086352: step 19386, loss 0.441064, acc 0.890625\n",
      "2018-05-04T19:32:16.013053: step 19387, loss 0.31123, acc 0.890625\n",
      "2018-05-04T19:32:16.945347: step 19388, loss 0.168635, acc 0.921875\n",
      "2018-05-04T19:32:17.904483: step 19389, loss 0.146402, acc 0.9375\n",
      "2018-05-04T19:32:18.856134: step 19390, loss 0.302893, acc 0.875\n",
      "2018-05-04T19:32:19.817387: step 19391, loss 0.247699, acc 0.859375\n",
      "2018-05-04T19:32:20.850526: step 19392, loss 0.341583, acc 0.890625\n",
      "2018-05-04T19:32:21.910118: step 19393, loss 0.270383, acc 0.875\n",
      "2018-05-04T19:32:22.897417: step 19394, loss 0.238321, acc 0.90625\n",
      "2018-05-04T19:32:23.921929: step 19395, loss 0.186238, acc 0.921875\n",
      "2018-05-04T19:32:24.864608: step 19396, loss 0.4038, acc 0.796875\n",
      "2018-05-04T19:32:25.790677: step 19397, loss 0.191597, acc 0.90625\n",
      "2018-05-04T19:32:26.810280: step 19398, loss 0.339825, acc 0.90625\n",
      "2018-05-04T19:32:27.730103: step 19399, loss 0.212282, acc 0.890625\n",
      "2018-05-04T19:32:28.667864: step 19400, loss 0.291813, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T19:32:31.492994: step 19400, loss 0.22686, acc 0.932\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-19400\n",
      "\n",
      "2018-05-04T19:32:32.641929: step 19401, loss 0.112455, acc 0.96875\n",
      "2018-05-04T19:32:33.648546: step 19402, loss 0.248956, acc 0.890625\n",
      "2018-05-04T19:32:34.659495: step 19403, loss 0.391981, acc 0.890625\n",
      "2018-05-04T19:32:35.740066: step 19404, loss 0.197874, acc 0.890625\n",
      "2018-05-04T19:32:36.797943: step 19405, loss 0.231291, acc 0.9375\n",
      "2018-05-04T19:32:37.869932: step 19406, loss 0.308729, acc 0.890625\n",
      "2018-05-04T19:32:38.908481: step 19407, loss 0.261426, acc 0.9375\n",
      "2018-05-04T19:32:39.891471: step 19408, loss 0.216634, acc 0.90625\n",
      "2018-05-04T19:32:40.917563: step 19409, loss 0.231273, acc 0.921875\n",
      "2018-05-04T19:32:41.968258: step 19410, loss 0.205074, acc 0.90625\n",
      "2018-05-04T19:32:42.942293: step 19411, loss 0.0959074, acc 0.96875\n",
      "2018-05-04T19:32:43.903174: step 19412, loss 0.233204, acc 0.90625\n",
      "2018-05-04T19:32:44.887614: step 19413, loss 0.174151, acc 0.9375\n",
      "2018-05-04T19:32:45.882098: step 19414, loss 0.261483, acc 0.828125\n",
      "2018-05-04T19:32:46.885630: step 19415, loss 0.235282, acc 0.890625\n",
      "2018-05-04T19:32:47.875450: step 19416, loss 0.279984, acc 0.90625\n",
      "2018-05-04T19:32:48.860234: step 19417, loss 0.223975, acc 0.921875\n",
      "2018-05-04T19:32:49.818790: step 19418, loss 0.263368, acc 0.875\n",
      "2018-05-04T19:32:50.809808: step 19419, loss 0.374412, acc 0.8125\n",
      "2018-05-04T19:32:51.805646: step 19420, loss 0.171896, acc 0.921875\n",
      "2018-05-04T19:32:52.834044: step 19421, loss 0.210503, acc 0.90625\n",
      "2018-05-04T19:32:53.770065: step 19422, loss 0.202153, acc 0.953125\n",
      "2018-05-04T19:32:54.740258: step 19423, loss 0.240072, acc 0.921875\n",
      "2018-05-04T19:32:55.822584: step 19424, loss 0.222982, acc 0.859375\n",
      "2018-05-04T19:32:56.789067: step 19425, loss 0.274183, acc 0.890625\n",
      "2018-05-04T19:32:57.793303: step 19426, loss 0.388903, acc 0.8125\n",
      "2018-05-04T19:32:58.767081: step 19427, loss 0.183431, acc 0.90625\n",
      "2018-05-04T19:32:59.706663: step 19428, loss 0.31607, acc 0.859375\n",
      "2018-05-04T19:33:00.648901: step 19429, loss 0.259243, acc 0.875\n",
      "2018-05-04T19:33:01.628057: step 19430, loss 0.244034, acc 0.921875\n",
      "2018-05-04T19:33:02.604808: step 19431, loss 0.0938378, acc 0.984375\n",
      "2018-05-04T19:33:03.575454: step 19432, loss 0.234912, acc 0.90625\n",
      "2018-05-04T19:33:04.643810: step 19433, loss 0.232205, acc 0.890625\n",
      "2018-05-04T19:33:05.600660: step 19434, loss 0.261123, acc 0.921875\n",
      "2018-05-04T19:33:06.573584: step 19435, loss 0.328833, acc 0.859375\n",
      "2018-05-04T19:33:07.551721: step 19436, loss 0.272364, acc 0.859375\n",
      "2018-05-04T19:33:08.512089: step 19437, loss 0.291584, acc 0.90625\n",
      "2018-05-04T19:33:09.471732: step 19438, loss 0.174148, acc 0.921875\n",
      "2018-05-04T19:33:10.468679: step 19439, loss 0.177094, acc 0.9375\n",
      "2018-05-04T19:33:11.462285: step 19440, loss 0.399242, acc 0.84375\n",
      "2018-05-04T19:33:12.423833: step 19441, loss 0.365541, acc 0.859375\n",
      "2018-05-04T19:33:13.373579: step 19442, loss 0.253439, acc 0.890625\n",
      "2018-05-04T19:33:14.418861: step 19443, loss 0.238637, acc 0.890625\n",
      "2018-05-04T19:33:15.448981: step 19444, loss 0.25115, acc 0.890625\n",
      "2018-05-04T19:33:16.417182: step 19445, loss 0.225518, acc 0.90625\n",
      "2018-05-04T19:33:17.441687: step 19446, loss 0.296673, acc 0.796875\n",
      "2018-05-04T19:33:18.400903: step 19447, loss 0.242573, acc 0.875\n",
      "2018-05-04T19:33:19.377338: step 19448, loss 0.176641, acc 0.921875\n",
      "2018-05-04T19:33:20.351617: step 19449, loss 0.331691, acc 0.921875\n",
      "2018-05-04T19:33:21.388445: step 19450, loss 0.14365, acc 0.96875\n",
      "2018-05-04T19:33:22.320653: step 19451, loss 0.357913, acc 0.8125\n",
      "2018-05-04T19:33:23.344306: step 19452, loss 0.227747, acc 0.90625\n",
      "2018-05-04T19:33:24.316979: step 19453, loss 0.256766, acc 0.90625\n",
      "2018-05-04T19:33:25.276948: step 19454, loss 0.302116, acc 0.875\n",
      "2018-05-04T19:33:26.248901: step 19455, loss 0.277165, acc 0.890625\n",
      "2018-05-04T19:33:27.226507: step 19456, loss 0.282078, acc 0.90625\n",
      "2018-05-04T19:33:28.223067: step 19457, loss 0.222034, acc 0.890625\n",
      "2018-05-04T19:33:29.197342: step 19458, loss 0.291593, acc 0.890625\n",
      "2018-05-04T19:33:30.151076: step 19459, loss 0.357602, acc 0.84375\n",
      "2018-05-04T19:33:31.109144: step 19460, loss 0.208387, acc 0.921875\n",
      "2018-05-04T19:33:32.060116: step 19461, loss 0.305563, acc 0.890625\n",
      "2018-05-04T19:33:33.030845: step 19462, loss 0.245551, acc 0.890625\n",
      "2018-05-04T19:33:34.009008: step 19463, loss 0.218293, acc 0.875\n",
      "2018-05-04T19:33:34.995822: step 19464, loss 0.295651, acc 0.875\n",
      "2018-05-04T19:33:36.004510: step 19465, loss 0.253014, acc 0.875\n",
      "2018-05-04T19:33:36.963875: step 19466, loss 0.341073, acc 0.90625\n",
      "2018-05-04T19:33:37.918212: step 19467, loss 0.268045, acc 0.875\n",
      "2018-05-04T19:33:38.861461: step 19468, loss 0.276883, acc 0.90625\n",
      "2018-05-04T19:33:39.873084: step 19469, loss 0.337503, acc 0.796875\n",
      "2018-05-04T19:33:40.848092: step 19470, loss 0.150054, acc 0.953125\n",
      "2018-05-04T19:33:41.820332: step 19471, loss 0.221842, acc 0.90625\n",
      "2018-05-04T19:33:42.876086: step 19472, loss 0.208911, acc 0.875\n",
      "2018-05-04T19:33:43.844969: step 19473, loss 0.245758, acc 0.921875\n",
      "2018-05-04T19:33:44.808438: step 19474, loss 0.361311, acc 0.84375\n",
      "2018-05-04T19:33:45.755184: step 19475, loss 0.234051, acc 0.890625\n",
      "2018-05-04T19:33:46.723668: step 19476, loss 0.293131, acc 0.875\n",
      "2018-05-04T19:33:47.660306: step 19477, loss 0.333009, acc 0.875\n",
      "2018-05-04T19:33:48.614896: step 19478, loss 0.2046, acc 0.96875\n",
      "2018-05-04T19:33:49.585237: step 19479, loss 0.245851, acc 0.859375\n",
      "2018-05-04T19:33:50.570261: step 19480, loss 0.215167, acc 0.875\n",
      "2018-05-04T19:33:51.527982: step 19481, loss 0.221576, acc 0.90625\n",
      "2018-05-04T19:33:52.476654: step 19482, loss 0.261142, acc 0.890625\n",
      "2018-05-04T19:33:53.418761: step 19483, loss 0.312067, acc 0.84375\n",
      "2018-05-04T19:33:54.379646: step 19484, loss 0.161096, acc 0.953125\n",
      "2018-05-04T19:33:55.341999: step 19485, loss 0.215826, acc 0.921875\n",
      "2018-05-04T19:33:56.316654: step 19486, loss 0.204924, acc 0.890625\n",
      "2018-05-04T19:33:57.293937: step 19487, loss 0.273472, acc 0.90625\n",
      "2018-05-04T19:33:58.244650: step 19488, loss 0.26702, acc 0.828125\n",
      "2018-05-04T19:33:59.204026: step 19489, loss 0.248497, acc 0.890625\n",
      "2018-05-04T19:34:00.266902: step 19490, loss 0.278319, acc 0.890625\n",
      "2018-05-04T19:34:01.205995: step 19491, loss 0.229692, acc 0.859375\n",
      "2018-05-04T19:34:02.150871: step 19492, loss 0.373107, acc 0.875\n",
      "2018-05-04T19:34:03.097771: step 19493, loss 0.217214, acc 0.921875\n",
      "2018-05-04T19:34:04.045118: step 19494, loss 0.361638, acc 0.859375\n",
      "2018-05-04T19:34:04.980038: step 19495, loss 0.128945, acc 0.953125\n",
      "2018-05-04T19:34:05.944351: step 19496, loss 0.407421, acc 0.828125\n",
      "2018-05-04T19:34:06.945168: step 19497, loss 0.340052, acc 0.84375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T19:34:07.920823: step 19498, loss 0.173763, acc 0.90625\n",
      "2018-05-04T19:34:08.889940: step 19499, loss 0.351335, acc 0.828125\n",
      "2018-05-04T19:34:09.848906: step 19500, loss 0.281509, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T19:34:12.169577: step 19500, loss 0.227738, acc 0.93\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-19500\n",
      "\n",
      "2018-05-04T19:34:13.248405: step 19501, loss 0.165957, acc 0.953125\n",
      "2018-05-04T19:34:14.245869: step 19502, loss 0.175578, acc 0.9375\n",
      "2018-05-04T19:34:15.240978: step 19503, loss 0.309345, acc 0.890625\n",
      "2018-05-04T19:34:16.268505: step 19504, loss 0.331353, acc 0.875\n",
      "2018-05-04T19:34:17.329846: step 19505, loss 0.185892, acc 0.921875\n",
      "2018-05-04T19:34:18.365269: step 19506, loss 0.501611, acc 0.765625\n",
      "2018-05-04T19:34:19.351740: step 19507, loss 0.260545, acc 0.890625\n",
      "2018-05-04T19:34:20.378207: step 19508, loss 0.164685, acc 0.953125\n",
      "2018-05-04T19:34:21.340801: step 19509, loss 0.316584, acc 0.875\n",
      "2018-05-04T19:34:22.463808: step 19510, loss 0.382103, acc 0.875\n",
      "2018-05-04T19:34:23.442567: step 19511, loss 0.275895, acc 0.90625\n",
      "2018-05-04T19:34:24.427501: step 19512, loss 0.211313, acc 0.90625\n",
      "2018-05-04T19:34:25.394312: step 19513, loss 0.207789, acc 0.921875\n",
      "2018-05-04T19:34:26.353169: step 19514, loss 0.383998, acc 0.890625\n",
      "2018-05-04T19:34:27.333007: step 19515, loss 0.20563, acc 0.953125\n",
      "2018-05-04T19:34:28.391343: step 19516, loss 0.180751, acc 0.953125\n",
      "2018-05-04T19:34:29.452378: step 19517, loss 0.254498, acc 0.859375\n",
      "2018-05-04T19:34:30.425675: step 19518, loss 0.216379, acc 0.921875\n",
      "2018-05-04T19:34:31.404479: step 19519, loss 0.261454, acc 0.921875\n",
      "2018-05-04T19:34:32.382808: step 19520, loss 0.30266, acc 0.859375\n",
      "2018-05-04T19:34:33.396569: step 19521, loss 0.295388, acc 0.875\n",
      "2018-05-04T19:34:34.411078: step 19522, loss 0.232999, acc 0.90625\n",
      "2018-05-04T19:34:35.443998: step 19523, loss 0.309547, acc 0.875\n",
      "2018-05-04T19:34:36.482745: step 19524, loss 0.224301, acc 0.921875\n",
      "2018-05-04T19:34:37.513787: step 19525, loss 0.144759, acc 0.953125\n",
      "2018-05-04T19:34:38.520254: step 19526, loss 0.236445, acc 0.890625\n",
      "2018-05-04T19:34:39.507737: step 19527, loss 0.223966, acc 0.953125\n",
      "2018-05-04T19:34:40.494881: step 19528, loss 0.175542, acc 0.953125\n",
      "2018-05-04T19:34:41.483497: step 19529, loss 0.325838, acc 0.859375\n",
      "2018-05-04T19:34:42.465513: step 19530, loss 0.343882, acc 0.859375\n",
      "2018-05-04T19:34:43.469977: step 19531, loss 0.257971, acc 0.875\n",
      "2018-05-04T19:34:44.432289: step 19532, loss 0.350449, acc 0.84375\n",
      "2018-05-04T19:34:45.425989: step 19533, loss 0.287246, acc 0.90625\n",
      "2018-05-04T19:34:46.394814: step 19534, loss 0.178908, acc 0.9375\n",
      "2018-05-04T19:34:47.370223: step 19535, loss 0.200239, acc 0.90625\n",
      "2018-05-04T19:34:48.337732: step 19536, loss 0.286975, acc 0.890625\n",
      "2018-05-04T19:34:49.306294: step 19537, loss 0.202991, acc 0.9375\n",
      "2018-05-04T19:34:50.296529: step 19538, loss 0.319775, acc 0.859375\n",
      "2018-05-04T19:34:51.258601: step 19539, loss 0.222494, acc 0.953125\n",
      "2018-05-04T19:34:52.221394: step 19540, loss 0.268089, acc 0.890625\n",
      "2018-05-04T19:34:53.179019: step 19541, loss 0.257565, acc 0.875\n",
      "2018-05-04T19:34:54.163130: step 19542, loss 0.13271, acc 1\n",
      "2018-05-04T19:34:55.128027: step 19543, loss 0.237263, acc 0.953125\n",
      "2018-05-04T19:34:56.121450: step 19544, loss 0.394853, acc 0.875\n",
      "2018-05-04T19:34:57.122427: step 19545, loss 0.331336, acc 0.875\n",
      "2018-05-04T19:34:58.099450: step 19546, loss 0.342078, acc 0.890625\n",
      "2018-05-04T19:34:59.078300: step 19547, loss 0.284776, acc 0.859375\n",
      "2018-05-04T19:35:00.036944: step 19548, loss 0.23768, acc 0.90625\n",
      "2018-05-04T19:35:00.987472: step 19549, loss 0.318884, acc 0.859375\n",
      "2018-05-04T19:35:02.036267: step 19550, loss 0.203872, acc 0.96875\n",
      "2018-05-04T19:35:03.027137: step 19551, loss 0.257996, acc 0.921875\n",
      "2018-05-04T19:35:03.998740: step 19552, loss 0.380557, acc 0.859375\n",
      "2018-05-04T19:35:04.954379: step 19553, loss 0.163961, acc 0.921875\n",
      "2018-05-04T19:35:05.922180: step 19554, loss 0.316858, acc 0.8125\n",
      "2018-05-04T19:35:06.891690: step 19555, loss 0.326778, acc 0.859375\n",
      "2018-05-04T19:35:07.900597: step 19556, loss 0.504299, acc 0.875\n",
      "2018-05-04T19:35:08.930890: step 19557, loss 0.300467, acc 0.890625\n",
      "2018-05-04T19:35:09.979909: step 19558, loss 0.24377, acc 0.8125\n",
      "2018-05-04T19:35:10.930891: step 19559, loss 0.338288, acc 0.890625\n",
      "2018-05-04T19:35:11.895418: step 19560, loss 0.186421, acc 0.921875\n",
      "2018-05-04T19:35:12.866762: step 19561, loss 0.227193, acc 0.90625\n",
      "2018-05-04T19:35:13.831094: step 19562, loss 0.266294, acc 0.921875\n",
      "2018-05-04T19:35:14.873618: step 19563, loss 0.22717, acc 0.875\n",
      "2018-05-04T19:35:15.823041: step 19564, loss 0.28631, acc 0.84375\n",
      "2018-05-04T19:35:16.773329: step 19565, loss 0.411908, acc 0.890625\n",
      "2018-05-04T19:35:17.747114: step 19566, loss 0.248587, acc 0.875\n",
      "2018-05-04T19:35:18.710523: step 19567, loss 0.225504, acc 0.921875\n",
      "2018-05-04T19:35:19.664714: step 19568, loss 0.30857, acc 0.84375\n",
      "2018-05-04T19:35:20.675271: step 19569, loss 0.226179, acc 0.921875\n",
      "2018-05-04T19:35:21.661302: step 19570, loss 0.259826, acc 0.953125\n",
      "2018-05-04T19:35:22.641719: step 19571, loss 0.225414, acc 0.890625\n",
      "2018-05-04T19:35:23.682488: step 19572, loss 0.285942, acc 0.90625\n",
      "2018-05-04T19:35:24.671652: step 19573, loss 0.329331, acc 0.859375\n",
      "2018-05-04T19:35:25.664586: step 19574, loss 0.238847, acc 0.90625\n",
      "2018-05-04T19:35:26.609167: step 19575, loss 0.246332, acc 0.90625\n",
      "2018-05-04T19:35:27.566817: step 19576, loss 0.238038, acc 0.921875\n",
      "2018-05-04T19:35:28.519201: step 19577, loss 0.282124, acc 0.890625\n",
      "2018-05-04T19:35:29.474275: step 19578, loss 0.215987, acc 0.9375\n",
      "2018-05-04T19:35:30.432177: step 19579, loss 0.259896, acc 0.890625\n",
      "2018-05-04T19:35:31.446467: step 19580, loss 0.232654, acc 0.921875\n",
      "2018-05-04T19:35:32.420952: step 19581, loss 0.260463, acc 0.875\n",
      "2018-05-04T19:35:33.450432: step 19582, loss 0.236607, acc 0.921875\n",
      "2018-05-04T19:35:34.421920: step 19583, loss 0.425152, acc 0.828125\n",
      "2018-05-04T19:35:35.378627: step 19584, loss 0.20969, acc 0.890625\n",
      "2018-05-04T19:35:36.339064: step 19585, loss 0.237666, acc 0.90625\n",
      "2018-05-04T19:35:37.276826: step 19586, loss 0.218124, acc 0.90625\n",
      "2018-05-04T19:35:38.242682: step 19587, loss 0.228272, acc 0.90625\n",
      "2018-05-04T19:35:39.209407: step 19588, loss 0.177996, acc 0.921875\n",
      "2018-05-04T19:35:40.131287: step 19589, loss 0.15346, acc 0.953125\n",
      "2018-05-04T19:35:41.103856: step 19590, loss 0.188031, acc 0.90625\n",
      "2018-05-04T19:35:42.083482: step 19591, loss 0.208495, acc 0.90625\n",
      "2018-05-04T19:35:43.038703: step 19592, loss 0.380984, acc 0.859375\n",
      "2018-05-04T19:35:43.989454: step 19593, loss 0.337734, acc 0.890625\n",
      "2018-05-04T19:35:44.927931: step 19594, loss 0.214612, acc 0.921875\n",
      "2018-05-04T19:35:45.935932: step 19595, loss 0.295291, acc 0.90625\n",
      "2018-05-04T19:35:46.986207: step 19596, loss 0.321963, acc 0.890625\n",
      "2018-05-04T19:35:47.938610: step 19597, loss 0.294292, acc 0.90625\n",
      "2018-05-04T19:35:48.888486: step 19598, loss 0.278495, acc 0.875\n",
      "2018-05-04T19:35:49.897393: step 19599, loss 0.194325, acc 0.921875\n",
      "2018-05-04T19:35:50.843779: step 19600, loss 0.318795, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T19:35:53.293669: step 19600, loss 0.216771, acc 0.926\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-19600\n",
      "\n",
      "2018-05-04T19:35:54.353417: step 19601, loss 0.212667, acc 0.90625\n",
      "2018-05-04T19:35:55.364313: step 19602, loss 0.280822, acc 0.90625\n",
      "2018-05-04T19:35:56.347133: step 19603, loss 0.33372, acc 0.90625\n",
      "2018-05-04T19:35:57.382339: step 19604, loss 0.285169, acc 0.921875\n",
      "2018-05-04T19:35:58.412410: step 19605, loss 0.239179, acc 0.890625\n",
      "2018-05-04T19:35:59.441948: step 19606, loss 0.459246, acc 0.859375\n",
      "2018-05-04T19:36:00.471649: step 19607, loss 0.377732, acc 0.84375\n",
      "2018-05-04T19:36:01.453094: step 19608, loss 0.432102, acc 0.875\n",
      "2018-05-04T19:36:02.428650: step 19609, loss 0.226174, acc 0.90625\n",
      "2018-05-04T19:36:03.466778: step 19610, loss 0.379916, acc 0.859375\n",
      "2018-05-04T19:36:04.460366: step 19611, loss 0.196722, acc 0.921875\n",
      "2018-05-04T19:36:05.493034: step 19612, loss 0.196016, acc 0.90625\n",
      "2018-05-04T19:36:06.461646: step 19613, loss 0.159943, acc 0.9375\n",
      "2018-05-04T19:36:07.527652: step 19614, loss 0.11745, acc 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T19:36:08.492416: step 19615, loss 0.163546, acc 0.921875\n",
      "2018-05-04T19:36:09.460880: step 19616, loss 0.295241, acc 0.875\n",
      "2018-05-04T19:36:10.447916: step 19617, loss 0.244965, acc 0.90625\n",
      "2018-05-04T19:36:11.412133: step 19618, loss 0.152924, acc 0.9375\n",
      "2018-05-04T19:36:12.351117: step 19619, loss 0.418544, acc 0.84375\n",
      "2018-05-04T19:36:13.294330: step 19620, loss 0.345437, acc 0.859375\n",
      "2018-05-04T19:36:14.248705: step 19621, loss 0.243475, acc 0.890625\n",
      "2018-05-04T19:36:15.212118: step 19622, loss 0.346253, acc 0.84375\n",
      "2018-05-04T19:36:16.159346: step 19623, loss 0.220783, acc 0.890625\n",
      "2018-05-04T19:36:17.118790: step 19624, loss 0.182801, acc 0.921875\n",
      "2018-05-04T19:36:18.082620: step 19625, loss 0.217766, acc 0.921875\n",
      "2018-05-04T19:36:19.054674: step 19626, loss 0.22845, acc 0.9375\n",
      "2018-05-04T19:36:20.014392: step 19627, loss 0.206634, acc 0.9375\n",
      "2018-05-04T19:36:21.053486: step 19628, loss 0.306704, acc 0.859375\n",
      "2018-05-04T19:36:22.064003: step 19629, loss 0.143817, acc 0.96875\n",
      "2018-05-04T19:36:23.039285: step 19630, loss 0.254277, acc 0.921875\n",
      "2018-05-04T19:36:23.989473: step 19631, loss 0.271615, acc 0.828125\n",
      "2018-05-04T19:36:24.978465: step 19632, loss 0.268172, acc 0.875\n",
      "2018-05-04T19:36:25.956935: step 19633, loss 0.252589, acc 0.90625\n",
      "2018-05-04T19:36:26.944448: step 19634, loss 0.329753, acc 0.890625\n",
      "2018-05-04T19:36:27.892885: step 19635, loss 0.248979, acc 0.859375\n",
      "2018-05-04T19:36:28.862270: step 19636, loss 0.197354, acc 0.953125\n",
      "2018-05-04T19:36:29.850586: step 19637, loss 0.307892, acc 0.859375\n",
      "2018-05-04T19:36:30.974168: step 19638, loss 0.129711, acc 0.953125\n",
      "2018-05-04T19:36:32.036353: step 19639, loss 0.181786, acc 0.9375\n",
      "2018-05-04T19:36:33.022187: step 19640, loss 0.200222, acc 0.90625\n",
      "2018-05-04T19:36:33.998666: step 19641, loss 0.2228, acc 0.890625\n",
      "2018-05-04T19:36:34.951294: step 19642, loss 0.214278, acc 0.921875\n",
      "2018-05-04T19:36:35.920702: step 19643, loss 0.294376, acc 0.828125\n",
      "2018-05-04T19:36:36.887169: step 19644, loss 0.173641, acc 0.921875\n",
      "2018-05-04T19:36:37.867100: step 19645, loss 0.264838, acc 0.890625\n",
      "2018-05-04T19:36:38.833058: step 19646, loss 0.257077, acc 0.921875\n",
      "2018-05-04T19:36:39.791723: step 19647, loss 0.244392, acc 0.90625\n",
      "2018-05-04T19:36:40.754684: step 19648, loss 0.140192, acc 0.96875\n",
      "2018-05-04T19:36:41.752398: step 19649, loss 0.156281, acc 0.953125\n",
      "2018-05-04T19:36:42.729779: step 19650, loss 0.305065, acc 0.9375\n",
      "2018-05-04T19:36:43.713976: step 19651, loss 0.388922, acc 0.859375\n",
      "2018-05-04T19:36:44.682491: step 19652, loss 0.278612, acc 0.859375\n",
      "2018-05-04T19:36:45.637295: step 19653, loss 0.425517, acc 0.875\n",
      "2018-05-04T19:36:46.631926: step 19654, loss 0.309742, acc 0.859375\n",
      "2018-05-04T19:36:47.702299: step 19655, loss 0.315499, acc 0.84375\n",
      "2018-05-04T19:36:48.663347: step 19656, loss 0.349719, acc 0.859375\n",
      "2018-05-04T19:36:49.620669: step 19657, loss 0.226984, acc 0.921875\n",
      "2018-05-04T19:36:50.594181: step 19658, loss 0.216227, acc 0.90625\n",
      "2018-05-04T19:36:51.601896: step 19659, loss 0.288816, acc 0.890625\n",
      "2018-05-04T19:36:52.618301: step 19660, loss 0.184553, acc 0.921875\n",
      "2018-05-04T19:36:53.576018: step 19661, loss 0.26567, acc 0.90625\n",
      "2018-05-04T19:36:54.578981: step 19662, loss 0.287843, acc 0.90625\n",
      "2018-05-04T19:36:55.557735: step 19663, loss 0.257211, acc 0.90625\n",
      "2018-05-04T19:36:56.515585: step 19664, loss 0.304658, acc 0.921875\n",
      "2018-05-04T19:36:57.473097: step 19665, loss 0.250755, acc 0.890625\n",
      "2018-05-04T19:36:58.444519: step 19666, loss 0.269821, acc 0.890625\n",
      "2018-05-04T19:36:59.485036: step 19667, loss 0.213329, acc 0.90625\n",
      "2018-05-04T19:37:00.428508: step 19668, loss 0.21915, acc 0.890625\n",
      "2018-05-04T19:37:01.384090: step 19669, loss 0.257965, acc 0.875\n",
      "2018-05-04T19:37:02.322512: step 19670, loss 0.266201, acc 0.90625\n",
      "2018-05-04T19:37:03.299975: step 19671, loss 0.223521, acc 0.890625\n",
      "2018-05-04T19:37:04.265720: step 19672, loss 0.237276, acc 0.90625\n",
      "2018-05-04T19:37:05.193919: step 19673, loss 0.22098, acc 0.921875\n",
      "2018-05-04T19:37:06.259080: step 19674, loss 0.342749, acc 0.875\n",
      "2018-05-04T19:37:07.223040: step 19675, loss 0.194491, acc 0.890625\n",
      "2018-05-04T19:37:08.179571: step 19676, loss 0.207545, acc 0.921875\n",
      "2018-05-04T19:37:09.233522: step 19677, loss 0.205536, acc 0.890625\n",
      "2018-05-04T19:37:10.181361: step 19678, loss 0.319844, acc 0.875\n",
      "2018-05-04T19:37:11.186581: step 19679, loss 0.159712, acc 0.90625\n",
      "2018-05-04T19:37:12.280704: step 19680, loss 0.28793, acc 0.90625\n",
      "2018-05-04T19:37:13.271235: step 19681, loss 0.26206, acc 0.859375\n",
      "2018-05-04T19:37:14.273369: step 19682, loss 0.440883, acc 0.78125\n",
      "2018-05-04T19:37:15.238257: step 19683, loss 0.190243, acc 0.921875\n",
      "2018-05-04T19:37:16.195078: step 19684, loss 0.192074, acc 0.9375\n",
      "2018-05-04T19:37:17.141631: step 19685, loss 0.254336, acc 0.890625\n",
      "2018-05-04T19:37:18.128549: step 19686, loss 0.560873, acc 0.8125\n",
      "2018-05-04T19:37:19.191900: step 19687, loss 0.443594, acc 0.828125\n",
      "2018-05-04T19:37:20.143861: step 19688, loss 0.288337, acc 0.90625\n",
      "2018-05-04T19:37:21.101123: step 19689, loss 0.179225, acc 0.9375\n",
      "2018-05-04T19:37:22.051750: step 19690, loss 0.307283, acc 0.90625\n",
      "2018-05-04T19:37:23.067195: step 19691, loss 0.313415, acc 0.890625\n",
      "2018-05-04T19:37:24.024428: step 19692, loss 0.242767, acc 0.890625\n",
      "2018-05-04T19:37:24.969850: step 19693, loss 0.234247, acc 0.90625\n",
      "2018-05-04T19:37:25.925458: step 19694, loss 0.168961, acc 0.9375\n",
      "2018-05-04T19:37:26.895125: step 19695, loss 0.278492, acc 0.8125\n",
      "2018-05-04T19:37:27.855202: step 19696, loss 0.284663, acc 0.890625\n",
      "2018-05-04T19:37:28.814996: step 19697, loss 0.246708, acc 0.84375\n",
      "2018-05-04T19:37:29.780754: step 19698, loss 0.275342, acc 0.890625\n",
      "2018-05-04T19:37:30.723968: step 19699, loss 0.266267, acc 0.921875\n",
      "2018-05-04T19:37:31.718443: step 19700, loss 0.160759, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T19:37:34.054876: step 19700, loss 0.230253, acc 0.92\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-19700\n",
      "\n",
      "2018-05-04T19:37:35.219170: step 19701, loss 0.163581, acc 0.953125\n",
      "2018-05-04T19:37:36.275813: step 19702, loss 0.18061, acc 0.9375\n",
      "2018-05-04T19:37:37.244082: step 19703, loss 0.218679, acc 0.921875\n",
      "2018-05-04T19:37:38.201427: step 19704, loss 0.320908, acc 0.859375\n",
      "2018-05-04T19:37:39.168465: step 19705, loss 0.401463, acc 0.765625\n",
      "2018-05-04T19:37:40.121722: step 19706, loss 0.250457, acc 0.875\n",
      "2018-05-04T19:37:41.089048: step 19707, loss 0.297291, acc 0.828125\n",
      "2018-05-04T19:37:42.081313: step 19708, loss 0.262312, acc 0.875\n",
      "2018-05-04T19:37:43.067838: step 19709, loss 0.3273, acc 0.84375\n",
      "2018-05-04T19:37:44.034508: step 19710, loss 0.390719, acc 0.796875\n",
      "2018-05-04T19:37:44.984349: step 19711, loss 0.263241, acc 0.828125\n",
      "2018-05-04T19:37:45.967088: step 19712, loss 0.465651, acc 0.875\n",
      "2018-05-04T19:37:46.918154: step 19713, loss 0.37287, acc 0.828125\n",
      "2018-05-04T19:37:47.862012: step 19714, loss 0.265472, acc 0.921875\n",
      "2018-05-04T19:37:48.812521: step 19715, loss 0.303698, acc 0.875\n",
      "2018-05-04T19:37:49.766219: step 19716, loss 0.355556, acc 0.890625\n",
      "2018-05-04T19:37:50.715366: step 19717, loss 0.258773, acc 0.890625\n",
      "2018-05-04T19:37:51.676218: step 19718, loss 0.200839, acc 0.921875\n",
      "2018-05-04T19:37:52.615014: step 19719, loss 0.214667, acc 0.9375\n",
      "2018-05-04T19:37:53.576322: step 19720, loss 0.468599, acc 0.765625\n",
      "2018-05-04T19:37:54.523219: step 19721, loss 0.21032, acc 0.90625\n",
      "2018-05-04T19:37:55.473931: step 19722, loss 0.359135, acc 0.828125\n",
      "2018-05-04T19:37:56.410826: step 19723, loss 0.239288, acc 0.890625\n",
      "2018-05-04T19:37:57.358040: step 19724, loss 0.183523, acc 0.953125\n",
      "2018-05-04T19:37:58.334982: step 19725, loss 0.307326, acc 0.859375\n",
      "2018-05-04T19:37:59.361648: step 19726, loss 0.236952, acc 0.890625\n",
      "2018-05-04T19:38:00.303716: step 19727, loss 0.203359, acc 0.90625\n",
      "2018-05-04T19:38:01.257583: step 19728, loss 0.285106, acc 0.90625\n",
      "2018-05-04T19:38:02.236503: step 19729, loss 0.287304, acc 0.84375\n",
      "2018-05-04T19:38:03.195422: step 19730, loss 0.255577, acc 0.921875\n",
      "2018-05-04T19:38:04.176323: step 19731, loss 0.244323, acc 0.921875\n",
      "2018-05-04T19:38:05.159199: step 19732, loss 0.245377, acc 0.921875\n",
      "2018-05-04T19:38:06.111911: step 19733, loss 0.333654, acc 0.859375\n",
      "2018-05-04T19:38:07.067510: step 19734, loss 0.359057, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T19:38:07.988899: step 19735, loss 0.364124, acc 0.859375\n",
      "2018-05-04T19:38:08.930998: step 19736, loss 0.252771, acc 0.859375\n",
      "2018-05-04T19:38:09.968493: step 19737, loss 0.301998, acc 0.90625\n",
      "2018-05-04T19:38:10.907206: step 19738, loss 0.410357, acc 0.84375\n",
      "2018-05-04T19:38:11.833991: step 19739, loss 0.236733, acc 0.890625\n",
      "2018-05-04T19:38:12.768274: step 19740, loss 0.190456, acc 0.9375\n",
      "2018-05-04T19:38:13.698613: step 19741, loss 0.229945, acc 0.921875\n",
      "2018-05-04T19:38:14.696407: step 19742, loss 0.207303, acc 0.921875\n",
      "2018-05-04T19:38:15.669895: step 19743, loss 0.308581, acc 0.859375\n",
      "2018-05-04T19:38:16.644939: step 19744, loss 0.283697, acc 0.921875\n",
      "2018-05-04T19:38:17.610933: step 19745, loss 0.241836, acc 0.921875\n",
      "2018-05-04T19:38:18.559537: step 19746, loss 0.427808, acc 0.828125\n",
      "2018-05-04T19:38:19.523786: step 19747, loss 0.128403, acc 0.96875\n",
      "2018-05-04T19:38:20.460977: step 19748, loss 0.216611, acc 0.90625\n",
      "2018-05-04T19:38:21.425617: step 19749, loss 0.345187, acc 0.828125\n",
      "2018-05-04T19:38:22.384210: step 19750, loss 0.310833, acc 0.890625\n",
      "2018-05-04T19:38:23.341519: step 19751, loss 0.200386, acc 0.9375\n",
      "2018-05-04T19:38:24.361220: step 19752, loss 0.198687, acc 0.90625\n",
      "2018-05-04T19:38:25.297075: step 19753, loss 0.29239, acc 0.875\n",
      "2018-05-04T19:38:26.238802: step 19754, loss 0.361274, acc 0.875\n",
      "2018-05-04T19:38:27.179938: step 19755, loss 0.354014, acc 0.875\n",
      "2018-05-04T19:38:28.118991: step 19756, loss 0.237739, acc 0.90625\n",
      "2018-05-04T19:38:29.052572: step 19757, loss 0.374384, acc 0.84375\n",
      "2018-05-04T19:38:30.017561: step 19758, loss 0.49268, acc 0.78125\n",
      "2018-05-04T19:38:31.001470: step 19759, loss 0.267244, acc 0.875\n",
      "2018-05-04T19:38:31.946911: step 19760, loss 0.312797, acc 0.875\n",
      "2018-05-04T19:38:32.869155: step 19761, loss 0.211898, acc 0.90625\n",
      "2018-05-04T19:38:33.897237: step 19762, loss 0.29711, acc 0.859375\n",
      "2018-05-04T19:38:34.827476: step 19763, loss 0.207535, acc 0.90625\n",
      "2018-05-04T19:38:35.782104: step 19764, loss 0.337018, acc 0.796875\n",
      "2018-05-04T19:38:36.752650: step 19765, loss 0.156246, acc 0.953125\n",
      "2018-05-04T19:38:37.712592: step 19766, loss 0.221902, acc 0.921875\n",
      "2018-05-04T19:38:38.654535: step 19767, loss 0.328285, acc 0.90625\n",
      "2018-05-04T19:38:39.601467: step 19768, loss 0.198844, acc 0.9375\n",
      "2018-05-04T19:38:40.548036: step 19769, loss 0.188904, acc 0.9375\n",
      "2018-05-04T19:38:41.500777: step 19770, loss 0.261434, acc 0.90625\n",
      "2018-05-04T19:38:42.492721: step 19771, loss 0.261205, acc 0.890625\n",
      "2018-05-04T19:38:43.478846: step 19772, loss 0.230408, acc 0.921875\n",
      "2018-05-04T19:38:44.449029: step 19773, loss 0.421018, acc 0.859375\n",
      "2018-05-04T19:38:45.438013: step 19774, loss 0.282788, acc 0.90625\n",
      "2018-05-04T19:38:46.396498: step 19775, loss 0.279379, acc 0.828125\n",
      "2018-05-04T19:38:47.323982: step 19776, loss 0.353445, acc 0.8125\n",
      "2018-05-04T19:38:48.279761: step 19777, loss 0.44405, acc 0.890625\n",
      "2018-05-04T19:38:49.216133: step 19778, loss 0.383431, acc 0.890625\n",
      "2018-05-04T19:38:50.195324: step 19779, loss 0.176342, acc 0.9375\n",
      "2018-05-04T19:38:51.155618: step 19780, loss 0.330271, acc 0.90625\n",
      "2018-05-04T19:38:52.138546: step 19781, loss 0.33576, acc 0.84375\n",
      "2018-05-04T19:38:53.079396: step 19782, loss 0.246366, acc 0.90625\n",
      "2018-05-04T19:38:54.029653: step 19783, loss 0.235187, acc 0.921875\n",
      "2018-05-04T19:38:54.977282: step 19784, loss 0.319828, acc 0.859375\n",
      "2018-05-04T19:38:56.004415: step 19785, loss 0.332899, acc 0.84375\n",
      "2018-05-04T19:38:56.928597: step 19786, loss 0.187753, acc 0.921875\n",
      "2018-05-04T19:38:57.946080: step 19787, loss 0.212859, acc 0.875\n",
      "2018-05-04T19:38:58.887163: step 19788, loss 0.18213, acc 0.9375\n",
      "2018-05-04T19:38:59.813831: step 19789, loss 0.185084, acc 0.9375\n",
      "2018-05-04T19:39:00.749024: step 19790, loss 0.218354, acc 0.890625\n",
      "2018-05-04T19:39:01.795116: step 19791, loss 0.224133, acc 0.953125\n",
      "2018-05-04T19:39:02.726107: step 19792, loss 0.206019, acc 0.921875\n",
      "2018-05-04T19:39:03.681381: step 19793, loss 0.348663, acc 0.875\n",
      "2018-05-04T19:39:04.725395: step 19794, loss 0.328423, acc 0.84375\n",
      "2018-05-04T19:39:05.687206: step 19795, loss 0.355827, acc 0.828125\n",
      "2018-05-04T19:39:06.641695: step 19796, loss 0.271559, acc 0.875\n",
      "2018-05-04T19:39:07.583413: step 19797, loss 0.179445, acc 0.90625\n",
      "2018-05-04T19:39:08.617877: step 19798, loss 0.224725, acc 0.90625\n",
      "2018-05-04T19:39:09.689417: step 19799, loss 0.247189, acc 0.859375\n",
      "2018-05-04T19:39:10.698981: step 19800, loss 0.203731, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T19:39:13.783775: step 19800, loss 0.240366, acc 0.914\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-19800\n",
      "\n",
      "2018-05-04T19:39:14.935370: step 19801, loss 0.189221, acc 0.90625\n",
      "2018-05-04T19:39:15.933919: step 19802, loss 0.244855, acc 0.859375\n",
      "2018-05-04T19:39:16.947083: step 19803, loss 0.333953, acc 0.859375\n",
      "2018-05-04T19:39:17.982183: step 19804, loss 0.295284, acc 0.921875\n",
      "2018-05-04T19:39:19.008640: step 19805, loss 0.242046, acc 0.90625\n",
      "2018-05-04T19:39:19.986538: step 19806, loss 0.374591, acc 0.84375\n",
      "2018-05-04T19:39:20.950437: step 19807, loss 0.19749, acc 0.921875\n",
      "2018-05-04T19:39:21.947335: step 19808, loss 0.177118, acc 0.90625\n",
      "2018-05-04T19:39:22.907462: step 19809, loss 0.219344, acc 0.875\n",
      "2018-05-04T19:39:23.904249: step 19810, loss 0.223902, acc 0.90625\n",
      "2018-05-04T19:39:24.888831: step 19811, loss 0.1923, acc 0.921875\n",
      "2018-05-04T19:39:25.952690: step 19812, loss 0.206999, acc 0.9375\n",
      "2018-05-04T19:39:26.986683: step 19813, loss 0.416614, acc 0.859375\n",
      "2018-05-04T19:39:27.950585: step 19814, loss 0.16686, acc 0.890625\n",
      "2018-05-04T19:39:28.918919: step 19815, loss 0.310778, acc 0.921875\n",
      "2018-05-04T19:39:29.862756: step 19816, loss 0.282138, acc 0.90625\n",
      "2018-05-04T19:39:30.849418: step 19817, loss 0.183695, acc 0.90625\n",
      "2018-05-04T19:39:31.821520: step 19818, loss 0.345735, acc 0.84375\n",
      "2018-05-04T19:39:32.775651: step 19819, loss 0.227684, acc 0.875\n",
      "2018-05-04T19:39:33.726670: step 19820, loss 0.345371, acc 0.828125\n",
      "2018-05-04T19:39:34.720619: step 19821, loss 0.211129, acc 0.921875\n",
      "2018-05-04T19:39:35.688870: step 19822, loss 0.16861, acc 0.953125\n",
      "2018-05-04T19:39:36.685681: step 19823, loss 0.156434, acc 0.921875\n",
      "2018-05-04T19:39:37.664963: step 19824, loss 0.209543, acc 0.921875\n",
      "2018-05-04T19:39:38.667458: step 19825, loss 0.211779, acc 0.953125\n",
      "2018-05-04T19:39:39.645541: step 19826, loss 0.189378, acc 0.921875\n",
      "2018-05-04T19:39:40.625504: step 19827, loss 0.391404, acc 0.828125\n",
      "2018-05-04T19:39:41.630027: step 19828, loss 0.19563, acc 0.921875\n",
      "2018-05-04T19:39:42.604100: step 19829, loss 0.149989, acc 0.9375\n",
      "2018-05-04T19:39:43.590558: step 19830, loss 0.445085, acc 0.8125\n",
      "2018-05-04T19:39:44.592425: step 19831, loss 0.302941, acc 0.859375\n",
      "2018-05-04T19:39:45.563711: step 19832, loss 0.311308, acc 0.875\n",
      "2018-05-04T19:39:46.532963: step 19833, loss 0.252067, acc 0.859375\n",
      "2018-05-04T19:39:47.551583: step 19834, loss 0.300357, acc 0.921875\n",
      "2018-05-04T19:39:48.527633: step 19835, loss 0.278681, acc 0.90625\n",
      "2018-05-04T19:39:49.534264: step 19836, loss 0.2461, acc 0.859375\n",
      "2018-05-04T19:39:50.557474: step 19837, loss 0.202565, acc 0.90625\n",
      "2018-05-04T19:39:51.540202: step 19838, loss 0.260241, acc 0.859375\n",
      "2018-05-04T19:39:52.542673: step 19839, loss 0.252129, acc 0.921875\n",
      "2018-05-04T19:39:53.604009: step 19840, loss 0.315912, acc 0.859375\n",
      "2018-05-04T19:39:54.571933: step 19841, loss 0.210737, acc 0.9375\n",
      "2018-05-04T19:39:55.560251: step 19842, loss 0.297276, acc 0.84375\n",
      "2018-05-04T19:39:56.527112: step 19843, loss 0.251045, acc 0.90625\n",
      "2018-05-04T19:39:57.505322: step 19844, loss 0.227868, acc 0.890625\n",
      "2018-05-04T19:39:58.472267: step 19845, loss 0.206269, acc 0.953125\n",
      "2018-05-04T19:39:59.437121: step 19846, loss 0.450657, acc 0.828125\n",
      "2018-05-04T19:40:00.397111: step 19847, loss 0.237463, acc 0.890625\n",
      "2018-05-04T19:40:01.370673: step 19848, loss 0.25554, acc 0.90625\n",
      "2018-05-04T19:40:02.343455: step 19849, loss 0.125741, acc 0.96875\n",
      "2018-05-04T19:40:03.287090: step 19850, loss 0.229273, acc 0.90625\n",
      "2018-05-04T19:40:04.308711: step 19851, loss 0.361892, acc 0.875\n",
      "2018-05-04T19:40:05.367953: step 19852, loss 0.241341, acc 0.921875\n",
      "2018-05-04T19:40:06.348949: step 19853, loss 0.25306, acc 0.921875\n",
      "2018-05-04T19:40:07.318594: step 19854, loss 0.225063, acc 0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T19:40:08.272053: step 19855, loss 0.162538, acc 0.96875\n",
      "2018-05-04T19:40:09.251952: step 19856, loss 0.340409, acc 0.859375\n",
      "2018-05-04T19:40:10.223648: step 19857, loss 0.379908, acc 0.859375\n",
      "2018-05-04T19:40:11.189576: step 19858, loss 0.22263, acc 0.90625\n",
      "2018-05-04T19:40:12.167074: step 19859, loss 0.157544, acc 0.953125\n",
      "2018-05-04T19:40:13.149628: step 19860, loss 0.223807, acc 0.90625\n",
      "2018-05-04T19:40:14.150397: step 19861, loss 0.368699, acc 0.859375\n",
      "2018-05-04T19:40:15.220961: step 19862, loss 0.322229, acc 0.84375\n",
      "2018-05-04T19:40:16.198262: step 19863, loss 0.299919, acc 0.875\n",
      "2018-05-04T19:40:17.172850: step 19864, loss 0.199325, acc 0.9375\n",
      "2018-05-04T19:40:18.137651: step 19865, loss 0.234419, acc 0.890625\n",
      "2018-05-04T19:40:19.093669: step 19866, loss 0.323075, acc 0.859375\n",
      "2018-05-04T19:40:20.061520: step 19867, loss 0.283903, acc 0.890625\n",
      "2018-05-04T19:40:21.005224: step 19868, loss 0.190095, acc 0.9375\n",
      "2018-05-04T19:40:21.949696: step 19869, loss 0.366416, acc 0.84375\n",
      "2018-05-04T19:40:22.907244: step 19870, loss 0.324487, acc 0.921875\n",
      "2018-05-04T19:40:23.861530: step 19871, loss 0.317526, acc 0.828125\n",
      "2018-05-04T19:40:24.846748: step 19872, loss 0.11781, acc 0.96875\n",
      "2018-05-04T19:40:25.788580: step 19873, loss 0.234416, acc 0.859375\n",
      "2018-05-04T19:40:26.769278: step 19874, loss 0.230311, acc 0.921875\n",
      "2018-05-04T19:40:27.747541: step 19875, loss 0.201559, acc 0.9375\n",
      "2018-05-04T19:40:28.725067: step 19876, loss 0.269794, acc 0.890625\n",
      "2018-05-04T19:40:29.688141: step 19877, loss 0.183362, acc 0.921875\n",
      "2018-05-04T19:40:30.646964: step 19878, loss 0.21061, acc 0.890625\n",
      "2018-05-04T19:40:31.607540: step 19879, loss 0.363955, acc 0.8125\n",
      "2018-05-04T19:40:32.604646: step 19880, loss 0.254306, acc 0.890625\n",
      "2018-05-04T19:40:33.654800: step 19881, loss 0.245792, acc 0.90625\n",
      "2018-05-04T19:40:34.702195: step 19882, loss 0.253712, acc 0.875\n",
      "2018-05-04T19:40:35.730336: step 19883, loss 0.300308, acc 0.84375\n",
      "2018-05-04T19:40:36.745461: step 19884, loss 0.267998, acc 0.953125\n",
      "2018-05-04T19:40:37.723911: step 19885, loss 0.261654, acc 0.90625\n",
      "2018-05-04T19:40:38.692495: step 19886, loss 0.235076, acc 0.921875\n",
      "2018-05-04T19:40:39.659241: step 19887, loss 0.261747, acc 0.90625\n",
      "2018-05-04T19:40:40.630594: step 19888, loss 0.143123, acc 0.96875\n",
      "2018-05-04T19:40:41.594153: step 19889, loss 0.216238, acc 0.9375\n",
      "2018-05-04T19:40:42.550478: step 19890, loss 0.281644, acc 0.796875\n",
      "2018-05-04T19:40:43.495843: step 19891, loss 0.324907, acc 0.9375\n",
      "2018-05-04T19:40:44.456692: step 19892, loss 0.225611, acc 0.875\n",
      "2018-05-04T19:40:45.414912: step 19893, loss 0.354288, acc 0.8125\n",
      "2018-05-04T19:40:46.376386: step 19894, loss 0.24734, acc 0.890625\n",
      "2018-05-04T19:40:47.406192: step 19895, loss 0.373522, acc 0.859375\n",
      "2018-05-04T19:40:48.345419: step 19896, loss 0.157481, acc 0.96875\n",
      "2018-05-04T19:40:49.320992: step 19897, loss 0.269012, acc 0.890625\n",
      "2018-05-04T19:40:50.282459: step 19898, loss 0.368448, acc 0.828125\n",
      "2018-05-04T19:40:51.239700: step 19899, loss 0.22715, acc 0.9375\n",
      "2018-05-04T19:40:52.233976: step 19900, loss 0.12413, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T19:40:54.831611: step 19900, loss 0.219749, acc 0.922\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-19900\n",
      "\n",
      "2018-05-04T19:40:55.891943: step 19901, loss 0.255236, acc 0.859375\n",
      "2018-05-04T19:40:56.877456: step 19902, loss 0.447501, acc 0.84375\n",
      "2018-05-04T19:40:57.871385: step 19903, loss 0.375558, acc 0.859375\n",
      "2018-05-04T19:40:58.881742: step 19904, loss 0.151872, acc 0.9375\n",
      "2018-05-04T19:40:59.879941: step 19905, loss 0.352267, acc 0.859375\n",
      "2018-05-04T19:41:00.897183: step 19906, loss 0.335111, acc 0.875\n",
      "2018-05-04T19:41:01.881430: step 19907, loss 0.307482, acc 0.84375\n",
      "2018-05-04T19:41:02.893011: step 19908, loss 0.273081, acc 0.84375\n",
      "2018-05-04T19:41:03.877271: step 19909, loss 0.290603, acc 0.890625\n",
      "2018-05-04T19:41:04.958863: step 19910, loss 0.13391, acc 0.96875\n",
      "2018-05-04T19:41:05.961374: step 19911, loss 0.34529, acc 0.84375\n",
      "2018-05-04T19:41:06.939896: step 19912, loss 0.22978, acc 0.921875\n",
      "2018-05-04T19:41:07.912065: step 19913, loss 0.25486, acc 0.921875\n",
      "2018-05-04T19:41:08.884589: step 19914, loss 0.172347, acc 0.953125\n",
      "2018-05-04T19:41:09.941717: step 19915, loss 0.301779, acc 0.875\n",
      "2018-05-04T19:41:10.891914: step 19916, loss 0.301601, acc 0.90625\n",
      "2018-05-04T19:41:11.861085: step 19917, loss 0.182768, acc 0.953125\n",
      "2018-05-04T19:41:12.850538: step 19918, loss 0.122639, acc 0.984375\n",
      "2018-05-04T19:41:13.834383: step 19919, loss 0.33524, acc 0.859375\n",
      "2018-05-04T19:41:14.770316: step 19920, loss 0.168446, acc 0.953125\n",
      "2018-05-04T19:41:15.857741: step 19921, loss 0.206906, acc 0.875\n",
      "2018-05-04T19:41:16.900625: step 19922, loss 0.313679, acc 0.875\n",
      "2018-05-04T19:41:17.895711: step 19923, loss 0.209349, acc 0.9375\n",
      "2018-05-04T19:41:18.869450: step 19924, loss 0.377232, acc 0.875\n",
      "2018-05-04T19:41:19.891039: step 19925, loss 0.237202, acc 0.921875\n",
      "2018-05-04T19:41:20.891380: step 19926, loss 0.265156, acc 0.890625\n",
      "2018-05-04T19:41:21.869385: step 19927, loss 0.199204, acc 0.921875\n",
      "2018-05-04T19:41:22.934487: step 19928, loss 0.21997, acc 0.953125\n",
      "2018-05-04T19:41:23.958746: step 19929, loss 0.298098, acc 0.890625\n",
      "2018-05-04T19:41:24.919993: step 19930, loss 0.297566, acc 0.859375\n",
      "2018-05-04T19:41:25.981604: step 19931, loss 0.253959, acc 0.875\n",
      "2018-05-04T19:41:26.933639: step 19932, loss 0.335627, acc 0.859375\n",
      "2018-05-04T19:41:27.985372: step 19933, loss 0.383547, acc 0.828125\n",
      "2018-05-04T19:41:28.951836: step 19934, loss 0.290896, acc 0.859375\n",
      "2018-05-04T19:41:29.925047: step 19935, loss 0.427161, acc 0.8125\n",
      "2018-05-04T19:41:30.973242: step 19936, loss 0.211373, acc 0.890625\n",
      "2018-05-04T19:41:31.935521: step 19937, loss 0.479733, acc 0.84375\n",
      "2018-05-04T19:41:32.908104: step 19938, loss 0.222164, acc 0.875\n",
      "2018-05-04T19:41:33.871602: step 19939, loss 0.156066, acc 0.953125\n",
      "2018-05-04T19:41:34.825743: step 19940, loss 0.327701, acc 0.84375\n",
      "2018-05-04T19:41:35.809149: step 19941, loss 0.332083, acc 0.921875\n",
      "2018-05-04T19:41:36.801137: step 19942, loss 0.298147, acc 0.84375\n",
      "2018-05-04T19:41:37.766470: step 19943, loss 0.351893, acc 0.859375\n",
      "2018-05-04T19:41:38.751017: step 19944, loss 0.309418, acc 0.84375\n",
      "2018-05-04T19:41:39.746595: step 19945, loss 0.299108, acc 0.890625\n",
      "2018-05-04T19:41:40.727950: step 19946, loss 0.324721, acc 0.84375\n",
      "2018-05-04T19:41:41.699843: step 19947, loss 0.152126, acc 1\n",
      "2018-05-04T19:41:42.666780: step 19948, loss 0.270239, acc 0.859375\n",
      "2018-05-04T19:41:43.642218: step 19949, loss 0.254487, acc 0.859375\n",
      "2018-05-04T19:41:44.630342: step 19950, loss 0.22295, acc 0.921875\n",
      "2018-05-04T19:41:45.626263: step 19951, loss 0.232967, acc 0.859375\n",
      "2018-05-04T19:41:46.624834: step 19952, loss 0.370996, acc 0.875\n",
      "2018-05-04T19:41:47.573997: step 19953, loss 0.33563, acc 0.84375\n",
      "2018-05-04T19:41:48.546273: step 19954, loss 0.312798, acc 0.875\n",
      "2018-05-04T19:41:49.520528: step 19955, loss 0.172048, acc 0.953125\n",
      "2018-05-04T19:41:50.499487: step 19956, loss 0.285856, acc 0.828125\n",
      "2018-05-04T19:41:51.477368: step 19957, loss 0.304435, acc 0.890625\n",
      "2018-05-04T19:41:52.449126: step 19958, loss 0.154142, acc 0.953125\n",
      "2018-05-04T19:41:53.404940: step 19959, loss 0.274143, acc 0.90625\n",
      "2018-05-04T19:41:54.387709: step 19960, loss 0.294521, acc 0.859375\n",
      "2018-05-04T19:41:55.321027: step 19961, loss 0.242724, acc 0.828125\n",
      "2018-05-04T19:41:56.279072: step 19962, loss 0.19368, acc 0.953125\n",
      "2018-05-04T19:41:57.319951: step 19963, loss 0.257101, acc 0.90625\n",
      "2018-05-04T19:41:58.256001: step 19964, loss 0.176223, acc 0.953125\n",
      "2018-05-04T19:41:59.192393: step 19965, loss 0.312476, acc 0.921875\n",
      "2018-05-04T19:42:00.191244: step 19966, loss 0.246372, acc 0.890625\n",
      "2018-05-04T19:42:01.301634: step 19967, loss 0.232219, acc 0.921875\n",
      "2018-05-04T19:42:02.304937: step 19968, loss 0.293649, acc 0.890625\n",
      "2018-05-04T19:42:03.238647: step 19969, loss 0.222053, acc 0.921875\n",
      "2018-05-04T19:42:04.206206: step 19970, loss 0.320044, acc 0.84375\n",
      "2018-05-04T19:42:05.166363: step 19971, loss 0.282991, acc 0.890625\n",
      "2018-05-04T19:42:06.169945: step 19972, loss 0.194543, acc 0.9375\n",
      "2018-05-04T19:42:07.149741: step 19973, loss 0.222012, acc 0.921875\n",
      "2018-05-04T19:42:08.134181: step 19974, loss 0.396568, acc 0.84375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T19:42:09.166708: step 19975, loss 0.25072, acc 0.9375\n",
      "2018-05-04T19:42:10.209320: step 19976, loss 0.41573, acc 0.875\n",
      "2018-05-04T19:42:11.154069: step 19977, loss 0.275835, acc 0.9375\n",
      "2018-05-04T19:42:12.101492: step 19978, loss 0.210181, acc 0.890625\n",
      "2018-05-04T19:42:13.041748: step 19979, loss 0.171741, acc 0.9375\n",
      "2018-05-04T19:42:14.010692: step 19980, loss 0.427162, acc 0.828125\n",
      "2018-05-04T19:42:14.951823: step 19981, loss 0.32425, acc 0.890625\n",
      "2018-05-04T19:42:15.914821: step 19982, loss 0.212345, acc 0.90625\n",
      "2018-05-04T19:42:16.877390: step 19983, loss 0.223212, acc 0.90625\n",
      "2018-05-04T19:42:17.811643: step 19984, loss 0.23772, acc 0.90625\n",
      "2018-05-04T19:42:18.754147: step 19985, loss 0.197295, acc 0.9375\n",
      "2018-05-04T19:42:19.705823: step 19986, loss 0.139448, acc 0.9375\n",
      "2018-05-04T19:42:20.664790: step 19987, loss 0.395086, acc 0.890625\n",
      "2018-05-04T19:42:21.646225: step 19988, loss 0.277828, acc 0.90625\n",
      "2018-05-04T19:42:22.635578: step 19989, loss 0.155574, acc 0.953125\n",
      "2018-05-04T19:42:23.569753: step 19990, loss 0.234691, acc 0.90625\n",
      "2018-05-04T19:42:24.572838: step 19991, loss 0.280679, acc 0.859375\n",
      "2018-05-04T19:42:25.536377: step 19992, loss 0.249726, acc 0.890625\n",
      "2018-05-04T19:42:26.508956: step 19993, loss 0.215885, acc 0.890625\n",
      "2018-05-04T19:42:27.493652: step 19994, loss 0.24754, acc 0.875\n",
      "2018-05-04T19:42:28.449310: step 19995, loss 0.330511, acc 0.890625\n",
      "2018-05-04T19:42:29.409409: step 19996, loss 0.345098, acc 0.828125\n",
      "2018-05-04T19:42:30.427047: step 19997, loss 0.212047, acc 0.90625\n",
      "2018-05-04T19:42:31.384998: step 19998, loss 0.233263, acc 0.890625\n",
      "2018-05-04T19:42:32.382308: step 19999, loss 0.239579, acc 0.90625\n",
      "2018-05-04T19:42:33.330671: step 20000, loss 0.314832, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T19:42:35.814295: step 20000, loss 0.225954, acc 0.922\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-20000\n",
      "\n",
      "2018-05-04T19:42:36.880683: step 20001, loss 0.275845, acc 0.890625\n",
      "2018-05-04T19:42:37.901461: step 20002, loss 0.252401, acc 0.90625\n",
      "2018-05-04T19:42:38.907689: step 20003, loss 0.262445, acc 0.921875\n",
      "2018-05-04T19:42:39.928200: step 20004, loss 0.202989, acc 0.875\n",
      "2018-05-04T19:42:40.935335: step 20005, loss 0.367654, acc 0.875\n",
      "2018-05-04T19:42:41.955314: step 20006, loss 0.397291, acc 0.875\n",
      "2018-05-04T19:42:42.953085: step 20007, loss 0.218688, acc 0.875\n",
      "2018-05-04T19:42:43.958203: step 20008, loss 0.257377, acc 0.875\n",
      "2018-05-04T19:42:44.913799: step 20009, loss 0.296342, acc 0.921875\n",
      "2018-05-04T19:42:45.893456: step 20010, loss 0.204721, acc 0.921875\n",
      "2018-05-04T19:42:46.940962: step 20011, loss 0.182507, acc 0.890625\n",
      "2018-05-04T19:42:47.940840: step 20012, loss 0.192381, acc 0.90625\n",
      "2018-05-04T19:42:48.905994: step 20013, loss 0.233944, acc 0.875\n",
      "2018-05-04T19:42:49.872607: step 20014, loss 0.380052, acc 0.84375\n",
      "2018-05-04T19:42:50.861240: step 20015, loss 0.214797, acc 0.90625\n",
      "2018-05-04T19:42:51.822815: step 20016, loss 0.276096, acc 0.90625\n",
      "2018-05-04T19:42:52.770961: step 20017, loss 0.206179, acc 0.9375\n",
      "2018-05-04T19:42:53.776085: step 20018, loss 0.254371, acc 0.90625\n",
      "2018-05-04T19:42:54.799397: step 20019, loss 0.320163, acc 0.84375\n",
      "2018-05-04T19:42:55.821889: step 20020, loss 0.343226, acc 0.875\n",
      "2018-05-04T19:42:56.790474: step 20021, loss 0.302721, acc 0.890625\n",
      "2018-05-04T19:42:57.753466: step 20022, loss 0.247496, acc 0.890625\n",
      "2018-05-04T19:42:58.712858: step 20023, loss 0.312748, acc 0.921875\n",
      "2018-05-04T19:42:59.665722: step 20024, loss 0.171548, acc 0.9375\n",
      "2018-05-04T19:43:00.655776: step 20025, loss 0.229734, acc 0.953125\n",
      "2018-05-04T19:43:01.615356: step 20026, loss 0.314442, acc 0.84375\n",
      "2018-05-04T19:43:02.607986: step 20027, loss 0.319298, acc 0.90625\n",
      "2018-05-04T19:43:03.559954: step 20028, loss 0.343588, acc 0.828125\n",
      "2018-05-04T19:43:04.555663: step 20029, loss 0.199852, acc 0.921875\n",
      "2018-05-04T19:43:05.606047: step 20030, loss 0.132826, acc 0.96875\n",
      "2018-05-04T19:43:06.582769: step 20031, loss 0.291503, acc 0.90625\n",
      "2018-05-04T19:43:07.546092: step 20032, loss 0.367298, acc 0.8125\n",
      "2018-05-04T19:43:08.522853: step 20033, loss 0.133534, acc 0.9375\n",
      "2018-05-04T19:43:09.525020: step 20034, loss 0.2515, acc 0.859375\n",
      "2018-05-04T19:43:10.534936: step 20035, loss 0.168788, acc 0.90625\n",
      "2018-05-04T19:43:11.523840: step 20036, loss 0.196685, acc 0.9375\n",
      "2018-05-04T19:43:12.532116: step 20037, loss 0.200518, acc 0.890625\n",
      "2018-05-04T19:43:13.513358: step 20038, loss 0.319821, acc 0.859375\n",
      "2018-05-04T19:43:14.477842: step 20039, loss 0.403861, acc 0.875\n",
      "2018-05-04T19:43:15.499922: step 20040, loss 0.289974, acc 0.890625\n",
      "2018-05-04T19:43:16.562371: step 20041, loss 0.115646, acc 0.96875\n",
      "2018-05-04T19:43:17.557447: step 20042, loss 0.238991, acc 0.875\n",
      "2018-05-04T19:43:18.529309: step 20043, loss 0.194918, acc 0.953125\n",
      "2018-05-04T19:43:19.511816: step 20044, loss 0.187606, acc 0.921875\n",
      "2018-05-04T19:43:20.474470: step 20045, loss 0.300212, acc 0.90625\n",
      "2018-05-04T19:43:21.507091: step 20046, loss 0.228049, acc 0.9375\n",
      "2018-05-04T19:43:22.475157: step 20047, loss 0.215375, acc 0.921875\n",
      "2018-05-04T19:43:23.463938: step 20048, loss 0.266374, acc 0.890625\n",
      "2018-05-04T19:43:24.461038: step 20049, loss 0.370042, acc 0.875\n",
      "2018-05-04T19:43:25.431440: step 20050, loss 0.217819, acc 0.90625\n",
      "2018-05-04T19:43:26.403111: step 20051, loss 0.23486, acc 0.9375\n",
      "2018-05-04T19:43:27.371056: step 20052, loss 0.200282, acc 0.9375\n",
      "2018-05-04T19:43:28.318254: step 20053, loss 0.362361, acc 0.859375\n",
      "2018-05-04T19:43:29.355942: step 20054, loss 0.295633, acc 0.875\n",
      "2018-05-04T19:43:30.290660: step 20055, loss 0.403856, acc 0.859375\n",
      "2018-05-04T19:43:31.355609: step 20056, loss 0.259914, acc 0.921875\n",
      "2018-05-04T19:43:32.341754: step 20057, loss 0.29514, acc 0.828125\n",
      "2018-05-04T19:43:33.341999: step 20058, loss 0.292682, acc 0.875\n",
      "2018-05-04T19:43:34.357414: step 20059, loss 0.288317, acc 0.890625\n",
      "2018-05-04T19:43:35.382352: step 20060, loss 0.308699, acc 0.90625\n",
      "2018-05-04T19:43:36.423205: step 20061, loss 0.184611, acc 0.9375\n",
      "2018-05-04T19:43:37.447541: step 20062, loss 0.224981, acc 0.90625\n",
      "2018-05-04T19:43:38.459978: step 20063, loss 0.182088, acc 0.90625\n",
      "2018-05-04T19:43:39.460404: step 20064, loss 0.162147, acc 0.953125\n",
      "2018-05-04T19:43:40.433954: step 20065, loss 0.177104, acc 0.90625\n",
      "2018-05-04T19:43:41.467015: step 20066, loss 0.224636, acc 0.90625\n",
      "2018-05-04T19:43:42.427160: step 20067, loss 0.382815, acc 0.875\n",
      "2018-05-04T19:43:43.480068: step 20068, loss 0.288072, acc 0.890625\n",
      "2018-05-04T19:43:44.516270: step 20069, loss 0.327357, acc 0.90625\n",
      "2018-05-04T19:43:45.491647: step 20070, loss 0.395749, acc 0.84375\n",
      "2018-05-04T19:43:46.441545: step 20071, loss 0.364477, acc 0.828125\n",
      "2018-05-04T19:43:47.407942: step 20072, loss 0.170129, acc 0.921875\n",
      "2018-05-04T19:43:48.373751: step 20073, loss 0.207507, acc 0.921875\n",
      "2018-05-04T19:43:49.348562: step 20074, loss 0.374732, acc 0.890625\n",
      "2018-05-04T19:43:50.296340: step 20075, loss 0.209585, acc 0.9375\n",
      "2018-05-04T19:43:51.263548: step 20076, loss 0.181732, acc 0.953125\n",
      "2018-05-04T19:43:52.214214: step 20077, loss 0.266377, acc 0.875\n",
      "2018-05-04T19:43:53.193155: step 20078, loss 0.20818, acc 0.90625\n",
      "2018-05-04T19:43:54.181296: step 20079, loss 0.198135, acc 0.90625\n",
      "2018-05-04T19:43:55.151922: step 20080, loss 0.189239, acc 0.921875\n",
      "2018-05-04T19:43:56.098374: step 20081, loss 0.344274, acc 0.828125\n",
      "2018-05-04T19:43:57.067705: step 20082, loss 0.23492, acc 0.890625\n",
      "2018-05-04T19:43:58.013722: step 20083, loss 0.463833, acc 0.8125\n",
      "2018-05-04T19:43:58.969311: step 20084, loss 0.336551, acc 0.890625\n",
      "2018-05-04T19:43:59.911003: step 20085, loss 0.304722, acc 0.875\n",
      "2018-05-04T19:44:00.923609: step 20086, loss 0.154532, acc 0.953125\n",
      "2018-05-04T19:44:01.927106: step 20087, loss 0.165086, acc 0.953125\n",
      "2018-05-04T19:44:02.896347: step 20088, loss 0.325303, acc 0.875\n",
      "2018-05-04T19:44:03.887704: step 20089, loss 0.198739, acc 0.9375\n",
      "2018-05-04T19:44:04.842566: step 20090, loss 0.193697, acc 0.90625\n",
      "2018-05-04T19:44:05.814538: step 20091, loss 0.43098, acc 0.8125\n",
      "2018-05-04T19:44:06.783759: step 20092, loss 0.208686, acc 0.890625\n",
      "2018-05-04T19:44:07.734995: step 20093, loss 0.243338, acc 0.890625\n",
      "2018-05-04T19:44:08.679683: step 20094, loss 0.199085, acc 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T19:44:09.647874: step 20095, loss 0.37099, acc 0.84375\n",
      "2018-05-04T19:44:10.618084: step 20096, loss 0.294244, acc 0.859375\n",
      "2018-05-04T19:44:11.566714: step 20097, loss 0.312087, acc 0.890625\n",
      "2018-05-04T19:44:12.518915: step 20098, loss 0.458139, acc 0.734375\n",
      "2018-05-04T19:44:13.462022: step 20099, loss 0.312256, acc 0.859375\n",
      "2018-05-04T19:44:14.399215: step 20100, loss 0.37659, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T19:44:16.954120: step 20100, loss 0.222509, acc 0.93\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-20100\n",
      "\n",
      "2018-05-04T19:44:18.111020: step 20101, loss 0.41327, acc 0.875\n",
      "2018-05-04T19:44:19.111799: step 20102, loss 0.261888, acc 0.859375\n",
      "2018-05-04T19:44:20.107995: step 20103, loss 0.329854, acc 0.875\n",
      "2018-05-04T19:44:21.124291: step 20104, loss 0.264093, acc 0.890625\n",
      "2018-05-04T19:44:22.196858: step 20105, loss 0.250028, acc 0.875\n",
      "2018-05-04T19:44:23.227844: step 20106, loss 0.175947, acc 0.953125\n",
      "2018-05-04T19:44:24.205619: step 20107, loss 0.236711, acc 0.875\n",
      "2018-05-04T19:44:25.236957: step 20108, loss 0.189933, acc 0.953125\n",
      "2018-05-04T19:44:26.239514: step 20109, loss 0.18996, acc 0.953125\n",
      "2018-05-04T19:44:27.200921: step 20110, loss 0.172128, acc 0.953125\n",
      "2018-05-04T19:44:28.177856: step 20111, loss 0.238004, acc 0.875\n",
      "2018-05-04T19:44:29.265918: step 20112, loss 0.446056, acc 0.796875\n",
      "2018-05-04T19:44:30.219438: step 20113, loss 0.267889, acc 0.890625\n",
      "2018-05-04T19:44:31.213335: step 20114, loss 0.166918, acc 0.953125\n",
      "2018-05-04T19:44:32.181773: step 20115, loss 0.25289, acc 0.875\n",
      "2018-05-04T19:44:33.150504: step 20116, loss 0.289742, acc 0.90625\n",
      "2018-05-04T19:44:34.188188: step 20117, loss 0.430126, acc 0.859375\n",
      "2018-05-04T19:44:35.155428: step 20118, loss 0.214578, acc 0.9375\n",
      "2018-05-04T19:44:36.130957: step 20119, loss 0.213901, acc 0.90625\n",
      "2018-05-04T19:44:37.074422: step 20120, loss 0.186523, acc 0.921875\n",
      "2018-05-04T19:44:38.139587: step 20121, loss 0.16161, acc 0.953125\n",
      "2018-05-04T19:44:39.118603: step 20122, loss 0.23015, acc 0.921875\n",
      "2018-05-04T19:44:40.075780: step 20123, loss 0.245753, acc 0.90625\n",
      "2018-05-04T19:44:41.147146: step 20124, loss 0.292676, acc 0.84375\n",
      "2018-05-04T19:44:42.104572: step 20125, loss 0.294589, acc 0.84375\n",
      "2018-05-04T19:44:43.049925: step 20126, loss 0.202137, acc 0.90625\n",
      "2018-05-04T19:44:44.026768: step 20127, loss 0.177546, acc 0.953125\n",
      "2018-05-04T19:44:44.992859: step 20128, loss 0.354714, acc 0.875\n",
      "2018-05-04T19:44:45.955705: step 20129, loss 0.231578, acc 0.921875\n",
      "2018-05-04T19:44:46.929702: step 20130, loss 0.310135, acc 0.84375\n",
      "2018-05-04T19:44:47.906725: step 20131, loss 0.318835, acc 0.859375\n",
      "2018-05-04T19:44:48.875732: step 20132, loss 0.300117, acc 0.84375\n",
      "2018-05-04T19:44:49.840671: step 20133, loss 0.139495, acc 0.953125\n",
      "2018-05-04T19:44:50.808704: step 20134, loss 0.258454, acc 0.921875\n",
      "2018-05-04T19:44:51.843333: step 20135, loss 0.396292, acc 0.859375\n",
      "2018-05-04T19:44:52.883091: step 20136, loss 0.175489, acc 0.953125\n",
      "2018-05-04T19:44:53.853727: step 20137, loss 0.135785, acc 0.984375\n",
      "2018-05-04T19:44:54.820198: step 20138, loss 0.260983, acc 0.921875\n",
      "2018-05-04T19:44:55.784491: step 20139, loss 0.284511, acc 0.890625\n",
      "2018-05-04T19:44:56.781149: step 20140, loss 0.25767, acc 0.921875\n",
      "2018-05-04T19:44:57.814504: step 20141, loss 0.249602, acc 0.9375\n",
      "2018-05-04T19:44:58.806740: step 20142, loss 0.35369, acc 0.890625\n",
      "2018-05-04T19:44:59.779309: step 20143, loss 0.299008, acc 0.875\n",
      "2018-05-04T19:45:00.748095: step 20144, loss 0.21508, acc 0.90625\n",
      "2018-05-04T19:45:01.735899: step 20145, loss 0.236137, acc 0.890625\n",
      "2018-05-04T19:45:02.699287: step 20146, loss 0.359134, acc 0.8125\n",
      "2018-05-04T19:45:03.658246: step 20147, loss 0.34077, acc 0.828125\n",
      "2018-05-04T19:45:04.655364: step 20148, loss 0.339023, acc 0.84375\n",
      "2018-05-04T19:45:05.696178: step 20149, loss 0.313727, acc 0.875\n",
      "2018-05-04T19:45:06.656358: step 20150, loss 0.356045, acc 0.875\n",
      "2018-05-04T19:45:07.730957: step 20151, loss 0.213927, acc 0.921875\n",
      "2018-05-04T19:45:08.682741: step 20152, loss 0.207948, acc 0.890625\n",
      "2018-05-04T19:45:09.641092: step 20153, loss 0.248928, acc 0.90625\n",
      "2018-05-04T19:45:10.616039: step 20154, loss 0.205099, acc 0.890625\n",
      "2018-05-04T19:45:11.576214: step 20155, loss 0.306012, acc 0.8125\n",
      "2018-05-04T19:45:12.579547: step 20156, loss 0.374633, acc 0.84375\n",
      "2018-05-04T19:45:13.563903: step 20157, loss 0.295774, acc 0.875\n",
      "2018-05-04T19:45:14.555039: step 20158, loss 0.314524, acc 0.921875\n",
      "2018-05-04T19:45:15.541901: step 20159, loss 0.278246, acc 0.859375\n",
      "2018-05-04T19:45:16.551900: step 20160, loss 0.263787, acc 0.859375\n",
      "2018-05-04T19:45:17.594969: step 20161, loss 0.253089, acc 0.875\n",
      "2018-05-04T19:45:18.554366: step 20162, loss 0.145323, acc 0.953125\n",
      "2018-05-04T19:45:19.521641: step 20163, loss 0.333516, acc 0.859375\n",
      "2018-05-04T19:45:20.490801: step 20164, loss 0.204861, acc 0.921875\n",
      "2018-05-04T19:45:21.466192: step 20165, loss 0.232199, acc 0.90625\n",
      "2018-05-04T19:45:22.429484: step 20166, loss 0.263587, acc 0.875\n",
      "2018-05-04T19:45:23.395591: step 20167, loss 0.239425, acc 0.875\n",
      "2018-05-04T19:45:24.344417: step 20168, loss 0.218165, acc 0.875\n",
      "2018-05-04T19:45:25.341962: step 20169, loss 0.168857, acc 0.96875\n",
      "2018-05-04T19:45:26.391106: step 20170, loss 0.338477, acc 0.84375\n",
      "2018-05-04T19:45:27.349259: step 20171, loss 0.231757, acc 0.90625\n",
      "2018-05-04T19:45:28.310964: step 20172, loss 0.151727, acc 0.9375\n",
      "2018-05-04T19:45:29.259973: step 20173, loss 0.208506, acc 0.921875\n",
      "2018-05-04T19:45:30.207491: step 20174, loss 0.261669, acc 0.859375\n",
      "2018-05-04T19:45:31.180429: step 20175, loss 0.206638, acc 0.921875\n",
      "2018-05-04T19:45:32.137550: step 20176, loss 0.186393, acc 0.953125\n",
      "2018-05-04T19:45:33.154140: step 20177, loss 0.269889, acc 0.84375\n",
      "2018-05-04T19:45:34.193710: step 20178, loss 0.337805, acc 0.84375\n",
      "2018-05-04T19:45:35.135902: step 20179, loss 0.187957, acc 0.953125\n",
      "2018-05-04T19:45:36.185634: step 20180, loss 0.210684, acc 0.90625\n",
      "2018-05-04T19:45:37.133589: step 20181, loss 0.275181, acc 0.890625\n",
      "2018-05-04T19:45:38.082771: step 20182, loss 0.128113, acc 0.96875\n",
      "2018-05-04T19:45:39.052882: step 20183, loss 0.229288, acc 0.9375\n",
      "2018-05-04T19:45:40.011863: step 20184, loss 0.171706, acc 0.90625\n",
      "2018-05-04T19:45:40.969841: step 20185, loss 0.184555, acc 0.921875\n",
      "2018-05-04T19:45:41.941946: step 20186, loss 0.226714, acc 0.90625\n",
      "2018-05-04T19:45:42.907299: step 20187, loss 0.236324, acc 0.859375\n",
      "2018-05-04T19:45:43.898994: step 20188, loss 0.335256, acc 0.875\n",
      "2018-05-04T19:45:44.877936: step 20189, loss 0.235131, acc 0.890625\n",
      "2018-05-04T19:45:45.909685: step 20190, loss 0.281704, acc 0.875\n",
      "2018-05-04T19:45:46.869101: step 20191, loss 0.283158, acc 0.875\n",
      "2018-05-04T19:45:47.807949: step 20192, loss 0.20692, acc 0.921875\n",
      "2018-05-04T19:45:48.752610: step 20193, loss 0.239797, acc 0.90625\n",
      "2018-05-04T19:45:49.699571: step 20194, loss 0.228595, acc 0.890625\n",
      "2018-05-04T19:45:50.662542: step 20195, loss 0.276709, acc 0.890625\n",
      "2018-05-04T19:45:51.610876: step 20196, loss 0.264865, acc 0.875\n",
      "2018-05-04T19:45:52.555146: step 20197, loss 0.334413, acc 0.890625\n",
      "2018-05-04T19:45:53.511020: step 20198, loss 0.283316, acc 0.875\n",
      "2018-05-04T19:45:54.470054: step 20199, loss 0.263324, acc 0.90625\n",
      "2018-05-04T19:45:55.400058: step 20200, loss 0.226319, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T19:45:57.519493: step 20200, loss 0.22524, acc 0.92\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-20200\n",
      "\n",
      "2018-05-04T19:45:58.571487: step 20201, loss 0.280544, acc 0.875\n",
      "2018-05-04T19:45:59.611769: step 20202, loss 0.458615, acc 0.796875\n",
      "2018-05-04T19:46:00.551900: step 20203, loss 0.219423, acc 0.90625\n",
      "2018-05-04T19:46:01.540511: step 20204, loss 0.357389, acc 0.90625\n",
      "2018-05-04T19:46:02.473644: step 20205, loss 0.245672, acc 0.90625\n",
      "2018-05-04T19:46:03.422614: step 20206, loss 0.280911, acc 0.875\n",
      "2018-05-04T19:46:04.397737: step 20207, loss 0.256226, acc 0.875\n",
      "2018-05-04T19:46:05.373804: step 20208, loss 0.287397, acc 0.875\n",
      "2018-05-04T19:46:06.392880: step 20209, loss 0.29919, acc 0.890625\n",
      "2018-05-04T19:46:07.347969: step 20210, loss 0.295927, acc 0.875\n",
      "2018-05-04T19:46:08.300957: step 20211, loss 0.276738, acc 0.890625\n",
      "2018-05-04T19:46:09.264646: step 20212, loss 0.232373, acc 0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T19:46:10.199740: step 20213, loss 0.312495, acc 0.875\n",
      "2018-05-04T19:46:11.121379: step 20214, loss 0.329259, acc 0.875\n",
      "2018-05-04T19:46:12.070221: step 20215, loss 0.197713, acc 0.921875\n",
      "2018-05-04T19:46:13.012793: step 20216, loss 0.200634, acc 0.875\n",
      "2018-05-04T19:46:13.962950: step 20217, loss 0.28916, acc 0.890625\n",
      "2018-05-04T19:46:14.926638: step 20218, loss 0.191394, acc 0.921875\n",
      "2018-05-04T19:46:15.881910: step 20219, loss 0.160134, acc 0.9375\n",
      "2018-05-04T19:46:16.850229: step 20220, loss 0.178331, acc 0.9375\n",
      "2018-05-04T19:46:17.898807: step 20221, loss 0.148588, acc 0.9375\n",
      "2018-05-04T19:46:18.849610: step 20222, loss 0.187369, acc 0.921875\n",
      "2018-05-04T19:46:19.794533: step 20223, loss 0.301459, acc 0.890625\n",
      "2018-05-04T19:46:20.729496: step 20224, loss 0.228089, acc 0.90625\n",
      "2018-05-04T19:46:21.681900: step 20225, loss 0.353133, acc 0.84375\n",
      "2018-05-04T19:46:22.660340: step 20226, loss 0.308231, acc 0.875\n",
      "2018-05-04T19:46:23.624600: step 20227, loss 0.243687, acc 0.875\n",
      "2018-05-04T19:46:24.647263: step 20228, loss 0.281301, acc 0.890625\n",
      "2018-05-04T19:46:25.601767: step 20229, loss 0.16976, acc 0.953125\n",
      "2018-05-04T19:46:26.554157: step 20230, loss 0.237412, acc 0.890625\n",
      "2018-05-04T19:46:27.529828: step 20231, loss 0.205054, acc 0.921875\n",
      "2018-05-04T19:46:28.475836: step 20232, loss 0.270779, acc 0.90625\n",
      "2018-05-04T19:46:29.416525: step 20233, loss 0.21383, acc 0.890625\n",
      "2018-05-04T19:46:30.376761: step 20234, loss 0.265002, acc 0.859375\n",
      "2018-05-04T19:46:31.400583: step 20235, loss 0.23177, acc 0.9375\n",
      "2018-05-04T19:46:32.334797: step 20236, loss 0.336882, acc 0.875\n",
      "2018-05-04T19:46:33.348128: step 20237, loss 0.18044, acc 0.9375\n",
      "2018-05-04T19:46:34.371893: step 20238, loss 0.411672, acc 0.828125\n",
      "2018-05-04T19:46:35.397012: step 20239, loss 0.44926, acc 0.875\n",
      "2018-05-04T19:46:36.401025: step 20240, loss 0.243876, acc 0.890625\n",
      "2018-05-04T19:46:37.393039: step 20241, loss 0.221269, acc 0.875\n",
      "2018-05-04T19:46:38.354012: step 20242, loss 0.199244, acc 0.953125\n",
      "2018-05-04T19:46:39.317234: step 20243, loss 0.250512, acc 0.890625\n",
      "2018-05-04T19:46:40.287033: step 20244, loss 0.142244, acc 0.953125\n",
      "2018-05-04T19:46:41.257918: step 20245, loss 0.295215, acc 0.90625\n",
      "2018-05-04T19:46:42.228525: step 20246, loss 0.282228, acc 0.875\n",
      "2018-05-04T19:46:43.164271: step 20247, loss 0.256117, acc 0.875\n",
      "2018-05-04T19:46:44.117355: step 20248, loss 0.242628, acc 0.921875\n",
      "2018-05-04T19:46:45.062061: step 20249, loss 0.247736, acc 0.90625\n",
      "2018-05-04T19:46:46.016432: step 20250, loss 0.17243, acc 0.9375\n",
      "2018-05-04T19:46:47.041992: step 20251, loss 0.264485, acc 0.890625\n",
      "2018-05-04T19:46:48.060809: step 20252, loss 0.258186, acc 0.875\n",
      "2018-05-04T19:46:48.995504: step 20253, loss 0.363374, acc 0.859375\n",
      "2018-05-04T19:46:49.907764: step 20254, loss 0.185674, acc 0.90625\n",
      "2018-05-04T19:46:50.929017: step 20255, loss 0.313726, acc 0.859375\n",
      "2018-05-04T19:46:51.970544: step 20256, loss 0.282283, acc 0.890625\n",
      "2018-05-04T19:46:52.899122: step 20257, loss 0.144163, acc 0.96875\n",
      "2018-05-04T19:46:53.843819: step 20258, loss 0.178539, acc 0.953125\n",
      "2018-05-04T19:46:54.813987: step 20259, loss 0.171013, acc 0.9375\n",
      "2018-05-04T19:46:55.766789: step 20260, loss 0.173944, acc 0.90625\n",
      "2018-05-04T19:46:56.728923: step 20261, loss 0.259244, acc 0.875\n",
      "2018-05-04T19:46:57.692564: step 20262, loss 0.273124, acc 0.921875\n",
      "2018-05-04T19:46:58.632775: step 20263, loss 0.401687, acc 0.859375\n",
      "2018-05-04T19:46:59.573646: step 20264, loss 0.312583, acc 0.859375\n",
      "2018-05-04T19:47:00.518303: step 20265, loss 0.340033, acc 0.890625\n",
      "2018-05-04T19:47:01.503037: step 20266, loss 0.225535, acc 0.9375\n",
      "2018-05-04T19:47:02.435535: step 20267, loss 0.151301, acc 0.96875\n",
      "2018-05-04T19:47:03.396295: step 20268, loss 0.386778, acc 0.875\n",
      "2018-05-04T19:47:04.403205: step 20269, loss 0.407965, acc 0.875\n",
      "2018-05-04T19:47:05.369568: step 20270, loss 0.254663, acc 0.90625\n",
      "2018-05-04T19:47:06.285158: step 20271, loss 0.264835, acc 0.890625\n",
      "2018-05-04T19:47:07.220184: step 20272, loss 0.224067, acc 0.90625\n",
      "2018-05-04T19:47:08.178325: step 20273, loss 0.408142, acc 0.796875\n",
      "2018-05-04T19:47:09.145811: step 20274, loss 0.22952, acc 0.875\n",
      "2018-05-04T19:47:10.108817: step 20275, loss 0.355625, acc 0.875\n",
      "2018-05-04T19:47:11.130254: step 20276, loss 0.30564, acc 0.875\n",
      "2018-05-04T19:47:12.118696: step 20277, loss 0.371653, acc 0.828125\n",
      "2018-05-04T19:47:13.128721: step 20278, loss 0.382166, acc 0.84375\n",
      "2018-05-04T19:47:14.058118: step 20279, loss 0.391875, acc 0.84375\n",
      "2018-05-04T19:47:14.990306: step 20280, loss 0.275966, acc 0.90625\n",
      "2018-05-04T19:47:15.909901: step 20281, loss 0.288879, acc 0.921875\n",
      "2018-05-04T19:47:16.924661: step 20282, loss 0.293842, acc 0.84375\n",
      "2018-05-04T19:47:17.881223: step 20283, loss 0.26744, acc 0.90625\n",
      "2018-05-04T19:47:18.896908: step 20284, loss 0.167638, acc 0.96875\n",
      "2018-05-04T19:47:19.842988: step 20285, loss 0.239317, acc 0.90625\n",
      "2018-05-04T19:47:20.785388: step 20286, loss 0.197999, acc 0.90625\n",
      "2018-05-04T19:47:21.771331: step 20287, loss 0.356464, acc 0.890625\n",
      "2018-05-04T19:47:22.692135: step 20288, loss 0.311143, acc 0.875\n",
      "2018-05-04T19:47:23.693606: step 20289, loss 0.179064, acc 0.9375\n",
      "2018-05-04T19:47:24.638146: step 20290, loss 0.229392, acc 0.9375\n",
      "2018-05-04T19:47:25.603456: step 20291, loss 0.365596, acc 0.875\n",
      "2018-05-04T19:47:26.544856: step 20292, loss 0.356515, acc 0.828125\n",
      "2018-05-04T19:47:27.500997: step 20293, loss 0.399236, acc 0.84375\n",
      "2018-05-04T19:47:28.466754: step 20294, loss 0.18832, acc 0.9375\n",
      "2018-05-04T19:47:29.445039: step 20295, loss 0.256209, acc 0.84375\n",
      "2018-05-04T19:47:30.386464: step 20296, loss 0.308029, acc 0.921875\n",
      "2018-05-04T19:47:31.352035: step 20297, loss 0.123433, acc 0.984375\n",
      "2018-05-04T19:47:32.319920: step 20298, loss 0.295224, acc 0.859375\n",
      "2018-05-04T19:47:33.364195: step 20299, loss 0.25308, acc 0.90625\n",
      "2018-05-04T19:47:34.377303: step 20300, loss 0.215283, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T19:47:37.363655: step 20300, loss 0.236953, acc 0.912\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-20300\n",
      "\n",
      "2018-05-04T19:47:38.434845: step 20301, loss 0.201887, acc 0.9375\n",
      "2018-05-04T19:47:39.443421: step 20302, loss 0.255118, acc 0.875\n",
      "2018-05-04T19:47:40.429285: step 20303, loss 0.239028, acc 0.859375\n",
      "2018-05-04T19:47:41.525850: step 20304, loss 0.258609, acc 0.890625\n",
      "2018-05-04T19:47:42.532470: step 20305, loss 0.237599, acc 0.875\n",
      "2018-05-04T19:47:43.583049: step 20306, loss 0.332525, acc 0.890625\n",
      "2018-05-04T19:47:44.585659: step 20307, loss 0.309182, acc 0.875\n",
      "2018-05-04T19:47:45.595213: step 20308, loss 0.290271, acc 0.859375\n",
      "2018-05-04T19:47:46.578403: step 20309, loss 0.209025, acc 0.921875\n",
      "2018-05-04T19:47:47.572012: step 20310, loss 0.180095, acc 0.9375\n",
      "2018-05-04T19:47:48.531689: step 20311, loss 0.16987, acc 0.9375\n",
      "2018-05-04T19:47:49.508077: step 20312, loss 0.317731, acc 0.875\n",
      "2018-05-04T19:47:50.483592: step 20313, loss 0.256119, acc 0.921875\n",
      "2018-05-04T19:47:51.449322: step 20314, loss 0.239709, acc 0.90625\n",
      "2018-05-04T19:47:52.417056: step 20315, loss 0.269682, acc 0.96875\n",
      "2018-05-04T19:47:53.399271: step 20316, loss 0.188181, acc 0.9375\n",
      "2018-05-04T19:47:54.457172: step 20317, loss 0.371292, acc 0.828125\n",
      "2018-05-04T19:47:55.422664: step 20318, loss 0.291699, acc 0.90625\n",
      "2018-05-04T19:47:56.385364: step 20319, loss 0.38407, acc 0.828125\n",
      "2018-05-04T19:47:57.456605: step 20320, loss 0.270345, acc 0.859375\n",
      "2018-05-04T19:47:58.445289: step 20321, loss 0.249134, acc 0.90625\n",
      "2018-05-04T19:47:59.436303: step 20322, loss 0.32741, acc 0.84375\n",
      "2018-05-04T19:48:00.424495: step 20323, loss 0.239328, acc 0.875\n",
      "2018-05-04T19:48:01.472637: step 20324, loss 0.309332, acc 0.875\n",
      "2018-05-04T19:48:02.477027: step 20325, loss 0.258621, acc 0.890625\n",
      "2018-05-04T19:48:03.483593: step 20326, loss 0.218734, acc 0.90625\n",
      "2018-05-04T19:48:04.505234: step 20327, loss 0.212807, acc 0.921875\n",
      "2018-05-04T19:48:05.514227: step 20328, loss 0.36946, acc 0.875\n",
      "2018-05-04T19:48:06.526177: step 20329, loss 0.325146, acc 0.859375\n",
      "2018-05-04T19:48:07.514201: step 20330, loss 0.246115, acc 0.890625\n",
      "2018-05-04T19:48:08.484919: step 20331, loss 0.168785, acc 0.96875\n",
      "2018-05-04T19:48:09.465697: step 20332, loss 0.314544, acc 0.90625\n",
      "2018-05-04T19:48:10.451759: step 20333, loss 0.181826, acc 0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T19:48:11.427398: step 20334, loss 0.444665, acc 0.84375\n",
      "2018-05-04T19:48:12.416172: step 20335, loss 0.128, acc 0.96875\n",
      "2018-05-04T19:48:13.410734: step 20336, loss 0.240652, acc 0.90625\n",
      "2018-05-04T19:48:14.494160: step 20337, loss 0.233511, acc 0.890625\n",
      "2018-05-04T19:48:15.455233: step 20338, loss 0.216574, acc 0.9375\n",
      "2018-05-04T19:48:16.445376: step 20339, loss 0.319566, acc 0.875\n",
      "2018-05-04T19:48:17.423784: step 20340, loss 0.356164, acc 0.890625\n",
      "2018-05-04T19:48:18.406878: step 20341, loss 0.36069, acc 0.828125\n",
      "2018-05-04T19:48:19.411223: step 20342, loss 0.268751, acc 0.875\n",
      "2018-05-04T19:48:20.477255: step 20343, loss 0.198752, acc 0.9375\n",
      "2018-05-04T19:48:21.455185: step 20344, loss 0.255684, acc 0.875\n",
      "2018-05-04T19:48:22.432247: step 20345, loss 0.365789, acc 0.796875\n",
      "2018-05-04T19:48:23.405332: step 20346, loss 0.264734, acc 0.875\n",
      "2018-05-04T19:48:24.442400: step 20347, loss 0.279093, acc 0.953125\n",
      "2018-05-04T19:48:25.392058: step 20348, loss 0.316002, acc 0.84375\n",
      "2018-05-04T19:48:26.341746: step 20349, loss 0.205021, acc 0.953125\n",
      "2018-05-04T19:48:27.331614: step 20350, loss 0.294637, acc 0.859375\n",
      "2018-05-04T19:48:28.271875: step 20351, loss 0.233181, acc 0.921875\n",
      "2018-05-04T19:48:29.237163: step 20352, loss 0.246687, acc 0.875\n",
      "2018-05-04T19:48:30.194744: step 20353, loss 0.164426, acc 0.921875\n",
      "2018-05-04T19:48:31.211143: step 20354, loss 0.296064, acc 0.875\n",
      "2018-05-04T19:48:32.190364: step 20355, loss 0.29291, acc 0.890625\n",
      "2018-05-04T19:48:33.178375: step 20356, loss 0.176127, acc 0.921875\n",
      "2018-05-04T19:48:34.198633: step 20357, loss 0.156385, acc 0.953125\n",
      "2018-05-04T19:48:35.238309: step 20358, loss 0.178212, acc 0.90625\n",
      "2018-05-04T19:48:36.214215: step 20359, loss 0.168015, acc 0.953125\n",
      "2018-05-04T19:48:37.190776: step 20360, loss 0.164964, acc 0.9375\n",
      "2018-05-04T19:48:38.178699: step 20361, loss 0.225454, acc 0.859375\n",
      "2018-05-04T19:48:39.145953: step 20362, loss 0.240513, acc 0.890625\n",
      "2018-05-04T19:48:40.167249: step 20363, loss 0.193932, acc 0.90625\n",
      "2018-05-04T19:48:41.113145: step 20364, loss 0.241311, acc 0.90625\n",
      "2018-05-04T19:48:42.156502: step 20365, loss 0.295969, acc 0.84375\n",
      "2018-05-04T19:48:43.113190: step 20366, loss 0.285785, acc 0.9375\n",
      "2018-05-04T19:48:44.073873: step 20367, loss 0.337417, acc 0.875\n",
      "2018-05-04T19:48:45.016707: step 20368, loss 0.253486, acc 0.921875\n",
      "2018-05-04T19:48:45.993247: step 20369, loss 0.376616, acc 0.875\n",
      "2018-05-04T19:48:46.940025: step 20370, loss 0.274399, acc 0.890625\n",
      "2018-05-04T19:48:47.912256: step 20371, loss 0.239857, acc 0.921875\n",
      "2018-05-04T19:48:48.872430: step 20372, loss 0.208974, acc 0.875\n",
      "2018-05-04T19:48:49.917500: step 20373, loss 0.145295, acc 0.953125\n",
      "2018-05-04T19:48:50.880041: step 20374, loss 0.200333, acc 0.90625\n",
      "2018-05-04T19:48:51.828562: step 20375, loss 0.283553, acc 0.890625\n",
      "2018-05-04T19:48:52.779413: step 20376, loss 0.234592, acc 0.90625\n",
      "2018-05-04T19:48:53.744877: step 20377, loss 0.269872, acc 0.890625\n",
      "2018-05-04T19:48:54.800989: step 20378, loss 0.386808, acc 0.84375\n",
      "2018-05-04T19:48:55.836383: step 20379, loss 0.216147, acc 0.90625\n",
      "2018-05-04T19:48:56.790699: step 20380, loss 0.197451, acc 0.9375\n",
      "2018-05-04T19:48:57.739309: step 20381, loss 0.277678, acc 0.875\n",
      "2018-05-04T19:48:58.677535: step 20382, loss 0.18033, acc 0.9375\n",
      "2018-05-04T19:48:59.642202: step 20383, loss 0.196893, acc 0.9375\n",
      "2018-05-04T19:49:00.642017: step 20384, loss 0.219169, acc 0.90625\n",
      "2018-05-04T19:49:01.688979: step 20385, loss 0.314062, acc 0.859375\n",
      "2018-05-04T19:49:02.659529: step 20386, loss 0.175953, acc 0.921875\n",
      "2018-05-04T19:49:03.642318: step 20387, loss 0.176822, acc 0.921875\n",
      "2018-05-04T19:49:04.693362: step 20388, loss 0.275373, acc 0.875\n",
      "2018-05-04T19:49:05.680972: step 20389, loss 0.31675, acc 0.90625\n",
      "2018-05-04T19:49:06.654404: step 20390, loss 0.259116, acc 0.90625\n",
      "2018-05-04T19:49:07.597589: step 20391, loss 0.404486, acc 0.859375\n",
      "2018-05-04T19:49:08.530910: step 20392, loss 0.22772, acc 0.890625\n",
      "2018-05-04T19:49:09.482304: step 20393, loss 0.419222, acc 0.84375\n",
      "2018-05-04T19:49:10.427051: step 20394, loss 0.286161, acc 0.859375\n",
      "2018-05-04T19:49:11.374271: step 20395, loss 0.294474, acc 0.875\n",
      "2018-05-04T19:49:12.313037: step 20396, loss 0.273438, acc 0.875\n",
      "2018-05-04T19:49:13.262250: step 20397, loss 0.171363, acc 0.921875\n",
      "2018-05-04T19:49:14.216207: step 20398, loss 0.228285, acc 0.890625\n",
      "2018-05-04T19:49:15.157377: step 20399, loss 0.248566, acc 0.921875\n",
      "2018-05-04T19:49:16.117795: step 20400, loss 0.280283, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T19:49:18.580506: step 20400, loss 0.233681, acc 0.92\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-20400\n",
      "\n",
      "2018-05-04T19:49:19.738850: step 20401, loss 0.265698, acc 0.890625\n",
      "2018-05-04T19:49:20.732545: step 20402, loss 0.270185, acc 0.875\n",
      "2018-05-04T19:49:21.734987: step 20403, loss 0.301474, acc 0.90625\n",
      "2018-05-04T19:49:22.804269: step 20404, loss 0.276634, acc 0.875\n",
      "2018-05-04T19:49:23.815570: step 20405, loss 0.197158, acc 0.9375\n",
      "2018-05-04T19:49:24.870787: step 20406, loss 0.21417, acc 0.90625\n",
      "2018-05-04T19:49:25.840344: step 20407, loss 0.341497, acc 0.828125\n",
      "2018-05-04T19:49:26.840853: step 20408, loss 0.453002, acc 0.84375\n",
      "2018-05-04T19:49:27.796766: step 20409, loss 0.345174, acc 0.84375\n",
      "2018-05-04T19:49:28.765325: step 20410, loss 0.194122, acc 0.921875\n",
      "2018-05-04T19:49:29.793163: step 20411, loss 0.185653, acc 0.953125\n",
      "2018-05-04T19:49:30.774165: step 20412, loss 0.177435, acc 0.953125\n",
      "2018-05-04T19:49:31.717675: step 20413, loss 0.171522, acc 0.9375\n",
      "2018-05-04T19:49:32.687992: step 20414, loss 0.357577, acc 0.828125\n",
      "2018-05-04T19:49:33.704973: step 20415, loss 0.241882, acc 0.84375\n",
      "2018-05-04T19:49:34.757768: step 20416, loss 0.356456, acc 0.84375\n",
      "2018-05-04T19:49:35.802900: step 20417, loss 0.281786, acc 0.921875\n",
      "2018-05-04T19:49:36.884566: step 20418, loss 0.336888, acc 0.890625\n",
      "2018-05-04T19:49:37.899122: step 20419, loss 0.312402, acc 0.875\n",
      "2018-05-04T19:49:38.927110: step 20420, loss 0.433899, acc 0.828125\n",
      "2018-05-04T19:49:39.919794: step 20421, loss 0.224448, acc 0.9375\n",
      "2018-05-04T19:49:40.916701: step 20422, loss 0.214585, acc 0.890625\n",
      "2018-05-04T19:49:41.880543: step 20423, loss 0.387837, acc 0.8125\n",
      "2018-05-04T19:49:42.884704: step 20424, loss 0.208282, acc 0.890625\n",
      "2018-05-04T19:49:43.905219: step 20425, loss 0.238819, acc 0.90625\n",
      "2018-05-04T19:49:44.918752: step 20426, loss 0.315645, acc 0.84375\n",
      "2018-05-04T19:49:45.939483: step 20427, loss 0.256143, acc 0.859375\n",
      "2018-05-04T19:49:46.914902: step 20428, loss 0.209137, acc 0.921875\n",
      "2018-05-04T19:49:47.968902: step 20429, loss 0.323013, acc 0.84375\n",
      "2018-05-04T19:49:48.954165: step 20430, loss 0.25301, acc 0.890625\n",
      "2018-05-04T19:49:49.920986: step 20431, loss 0.273258, acc 0.84375\n",
      "2018-05-04T19:49:50.896511: step 20432, loss 0.309971, acc 0.875\n",
      "2018-05-04T19:49:51.882647: step 20433, loss 0.32481, acc 0.921875\n",
      "2018-05-04T19:49:52.864453: step 20434, loss 0.174999, acc 0.953125\n",
      "2018-05-04T19:49:53.836891: step 20435, loss 0.20137, acc 0.921875\n",
      "2018-05-04T19:49:54.821903: step 20436, loss 0.255658, acc 0.875\n",
      "2018-05-04T19:49:55.863183: step 20437, loss 0.302342, acc 0.875\n",
      "2018-05-04T19:49:56.823190: step 20438, loss 0.362378, acc 0.8125\n",
      "2018-05-04T19:49:57.797184: step 20439, loss 0.417356, acc 0.875\n",
      "2018-05-04T19:49:58.749615: step 20440, loss 0.326888, acc 0.875\n",
      "2018-05-04T19:49:59.722302: step 20441, loss 0.225932, acc 0.921875\n",
      "2018-05-04T19:50:00.688230: step 20442, loss 0.3006, acc 0.859375\n",
      "2018-05-04T19:50:01.648271: step 20443, loss 0.303084, acc 0.875\n",
      "2018-05-04T19:50:02.677678: step 20444, loss 0.22588, acc 0.875\n",
      "2018-05-04T19:50:03.668504: step 20445, loss 0.173352, acc 0.96875\n",
      "2018-05-04T19:50:04.651121: step 20446, loss 0.290905, acc 0.890625\n",
      "2018-05-04T19:50:05.628570: step 20447, loss 0.339953, acc 0.84375\n",
      "2018-05-04T19:50:06.606247: step 20448, loss 0.22806, acc 0.875\n",
      "2018-05-04T19:50:07.589883: step 20449, loss 0.347383, acc 0.84375\n",
      "2018-05-04T19:50:08.555536: step 20450, loss 0.415052, acc 0.84375\n",
      "2018-05-04T19:50:09.535952: step 20451, loss 0.277961, acc 0.921875\n",
      "2018-05-04T19:50:10.510093: step 20452, loss 0.258985, acc 0.90625\n",
      "2018-05-04T19:50:11.569697: step 20453, loss 0.282369, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T19:50:12.567909: step 20454, loss 0.150133, acc 0.9375\n",
      "2018-05-04T19:50:13.536404: step 20455, loss 0.370736, acc 0.828125\n",
      "2018-05-04T19:50:14.523360: step 20456, loss 0.219739, acc 0.921875\n",
      "2018-05-04T19:50:15.516843: step 20457, loss 0.137056, acc 0.96875\n",
      "2018-05-04T19:50:16.492206: step 20458, loss 0.214987, acc 0.921875\n",
      "2018-05-04T19:50:17.456062: step 20459, loss 0.232035, acc 0.921875\n",
      "2018-05-04T19:50:18.408049: step 20460, loss 0.294831, acc 0.890625\n",
      "2018-05-04T19:50:19.435567: step 20461, loss 0.332693, acc 0.875\n",
      "2018-05-04T19:50:20.389730: step 20462, loss 0.195729, acc 0.875\n",
      "2018-05-04T19:50:21.333419: step 20463, loss 0.361481, acc 0.859375\n",
      "2018-05-04T19:50:22.283487: step 20464, loss 0.258049, acc 0.9375\n",
      "2018-05-04T19:50:23.232193: step 20465, loss 0.241423, acc 0.921875\n",
      "2018-05-04T19:50:24.220499: step 20466, loss 0.284933, acc 0.890625\n",
      "2018-05-04T19:50:25.198059: step 20467, loss 0.26593, acc 0.859375\n",
      "2018-05-04T19:50:26.150610: step 20468, loss 0.292, acc 0.875\n",
      "2018-05-04T19:50:27.111660: step 20469, loss 0.210481, acc 0.921875\n",
      "2018-05-04T19:50:28.071536: step 20470, loss 0.248815, acc 0.9375\n",
      "2018-05-04T19:50:29.022510: step 20471, loss 0.293344, acc 0.90625\n",
      "2018-05-04T19:50:29.964318: step 20472, loss 0.337807, acc 0.828125\n",
      "2018-05-04T19:50:30.925529: step 20473, loss 0.330361, acc 0.84375\n",
      "2018-05-04T19:50:31.921661: step 20474, loss 0.153404, acc 0.953125\n",
      "2018-05-04T19:50:32.944249: step 20475, loss 0.260857, acc 0.875\n",
      "2018-05-04T19:50:33.914500: step 20476, loss 0.296429, acc 0.875\n",
      "2018-05-04T19:50:34.880933: step 20477, loss 0.276973, acc 0.875\n",
      "2018-05-04T19:50:35.851658: step 20478, loss 0.359211, acc 0.828125\n",
      "2018-05-04T19:50:36.879461: step 20479, loss 0.206624, acc 0.90625\n",
      "2018-05-04T19:50:37.825403: step 20480, loss 0.248876, acc 0.9375\n",
      "2018-05-04T19:50:38.785712: step 20481, loss 0.187957, acc 0.90625\n",
      "2018-05-04T19:50:39.719720: step 20482, loss 0.299711, acc 0.90625\n",
      "2018-05-04T19:50:40.665973: step 20483, loss 0.140527, acc 0.953125\n",
      "2018-05-04T19:50:41.616639: step 20484, loss 0.213009, acc 0.90625\n",
      "2018-05-04T19:50:42.576725: step 20485, loss 0.250295, acc 0.890625\n",
      "2018-05-04T19:50:43.528721: step 20486, loss 0.347938, acc 0.875\n",
      "2018-05-04T19:50:44.489616: step 20487, loss 0.298148, acc 0.875\n",
      "2018-05-04T19:50:45.476022: step 20488, loss 0.184874, acc 0.921875\n",
      "2018-05-04T19:50:46.430949: step 20489, loss 0.197658, acc 0.90625\n",
      "2018-05-04T19:50:47.367738: step 20490, loss 0.200352, acc 0.9375\n",
      "2018-05-04T19:50:48.357779: step 20491, loss 0.251619, acc 0.859375\n",
      "2018-05-04T19:50:49.354325: step 20492, loss 0.391388, acc 0.859375\n",
      "2018-05-04T19:50:50.316633: step 20493, loss 0.204352, acc 0.9375\n",
      "2018-05-04T19:50:51.274677: step 20494, loss 0.240649, acc 0.859375\n",
      "2018-05-04T19:50:52.226340: step 20495, loss 0.245297, acc 0.921875\n",
      "2018-05-04T19:50:53.169620: step 20496, loss 0.368608, acc 0.875\n",
      "2018-05-04T19:50:54.124090: step 20497, loss 0.258645, acc 0.90625\n",
      "2018-05-04T19:50:55.060920: step 20498, loss 0.368876, acc 0.90625\n",
      "2018-05-04T19:50:55.993853: step 20499, loss 0.296928, acc 0.875\n",
      "2018-05-04T19:50:56.933237: step 20500, loss 0.314993, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T19:50:59.174926: step 20500, loss 0.223653, acc 0.926\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-20500\n",
      "\n",
      "2018-05-04T19:51:00.284071: step 20501, loss 0.24376, acc 0.875\n",
      "2018-05-04T19:51:01.275358: step 20502, loss 0.248717, acc 0.9375\n",
      "2018-05-04T19:51:02.302828: step 20503, loss 0.253633, acc 0.875\n",
      "2018-05-04T19:51:03.319948: step 20504, loss 0.334205, acc 0.859375\n",
      "2018-05-04T19:51:04.415663: step 20505, loss 0.383671, acc 0.84375\n",
      "2018-05-04T19:51:05.432860: step 20506, loss 0.226052, acc 0.90625\n",
      "2018-05-04T19:51:06.451304: step 20507, loss 0.21627, acc 0.921875\n",
      "2018-05-04T19:51:07.411088: step 20508, loss 0.371239, acc 0.921875\n",
      "2018-05-04T19:51:08.448313: step 20509, loss 0.382053, acc 0.84375\n",
      "2018-05-04T19:51:09.437548: step 20510, loss 0.20134, acc 0.90625\n",
      "2018-05-04T19:51:10.394791: step 20511, loss 0.170365, acc 0.953125\n",
      "2018-05-04T19:51:11.472747: step 20512, loss 0.153327, acc 0.953125\n",
      "2018-05-04T19:51:12.427444: step 20513, loss 0.32829, acc 0.84375\n",
      "2018-05-04T19:51:13.386549: step 20514, loss 0.243046, acc 0.90625\n",
      "2018-05-04T19:51:14.359713: step 20515, loss 0.177271, acc 0.953125\n",
      "2018-05-04T19:51:15.322770: step 20516, loss 0.252128, acc 0.90625\n",
      "2018-05-04T19:51:16.295006: step 20517, loss 0.297295, acc 0.875\n",
      "2018-05-04T19:51:17.334273: step 20518, loss 0.214928, acc 0.90625\n",
      "2018-05-04T19:51:18.304953: step 20519, loss 0.390555, acc 0.828125\n",
      "2018-05-04T19:51:19.306171: step 20520, loss 0.259918, acc 0.9375\n",
      "2018-05-04T19:51:20.289757: step 20521, loss 0.177893, acc 0.921875\n",
      "2018-05-04T19:51:21.265475: step 20522, loss 0.278769, acc 0.84375\n",
      "2018-05-04T19:51:22.226382: step 20523, loss 0.202164, acc 0.90625\n",
      "2018-05-04T19:51:23.210945: step 20524, loss 0.276277, acc 0.859375\n",
      "2018-05-04T19:51:24.233424: step 20525, loss 0.316264, acc 0.859375\n",
      "2018-05-04T19:51:25.212349: step 20526, loss 0.235988, acc 0.875\n",
      "2018-05-04T19:51:26.209937: step 20527, loss 0.149223, acc 0.9375\n",
      "2018-05-04T19:51:27.185307: step 20528, loss 0.313565, acc 0.84375\n",
      "2018-05-04T19:51:28.181291: step 20529, loss 0.13964, acc 0.96875\n",
      "2018-05-04T19:51:29.156150: step 20530, loss 0.376323, acc 0.84375\n",
      "2018-05-04T19:51:30.136782: step 20531, loss 0.317709, acc 0.859375\n",
      "2018-05-04T19:51:31.123251: step 20532, loss 0.248224, acc 0.875\n",
      "2018-05-04T19:51:32.145972: step 20533, loss 0.265002, acc 0.90625\n",
      "2018-05-04T19:51:33.123690: step 20534, loss 0.270472, acc 0.875\n",
      "2018-05-04T19:51:34.110396: step 20535, loss 0.294776, acc 0.90625\n",
      "2018-05-04T19:51:35.079793: step 20536, loss 0.19498, acc 0.90625\n",
      "2018-05-04T19:51:36.034097: step 20537, loss 0.215368, acc 0.9375\n",
      "2018-05-04T19:51:37.027646: step 20538, loss 0.35348, acc 0.875\n",
      "2018-05-04T19:51:37.988838: step 20539, loss 0.220696, acc 0.859375\n",
      "2018-05-04T19:51:38.966515: step 20540, loss 0.296734, acc 0.921875\n",
      "2018-05-04T19:51:39.904671: step 20541, loss 0.270874, acc 0.9375\n",
      "2018-05-04T19:51:40.893685: step 20542, loss 0.324591, acc 0.84375\n",
      "2018-05-04T19:51:41.855504: step 20543, loss 0.337566, acc 0.84375\n",
      "2018-05-04T19:51:42.828453: step 20544, loss 0.292235, acc 0.859375\n",
      "2018-05-04T19:51:43.790526: step 20545, loss 0.298736, acc 0.890625\n",
      "2018-05-04T19:51:44.780753: step 20546, loss 0.296233, acc 0.84375\n",
      "2018-05-04T19:51:45.782902: step 20547, loss 0.236843, acc 0.875\n",
      "2018-05-04T19:51:46.778748: step 20548, loss 0.258693, acc 0.90625\n",
      "2018-05-04T19:51:47.803718: step 20549, loss 0.222015, acc 0.90625\n",
      "2018-05-04T19:51:48.764397: step 20550, loss 0.185204, acc 0.921875\n",
      "2018-05-04T19:51:49.760774: step 20551, loss 0.165919, acc 0.9375\n",
      "2018-05-04T19:51:50.742020: step 20552, loss 0.308852, acc 0.859375\n",
      "2018-05-04T19:51:51.801862: step 20553, loss 0.302448, acc 0.90625\n",
      "2018-05-04T19:51:52.853466: step 20554, loss 0.216021, acc 0.890625\n",
      "2018-05-04T19:51:53.786063: step 20555, loss 0.195031, acc 0.875\n",
      "2018-05-04T19:51:54.723950: step 20556, loss 0.254799, acc 0.875\n",
      "2018-05-04T19:51:55.690535: step 20557, loss 0.356714, acc 0.890625\n",
      "2018-05-04T19:51:56.659016: step 20558, loss 0.401786, acc 0.796875\n",
      "2018-05-04T19:51:57.627823: step 20559, loss 0.445543, acc 0.78125\n",
      "2018-05-04T19:51:58.584534: step 20560, loss 0.211945, acc 0.9375\n",
      "2018-05-04T19:51:59.552558: step 20561, loss 0.300806, acc 0.84375\n",
      "2018-05-04T19:52:00.517553: step 20562, loss 0.417317, acc 0.84375\n",
      "2018-05-04T19:52:01.471313: step 20563, loss 0.316289, acc 0.890625\n",
      "2018-05-04T19:52:02.426635: step 20564, loss 0.350116, acc 0.859375\n",
      "2018-05-04T19:52:03.371108: step 20565, loss 0.324769, acc 0.875\n",
      "2018-05-04T19:52:04.346525: step 20566, loss 0.145831, acc 0.9375\n",
      "2018-05-04T19:52:05.290640: step 20567, loss 0.333442, acc 0.859375\n",
      "2018-05-04T19:52:06.244478: step 20568, loss 0.234614, acc 0.890625\n",
      "2018-05-04T19:52:07.206946: step 20569, loss 0.35388, acc 0.875\n",
      "2018-05-04T19:52:08.158680: step 20570, loss 0.371398, acc 0.8125\n",
      "2018-05-04T19:52:09.129227: step 20571, loss 0.245013, acc 0.875\n",
      "2018-05-04T19:52:10.098324: step 20572, loss 0.234894, acc 0.890625\n",
      "2018-05-04T19:52:11.063625: step 20573, loss 0.262482, acc 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T19:52:12.043246: step 20574, loss 0.172408, acc 0.921875\n",
      "2018-05-04T19:52:13.057567: step 20575, loss 0.132395, acc 0.9375\n",
      "2018-05-04T19:52:14.038405: step 20576, loss 0.422824, acc 0.765625\n",
      "2018-05-04T19:52:15.033227: step 20577, loss 0.179264, acc 0.921875\n",
      "2018-05-04T19:52:16.002929: step 20578, loss 0.292579, acc 0.875\n",
      "2018-05-04T19:52:16.980616: step 20579, loss 0.325219, acc 0.890625\n",
      "2018-05-04T19:52:17.933332: step 20580, loss 0.264744, acc 0.875\n",
      "2018-05-04T19:52:18.892430: step 20581, loss 0.244856, acc 0.890625\n",
      "2018-05-04T19:52:19.922662: step 20582, loss 0.29358, acc 0.921875\n",
      "2018-05-04T19:52:20.957442: step 20583, loss 0.179786, acc 0.921875\n",
      "2018-05-04T19:52:21.992850: step 20584, loss 0.272228, acc 0.90625\n",
      "2018-05-04T19:52:22.942183: step 20585, loss 0.40171, acc 0.90625\n",
      "2018-05-04T19:52:23.886405: step 20586, loss 0.212977, acc 0.890625\n",
      "2018-05-04T19:52:24.823576: step 20587, loss 0.302929, acc 0.859375\n",
      "2018-05-04T19:52:25.748779: step 20588, loss 0.135541, acc 0.96875\n",
      "2018-05-04T19:52:26.761504: step 20589, loss 0.22284, acc 0.90625\n",
      "2018-05-04T19:52:27.705678: step 20590, loss 0.299179, acc 0.859375\n",
      "2018-05-04T19:52:28.662335: step 20591, loss 0.156516, acc 0.90625\n",
      "2018-05-04T19:52:29.607003: step 20592, loss 0.232119, acc 0.9375\n",
      "2018-05-04T19:52:30.561558: step 20593, loss 0.275575, acc 0.890625\n",
      "2018-05-04T19:52:31.511409: step 20594, loss 0.227459, acc 0.9375\n",
      "2018-05-04T19:52:32.499351: step 20595, loss 0.227728, acc 0.90625\n",
      "2018-05-04T19:52:33.533316: step 20596, loss 0.163083, acc 0.921875\n",
      "2018-05-04T19:52:34.583093: step 20597, loss 0.379549, acc 0.84375\n",
      "2018-05-04T19:52:35.608203: step 20598, loss 0.195818, acc 0.90625\n",
      "2018-05-04T19:52:36.622684: step 20599, loss 0.261987, acc 0.90625\n",
      "2018-05-04T19:52:37.590651: step 20600, loss 0.247651, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T19:52:39.923976: step 20600, loss 0.216363, acc 0.932\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-20600\n",
      "\n",
      "2018-05-04T19:52:41.035229: step 20601, loss 0.406098, acc 0.828125\n",
      "2018-05-04T19:52:42.083477: step 20602, loss 0.251355, acc 0.890625\n",
      "2018-05-04T19:52:43.095280: step 20603, loss 0.336064, acc 0.859375\n",
      "2018-05-04T19:52:44.118514: step 20604, loss 0.223474, acc 0.921875\n",
      "2018-05-04T19:52:45.102761: step 20605, loss 0.15858, acc 0.90625\n",
      "2018-05-04T19:52:46.084684: step 20606, loss 0.286056, acc 0.890625\n",
      "2018-05-04T19:52:47.067738: step 20607, loss 0.218029, acc 0.890625\n",
      "2018-05-04T19:52:48.044822: step 20608, loss 0.19892, acc 0.96875\n",
      "2018-05-04T19:52:49.028538: step 20609, loss 0.200799, acc 0.890625\n",
      "2018-05-04T19:52:49.995553: step 20610, loss 0.279274, acc 0.875\n",
      "2018-05-04T19:52:50.979741: step 20611, loss 0.202597, acc 0.890625\n",
      "2018-05-04T19:52:51.966057: step 20612, loss 0.471865, acc 0.8125\n",
      "2018-05-04T19:52:52.927923: step 20613, loss 0.26897, acc 0.921875\n",
      "2018-05-04T19:52:53.911818: step 20614, loss 0.249979, acc 0.90625\n",
      "2018-05-04T19:52:54.868869: step 20615, loss 0.182991, acc 0.9375\n",
      "2018-05-04T19:52:55.847965: step 20616, loss 0.323287, acc 0.890625\n",
      "2018-05-04T19:52:56.828051: step 20617, loss 0.214286, acc 0.875\n",
      "2018-05-04T19:52:57.804449: step 20618, loss 0.17148, acc 0.9375\n",
      "2018-05-04T19:52:58.780828: step 20619, loss 0.238645, acc 0.90625\n",
      "2018-05-04T19:52:59.752998: step 20620, loss 0.349954, acc 0.84375\n",
      "2018-05-04T19:53:00.742080: step 20621, loss 0.267897, acc 0.921875\n",
      "2018-05-04T19:53:01.712136: step 20622, loss 0.190258, acc 0.921875\n",
      "2018-05-04T19:53:02.711512: step 20623, loss 0.299107, acc 0.90625\n",
      "2018-05-04T19:53:03.711527: step 20624, loss 0.211849, acc 0.921875\n",
      "2018-05-04T19:53:04.689542: step 20625, loss 0.193129, acc 0.890625\n",
      "2018-05-04T19:53:05.671223: step 20626, loss 0.184525, acc 0.890625\n",
      "2018-05-04T19:53:06.652117: step 20627, loss 0.234617, acc 0.90625\n",
      "2018-05-04T19:53:07.623563: step 20628, loss 0.261922, acc 0.90625\n",
      "2018-05-04T19:53:08.620215: step 20629, loss 0.164104, acc 0.921875\n",
      "2018-05-04T19:53:09.629517: step 20630, loss 0.159151, acc 0.921875\n",
      "2018-05-04T19:53:10.605310: step 20631, loss 0.240092, acc 0.890625\n",
      "2018-05-04T19:53:11.569091: step 20632, loss 0.185111, acc 0.953125\n",
      "2018-05-04T19:53:12.555010: step 20633, loss 0.185542, acc 0.921875\n",
      "2018-05-04T19:53:13.549654: step 20634, loss 0.321166, acc 0.890625\n",
      "2018-05-04T19:53:14.549738: step 20635, loss 0.277435, acc 0.875\n",
      "2018-05-04T19:53:15.590782: step 20636, loss 0.264019, acc 0.90625\n",
      "2018-05-04T19:53:16.588995: step 20637, loss 0.227767, acc 0.890625\n",
      "2018-05-04T19:53:17.592505: step 20638, loss 0.272443, acc 0.921875\n",
      "2018-05-04T19:53:18.571230: step 20639, loss 0.27975, acc 0.875\n",
      "2018-05-04T19:53:19.556426: step 20640, loss 0.443735, acc 0.875\n",
      "2018-05-04T19:53:20.507690: step 20641, loss 0.247654, acc 0.875\n",
      "2018-05-04T19:53:21.553413: step 20642, loss 0.352602, acc 0.890625\n",
      "2018-05-04T19:53:22.525533: step 20643, loss 0.167848, acc 0.96875\n",
      "2018-05-04T19:53:23.486855: step 20644, loss 0.288063, acc 0.890625\n",
      "2018-05-04T19:53:24.462047: step 20645, loss 0.162419, acc 0.921875\n",
      "2018-05-04T19:53:25.412967: step 20646, loss 0.229147, acc 0.9375\n",
      "2018-05-04T19:53:26.378342: step 20647, loss 0.359319, acc 0.890625\n",
      "2018-05-04T19:53:27.348953: step 20648, loss 0.111701, acc 0.96875\n",
      "2018-05-04T19:53:28.295542: step 20649, loss 0.29756, acc 0.84375\n",
      "2018-05-04T19:53:29.268953: step 20650, loss 0.313034, acc 0.90625\n",
      "2018-05-04T19:53:30.240671: step 20651, loss 0.18428, acc 0.921875\n",
      "2018-05-04T19:53:31.209793: step 20652, loss 0.340327, acc 0.90625\n",
      "2018-05-04T19:53:32.178401: step 20653, loss 0.496121, acc 0.796875\n",
      "2018-05-04T19:53:33.207097: step 20654, loss 0.154415, acc 0.921875\n",
      "2018-05-04T19:53:34.199359: step 20655, loss 0.236924, acc 0.90625\n",
      "2018-05-04T19:53:35.174353: step 20656, loss 0.267438, acc 0.875\n",
      "2018-05-04T19:53:36.198531: step 20657, loss 0.270341, acc 0.875\n",
      "2018-05-04T19:53:37.244110: step 20658, loss 0.268226, acc 0.890625\n",
      "2018-05-04T19:53:38.185843: step 20659, loss 0.176478, acc 0.953125\n",
      "2018-05-04T19:53:39.144777: step 20660, loss 0.321936, acc 0.84375\n",
      "2018-05-04T19:53:40.129474: step 20661, loss 0.258396, acc 0.875\n",
      "2018-05-04T19:53:41.075554: step 20662, loss 0.257897, acc 0.921875\n",
      "2018-05-04T19:53:42.117215: step 20663, loss 0.250007, acc 0.90625\n",
      "2018-05-04T19:53:43.086260: step 20664, loss 0.17496, acc 0.9375\n",
      "2018-05-04T19:53:44.040674: step 20665, loss 0.229753, acc 0.90625\n",
      "2018-05-04T19:53:45.073943: step 20666, loss 0.225662, acc 0.859375\n",
      "2018-05-04T19:53:46.021561: step 20667, loss 0.363948, acc 0.828125\n",
      "2018-05-04T19:53:46.970398: step 20668, loss 0.364411, acc 0.828125\n",
      "2018-05-04T19:53:47.918321: step 20669, loss 0.330756, acc 0.828125\n",
      "2018-05-04T19:53:48.889539: step 20670, loss 0.285432, acc 0.859375\n",
      "2018-05-04T19:53:49.845705: step 20671, loss 0.172457, acc 0.9375\n",
      "2018-05-04T19:53:50.803334: step 20672, loss 0.245036, acc 0.875\n",
      "2018-05-04T19:53:51.763024: step 20673, loss 0.335986, acc 0.875\n",
      "2018-05-04T19:53:52.727793: step 20674, loss 0.310132, acc 0.890625\n",
      "2018-05-04T19:53:53.767362: step 20675, loss 0.366626, acc 0.890625\n",
      "2018-05-04T19:53:54.717146: step 20676, loss 0.274101, acc 0.890625\n",
      "2018-05-04T19:53:55.713184: step 20677, loss 0.268251, acc 0.921875\n",
      "2018-05-04T19:53:56.683743: step 20678, loss 0.199042, acc 0.90625\n",
      "2018-05-04T19:53:57.641515: step 20679, loss 0.341002, acc 0.875\n",
      "2018-05-04T19:53:58.606294: step 20680, loss 0.33442, acc 0.875\n",
      "2018-05-04T19:53:59.561764: step 20681, loss 0.19548, acc 0.953125\n",
      "2018-05-04T19:54:00.550277: step 20682, loss 0.163809, acc 0.9375\n",
      "2018-05-04T19:54:01.529938: step 20683, loss 0.45157, acc 0.765625\n",
      "2018-05-04T19:54:02.519170: step 20684, loss 0.219995, acc 0.921875\n",
      "2018-05-04T19:54:03.487441: step 20685, loss 0.26269, acc 0.84375\n",
      "2018-05-04T19:54:04.457898: step 20686, loss 0.429867, acc 0.84375\n",
      "2018-05-04T19:54:05.428140: step 20687, loss 0.165966, acc 0.9375\n",
      "2018-05-04T19:54:06.371448: step 20688, loss 0.334272, acc 0.84375\n",
      "2018-05-04T19:54:07.351838: step 20689, loss 0.281553, acc 0.921875\n",
      "2018-05-04T19:54:08.291216: step 20690, loss 0.205927, acc 0.90625\n",
      "2018-05-04T19:54:09.273667: step 20691, loss 0.246773, acc 0.890625\n",
      "2018-05-04T19:54:10.211115: step 20692, loss 0.248029, acc 0.9375\n",
      "2018-05-04T19:54:11.178878: step 20693, loss 0.260182, acc 0.859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T19:54:12.151184: step 20694, loss 0.165264, acc 0.921875\n",
      "2018-05-04T19:54:13.135912: step 20695, loss 0.376159, acc 0.828125\n",
      "2018-05-04T19:54:14.102343: step 20696, loss 0.229155, acc 0.90625\n",
      "2018-05-04T19:54:15.158383: step 20697, loss 0.278085, acc 0.890625\n",
      "2018-05-04T19:54:16.109767: step 20698, loss 0.191049, acc 0.9375\n",
      "2018-05-04T19:54:17.069471: step 20699, loss 0.293068, acc 0.890625\n",
      "2018-05-04T19:54:18.016677: step 20700, loss 0.201233, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T19:54:20.189367: step 20700, loss 0.217811, acc 0.922\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-20700\n",
      "\n",
      "2018-05-04T19:54:21.253528: step 20701, loss 0.258757, acc 0.890625\n",
      "2018-05-04T19:54:22.225590: step 20702, loss 0.143006, acc 0.9375\n",
      "2018-05-04T19:54:23.160073: step 20703, loss 0.265154, acc 0.921875\n",
      "2018-05-04T19:54:24.124204: step 20704, loss 0.21927, acc 0.90625\n",
      "2018-05-04T19:54:25.077221: step 20705, loss 0.185617, acc 0.921875\n",
      "2018-05-04T19:54:26.045261: step 20706, loss 0.371666, acc 0.8125\n",
      "2018-05-04T19:54:27.009761: step 20707, loss 0.232161, acc 0.921875\n",
      "2018-05-04T19:54:27.947024: step 20708, loss 0.343366, acc 0.890625\n",
      "2018-05-04T19:54:28.892629: step 20709, loss 0.234906, acc 0.90625\n",
      "2018-05-04T19:54:29.844039: step 20710, loss 0.208748, acc 0.890625\n",
      "2018-05-04T19:54:30.841682: step 20711, loss 0.271729, acc 0.859375\n",
      "2018-05-04T19:54:31.797129: step 20712, loss 0.334074, acc 0.859375\n",
      "2018-05-04T19:54:32.750170: step 20713, loss 0.195827, acc 0.953125\n",
      "2018-05-04T19:54:33.708608: step 20714, loss 0.125781, acc 0.984375\n",
      "2018-05-04T19:54:34.752694: step 20715, loss 0.166356, acc 0.953125\n",
      "2018-05-04T19:54:35.701510: step 20716, loss 0.251726, acc 0.921875\n",
      "2018-05-04T19:54:36.629392: step 20717, loss 0.301101, acc 0.90625\n",
      "2018-05-04T19:54:37.592957: step 20718, loss 0.236966, acc 0.890625\n",
      "2018-05-04T19:54:38.531070: step 20719, loss 0.289785, acc 0.9375\n",
      "2018-05-04T19:54:39.489878: step 20720, loss 0.239111, acc 0.921875\n",
      "2018-05-04T19:54:40.512493: step 20721, loss 0.323182, acc 0.8125\n",
      "2018-05-04T19:54:41.476539: step 20722, loss 0.20017, acc 0.90625\n",
      "2018-05-04T19:54:42.455676: step 20723, loss 0.270293, acc 0.90625\n",
      "2018-05-04T19:54:43.415943: step 20724, loss 0.315513, acc 0.875\n",
      "2018-05-04T19:54:44.375797: step 20725, loss 0.209217, acc 0.90625\n",
      "2018-05-04T19:54:45.319718: step 20726, loss 0.266922, acc 0.90625\n",
      "2018-05-04T19:54:46.276121: step 20727, loss 0.122457, acc 0.96875\n",
      "2018-05-04T19:54:47.212202: step 20728, loss 0.16209, acc 0.96875\n",
      "2018-05-04T19:54:48.161773: step 20729, loss 0.177267, acc 0.921875\n",
      "2018-05-04T19:54:49.105946: step 20730, loss 0.318825, acc 0.859375\n",
      "2018-05-04T19:54:50.072226: step 20731, loss 0.423831, acc 0.859375\n",
      "2018-05-04T19:54:51.035884: step 20732, loss 0.331962, acc 0.875\n",
      "2018-05-04T19:54:52.009166: step 20733, loss 0.224866, acc 0.90625\n",
      "2018-05-04T19:54:53.030056: step 20734, loss 0.27678, acc 0.859375\n",
      "2018-05-04T19:54:53.985398: step 20735, loss 0.128457, acc 0.96875\n",
      "2018-05-04T19:54:54.930404: step 20736, loss 0.309839, acc 0.890625\n",
      "2018-05-04T19:54:55.873954: step 20737, loss 0.344794, acc 0.875\n",
      "2018-05-04T19:54:56.820334: step 20738, loss 0.25106, acc 0.890625\n",
      "2018-05-04T19:54:57.802809: step 20739, loss 0.330375, acc 0.859375\n",
      "2018-05-04T19:54:58.735109: step 20740, loss 0.320557, acc 0.921875\n",
      "2018-05-04T19:54:59.687651: step 20741, loss 0.265935, acc 0.90625\n",
      "2018-05-04T19:55:00.630528: step 20742, loss 0.265403, acc 0.859375\n",
      "2018-05-04T19:55:01.573489: step 20743, loss 0.217317, acc 0.890625\n",
      "2018-05-04T19:55:02.613261: step 20744, loss 0.310806, acc 0.875\n",
      "2018-05-04T19:55:03.539039: step 20745, loss 0.341245, acc 0.90625\n",
      "2018-05-04T19:55:04.499030: step 20746, loss 0.249987, acc 0.890625\n",
      "2018-05-04T19:55:05.515416: step 20747, loss 0.3218, acc 0.875\n",
      "2018-05-04T19:55:06.449028: step 20748, loss 0.247215, acc 0.9375\n",
      "2018-05-04T19:55:07.399918: step 20749, loss 0.293678, acc 0.84375\n",
      "2018-05-04T19:55:08.350204: step 20750, loss 0.167269, acc 0.921875\n",
      "2018-05-04T19:55:09.301503: step 20751, loss 0.356751, acc 0.84375\n",
      "2018-05-04T19:55:10.261285: step 20752, loss 0.160788, acc 0.9375\n",
      "2018-05-04T19:55:11.227170: step 20753, loss 0.235213, acc 0.90625\n",
      "2018-05-04T19:55:12.178617: step 20754, loss 0.301714, acc 0.890625\n",
      "2018-05-04T19:55:13.114079: step 20755, loss 0.284393, acc 0.890625\n",
      "2018-05-04T19:55:14.051506: step 20756, loss 0.180088, acc 0.9375\n",
      "2018-05-04T19:55:14.982355: step 20757, loss 0.209844, acc 0.890625\n",
      "2018-05-04T19:55:15.922789: step 20758, loss 0.202942, acc 0.953125\n",
      "2018-05-04T19:55:16.875045: step 20759, loss 0.211523, acc 0.921875\n",
      "2018-05-04T19:55:17.948462: step 20760, loss 0.320195, acc 0.90625\n",
      "2018-05-04T19:55:18.979998: step 20761, loss 0.311173, acc 0.890625\n",
      "2018-05-04T19:55:19.928157: step 20762, loss 0.156399, acc 0.953125\n",
      "2018-05-04T19:55:20.878653: step 20763, loss 0.273123, acc 0.875\n",
      "2018-05-04T19:55:21.830195: step 20764, loss 0.2251, acc 0.90625\n",
      "2018-05-04T19:55:22.826572: step 20765, loss 0.218885, acc 0.9375\n",
      "2018-05-04T19:55:23.801802: step 20766, loss 0.327544, acc 0.875\n",
      "2018-05-04T19:55:24.781765: step 20767, loss 0.187982, acc 0.921875\n",
      "2018-05-04T19:55:25.743356: step 20768, loss 0.231289, acc 0.890625\n",
      "2018-05-04T19:55:26.719663: step 20769, loss 0.206262, acc 0.921875\n",
      "2018-05-04T19:55:27.679474: step 20770, loss 0.195342, acc 0.921875\n",
      "2018-05-04T19:55:28.626780: step 20771, loss 0.213391, acc 0.9375\n",
      "2018-05-04T19:55:29.565335: step 20772, loss 0.20575, acc 0.890625\n",
      "2018-05-04T19:55:30.523711: step 20773, loss 0.21915, acc 0.921875\n",
      "2018-05-04T19:55:31.506599: step 20774, loss 0.158896, acc 0.9375\n",
      "2018-05-04T19:55:32.471042: step 20775, loss 0.218303, acc 0.890625\n",
      "2018-05-04T19:55:33.488084: step 20776, loss 0.194452, acc 0.921875\n",
      "2018-05-04T19:55:34.511225: step 20777, loss 0.20577, acc 0.90625\n",
      "2018-05-04T19:55:35.545616: step 20778, loss 0.219786, acc 0.875\n",
      "2018-05-04T19:55:36.611896: step 20779, loss 0.167279, acc 0.953125\n",
      "2018-05-04T19:55:37.546725: step 20780, loss 0.267514, acc 0.890625\n",
      "2018-05-04T19:55:38.475195: step 20781, loss 0.240628, acc 0.875\n",
      "2018-05-04T19:55:39.416199: step 20782, loss 0.323083, acc 0.875\n",
      "2018-05-04T19:55:40.357216: step 20783, loss 0.253319, acc 0.875\n",
      "2018-05-04T19:55:41.293372: step 20784, loss 0.160371, acc 0.90625\n",
      "2018-05-04T19:55:42.259481: step 20785, loss 0.384304, acc 0.828125\n",
      "2018-05-04T19:55:43.220883: step 20786, loss 0.442412, acc 0.859375\n",
      "2018-05-04T19:55:44.214271: step 20787, loss 0.454795, acc 0.84375\n",
      "2018-05-04T19:55:45.172496: step 20788, loss 0.216349, acc 0.90625\n",
      "2018-05-04T19:55:46.119797: step 20789, loss 0.249826, acc 0.921875\n",
      "2018-05-04T19:55:47.055350: step 20790, loss 0.518949, acc 0.765625\n",
      "2018-05-04T19:55:47.988786: step 20791, loss 0.171172, acc 0.9375\n",
      "2018-05-04T19:55:48.946118: step 20792, loss 0.173716, acc 0.9375\n",
      "2018-05-04T19:55:49.887113: step 20793, loss 0.240485, acc 0.921875\n",
      "2018-05-04T19:55:50.813690: step 20794, loss 0.172113, acc 0.921875\n",
      "2018-05-04T19:55:51.808716: step 20795, loss 0.273058, acc 0.9375\n",
      "2018-05-04T19:55:52.853236: step 20796, loss 0.200482, acc 0.921875\n",
      "2018-05-04T19:55:53.810595: step 20797, loss 0.333223, acc 0.84375\n",
      "2018-05-04T19:55:54.762004: step 20798, loss 0.281619, acc 0.90625\n",
      "2018-05-04T19:55:55.761167: step 20799, loss 0.223882, acc 0.9375\n",
      "2018-05-04T19:55:56.750270: step 20800, loss 0.207265, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T19:55:59.592883: step 20800, loss 0.209515, acc 0.926\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-20800\n",
      "\n",
      "2018-05-04T19:56:00.654554: step 20801, loss 0.294607, acc 0.828125\n",
      "2018-05-04T19:56:01.647939: step 20802, loss 0.235492, acc 0.890625\n",
      "2018-05-04T19:56:02.646412: step 20803, loss 0.216698, acc 0.890625\n",
      "2018-05-04T19:56:03.631794: step 20804, loss 0.194889, acc 0.921875\n",
      "2018-05-04T19:56:04.671143: step 20805, loss 0.284871, acc 0.875\n",
      "2018-05-04T19:56:05.694956: step 20806, loss 0.234947, acc 0.890625\n",
      "2018-05-04T19:56:06.712703: step 20807, loss 0.21003, acc 0.921875\n",
      "2018-05-04T19:56:07.725829: step 20808, loss 0.260949, acc 0.9375\n",
      "2018-05-04T19:56:08.685230: step 20809, loss 0.336248, acc 0.875\n",
      "2018-05-04T19:56:09.650309: step 20810, loss 0.245232, acc 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T19:56:10.643910: step 20811, loss 0.172857, acc 0.953125\n",
      "2018-05-04T19:56:11.617593: step 20812, loss 0.295661, acc 0.859375\n",
      "2018-05-04T19:56:12.664867: step 20813, loss 0.275309, acc 0.875\n",
      "2018-05-04T19:56:13.642138: step 20814, loss 0.319816, acc 0.859375\n",
      "2018-05-04T19:56:14.596758: step 20815, loss 0.333546, acc 0.890625\n",
      "2018-05-04T19:56:15.554432: step 20816, loss 0.299346, acc 0.90625\n",
      "2018-05-04T19:56:16.539855: step 20817, loss 0.14486, acc 0.9375\n",
      "2018-05-04T19:56:17.515464: step 20818, loss 0.255241, acc 0.890625\n",
      "2018-05-04T19:56:18.482653: step 20819, loss 0.204096, acc 0.921875\n",
      "2018-05-04T19:56:19.466960: step 20820, loss 0.218093, acc 0.921875\n",
      "2018-05-04T19:56:20.483400: step 20821, loss 0.301908, acc 0.859375\n",
      "2018-05-04T19:56:21.528369: step 20822, loss 0.162099, acc 0.953125\n",
      "2018-05-04T19:56:22.479938: step 20823, loss 0.238374, acc 0.921875\n",
      "2018-05-04T19:56:23.440149: step 20824, loss 0.265494, acc 0.90625\n",
      "2018-05-04T19:56:24.392861: step 20825, loss 0.185302, acc 0.90625\n",
      "2018-05-04T19:56:25.355537: step 20826, loss 0.226887, acc 0.90625\n",
      "2018-05-04T19:56:26.325163: step 20827, loss 0.277478, acc 0.875\n",
      "2018-05-04T19:56:27.298340: step 20828, loss 0.143484, acc 0.921875\n",
      "2018-05-04T19:56:28.278750: step 20829, loss 0.207666, acc 0.90625\n",
      "2018-05-04T19:56:29.227756: step 20830, loss 0.201891, acc 0.875\n",
      "2018-05-04T19:56:30.211091: step 20831, loss 0.249845, acc 0.921875\n",
      "2018-05-04T19:56:31.231492: step 20832, loss 0.222198, acc 0.875\n",
      "2018-05-04T19:56:32.251811: step 20833, loss 0.240648, acc 0.921875\n",
      "2018-05-04T19:56:33.227788: step 20834, loss 0.324421, acc 0.8125\n",
      "2018-05-04T19:56:34.222099: step 20835, loss 0.296425, acc 0.84375\n",
      "2018-05-04T19:56:35.184689: step 20836, loss 0.22431, acc 0.90625\n",
      "2018-05-04T19:56:36.254112: step 20837, loss 0.288039, acc 0.875\n",
      "2018-05-04T19:56:37.232775: step 20838, loss 0.261418, acc 0.859375\n",
      "2018-05-04T19:56:38.191386: step 20839, loss 0.310578, acc 0.875\n",
      "2018-05-04T19:56:39.148150: step 20840, loss 0.481896, acc 0.8125\n",
      "2018-05-04T19:56:40.107750: step 20841, loss 0.404712, acc 0.84375\n",
      "2018-05-04T19:56:41.095849: step 20842, loss 0.292302, acc 0.859375\n",
      "2018-05-04T19:56:42.062733: step 20843, loss 0.201799, acc 0.875\n",
      "2018-05-04T19:56:43.032038: step 20844, loss 0.232492, acc 0.859375\n",
      "2018-05-04T19:56:44.018088: step 20845, loss 0.267563, acc 0.875\n",
      "2018-05-04T19:56:44.974815: step 20846, loss 0.326584, acc 0.84375\n",
      "2018-05-04T19:56:46.007794: step 20847, loss 0.182959, acc 0.96875\n",
      "2018-05-04T19:56:46.954432: step 20848, loss 0.306555, acc 0.890625\n",
      "2018-05-04T19:56:47.930349: step 20849, loss 0.252894, acc 0.890625\n",
      "2018-05-04T19:56:48.907558: step 20850, loss 0.201802, acc 0.90625\n",
      "2018-05-04T19:56:49.963130: step 20851, loss 0.581568, acc 0.75\n",
      "2018-05-04T19:56:50.977862: step 20852, loss 0.139246, acc 0.96875\n",
      "2018-05-04T19:56:51.964425: step 20853, loss 0.34432, acc 0.875\n",
      "2018-05-04T19:56:52.929793: step 20854, loss 0.227876, acc 0.90625\n",
      "2018-05-04T19:56:53.991131: step 20855, loss 0.332759, acc 0.890625\n",
      "2018-05-04T19:56:55.029363: step 20856, loss 0.278556, acc 0.890625\n",
      "2018-05-04T19:56:56.067251: step 20857, loss 0.308774, acc 0.90625\n",
      "2018-05-04T19:56:57.021351: step 20858, loss 0.413005, acc 0.84375\n",
      "2018-05-04T19:56:57.985949: step 20859, loss 0.236975, acc 0.890625\n",
      "2018-05-04T19:56:58.944289: step 20860, loss 0.267877, acc 0.875\n",
      "2018-05-04T19:57:00.001615: step 20861, loss 0.306295, acc 0.921875\n",
      "2018-05-04T19:57:00.966778: step 20862, loss 0.236686, acc 0.875\n",
      "2018-05-04T19:57:01.927611: step 20863, loss 0.224859, acc 0.90625\n",
      "2018-05-04T19:57:02.962408: step 20864, loss 0.193219, acc 0.921875\n",
      "2018-05-04T19:57:04.015139: step 20865, loss 0.289487, acc 0.890625\n",
      "2018-05-04T19:57:04.968341: step 20866, loss 0.264644, acc 0.9375\n",
      "2018-05-04T19:57:05.967873: step 20867, loss 0.275523, acc 0.890625\n",
      "2018-05-04T19:57:06.905541: step 20868, loss 0.475107, acc 0.765625\n",
      "2018-05-04T19:57:07.868769: step 20869, loss 0.287942, acc 0.9375\n",
      "2018-05-04T19:57:08.843032: step 20870, loss 0.258362, acc 0.890625\n",
      "2018-05-04T19:57:09.842380: step 20871, loss 0.21723, acc 0.921875\n",
      "2018-05-04T19:57:10.804628: step 20872, loss 0.208046, acc 0.9375\n",
      "2018-05-04T19:57:11.776043: step 20873, loss 0.17585, acc 0.9375\n",
      "2018-05-04T19:57:12.736464: step 20874, loss 0.227098, acc 0.9375\n",
      "2018-05-04T19:57:13.685637: step 20875, loss 0.330027, acc 0.84375\n",
      "2018-05-04T19:57:14.653491: step 20876, loss 0.169223, acc 0.921875\n",
      "2018-05-04T19:57:15.631368: step 20877, loss 0.358428, acc 0.8125\n",
      "2018-05-04T19:57:16.596267: step 20878, loss 0.254944, acc 0.890625\n",
      "2018-05-04T19:57:17.627464: step 20879, loss 0.222021, acc 0.90625\n",
      "2018-05-04T19:57:18.592045: step 20880, loss 0.211731, acc 0.875\n",
      "2018-05-04T19:57:19.599566: step 20881, loss 0.175579, acc 0.9375\n",
      "2018-05-04T19:57:20.585467: step 20882, loss 0.193095, acc 0.921875\n",
      "2018-05-04T19:57:21.576815: step 20883, loss 0.163411, acc 0.9375\n",
      "2018-05-04T19:57:22.519011: step 20884, loss 0.184194, acc 0.953125\n",
      "2018-05-04T19:57:23.495063: step 20885, loss 0.30956, acc 0.875\n",
      "2018-05-04T19:57:24.463943: step 20886, loss 0.251179, acc 0.921875\n",
      "2018-05-04T19:57:25.445876: step 20887, loss 0.231212, acc 0.9375\n",
      "2018-05-04T19:57:26.436584: step 20888, loss 0.175692, acc 0.9375\n",
      "2018-05-04T19:57:27.385485: step 20889, loss 0.134516, acc 0.953125\n",
      "2018-05-04T19:57:28.338274: step 20890, loss 0.27213, acc 0.875\n",
      "2018-05-04T19:57:29.281407: step 20891, loss 0.429499, acc 0.859375\n",
      "2018-05-04T19:57:30.214943: step 20892, loss 0.289206, acc 0.84375\n",
      "2018-05-04T19:57:31.153501: step 20893, loss 0.234566, acc 0.953125\n",
      "2018-05-04T19:57:32.079417: step 20894, loss 0.274793, acc 0.890625\n",
      "2018-05-04T19:57:33.035786: step 20895, loss 0.3012, acc 0.890625\n",
      "2018-05-04T19:57:34.001396: step 20896, loss 0.260183, acc 0.90625\n",
      "2018-05-04T19:57:34.988609: step 20897, loss 0.0908806, acc 0.984375\n",
      "2018-05-04T19:57:35.995629: step 20898, loss 0.220427, acc 0.890625\n",
      "2018-05-04T19:57:37.053178: step 20899, loss 0.215681, acc 0.921875\n",
      "2018-05-04T19:57:38.075939: step 20900, loss 0.203616, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T19:57:40.369459: step 20900, loss 0.217884, acc 0.928\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-20900\n",
      "\n",
      "2018-05-04T19:57:41.522468: step 20901, loss 0.222727, acc 0.890625\n",
      "2018-05-04T19:57:42.543065: step 20902, loss 0.2015, acc 0.90625\n",
      "2018-05-04T19:57:43.527557: step 20903, loss 0.204541, acc 0.9375\n",
      "2018-05-04T19:57:44.525350: step 20904, loss 0.356151, acc 0.875\n",
      "2018-05-04T19:57:45.531388: step 20905, loss 0.300238, acc 0.84375\n",
      "2018-05-04T19:57:46.541987: step 20906, loss 0.237857, acc 0.875\n",
      "2018-05-04T19:57:47.535392: step 20907, loss 0.304927, acc 0.859375\n",
      "2018-05-04T19:57:48.601944: step 20908, loss 0.310819, acc 0.890625\n",
      "2018-05-04T19:57:49.559093: step 20909, loss 0.257618, acc 0.890625\n",
      "2018-05-04T19:57:50.515988: step 20910, loss 0.256617, acc 0.921875\n",
      "2018-05-04T19:57:51.604609: step 20911, loss 0.241796, acc 0.890625\n",
      "2018-05-04T19:57:52.597586: step 20912, loss 0.209471, acc 0.90625\n",
      "2018-05-04T19:57:53.562388: step 20913, loss 0.355076, acc 0.859375\n",
      "2018-05-04T19:57:54.542255: step 20914, loss 0.260817, acc 0.84375\n",
      "2018-05-04T19:57:55.523014: step 20915, loss 0.364128, acc 0.875\n",
      "2018-05-04T19:57:56.507698: step 20916, loss 0.186288, acc 0.921875\n",
      "2018-05-04T19:57:57.470806: step 20917, loss 0.198707, acc 0.90625\n",
      "2018-05-04T19:57:58.442907: step 20918, loss 0.299331, acc 0.890625\n",
      "2018-05-04T19:57:59.439497: step 20919, loss 0.41091, acc 0.828125\n",
      "2018-05-04T19:58:00.414992: step 20920, loss 0.363882, acc 0.875\n",
      "2018-05-04T19:58:01.400026: step 20921, loss 0.206168, acc 0.90625\n",
      "2018-05-04T19:58:02.433164: step 20922, loss 0.275793, acc 0.859375\n",
      "2018-05-04T19:58:03.413355: step 20923, loss 0.409037, acc 0.859375\n",
      "2018-05-04T19:58:04.463267: step 20924, loss 0.329674, acc 0.890625\n",
      "2018-05-04T19:58:05.434179: step 20925, loss 0.296995, acc 0.84375\n",
      "2018-05-04T19:58:06.403005: step 20926, loss 0.189869, acc 0.90625\n",
      "2018-05-04T19:58:07.340533: step 20927, loss 0.342643, acc 0.859375\n",
      "2018-05-04T19:58:08.306195: step 20928, loss 0.224034, acc 0.890625\n",
      "2018-05-04T19:58:09.265935: step 20929, loss 0.346163, acc 0.890625\n",
      "2018-05-04T19:58:10.229803: step 20930, loss 0.267594, acc 0.84375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T19:58:11.215746: step 20931, loss 0.257023, acc 0.875\n",
      "2018-05-04T19:58:12.189884: step 20932, loss 0.207418, acc 0.90625\n",
      "2018-05-04T19:58:13.155053: step 20933, loss 0.108896, acc 0.984375\n",
      "2018-05-04T19:58:14.133172: step 20934, loss 0.216848, acc 0.9375\n",
      "2018-05-04T19:58:15.164645: step 20935, loss 0.192497, acc 0.9375\n",
      "2018-05-04T19:58:16.137517: step 20936, loss 0.295339, acc 0.84375\n",
      "2018-05-04T19:58:17.107999: step 20937, loss 0.293539, acc 0.875\n",
      "2018-05-04T19:58:18.075267: step 20938, loss 0.332478, acc 0.859375\n",
      "2018-05-04T19:58:19.042583: step 20939, loss 0.254441, acc 0.9375\n",
      "2018-05-04T19:58:20.010164: step 20940, loss 0.249403, acc 0.921875\n",
      "2018-05-04T19:58:21.016434: step 20941, loss 0.305378, acc 0.859375\n",
      "2018-05-04T19:58:22.014203: step 20942, loss 0.314827, acc 0.875\n",
      "2018-05-04T19:58:23.027468: step 20943, loss 0.216268, acc 0.890625\n",
      "2018-05-04T19:58:24.048323: step 20944, loss 0.259982, acc 0.859375\n",
      "2018-05-04T19:58:25.028262: step 20945, loss 0.305274, acc 0.875\n",
      "2018-05-04T19:58:25.991852: step 20946, loss 0.251063, acc 0.890625\n",
      "2018-05-04T19:58:26.949082: step 20947, loss 0.164481, acc 0.921875\n",
      "2018-05-04T19:58:27.915839: step 20948, loss 0.236075, acc 0.921875\n",
      "2018-05-04T19:58:28.900030: step 20949, loss 0.325572, acc 0.84375\n",
      "2018-05-04T19:58:29.864631: step 20950, loss 0.294211, acc 0.859375\n",
      "2018-05-04T19:58:30.906916: step 20951, loss 0.474135, acc 0.84375\n",
      "2018-05-04T19:58:31.971934: step 20952, loss 0.271579, acc 0.921875\n",
      "2018-05-04T19:58:32.981424: step 20953, loss 0.410403, acc 0.859375\n",
      "2018-05-04T19:58:33.997370: step 20954, loss 0.15949, acc 0.9375\n",
      "2018-05-04T19:58:35.012186: step 20955, loss 0.159259, acc 0.953125\n",
      "2018-05-04T19:58:36.034006: step 20956, loss 0.233585, acc 0.90625\n",
      "2018-05-04T19:58:37.052797: step 20957, loss 0.33211, acc 0.875\n",
      "2018-05-04T19:58:38.058701: step 20958, loss 0.230757, acc 0.90625\n",
      "2018-05-04T19:58:39.060595: step 20959, loss 0.214495, acc 0.921875\n",
      "2018-05-04T19:58:40.030160: step 20960, loss 0.189909, acc 0.96875\n",
      "2018-05-04T19:58:41.009294: step 20961, loss 0.191311, acc 0.921875\n",
      "2018-05-04T19:58:42.021533: step 20962, loss 0.313507, acc 0.890625\n",
      "2018-05-04T19:58:42.948574: step 20963, loss 0.339884, acc 0.859375\n",
      "2018-05-04T19:58:43.909811: step 20964, loss 0.277764, acc 0.890625\n",
      "2018-05-04T19:58:44.870960: step 20965, loss 0.345776, acc 0.875\n",
      "2018-05-04T19:58:45.814265: step 20966, loss 0.13469, acc 0.953125\n",
      "2018-05-04T19:58:46.876400: step 20967, loss 0.375753, acc 0.84375\n",
      "2018-05-04T19:58:47.831661: step 20968, loss 0.325171, acc 0.84375\n",
      "2018-05-04T19:58:48.811971: step 20969, loss 0.195101, acc 0.921875\n",
      "2018-05-04T19:58:49.754933: step 20970, loss 0.213648, acc 0.9375\n",
      "2018-05-04T19:58:50.706014: step 20971, loss 0.18062, acc 0.921875\n",
      "2018-05-04T19:58:51.659021: step 20972, loss 0.21494, acc 0.9375\n",
      "2018-05-04T19:58:52.617754: step 20973, loss 0.113043, acc 0.96875\n",
      "2018-05-04T19:58:53.582261: step 20974, loss 0.271622, acc 0.90625\n",
      "2018-05-04T19:58:54.559791: step 20975, loss 0.23056, acc 0.90625\n",
      "2018-05-04T19:58:55.506088: step 20976, loss 0.202941, acc 0.921875\n",
      "2018-05-04T19:58:56.477564: step 20977, loss 0.298704, acc 0.875\n",
      "2018-05-04T19:58:57.452568: step 20978, loss 0.305006, acc 0.875\n",
      "2018-05-04T19:58:58.405136: step 20979, loss 0.177909, acc 0.9375\n",
      "2018-05-04T19:58:59.381421: step 20980, loss 0.256693, acc 0.859375\n",
      "2018-05-04T19:59:00.341418: step 20981, loss 0.17409, acc 0.953125\n",
      "2018-05-04T19:59:01.327759: step 20982, loss 0.286424, acc 0.859375\n",
      "2018-05-04T19:59:02.296744: step 20983, loss 0.144959, acc 0.9375\n",
      "2018-05-04T19:59:03.259602: step 20984, loss 0.119455, acc 0.984375\n",
      "2018-05-04T19:59:04.232191: step 20985, loss 0.355042, acc 0.875\n",
      "2018-05-04T19:59:05.296976: step 20986, loss 0.121582, acc 0.953125\n",
      "2018-05-04T19:59:06.247070: step 20987, loss 0.281301, acc 0.921875\n",
      "2018-05-04T19:59:07.211189: step 20988, loss 0.324163, acc 0.90625\n",
      "2018-05-04T19:59:08.153126: step 20989, loss 0.278398, acc 0.859375\n",
      "2018-05-04T19:59:09.089583: step 20990, loss 0.186829, acc 0.90625\n",
      "2018-05-04T19:59:10.057339: step 20991, loss 0.260111, acc 0.90625\n",
      "2018-05-04T19:59:11.011252: step 20992, loss 0.242661, acc 0.921875\n",
      "2018-05-04T19:59:11.973213: step 20993, loss 0.14811, acc 0.953125\n",
      "2018-05-04T19:59:12.997159: step 20994, loss 0.195267, acc 0.9375\n",
      "2018-05-04T19:59:13.952493: step 20995, loss 0.25565, acc 0.859375\n",
      "2018-05-04T19:59:14.889229: step 20996, loss 0.305442, acc 0.890625\n",
      "2018-05-04T19:59:15.843181: step 20997, loss 0.183173, acc 0.90625\n",
      "2018-05-04T19:59:16.770167: step 20998, loss 0.364247, acc 0.859375\n",
      "2018-05-04T19:59:17.773394: step 20999, loss 0.319241, acc 0.84375\n",
      "2018-05-04T19:59:18.715729: step 21000, loss 0.334052, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T19:59:20.864897: step 21000, loss 0.211061, acc 0.926\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-21000\n",
      "\n",
      "2018-05-04T19:59:21.966647: step 21001, loss 0.348431, acc 0.859375\n",
      "2018-05-04T19:59:22.932800: step 21002, loss 0.166269, acc 0.9375\n",
      "2018-05-04T19:59:23.866281: step 21003, loss 0.146007, acc 0.96875\n",
      "2018-05-04T19:59:24.813502: step 21004, loss 0.293837, acc 0.890625\n",
      "2018-05-04T19:59:25.779200: step 21005, loss 0.270446, acc 0.890625\n",
      "2018-05-04T19:59:26.740756: step 21006, loss 0.256067, acc 0.90625\n",
      "2018-05-04T19:59:27.701802: step 21007, loss 0.242924, acc 0.90625\n",
      "2018-05-04T19:59:28.664730: step 21008, loss 0.285558, acc 0.890625\n",
      "2018-05-04T19:59:29.618817: step 21009, loss 0.0941, acc 0.984375\n",
      "2018-05-04T19:59:30.594280: step 21010, loss 0.185618, acc 0.921875\n",
      "2018-05-04T19:59:31.580346: step 21011, loss 0.27567, acc 0.859375\n",
      "2018-05-04T19:59:32.555297: step 21012, loss 0.179293, acc 0.921875\n",
      "2018-05-04T19:59:33.509487: step 21013, loss 0.31015, acc 0.90625\n",
      "2018-05-04T19:59:34.468411: step 21014, loss 0.179253, acc 0.90625\n",
      "2018-05-04T19:59:35.407855: step 21015, loss 0.275134, acc 0.875\n",
      "2018-05-04T19:59:36.355509: step 21016, loss 0.173502, acc 0.9375\n",
      "2018-05-04T19:59:37.319023: step 21017, loss 0.330164, acc 0.84375\n",
      "2018-05-04T19:59:38.291075: step 21018, loss 0.263137, acc 0.828125\n",
      "2018-05-04T19:59:39.257451: step 21019, loss 0.182951, acc 0.90625\n",
      "2018-05-04T19:59:40.207400: step 21020, loss 0.184823, acc 0.90625\n",
      "2018-05-04T19:59:41.155476: step 21021, loss 0.169478, acc 0.921875\n",
      "2018-05-04T19:59:42.178753: step 21022, loss 0.359161, acc 0.875\n",
      "2018-05-04T19:59:43.224147: step 21023, loss 0.272862, acc 0.875\n",
      "2018-05-04T19:59:44.175013: step 21024, loss 0.282125, acc 0.890625\n",
      "2018-05-04T19:59:45.112651: step 21025, loss 0.207641, acc 0.9375\n",
      "2018-05-04T19:59:46.042538: step 21026, loss 0.50308, acc 0.78125\n",
      "2018-05-04T19:59:46.982463: step 21027, loss 0.24148, acc 0.90625\n",
      "2018-05-04T19:59:47.916406: step 21028, loss 0.27569, acc 0.921875\n",
      "2018-05-04T19:59:48.901296: step 21029, loss 0.22995, acc 0.90625\n",
      "2018-05-04T19:59:49.846048: step 21030, loss 0.236151, acc 0.875\n",
      "2018-05-04T19:59:50.879383: step 21031, loss 0.224456, acc 0.921875\n",
      "2018-05-04T19:59:51.939347: step 21032, loss 0.296247, acc 0.875\n",
      "2018-05-04T19:59:52.867247: step 21033, loss 0.227223, acc 0.90625\n",
      "2018-05-04T19:59:53.814770: step 21034, loss 0.301272, acc 0.8125\n",
      "2018-05-04T19:59:54.763456: step 21035, loss 0.148329, acc 0.953125\n",
      "2018-05-04T19:59:55.706225: step 21036, loss 0.102542, acc 0.984375\n",
      "2018-05-04T19:59:56.681397: step 21037, loss 0.215483, acc 0.953125\n",
      "2018-05-04T19:59:57.631612: step 21038, loss 0.383327, acc 0.84375\n",
      "2018-05-04T19:59:58.583511: step 21039, loss 0.358341, acc 0.875\n",
      "2018-05-04T19:59:59.526372: step 21040, loss 0.313516, acc 0.921875\n",
      "2018-05-04T20:00:00.454877: step 21041, loss 0.319888, acc 0.875\n",
      "2018-05-04T20:00:01.391774: step 21042, loss 0.167103, acc 0.953125\n",
      "2018-05-04T20:00:02.358347: step 21043, loss 0.238194, acc 0.875\n",
      "2018-05-04T20:00:03.311459: step 21044, loss 0.225816, acc 0.875\n",
      "2018-05-04T20:00:04.308889: step 21045, loss 0.204613, acc 0.921875\n",
      "2018-05-04T20:00:05.300873: step 21046, loss 0.290924, acc 0.875\n",
      "2018-05-04T20:00:06.264500: step 21047, loss 0.322768, acc 0.828125\n",
      "2018-05-04T20:00:07.228865: step 21048, loss 0.37963, acc 0.8125\n",
      "2018-05-04T20:00:08.294282: step 21049, loss 0.194565, acc 0.921875\n",
      "2018-05-04T20:00:09.291107: step 21050, loss 0.203008, acc 0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T20:00:10.243784: step 21051, loss 0.216264, acc 0.921875\n",
      "2018-05-04T20:00:11.194045: step 21052, loss 0.299057, acc 0.890625\n",
      "2018-05-04T20:00:12.141530: step 21053, loss 0.223733, acc 0.953125\n",
      "2018-05-04T20:00:13.092433: step 21054, loss 0.25081, acc 0.875\n",
      "2018-05-04T20:00:14.035639: step 21055, loss 0.217477, acc 0.9375\n",
      "2018-05-04T20:00:14.983275: step 21056, loss 0.161667, acc 0.890625\n",
      "2018-05-04T20:00:15.913987: step 21057, loss 0.466964, acc 0.8125\n",
      "2018-05-04T20:00:16.865275: step 21058, loss 0.299905, acc 0.859375\n",
      "2018-05-04T20:00:17.843104: step 21059, loss 0.216908, acc 0.90625\n",
      "2018-05-04T20:00:18.804381: step 21060, loss 0.213257, acc 0.9375\n",
      "2018-05-04T20:00:19.761406: step 21061, loss 0.234801, acc 0.921875\n",
      "2018-05-04T20:00:20.738736: step 21062, loss 0.23318, acc 0.890625\n",
      "2018-05-04T20:00:21.731223: step 21063, loss 0.241711, acc 0.953125\n",
      "2018-05-04T20:00:22.687084: step 21064, loss 0.312235, acc 0.90625\n",
      "2018-05-04T20:00:23.639123: step 21065, loss 0.235267, acc 0.921875\n",
      "2018-05-04T20:00:24.584584: step 21066, loss 0.273145, acc 0.90625\n",
      "2018-05-04T20:00:25.548291: step 21067, loss 0.206877, acc 0.921875\n",
      "2018-05-04T20:00:26.484716: step 21068, loss 0.295313, acc 0.875\n",
      "2018-05-04T20:00:27.457909: step 21069, loss 0.174861, acc 0.921875\n",
      "2018-05-04T20:00:28.397492: step 21070, loss 0.219985, acc 0.9375\n",
      "2018-05-04T20:00:29.349927: step 21071, loss 0.240445, acc 0.859375\n",
      "2018-05-04T20:00:30.291227: step 21072, loss 0.22685, acc 0.921875\n",
      "2018-05-04T20:00:31.269324: step 21073, loss 0.416239, acc 0.890625\n",
      "2018-05-04T20:00:32.282681: step 21074, loss 0.207383, acc 0.90625\n",
      "2018-05-04T20:00:33.226322: step 21075, loss 0.19428, acc 0.9375\n",
      "2018-05-04T20:00:34.160859: step 21076, loss 0.2868, acc 0.8125\n",
      "2018-05-04T20:00:35.101348: step 21077, loss 0.240994, acc 0.859375\n",
      "2018-05-04T20:00:36.033210: step 21078, loss 0.28307, acc 0.890625\n",
      "2018-05-04T20:00:36.990416: step 21079, loss 0.267134, acc 0.890625\n",
      "2018-05-04T20:00:37.935494: step 21080, loss 0.362388, acc 0.859375\n",
      "2018-05-04T20:00:38.964035: step 21081, loss 0.16567, acc 0.953125\n",
      "2018-05-04T20:00:39.894044: step 21082, loss 0.144239, acc 0.953125\n",
      "2018-05-04T20:00:40.831836: step 21083, loss 0.281483, acc 0.890625\n",
      "2018-05-04T20:00:41.763303: step 21084, loss 0.324614, acc 0.875\n",
      "2018-05-04T20:00:42.798307: step 21085, loss 0.28102, acc 0.875\n",
      "2018-05-04T20:00:43.738191: step 21086, loss 0.332202, acc 0.84375\n",
      "2018-05-04T20:00:44.673030: step 21087, loss 0.324893, acc 0.875\n",
      "2018-05-04T20:00:45.657456: step 21088, loss 0.518796, acc 0.78125\n",
      "2018-05-04T20:00:46.604115: step 21089, loss 0.191614, acc 0.953125\n",
      "2018-05-04T20:00:47.542632: step 21090, loss 0.176639, acc 0.921875\n",
      "2018-05-04T20:00:48.500331: step 21091, loss 0.159388, acc 0.90625\n",
      "2018-05-04T20:00:49.537791: step 21092, loss 0.291113, acc 0.84375\n",
      "2018-05-04T20:00:50.552004: step 21093, loss 0.323824, acc 0.875\n",
      "2018-05-04T20:00:51.542839: step 21094, loss 0.235305, acc 0.921875\n",
      "2018-05-04T20:00:52.482142: step 21095, loss 0.414358, acc 0.890625\n",
      "2018-05-04T20:00:53.430495: step 21096, loss 0.295502, acc 0.890625\n",
      "2018-05-04T20:00:54.367484: step 21097, loss 0.162923, acc 0.921875\n",
      "2018-05-04T20:00:55.330467: step 21098, loss 0.19753, acc 0.921875\n",
      "2018-05-04T20:00:56.294896: step 21099, loss 0.325634, acc 0.8125\n",
      "2018-05-04T20:00:57.250494: step 21100, loss 0.356477, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T20:00:59.807593: step 21100, loss 0.223922, acc 0.922\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-21100\n",
      "\n",
      "2018-05-04T20:01:00.880037: step 21101, loss 0.133959, acc 0.96875\n",
      "2018-05-04T20:01:01.871733: step 21102, loss 0.240917, acc 0.921875\n",
      "2018-05-04T20:01:02.955731: step 21103, loss 0.173188, acc 0.9375\n",
      "2018-05-04T20:01:03.964588: step 21104, loss 0.301321, acc 0.90625\n",
      "2018-05-04T20:01:05.033928: step 21105, loss 0.20789, acc 0.953125\n",
      "2018-05-04T20:01:06.055364: step 21106, loss 0.209829, acc 0.921875\n",
      "2018-05-04T20:01:07.060366: step 21107, loss 0.295102, acc 0.890625\n",
      "2018-05-04T20:01:08.064435: step 21108, loss 0.315771, acc 0.890625\n",
      "2018-05-04T20:01:09.030435: step 21109, loss 0.300713, acc 0.90625\n",
      "2018-05-04T20:01:10.061397: step 21110, loss 0.345364, acc 0.90625\n",
      "2018-05-04T20:01:11.068891: step 21111, loss 0.282205, acc 0.859375\n",
      "2018-05-04T20:01:12.079218: step 21112, loss 0.247399, acc 0.875\n",
      "2018-05-04T20:01:13.102263: step 21113, loss 0.36355, acc 0.859375\n",
      "2018-05-04T20:01:14.069377: step 21114, loss 0.165533, acc 0.9375\n",
      "2018-05-04T20:01:15.024264: step 21115, loss 0.221767, acc 0.875\n",
      "2018-05-04T20:01:15.986336: step 21116, loss 0.411485, acc 0.859375\n",
      "2018-05-04T20:01:16.948410: step 21117, loss 0.222166, acc 0.90625\n",
      "2018-05-04T20:01:17.972693: step 21118, loss 0.207649, acc 0.890625\n",
      "2018-05-04T20:01:18.939712: step 21119, loss 0.350581, acc 0.828125\n",
      "2018-05-04T20:01:19.923524: step 21120, loss 0.33538, acc 0.875\n",
      "2018-05-04T20:01:20.878470: step 21121, loss 0.208723, acc 0.875\n",
      "2018-05-04T20:01:21.852215: step 21122, loss 0.315794, acc 0.875\n",
      "2018-05-04T20:01:22.832714: step 21123, loss 0.247242, acc 0.921875\n",
      "2018-05-04T20:01:23.809803: step 21124, loss 0.112097, acc 0.96875\n",
      "2018-05-04T20:01:24.757581: step 21125, loss 0.267422, acc 0.890625\n",
      "2018-05-04T20:01:25.734711: step 21126, loss 0.203659, acc 0.921875\n",
      "2018-05-04T20:01:26.666976: step 21127, loss 0.404859, acc 0.859375\n",
      "2018-05-04T20:01:27.640017: step 21128, loss 0.317525, acc 0.890625\n",
      "2018-05-04T20:01:28.593662: step 21129, loss 0.223799, acc 0.921875\n",
      "2018-05-04T20:01:29.606159: step 21130, loss 0.239056, acc 0.84375\n",
      "2018-05-04T20:01:30.634646: step 21131, loss 0.355569, acc 0.8125\n",
      "2018-05-04T20:01:31.592536: step 21132, loss 0.346116, acc 0.90625\n",
      "2018-05-04T20:01:32.594740: step 21133, loss 0.311393, acc 0.859375\n",
      "2018-05-04T20:01:33.632649: step 21134, loss 0.266897, acc 0.890625\n",
      "2018-05-04T20:01:34.669617: step 21135, loss 0.187659, acc 0.96875\n",
      "2018-05-04T20:01:35.711898: step 21136, loss 0.37956, acc 0.8125\n",
      "2018-05-04T20:01:36.767454: step 21137, loss 0.188016, acc 0.921875\n",
      "2018-05-04T20:01:37.742202: step 21138, loss 0.472427, acc 0.796875\n",
      "2018-05-04T20:01:38.732611: step 21139, loss 0.320946, acc 0.859375\n",
      "2018-05-04T20:01:39.723780: step 21140, loss 0.216781, acc 0.890625\n",
      "2018-05-04T20:01:40.704885: step 21141, loss 0.35138, acc 0.8125\n",
      "2018-05-04T20:01:41.708833: step 21142, loss 0.284563, acc 0.90625\n",
      "2018-05-04T20:01:42.673017: step 21143, loss 0.231312, acc 0.890625\n",
      "2018-05-04T20:01:43.625599: step 21144, loss 0.352976, acc 0.84375\n",
      "2018-05-04T20:01:44.593190: step 21145, loss 0.154383, acc 0.953125\n",
      "2018-05-04T20:01:45.578488: step 21146, loss 0.331743, acc 0.890625\n",
      "2018-05-04T20:01:46.551314: step 21147, loss 0.254752, acc 0.890625\n",
      "2018-05-04T20:01:47.536657: step 21148, loss 0.249281, acc 0.890625\n",
      "2018-05-04T20:01:48.578254: step 21149, loss 0.175379, acc 0.921875\n",
      "2018-05-04T20:01:49.535813: step 21150, loss 0.189024, acc 0.953125\n",
      "2018-05-04T20:01:50.500988: step 21151, loss 0.287041, acc 0.890625\n",
      "2018-05-04T20:01:51.538589: step 21152, loss 0.197348, acc 0.890625\n",
      "2018-05-04T20:01:52.577050: step 21153, loss 0.356242, acc 0.84375\n",
      "2018-05-04T20:01:53.556625: step 21154, loss 0.271952, acc 0.875\n",
      "2018-05-04T20:01:54.521707: step 21155, loss 0.178355, acc 0.921875\n",
      "2018-05-04T20:01:55.487520: step 21156, loss 0.371344, acc 0.84375\n",
      "2018-05-04T20:01:56.459547: step 21157, loss 0.218599, acc 0.9375\n",
      "2018-05-04T20:01:57.415914: step 21158, loss 0.300751, acc 0.890625\n",
      "2018-05-04T20:01:58.371701: step 21159, loss 0.361283, acc 0.828125\n",
      "2018-05-04T20:01:59.331076: step 21160, loss 0.360038, acc 0.828125\n",
      "2018-05-04T20:02:00.363310: step 21161, loss 0.265287, acc 0.859375\n",
      "2018-05-04T20:02:01.325005: step 21162, loss 0.242923, acc 0.90625\n",
      "2018-05-04T20:02:02.287819: step 21163, loss 0.27673, acc 0.890625\n",
      "2018-05-04T20:02:03.237164: step 21164, loss 0.269828, acc 0.90625\n",
      "2018-05-04T20:02:04.257191: step 21165, loss 0.29658, acc 0.875\n",
      "2018-05-04T20:02:05.263619: step 21166, loss 0.386764, acc 0.859375\n",
      "2018-05-04T20:02:06.313111: step 21167, loss 0.168357, acc 0.9375\n",
      "2018-05-04T20:02:07.347701: step 21168, loss 0.247136, acc 0.890625\n",
      "2018-05-04T20:02:08.288223: step 21169, loss 0.232233, acc 0.90625\n",
      "2018-05-04T20:02:09.243546: step 21170, loss 0.207383, acc 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T20:02:10.184331: step 21171, loss 0.305797, acc 0.890625\n",
      "2018-05-04T20:02:11.126311: step 21172, loss 0.148209, acc 0.953125\n",
      "2018-05-04T20:02:12.093505: step 21173, loss 0.29507, acc 0.9375\n",
      "2018-05-04T20:02:13.059968: step 21174, loss 0.310252, acc 0.875\n",
      "2018-05-04T20:02:14.053573: step 21175, loss 0.27225, acc 0.890625\n",
      "2018-05-04T20:02:14.998634: step 21176, loss 0.241858, acc 0.90625\n",
      "2018-05-04T20:02:15.925249: step 21177, loss 0.262402, acc 0.921875\n",
      "2018-05-04T20:02:16.878203: step 21178, loss 0.249011, acc 0.921875\n",
      "2018-05-04T20:02:17.847314: step 21179, loss 0.140538, acc 0.921875\n",
      "2018-05-04T20:02:18.796379: step 21180, loss 0.354167, acc 0.78125\n",
      "2018-05-04T20:02:19.770109: step 21181, loss 0.315045, acc 0.84375\n",
      "2018-05-04T20:02:20.743771: step 21182, loss 0.306381, acc 0.921875\n",
      "2018-05-04T20:02:21.733491: step 21183, loss 0.284357, acc 0.890625\n",
      "2018-05-04T20:02:22.695219: step 21184, loss 0.309301, acc 0.84375\n",
      "2018-05-04T20:02:23.673221: step 21185, loss 0.31242, acc 0.921875\n",
      "2018-05-04T20:02:24.606958: step 21186, loss 0.323618, acc 0.84375\n",
      "2018-05-04T20:02:25.562886: step 21187, loss 0.244126, acc 0.90625\n",
      "2018-05-04T20:02:26.525209: step 21188, loss 0.375734, acc 0.828125\n",
      "2018-05-04T20:02:27.473964: step 21189, loss 0.303912, acc 0.859375\n",
      "2018-05-04T20:02:28.435956: step 21190, loss 0.257103, acc 0.921875\n",
      "2018-05-04T20:02:29.435264: step 21191, loss 0.230413, acc 0.90625\n",
      "2018-05-04T20:02:30.386459: step 21192, loss 0.401618, acc 0.828125\n",
      "2018-05-04T20:02:31.352044: step 21193, loss 0.247387, acc 0.875\n",
      "2018-05-04T20:02:32.332820: step 21194, loss 0.305073, acc 0.890625\n",
      "2018-05-04T20:02:33.327581: step 21195, loss 0.167878, acc 0.9375\n",
      "2018-05-04T20:02:34.277628: step 21196, loss 0.19402, acc 0.921875\n",
      "2018-05-04T20:02:35.228664: step 21197, loss 0.227499, acc 0.953125\n",
      "2018-05-04T20:02:36.194648: step 21198, loss 0.256881, acc 0.859375\n",
      "2018-05-04T20:02:37.143344: step 21199, loss 0.182927, acc 0.9375\n",
      "2018-05-04T20:02:38.080940: step 21200, loss 0.133639, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T20:02:40.186385: step 21200, loss 0.211738, acc 0.926\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-21200\n",
      "\n",
      "2018-05-04T20:02:41.326142: step 21201, loss 0.173815, acc 0.9375\n",
      "2018-05-04T20:02:42.280217: step 21202, loss 0.248022, acc 0.890625\n",
      "2018-05-04T20:02:43.218389: step 21203, loss 0.375014, acc 0.84375\n",
      "2018-05-04T20:02:44.175723: step 21204, loss 0.439184, acc 0.78125\n",
      "2018-05-04T20:02:45.122292: step 21205, loss 0.183664, acc 0.953125\n",
      "2018-05-04T20:02:46.148748: step 21206, loss 0.288623, acc 0.90625\n",
      "2018-05-04T20:02:47.106908: step 21207, loss 0.193598, acc 0.90625\n",
      "2018-05-04T20:02:48.056560: step 21208, loss 0.300729, acc 0.875\n",
      "2018-05-04T20:02:48.993818: step 21209, loss 0.289409, acc 0.859375\n",
      "2018-05-04T20:02:49.955663: step 21210, loss 0.381956, acc 0.859375\n",
      "2018-05-04T20:02:50.914345: step 21211, loss 0.265023, acc 0.875\n",
      "2018-05-04T20:02:51.863396: step 21212, loss 0.208567, acc 0.90625\n",
      "2018-05-04T20:02:52.836277: step 21213, loss 0.289667, acc 0.90625\n",
      "2018-05-04T20:02:53.807195: step 21214, loss 0.343622, acc 0.875\n",
      "2018-05-04T20:02:54.842741: step 21215, loss 0.150259, acc 0.9375\n",
      "2018-05-04T20:02:55.819443: step 21216, loss 0.264313, acc 0.890625\n",
      "2018-05-04T20:02:56.771734: step 21217, loss 0.167345, acc 0.953125\n",
      "2018-05-04T20:02:57.695530: step 21218, loss 0.23608, acc 0.890625\n",
      "2018-05-04T20:02:58.631800: step 21219, loss 0.285186, acc 0.890625\n",
      "2018-05-04T20:02:59.576293: step 21220, loss 0.295383, acc 0.875\n",
      "2018-05-04T20:03:00.634444: step 21221, loss 0.275577, acc 0.859375\n",
      "2018-05-04T20:03:01.653792: step 21222, loss 0.38715, acc 0.84375\n",
      "2018-05-04T20:03:02.632863: step 21223, loss 0.199603, acc 0.9375\n",
      "2018-05-04T20:03:03.620531: step 21224, loss 0.214889, acc 0.9375\n",
      "2018-05-04T20:03:04.660963: step 21225, loss 0.275812, acc 0.890625\n",
      "2018-05-04T20:03:05.642973: step 21226, loss 0.20234, acc 0.921875\n",
      "2018-05-04T20:03:06.619786: step 21227, loss 0.295739, acc 0.90625\n",
      "2018-05-04T20:03:07.562483: step 21228, loss 0.283575, acc 0.859375\n",
      "2018-05-04T20:03:08.495083: step 21229, loss 0.310337, acc 0.890625\n",
      "2018-05-04T20:03:09.446853: step 21230, loss 0.253121, acc 0.875\n",
      "2018-05-04T20:03:10.404396: step 21231, loss 0.296086, acc 0.859375\n",
      "2018-05-04T20:03:11.364574: step 21232, loss 0.267422, acc 0.859375\n",
      "2018-05-04T20:03:12.375822: step 21233, loss 0.306719, acc 0.859375\n",
      "2018-05-04T20:03:13.323287: step 21234, loss 0.342503, acc 0.90625\n",
      "2018-05-04T20:03:14.262424: step 21235, loss 0.275509, acc 0.90625\n",
      "2018-05-04T20:03:15.218831: step 21236, loss 0.228219, acc 0.90625\n",
      "2018-05-04T20:03:16.167454: step 21237, loss 0.311037, acc 0.859375\n",
      "2018-05-04T20:03:17.120444: step 21238, loss 0.311149, acc 0.921875\n",
      "2018-05-04T20:03:18.106978: step 21239, loss 0.19405, acc 0.921875\n",
      "2018-05-04T20:03:19.068279: step 21240, loss 0.251064, acc 0.890625\n",
      "2018-05-04T20:03:20.008603: step 21241, loss 0.226702, acc 0.890625\n",
      "2018-05-04T20:03:21.072918: step 21242, loss 0.276087, acc 0.90625\n",
      "2018-05-04T20:03:22.152358: step 21243, loss 0.263428, acc 0.90625\n",
      "2018-05-04T20:03:23.087340: step 21244, loss 0.207498, acc 0.90625\n",
      "2018-05-04T20:03:24.036171: step 21245, loss 0.170076, acc 0.921875\n",
      "2018-05-04T20:03:24.968731: step 21246, loss 0.245096, acc 0.90625\n",
      "2018-05-04T20:03:25.923519: step 21247, loss 0.255633, acc 0.890625\n",
      "2018-05-04T20:03:26.869150: step 21248, loss 0.148138, acc 0.96875\n",
      "2018-05-04T20:03:27.823653: step 21249, loss 0.291298, acc 0.859375\n",
      "2018-05-04T20:03:28.805128: step 21250, loss 0.229729, acc 0.921875\n",
      "2018-05-04T20:03:29.785835: step 21251, loss 0.360842, acc 0.859375\n",
      "2018-05-04T20:03:30.721943: step 21252, loss 0.239794, acc 0.921875\n",
      "2018-05-04T20:03:31.668426: step 21253, loss 0.253361, acc 0.875\n",
      "2018-05-04T20:03:32.610883: step 21254, loss 0.244241, acc 0.921875\n",
      "2018-05-04T20:03:33.627993: step 21255, loss 0.178251, acc 0.90625\n",
      "2018-05-04T20:03:34.580472: step 21256, loss 0.251017, acc 0.9375\n",
      "2018-05-04T20:03:35.528598: step 21257, loss 0.232964, acc 0.9375\n",
      "2018-05-04T20:03:36.472909: step 21258, loss 0.312972, acc 0.875\n",
      "2018-05-04T20:03:37.424365: step 21259, loss 0.225942, acc 0.90625\n",
      "2018-05-04T20:03:38.374238: step 21260, loss 0.229782, acc 0.890625\n",
      "2018-05-04T20:03:39.320244: step 21261, loss 0.26913, acc 0.890625\n",
      "2018-05-04T20:03:40.260915: step 21262, loss 0.170163, acc 0.953125\n",
      "2018-05-04T20:03:41.206422: step 21263, loss 0.180336, acc 0.90625\n",
      "2018-05-04T20:03:42.234871: step 21264, loss 0.220268, acc 0.9375\n",
      "2018-05-04T20:03:43.206441: step 21265, loss 0.293585, acc 0.84375\n",
      "2018-05-04T20:03:44.165434: step 21266, loss 0.277819, acc 0.890625\n",
      "2018-05-04T20:03:45.105096: step 21267, loss 0.178737, acc 0.921875\n",
      "2018-05-04T20:03:46.048773: step 21268, loss 0.174195, acc 0.953125\n",
      "2018-05-04T20:03:46.979084: step 21269, loss 0.314739, acc 0.90625\n",
      "2018-05-04T20:03:47.908461: step 21270, loss 0.258219, acc 0.921875\n",
      "2018-05-04T20:03:48.855906: step 21271, loss 0.28199, acc 0.84375\n",
      "2018-05-04T20:03:49.796297: step 21272, loss 0.235793, acc 0.875\n",
      "2018-05-04T20:03:50.846674: step 21273, loss 0.207258, acc 0.9375\n",
      "2018-05-04T20:03:51.777069: step 21274, loss 0.167675, acc 0.953125\n",
      "2018-05-04T20:03:52.785312: step 21275, loss 0.151794, acc 0.90625\n",
      "2018-05-04T20:03:53.727185: step 21276, loss 0.146754, acc 0.953125\n",
      "2018-05-04T20:03:54.661172: step 21277, loss 0.254729, acc 0.890625\n",
      "2018-05-04T20:03:55.598453: step 21278, loss 0.161481, acc 0.921875\n",
      "2018-05-04T20:03:56.539656: step 21279, loss 0.46485, acc 0.84375\n",
      "2018-05-04T20:03:57.478518: step 21280, loss 0.206574, acc 0.9375\n",
      "2018-05-04T20:03:58.424242: step 21281, loss 0.175839, acc 0.953125\n",
      "2018-05-04T20:03:59.382582: step 21282, loss 0.327227, acc 0.828125\n",
      "2018-05-04T20:04:00.390358: step 21283, loss 0.151966, acc 0.953125\n",
      "2018-05-04T20:04:01.369554: step 21284, loss 0.219382, acc 0.90625\n",
      "2018-05-04T20:04:02.330955: step 21285, loss 0.298889, acc 0.875\n",
      "2018-05-04T20:04:03.269632: step 21286, loss 0.273981, acc 0.875\n",
      "2018-05-04T20:04:04.258221: step 21287, loss 0.271528, acc 0.953125\n",
      "2018-05-04T20:04:05.274283: step 21288, loss 0.25951, acc 0.90625\n",
      "2018-05-04T20:04:06.218682: step 21289, loss 0.122317, acc 0.953125\n",
      "2018-05-04T20:04:07.148203: step 21290, loss 0.208542, acc 0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T20:04:08.163728: step 21291, loss 0.214336, acc 0.9375\n",
      "2018-05-04T20:04:09.085945: step 21292, loss 0.19983, acc 0.921875\n",
      "2018-05-04T20:04:10.023448: step 21293, loss 0.151134, acc 0.90625\n",
      "2018-05-04T20:04:10.964988: step 21294, loss 0.311402, acc 0.859375\n",
      "2018-05-04T20:04:11.962748: step 21295, loss 0.249663, acc 0.921875\n",
      "2018-05-04T20:04:12.896191: step 21296, loss 0.155098, acc 0.921875\n",
      "2018-05-04T20:04:13.850703: step 21297, loss 0.198064, acc 0.90625\n",
      "2018-05-04T20:04:14.787512: step 21298, loss 0.272009, acc 0.90625\n",
      "2018-05-04T20:04:15.822491: step 21299, loss 0.220602, acc 0.890625\n",
      "2018-05-04T20:04:16.736995: step 21300, loss 0.243177, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T20:04:19.419425: step 21300, loss 0.244631, acc 0.918\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-21300\n",
      "\n",
      "2018-05-04T20:04:20.465324: step 21301, loss 0.182877, acc 0.921875\n",
      "2018-05-04T20:04:21.404089: step 21302, loss 0.37163, acc 0.84375\n",
      "2018-05-04T20:04:22.447965: step 21303, loss 0.394449, acc 0.84375\n",
      "2018-05-04T20:04:23.420314: step 21304, loss 0.177933, acc 0.921875\n",
      "2018-05-04T20:04:24.413225: step 21305, loss 0.242447, acc 0.890625\n",
      "2018-05-04T20:04:25.502139: step 21306, loss 0.266962, acc 0.890625\n",
      "2018-05-04T20:04:26.456217: step 21307, loss 0.254552, acc 0.921875\n",
      "2018-05-04T20:04:27.554024: step 21308, loss 0.11239, acc 0.96875\n",
      "2018-05-04T20:04:28.529404: step 21309, loss 0.234751, acc 0.875\n",
      "2018-05-04T20:04:29.553272: step 21310, loss 0.373182, acc 0.84375\n",
      "2018-05-04T20:04:30.514288: step 21311, loss 0.396461, acc 0.84375\n",
      "2018-05-04T20:04:31.519420: step 21312, loss 0.12, acc 0.96875\n",
      "2018-05-04T20:04:32.499976: step 21313, loss 0.240107, acc 0.921875\n",
      "2018-05-04T20:04:33.522192: step 21314, loss 0.210765, acc 0.921875\n",
      "2018-05-04T20:04:34.553694: step 21315, loss 0.17253, acc 0.921875\n",
      "2018-05-04T20:04:35.614420: step 21316, loss 0.172875, acc 0.90625\n",
      "2018-05-04T20:04:36.618741: step 21317, loss 0.348119, acc 0.890625\n",
      "2018-05-04T20:04:37.621694: step 21318, loss 0.25002, acc 0.890625\n",
      "2018-05-04T20:04:38.624887: step 21319, loss 0.241598, acc 0.9375\n",
      "2018-05-04T20:04:39.611488: step 21320, loss 0.213791, acc 0.90625\n",
      "2018-05-04T20:04:40.584871: step 21321, loss 0.271601, acc 0.90625\n",
      "2018-05-04T20:04:41.603125: step 21322, loss 0.275969, acc 0.890625\n",
      "2018-05-04T20:04:42.628006: step 21323, loss 0.199976, acc 0.890625\n",
      "2018-05-04T20:04:43.592802: step 21324, loss 0.289222, acc 0.890625\n",
      "2018-05-04T20:04:44.562748: step 21325, loss 0.401838, acc 0.84375\n",
      "2018-05-04T20:04:45.522254: step 21326, loss 0.193352, acc 0.890625\n",
      "2018-05-04T20:04:46.481453: step 21327, loss 0.295012, acc 0.890625\n",
      "2018-05-04T20:04:47.432845: step 21328, loss 0.299652, acc 0.875\n",
      "2018-05-04T20:04:48.399103: step 21329, loss 0.173379, acc 0.9375\n",
      "2018-05-04T20:04:49.371688: step 21330, loss 0.367641, acc 0.921875\n",
      "2018-05-04T20:04:50.336440: step 21331, loss 0.296551, acc 0.90625\n",
      "2018-05-04T20:04:51.316723: step 21332, loss 0.171711, acc 0.953125\n",
      "2018-05-04T20:04:52.283634: step 21333, loss 0.417073, acc 0.875\n",
      "2018-05-04T20:04:53.246587: step 21334, loss 0.19844, acc 0.96875\n",
      "2018-05-04T20:04:54.237373: step 21335, loss 0.30424, acc 0.90625\n",
      "2018-05-04T20:04:55.211000: step 21336, loss 0.192707, acc 0.9375\n",
      "2018-05-04T20:04:56.182730: step 21337, loss 0.174286, acc 0.9375\n",
      "2018-05-04T20:04:57.220722: step 21338, loss 0.266794, acc 0.890625\n",
      "2018-05-04T20:04:58.182746: step 21339, loss 0.19758, acc 0.921875\n",
      "2018-05-04T20:04:59.164181: step 21340, loss 0.277391, acc 0.890625\n",
      "2018-05-04T20:05:00.127850: step 21341, loss 0.282597, acc 0.921875\n",
      "2018-05-04T20:05:01.072902: step 21342, loss 0.259822, acc 0.890625\n",
      "2018-05-04T20:05:02.023434: step 21343, loss 0.141595, acc 0.953125\n",
      "2018-05-04T20:05:02.997227: step 21344, loss 0.24476, acc 0.90625\n",
      "2018-05-04T20:05:04.014737: step 21345, loss 0.275246, acc 0.875\n",
      "2018-05-04T20:05:04.997816: step 21346, loss 0.348997, acc 0.84375\n",
      "2018-05-04T20:05:05.965438: step 21347, loss 0.189495, acc 0.9375\n",
      "2018-05-04T20:05:06.939803: step 21348, loss 0.308452, acc 0.875\n",
      "2018-05-04T20:05:07.994344: step 21349, loss 0.209523, acc 0.9375\n",
      "2018-05-04T20:05:08.972087: step 21350, loss 0.278582, acc 0.859375\n",
      "2018-05-04T20:05:09.923325: step 21351, loss 0.306064, acc 0.875\n",
      "2018-05-04T20:05:10.893030: step 21352, loss 0.303828, acc 0.875\n",
      "2018-05-04T20:05:11.859736: step 21353, loss 0.239535, acc 0.890625\n",
      "2018-05-04T20:05:12.827952: step 21354, loss 0.306248, acc 0.859375\n",
      "2018-05-04T20:05:13.787492: step 21355, loss 0.311597, acc 0.859375\n",
      "2018-05-04T20:05:14.741804: step 21356, loss 0.182003, acc 0.953125\n",
      "2018-05-04T20:05:15.722422: step 21357, loss 0.329227, acc 0.890625\n",
      "2018-05-04T20:05:16.702679: step 21358, loss 0.282597, acc 0.890625\n",
      "2018-05-04T20:05:17.699899: step 21359, loss 0.336676, acc 0.859375\n",
      "2018-05-04T20:05:18.727100: step 21360, loss 0.25239, acc 0.90625\n",
      "2018-05-04T20:05:19.733288: step 21361, loss 0.192337, acc 0.9375\n",
      "2018-05-04T20:05:20.780232: step 21362, loss 0.275298, acc 0.90625\n",
      "2018-05-04T20:05:21.753641: step 21363, loss 0.153854, acc 0.953125\n",
      "2018-05-04T20:05:22.751718: step 21364, loss 0.230763, acc 0.890625\n",
      "2018-05-04T20:05:23.729374: step 21365, loss 0.192765, acc 0.90625\n",
      "2018-05-04T20:05:24.742444: step 21366, loss 0.369379, acc 0.828125\n",
      "2018-05-04T20:05:25.719435: step 21367, loss 0.19104, acc 0.921875\n",
      "2018-05-04T20:05:26.681381: step 21368, loss 0.176747, acc 0.953125\n",
      "2018-05-04T20:05:27.630362: step 21369, loss 0.262966, acc 0.890625\n",
      "2018-05-04T20:05:28.560765: step 21370, loss 0.265312, acc 0.890625\n",
      "2018-05-04T20:05:29.538555: step 21371, loss 0.235099, acc 0.890625\n",
      "2018-05-04T20:05:30.595332: step 21372, loss 0.445114, acc 0.890625\n",
      "2018-05-04T20:05:31.616048: step 21373, loss 0.156774, acc 0.9375\n",
      "2018-05-04T20:05:32.557271: step 21374, loss 0.245146, acc 0.90625\n",
      "2018-05-04T20:05:33.526068: step 21375, loss 0.271835, acc 0.875\n",
      "2018-05-04T20:05:34.486210: step 21376, loss 0.205541, acc 0.890625\n",
      "2018-05-04T20:05:35.434495: step 21377, loss 0.322906, acc 0.84375\n",
      "2018-05-04T20:05:36.390162: step 21378, loss 0.279791, acc 0.921875\n",
      "2018-05-04T20:05:37.367480: step 21379, loss 0.312423, acc 0.875\n",
      "2018-05-04T20:05:38.337456: step 21380, loss 0.259194, acc 0.859375\n",
      "2018-05-04T20:05:39.326692: step 21381, loss 0.166073, acc 0.921875\n",
      "2018-05-04T20:05:40.296680: step 21382, loss 0.239622, acc 0.890625\n",
      "2018-05-04T20:05:41.290694: step 21383, loss 0.15317, acc 0.9375\n",
      "2018-05-04T20:05:42.266378: step 21384, loss 0.368361, acc 0.890625\n",
      "2018-05-04T20:05:43.232917: step 21385, loss 0.433709, acc 0.8125\n",
      "2018-05-04T20:05:44.185398: step 21386, loss 0.24432, acc 0.875\n",
      "2018-05-04T20:05:45.164081: step 21387, loss 0.274341, acc 0.875\n",
      "2018-05-04T20:05:46.111036: step 21388, loss 0.165694, acc 0.953125\n",
      "2018-05-04T20:05:47.060235: step 21389, loss 0.149992, acc 0.96875\n",
      "2018-05-04T20:05:48.024235: step 21390, loss 0.359838, acc 0.8125\n",
      "2018-05-04T20:05:48.955425: step 21391, loss 0.195173, acc 0.953125\n",
      "2018-05-04T20:05:49.913064: step 21392, loss 0.287688, acc 0.890625\n",
      "2018-05-04T20:05:50.876093: step 21393, loss 0.180592, acc 0.890625\n",
      "2018-05-04T20:05:51.831423: step 21394, loss 0.163059, acc 0.921875\n",
      "2018-05-04T20:05:52.796150: step 21395, loss 0.379089, acc 0.796875\n",
      "2018-05-04T20:05:53.781246: step 21396, loss 0.354873, acc 0.828125\n",
      "2018-05-04T20:05:54.720447: step 21397, loss 0.233065, acc 0.9375\n",
      "2018-05-04T20:05:55.677315: step 21398, loss 0.371275, acc 0.90625\n",
      "2018-05-04T20:05:56.649567: step 21399, loss 0.292914, acc 0.890625\n",
      "2018-05-04T20:05:57.634769: step 21400, loss 0.223217, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T20:05:59.768174: step 21400, loss 0.205626, acc 0.936\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-21400\n",
      "\n",
      "2018-05-04T20:06:00.782637: step 21401, loss 0.201947, acc 0.90625\n",
      "2018-05-04T20:06:01.745708: step 21402, loss 0.185463, acc 0.90625\n",
      "2018-05-04T20:06:02.690738: step 21403, loss 0.206248, acc 0.921875\n",
      "2018-05-04T20:06:03.652577: step 21404, loss 0.301826, acc 0.875\n",
      "2018-05-04T20:06:04.625775: step 21405, loss 0.265758, acc 0.890625\n",
      "2018-05-04T20:06:05.571757: step 21406, loss 0.255987, acc 0.9375\n",
      "2018-05-04T20:06:06.535778: step 21407, loss 0.289441, acc 0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T20:06:07.565798: step 21408, loss 0.218245, acc 0.921875\n",
      "2018-05-04T20:06:08.554127: step 21409, loss 0.227857, acc 0.921875\n",
      "2018-05-04T20:06:09.505185: step 21410, loss 0.447741, acc 0.828125\n",
      "2018-05-04T20:06:10.457123: step 21411, loss 0.205552, acc 0.9375\n",
      "2018-05-04T20:06:11.389729: step 21412, loss 0.179278, acc 0.890625\n",
      "2018-05-04T20:06:12.330511: step 21413, loss 0.230695, acc 0.890625\n",
      "2018-05-04T20:06:13.276671: step 21414, loss 0.208928, acc 0.875\n",
      "2018-05-04T20:06:14.239593: step 21415, loss 0.205039, acc 0.921875\n",
      "2018-05-04T20:06:15.233127: step 21416, loss 0.278125, acc 0.875\n",
      "2018-05-04T20:06:16.197830: step 21417, loss 0.261101, acc 0.875\n",
      "2018-05-04T20:06:17.156150: step 21418, loss 0.354515, acc 0.84375\n",
      "2018-05-04T20:06:18.145018: step 21419, loss 0.318638, acc 0.84375\n",
      "2018-05-04T20:06:19.122199: step 21420, loss 0.267041, acc 0.859375\n",
      "2018-05-04T20:06:20.041271: step 21421, loss 0.180145, acc 0.921875\n",
      "2018-05-04T20:06:21.014862: step 21422, loss 0.237595, acc 0.9375\n",
      "2018-05-04T20:06:22.055242: step 21423, loss 0.243596, acc 0.890625\n",
      "2018-05-04T20:06:23.008760: step 21424, loss 0.226841, acc 0.890625\n",
      "2018-05-04T20:06:23.955192: step 21425, loss 0.142366, acc 0.96875\n",
      "2018-05-04T20:06:24.997406: step 21426, loss 0.401964, acc 0.890625\n",
      "2018-05-04T20:06:25.947778: step 21427, loss 0.222593, acc 0.890625\n",
      "2018-05-04T20:06:26.884172: step 21428, loss 0.183757, acc 0.9375\n",
      "2018-05-04T20:06:27.836816: step 21429, loss 0.365065, acc 0.859375\n",
      "2018-05-04T20:06:28.785109: step 21430, loss 0.296858, acc 0.875\n",
      "2018-05-04T20:06:29.734591: step 21431, loss 0.240762, acc 0.90625\n",
      "2018-05-04T20:06:30.689317: step 21432, loss 0.290881, acc 0.875\n",
      "2018-05-04T20:06:31.640886: step 21433, loss 0.150619, acc 0.953125\n",
      "2018-05-04T20:06:32.578775: step 21434, loss 0.156661, acc 0.9375\n",
      "2018-05-04T20:06:33.529704: step 21435, loss 0.194146, acc 0.9375\n",
      "2018-05-04T20:06:34.485187: step 21436, loss 0.270811, acc 0.84375\n",
      "2018-05-04T20:06:35.510091: step 21437, loss 0.315976, acc 0.875\n",
      "2018-05-04T20:06:36.542778: step 21438, loss 0.325626, acc 0.875\n",
      "2018-05-04T20:06:37.495576: step 21439, loss 0.176889, acc 0.90625\n",
      "2018-05-04T20:06:38.443243: step 21440, loss 0.156892, acc 0.9375\n",
      "2018-05-04T20:06:39.518827: step 21441, loss 0.325017, acc 0.8125\n",
      "2018-05-04T20:06:40.569351: step 21442, loss 0.225343, acc 0.921875\n",
      "2018-05-04T20:06:41.527445: step 21443, loss 0.291495, acc 0.875\n",
      "2018-05-04T20:06:42.468313: step 21444, loss 0.182042, acc 0.9375\n",
      "2018-05-04T20:06:43.428310: step 21445, loss 0.138312, acc 0.953125\n",
      "2018-05-04T20:06:44.375236: step 21446, loss 0.356138, acc 0.859375\n",
      "2018-05-04T20:06:45.333938: step 21447, loss 0.352517, acc 0.84375\n",
      "2018-05-04T20:06:46.269821: step 21448, loss 0.435297, acc 0.84375\n",
      "2018-05-04T20:06:47.188050: step 21449, loss 0.394537, acc 0.859375\n",
      "2018-05-04T20:06:48.117293: step 21450, loss 0.271441, acc 0.890625\n",
      "2018-05-04T20:06:49.085664: step 21451, loss 0.341753, acc 0.90625\n",
      "2018-05-04T20:06:50.009901: step 21452, loss 0.284298, acc 0.875\n",
      "2018-05-04T20:06:50.961569: step 21453, loss 0.332618, acc 0.859375\n",
      "2018-05-04T20:06:51.931918: step 21454, loss 0.273745, acc 0.859375\n",
      "2018-05-04T20:06:52.884045: step 21455, loss 0.203227, acc 0.90625\n",
      "2018-05-04T20:06:53.869589: step 21456, loss 0.115698, acc 0.984375\n",
      "2018-05-04T20:06:54.804832: step 21457, loss 0.353004, acc 0.90625\n",
      "2018-05-04T20:06:55.730405: step 21458, loss 0.161579, acc 0.9375\n",
      "2018-05-04T20:06:56.666662: step 21459, loss 0.302835, acc 0.90625\n",
      "2018-05-04T20:06:57.625437: step 21460, loss 0.249477, acc 0.921875\n",
      "2018-05-04T20:06:58.586683: step 21461, loss 0.267436, acc 0.90625\n",
      "2018-05-04T20:06:59.540895: step 21462, loss 0.246829, acc 0.875\n",
      "2018-05-04T20:07:00.521507: step 21463, loss 0.15988, acc 0.9375\n",
      "2018-05-04T20:07:01.469392: step 21464, loss 0.301153, acc 0.875\n",
      "2018-05-04T20:07:02.409726: step 21465, loss 0.21861, acc 0.90625\n",
      "2018-05-04T20:07:03.376937: step 21466, loss 0.186954, acc 0.9375\n",
      "2018-05-04T20:07:04.376589: step 21467, loss 0.233974, acc 0.890625\n",
      "2018-05-04T20:07:05.356847: step 21468, loss 0.218705, acc 0.9375\n",
      "2018-05-04T20:07:06.299429: step 21469, loss 0.328274, acc 0.84375\n",
      "2018-05-04T20:07:07.237589: step 21470, loss 0.324625, acc 0.890625\n",
      "2018-05-04T20:07:08.168195: step 21471, loss 0.24466, acc 0.921875\n",
      "2018-05-04T20:07:09.100200: step 21472, loss 0.135734, acc 0.96875\n",
      "2018-05-04T20:07:10.057360: step 21473, loss 0.276795, acc 0.90625\n",
      "2018-05-04T20:07:11.031544: step 21474, loss 0.219439, acc 0.9375\n",
      "2018-05-04T20:07:11.997921: step 21475, loss 0.225147, acc 0.9375\n",
      "2018-05-04T20:07:13.014982: step 21476, loss 0.244423, acc 0.859375\n",
      "2018-05-04T20:07:13.949097: step 21477, loss 0.221797, acc 0.921875\n",
      "2018-05-04T20:07:14.873951: step 21478, loss 0.237266, acc 0.921875\n",
      "2018-05-04T20:07:15.802346: step 21479, loss 0.237909, acc 0.921875\n",
      "2018-05-04T20:07:16.741192: step 21480, loss 0.274793, acc 0.9375\n",
      "2018-05-04T20:07:17.733359: step 21481, loss 0.281225, acc 0.890625\n",
      "2018-05-04T20:07:18.679912: step 21482, loss 0.364539, acc 0.890625\n",
      "2018-05-04T20:07:19.718676: step 21483, loss 0.272803, acc 0.890625\n",
      "2018-05-04T20:07:20.785386: step 21484, loss 0.189261, acc 0.9375\n",
      "2018-05-04T20:07:21.771270: step 21485, loss 0.215948, acc 0.921875\n",
      "2018-05-04T20:07:22.729040: step 21486, loss 0.255849, acc 0.859375\n",
      "2018-05-04T20:07:23.670305: step 21487, loss 0.172052, acc 0.90625\n",
      "2018-05-04T20:07:24.611086: step 21488, loss 0.310048, acc 0.90625\n",
      "2018-05-04T20:07:25.573822: step 21489, loss 0.361195, acc 0.890625\n",
      "2018-05-04T20:07:26.531786: step 21490, loss 0.225745, acc 0.90625\n",
      "2018-05-04T20:07:27.551401: step 21491, loss 0.235494, acc 0.90625\n",
      "2018-05-04T20:07:28.562218: step 21492, loss 0.222619, acc 0.921875\n",
      "2018-05-04T20:07:29.500567: step 21493, loss 0.274995, acc 0.9375\n",
      "2018-05-04T20:07:30.429334: step 21494, loss 0.212038, acc 0.890625\n",
      "2018-05-04T20:07:31.365265: step 21495, loss 0.165076, acc 0.953125\n",
      "2018-05-04T20:07:32.355189: step 21496, loss 0.225819, acc 0.90625\n",
      "2018-05-04T20:07:33.355799: step 21497, loss 0.140362, acc 0.953125\n",
      "2018-05-04T20:07:34.354688: step 21498, loss 0.194586, acc 0.921875\n",
      "2018-05-04T20:07:35.344934: step 21499, loss 0.380607, acc 0.78125\n",
      "2018-05-04T20:07:36.364311: step 21500, loss 0.276681, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T20:07:38.487669: step 21500, loss 0.20885, acc 0.918\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-21500\n",
      "\n",
      "2018-05-04T20:07:39.576091: step 21501, loss 0.243321, acc 0.890625\n",
      "2018-05-04T20:07:40.599892: step 21502, loss 0.166788, acc 0.921875\n",
      "2018-05-04T20:07:41.616167: step 21503, loss 0.541476, acc 0.8125\n",
      "2018-05-04T20:07:42.593970: step 21504, loss 0.162879, acc 0.953125\n",
      "2018-05-04T20:07:43.510729: step 21505, loss 0.200908, acc 0.921875\n",
      "2018-05-04T20:07:44.444201: step 21506, loss 0.224592, acc 0.90625\n",
      "2018-05-04T20:07:45.462104: step 21507, loss 0.1676, acc 0.921875\n",
      "2018-05-04T20:07:46.401016: step 21508, loss 0.22368, acc 0.921875\n",
      "2018-05-04T20:07:47.338220: step 21509, loss 0.145106, acc 0.9375\n",
      "2018-05-04T20:07:48.366911: step 21510, loss 0.178081, acc 0.9375\n",
      "2018-05-04T20:07:49.294518: step 21511, loss 0.210003, acc 0.875\n",
      "2018-05-04T20:07:50.223432: step 21512, loss 0.24511, acc 0.875\n",
      "2018-05-04T20:07:51.151789: step 21513, loss 0.340177, acc 0.875\n",
      "2018-05-04T20:07:52.086289: step 21514, loss 0.311751, acc 0.859375\n",
      "2018-05-04T20:07:53.099876: step 21515, loss 0.322109, acc 0.90625\n",
      "2018-05-04T20:07:54.031371: step 21516, loss 0.361114, acc 0.828125\n",
      "2018-05-04T20:07:55.032411: step 21517, loss 0.182897, acc 0.9375\n",
      "2018-05-04T20:07:56.021385: step 21518, loss 0.322531, acc 0.859375\n",
      "2018-05-04T20:07:56.944720: step 21519, loss 0.15081, acc 0.96875\n",
      "2018-05-04T20:07:57.949659: step 21520, loss 0.210629, acc 0.890625\n",
      "2018-05-04T20:07:58.959877: step 21521, loss 0.238175, acc 0.90625\n",
      "2018-05-04T20:07:59.874084: step 21522, loss 0.289147, acc 0.875\n",
      "2018-05-04T20:08:00.803805: step 21523, loss 0.158394, acc 0.9375\n",
      "2018-05-04T20:08:01.739543: step 21524, loss 0.271164, acc 0.875\n",
      "2018-05-04T20:08:02.724027: step 21525, loss 0.2488, acc 0.90625\n",
      "2018-05-04T20:08:03.658629: step 21526, loss 0.277758, acc 0.875\n",
      "2018-05-04T20:08:04.686911: step 21527, loss 0.330175, acc 0.84375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T20:08:05.620340: step 21528, loss 0.176399, acc 0.90625\n",
      "2018-05-04T20:08:06.555085: step 21529, loss 0.219493, acc 0.921875\n",
      "2018-05-04T20:08:07.494106: step 21530, loss 0.345439, acc 0.8125\n",
      "2018-05-04T20:08:08.452575: step 21531, loss 0.219226, acc 0.90625\n",
      "2018-05-04T20:08:09.420997: step 21532, loss 0.181632, acc 0.921875\n",
      "2018-05-04T20:08:10.450674: step 21533, loss 0.361094, acc 0.828125\n",
      "2018-05-04T20:08:11.464805: step 21534, loss 0.210077, acc 0.9375\n",
      "2018-05-04T20:08:12.484759: step 21535, loss 0.154576, acc 0.921875\n",
      "2018-05-04T20:08:13.496972: step 21536, loss 0.299255, acc 0.84375\n",
      "2018-05-04T20:08:14.412055: step 21537, loss 0.196055, acc 0.9375\n",
      "2018-05-04T20:08:15.324377: step 21538, loss 0.357912, acc 0.890625\n",
      "2018-05-04T20:08:16.336759: step 21539, loss 0.28046, acc 0.84375\n",
      "2018-05-04T20:08:17.262986: step 21540, loss 0.251931, acc 0.875\n",
      "2018-05-04T20:08:18.207992: step 21541, loss 0.359985, acc 0.859375\n",
      "2018-05-04T20:08:19.144738: step 21542, loss 0.133259, acc 0.984375\n",
      "2018-05-04T20:08:20.159109: step 21543, loss 0.338423, acc 0.828125\n",
      "2018-05-04T20:08:21.108466: step 21544, loss 0.236786, acc 0.875\n",
      "2018-05-04T20:08:22.117959: step 21545, loss 0.149981, acc 0.953125\n",
      "2018-05-04T20:08:23.039687: step 21546, loss 0.208162, acc 0.90625\n",
      "2018-05-04T20:08:24.014133: step 21547, loss 0.31438, acc 0.859375\n",
      "2018-05-04T20:08:25.035547: step 21548, loss 0.277903, acc 0.921875\n",
      "2018-05-04T20:08:26.044781: step 21549, loss 0.250365, acc 0.859375\n",
      "2018-05-04T20:08:27.054621: step 21550, loss 0.190052, acc 0.921875\n",
      "2018-05-04T20:08:28.062682: step 21551, loss 0.245812, acc 0.921875\n",
      "2018-05-04T20:08:28.990353: step 21552, loss 0.214214, acc 0.921875\n",
      "2018-05-04T20:08:29.915772: step 21553, loss 0.218636, acc 0.890625\n",
      "2018-05-04T20:08:30.877819: step 21554, loss 0.209904, acc 0.921875\n",
      "2018-05-04T20:08:31.856341: step 21555, loss 0.235518, acc 0.84375\n",
      "2018-05-04T20:08:32.805577: step 21556, loss 0.192818, acc 0.921875\n",
      "2018-05-04T20:08:33.821594: step 21557, loss 0.331316, acc 0.859375\n",
      "2018-05-04T20:08:34.846987: step 21558, loss 0.345056, acc 0.859375\n",
      "2018-05-04T20:08:35.789588: step 21559, loss 0.303328, acc 0.84375\n",
      "2018-05-04T20:08:36.785390: step 21560, loss 0.202019, acc 0.890625\n",
      "2018-05-04T20:08:37.758662: step 21561, loss 0.288798, acc 0.90625\n",
      "2018-05-04T20:08:38.693850: step 21562, loss 0.269072, acc 0.84375\n",
      "2018-05-04T20:08:39.683068: step 21563, loss 0.256833, acc 0.859375\n",
      "2018-05-04T20:08:40.705442: step 21564, loss 0.157937, acc 0.921875\n",
      "2018-05-04T20:08:41.680596: step 21565, loss 0.262313, acc 0.921875\n",
      "2018-05-04T20:08:42.601740: step 21566, loss 0.165926, acc 0.953125\n",
      "2018-05-04T20:08:43.640082: step 21567, loss 0.228735, acc 0.953125\n",
      "2018-05-04T20:08:44.559020: step 21568, loss 0.229962, acc 0.90625\n",
      "2018-05-04T20:08:45.563442: step 21569, loss 0.366219, acc 0.828125\n",
      "2018-05-04T20:08:46.566675: step 21570, loss 0.0910401, acc 0.96875\n",
      "2018-05-04T20:08:47.570564: step 21571, loss 0.142867, acc 0.9375\n",
      "2018-05-04T20:08:48.474030: step 21572, loss 0.257379, acc 0.875\n",
      "2018-05-04T20:08:49.483131: step 21573, loss 0.232101, acc 0.90625\n",
      "2018-05-04T20:08:50.530938: step 21574, loss 0.31936, acc 0.875\n",
      "2018-05-04T20:08:51.509659: step 21575, loss 0.2337, acc 0.90625\n",
      "2018-05-04T20:08:52.517513: step 21576, loss 0.220971, acc 0.921875\n",
      "2018-05-04T20:08:53.438556: step 21577, loss 0.332077, acc 0.890625\n",
      "2018-05-04T20:08:54.406423: step 21578, loss 0.176786, acc 0.9375\n",
      "2018-05-04T20:08:55.385448: step 21579, loss 0.163541, acc 0.9375\n",
      "2018-05-04T20:08:56.398435: step 21580, loss 0.302117, acc 0.859375\n",
      "2018-05-04T20:08:57.397488: step 21581, loss 0.211548, acc 0.953125\n",
      "2018-05-04T20:08:58.393942: step 21582, loss 0.388147, acc 0.84375\n",
      "2018-05-04T20:08:59.406699: step 21583, loss 0.31069, acc 0.875\n",
      "2018-05-04T20:09:00.394215: step 21584, loss 0.164676, acc 0.9375\n",
      "2018-05-04T20:09:01.351886: step 21585, loss 0.237108, acc 0.890625\n",
      "2018-05-04T20:09:02.332870: step 21586, loss 0.248014, acc 0.921875\n",
      "2018-05-04T20:09:03.341078: step 21587, loss 0.183363, acc 0.890625\n",
      "2018-05-04T20:09:04.375386: step 21588, loss 0.162191, acc 0.953125\n",
      "2018-05-04T20:09:05.376465: step 21589, loss 0.193352, acc 0.921875\n",
      "2018-05-04T20:09:06.287550: step 21590, loss 0.191816, acc 0.921875\n",
      "2018-05-04T20:09:07.298988: step 21591, loss 0.235748, acc 0.921875\n",
      "2018-05-04T20:09:08.309667: step 21592, loss 0.30678, acc 0.859375\n",
      "2018-05-04T20:09:09.297980: step 21593, loss 0.281163, acc 0.875\n",
      "2018-05-04T20:09:10.351986: step 21594, loss 0.235814, acc 0.890625\n",
      "2018-05-04T20:09:11.376416: step 21595, loss 0.213682, acc 0.90625\n",
      "2018-05-04T20:09:12.392356: step 21596, loss 0.212515, acc 0.890625\n",
      "2018-05-04T20:09:13.408002: step 21597, loss 0.251514, acc 0.921875\n",
      "2018-05-04T20:09:14.447067: step 21598, loss 0.422567, acc 0.84375\n",
      "2018-05-04T20:09:15.444298: step 21599, loss 0.161151, acc 0.9375\n",
      "2018-05-04T20:09:16.410367: step 21600, loss 0.151806, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T20:09:18.955540: step 21600, loss 0.205437, acc 0.928\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-21600\n",
      "\n",
      "2018-05-04T20:09:20.020004: step 21601, loss 0.140856, acc 0.9375\n",
      "2018-05-04T20:09:20.988135: step 21602, loss 0.164267, acc 0.9375\n",
      "2018-05-04T20:09:21.980256: step 21603, loss 0.39248, acc 0.796875\n",
      "2018-05-04T20:09:23.000086: step 21604, loss 0.310283, acc 0.90625\n",
      "2018-05-04T20:09:23.987674: step 21605, loss 0.299733, acc 0.875\n",
      "2018-05-04T20:09:24.971070: step 21606, loss 0.290428, acc 0.859375\n",
      "2018-05-04T20:09:25.946245: step 21607, loss 0.251529, acc 0.90625\n",
      "2018-05-04T20:09:26.974557: step 21608, loss 0.352224, acc 0.828125\n",
      "2018-05-04T20:09:27.950918: step 21609, loss 0.278656, acc 0.921875\n",
      "2018-05-04T20:09:28.934133: step 21610, loss 0.29028, acc 0.84375\n",
      "2018-05-04T20:09:29.907972: step 21611, loss 0.16587, acc 0.90625\n",
      "2018-05-04T20:09:30.970483: step 21612, loss 0.159961, acc 0.9375\n",
      "2018-05-04T20:09:31.949391: step 21613, loss 0.270176, acc 0.84375\n",
      "2018-05-04T20:09:32.922369: step 21614, loss 0.405118, acc 0.828125\n",
      "2018-05-04T20:09:33.895492: step 21615, loss 0.284161, acc 0.890625\n",
      "2018-05-04T20:09:34.846975: step 21616, loss 0.245943, acc 0.890625\n",
      "2018-05-04T20:09:35.831053: step 21617, loss 0.23269, acc 0.890625\n",
      "2018-05-04T20:09:36.813646: step 21618, loss 0.201686, acc 0.921875\n",
      "2018-05-04T20:09:37.865809: step 21619, loss 0.200781, acc 0.9375\n",
      "2018-05-04T20:09:38.835619: step 21620, loss 0.228474, acc 0.890625\n",
      "2018-05-04T20:09:39.791000: step 21621, loss 0.208357, acc 0.890625\n",
      "2018-05-04T20:09:40.857781: step 21622, loss 0.329818, acc 0.859375\n",
      "2018-05-04T20:09:41.829014: step 21623, loss 0.294135, acc 0.875\n",
      "2018-05-04T20:09:42.775579: step 21624, loss 0.260615, acc 0.890625\n",
      "2018-05-04T20:09:43.754978: step 21625, loss 0.21876, acc 0.921875\n",
      "2018-05-04T20:09:44.708381: step 21626, loss 0.13878, acc 0.96875\n",
      "2018-05-04T20:09:45.692537: step 21627, loss 0.262417, acc 0.875\n",
      "2018-05-04T20:09:46.637433: step 21628, loss 0.316849, acc 0.828125\n",
      "2018-05-04T20:09:47.597739: step 21629, loss 0.226838, acc 0.921875\n",
      "2018-05-04T20:09:48.558089: step 21630, loss 0.301641, acc 0.828125\n",
      "2018-05-04T20:09:49.523601: step 21631, loss 0.220136, acc 0.921875\n",
      "2018-05-04T20:09:50.499379: step 21632, loss 0.206527, acc 0.9375\n",
      "2018-05-04T20:09:51.471356: step 21633, loss 0.323434, acc 0.84375\n",
      "2018-05-04T20:09:52.433930: step 21634, loss 0.293324, acc 0.859375\n",
      "2018-05-04T20:09:53.406564: step 21635, loss 0.19976, acc 0.90625\n",
      "2018-05-04T20:09:54.376991: step 21636, loss 0.28807, acc 0.875\n",
      "2018-05-04T20:09:55.343212: step 21637, loss 0.271287, acc 0.859375\n",
      "2018-05-04T20:09:56.309217: step 21638, loss 0.199647, acc 0.953125\n",
      "2018-05-04T20:09:57.284362: step 21639, loss 0.181628, acc 0.90625\n",
      "2018-05-04T20:09:58.258471: step 21640, loss 0.350066, acc 0.875\n",
      "2018-05-04T20:09:59.264403: step 21641, loss 0.328975, acc 0.90625\n",
      "2018-05-04T20:10:00.242581: step 21642, loss 0.272605, acc 0.90625\n",
      "2018-05-04T20:10:01.286569: step 21643, loss 0.201434, acc 0.90625\n",
      "2018-05-04T20:10:02.252411: step 21644, loss 0.21168, acc 0.90625\n",
      "2018-05-04T20:10:03.203480: step 21645, loss 0.344168, acc 0.84375\n",
      "2018-05-04T20:10:04.157231: step 21646, loss 0.298268, acc 0.859375\n",
      "2018-05-04T20:10:05.141782: step 21647, loss 0.167895, acc 0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T20:10:06.110029: step 21648, loss 0.431177, acc 0.828125\n",
      "2018-05-04T20:10:07.076787: step 21649, loss 0.379625, acc 0.828125\n",
      "2018-05-04T20:10:08.040307: step 21650, loss 0.237809, acc 0.9375\n",
      "2018-05-04T20:10:08.999171: step 21651, loss 0.273665, acc 0.875\n",
      "2018-05-04T20:10:09.965525: step 21652, loss 0.249125, acc 0.890625\n",
      "2018-05-04T20:10:10.977240: step 21653, loss 0.271971, acc 0.890625\n",
      "2018-05-04T20:10:11.919796: step 21654, loss 0.181236, acc 0.90625\n",
      "2018-05-04T20:10:12.865036: step 21655, loss 0.20026, acc 0.953125\n",
      "2018-05-04T20:10:13.846313: step 21656, loss 0.216926, acc 0.90625\n",
      "2018-05-04T20:10:14.804113: step 21657, loss 0.357384, acc 0.828125\n",
      "2018-05-04T20:10:15.827688: step 21658, loss 0.214016, acc 0.875\n",
      "2018-05-04T20:10:16.809674: step 21659, loss 0.21087, acc 0.9375\n",
      "2018-05-04T20:10:17.774459: step 21660, loss 0.280012, acc 0.875\n",
      "2018-05-04T20:10:18.771666: step 21661, loss 0.169434, acc 0.9375\n",
      "2018-05-04T20:10:19.800888: step 21662, loss 0.344028, acc 0.890625\n",
      "2018-05-04T20:10:20.783075: step 21663, loss 0.355759, acc 0.859375\n",
      "2018-05-04T20:10:21.752610: step 21664, loss 0.181049, acc 0.90625\n",
      "2018-05-04T20:10:22.714122: step 21665, loss 0.226802, acc 0.921875\n",
      "2018-05-04T20:10:23.674279: step 21666, loss 0.138944, acc 0.9375\n",
      "2018-05-04T20:10:24.613489: step 21667, loss 0.149355, acc 0.96875\n",
      "2018-05-04T20:10:25.624409: step 21668, loss 0.164256, acc 0.9375\n",
      "2018-05-04T20:10:26.574795: step 21669, loss 0.23854, acc 0.921875\n",
      "2018-05-04T20:10:27.517619: step 21670, loss 0.354071, acc 0.828125\n",
      "2018-05-04T20:10:28.584900: step 21671, loss 0.209177, acc 0.921875\n",
      "2018-05-04T20:10:29.545485: step 21672, loss 0.217277, acc 0.9375\n",
      "2018-05-04T20:10:30.539901: step 21673, loss 0.301876, acc 0.890625\n",
      "2018-05-04T20:10:31.515513: step 21674, loss 0.251142, acc 0.875\n",
      "2018-05-04T20:10:32.481041: step 21675, loss 0.261142, acc 0.921875\n",
      "2018-05-04T20:10:33.475468: step 21676, loss 0.275197, acc 0.875\n",
      "2018-05-04T20:10:34.499777: step 21677, loss 0.328101, acc 0.875\n",
      "2018-05-04T20:10:35.523498: step 21678, loss 0.306874, acc 0.8125\n",
      "2018-05-04T20:10:36.546559: step 21679, loss 0.418438, acc 0.890625\n",
      "2018-05-04T20:10:37.529293: step 21680, loss 0.230393, acc 0.890625\n",
      "2018-05-04T20:10:38.546246: step 21681, loss 0.226666, acc 0.875\n",
      "2018-05-04T20:10:39.532166: step 21682, loss 0.237772, acc 0.859375\n",
      "2018-05-04T20:10:40.499097: step 21683, loss 0.143876, acc 0.953125\n",
      "2018-05-04T20:10:41.486370: step 21684, loss 0.335024, acc 0.84375\n",
      "2018-05-04T20:10:42.431204: step 21685, loss 0.425846, acc 0.859375\n",
      "2018-05-04T20:10:43.387584: step 21686, loss 0.360079, acc 0.828125\n",
      "2018-05-04T20:10:44.347636: step 21687, loss 0.3477, acc 0.859375\n",
      "2018-05-04T20:10:45.290509: step 21688, loss 0.299325, acc 0.90625\n",
      "2018-05-04T20:10:46.254144: step 21689, loss 0.21308, acc 0.9375\n",
      "2018-05-04T20:10:47.245966: step 21690, loss 0.195717, acc 0.9375\n",
      "2018-05-04T20:10:48.298922: step 21691, loss 0.300817, acc 0.890625\n",
      "2018-05-04T20:10:49.254588: step 21692, loss 0.350187, acc 0.859375\n",
      "2018-05-04T20:10:50.191621: step 21693, loss 0.520303, acc 0.796875\n",
      "2018-05-04T20:10:51.151953: step 21694, loss 0.237104, acc 0.90625\n",
      "2018-05-04T20:10:52.135117: step 21695, loss 0.311162, acc 0.875\n",
      "2018-05-04T20:10:53.084272: step 21696, loss 0.327189, acc 0.859375\n",
      "2018-05-04T20:10:54.029617: step 21697, loss 0.267846, acc 0.9375\n",
      "2018-05-04T20:10:54.986838: step 21698, loss 0.172911, acc 0.90625\n",
      "2018-05-04T20:10:55.946546: step 21699, loss 0.270223, acc 0.890625\n",
      "2018-05-04T20:10:56.930653: step 21700, loss 0.348434, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T20:10:59.026183: step 21700, loss 0.21555, acc 0.93\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-21700\n",
      "\n",
      "2018-05-04T20:11:00.122913: step 21701, loss 0.255809, acc 0.875\n",
      "2018-05-04T20:11:01.076908: step 21702, loss 0.259746, acc 0.875\n",
      "2018-05-04T20:11:02.011847: step 21703, loss 0.277269, acc 0.90625\n",
      "2018-05-04T20:11:02.951514: step 21704, loss 0.22682, acc 0.921875\n",
      "2018-05-04T20:11:03.900811: step 21705, loss 0.309724, acc 0.84375\n",
      "2018-05-04T20:11:04.837090: step 21706, loss 0.188916, acc 0.921875\n",
      "2018-05-04T20:11:05.884234: step 21707, loss 0.214504, acc 0.9375\n",
      "2018-05-04T20:11:06.845301: step 21708, loss 0.220769, acc 0.96875\n",
      "2018-05-04T20:11:07.797499: step 21709, loss 0.257296, acc 0.890625\n",
      "2018-05-04T20:11:08.768433: step 21710, loss 0.20936, acc 0.921875\n",
      "2018-05-04T20:11:09.721776: step 21711, loss 0.208391, acc 0.921875\n",
      "2018-05-04T20:11:10.676842: step 21712, loss 0.332374, acc 0.859375\n",
      "2018-05-04T20:11:11.638707: step 21713, loss 0.189255, acc 0.9375\n",
      "2018-05-04T20:11:12.578486: step 21714, loss 0.165639, acc 0.921875\n",
      "2018-05-04T20:11:13.558176: step 21715, loss 0.19866, acc 0.90625\n",
      "2018-05-04T20:11:14.508881: step 21716, loss 0.164078, acc 0.9375\n",
      "2018-05-04T20:11:15.453411: step 21717, loss 0.240642, acc 0.890625\n",
      "2018-05-04T20:11:16.383645: step 21718, loss 0.206111, acc 0.921875\n",
      "2018-05-04T20:11:17.387146: step 21719, loss 0.319147, acc 0.84375\n",
      "2018-05-04T20:11:18.450212: step 21720, loss 0.366081, acc 0.890625\n",
      "2018-05-04T20:11:19.394875: step 21721, loss 0.189554, acc 0.921875\n",
      "2018-05-04T20:11:20.336486: step 21722, loss 0.26717, acc 0.90625\n",
      "2018-05-04T20:11:21.313213: step 21723, loss 0.418277, acc 0.875\n",
      "2018-05-04T20:11:22.268989: step 21724, loss 0.218813, acc 0.875\n",
      "2018-05-04T20:11:23.239315: step 21725, loss 0.34394, acc 0.890625\n",
      "2018-05-04T20:11:24.193231: step 21726, loss 0.20178, acc 0.984375\n",
      "2018-05-04T20:11:25.142643: step 21727, loss 0.157025, acc 0.9375\n",
      "2018-05-04T20:11:26.163986: step 21728, loss 0.152063, acc 0.9375\n",
      "2018-05-04T20:11:27.113167: step 21729, loss 0.331039, acc 0.890625\n",
      "2018-05-04T20:11:28.057749: step 21730, loss 0.233851, acc 0.875\n",
      "2018-05-04T20:11:28.994506: step 21731, loss 0.41999, acc 0.84375\n",
      "2018-05-04T20:11:29.961774: step 21732, loss 0.147212, acc 0.90625\n",
      "2018-05-04T20:11:30.911527: step 21733, loss 0.359764, acc 0.921875\n",
      "2018-05-04T20:11:31.862818: step 21734, loss 0.317175, acc 0.84375\n",
      "2018-05-04T20:11:32.815189: step 21735, loss 0.114604, acc 0.96875\n",
      "2018-05-04T20:11:33.784605: step 21736, loss 0.340129, acc 0.875\n",
      "2018-05-04T20:11:34.731213: step 21737, loss 0.281949, acc 0.890625\n",
      "2018-05-04T20:11:35.662622: step 21738, loss 0.2369, acc 0.9375\n",
      "2018-05-04T20:11:36.613052: step 21739, loss 0.299523, acc 0.875\n",
      "2018-05-04T20:11:37.582908: step 21740, loss 0.199405, acc 0.90625\n",
      "2018-05-04T20:11:38.554458: step 21741, loss 0.30692, acc 0.890625\n",
      "2018-05-04T20:11:39.565112: step 21742, loss 0.249912, acc 0.9375\n",
      "2018-05-04T20:11:40.506381: step 21743, loss 0.303383, acc 0.890625\n",
      "2018-05-04T20:11:41.587551: step 21744, loss 0.114271, acc 0.96875\n",
      "2018-05-04T20:11:42.504694: step 21745, loss 0.299504, acc 0.859375\n",
      "2018-05-04T20:11:43.445236: step 21746, loss 0.214699, acc 0.921875\n",
      "2018-05-04T20:11:44.368049: step 21747, loss 0.217339, acc 0.9375\n",
      "2018-05-04T20:11:45.297584: step 21748, loss 0.197924, acc 0.921875\n",
      "2018-05-04T20:11:46.234398: step 21749, loss 0.275923, acc 0.90625\n",
      "2018-05-04T20:11:47.167837: step 21750, loss 0.132447, acc 0.984375\n",
      "2018-05-04T20:11:48.097720: step 21751, loss 0.253729, acc 0.859375\n",
      "2018-05-04T20:11:49.062542: step 21752, loss 0.253038, acc 0.828125\n",
      "2018-05-04T20:11:50.121290: step 21753, loss 0.337468, acc 0.875\n",
      "2018-05-04T20:11:51.044419: step 21754, loss 0.286262, acc 0.90625\n",
      "2018-05-04T20:11:51.992139: step 21755, loss 0.300148, acc 0.90625\n",
      "2018-05-04T20:11:52.928110: step 21756, loss 0.293698, acc 0.890625\n",
      "2018-05-04T20:11:53.974399: step 21757, loss 0.183652, acc 0.90625\n",
      "2018-05-04T20:11:54.911305: step 21758, loss 0.130815, acc 0.953125\n",
      "2018-05-04T20:11:55.938808: step 21759, loss 0.312744, acc 0.859375\n",
      "2018-05-04T20:11:56.879928: step 21760, loss 0.264482, acc 0.875\n",
      "2018-05-04T20:11:57.815464: step 21761, loss 0.288941, acc 0.875\n",
      "2018-05-04T20:11:58.736939: step 21762, loss 0.203252, acc 0.921875\n",
      "2018-05-04T20:11:59.677390: step 21763, loss 0.210015, acc 0.90625\n",
      "2018-05-04T20:12:00.623806: step 21764, loss 0.386226, acc 0.875\n",
      "2018-05-04T20:12:01.621125: step 21765, loss 0.276783, acc 0.890625\n",
      "2018-05-04T20:12:02.556066: step 21766, loss 0.216086, acc 0.890625\n",
      "2018-05-04T20:12:03.517681: step 21767, loss 0.303479, acc 0.84375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T20:12:04.495291: step 21768, loss 0.242561, acc 0.90625\n",
      "2018-05-04T20:12:05.446404: step 21769, loss 0.200909, acc 0.90625\n",
      "2018-05-04T20:12:06.387664: step 21770, loss 0.149494, acc 0.9375\n",
      "2018-05-04T20:12:07.406507: step 21771, loss 0.196944, acc 0.90625\n",
      "2018-05-04T20:12:08.345743: step 21772, loss 0.365352, acc 0.828125\n",
      "2018-05-04T20:12:09.270387: step 21773, loss 0.148629, acc 0.921875\n",
      "2018-05-04T20:12:10.202318: step 21774, loss 0.316661, acc 0.859375\n",
      "2018-05-04T20:12:11.150878: step 21775, loss 0.260731, acc 0.90625\n",
      "2018-05-04T20:12:12.087567: step 21776, loss 0.241387, acc 0.875\n",
      "2018-05-04T20:12:13.015394: step 21777, loss 0.266046, acc 0.859375\n",
      "2018-05-04T20:12:14.042930: step 21778, loss 0.320274, acc 0.921875\n",
      "2018-05-04T20:12:14.972728: step 21779, loss 0.29201, acc 0.890625\n",
      "2018-05-04T20:12:15.901835: step 21780, loss 0.312732, acc 0.859375\n",
      "2018-05-04T20:12:16.854731: step 21781, loss 0.267639, acc 0.890625\n",
      "2018-05-04T20:12:17.794732: step 21782, loss 0.252318, acc 0.890625\n",
      "2018-05-04T20:12:18.808555: step 21783, loss 0.290811, acc 0.890625\n",
      "2018-05-04T20:12:19.757307: step 21784, loss 0.084954, acc 0.96875\n",
      "2018-05-04T20:12:20.741820: step 21785, loss 0.26191, acc 0.90625\n",
      "2018-05-04T20:12:21.734841: step 21786, loss 0.249416, acc 0.890625\n",
      "2018-05-04T20:12:22.689201: step 21787, loss 0.345633, acc 0.875\n",
      "2018-05-04T20:12:23.650635: step 21788, loss 0.28989, acc 0.921875\n",
      "2018-05-04T20:12:24.614726: step 21789, loss 0.207716, acc 0.90625\n",
      "2018-05-04T20:12:25.626445: step 21790, loss 0.299102, acc 0.90625\n",
      "2018-05-04T20:12:26.652419: step 21791, loss 0.187825, acc 0.90625\n",
      "2018-05-04T20:12:27.570778: step 21792, loss 0.189381, acc 0.875\n",
      "2018-05-04T20:12:28.507634: step 21793, loss 0.229421, acc 0.921875\n",
      "2018-05-04T20:12:29.463818: step 21794, loss 0.292719, acc 0.890625\n",
      "2018-05-04T20:12:30.394836: step 21795, loss 0.218087, acc 0.90625\n",
      "2018-05-04T20:12:31.324689: step 21796, loss 0.289012, acc 0.90625\n",
      "2018-05-04T20:12:32.263743: step 21797, loss 0.213314, acc 0.921875\n",
      "2018-05-04T20:12:33.279790: step 21798, loss 0.274018, acc 0.875\n",
      "2018-05-04T20:12:34.186341: step 21799, loss 0.172331, acc 0.953125\n",
      "2018-05-04T20:12:35.099673: step 21800, loss 0.29032, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T20:12:37.540650: step 21800, loss 0.229217, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-21800\n",
      "\n",
      "2018-05-04T20:12:38.648621: step 21801, loss 0.207866, acc 0.921875\n",
      "2018-05-04T20:12:39.618770: step 21802, loss 0.218643, acc 0.90625\n",
      "2018-05-04T20:12:40.609015: step 21803, loss 0.321227, acc 0.828125\n",
      "2018-05-04T20:12:41.589362: step 21804, loss 0.356637, acc 0.84375\n",
      "2018-05-04T20:12:42.679392: step 21805, loss 0.321009, acc 0.90625\n",
      "2018-05-04T20:12:43.689059: step 21806, loss 0.318036, acc 0.828125\n",
      "2018-05-04T20:12:44.708942: step 21807, loss 0.201175, acc 0.953125\n",
      "2018-05-04T20:12:45.710032: step 21808, loss 0.234762, acc 0.921875\n",
      "2018-05-04T20:12:46.741273: step 21809, loss 0.316822, acc 0.90625\n",
      "2018-05-04T20:12:47.752178: step 21810, loss 0.315037, acc 0.875\n",
      "2018-05-04T20:12:48.722991: step 21811, loss 0.252324, acc 0.90625\n",
      "2018-05-04T20:12:49.695994: step 21812, loss 0.29461, acc 0.875\n",
      "2018-05-04T20:12:50.651175: step 21813, loss 0.492418, acc 0.84375\n",
      "2018-05-04T20:12:51.692415: step 21814, loss 0.22439, acc 0.921875\n",
      "2018-05-04T20:12:52.675319: step 21815, loss 0.228615, acc 0.875\n",
      "2018-05-04T20:12:53.661186: step 21816, loss 0.319161, acc 0.859375\n",
      "2018-05-04T20:12:54.640973: step 21817, loss 0.253585, acc 0.890625\n",
      "2018-05-04T20:12:55.603719: step 21818, loss 0.347472, acc 0.875\n",
      "2018-05-04T20:12:56.578362: step 21819, loss 0.237755, acc 0.890625\n",
      "2018-05-04T20:12:57.593644: step 21820, loss 0.290145, acc 0.890625\n",
      "2018-05-04T20:12:58.585133: step 21821, loss 0.191065, acc 0.921875\n",
      "2018-05-04T20:12:59.582276: step 21822, loss 0.224548, acc 0.90625\n",
      "2018-05-04T20:13:00.560470: step 21823, loss 0.308743, acc 0.859375\n",
      "2018-05-04T20:13:01.620939: step 21824, loss 0.289571, acc 0.84375\n",
      "2018-05-04T20:13:02.591868: step 21825, loss 0.237427, acc 0.921875\n",
      "2018-05-04T20:13:03.573587: step 21826, loss 0.346199, acc 0.84375\n",
      "2018-05-04T20:13:04.542144: step 21827, loss 0.32451, acc 0.875\n",
      "2018-05-04T20:13:05.540152: step 21828, loss 0.372431, acc 0.828125\n",
      "2018-05-04T20:13:06.497822: step 21829, loss 0.262242, acc 0.921875\n",
      "2018-05-04T20:13:07.457071: step 21830, loss 0.188758, acc 0.9375\n",
      "2018-05-04T20:13:08.399180: step 21831, loss 0.270049, acc 0.875\n",
      "2018-05-04T20:13:09.375839: step 21832, loss 0.271748, acc 0.859375\n",
      "2018-05-04T20:13:10.337746: step 21833, loss 0.28456, acc 0.890625\n",
      "2018-05-04T20:13:11.303121: step 21834, loss 0.399812, acc 0.8125\n",
      "2018-05-04T20:13:12.270150: step 21835, loss 0.410995, acc 0.765625\n",
      "2018-05-04T20:13:13.228036: step 21836, loss 0.23422, acc 0.90625\n",
      "2018-05-04T20:13:14.182515: step 21837, loss 0.35972, acc 0.875\n",
      "2018-05-04T20:13:15.196836: step 21838, loss 0.387063, acc 0.859375\n",
      "2018-05-04T20:13:16.176622: step 21839, loss 0.209785, acc 0.90625\n",
      "2018-05-04T20:13:17.157833: step 21840, loss 0.189469, acc 0.9375\n",
      "2018-05-04T20:13:18.126176: step 21841, loss 0.363837, acc 0.796875\n",
      "2018-05-04T20:13:19.080803: step 21842, loss 0.168485, acc 0.921875\n",
      "2018-05-04T20:13:20.048101: step 21843, loss 0.257696, acc 0.890625\n",
      "2018-05-04T20:13:21.042860: step 21844, loss 0.192413, acc 0.953125\n",
      "2018-05-04T20:13:22.068556: step 21845, loss 0.326231, acc 0.8125\n",
      "2018-05-04T20:13:23.033923: step 21846, loss 0.264567, acc 0.90625\n",
      "2018-05-04T20:13:23.999178: step 21847, loss 0.157047, acc 0.96875\n",
      "2018-05-04T20:13:24.973772: step 21848, loss 0.236911, acc 0.890625\n",
      "2018-05-04T20:13:25.929284: step 21849, loss 0.228718, acc 0.9375\n",
      "2018-05-04T20:13:26.894391: step 21850, loss 0.476281, acc 0.84375\n",
      "2018-05-04T20:13:27.932423: step 21851, loss 0.305442, acc 0.84375\n",
      "2018-05-04T20:13:28.991725: step 21852, loss 0.230865, acc 0.890625\n",
      "2018-05-04T20:13:30.045259: step 21853, loss 0.211058, acc 0.953125\n",
      "2018-05-04T20:13:31.014190: step 21854, loss 0.245937, acc 0.890625\n",
      "2018-05-04T20:13:32.018762: step 21855, loss 0.377696, acc 0.8125\n",
      "2018-05-04T20:13:32.997131: step 21856, loss 0.180597, acc 0.953125\n",
      "2018-05-04T20:13:34.019724: step 21857, loss 0.249355, acc 0.90625\n",
      "2018-05-04T20:13:35.036001: step 21858, loss 0.242724, acc 0.921875\n",
      "2018-05-04T20:13:36.034640: step 21859, loss 0.193645, acc 0.921875\n",
      "2018-05-04T20:13:37.066359: step 21860, loss 0.29048, acc 0.828125\n",
      "2018-05-04T20:13:38.034428: step 21861, loss 0.242834, acc 0.859375\n",
      "2018-05-04T20:13:38.996999: step 21862, loss 0.20339, acc 0.921875\n",
      "2018-05-04T20:13:39.959147: step 21863, loss 0.212005, acc 0.921875\n",
      "2018-05-04T20:13:40.916912: step 21864, loss 0.243451, acc 0.890625\n",
      "2018-05-04T20:13:41.895042: step 21865, loss 0.294292, acc 0.890625\n",
      "2018-05-04T20:13:42.849545: step 21866, loss 0.302159, acc 0.890625\n",
      "2018-05-04T20:13:43.796028: step 21867, loss 0.34819, acc 0.890625\n",
      "2018-05-04T20:13:44.753746: step 21868, loss 0.335698, acc 0.84375\n",
      "2018-05-04T20:13:45.705937: step 21869, loss 0.164547, acc 0.921875\n",
      "2018-05-04T20:13:46.699494: step 21870, loss 0.243722, acc 0.90625\n",
      "2018-05-04T20:13:47.678980: step 21871, loss 0.282899, acc 0.875\n",
      "2018-05-04T20:13:48.696575: step 21872, loss 0.209943, acc 0.90625\n",
      "2018-05-04T20:13:49.669269: step 21873, loss 0.147823, acc 0.90625\n",
      "2018-05-04T20:13:50.629005: step 21874, loss 0.280001, acc 0.890625\n",
      "2018-05-04T20:13:51.599389: step 21875, loss 0.327057, acc 0.828125\n",
      "2018-05-04T20:13:52.599772: step 21876, loss 0.332991, acc 0.84375\n",
      "2018-05-04T20:13:53.592213: step 21877, loss 0.284192, acc 0.875\n",
      "2018-05-04T20:13:54.548802: step 21878, loss 0.24788, acc 0.890625\n",
      "2018-05-04T20:13:55.507128: step 21879, loss 0.157457, acc 0.9375\n",
      "2018-05-04T20:13:56.500074: step 21880, loss 0.211768, acc 0.890625\n",
      "2018-05-04T20:13:57.459624: step 21881, loss 0.20095, acc 0.90625\n",
      "2018-05-04T20:13:58.405297: step 21882, loss 0.292194, acc 0.859375\n",
      "2018-05-04T20:13:59.361728: step 21883, loss 0.31596, acc 0.875\n",
      "2018-05-04T20:14:00.297987: step 21884, loss 0.319764, acc 0.875\n",
      "2018-05-04T20:14:01.324339: step 21885, loss 0.248248, acc 0.921875\n",
      "2018-05-04T20:14:02.265019: step 21886, loss 0.142837, acc 0.953125\n",
      "2018-05-04T20:14:03.206390: step 21887, loss 0.277508, acc 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T20:14:04.183056: step 21888, loss 0.317019, acc 0.859375\n",
      "2018-05-04T20:14:05.163534: step 21889, loss 0.258003, acc 0.875\n",
      "2018-05-04T20:14:06.135190: step 21890, loss 0.27984, acc 0.890625\n",
      "2018-05-04T20:14:07.111268: step 21891, loss 0.314352, acc 0.859375\n",
      "2018-05-04T20:14:08.073001: step 21892, loss 0.360457, acc 0.84375\n",
      "2018-05-04T20:14:09.113431: step 21893, loss 0.241849, acc 0.9375\n",
      "2018-05-04T20:14:10.130647: step 21894, loss 0.252333, acc 0.875\n",
      "2018-05-04T20:14:11.050928: step 21895, loss 0.201397, acc 0.875\n",
      "2018-05-04T20:14:11.990388: step 21896, loss 0.157486, acc 0.921875\n",
      "2018-05-04T20:14:13.004312: step 21897, loss 0.329428, acc 0.859375\n",
      "2018-05-04T20:14:14.018088: step 21898, loss 0.209561, acc 0.90625\n",
      "2018-05-04T20:14:15.034304: step 21899, loss 0.251408, acc 0.890625\n",
      "2018-05-04T20:14:15.962050: step 21900, loss 0.298051, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T20:14:18.279855: step 21900, loss 0.216534, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-21900\n",
      "\n",
      "2018-05-04T20:14:19.383605: step 21901, loss 0.409379, acc 0.84375\n",
      "2018-05-04T20:14:20.366928: step 21902, loss 0.272608, acc 0.890625\n",
      "2018-05-04T20:14:21.349814: step 21903, loss 0.260347, acc 0.921875\n",
      "2018-05-04T20:14:22.367983: step 21904, loss 0.450185, acc 0.84375\n",
      "2018-05-04T20:14:23.375849: step 21905, loss 0.199484, acc 0.921875\n",
      "2018-05-04T20:14:24.395358: step 21906, loss 0.320133, acc 0.875\n",
      "2018-05-04T20:14:25.408488: step 21907, loss 0.275308, acc 0.859375\n",
      "2018-05-04T20:14:26.460243: step 21908, loss 0.21884, acc 0.90625\n",
      "2018-05-04T20:14:27.449116: step 21909, loss 0.196665, acc 0.9375\n",
      "2018-05-04T20:14:28.440454: step 21910, loss 0.301054, acc 0.859375\n",
      "2018-05-04T20:14:29.411837: step 21911, loss 0.224031, acc 0.90625\n",
      "2018-05-04T20:14:30.409875: step 21912, loss 0.170247, acc 0.953125\n",
      "2018-05-04T20:14:31.390667: step 21913, loss 0.373439, acc 0.859375\n",
      "2018-05-04T20:14:32.360852: step 21914, loss 0.227716, acc 0.875\n",
      "2018-05-04T20:14:33.324329: step 21915, loss 0.405362, acc 0.859375\n",
      "2018-05-04T20:14:34.286380: step 21916, loss 0.252331, acc 0.90625\n",
      "2018-05-04T20:14:35.310839: step 21917, loss 0.323282, acc 0.921875\n",
      "2018-05-04T20:14:36.289477: step 21918, loss 0.229514, acc 0.890625\n",
      "2018-05-04T20:14:37.273481: step 21919, loss 0.19569, acc 0.921875\n",
      "2018-05-04T20:14:38.213128: step 21920, loss 0.198495, acc 0.90625\n",
      "2018-05-04T20:14:39.163302: step 21921, loss 0.261839, acc 0.90625\n",
      "2018-05-04T20:14:40.128786: step 21922, loss 0.333007, acc 0.890625\n",
      "2018-05-04T20:14:41.083038: step 21923, loss 0.126939, acc 0.96875\n",
      "2018-05-04T20:14:42.038832: step 21924, loss 0.260239, acc 0.9375\n",
      "2018-05-04T20:14:43.008540: step 21925, loss 0.33243, acc 0.84375\n",
      "2018-05-04T20:14:43.990758: step 21926, loss 0.194829, acc 0.9375\n",
      "2018-05-04T20:14:44.967248: step 21927, loss 0.198128, acc 0.9375\n",
      "2018-05-04T20:14:45.931505: step 21928, loss 0.150945, acc 0.953125\n",
      "2018-05-04T20:14:46.895113: step 21929, loss 0.31049, acc 0.90625\n",
      "2018-05-04T20:14:47.911094: step 21930, loss 0.25624, acc 0.890625\n",
      "2018-05-04T20:14:48.902863: step 21931, loss 0.320853, acc 0.890625\n",
      "2018-05-04T20:14:49.955704: step 21932, loss 0.253892, acc 0.921875\n",
      "2018-05-04T20:14:50.943890: step 21933, loss 0.390172, acc 0.8125\n",
      "2018-05-04T20:14:51.917561: step 21934, loss 0.198207, acc 0.9375\n",
      "2018-05-04T20:14:52.871766: step 21935, loss 0.254403, acc 0.875\n",
      "2018-05-04T20:14:53.881902: step 21936, loss 0.225087, acc 0.921875\n",
      "2018-05-04T20:14:54.861712: step 21937, loss 0.26091, acc 0.890625\n",
      "2018-05-04T20:14:55.869804: step 21938, loss 0.362284, acc 0.890625\n",
      "2018-05-04T20:14:56.880678: step 21939, loss 0.244692, acc 0.90625\n",
      "2018-05-04T20:14:57.946135: step 21940, loss 0.20879, acc 0.921875\n",
      "2018-05-04T20:14:58.880875: step 21941, loss 0.40773, acc 0.859375\n",
      "2018-05-04T20:14:59.825561: step 21942, loss 0.197656, acc 0.9375\n",
      "2018-05-04T20:15:00.782847: step 21943, loss 0.15664, acc 0.953125\n",
      "2018-05-04T20:15:01.794790: step 21944, loss 0.315846, acc 0.859375\n",
      "2018-05-04T20:15:02.782562: step 21945, loss 0.148344, acc 0.921875\n",
      "2018-05-04T20:15:03.774343: step 21946, loss 0.30095, acc 0.875\n",
      "2018-05-04T20:15:04.756007: step 21947, loss 0.216265, acc 0.90625\n",
      "2018-05-04T20:15:05.740815: step 21948, loss 0.207234, acc 0.90625\n",
      "2018-05-04T20:15:06.699357: step 21949, loss 0.229713, acc 0.875\n",
      "2018-05-04T20:15:07.672331: step 21950, loss 0.230649, acc 0.890625\n",
      "2018-05-04T20:15:08.627334: step 21951, loss 0.371645, acc 0.84375\n",
      "2018-05-04T20:15:09.619656: step 21952, loss 0.106402, acc 0.96875\n",
      "2018-05-04T20:15:10.690017: step 21953, loss 0.472208, acc 0.90625\n",
      "2018-05-04T20:15:11.715456: step 21954, loss 0.251352, acc 0.921875\n",
      "2018-05-04T20:15:12.702184: step 21955, loss 0.23275, acc 0.90625\n",
      "2018-05-04T20:15:13.667097: step 21956, loss 0.36921, acc 0.828125\n",
      "2018-05-04T20:15:14.634403: step 21957, loss 0.195097, acc 0.921875\n",
      "2018-05-04T20:15:15.582235: step 21958, loss 0.317713, acc 0.859375\n",
      "2018-05-04T20:15:16.536942: step 21959, loss 0.27835, acc 0.8125\n",
      "2018-05-04T20:15:17.578941: step 21960, loss 0.192888, acc 0.921875\n",
      "2018-05-04T20:15:18.555843: step 21961, loss 0.193667, acc 0.921875\n",
      "2018-05-04T20:15:19.605632: step 21962, loss 0.270421, acc 0.875\n",
      "2018-05-04T20:15:20.561016: step 21963, loss 0.309053, acc 0.90625\n",
      "2018-05-04T20:15:21.529492: step 21964, loss 0.271644, acc 0.90625\n",
      "2018-05-04T20:15:22.558726: step 21965, loss 0.177553, acc 0.90625\n",
      "2018-05-04T20:15:23.538135: step 21966, loss 0.369027, acc 0.828125\n",
      "2018-05-04T20:15:24.492628: step 21967, loss 0.197986, acc 0.90625\n",
      "2018-05-04T20:15:25.458835: step 21968, loss 0.304077, acc 0.859375\n",
      "2018-05-04T20:15:26.451171: step 21969, loss 0.274646, acc 0.890625\n",
      "2018-05-04T20:15:27.427882: step 21970, loss 0.154721, acc 0.9375\n",
      "2018-05-04T20:15:28.370515: step 21971, loss 0.323844, acc 0.875\n",
      "2018-05-04T20:15:29.317740: step 21972, loss 0.275003, acc 0.890625\n",
      "2018-05-04T20:15:30.264819: step 21973, loss 0.360038, acc 0.875\n",
      "2018-05-04T20:15:31.235635: step 21974, loss 0.178759, acc 0.9375\n",
      "2018-05-04T20:15:32.192001: step 21975, loss 0.171435, acc 0.953125\n",
      "2018-05-04T20:15:33.235106: step 21976, loss 0.308671, acc 0.828125\n",
      "2018-05-04T20:15:34.222521: step 21977, loss 0.197853, acc 0.921875\n",
      "2018-05-04T20:15:35.195004: step 21978, loss 0.166282, acc 0.953125\n",
      "2018-05-04T20:15:36.149481: step 21979, loss 0.245996, acc 0.875\n",
      "2018-05-04T20:15:37.182865: step 21980, loss 0.162894, acc 0.96875\n",
      "2018-05-04T20:15:38.136464: step 21981, loss 0.252527, acc 0.921875\n",
      "2018-05-04T20:15:39.087641: step 21982, loss 0.276368, acc 0.890625\n",
      "2018-05-04T20:15:40.028226: step 21983, loss 0.273474, acc 0.875\n",
      "2018-05-04T20:15:40.961852: step 21984, loss 0.36961, acc 0.84375\n",
      "2018-05-04T20:15:41.897418: step 21985, loss 0.352257, acc 0.84375\n",
      "2018-05-04T20:15:42.860610: step 21986, loss 0.419794, acc 0.828125\n",
      "2018-05-04T20:15:43.813106: step 21987, loss 0.187136, acc 0.921875\n",
      "2018-05-04T20:15:44.740896: step 21988, loss 0.264884, acc 0.921875\n",
      "2018-05-04T20:15:45.760469: step 21989, loss 0.215163, acc 0.9375\n",
      "2018-05-04T20:15:46.713976: step 21990, loss 0.328762, acc 0.875\n",
      "2018-05-04T20:15:47.637814: step 21991, loss 0.240334, acc 0.875\n",
      "2018-05-04T20:15:48.562072: step 21992, loss 0.375672, acc 0.859375\n",
      "2018-05-04T20:15:49.517119: step 21993, loss 0.280347, acc 0.84375\n",
      "2018-05-04T20:15:50.460191: step 21994, loss 0.236461, acc 0.875\n",
      "2018-05-04T20:15:51.400556: step 21995, loss 0.168267, acc 0.96875\n",
      "2018-05-04T20:15:52.387785: step 21996, loss 0.422411, acc 0.75\n",
      "2018-05-04T20:15:53.361000: step 21997, loss 0.190465, acc 0.921875\n",
      "2018-05-04T20:15:54.312000: step 21998, loss 0.258338, acc 0.90625\n",
      "2018-05-04T20:15:55.282237: step 21999, loss 0.266333, acc 0.90625\n",
      "2018-05-04T20:15:56.231886: step 22000, loss 0.268237, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T20:15:58.358020: step 22000, loss 0.223968, acc 0.922\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-22000\n",
      "\n",
      "2018-05-04T20:15:59.400230: step 22001, loss 0.266568, acc 0.890625\n",
      "2018-05-04T20:16:00.358363: step 22002, loss 0.165429, acc 0.953125\n",
      "2018-05-04T20:16:01.292848: step 22003, loss 0.158076, acc 0.921875\n",
      "2018-05-04T20:16:02.240078: step 22004, loss 0.392206, acc 0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T20:16:03.199395: step 22005, loss 0.310666, acc 0.890625\n",
      "2018-05-04T20:16:04.165327: step 22006, loss 0.329002, acc 0.875\n",
      "2018-05-04T20:16:05.118337: step 22007, loss 0.322419, acc 0.890625\n",
      "2018-05-04T20:16:06.059484: step 22008, loss 0.236638, acc 0.890625\n",
      "2018-05-04T20:16:06.994098: step 22009, loss 0.230746, acc 0.890625\n",
      "2018-05-04T20:16:07.920584: step 22010, loss 0.254511, acc 0.890625\n",
      "2018-05-04T20:16:08.862008: step 22011, loss 0.421669, acc 0.828125\n",
      "2018-05-04T20:16:09.838124: step 22012, loss 0.21808, acc 0.90625\n",
      "2018-05-04T20:16:10.804728: step 22013, loss 0.393564, acc 0.859375\n",
      "2018-05-04T20:16:11.837574: step 22014, loss 0.261116, acc 0.890625\n",
      "2018-05-04T20:16:12.811525: step 22015, loss 0.191393, acc 0.953125\n",
      "2018-05-04T20:16:13.826307: step 22016, loss 0.303801, acc 0.890625\n",
      "2018-05-04T20:16:14.767588: step 22017, loss 0.248028, acc 0.875\n",
      "2018-05-04T20:16:15.710272: step 22018, loss 0.547349, acc 0.78125\n",
      "2018-05-04T20:16:16.659040: step 22019, loss 0.418626, acc 0.828125\n",
      "2018-05-04T20:16:17.598706: step 22020, loss 0.188426, acc 0.9375\n",
      "2018-05-04T20:16:18.544979: step 22021, loss 0.22183, acc 0.921875\n",
      "2018-05-04T20:16:19.492650: step 22022, loss 0.279646, acc 0.890625\n",
      "2018-05-04T20:16:20.419196: step 22023, loss 0.263844, acc 0.875\n",
      "2018-05-04T20:16:21.345834: step 22024, loss 0.263356, acc 0.90625\n",
      "2018-05-04T20:16:22.305304: step 22025, loss 0.182912, acc 0.9375\n",
      "2018-05-04T20:16:23.231955: step 22026, loss 0.271011, acc 0.84375\n",
      "2018-05-04T20:16:24.175451: step 22027, loss 0.129176, acc 0.984375\n",
      "2018-05-04T20:16:25.202809: step 22028, loss 0.162027, acc 0.953125\n",
      "2018-05-04T20:16:26.156070: step 22029, loss 0.375452, acc 0.84375\n",
      "2018-05-04T20:16:27.134035: step 22030, loss 0.281649, acc 0.890625\n",
      "2018-05-04T20:16:28.051756: step 22031, loss 0.26109, acc 0.890625\n",
      "2018-05-04T20:16:29.124182: step 22032, loss 0.224758, acc 0.90625\n",
      "2018-05-04T20:16:30.053742: step 22033, loss 0.209443, acc 0.921875\n",
      "2018-05-04T20:16:30.974651: step 22034, loss 0.293528, acc 0.859375\n",
      "2018-05-04T20:16:31.913066: step 22035, loss 0.181101, acc 0.953125\n",
      "2018-05-04T20:16:32.891490: step 22036, loss 0.154149, acc 0.9375\n",
      "2018-05-04T20:16:33.874305: step 22037, loss 0.292731, acc 0.8125\n",
      "2018-05-04T20:16:35.046662: step 22038, loss 0.205222, acc 0.90625\n",
      "2018-05-04T20:16:36.126019: step 22039, loss 0.338262, acc 0.859375\n",
      "2018-05-04T20:16:37.106227: step 22040, loss 0.316062, acc 0.90625\n",
      "2018-05-04T20:16:38.019212: step 22041, loss 0.201588, acc 0.921875\n",
      "2018-05-04T20:16:38.939864: step 22042, loss 0.210587, acc 0.90625\n",
      "2018-05-04T20:16:39.951329: step 22043, loss 0.232472, acc 0.90625\n",
      "2018-05-04T20:16:40.995518: step 22044, loss 0.298969, acc 0.890625\n",
      "2018-05-04T20:16:41.922271: step 22045, loss 0.22726, acc 0.90625\n",
      "2018-05-04T20:16:42.935302: step 22046, loss 0.333568, acc 0.875\n",
      "2018-05-04T20:16:43.931854: step 22047, loss 0.186508, acc 0.953125\n",
      "2018-05-04T20:16:44.936449: step 22048, loss 0.392371, acc 0.84375\n",
      "2018-05-04T20:16:45.872650: step 22049, loss 0.198365, acc 0.921875\n",
      "2018-05-04T20:16:46.801879: step 22050, loss 0.306166, acc 0.859375\n",
      "2018-05-04T20:16:47.743885: step 22051, loss 0.223509, acc 0.921875\n",
      "2018-05-04T20:16:48.684694: step 22052, loss 0.252621, acc 0.875\n",
      "2018-05-04T20:16:49.705567: step 22053, loss 0.252116, acc 0.90625\n",
      "2018-05-04T20:16:50.640583: step 22054, loss 0.342056, acc 0.84375\n",
      "2018-05-04T20:16:51.562903: step 22055, loss 0.260623, acc 0.875\n",
      "2018-05-04T20:16:52.584814: step 22056, loss 0.256688, acc 0.890625\n",
      "2018-05-04T20:16:53.510824: step 22057, loss 0.254357, acc 0.90625\n",
      "2018-05-04T20:16:54.440002: step 22058, loss 0.224614, acc 0.890625\n",
      "2018-05-04T20:16:55.511823: step 22059, loss 0.25449, acc 0.90625\n",
      "2018-05-04T20:16:56.509081: step 22060, loss 0.239981, acc 0.90625\n",
      "2018-05-04T20:16:57.433446: step 22061, loss 0.309349, acc 0.875\n",
      "2018-05-04T20:16:58.368311: step 22062, loss 0.170062, acc 0.9375\n",
      "2018-05-04T20:16:59.431782: step 22063, loss 0.159453, acc 0.9375\n",
      "2018-05-04T20:17:00.356804: step 22064, loss 0.331024, acc 0.875\n",
      "2018-05-04T20:17:01.379477: step 22065, loss 0.325485, acc 0.90625\n",
      "2018-05-04T20:17:02.319967: step 22066, loss 0.206945, acc 0.90625\n",
      "2018-05-04T20:17:03.325550: step 22067, loss 0.219793, acc 0.90625\n",
      "2018-05-04T20:17:04.271815: step 22068, loss 0.30976, acc 0.890625\n",
      "2018-05-04T20:17:05.202381: step 22069, loss 0.284784, acc 0.875\n",
      "2018-05-04T20:17:06.131781: step 22070, loss 0.157851, acc 0.953125\n",
      "2018-05-04T20:17:07.065774: step 22071, loss 0.296377, acc 0.890625\n",
      "2018-05-04T20:17:07.992348: step 22072, loss 0.195376, acc 0.890625\n",
      "2018-05-04T20:17:08.948772: step 22073, loss 0.249464, acc 0.90625\n",
      "2018-05-04T20:17:09.888801: step 22074, loss 0.389767, acc 0.859375\n",
      "2018-05-04T20:17:10.846435: step 22075, loss 0.18199, acc 0.90625\n",
      "2018-05-04T20:17:11.876312: step 22076, loss 0.296936, acc 0.875\n",
      "2018-05-04T20:17:12.891313: step 22077, loss 0.301608, acc 0.90625\n",
      "2018-05-04T20:17:13.913753: step 22078, loss 0.236011, acc 0.890625\n",
      "2018-05-04T20:17:14.843032: step 22079, loss 0.21162, acc 0.90625\n",
      "2018-05-04T20:17:15.774248: step 22080, loss 0.310645, acc 0.890625\n",
      "2018-05-04T20:17:16.813139: step 22081, loss 0.237167, acc 0.890625\n",
      "2018-05-04T20:17:17.785789: step 22082, loss 0.192022, acc 0.921875\n",
      "2018-05-04T20:17:18.724444: step 22083, loss 0.110586, acc 0.96875\n",
      "2018-05-04T20:17:19.656703: step 22084, loss 0.245693, acc 0.90625\n",
      "2018-05-04T20:17:20.649610: step 22085, loss 0.215479, acc 0.921875\n",
      "2018-05-04T20:17:21.696647: step 22086, loss 0.250796, acc 0.859375\n",
      "2018-05-04T20:17:22.713405: step 22087, loss 0.252947, acc 0.890625\n",
      "2018-05-04T20:17:23.645558: step 22088, loss 0.250394, acc 0.875\n",
      "2018-05-04T20:17:24.652409: step 22089, loss 0.192623, acc 0.90625\n",
      "2018-05-04T20:17:25.566317: step 22090, loss 0.329252, acc 0.875\n",
      "2018-05-04T20:17:26.579838: step 22091, loss 0.369873, acc 0.90625\n",
      "2018-05-04T20:17:27.594331: step 22092, loss 0.115907, acc 0.96875\n",
      "2018-05-04T20:17:28.598660: step 22093, loss 0.314003, acc 0.90625\n",
      "2018-05-04T20:17:29.622116: step 22094, loss 0.238865, acc 0.921875\n",
      "2018-05-04T20:17:30.627927: step 22095, loss 0.197574, acc 0.921875\n",
      "2018-05-04T20:17:31.638282: step 22096, loss 0.19737, acc 0.9375\n",
      "2018-05-04T20:17:32.639455: step 22097, loss 0.346982, acc 0.875\n",
      "2018-05-04T20:17:33.558821: step 22098, loss 0.27057, acc 0.875\n",
      "2018-05-04T20:17:34.593034: step 22099, loss 0.277598, acc 0.921875\n",
      "2018-05-04T20:17:35.515336: step 22100, loss 0.348436, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T20:17:38.855774: step 22100, loss 0.225958, acc 0.918\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-22100\n",
      "\n",
      "2018-05-04T20:17:39.962347: step 22101, loss 0.169365, acc 0.9375\n",
      "2018-05-04T20:17:40.942062: step 22102, loss 0.268813, acc 0.875\n",
      "2018-05-04T20:17:41.985045: step 22103, loss 0.259641, acc 0.90625\n",
      "2018-05-04T20:17:42.977083: step 22104, loss 0.188295, acc 0.9375\n",
      "2018-05-04T20:17:43.969222: step 22105, loss 0.216772, acc 0.9375\n",
      "2018-05-04T20:17:44.955346: step 22106, loss 0.267832, acc 0.90625\n",
      "2018-05-04T20:17:45.965101: step 22107, loss 0.27095, acc 0.84375\n",
      "2018-05-04T20:17:46.954862: step 22108, loss 0.35687, acc 0.90625\n",
      "2018-05-04T20:17:47.937840: step 22109, loss 0.18128, acc 0.90625\n",
      "2018-05-04T20:17:48.926076: step 22110, loss 0.290498, acc 0.859375\n",
      "2018-05-04T20:17:49.871950: step 22111, loss 0.308961, acc 0.859375\n",
      "2018-05-04T20:17:50.848360: step 22112, loss 0.363431, acc 0.78125\n",
      "2018-05-04T20:17:51.823627: step 22113, loss 0.363843, acc 0.859375\n",
      "2018-05-04T20:17:52.775142: step 22114, loss 0.321362, acc 0.90625\n",
      "2018-05-04T20:17:53.759881: step 22115, loss 0.230676, acc 0.890625\n",
      "2018-05-04T20:17:54.717119: step 22116, loss 0.306899, acc 0.859375\n",
      "2018-05-04T20:17:55.698739: step 22117, loss 0.323597, acc 0.890625\n",
      "2018-05-04T20:17:56.669751: step 22118, loss 0.303181, acc 0.890625\n",
      "2018-05-04T20:17:57.657580: step 22119, loss 0.359354, acc 0.875\n",
      "2018-05-04T20:17:58.639153: step 22120, loss 0.228471, acc 0.875\n",
      "2018-05-04T20:17:59.674387: step 22121, loss 0.365275, acc 0.828125\n",
      "2018-05-04T20:18:00.650615: step 22122, loss 0.283742, acc 0.84375\n",
      "2018-05-04T20:18:01.662248: step 22123, loss 0.228339, acc 0.9375\n",
      "2018-05-04T20:18:02.759713: step 22124, loss 0.316112, acc 0.84375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T20:18:03.717648: step 22125, loss 0.461071, acc 0.78125\n",
      "2018-05-04T20:18:04.698249: step 22126, loss 0.224723, acc 0.90625\n",
      "2018-05-04T20:18:05.658678: step 22127, loss 0.181303, acc 0.921875\n",
      "2018-05-04T20:18:06.654274: step 22128, loss 0.189014, acc 0.953125\n",
      "2018-05-04T20:18:07.629074: step 22129, loss 0.361343, acc 0.84375\n",
      "2018-05-04T20:18:08.598748: step 22130, loss 0.224365, acc 0.890625\n",
      "2018-05-04T20:18:09.566245: step 22131, loss 0.199057, acc 0.90625\n",
      "2018-05-04T20:18:10.538731: step 22132, loss 0.2282, acc 0.890625\n",
      "2018-05-04T20:18:11.501852: step 22133, loss 0.221491, acc 0.90625\n",
      "2018-05-04T20:18:12.515136: step 22134, loss 0.238116, acc 0.90625\n",
      "2018-05-04T20:18:13.484362: step 22135, loss 0.216319, acc 0.9375\n",
      "2018-05-04T20:18:14.536548: step 22136, loss 0.284028, acc 0.84375\n",
      "2018-05-04T20:18:15.494220: step 22137, loss 0.21316, acc 0.9375\n",
      "2018-05-04T20:18:16.461791: step 22138, loss 0.233401, acc 0.921875\n",
      "2018-05-04T20:18:17.432428: step 22139, loss 0.227987, acc 0.890625\n",
      "2018-05-04T20:18:18.386820: step 22140, loss 0.213999, acc 0.890625\n",
      "2018-05-04T20:18:19.358671: step 22141, loss 0.283654, acc 0.890625\n",
      "2018-05-04T20:18:20.332133: step 22142, loss 0.19562, acc 0.90625\n",
      "2018-05-04T20:18:21.296859: step 22143, loss 0.275522, acc 0.875\n",
      "2018-05-04T20:18:22.316027: step 22144, loss 0.263892, acc 0.890625\n",
      "2018-05-04T20:18:23.322200: step 22145, loss 0.211526, acc 0.921875\n",
      "2018-05-04T20:18:24.391069: step 22146, loss 0.203235, acc 0.9375\n",
      "2018-05-04T20:18:25.390034: step 22147, loss 0.279074, acc 0.859375\n",
      "2018-05-04T20:18:26.368767: step 22148, loss 0.215749, acc 0.890625\n",
      "2018-05-04T20:18:27.341251: step 22149, loss 0.367091, acc 0.84375\n",
      "2018-05-04T20:18:28.299517: step 22150, loss 0.209566, acc 0.875\n",
      "2018-05-04T20:18:29.288909: step 22151, loss 0.231749, acc 0.921875\n",
      "2018-05-04T20:18:30.296534: step 22152, loss 0.20511, acc 0.890625\n",
      "2018-05-04T20:18:31.362027: step 22153, loss 0.218159, acc 0.921875\n",
      "2018-05-04T20:18:32.362285: step 22154, loss 0.234371, acc 0.90625\n",
      "2018-05-04T20:18:33.344920: step 22155, loss 0.202287, acc 0.9375\n",
      "2018-05-04T20:18:34.335605: step 22156, loss 0.333072, acc 0.875\n",
      "2018-05-04T20:18:35.274098: step 22157, loss 0.25022, acc 0.890625\n",
      "2018-05-04T20:18:36.248387: step 22158, loss 0.339721, acc 0.859375\n",
      "2018-05-04T20:18:37.226974: step 22159, loss 0.154198, acc 0.96875\n",
      "2018-05-04T20:18:38.219500: step 22160, loss 0.345116, acc 0.859375\n",
      "2018-05-04T20:18:39.242166: step 22161, loss 0.215704, acc 0.890625\n",
      "2018-05-04T20:18:40.220191: step 22162, loss 0.343616, acc 0.90625\n",
      "2018-05-04T20:18:41.185659: step 22163, loss 0.242092, acc 0.859375\n",
      "2018-05-04T20:18:42.137636: step 22164, loss 0.383065, acc 0.8125\n",
      "2018-05-04T20:18:43.096382: step 22165, loss 0.175079, acc 0.921875\n",
      "2018-05-04T20:18:44.082055: step 22166, loss 0.26912, acc 0.90625\n",
      "2018-05-04T20:18:45.099180: step 22167, loss 0.269529, acc 0.90625\n",
      "2018-05-04T20:18:46.089643: step 22168, loss 0.169098, acc 0.953125\n",
      "2018-05-04T20:18:47.029892: step 22169, loss 0.267829, acc 0.828125\n",
      "2018-05-04T20:18:47.979918: step 22170, loss 0.398825, acc 0.828125\n",
      "2018-05-04T20:18:48.937517: step 22171, loss 0.330173, acc 0.84375\n",
      "2018-05-04T20:18:49.893190: step 22172, loss 0.259605, acc 0.921875\n",
      "2018-05-04T20:18:50.858314: step 22173, loss 0.225996, acc 0.90625\n",
      "2018-05-04T20:18:51.843962: step 22174, loss 0.215042, acc 0.9375\n",
      "2018-05-04T20:18:52.837612: step 22175, loss 0.286013, acc 0.875\n",
      "2018-05-04T20:18:53.825886: step 22176, loss 0.279883, acc 0.859375\n",
      "2018-05-04T20:18:54.777655: step 22177, loss 0.258527, acc 0.921875\n",
      "2018-05-04T20:18:55.740393: step 22178, loss 0.186332, acc 0.96875\n",
      "2018-05-04T20:18:56.703336: step 22179, loss 0.215599, acc 0.921875\n",
      "2018-05-04T20:18:57.675398: step 22180, loss 0.24779, acc 0.890625\n",
      "2018-05-04T20:18:58.622440: step 22181, loss 0.14498, acc 0.953125\n",
      "2018-05-04T20:18:59.587175: step 22182, loss 0.327114, acc 0.875\n",
      "2018-05-04T20:19:00.551336: step 22183, loss 0.355206, acc 0.875\n",
      "2018-05-04T20:19:01.502165: step 22184, loss 0.201537, acc 0.9375\n",
      "2018-05-04T20:19:02.453749: step 22185, loss 0.198763, acc 0.890625\n",
      "2018-05-04T20:19:03.437023: step 22186, loss 0.341463, acc 0.84375\n",
      "2018-05-04T20:19:04.417708: step 22187, loss 0.274099, acc 0.859375\n",
      "2018-05-04T20:19:05.391218: step 22188, loss 0.199416, acc 0.90625\n",
      "2018-05-04T20:19:06.355826: step 22189, loss 0.174136, acc 0.921875\n",
      "2018-05-04T20:19:07.308224: step 22190, loss 0.127242, acc 0.953125\n",
      "2018-05-04T20:19:08.236281: step 22191, loss 0.147906, acc 0.96875\n",
      "2018-05-04T20:19:09.264537: step 22192, loss 0.158768, acc 0.953125\n",
      "2018-05-04T20:19:10.293877: step 22193, loss 0.163813, acc 0.953125\n",
      "2018-05-04T20:19:11.240541: step 22194, loss 0.293647, acc 0.921875\n",
      "2018-05-04T20:19:12.185072: step 22195, loss 0.232314, acc 0.890625\n",
      "2018-05-04T20:19:13.138569: step 22196, loss 0.295319, acc 0.875\n",
      "2018-05-04T20:19:14.093685: step 22197, loss 0.394137, acc 0.859375\n",
      "2018-05-04T20:19:15.047673: step 22198, loss 0.194645, acc 0.921875\n",
      "2018-05-04T20:19:15.988289: step 22199, loss 0.279958, acc 0.875\n",
      "2018-05-04T20:19:16.954861: step 22200, loss 0.216802, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T20:19:19.421120: step 22200, loss 0.211858, acc 0.934\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-22200\n",
      "\n",
      "2018-05-04T20:19:20.486889: step 22201, loss 0.128494, acc 0.9375\n",
      "2018-05-04T20:19:21.499018: step 22202, loss 0.182259, acc 0.921875\n",
      "2018-05-04T20:19:22.502178: step 22203, loss 0.201459, acc 0.890625\n",
      "2018-05-04T20:19:23.572833: step 22204, loss 0.288462, acc 0.859375\n",
      "2018-05-04T20:19:24.580591: step 22205, loss 0.117488, acc 0.953125\n",
      "2018-05-04T20:19:25.666989: step 22206, loss 0.348693, acc 0.84375\n",
      "2018-05-04T20:19:26.752474: step 22207, loss 0.34223, acc 0.859375\n",
      "2018-05-04T20:19:27.743365: step 22208, loss 0.203487, acc 0.90625\n",
      "2018-05-04T20:19:28.742892: step 22209, loss 0.15564, acc 0.921875\n",
      "2018-05-04T20:19:29.744732: step 22210, loss 0.184038, acc 0.96875\n",
      "2018-05-04T20:19:30.728482: step 22211, loss 0.257814, acc 0.828125\n",
      "2018-05-04T20:19:31.729377: step 22212, loss 0.257485, acc 0.890625\n",
      "2018-05-04T20:19:32.744386: step 22213, loss 0.271754, acc 0.828125\n",
      "2018-05-04T20:19:33.749364: step 22214, loss 0.29422, acc 0.890625\n",
      "2018-05-04T20:19:34.806144: step 22215, loss 0.344132, acc 0.875\n",
      "2018-05-04T20:19:35.854412: step 22216, loss 0.450476, acc 0.859375\n",
      "2018-05-04T20:19:36.886731: step 22217, loss 0.224476, acc 0.921875\n",
      "2018-05-04T20:19:37.872436: step 22218, loss 0.175905, acc 0.9375\n",
      "2018-05-04T20:19:38.891759: step 22219, loss 0.210323, acc 0.9375\n",
      "2018-05-04T20:19:39.953756: step 22220, loss 0.231585, acc 0.9375\n",
      "2018-05-04T20:19:40.947517: step 22221, loss 0.289045, acc 0.84375\n",
      "2018-05-04T20:19:41.975258: step 22222, loss 0.267595, acc 0.890625\n",
      "2018-05-04T20:19:42.924785: step 22223, loss 0.235292, acc 0.90625\n",
      "2018-05-04T20:19:43.884341: step 22224, loss 0.344886, acc 0.84375\n",
      "2018-05-04T20:19:44.836764: step 22225, loss 0.190027, acc 0.921875\n",
      "2018-05-04T20:19:45.788327: step 22226, loss 0.284072, acc 0.890625\n",
      "2018-05-04T20:19:46.761754: step 22227, loss 0.143099, acc 0.953125\n",
      "2018-05-04T20:19:47.734249: step 22228, loss 0.274358, acc 0.90625\n",
      "2018-05-04T20:19:48.708064: step 22229, loss 0.113894, acc 1\n",
      "2018-05-04T20:19:49.730196: step 22230, loss 0.243767, acc 0.921875\n",
      "2018-05-04T20:19:50.686350: step 22231, loss 0.231712, acc 0.890625\n",
      "2018-05-04T20:19:51.640952: step 22232, loss 0.156098, acc 0.953125\n",
      "2018-05-04T20:19:52.602938: step 22233, loss 0.192339, acc 0.890625\n",
      "2018-05-04T20:19:53.569567: step 22234, loss 0.291895, acc 0.859375\n",
      "2018-05-04T20:19:54.610149: step 22235, loss 0.288195, acc 0.875\n",
      "2018-05-04T20:19:55.580947: step 22236, loss 0.249449, acc 0.90625\n",
      "2018-05-04T20:19:56.540951: step 22237, loss 0.397093, acc 0.875\n",
      "2018-05-04T20:19:57.495551: step 22238, loss 0.120936, acc 0.96875\n",
      "2018-05-04T20:19:58.466221: step 22239, loss 0.394813, acc 0.84375\n",
      "2018-05-04T20:19:59.468978: step 22240, loss 0.321867, acc 0.828125\n",
      "2018-05-04T20:20:00.541332: step 22241, loss 0.214666, acc 0.890625\n",
      "2018-05-04T20:20:01.519792: step 22242, loss 0.3336, acc 0.859375\n",
      "2018-05-04T20:20:02.517024: step 22243, loss 0.249347, acc 0.890625\n",
      "2018-05-04T20:20:03.492636: step 22244, loss 0.424356, acc 0.84375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T20:20:04.567388: step 22245, loss 0.330222, acc 0.828125\n",
      "2018-05-04T20:20:05.576889: step 22246, loss 0.263042, acc 0.90625\n",
      "2018-05-04T20:20:06.535779: step 22247, loss 0.263975, acc 0.859375\n",
      "2018-05-04T20:20:07.504503: step 22248, loss 0.246889, acc 0.890625\n",
      "2018-05-04T20:20:08.485641: step 22249, loss 0.203828, acc 0.921875\n",
      "2018-05-04T20:20:09.470946: step 22250, loss 0.322135, acc 0.890625\n",
      "2018-05-04T20:20:10.452979: step 22251, loss 0.165735, acc 0.953125\n",
      "2018-05-04T20:20:11.493850: step 22252, loss 0.270577, acc 0.890625\n",
      "2018-05-04T20:20:12.509050: step 22253, loss 0.215949, acc 0.9375\n",
      "2018-05-04T20:20:13.499848: step 22254, loss 0.229856, acc 0.90625\n",
      "2018-05-04T20:20:14.530215: step 22255, loss 0.390561, acc 0.875\n",
      "2018-05-04T20:20:15.480617: step 22256, loss 0.23775, acc 0.875\n",
      "2018-05-04T20:20:16.446711: step 22257, loss 0.298213, acc 0.90625\n",
      "2018-05-04T20:20:17.412292: step 22258, loss 0.334243, acc 0.859375\n",
      "2018-05-04T20:20:18.429218: step 22259, loss 0.355855, acc 0.8125\n",
      "2018-05-04T20:20:19.466506: step 22260, loss 0.323778, acc 0.890625\n",
      "2018-05-04T20:20:20.416205: step 22261, loss 0.215406, acc 0.953125\n",
      "2018-05-04T20:20:21.371607: step 22262, loss 0.458598, acc 0.859375\n",
      "2018-05-04T20:20:22.332982: step 22263, loss 0.366233, acc 0.84375\n",
      "2018-05-04T20:20:23.301946: step 22264, loss 0.286475, acc 0.859375\n",
      "2018-05-04T20:20:24.246763: step 22265, loss 0.343385, acc 0.859375\n",
      "2018-05-04T20:20:25.202128: step 22266, loss 0.251233, acc 0.890625\n",
      "2018-05-04T20:20:26.181734: step 22267, loss 0.258384, acc 0.890625\n",
      "2018-05-04T20:20:27.209573: step 22268, loss 0.293436, acc 0.921875\n",
      "2018-05-04T20:20:28.161307: step 22269, loss 0.280522, acc 0.890625\n",
      "2018-05-04T20:20:29.113542: step 22270, loss 0.202429, acc 0.921875\n",
      "2018-05-04T20:20:30.070960: step 22271, loss 0.218705, acc 0.9375\n",
      "2018-05-04T20:20:31.055090: step 22272, loss 0.29726, acc 0.828125\n",
      "2018-05-04T20:20:32.084385: step 22273, loss 0.192306, acc 0.9375\n",
      "2018-05-04T20:20:33.039918: step 22274, loss 0.198398, acc 0.921875\n",
      "2018-05-04T20:20:33.998456: step 22275, loss 0.160965, acc 0.953125\n",
      "2018-05-04T20:20:34.959375: step 22276, loss 0.30576, acc 0.828125\n",
      "2018-05-04T20:20:35.952846: step 22277, loss 0.246565, acc 0.90625\n",
      "2018-05-04T20:20:36.949015: step 22278, loss 0.247398, acc 0.9375\n",
      "2018-05-04T20:20:37.895376: step 22279, loss 0.346283, acc 0.9375\n",
      "2018-05-04T20:20:38.855610: step 22280, loss 0.288745, acc 0.890625\n",
      "2018-05-04T20:20:39.810479: step 22281, loss 0.231796, acc 0.890625\n",
      "2018-05-04T20:20:40.773504: step 22282, loss 0.249055, acc 0.921875\n",
      "2018-05-04T20:20:41.743231: step 22283, loss 0.217395, acc 0.921875\n",
      "2018-05-04T20:20:42.685122: step 22284, loss 0.2632, acc 0.890625\n",
      "2018-05-04T20:20:43.637262: step 22285, loss 0.300709, acc 0.890625\n",
      "2018-05-04T20:20:44.589964: step 22286, loss 0.304633, acc 0.828125\n",
      "2018-05-04T20:20:45.538763: step 22287, loss 0.287203, acc 0.90625\n",
      "2018-05-04T20:20:46.473123: step 22288, loss 0.251246, acc 0.90625\n",
      "2018-05-04T20:20:47.427211: step 22289, loss 0.29683, acc 0.875\n",
      "2018-05-04T20:20:48.366708: step 22290, loss 0.386163, acc 0.875\n",
      "2018-05-04T20:20:49.339706: step 22291, loss 0.330108, acc 0.890625\n",
      "2018-05-04T20:20:50.310945: step 22292, loss 0.145574, acc 0.984375\n",
      "2018-05-04T20:20:51.311303: step 22293, loss 0.171655, acc 0.9375\n",
      "2018-05-04T20:20:52.254706: step 22294, loss 0.331999, acc 0.875\n",
      "2018-05-04T20:20:53.210771: step 22295, loss 0.195282, acc 0.96875\n",
      "2018-05-04T20:20:54.166312: step 22296, loss 0.295836, acc 0.90625\n",
      "2018-05-04T20:20:55.105156: step 22297, loss 0.194841, acc 0.921875\n",
      "2018-05-04T20:20:56.041973: step 22298, loss 0.31696, acc 0.828125\n",
      "2018-05-04T20:20:56.969704: step 22299, loss 0.313914, acc 0.828125\n",
      "2018-05-04T20:20:57.907240: step 22300, loss 0.17805, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T20:21:00.475557: step 22300, loss 0.219044, acc 0.928\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-22300\n",
      "\n",
      "2018-05-04T20:21:01.692449: step 22301, loss 0.211824, acc 0.90625\n",
      "2018-05-04T20:21:02.750562: step 22302, loss 0.174262, acc 0.953125\n",
      "2018-05-04T20:21:03.748986: step 22303, loss 0.155313, acc 0.953125\n",
      "2018-05-04T20:21:04.750263: step 22304, loss 0.242355, acc 0.9375\n",
      "2018-05-04T20:21:05.769033: step 22305, loss 0.329642, acc 0.890625\n",
      "2018-05-04T20:21:06.810156: step 22306, loss 0.360086, acc 0.859375\n",
      "2018-05-04T20:21:07.839375: step 22307, loss 0.198377, acc 0.890625\n",
      "2018-05-04T20:21:08.818794: step 22308, loss 0.168155, acc 0.953125\n",
      "2018-05-04T20:21:09.838548: step 22309, loss 0.182786, acc 0.921875\n",
      "2018-05-04T20:21:10.864001: step 22310, loss 0.222723, acc 0.90625\n",
      "2018-05-04T20:21:11.858082: step 22311, loss 0.137993, acc 0.9375\n",
      "2018-05-04T20:21:12.822847: step 22312, loss 0.186657, acc 0.90625\n",
      "2018-05-04T20:21:13.798839: step 22313, loss 0.396346, acc 0.875\n",
      "2018-05-04T20:21:14.769491: step 22314, loss 0.219326, acc 0.9375\n",
      "2018-05-04T20:21:15.744939: step 22315, loss 0.184292, acc 0.921875\n",
      "2018-05-04T20:21:16.785918: step 22316, loss 0.24116, acc 0.875\n",
      "2018-05-04T20:21:17.786421: step 22317, loss 0.24314, acc 0.890625\n",
      "2018-05-04T20:21:18.755656: step 22318, loss 0.199414, acc 0.921875\n",
      "2018-05-04T20:21:19.703545: step 22319, loss 0.247572, acc 0.890625\n",
      "2018-05-04T20:21:20.681634: step 22320, loss 0.251607, acc 0.875\n",
      "2018-05-04T20:21:21.710112: step 22321, loss 0.21767, acc 0.9375\n",
      "2018-05-04T20:21:22.770475: step 22322, loss 0.301436, acc 0.890625\n",
      "2018-05-04T20:21:23.724658: step 22323, loss 0.334651, acc 0.890625\n",
      "2018-05-04T20:21:24.723970: step 22324, loss 0.23553, acc 0.921875\n",
      "2018-05-04T20:21:25.695590: step 22325, loss 0.227835, acc 0.90625\n",
      "2018-05-04T20:21:26.667542: step 22326, loss 0.279878, acc 0.859375\n",
      "2018-05-04T20:21:27.631831: step 22327, loss 0.235034, acc 0.90625\n",
      "2018-05-04T20:21:28.592061: step 22328, loss 0.40728, acc 0.828125\n",
      "2018-05-04T20:21:29.560372: step 22329, loss 0.290879, acc 0.859375\n",
      "2018-05-04T20:21:30.543423: step 22330, loss 0.392066, acc 0.828125\n",
      "2018-05-04T20:21:31.555309: step 22331, loss 0.248704, acc 0.875\n",
      "2018-05-04T20:21:32.561541: step 22332, loss 0.252396, acc 0.921875\n",
      "2018-05-04T20:21:33.546727: step 22333, loss 0.213521, acc 0.90625\n",
      "2018-05-04T20:21:34.541693: step 22334, loss 0.179573, acc 0.90625\n",
      "2018-05-04T20:21:35.533466: step 22335, loss 0.320227, acc 0.84375\n",
      "2018-05-04T20:21:36.575227: step 22336, loss 0.260704, acc 0.890625\n",
      "2018-05-04T20:21:37.556439: step 22337, loss 0.3657, acc 0.84375\n",
      "2018-05-04T20:21:38.580239: step 22338, loss 0.201491, acc 0.9375\n",
      "2018-05-04T20:21:39.633380: step 22339, loss 0.215265, acc 0.90625\n",
      "2018-05-04T20:21:40.589201: step 22340, loss 0.18676, acc 0.9375\n",
      "2018-05-04T20:21:41.538069: step 22341, loss 0.206687, acc 0.921875\n",
      "2018-05-04T20:21:42.518570: step 22342, loss 0.270243, acc 0.875\n",
      "2018-05-04T20:21:43.501741: step 22343, loss 0.36212, acc 0.859375\n",
      "2018-05-04T20:21:44.496728: step 22344, loss 0.244422, acc 0.859375\n",
      "2018-05-04T20:21:45.470353: step 22345, loss 0.209796, acc 0.921875\n",
      "2018-05-04T20:21:46.430255: step 22346, loss 0.16331, acc 0.921875\n",
      "2018-05-04T20:21:47.404964: step 22347, loss 0.268651, acc 0.875\n",
      "2018-05-04T20:21:48.384744: step 22348, loss 0.182784, acc 0.921875\n",
      "2018-05-04T20:21:49.386292: step 22349, loss 0.218833, acc 0.90625\n",
      "2018-05-04T20:21:50.355802: step 22350, loss 0.369566, acc 0.859375\n",
      "2018-05-04T20:21:51.342788: step 22351, loss 0.261311, acc 0.921875\n",
      "2018-05-04T20:21:52.374071: step 22352, loss 0.272879, acc 0.875\n",
      "2018-05-04T20:21:53.355052: step 22353, loss 0.215723, acc 0.921875\n",
      "2018-05-04T20:21:54.341352: step 22354, loss 0.265831, acc 0.921875\n",
      "2018-05-04T20:21:55.293129: step 22355, loss 0.176082, acc 0.9375\n",
      "2018-05-04T20:21:56.265036: step 22356, loss 0.298931, acc 0.875\n",
      "2018-05-04T20:21:57.228650: step 22357, loss 0.400455, acc 0.859375\n",
      "2018-05-04T20:21:58.269761: step 22358, loss 0.200536, acc 0.9375\n",
      "2018-05-04T20:21:59.226466: step 22359, loss 0.177099, acc 0.90625\n",
      "2018-05-04T20:22:00.241065: step 22360, loss 0.15178, acc 0.96875\n",
      "2018-05-04T20:22:01.188757: step 22361, loss 0.272318, acc 0.859375\n",
      "2018-05-04T20:22:02.143976: step 22362, loss 0.295298, acc 0.875\n",
      "2018-05-04T20:22:03.117513: step 22363, loss 0.313097, acc 0.875\n",
      "2018-05-04T20:22:04.087885: step 22364, loss 0.253903, acc 0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T20:22:05.040000: step 22365, loss 0.160282, acc 0.96875\n",
      "2018-05-04T20:22:05.985830: step 22366, loss 0.228135, acc 0.859375\n",
      "2018-05-04T20:22:06.926190: step 22367, loss 0.21713, acc 0.921875\n",
      "2018-05-04T20:22:07.882531: step 22368, loss 0.179599, acc 0.96875\n",
      "2018-05-04T20:22:08.839225: step 22369, loss 0.331776, acc 0.875\n",
      "2018-05-04T20:22:09.873791: step 22370, loss 0.152369, acc 0.9375\n",
      "2018-05-04T20:22:10.815432: step 22371, loss 0.308003, acc 0.890625\n",
      "2018-05-04T20:22:11.780869: step 22372, loss 0.309005, acc 0.875\n",
      "2018-05-04T20:22:12.827885: step 22373, loss 0.233976, acc 0.875\n",
      "2018-05-04T20:22:13.862490: step 22374, loss 0.306886, acc 0.875\n",
      "2018-05-04T20:22:14.877141: step 22375, loss 0.239865, acc 0.90625\n",
      "2018-05-04T20:22:15.825339: step 22376, loss 0.290703, acc 0.84375\n",
      "2018-05-04T20:22:16.767479: step 22377, loss 0.246972, acc 0.890625\n",
      "2018-05-04T20:22:17.703230: step 22378, loss 0.15648, acc 0.921875\n",
      "2018-05-04T20:22:18.655397: step 22379, loss 0.235088, acc 0.875\n",
      "2018-05-04T20:22:19.592872: step 22380, loss 0.223704, acc 0.90625\n",
      "2018-05-04T20:22:20.542488: step 22381, loss 0.342231, acc 0.828125\n",
      "2018-05-04T20:22:21.474840: step 22382, loss 0.258706, acc 0.890625\n",
      "2018-05-04T20:22:22.435252: step 22383, loss 0.192844, acc 0.953125\n",
      "2018-05-04T20:22:23.393477: step 22384, loss 0.300854, acc 0.84375\n",
      "2018-05-04T20:22:24.368973: step 22385, loss 0.410176, acc 0.8125\n",
      "2018-05-04T20:22:25.339204: step 22386, loss 0.401706, acc 0.921875\n",
      "2018-05-04T20:22:26.309096: step 22387, loss 0.259188, acc 0.921875\n",
      "2018-05-04T20:22:27.249728: step 22388, loss 0.325472, acc 0.875\n",
      "2018-05-04T20:22:28.208811: step 22389, loss 0.222442, acc 0.9375\n",
      "2018-05-04T20:22:29.157041: step 22390, loss 0.334502, acc 0.875\n",
      "2018-05-04T20:22:30.185008: step 22391, loss 0.265646, acc 0.875\n",
      "2018-05-04T20:22:31.256831: step 22392, loss 0.377046, acc 0.84375\n",
      "2018-05-04T20:22:32.229717: step 22393, loss 0.181526, acc 0.9375\n",
      "2018-05-04T20:22:33.214757: step 22394, loss 0.131621, acc 0.953125\n",
      "2018-05-04T20:22:34.219407: step 22395, loss 0.237907, acc 0.9375\n",
      "2018-05-04T20:22:35.223426: step 22396, loss 0.211052, acc 0.90625\n",
      "2018-05-04T20:22:36.300990: step 22397, loss 0.388672, acc 0.84375\n",
      "2018-05-04T20:22:37.316939: step 22398, loss 0.230204, acc 0.890625\n",
      "2018-05-04T20:22:38.287547: step 22399, loss 0.198772, acc 0.9375\n",
      "2018-05-04T20:22:39.279047: step 22400, loss 0.137807, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T20:22:41.777321: step 22400, loss 0.211432, acc 0.928\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-22400\n",
      "\n",
      "2018-05-04T20:22:42.836938: step 22401, loss 0.259223, acc 0.921875\n",
      "2018-05-04T20:22:43.831577: step 22402, loss 0.209716, acc 0.9375\n",
      "2018-05-04T20:22:44.828735: step 22403, loss 0.308185, acc 0.875\n",
      "2018-05-04T20:22:45.851026: step 22404, loss 0.301328, acc 0.875\n",
      "2018-05-04T20:22:46.959070: step 22405, loss 0.190391, acc 0.9375\n",
      "2018-05-04T20:22:48.042254: step 22406, loss 0.158735, acc 0.9375\n",
      "2018-05-04T20:22:48.999203: step 22407, loss 0.216878, acc 0.875\n",
      "2018-05-04T20:22:49.957928: step 22408, loss 0.208631, acc 0.859375\n",
      "2018-05-04T20:22:51.003902: step 22409, loss 0.294216, acc 0.875\n",
      "2018-05-04T20:22:51.972780: step 22410, loss 0.388506, acc 0.859375\n",
      "2018-05-04T20:22:52.959385: step 22411, loss 0.246874, acc 0.890625\n",
      "2018-05-04T20:22:53.942607: step 22412, loss 0.235047, acc 0.875\n",
      "2018-05-04T20:22:54.894559: step 22413, loss 0.171558, acc 0.953125\n",
      "2018-05-04T20:22:55.863943: step 22414, loss 0.285687, acc 0.859375\n",
      "2018-05-04T20:22:56.833968: step 22415, loss 0.229105, acc 0.9375\n",
      "2018-05-04T20:22:57.813047: step 22416, loss 0.211754, acc 0.890625\n",
      "2018-05-04T20:22:58.787217: step 22417, loss 0.214062, acc 0.890625\n",
      "2018-05-04T20:22:59.783640: step 22418, loss 0.280816, acc 0.90625\n",
      "2018-05-04T20:23:00.755988: step 22419, loss 0.306474, acc 0.90625\n",
      "2018-05-04T20:23:01.732949: step 22420, loss 0.303819, acc 0.9375\n",
      "2018-05-04T20:23:02.710357: step 22421, loss 0.10988, acc 0.96875\n",
      "2018-05-04T20:23:03.705826: step 22422, loss 0.263697, acc 0.859375\n",
      "2018-05-04T20:23:04.704377: step 22423, loss 0.291464, acc 0.875\n",
      "2018-05-04T20:23:05.670828: step 22424, loss 0.323693, acc 0.84375\n",
      "2018-05-04T20:23:06.639125: step 22425, loss 0.374251, acc 0.828125\n",
      "2018-05-04T20:23:07.598367: step 22426, loss 0.234509, acc 0.859375\n",
      "2018-05-04T20:23:08.569266: step 22427, loss 0.176836, acc 0.96875\n",
      "2018-05-04T20:23:09.560139: step 22428, loss 0.258767, acc 0.859375\n",
      "2018-05-04T20:23:10.546118: step 22429, loss 0.217098, acc 0.90625\n",
      "2018-05-04T20:23:11.568349: step 22430, loss 0.16704, acc 0.9375\n",
      "2018-05-04T20:23:12.574508: step 22431, loss 0.286847, acc 0.875\n",
      "2018-05-04T20:23:13.538216: step 22432, loss 0.215026, acc 0.9375\n",
      "2018-05-04T20:23:14.528976: step 22433, loss 0.234242, acc 0.9375\n",
      "2018-05-04T20:23:15.521726: step 22434, loss 0.166293, acc 0.921875\n",
      "2018-05-04T20:23:16.476498: step 22435, loss 0.28882, acc 0.90625\n",
      "2018-05-04T20:23:17.588057: step 22436, loss 0.260896, acc 0.890625\n",
      "2018-05-04T20:23:18.535376: step 22437, loss 0.198758, acc 0.90625\n",
      "2018-05-04T20:23:19.509250: step 22438, loss 0.231082, acc 0.90625\n",
      "2018-05-04T20:23:20.479212: step 22439, loss 0.335585, acc 0.859375\n",
      "2018-05-04T20:23:21.480414: step 22440, loss 0.234966, acc 0.90625\n",
      "2018-05-04T20:23:22.437667: step 22441, loss 0.235599, acc 0.90625\n",
      "2018-05-04T20:23:23.409716: step 22442, loss 0.19745, acc 0.90625\n",
      "2018-05-04T20:23:24.404761: step 22443, loss 0.267882, acc 0.90625\n",
      "2018-05-04T20:23:25.369354: step 22444, loss 0.266573, acc 0.90625\n",
      "2018-05-04T20:23:26.345944: step 22445, loss 0.27123, acc 0.875\n",
      "2018-05-04T20:23:27.318362: step 22446, loss 0.302498, acc 0.890625\n",
      "2018-05-04T20:23:28.317511: step 22447, loss 0.25651, acc 0.859375\n",
      "2018-05-04T20:23:29.288683: step 22448, loss 0.211166, acc 0.90625\n",
      "2018-05-04T20:23:30.282863: step 22449, loss 0.407254, acc 0.859375\n",
      "2018-05-04T20:23:31.245354: step 22450, loss 0.234028, acc 0.890625\n",
      "2018-05-04T20:23:32.224584: step 22451, loss 0.331487, acc 0.796875\n",
      "2018-05-04T20:23:33.256309: step 22452, loss 0.236528, acc 0.921875\n",
      "2018-05-04T20:23:34.227507: step 22453, loss 0.300536, acc 0.859375\n",
      "2018-05-04T20:23:35.206545: step 22454, loss 0.169483, acc 0.90625\n",
      "2018-05-04T20:23:36.216587: step 22455, loss 0.192947, acc 0.90625\n",
      "2018-05-04T20:23:37.278368: step 22456, loss 0.25368, acc 0.859375\n",
      "2018-05-04T20:23:38.259191: step 22457, loss 0.221234, acc 0.921875\n",
      "2018-05-04T20:23:39.269503: step 22458, loss 0.296817, acc 0.875\n",
      "2018-05-04T20:23:40.227808: step 22459, loss 0.275167, acc 0.875\n",
      "2018-05-04T20:23:41.187151: step 22460, loss 0.116195, acc 0.96875\n",
      "2018-05-04T20:23:42.142908: step 22461, loss 0.336947, acc 0.859375\n",
      "2018-05-04T20:23:43.107262: step 22462, loss 0.324952, acc 0.890625\n",
      "2018-05-04T20:23:44.050133: step 22463, loss 0.172072, acc 0.921875\n",
      "2018-05-04T20:23:44.999017: step 22464, loss 0.264258, acc 0.890625\n",
      "2018-05-04T20:23:46.042384: step 22465, loss 0.225636, acc 0.875\n",
      "2018-05-04T20:23:47.068610: step 22466, loss 0.21915, acc 0.921875\n",
      "2018-05-04T20:23:47.991052: step 22467, loss 0.384423, acc 0.859375\n",
      "2018-05-04T20:23:48.939410: step 22468, loss 0.215885, acc 0.9375\n",
      "2018-05-04T20:23:49.912495: step 22469, loss 0.252962, acc 0.875\n",
      "2018-05-04T20:23:50.855342: step 22470, loss 0.228844, acc 0.921875\n",
      "2018-05-04T20:23:51.819745: step 22471, loss 0.241842, acc 0.921875\n",
      "2018-05-04T20:23:52.784268: step 22472, loss 0.207708, acc 0.921875\n",
      "2018-05-04T20:23:53.783272: step 22473, loss 0.261891, acc 0.890625\n",
      "2018-05-04T20:23:54.748776: step 22474, loss 0.293288, acc 0.875\n",
      "2018-05-04T20:23:55.801568: step 22475, loss 0.290415, acc 0.890625\n",
      "2018-05-04T20:23:56.783112: step 22476, loss 0.342266, acc 0.84375\n",
      "2018-05-04T20:23:57.748458: step 22477, loss 0.36046, acc 0.828125\n",
      "2018-05-04T20:23:58.690338: step 22478, loss 0.160054, acc 0.921875\n",
      "2018-05-04T20:23:59.660865: step 22479, loss 0.318058, acc 0.875\n",
      "2018-05-04T20:24:00.627270: step 22480, loss 0.2663, acc 0.90625\n",
      "2018-05-04T20:24:01.629227: step 22481, loss 0.26985, acc 0.875\n",
      "2018-05-04T20:24:02.584995: step 22482, loss 0.286075, acc 0.875\n",
      "2018-05-04T20:24:03.534895: step 22483, loss 0.231048, acc 0.859375\n",
      "2018-05-04T20:24:04.516858: step 22484, loss 0.300515, acc 0.859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T20:24:05.473083: step 22485, loss 0.233533, acc 0.859375\n",
      "2018-05-04T20:24:06.437440: step 22486, loss 0.230349, acc 0.921875\n",
      "2018-05-04T20:24:07.378855: step 22487, loss 0.231966, acc 0.90625\n",
      "2018-05-04T20:24:08.326577: step 22488, loss 0.304187, acc 0.90625\n",
      "2018-05-04T20:24:09.297021: step 22489, loss 0.451934, acc 0.765625\n",
      "2018-05-04T20:24:10.275063: step 22490, loss 0.245298, acc 0.90625\n",
      "2018-05-04T20:24:11.239498: step 22491, loss 0.455321, acc 0.78125\n",
      "2018-05-04T20:24:12.205293: step 22492, loss 0.335251, acc 0.859375\n",
      "2018-05-04T20:24:13.173331: step 22493, loss 0.240922, acc 0.890625\n",
      "2018-05-04T20:24:14.108850: step 22494, loss 0.181347, acc 0.921875\n",
      "2018-05-04T20:24:15.040067: step 22495, loss 0.257073, acc 0.890625\n",
      "2018-05-04T20:24:15.995149: step 22496, loss 0.263177, acc 0.875\n",
      "2018-05-04T20:24:17.035163: step 22497, loss 0.198029, acc 0.921875\n",
      "2018-05-04T20:24:17.982510: step 22498, loss 0.266625, acc 0.921875\n",
      "2018-05-04T20:24:18.924113: step 22499, loss 0.269945, acc 0.890625\n",
      "2018-05-04T20:24:19.947231: step 22500, loss 0.284223, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T20:24:22.036324: step 22500, loss 0.254021, acc 0.912\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-22500\n",
      "\n",
      "2018-05-04T20:24:23.087884: step 22501, loss 0.253319, acc 0.90625\n",
      "2018-05-04T20:24:24.056382: step 22502, loss 0.320474, acc 0.859375\n",
      "2018-05-04T20:24:25.012639: step 22503, loss 0.120694, acc 0.953125\n",
      "2018-05-04T20:24:25.991057: step 22504, loss 0.198083, acc 0.90625\n",
      "2018-05-04T20:24:26.936748: step 22505, loss 0.19595, acc 0.9375\n",
      "2018-05-04T20:24:27.932615: step 22506, loss 0.154264, acc 0.96875\n",
      "2018-05-04T20:24:28.886266: step 22507, loss 0.207196, acc 0.953125\n",
      "2018-05-04T20:24:29.843711: step 22508, loss 0.159583, acc 0.9375\n",
      "2018-05-04T20:24:30.792776: step 22509, loss 0.143649, acc 0.953125\n",
      "2018-05-04T20:24:31.746160: step 22510, loss 0.2926, acc 0.859375\n",
      "2018-05-04T20:24:32.719644: step 22511, loss 0.189404, acc 0.953125\n",
      "2018-05-04T20:24:33.687733: step 22512, loss 0.259902, acc 0.90625\n",
      "2018-05-04T20:24:34.665511: step 22513, loss 0.260244, acc 0.859375\n",
      "2018-05-04T20:24:35.598114: step 22514, loss 0.296389, acc 0.84375\n",
      "2018-05-04T20:24:36.539280: step 22515, loss 0.199592, acc 0.9375\n",
      "2018-05-04T20:24:37.490057: step 22516, loss 0.259018, acc 0.859375\n",
      "2018-05-04T20:24:38.421131: step 22517, loss 0.277921, acc 0.859375\n",
      "2018-05-04T20:24:39.371721: step 22518, loss 0.253986, acc 0.890625\n",
      "2018-05-04T20:24:40.358230: step 22519, loss 0.385283, acc 0.890625\n",
      "2018-05-04T20:24:41.307961: step 22520, loss 0.118125, acc 0.984375\n",
      "2018-05-04T20:24:42.248453: step 22521, loss 0.290321, acc 0.875\n",
      "2018-05-04T20:24:43.223794: step 22522, loss 0.131512, acc 0.96875\n",
      "2018-05-04T20:24:44.220576: step 22523, loss 0.396239, acc 0.84375\n",
      "2018-05-04T20:24:45.180955: step 22524, loss 0.295966, acc 0.90625\n",
      "2018-05-04T20:24:46.180022: step 22525, loss 0.257967, acc 0.921875\n",
      "2018-05-04T20:24:47.180920: step 22526, loss 0.361472, acc 0.859375\n",
      "2018-05-04T20:24:48.197168: step 22527, loss 0.350124, acc 0.859375\n",
      "2018-05-04T20:24:49.133503: step 22528, loss 0.271898, acc 0.875\n",
      "2018-05-04T20:24:50.082807: step 22529, loss 0.234925, acc 0.875\n",
      "2018-05-04T20:24:51.023182: step 22530, loss 0.219503, acc 0.890625\n",
      "2018-05-04T20:24:51.975140: step 22531, loss 0.272948, acc 0.90625\n",
      "2018-05-04T20:24:53.019499: step 22532, loss 0.227302, acc 0.921875\n",
      "2018-05-04T20:24:53.951523: step 22533, loss 0.258128, acc 0.890625\n",
      "2018-05-04T20:24:54.892924: step 22534, loss 0.330477, acc 0.890625\n",
      "2018-05-04T20:24:55.829825: step 22535, loss 0.311538, acc 0.890625\n",
      "2018-05-04T20:24:56.768211: step 22536, loss 0.21459, acc 0.90625\n",
      "2018-05-04T20:24:57.715468: step 22537, loss 0.276769, acc 0.90625\n",
      "2018-05-04T20:24:58.653794: step 22538, loss 0.290985, acc 0.84375\n",
      "2018-05-04T20:24:59.593054: step 22539, loss 0.201142, acc 0.9375\n",
      "2018-05-04T20:25:00.538073: step 22540, loss 0.180153, acc 0.9375\n",
      "2018-05-04T20:25:01.610953: step 22541, loss 0.145299, acc 0.921875\n",
      "2018-05-04T20:25:02.630025: step 22542, loss 0.238206, acc 0.921875\n",
      "2018-05-04T20:25:03.600893: step 22543, loss 0.331643, acc 0.859375\n",
      "2018-05-04T20:25:04.591278: step 22544, loss 0.309969, acc 0.890625\n",
      "2018-05-04T20:25:05.562200: step 22545, loss 0.227122, acc 0.921875\n",
      "2018-05-04T20:25:06.505992: step 22546, loss 0.142497, acc 0.953125\n",
      "2018-05-04T20:25:07.456502: step 22547, loss 0.371512, acc 0.859375\n",
      "2018-05-04T20:25:08.407410: step 22548, loss 0.256011, acc 0.890625\n",
      "2018-05-04T20:25:09.354104: step 22549, loss 0.21496, acc 0.921875\n",
      "2018-05-04T20:25:10.296015: step 22550, loss 0.199217, acc 0.9375\n",
      "2018-05-04T20:25:11.228690: step 22551, loss 0.155678, acc 0.90625\n",
      "2018-05-04T20:25:12.179364: step 22552, loss 0.30263, acc 0.890625\n",
      "2018-05-04T20:25:13.118813: step 22553, loss 0.400532, acc 0.796875\n",
      "2018-05-04T20:25:14.043194: step 22554, loss 0.204085, acc 0.890625\n",
      "2018-05-04T20:25:14.985048: step 22555, loss 0.191407, acc 0.921875\n",
      "2018-05-04T20:25:15.951955: step 22556, loss 0.300892, acc 0.890625\n",
      "2018-05-04T20:25:16.940855: step 22557, loss 0.145191, acc 0.953125\n",
      "2018-05-04T20:25:17.935222: step 22558, loss 0.251865, acc 0.921875\n",
      "2018-05-04T20:25:18.893905: step 22559, loss 0.289203, acc 0.921875\n",
      "2018-05-04T20:25:19.851462: step 22560, loss 0.389276, acc 0.859375\n",
      "2018-05-04T20:25:20.802365: step 22561, loss 0.218729, acc 0.890625\n",
      "2018-05-04T20:25:21.757403: step 22562, loss 0.258322, acc 0.84375\n",
      "2018-05-04T20:25:22.682958: step 22563, loss 0.388264, acc 0.859375\n",
      "2018-05-04T20:25:23.653800: step 22564, loss 0.275464, acc 0.90625\n",
      "2018-05-04T20:25:24.622421: step 22565, loss 0.195223, acc 0.921875\n",
      "2018-05-04T20:25:25.586410: step 22566, loss 0.325678, acc 0.875\n",
      "2018-05-04T20:25:26.598055: step 22567, loss 0.178379, acc 0.9375\n",
      "2018-05-04T20:25:27.600264: step 22568, loss 0.249988, acc 0.9375\n",
      "2018-05-04T20:25:28.561204: step 22569, loss 0.192778, acc 0.953125\n",
      "2018-05-04T20:25:29.491486: step 22570, loss 0.23247, acc 0.890625\n",
      "2018-05-04T20:25:30.442403: step 22571, loss 0.167261, acc 0.96875\n",
      "2018-05-04T20:25:31.422627: step 22572, loss 0.332661, acc 0.84375\n",
      "2018-05-04T20:25:32.451291: step 22573, loss 0.426245, acc 0.828125\n",
      "2018-05-04T20:25:33.528484: step 22574, loss 0.267992, acc 0.890625\n",
      "2018-05-04T20:25:34.613655: step 22575, loss 0.292387, acc 0.890625\n",
      "2018-05-04T20:25:35.682351: step 22576, loss 0.187621, acc 0.921875\n",
      "2018-05-04T20:25:36.761478: step 22577, loss 0.153064, acc 0.9375\n",
      "2018-05-04T20:25:37.681494: step 22578, loss 0.241944, acc 0.890625\n",
      "2018-05-04T20:25:38.624608: step 22579, loss 0.224183, acc 0.875\n",
      "2018-05-04T20:25:39.575180: step 22580, loss 0.371355, acc 0.875\n",
      "2018-05-04T20:25:40.525467: step 22581, loss 0.400823, acc 0.890625\n",
      "2018-05-04T20:25:41.468446: step 22582, loss 0.196215, acc 0.90625\n",
      "2018-05-04T20:25:42.438312: step 22583, loss 0.249571, acc 0.90625\n",
      "2018-05-04T20:25:43.407392: step 22584, loss 0.266816, acc 0.859375\n",
      "2018-05-04T20:25:44.356398: step 22585, loss 0.348885, acc 0.84375\n",
      "2018-05-04T20:25:45.301772: step 22586, loss 0.228518, acc 0.90625\n",
      "2018-05-04T20:25:46.258747: step 22587, loss 0.337528, acc 0.859375\n",
      "2018-05-04T20:25:47.179668: step 22588, loss 0.291749, acc 0.875\n",
      "2018-05-04T20:25:48.113131: step 22589, loss 0.210029, acc 0.921875\n",
      "2018-05-04T20:25:49.049146: step 22590, loss 0.199997, acc 0.921875\n",
      "2018-05-04T20:25:50.010258: step 22591, loss 0.159793, acc 0.953125\n",
      "2018-05-04T20:25:50.977783: step 22592, loss 0.44397, acc 0.796875\n",
      "2018-05-04T20:25:51.919299: step 22593, loss 0.266426, acc 0.890625\n",
      "2018-05-04T20:25:52.889395: step 22594, loss 0.203699, acc 0.921875\n",
      "2018-05-04T20:25:53.848573: step 22595, loss 0.183157, acc 0.9375\n",
      "2018-05-04T20:25:54.892034: step 22596, loss 0.320848, acc 0.890625\n",
      "2018-05-04T20:25:55.922430: step 22597, loss 0.271688, acc 0.921875\n",
      "2018-05-04T20:25:56.872893: step 22598, loss 0.315035, acc 0.875\n",
      "2018-05-04T20:25:57.796961: step 22599, loss 0.227394, acc 0.859375\n",
      "2018-05-04T20:25:58.735249: step 22600, loss 0.24514, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T20:26:01.887056: step 22600, loss 0.223094, acc 0.926\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-22600\n",
      "\n",
      "2018-05-04T20:26:03.020583: step 22601, loss 0.222121, acc 0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T20:26:04.033130: step 22602, loss 0.185998, acc 0.9375\n",
      "2018-05-04T20:26:05.045168: step 22603, loss 0.254253, acc 0.890625\n",
      "2018-05-04T20:26:06.065394: step 22604, loss 0.239176, acc 0.890625\n",
      "2018-05-04T20:26:07.096052: step 22605, loss 0.206159, acc 0.9375\n",
      "2018-05-04T20:26:08.100819: step 22606, loss 0.160851, acc 0.96875\n",
      "2018-05-04T20:26:09.091526: step 22607, loss 0.255844, acc 0.875\n",
      "2018-05-04T20:26:10.148722: step 22608, loss 0.22875, acc 0.921875\n",
      "2018-05-04T20:26:11.212800: step 22609, loss 0.286779, acc 0.890625\n",
      "2018-05-04T20:26:12.176740: step 22610, loss 0.258448, acc 0.921875\n",
      "2018-05-04T20:26:13.211541: step 22611, loss 0.239896, acc 0.9375\n",
      "2018-05-04T20:26:14.288138: step 22612, loss 0.158528, acc 0.921875\n",
      "2018-05-04T20:26:15.247402: step 22613, loss 0.210743, acc 0.90625\n",
      "2018-05-04T20:26:16.225081: step 22614, loss 0.286333, acc 0.859375\n",
      "2018-05-04T20:26:17.223760: step 22615, loss 0.241519, acc 0.875\n",
      "2018-05-04T20:26:18.207244: step 22616, loss 0.303345, acc 0.828125\n",
      "2018-05-04T20:26:19.163244: step 22617, loss 0.299463, acc 0.890625\n",
      "2018-05-04T20:26:20.132465: step 22618, loss 0.229049, acc 0.90625\n",
      "2018-05-04T20:26:21.122913: step 22619, loss 0.211848, acc 0.921875\n",
      "2018-05-04T20:26:22.098813: step 22620, loss 0.176082, acc 0.921875\n",
      "2018-05-04T20:26:23.054522: step 22621, loss 0.205519, acc 0.90625\n",
      "2018-05-04T20:26:24.054172: step 22622, loss 0.298427, acc 0.875\n",
      "2018-05-04T20:26:25.016915: step 22623, loss 0.166859, acc 0.984375\n",
      "2018-05-04T20:26:25.978257: step 22624, loss 0.159154, acc 0.953125\n",
      "2018-05-04T20:26:26.958877: step 22625, loss 0.234232, acc 0.90625\n",
      "2018-05-04T20:26:27.927799: step 22626, loss 0.169787, acc 0.9375\n",
      "2018-05-04T20:26:28.928894: step 22627, loss 0.267614, acc 0.90625\n",
      "2018-05-04T20:26:29.889849: step 22628, loss 0.168758, acc 0.9375\n",
      "2018-05-04T20:26:30.861718: step 22629, loss 0.292689, acc 0.890625\n",
      "2018-05-04T20:26:31.817145: step 22630, loss 0.321664, acc 0.8125\n",
      "2018-05-04T20:26:32.803758: step 22631, loss 0.253429, acc 0.875\n",
      "2018-05-04T20:26:33.791570: step 22632, loss 0.201798, acc 0.890625\n",
      "2018-05-04T20:26:34.795037: step 22633, loss 0.284237, acc 0.921875\n",
      "2018-05-04T20:26:35.762992: step 22634, loss 0.187417, acc 0.9375\n",
      "2018-05-04T20:26:36.735361: step 22635, loss 0.135197, acc 0.96875\n",
      "2018-05-04T20:26:37.716748: step 22636, loss 0.164264, acc 0.9375\n",
      "2018-05-04T20:26:38.700358: step 22637, loss 0.291934, acc 0.890625\n",
      "2018-05-04T20:26:39.651247: step 22638, loss 0.131383, acc 0.953125\n",
      "2018-05-04T20:26:40.650706: step 22639, loss 0.271301, acc 0.90625\n",
      "2018-05-04T20:26:41.691802: step 22640, loss 0.402286, acc 0.84375\n",
      "2018-05-04T20:26:42.721944: step 22641, loss 0.333928, acc 0.859375\n",
      "2018-05-04T20:26:43.741461: step 22642, loss 0.149875, acc 0.9375\n",
      "2018-05-04T20:26:44.854450: step 22643, loss 0.174587, acc 0.921875\n",
      "2018-05-04T20:26:45.942078: step 22644, loss 0.195674, acc 0.9375\n",
      "2018-05-04T20:26:47.067443: step 22645, loss 0.232251, acc 0.90625\n",
      "2018-05-04T20:26:48.056433: step 22646, loss 0.227211, acc 0.921875\n",
      "2018-05-04T20:26:49.052469: step 22647, loss 0.210433, acc 0.890625\n",
      "2018-05-04T20:26:50.110646: step 22648, loss 0.196137, acc 0.90625\n",
      "2018-05-04T20:26:51.090141: step 22649, loss 0.360855, acc 0.890625\n",
      "2018-05-04T20:26:52.042818: step 22650, loss 0.163121, acc 0.90625\n",
      "2018-05-04T20:26:53.006989: step 22651, loss 0.447864, acc 0.8125\n",
      "2018-05-04T20:26:54.006269: step 22652, loss 0.180663, acc 0.921875\n",
      "2018-05-04T20:26:55.012249: step 22653, loss 0.283424, acc 0.890625\n",
      "2018-05-04T20:26:56.004208: step 22654, loss 0.185577, acc 0.890625\n",
      "2018-05-04T20:26:56.968735: step 22655, loss 0.175491, acc 0.9375\n",
      "2018-05-04T20:26:57.983130: step 22656, loss 0.131493, acc 0.9375\n",
      "2018-05-04T20:26:58.938602: step 22657, loss 0.232897, acc 0.921875\n",
      "2018-05-04T20:26:59.885236: step 22658, loss 0.165745, acc 0.953125\n",
      "2018-05-04T20:27:00.849841: step 22659, loss 0.2593, acc 0.90625\n",
      "2018-05-04T20:27:01.836911: step 22660, loss 0.347903, acc 0.859375\n",
      "2018-05-04T20:27:02.825521: step 22661, loss 0.275766, acc 0.84375\n",
      "2018-05-04T20:27:03.818421: step 22662, loss 0.310833, acc 0.890625\n",
      "2018-05-04T20:27:04.802523: step 22663, loss 0.25049, acc 0.921875\n",
      "2018-05-04T20:27:05.844710: step 22664, loss 0.29267, acc 0.859375\n",
      "2018-05-04T20:27:06.776827: step 22665, loss 0.334042, acc 0.875\n",
      "2018-05-04T20:27:07.708175: step 22666, loss 0.272439, acc 0.875\n",
      "2018-05-04T20:27:08.656526: step 22667, loss 0.284176, acc 0.890625\n",
      "2018-05-04T20:27:09.591801: step 22668, loss 0.149595, acc 0.953125\n",
      "2018-05-04T20:27:10.554268: step 22669, loss 0.270133, acc 0.875\n",
      "2018-05-04T20:27:11.508019: step 22670, loss 0.26203, acc 0.84375\n",
      "2018-05-04T20:27:12.493616: step 22671, loss 0.261202, acc 0.90625\n",
      "2018-05-04T20:27:13.501587: step 22672, loss 0.246997, acc 0.9375\n",
      "2018-05-04T20:27:14.548283: step 22673, loss 0.175472, acc 0.953125\n",
      "2018-05-04T20:27:15.493301: step 22674, loss 0.209816, acc 0.921875\n",
      "2018-05-04T20:27:16.430928: step 22675, loss 0.0887639, acc 0.984375\n",
      "2018-05-04T20:27:17.438156: step 22676, loss 0.339139, acc 0.890625\n",
      "2018-05-04T20:27:18.405129: step 22677, loss 0.261753, acc 0.90625\n",
      "2018-05-04T20:27:19.402664: step 22678, loss 0.24925, acc 0.90625\n",
      "2018-05-04T20:27:20.357395: step 22679, loss 0.216334, acc 0.921875\n",
      "2018-05-04T20:27:21.394189: step 22680, loss 0.211963, acc 0.9375\n",
      "2018-05-04T20:27:22.405163: step 22681, loss 0.241285, acc 0.90625\n",
      "2018-05-04T20:27:23.383340: step 22682, loss 0.317261, acc 0.875\n",
      "2018-05-04T20:27:24.341480: step 22683, loss 0.11757, acc 0.984375\n",
      "2018-05-04T20:27:25.291650: step 22684, loss 0.280944, acc 0.859375\n",
      "2018-05-04T20:27:26.250461: step 22685, loss 0.180542, acc 0.9375\n",
      "2018-05-04T20:27:27.249794: step 22686, loss 0.282105, acc 0.890625\n",
      "2018-05-04T20:27:28.181881: step 22687, loss 0.364286, acc 0.859375\n",
      "2018-05-04T20:27:29.217707: step 22688, loss 0.256319, acc 0.921875\n",
      "2018-05-04T20:27:30.232644: step 22689, loss 0.275782, acc 0.90625\n",
      "2018-05-04T20:27:31.182948: step 22690, loss 0.176343, acc 0.953125\n",
      "2018-05-04T20:27:32.134470: step 22691, loss 0.293677, acc 0.921875\n",
      "2018-05-04T20:27:33.090159: step 22692, loss 0.218441, acc 0.921875\n",
      "2018-05-04T20:27:34.076464: step 22693, loss 0.176239, acc 0.953125\n",
      "2018-05-04T20:27:35.110392: step 22694, loss 0.135337, acc 0.96875\n",
      "2018-05-04T20:27:36.095959: step 22695, loss 0.203907, acc 0.9375\n",
      "2018-05-04T20:27:37.045566: step 22696, loss 0.169829, acc 0.9375\n",
      "2018-05-04T20:27:37.992015: step 22697, loss 0.202351, acc 0.921875\n",
      "2018-05-04T20:27:38.939265: step 22698, loss 0.250484, acc 0.921875\n",
      "2018-05-04T20:27:39.972562: step 22699, loss 0.175231, acc 0.9375\n",
      "2018-05-04T20:27:40.997032: step 22700, loss 0.310861, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T20:27:43.582703: step 22700, loss 0.224616, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-22700\n",
      "\n",
      "2018-05-04T20:27:44.668227: step 22701, loss 0.296236, acc 0.875\n",
      "2018-05-04T20:27:45.676595: step 22702, loss 0.167238, acc 0.921875\n",
      "2018-05-04T20:27:46.687079: step 22703, loss 0.347903, acc 0.859375\n",
      "2018-05-04T20:27:47.696422: step 22704, loss 0.196101, acc 0.953125\n",
      "2018-05-04T20:27:48.728551: step 22705, loss 0.292368, acc 0.875\n",
      "2018-05-04T20:27:49.761550: step 22706, loss 0.174479, acc 0.953125\n",
      "2018-05-04T20:27:50.776522: step 22707, loss 0.185087, acc 0.90625\n",
      "2018-05-04T20:27:51.793720: step 22708, loss 0.36208, acc 0.890625\n",
      "2018-05-04T20:27:52.785979: step 22709, loss 0.24473, acc 0.90625\n",
      "2018-05-04T20:27:53.771544: step 22710, loss 0.54795, acc 0.8125\n",
      "2018-05-04T20:27:54.758296: step 22711, loss 0.290663, acc 0.90625\n",
      "2018-05-04T20:27:55.760496: step 22712, loss 0.257896, acc 0.875\n",
      "2018-05-04T20:27:56.735136: step 22713, loss 0.252718, acc 0.90625\n",
      "2018-05-04T20:27:57.734854: step 22714, loss 0.260054, acc 0.90625\n",
      "2018-05-04T20:27:58.710399: step 22715, loss 0.165685, acc 0.90625\n",
      "2018-05-04T20:27:59.666665: step 22716, loss 0.222825, acc 0.875\n",
      "2018-05-04T20:28:00.663761: step 22717, loss 0.3962, acc 0.859375\n",
      "2018-05-04T20:28:01.641241: step 22718, loss 0.357896, acc 0.875\n",
      "2018-05-04T20:28:02.613377: step 22719, loss 0.175846, acc 0.9375\n",
      "2018-05-04T20:28:03.575412: step 22720, loss 0.249393, acc 0.90625\n",
      "2018-05-04T20:28:04.563427: step 22721, loss 0.238034, acc 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T20:28:05.533566: step 22722, loss 0.208256, acc 0.90625\n",
      "2018-05-04T20:28:06.495690: step 22723, loss 0.10433, acc 0.96875\n",
      "2018-05-04T20:28:07.521938: step 22724, loss 0.162383, acc 0.953125\n",
      "2018-05-04T20:28:08.487993: step 22725, loss 0.360131, acc 0.859375\n",
      "2018-05-04T20:28:09.456860: step 22726, loss 0.291372, acc 0.875\n",
      "2018-05-04T20:28:10.420745: step 22727, loss 0.251805, acc 0.875\n",
      "2018-05-04T20:28:11.402813: step 22728, loss 0.255409, acc 0.84375\n",
      "2018-05-04T20:28:12.376535: step 22729, loss 0.321467, acc 0.859375\n",
      "2018-05-04T20:28:13.356547: step 22730, loss 0.177557, acc 0.953125\n",
      "2018-05-04T20:28:14.338016: step 22731, loss 0.236142, acc 0.953125\n",
      "2018-05-04T20:28:15.309399: step 22732, loss 0.360259, acc 0.875\n",
      "2018-05-04T20:28:16.266482: step 22733, loss 0.191433, acc 0.90625\n",
      "2018-05-04T20:28:17.242621: step 22734, loss 0.188262, acc 0.90625\n",
      "2018-05-04T20:28:18.253868: step 22735, loss 0.234796, acc 0.921875\n",
      "2018-05-04T20:28:19.258617: step 22736, loss 0.227214, acc 0.90625\n",
      "2018-05-04T20:28:20.267570: step 22737, loss 0.265178, acc 0.90625\n",
      "2018-05-04T20:28:21.288045: step 22738, loss 0.26254, acc 0.875\n",
      "2018-05-04T20:28:22.273300: step 22739, loss 0.26546, acc 0.84375\n",
      "2018-05-04T20:28:23.215187: step 22740, loss 0.213613, acc 0.90625\n",
      "2018-05-04T20:28:24.197132: step 22741, loss 0.343455, acc 0.890625\n",
      "2018-05-04T20:28:25.185740: step 22742, loss 0.192541, acc 0.953125\n",
      "2018-05-04T20:28:26.186287: step 22743, loss 0.291223, acc 0.859375\n",
      "2018-05-04T20:28:27.166303: step 22744, loss 0.370532, acc 0.828125\n",
      "2018-05-04T20:28:28.226098: step 22745, loss 0.203938, acc 0.921875\n",
      "2018-05-04T20:28:29.250929: step 22746, loss 0.33078, acc 0.828125\n",
      "2018-05-04T20:28:30.222817: step 22747, loss 0.285393, acc 0.84375\n",
      "2018-05-04T20:28:31.178899: step 22748, loss 0.136573, acc 0.953125\n",
      "2018-05-04T20:28:32.140912: step 22749, loss 0.291518, acc 0.875\n",
      "2018-05-04T20:28:33.214463: step 22750, loss 0.309269, acc 0.890625\n",
      "2018-05-04T20:28:34.232407: step 22751, loss 0.285122, acc 0.875\n",
      "2018-05-04T20:28:35.315182: step 22752, loss 0.259682, acc 0.921875\n",
      "2018-05-04T20:28:36.341814: step 22753, loss 0.255767, acc 0.875\n",
      "2018-05-04T20:28:37.377884: step 22754, loss 0.275215, acc 0.9375\n",
      "2018-05-04T20:28:38.364688: step 22755, loss 0.29977, acc 0.859375\n",
      "2018-05-04T20:28:39.420819: step 22756, loss 0.389438, acc 0.828125\n",
      "2018-05-04T20:28:40.388238: step 22757, loss 0.339746, acc 0.859375\n",
      "2018-05-04T20:28:41.414069: step 22758, loss 0.282247, acc 0.859375\n",
      "2018-05-04T20:28:42.350207: step 22759, loss 0.268812, acc 0.84375\n",
      "2018-05-04T20:28:43.385460: step 22760, loss 0.161128, acc 0.9375\n",
      "2018-05-04T20:28:44.344532: step 22761, loss 0.218002, acc 0.921875\n",
      "2018-05-04T20:28:45.300864: step 22762, loss 0.365798, acc 0.828125\n",
      "2018-05-04T20:28:46.292101: step 22763, loss 0.242545, acc 0.921875\n",
      "2018-05-04T20:28:47.240643: step 22764, loss 0.161271, acc 0.9375\n",
      "2018-05-04T20:28:48.202876: step 22765, loss 0.325111, acc 0.875\n",
      "2018-05-04T20:28:49.154994: step 22766, loss 0.224679, acc 0.90625\n",
      "2018-05-04T20:28:50.111853: step 22767, loss 0.233327, acc 0.890625\n",
      "2018-05-04T20:28:51.080544: step 22768, loss 0.147635, acc 0.9375\n",
      "2018-05-04T20:28:52.054235: step 22769, loss 0.345725, acc 0.8125\n",
      "2018-05-04T20:28:53.027251: step 22770, loss 0.245499, acc 0.921875\n",
      "2018-05-04T20:28:54.005291: step 22771, loss 0.269623, acc 0.875\n",
      "2018-05-04T20:28:54.996059: step 22772, loss 0.227546, acc 0.921875\n",
      "2018-05-04T20:28:55.981232: step 22773, loss 0.248249, acc 0.875\n",
      "2018-05-04T20:28:56.939706: step 22774, loss 0.326288, acc 0.875\n",
      "2018-05-04T20:28:57.885250: step 22775, loss 0.420977, acc 0.890625\n",
      "2018-05-04T20:28:58.848145: step 22776, loss 0.308383, acc 0.90625\n",
      "2018-05-04T20:28:59.818817: step 22777, loss 0.285805, acc 0.890625\n",
      "2018-05-04T20:29:00.768556: step 22778, loss 0.27696, acc 0.890625\n",
      "2018-05-04T20:29:01.771140: step 22779, loss 0.192402, acc 0.890625\n",
      "2018-05-04T20:29:02.725746: step 22780, loss 0.239052, acc 0.90625\n",
      "2018-05-04T20:29:03.677490: step 22781, loss 0.22247, acc 0.875\n",
      "2018-05-04T20:29:04.648906: step 22782, loss 0.184634, acc 0.921875\n",
      "2018-05-04T20:29:05.601147: step 22783, loss 0.234055, acc 0.90625\n",
      "2018-05-04T20:29:06.563114: step 22784, loss 0.380046, acc 0.796875\n",
      "2018-05-04T20:29:07.521675: step 22785, loss 0.19312, acc 0.90625\n",
      "2018-05-04T20:29:08.490241: step 22786, loss 0.335151, acc 0.875\n",
      "2018-05-04T20:29:09.453432: step 22787, loss 0.412567, acc 0.828125\n",
      "2018-05-04T20:29:10.438667: step 22788, loss 0.218969, acc 0.921875\n",
      "2018-05-04T20:29:11.412890: step 22789, loss 0.273606, acc 0.90625\n",
      "2018-05-04T20:29:12.356778: step 22790, loss 0.279282, acc 0.875\n",
      "2018-05-04T20:29:13.311546: step 22791, loss 0.209912, acc 0.875\n",
      "2018-05-04T20:29:14.262379: step 22792, loss 0.253663, acc 0.90625\n",
      "2018-05-04T20:29:15.204656: step 22793, loss 0.329822, acc 0.90625\n",
      "2018-05-04T20:29:16.158672: step 22794, loss 0.491368, acc 0.78125\n",
      "2018-05-04T20:29:17.117191: step 22795, loss 0.205425, acc 0.921875\n",
      "2018-05-04T20:29:18.106241: step 22796, loss 0.202372, acc 0.921875\n",
      "2018-05-04T20:29:19.068449: step 22797, loss 0.233177, acc 0.859375\n",
      "2018-05-04T20:29:20.035939: step 22798, loss 0.260721, acc 0.875\n",
      "2018-05-04T20:29:20.986406: step 22799, loss 0.278614, acc 0.890625\n",
      "2018-05-04T20:29:21.944636: step 22800, loss 0.287638, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T20:29:24.437529: step 22800, loss 0.210988, acc 0.922\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-22800\n",
      "\n",
      "2018-05-04T20:29:25.601768: step 22801, loss 0.308962, acc 0.90625\n",
      "2018-05-04T20:29:26.584993: step 22802, loss 0.392836, acc 0.890625\n",
      "2018-05-04T20:29:27.571961: step 22803, loss 0.363508, acc 0.90625\n",
      "2018-05-04T20:29:28.578035: step 22804, loss 0.272701, acc 0.90625\n",
      "2018-05-04T20:29:29.553651: step 22805, loss 0.287218, acc 0.90625\n",
      "2018-05-04T20:29:30.581324: step 22806, loss 0.241834, acc 0.921875\n",
      "2018-05-04T20:29:31.569058: step 22807, loss 0.260305, acc 0.890625\n",
      "2018-05-04T20:29:32.543925: step 22808, loss 0.25702, acc 0.890625\n",
      "2018-05-04T20:29:33.556612: step 22809, loss 0.331396, acc 0.875\n",
      "2018-05-04T20:29:34.623785: step 22810, loss 0.161393, acc 0.921875\n",
      "2018-05-04T20:29:35.603218: step 22811, loss 0.236754, acc 0.890625\n",
      "2018-05-04T20:29:36.564890: step 22812, loss 0.326817, acc 0.84375\n",
      "2018-05-04T20:29:37.557625: step 22813, loss 0.221335, acc 0.9375\n",
      "2018-05-04T20:29:38.544117: step 22814, loss 0.336103, acc 0.84375\n",
      "2018-05-04T20:29:39.521294: step 22815, loss 0.252016, acc 0.90625\n",
      "2018-05-04T20:29:40.486185: step 22816, loss 0.241476, acc 0.90625\n",
      "2018-05-04T20:29:41.442832: step 22817, loss 0.330902, acc 0.890625\n",
      "2018-05-04T20:29:42.420932: step 22818, loss 0.224862, acc 0.9375\n",
      "2018-05-04T20:29:43.389320: step 22819, loss 0.165661, acc 0.9375\n",
      "2018-05-04T20:29:44.334505: step 22820, loss 0.272831, acc 0.90625\n",
      "2018-05-04T20:29:45.300739: step 22821, loss 0.386719, acc 0.859375\n",
      "2018-05-04T20:29:46.285023: step 22822, loss 0.243328, acc 0.90625\n",
      "2018-05-04T20:29:47.293288: step 22823, loss 0.217272, acc 0.90625\n",
      "2018-05-04T20:29:48.283050: step 22824, loss 0.269173, acc 0.90625\n",
      "2018-05-04T20:29:49.300578: step 22825, loss 0.29326, acc 0.859375\n",
      "2018-05-04T20:29:50.284392: step 22826, loss 0.235747, acc 0.921875\n",
      "2018-05-04T20:29:51.259532: step 22827, loss 0.339267, acc 0.890625\n",
      "2018-05-04T20:29:52.257113: step 22828, loss 0.229248, acc 0.890625\n",
      "2018-05-04T20:29:53.254375: step 22829, loss 0.306304, acc 0.90625\n",
      "2018-05-04T20:29:54.297078: step 22830, loss 0.370912, acc 0.828125\n",
      "2018-05-04T20:29:55.253663: step 22831, loss 0.255658, acc 0.921875\n",
      "2018-05-04T20:29:56.236276: step 22832, loss 0.27942, acc 0.859375\n",
      "2018-05-04T20:29:57.215905: step 22833, loss 0.278008, acc 0.875\n",
      "2018-05-04T20:29:58.190832: step 22834, loss 0.251349, acc 0.890625\n",
      "2018-05-04T20:29:59.177408: step 22835, loss 0.17341, acc 0.921875\n",
      "2018-05-04T20:30:00.184670: step 22836, loss 0.200278, acc 0.921875\n",
      "2018-05-04T20:30:01.142163: step 22837, loss 0.317855, acc 0.8125\n",
      "2018-05-04T20:30:02.098205: step 22838, loss 0.181217, acc 0.9375\n",
      "2018-05-04T20:30:03.143808: step 22839, loss 0.151936, acc 0.921875\n",
      "2018-05-04T20:30:04.132993: step 22840, loss 0.177185, acc 0.953125\n",
      "2018-05-04T20:30:05.114058: step 22841, loss 0.196743, acc 0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T20:30:06.086243: step 22842, loss 0.189564, acc 0.921875\n",
      "2018-05-04T20:30:07.063637: step 22843, loss 0.220971, acc 0.90625\n",
      "2018-05-04T20:30:08.034929: step 22844, loss 0.249199, acc 0.875\n",
      "2018-05-04T20:30:09.076684: step 22845, loss 0.240754, acc 0.859375\n",
      "2018-05-04T20:30:10.091480: step 22846, loss 0.175069, acc 0.9375\n",
      "2018-05-04T20:30:11.066322: step 22847, loss 0.273959, acc 0.859375\n",
      "2018-05-04T20:30:12.041254: step 22848, loss 0.410292, acc 0.828125\n",
      "2018-05-04T20:30:12.998943: step 22849, loss 0.248788, acc 0.875\n",
      "2018-05-04T20:30:14.056926: step 22850, loss 0.201419, acc 0.875\n",
      "2018-05-04T20:30:15.031013: step 22851, loss 0.21473, acc 0.90625\n",
      "2018-05-04T20:30:15.988969: step 22852, loss 0.247703, acc 0.921875\n",
      "2018-05-04T20:30:16.982288: step 22853, loss 0.297704, acc 0.828125\n",
      "2018-05-04T20:30:18.050978: step 22854, loss 0.481575, acc 0.84375\n",
      "2018-05-04T20:30:19.019739: step 22855, loss 0.318127, acc 0.875\n",
      "2018-05-04T20:30:20.025378: step 22856, loss 0.292669, acc 0.890625\n",
      "2018-05-04T20:30:21.088614: step 22857, loss 0.212766, acc 0.890625\n",
      "2018-05-04T20:30:22.037006: step 22858, loss 0.310207, acc 0.859375\n",
      "2018-05-04T20:30:23.081601: step 22859, loss 0.33128, acc 0.890625\n",
      "2018-05-04T20:30:24.117153: step 22860, loss 0.253974, acc 0.90625\n",
      "2018-05-04T20:30:25.098889: step 22861, loss 0.268875, acc 0.890625\n",
      "2018-05-04T20:30:26.132746: step 22862, loss 0.283421, acc 0.890625\n",
      "2018-05-04T20:30:27.150738: step 22863, loss 0.267335, acc 0.90625\n",
      "2018-05-04T20:30:28.216751: step 22864, loss 0.360149, acc 0.828125\n",
      "2018-05-04T20:30:29.238484: step 22865, loss 0.244966, acc 0.90625\n",
      "2018-05-04T20:30:30.317375: step 22866, loss 0.17229, acc 0.953125\n",
      "2018-05-04T20:30:31.415842: step 22867, loss 0.240131, acc 0.890625\n",
      "2018-05-04T20:30:32.440755: step 22868, loss 0.215219, acc 0.890625\n",
      "2018-05-04T20:30:33.485858: step 22869, loss 0.358097, acc 0.875\n",
      "2018-05-04T20:30:34.482470: step 22870, loss 0.396347, acc 0.875\n",
      "2018-05-04T20:30:35.430079: step 22871, loss 0.12999, acc 0.953125\n",
      "2018-05-04T20:30:36.359108: step 22872, loss 0.388089, acc 0.84375\n",
      "2018-05-04T20:30:37.302872: step 22873, loss 0.259229, acc 0.859375\n",
      "2018-05-04T20:30:38.479292: step 22874, loss 0.270095, acc 0.875\n",
      "2018-05-04T20:30:39.639106: step 22875, loss 0.19692, acc 0.90625\n",
      "2018-05-04T20:30:40.977889: step 22876, loss 0.349988, acc 0.875\n",
      "2018-05-04T20:30:42.142839: step 22877, loss 0.23796, acc 0.921875\n",
      "2018-05-04T20:30:43.320396: step 22878, loss 0.234735, acc 0.890625\n",
      "2018-05-04T20:30:44.445592: step 22879, loss 0.311793, acc 0.8125\n",
      "2018-05-04T20:30:45.537989: step 22880, loss 0.303111, acc 0.90625\n",
      "2018-05-04T20:30:46.556965: step 22881, loss 0.226107, acc 0.921875\n",
      "2018-05-04T20:30:47.647484: step 22882, loss 0.243418, acc 0.90625\n",
      "2018-05-04T20:30:48.735976: step 22883, loss 0.181282, acc 0.9375\n",
      "2018-05-04T20:30:49.875475: step 22884, loss 0.209739, acc 0.90625\n",
      "2018-05-04T20:30:50.974466: step 22885, loss 0.301116, acc 0.890625\n",
      "2018-05-04T20:30:52.154893: step 22886, loss 0.274273, acc 0.890625\n",
      "2018-05-04T20:30:53.350325: step 22887, loss 0.417746, acc 0.859375\n",
      "2018-05-04T20:30:54.373876: step 22888, loss 0.183153, acc 0.921875\n",
      "2018-05-04T20:30:55.364575: step 22889, loss 0.256135, acc 0.921875\n",
      "2018-05-04T20:30:56.580020: step 22890, loss 0.289789, acc 0.859375\n",
      "2018-05-04T20:30:57.587489: step 22891, loss 0.179706, acc 0.921875\n",
      "2018-05-04T20:30:58.671814: step 22892, loss 0.231987, acc 0.875\n",
      "2018-05-04T20:30:59.731639: step 22893, loss 0.43537, acc 0.8125\n",
      "2018-05-04T20:31:00.718107: step 22894, loss 0.233734, acc 0.90625\n",
      "2018-05-04T20:31:01.803590: step 22895, loss 0.275982, acc 0.90625\n",
      "2018-05-04T20:31:02.925706: step 22896, loss 0.140698, acc 0.96875\n",
      "2018-05-04T20:31:04.074103: step 22897, loss 0.230857, acc 0.90625\n",
      "2018-05-04T20:31:05.137894: step 22898, loss 0.399367, acc 0.78125\n",
      "2018-05-04T20:31:06.245799: step 22899, loss 0.275694, acc 0.890625\n",
      "2018-05-04T20:31:07.287281: step 22900, loss 0.166608, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T20:31:12.189105: step 22900, loss 0.208597, acc 0.928\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-22900\n",
      "\n",
      "2018-05-04T20:31:13.548670: step 22901, loss 0.18582, acc 0.921875\n",
      "2018-05-04T20:31:14.759830: step 22902, loss 0.302798, acc 0.875\n",
      "2018-05-04T20:31:15.964503: step 22903, loss 0.292619, acc 0.84375\n",
      "2018-05-04T20:31:16.999903: step 22904, loss 0.271526, acc 0.859375\n",
      "2018-05-04T20:31:18.042732: step 22905, loss 0.318407, acc 0.828125\n",
      "2018-05-04T20:31:19.089478: step 22906, loss 0.214668, acc 0.921875\n",
      "2018-05-04T20:31:20.305000: step 22907, loss 0.237466, acc 0.9375\n",
      "2018-05-04T20:31:21.586345: step 22908, loss 0.207662, acc 0.90625\n",
      "2018-05-04T20:31:22.824633: step 22909, loss 0.108629, acc 0.984375\n",
      "2018-05-04T20:31:23.882036: step 22910, loss 0.178946, acc 0.9375\n",
      "2018-05-04T20:31:25.016364: step 22911, loss 0.390212, acc 0.890625\n",
      "2018-05-04T20:31:26.162775: step 22912, loss 0.136664, acc 0.96875\n",
      "2018-05-04T20:31:27.412439: step 22913, loss 0.150471, acc 0.921875\n",
      "2018-05-04T20:31:28.717687: step 22914, loss 0.223807, acc 0.890625\n",
      "2018-05-04T20:31:30.034642: step 22915, loss 0.365508, acc 0.828125\n",
      "2018-05-04T20:31:31.160030: step 22916, loss 0.3151, acc 0.875\n",
      "2018-05-04T20:31:32.354741: step 22917, loss 0.286242, acc 0.828125\n",
      "2018-05-04T20:31:33.680880: step 22918, loss 0.257766, acc 0.875\n",
      "2018-05-04T20:31:35.044884: step 22919, loss 0.324082, acc 0.875\n",
      "2018-05-04T20:31:36.318462: step 22920, loss 0.241134, acc 0.828125\n",
      "2018-05-04T20:31:37.565645: step 22921, loss 0.327636, acc 0.875\n",
      "2018-05-04T20:31:38.689053: step 22922, loss 0.391965, acc 0.84375\n",
      "2018-05-04T20:31:39.815473: step 22923, loss 0.222792, acc 0.9375\n",
      "2018-05-04T20:31:41.057595: step 22924, loss 0.379058, acc 0.890625\n",
      "2018-05-04T20:31:42.281270: step 22925, loss 0.368785, acc 0.8125\n",
      "2018-05-04T20:31:43.601015: step 22926, loss 0.263607, acc 0.875\n",
      "2018-05-04T20:31:44.859923: step 22927, loss 0.312952, acc 0.875\n",
      "2018-05-04T20:31:46.068703: step 22928, loss 0.254522, acc 0.859375\n",
      "2018-05-04T20:31:47.373001: step 22929, loss 0.216416, acc 0.875\n",
      "2018-05-04T20:31:48.595179: step 22930, loss 0.271122, acc 0.890625\n",
      "2018-05-04T20:31:49.764776: step 22931, loss 0.26321, acc 0.875\n",
      "2018-05-04T20:31:50.942044: step 22932, loss 0.335621, acc 0.84375\n",
      "2018-05-04T20:31:52.174979: step 22933, loss 0.294374, acc 0.84375\n",
      "2018-05-04T20:31:53.325446: step 22934, loss 0.225547, acc 0.953125\n",
      "2018-05-04T20:31:54.504464: step 22935, loss 0.255077, acc 0.859375\n",
      "2018-05-04T20:31:55.655447: step 22936, loss 0.2424, acc 0.90625\n",
      "2018-05-04T20:31:56.937056: step 22937, loss 0.285644, acc 0.875\n",
      "2018-05-04T20:31:58.085216: step 22938, loss 0.230389, acc 0.890625\n",
      "2018-05-04T20:31:59.244051: step 22939, loss 0.230492, acc 0.9375\n",
      "2018-05-04T20:32:00.319547: step 22940, loss 0.239792, acc 0.90625\n",
      "2018-05-04T20:32:01.519635: step 22941, loss 0.236603, acc 0.890625\n",
      "2018-05-04T20:32:02.765311: step 22942, loss 0.25839, acc 0.890625\n",
      "2018-05-04T20:32:03.989381: step 22943, loss 0.390977, acc 0.8125\n",
      "2018-05-04T20:32:05.157500: step 22944, loss 0.241855, acc 0.890625\n",
      "2018-05-04T20:32:06.381003: step 22945, loss 0.224877, acc 0.921875\n",
      "2018-05-04T20:32:07.522981: step 22946, loss 0.17939, acc 0.921875\n",
      "2018-05-04T20:32:08.711544: step 22947, loss 0.234576, acc 0.90625\n",
      "2018-05-04T20:32:09.892248: step 22948, loss 0.220794, acc 0.90625\n",
      "2018-05-04T20:32:11.093896: step 22949, loss 0.355949, acc 0.859375\n",
      "2018-05-04T20:32:12.359464: step 22950, loss 0.21595, acc 0.90625\n",
      "2018-05-04T20:32:13.584769: step 22951, loss 0.24086, acc 0.890625\n",
      "2018-05-04T20:32:14.764902: step 22952, loss 0.163223, acc 0.921875\n",
      "2018-05-04T20:32:15.999978: step 22953, loss 0.251627, acc 0.875\n",
      "2018-05-04T20:32:17.227990: step 22954, loss 0.163707, acc 0.953125\n",
      "2018-05-04T20:32:18.405483: step 22955, loss 0.168795, acc 0.9375\n",
      "2018-05-04T20:32:19.635332: step 22956, loss 0.247771, acc 0.875\n",
      "2018-05-04T20:32:20.787837: step 22957, loss 0.3225, acc 0.875\n",
      "2018-05-04T20:32:22.070633: step 22958, loss 0.265834, acc 0.921875\n",
      "2018-05-04T20:32:23.354960: step 22959, loss 0.457888, acc 0.8125\n",
      "2018-05-04T20:32:24.592241: step 22960, loss 0.233527, acc 0.890625\n",
      "2018-05-04T20:32:25.690093: step 22961, loss 0.24109, acc 0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T20:32:26.816676: step 22962, loss 0.278449, acc 0.890625\n",
      "2018-05-04T20:32:28.048331: step 22963, loss 0.254848, acc 0.921875\n",
      "2018-05-04T20:32:29.215907: step 22964, loss 0.156831, acc 0.921875\n",
      "2018-05-04T20:32:30.447563: step 22965, loss 0.239015, acc 0.890625\n",
      "2018-05-04T20:32:31.833596: step 22966, loss 0.220636, acc 0.90625\n",
      "2018-05-04T20:32:33.106548: step 22967, loss 0.168246, acc 0.953125\n",
      "2018-05-04T20:32:34.419490: step 22968, loss 0.226638, acc 0.9375\n",
      "2018-05-04T20:32:35.688348: step 22969, loss 0.216889, acc 0.921875\n",
      "2018-05-04T20:32:37.031037: step 22970, loss 0.225116, acc 0.921875\n",
      "2018-05-04T20:32:38.206485: step 22971, loss 0.456168, acc 0.78125\n",
      "2018-05-04T20:32:39.337607: step 22972, loss 0.273333, acc 0.84375\n",
      "2018-05-04T20:32:40.434398: step 22973, loss 0.241163, acc 0.90625\n",
      "2018-05-04T20:32:41.610514: step 22974, loss 0.317467, acc 0.859375\n",
      "2018-05-04T20:32:42.781364: step 22975, loss 0.242922, acc 0.859375\n",
      "2018-05-04T20:32:43.988507: step 22976, loss 0.354882, acc 0.859375\n",
      "2018-05-04T20:32:45.168431: step 22977, loss 0.311678, acc 0.890625\n",
      "2018-05-04T20:32:46.344453: step 22978, loss 0.371653, acc 0.875\n",
      "2018-05-04T20:32:47.554127: step 22979, loss 0.230333, acc 0.890625\n",
      "2018-05-04T20:32:48.740529: step 22980, loss 0.270011, acc 0.90625\n",
      "2018-05-04T20:32:49.882830: step 22981, loss 0.20109, acc 0.921875\n",
      "2018-05-04T20:32:51.123404: step 22982, loss 0.404602, acc 0.8125\n",
      "2018-05-04T20:32:52.356826: step 22983, loss 0.400465, acc 0.828125\n",
      "2018-05-04T20:32:53.568934: step 22984, loss 0.246891, acc 0.921875\n",
      "2018-05-04T20:32:54.620265: step 22985, loss 0.228393, acc 0.9375\n",
      "2018-05-04T20:32:55.747871: step 22986, loss 0.231867, acc 0.9375\n",
      "2018-05-04T20:32:56.806788: step 22987, loss 0.300692, acc 0.859375\n",
      "2018-05-04T20:32:57.856942: step 22988, loss 0.330848, acc 0.859375\n",
      "2018-05-04T20:32:59.097590: step 22989, loss 0.25893, acc 0.890625\n",
      "2018-05-04T20:33:00.196445: step 22990, loss 0.183688, acc 0.953125\n",
      "2018-05-04T20:33:01.322999: step 22991, loss 0.243887, acc 0.859375\n",
      "2018-05-04T20:33:02.533715: step 22992, loss 0.241844, acc 0.9375\n",
      "2018-05-04T20:33:03.759039: step 22993, loss 0.244737, acc 0.890625\n",
      "2018-05-04T20:33:04.977828: step 22994, loss 0.188963, acc 0.921875\n",
      "2018-05-04T20:33:06.115288: step 22995, loss 0.280979, acc 0.859375\n",
      "2018-05-04T20:33:07.321983: step 22996, loss 0.331599, acc 0.859375\n",
      "2018-05-04T20:33:08.383802: step 22997, loss 0.178306, acc 0.921875\n",
      "2018-05-04T20:33:09.511794: step 22998, loss 0.277377, acc 0.921875\n",
      "2018-05-04T20:33:10.564648: step 22999, loss 0.198119, acc 0.921875\n",
      "2018-05-04T20:33:11.672102: step 23000, loss 0.298889, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T20:33:14.971861: step 23000, loss 0.228927, acc 0.928\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-23000\n",
      "\n",
      "2018-05-04T20:33:16.235601: step 23001, loss 0.181765, acc 0.921875\n",
      "2018-05-04T20:33:17.522747: step 23002, loss 0.284031, acc 0.859375\n",
      "2018-05-04T20:33:18.676871: step 23003, loss 0.203668, acc 0.90625\n",
      "2018-05-04T20:33:19.926635: step 23004, loss 0.227093, acc 0.921875\n",
      "2018-05-04T20:33:21.076349: step 23005, loss 0.227012, acc 0.90625\n",
      "2018-05-04T20:33:22.241431: step 23006, loss 0.180637, acc 0.921875\n",
      "2018-05-04T20:33:23.355506: step 23007, loss 0.128722, acc 0.953125\n",
      "2018-05-04T20:33:24.438280: step 23008, loss 0.328126, acc 0.890625\n",
      "2018-05-04T20:33:25.532328: step 23009, loss 0.233861, acc 0.90625\n",
      "2018-05-04T20:33:26.735656: step 23010, loss 0.265011, acc 0.9375\n",
      "2018-05-04T20:33:27.928515: step 23011, loss 0.317348, acc 0.90625\n",
      "2018-05-04T20:33:29.024082: step 23012, loss 0.172469, acc 0.984375\n",
      "2018-05-04T20:33:30.132623: step 23013, loss 0.234322, acc 0.890625\n",
      "2018-05-04T20:33:31.286601: step 23014, loss 0.231864, acc 0.890625\n",
      "2018-05-04T20:33:32.389396: step 23015, loss 0.39887, acc 0.890625\n",
      "2018-05-04T20:33:33.485082: step 23016, loss 0.129166, acc 0.984375\n",
      "2018-05-04T20:33:34.628207: step 23017, loss 0.354482, acc 0.8125\n",
      "2018-05-04T20:33:35.739649: step 23018, loss 0.202953, acc 0.921875\n",
      "2018-05-04T20:33:36.798990: step 23019, loss 0.202791, acc 0.875\n",
      "2018-05-04T20:33:37.874956: step 23020, loss 0.265306, acc 0.90625\n",
      "2018-05-04T20:33:38.981631: step 23021, loss 0.27475, acc 0.921875\n",
      "2018-05-04T20:33:39.985208: step 23022, loss 0.297171, acc 0.875\n",
      "2018-05-04T20:33:41.119123: step 23023, loss 0.224112, acc 0.90625\n",
      "2018-05-04T20:33:42.282459: step 23024, loss 0.124203, acc 0.96875\n",
      "2018-05-04T20:33:43.324374: step 23025, loss 0.296315, acc 0.890625\n",
      "2018-05-04T20:33:44.363319: step 23026, loss 0.30953, acc 0.84375\n",
      "2018-05-04T20:33:45.409201: step 23027, loss 0.263483, acc 0.84375\n",
      "2018-05-04T20:33:46.499555: step 23028, loss 0.315242, acc 0.859375\n",
      "2018-05-04T20:33:47.559201: step 23029, loss 0.236713, acc 0.921875\n",
      "2018-05-04T20:33:48.603070: step 23030, loss 0.171852, acc 0.90625\n",
      "2018-05-04T20:33:49.624608: step 23031, loss 0.303204, acc 0.859375\n",
      "2018-05-04T20:33:50.657464: step 23032, loss 0.234943, acc 0.90625\n",
      "2018-05-04T20:33:51.759558: step 23033, loss 0.224407, acc 0.9375\n",
      "2018-05-04T20:33:52.801364: step 23034, loss 0.147249, acc 0.96875\n",
      "2018-05-04T20:33:53.896911: step 23035, loss 0.3079, acc 0.859375\n",
      "2018-05-04T20:33:54.994263: step 23036, loss 0.372559, acc 0.84375\n",
      "2018-05-04T20:33:56.063410: step 23037, loss 0.174182, acc 0.953125\n",
      "2018-05-04T20:33:57.187253: step 23038, loss 0.281463, acc 0.921875\n",
      "2018-05-04T20:33:58.205030: step 23039, loss 0.233803, acc 0.9375\n",
      "2018-05-04T20:33:59.363886: step 23040, loss 0.210422, acc 0.9375\n",
      "2018-05-04T20:34:00.622767: step 23041, loss 0.296314, acc 0.921875\n",
      "2018-05-04T20:34:01.705064: step 23042, loss 0.135988, acc 0.921875\n",
      "2018-05-04T20:34:02.729489: step 23043, loss 0.247009, acc 0.90625\n",
      "2018-05-04T20:34:03.845321: step 23044, loss 0.23327, acc 0.828125\n",
      "2018-05-04T20:34:04.933737: step 23045, loss 0.331879, acc 0.84375\n",
      "2018-05-04T20:34:05.933894: step 23046, loss 0.259969, acc 0.921875\n",
      "2018-05-04T20:34:06.951137: step 23047, loss 0.313615, acc 0.84375\n",
      "2018-05-04T20:34:08.009540: step 23048, loss 0.236985, acc 0.90625\n",
      "2018-05-04T20:34:09.013079: step 23049, loss 0.123172, acc 0.953125\n",
      "2018-05-04T20:34:10.137343: step 23050, loss 0.306889, acc 0.90625\n",
      "2018-05-04T20:34:11.286512: step 23051, loss 0.297474, acc 0.875\n",
      "2018-05-04T20:34:12.381511: step 23052, loss 0.249773, acc 0.90625\n",
      "2018-05-04T20:34:13.436069: step 23053, loss 0.275802, acc 0.890625\n",
      "2018-05-04T20:34:14.524176: step 23054, loss 0.270502, acc 0.859375\n",
      "2018-05-04T20:34:15.645023: step 23055, loss 0.368276, acc 0.84375\n",
      "2018-05-04T20:34:16.823631: step 23056, loss 0.287858, acc 0.90625\n",
      "2018-05-04T20:34:17.963876: step 23057, loss 0.184463, acc 0.921875\n",
      "2018-05-04T20:34:19.144085: step 23058, loss 0.172811, acc 0.953125\n",
      "2018-05-04T20:34:20.338417: step 23059, loss 0.232509, acc 0.90625\n",
      "2018-05-04T20:34:21.516881: step 23060, loss 0.294088, acc 0.890625\n",
      "2018-05-04T20:34:22.673923: step 23061, loss 0.281958, acc 0.90625\n",
      "2018-05-04T20:34:23.785093: step 23062, loss 0.420328, acc 0.828125\n",
      "2018-05-04T20:34:24.875324: step 23063, loss 0.217333, acc 0.875\n",
      "2018-05-04T20:34:25.991479: step 23064, loss 0.282346, acc 0.90625\n",
      "2018-05-04T20:34:27.053816: step 23065, loss 0.181022, acc 0.921875\n",
      "2018-05-04T20:34:28.188403: step 23066, loss 0.380917, acc 0.90625\n",
      "2018-05-04T20:34:29.402469: step 23067, loss 0.28517, acc 0.859375\n",
      "2018-05-04T20:34:30.606987: step 23068, loss 0.313194, acc 0.84375\n",
      "2018-05-04T20:34:31.952330: step 23069, loss 0.157989, acc 0.9375\n",
      "2018-05-04T20:34:33.142159: step 23070, loss 0.315032, acc 0.859375\n",
      "2018-05-04T20:34:34.298479: step 23071, loss 0.212788, acc 0.921875\n",
      "2018-05-04T20:34:35.546178: step 23072, loss 0.184271, acc 0.9375\n",
      "2018-05-04T20:34:36.716242: step 23073, loss 0.204779, acc 0.921875\n",
      "2018-05-04T20:34:37.942349: step 23074, loss 0.271833, acc 0.890625\n",
      "2018-05-04T20:34:39.221488: step 23075, loss 0.193629, acc 0.921875\n",
      "2018-05-04T20:34:40.466490: step 23076, loss 0.207726, acc 0.890625\n",
      "2018-05-04T20:34:41.613295: step 23077, loss 0.255854, acc 0.890625\n",
      "2018-05-04T20:34:42.799782: step 23078, loss 0.361293, acc 0.875\n",
      "2018-05-04T20:34:43.975851: step 23079, loss 0.331396, acc 0.8125\n",
      "2018-05-04T20:34:45.169469: step 23080, loss 0.19968, acc 0.921875\n",
      "2018-05-04T20:34:46.316854: step 23081, loss 0.169835, acc 0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T20:34:47.368407: step 23082, loss 0.223725, acc 0.90625\n",
      "2018-05-04T20:34:48.378994: step 23083, loss 0.216931, acc 0.90625\n",
      "2018-05-04T20:34:49.476028: step 23084, loss 0.259097, acc 0.890625\n",
      "2018-05-04T20:34:50.574940: step 23085, loss 0.182038, acc 0.9375\n",
      "2018-05-04T20:34:51.827645: step 23086, loss 0.120431, acc 0.953125\n",
      "2018-05-04T20:34:53.188024: step 23087, loss 0.224916, acc 0.90625\n",
      "2018-05-04T20:34:54.498129: step 23088, loss 0.192194, acc 0.953125\n",
      "2018-05-04T20:34:55.780835: step 23089, loss 0.164733, acc 0.921875\n",
      "2018-05-04T20:34:57.090597: step 23090, loss 0.212069, acc 0.921875\n",
      "2018-05-04T20:34:58.347530: step 23091, loss 0.140241, acc 0.9375\n",
      "2018-05-04T20:34:59.700040: step 23092, loss 0.295204, acc 0.890625\n",
      "2018-05-04T20:35:00.900857: step 23093, loss 0.331195, acc 0.890625\n",
      "2018-05-04T20:35:02.267229: step 23094, loss 0.397913, acc 0.859375\n",
      "2018-05-04T20:35:03.743541: step 23095, loss 0.270725, acc 0.921875\n",
      "2018-05-04T20:35:05.041300: step 23096, loss 0.2219, acc 0.921875\n",
      "2018-05-04T20:35:06.360709: step 23097, loss 0.422871, acc 0.875\n",
      "2018-05-04T20:35:07.586020: step 23098, loss 0.258992, acc 0.890625\n",
      "2018-05-04T20:35:08.786076: step 23099, loss 0.203027, acc 0.90625\n",
      "2018-05-04T20:35:10.049054: step 23100, loss 0.280784, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T20:35:14.058831: step 23100, loss 0.221185, acc 0.93\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-23100\n",
      "\n",
      "2018-05-04T20:35:15.396562: step 23101, loss 0.243433, acc 0.921875\n",
      "2018-05-04T20:35:16.670499: step 23102, loss 0.228948, acc 0.890625\n",
      "2018-05-04T20:35:18.027141: step 23103, loss 0.343387, acc 0.84375\n",
      "2018-05-04T20:35:19.319058: step 23104, loss 0.296082, acc 0.890625\n",
      "2018-05-04T20:35:20.609949: step 23105, loss 0.343656, acc 0.875\n",
      "2018-05-04T20:35:21.945141: step 23106, loss 0.302482, acc 0.875\n",
      "2018-05-04T20:35:23.168797: step 23107, loss 0.450821, acc 0.796875\n",
      "2018-05-04T20:35:24.376306: step 23108, loss 0.207616, acc 0.921875\n",
      "2018-05-04T20:35:25.623904: step 23109, loss 0.256134, acc 0.90625\n",
      "2018-05-04T20:35:26.869316: step 23110, loss 0.204181, acc 0.9375\n",
      "2018-05-04T20:35:28.006938: step 23111, loss 0.221225, acc 0.921875\n",
      "2018-05-04T20:35:29.113462: step 23112, loss 0.250121, acc 0.921875\n",
      "2018-05-04T20:35:30.314919: step 23113, loss 0.333557, acc 0.90625\n",
      "2018-05-04T20:35:31.503283: step 23114, loss 0.425536, acc 0.796875\n",
      "2018-05-04T20:35:32.602136: step 23115, loss 0.315365, acc 0.8125\n",
      "2018-05-04T20:35:33.807297: step 23116, loss 0.246602, acc 0.890625\n",
      "2018-05-04T20:35:35.012931: step 23117, loss 0.199089, acc 0.9375\n",
      "2018-05-04T20:35:36.122674: step 23118, loss 0.298202, acc 0.90625\n",
      "2018-05-04T20:35:37.286554: step 23119, loss 0.220596, acc 0.921875\n",
      "2018-05-04T20:35:38.405236: step 23120, loss 0.210529, acc 0.875\n",
      "2018-05-04T20:35:39.549746: step 23121, loss 0.398134, acc 0.875\n",
      "2018-05-04T20:35:40.735283: step 23122, loss 0.306965, acc 0.9375\n",
      "2018-05-04T20:35:41.900752: step 23123, loss 0.210935, acc 0.90625\n",
      "2018-05-04T20:35:43.088243: step 23124, loss 0.149333, acc 0.9375\n",
      "2018-05-04T20:35:44.295939: step 23125, loss 0.284222, acc 0.875\n",
      "2018-05-04T20:35:45.504813: step 23126, loss 0.235693, acc 0.953125\n",
      "2018-05-04T20:35:46.591943: step 23127, loss 0.249891, acc 0.90625\n",
      "2018-05-04T20:35:47.662087: step 23128, loss 0.350126, acc 0.859375\n",
      "2018-05-04T20:35:48.729358: step 23129, loss 0.258325, acc 0.921875\n",
      "2018-05-04T20:35:49.889151: step 23130, loss 0.262854, acc 0.90625\n",
      "2018-05-04T20:35:50.989684: step 23131, loss 0.315706, acc 0.8125\n",
      "2018-05-04T20:35:52.219760: step 23132, loss 0.312493, acc 0.84375\n",
      "2018-05-04T20:35:53.462878: step 23133, loss 0.232346, acc 0.90625\n",
      "2018-05-04T20:35:54.593124: step 23134, loss 0.283414, acc 0.890625\n",
      "2018-05-04T20:35:55.697710: step 23135, loss 0.326982, acc 0.875\n",
      "2018-05-04T20:35:56.863997: step 23136, loss 0.308134, acc 0.859375\n",
      "2018-05-04T20:35:58.057928: step 23137, loss 0.329953, acc 0.828125\n",
      "2018-05-04T20:35:59.246836: step 23138, loss 0.276966, acc 0.921875\n",
      "2018-05-04T20:36:00.439892: step 23139, loss 0.182147, acc 0.9375\n",
      "2018-05-04T20:36:01.621341: step 23140, loss 0.237975, acc 0.875\n",
      "2018-05-04T20:36:02.702154: step 23141, loss 0.172764, acc 0.90625\n",
      "2018-05-04T20:36:03.780721: step 23142, loss 0.335194, acc 0.90625\n",
      "2018-05-04T20:36:04.938439: step 23143, loss 0.205008, acc 0.921875\n",
      "2018-05-04T20:36:06.065548: step 23144, loss 0.280512, acc 0.890625\n",
      "2018-05-04T20:36:07.175835: step 23145, loss 0.331757, acc 0.828125\n",
      "2018-05-04T20:36:08.376331: step 23146, loss 0.18934, acc 0.953125\n",
      "2018-05-04T20:36:09.455890: step 23147, loss 0.289763, acc 0.875\n",
      "2018-05-04T20:36:10.520430: step 23148, loss 0.30588, acc 0.84375\n",
      "2018-05-04T20:36:11.625845: step 23149, loss 0.172635, acc 0.90625\n",
      "2018-05-04T20:36:12.663872: step 23150, loss 0.263514, acc 0.9375\n",
      "2018-05-04T20:36:13.712086: step 23151, loss 0.238817, acc 0.875\n",
      "2018-05-04T20:36:14.772039: step 23152, loss 0.249614, acc 0.90625\n",
      "2018-05-04T20:36:15.808009: step 23153, loss 0.370254, acc 0.828125\n",
      "2018-05-04T20:36:16.831656: step 23154, loss 0.243908, acc 0.890625\n",
      "2018-05-04T20:36:17.918673: step 23155, loss 0.231272, acc 0.90625\n",
      "2018-05-04T20:36:19.086435: step 23156, loss 0.218449, acc 0.90625\n",
      "2018-05-04T20:36:20.147980: step 23157, loss 0.182221, acc 0.9375\n",
      "2018-05-04T20:36:21.236115: step 23158, loss 0.153677, acc 0.953125\n",
      "2018-05-04T20:36:22.249949: step 23159, loss 0.188283, acc 0.9375\n",
      "2018-05-04T20:36:23.275441: step 23160, loss 0.258781, acc 0.890625\n",
      "2018-05-04T20:36:24.287480: step 23161, loss 0.221621, acc 0.921875\n",
      "2018-05-04T20:36:25.286166: step 23162, loss 0.175614, acc 0.9375\n",
      "2018-05-04T20:36:26.295844: step 23163, loss 0.245198, acc 0.90625\n",
      "2018-05-04T20:36:27.311842: step 23164, loss 0.229926, acc 0.953125\n",
      "2018-05-04T20:36:28.342809: step 23165, loss 0.166871, acc 0.921875\n",
      "2018-05-04T20:36:29.393757: step 23166, loss 0.207771, acc 0.90625\n",
      "2018-05-04T20:36:30.432951: step 23167, loss 0.254064, acc 0.921875\n",
      "2018-05-04T20:36:31.520713: step 23168, loss 0.121663, acc 0.96875\n",
      "2018-05-04T20:36:32.571424: step 23169, loss 0.2609, acc 0.875\n",
      "2018-05-04T20:36:33.671671: step 23170, loss 0.29141, acc 0.84375\n",
      "2018-05-04T20:36:34.704540: step 23171, loss 0.447846, acc 0.8125\n",
      "2018-05-04T20:36:35.950741: step 23172, loss 0.115976, acc 0.96875\n",
      "2018-05-04T20:36:37.129604: step 23173, loss 0.198339, acc 0.921875\n",
      "2018-05-04T20:36:38.339460: step 23174, loss 0.432734, acc 0.796875\n",
      "2018-05-04T20:36:39.480670: step 23175, loss 0.203605, acc 0.921875\n",
      "2018-05-04T20:36:40.667948: step 23176, loss 0.157284, acc 0.9375\n",
      "2018-05-04T20:36:41.920573: step 23177, loss 0.21057, acc 0.90625\n",
      "2018-05-04T20:36:43.173292: step 23178, loss 0.198003, acc 0.921875\n",
      "2018-05-04T20:36:44.273709: step 23179, loss 0.308734, acc 0.890625\n",
      "2018-05-04T20:36:45.327076: step 23180, loss 0.200131, acc 0.890625\n",
      "2018-05-04T20:36:46.370383: step 23181, loss 0.367261, acc 0.8125\n",
      "2018-05-04T20:36:47.480229: step 23182, loss 0.272588, acc 0.890625\n",
      "2018-05-04T20:36:48.534922: step 23183, loss 0.225282, acc 0.9375\n",
      "2018-05-04T20:36:49.596855: step 23184, loss 0.182259, acc 0.890625\n",
      "2018-05-04T20:36:50.684132: step 23185, loss 0.232458, acc 0.890625\n",
      "2018-05-04T20:36:51.838373: step 23186, loss 0.274278, acc 0.9375\n",
      "2018-05-04T20:36:52.922996: step 23187, loss 0.190498, acc 0.921875\n",
      "2018-05-04T20:36:53.981602: step 23188, loss 0.504035, acc 0.859375\n",
      "2018-05-04T20:36:55.073437: step 23189, loss 0.276875, acc 0.84375\n",
      "2018-05-04T20:36:56.144031: step 23190, loss 0.226994, acc 0.890625\n",
      "2018-05-04T20:36:57.230652: step 23191, loss 0.217258, acc 0.90625\n",
      "2018-05-04T20:36:58.359124: step 23192, loss 0.313174, acc 0.9375\n",
      "2018-05-04T20:36:59.568307: step 23193, loss 0.264098, acc 0.875\n",
      "2018-05-04T20:37:00.622870: step 23194, loss 0.283244, acc 0.890625\n",
      "2018-05-04T20:37:01.772090: step 23195, loss 0.312681, acc 0.828125\n",
      "2018-05-04T20:37:02.950882: step 23196, loss 0.406424, acc 0.84375\n",
      "2018-05-04T20:37:04.044399: step 23197, loss 0.209719, acc 0.890625\n",
      "2018-05-04T20:37:05.342571: step 23198, loss 0.203352, acc 0.875\n",
      "2018-05-04T20:37:06.544263: step 23199, loss 0.303725, acc 0.90625\n",
      "2018-05-04T20:37:07.606029: step 23200, loss 0.412408, acc 0.796875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T20:37:11.187159: step 23200, loss 0.212783, acc 0.932\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-23200\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T20:37:12.361909: step 23201, loss 0.23282, acc 0.921875\n",
      "2018-05-04T20:37:13.444885: step 23202, loss 0.203697, acc 0.90625\n",
      "2018-05-04T20:37:14.635522: step 23203, loss 0.291794, acc 0.859375\n",
      "2018-05-04T20:37:15.799579: step 23204, loss 0.287546, acc 0.84375\n",
      "2018-05-04T20:37:17.016369: step 23205, loss 0.305354, acc 0.859375\n",
      "2018-05-04T20:37:18.108671: step 23206, loss 0.263436, acc 0.859375\n",
      "2018-05-04T20:37:19.309701: step 23207, loss 0.226844, acc 0.875\n",
      "2018-05-04T20:37:20.486220: step 23208, loss 0.319272, acc 0.828125\n",
      "2018-05-04T20:37:21.680089: step 23209, loss 0.164117, acc 0.953125\n",
      "2018-05-04T20:37:22.909936: step 23210, loss 0.34664, acc 0.875\n",
      "2018-05-04T20:37:24.039225: step 23211, loss 0.129021, acc 0.953125\n",
      "2018-05-04T20:37:25.102457: step 23212, loss 0.141318, acc 0.953125\n",
      "2018-05-04T20:37:26.254270: step 23213, loss 0.299793, acc 0.859375\n",
      "2018-05-04T20:37:27.274255: step 23214, loss 0.210046, acc 0.875\n",
      "2018-05-04T20:37:28.377323: step 23215, loss 0.434354, acc 0.8125\n",
      "2018-05-04T20:37:29.384078: step 23216, loss 0.270899, acc 0.90625\n",
      "2018-05-04T20:37:30.422665: step 23217, loss 0.226074, acc 0.859375\n",
      "2018-05-04T20:37:31.567254: step 23218, loss 0.412683, acc 0.828125\n",
      "2018-05-04T20:37:32.637045: step 23219, loss 0.359357, acc 0.859375\n",
      "2018-05-04T20:37:33.904511: step 23220, loss 0.0784609, acc 0.96875\n",
      "2018-05-04T20:37:35.000482: step 23221, loss 0.329663, acc 0.859375\n",
      "2018-05-04T20:37:36.087571: step 23222, loss 0.263018, acc 0.875\n",
      "2018-05-04T20:37:37.436241: step 23223, loss 0.247365, acc 0.875\n",
      "2018-05-04T20:37:38.637854: step 23224, loss 0.195883, acc 0.921875\n",
      "2018-05-04T20:37:39.801884: step 23225, loss 0.34199, acc 0.90625\n",
      "2018-05-04T20:37:40.821394: step 23226, loss 0.27682, acc 0.921875\n",
      "2018-05-04T20:37:41.877151: step 23227, loss 0.172309, acc 0.9375\n",
      "2018-05-04T20:37:42.997734: step 23228, loss 0.462638, acc 0.828125\n",
      "2018-05-04T20:37:44.069074: step 23229, loss 0.199202, acc 0.90625\n",
      "2018-05-04T20:37:45.273987: step 23230, loss 0.382909, acc 0.859375\n",
      "2018-05-04T20:37:46.470181: step 23231, loss 0.189824, acc 0.90625\n",
      "2018-05-04T20:37:47.640809: step 23232, loss 0.306953, acc 0.875\n",
      "2018-05-04T20:37:48.821422: step 23233, loss 0.281859, acc 0.890625\n",
      "2018-05-04T20:37:49.888081: step 23234, loss 0.311789, acc 0.890625\n",
      "2018-05-04T20:37:51.042924: step 23235, loss 0.228664, acc 0.90625\n",
      "2018-05-04T20:37:52.267426: step 23236, loss 0.225829, acc 0.890625\n",
      "2018-05-04T20:37:53.476381: step 23237, loss 0.156888, acc 0.921875\n",
      "2018-05-04T20:37:54.671571: step 23238, loss 0.136762, acc 0.953125\n",
      "2018-05-04T20:37:55.854824: step 23239, loss 0.297345, acc 0.90625\n",
      "2018-05-04T20:37:56.923997: step 23240, loss 0.274237, acc 0.921875\n",
      "2018-05-04T20:37:57.956544: step 23241, loss 0.244746, acc 0.90625\n",
      "2018-05-04T20:37:59.041134: step 23242, loss 0.291687, acc 0.890625\n",
      "2018-05-04T20:38:00.123838: step 23243, loss 0.308788, acc 0.859375\n",
      "2018-05-04T20:38:01.326570: step 23244, loss 0.202569, acc 0.953125\n",
      "2018-05-04T20:38:02.367245: step 23245, loss 0.250925, acc 0.90625\n",
      "2018-05-04T20:38:03.404698: step 23246, loss 0.321428, acc 0.859375\n",
      "2018-05-04T20:38:04.452029: step 23247, loss 0.396904, acc 0.859375\n",
      "2018-05-04T20:38:05.469176: step 23248, loss 0.286929, acc 0.8125\n",
      "2018-05-04T20:38:06.499824: step 23249, loss 0.200897, acc 0.90625\n",
      "2018-05-04T20:38:07.588019: step 23250, loss 0.20367, acc 0.953125\n",
      "2018-05-04T20:38:08.777748: step 23251, loss 0.226851, acc 0.921875\n",
      "2018-05-04T20:38:09.816531: step 23252, loss 0.299631, acc 0.921875\n",
      "2018-05-04T20:38:10.851928: step 23253, loss 0.326728, acc 0.90625\n",
      "2018-05-04T20:38:11.911816: step 23254, loss 0.22046, acc 0.890625\n",
      "2018-05-04T20:38:12.923626: step 23255, loss 0.19781, acc 0.921875\n",
      "2018-05-04T20:38:13.968595: step 23256, loss 0.344119, acc 0.875\n",
      "2018-05-04T20:38:15.071043: step 23257, loss 0.204261, acc 0.90625\n",
      "2018-05-04T20:38:16.113284: step 23258, loss 0.222334, acc 0.921875\n",
      "2018-05-04T20:38:17.288131: step 23259, loss 0.281324, acc 0.84375\n",
      "2018-05-04T20:38:18.382716: step 23260, loss 0.301685, acc 0.890625\n",
      "2018-05-04T20:38:19.477908: step 23261, loss 0.284691, acc 0.890625\n",
      "2018-05-04T20:38:20.651536: step 23262, loss 0.346005, acc 0.890625\n",
      "2018-05-04T20:38:21.876083: step 23263, loss 0.302977, acc 0.921875\n",
      "2018-05-04T20:38:23.091646: step 23264, loss 0.238937, acc 0.859375\n",
      "2018-05-04T20:38:24.298046: step 23265, loss 0.193052, acc 0.953125\n",
      "2018-05-04T20:38:25.408428: step 23266, loss 0.257094, acc 0.921875\n",
      "2018-05-04T20:38:26.535729: step 23267, loss 0.205998, acc 0.9375\n",
      "2018-05-04T20:38:27.758747: step 23268, loss 0.289813, acc 0.859375\n",
      "2018-05-04T20:38:28.974100: step 23269, loss 0.226929, acc 0.90625\n",
      "2018-05-04T20:38:30.076825: step 23270, loss 0.312148, acc 0.90625\n",
      "2018-05-04T20:38:31.149454: step 23271, loss 0.220186, acc 0.90625\n",
      "2018-05-04T20:38:32.319467: step 23272, loss 0.196872, acc 0.921875\n",
      "2018-05-04T20:38:33.457500: step 23273, loss 0.243056, acc 0.890625\n",
      "2018-05-04T20:38:34.552427: step 23274, loss 0.302364, acc 0.875\n",
      "2018-05-04T20:38:35.744680: step 23275, loss 0.26862, acc 0.875\n",
      "2018-05-04T20:38:36.984487: step 23276, loss 0.163712, acc 0.9375\n",
      "2018-05-04T20:38:38.169256: step 23277, loss 0.281836, acc 0.90625\n",
      "2018-05-04T20:38:39.229086: step 23278, loss 0.23377, acc 0.90625\n",
      "2018-05-04T20:38:40.313643: step 23279, loss 0.210511, acc 0.9375\n",
      "2018-05-04T20:38:41.472367: step 23280, loss 0.174522, acc 0.90625\n",
      "2018-05-04T20:38:42.521525: step 23281, loss 0.227739, acc 0.890625\n",
      "2018-05-04T20:38:43.554194: step 23282, loss 0.227287, acc 0.90625\n",
      "2018-05-04T20:38:44.621453: step 23283, loss 0.141936, acc 0.96875\n",
      "2018-05-04T20:38:45.718446: step 23284, loss 0.280004, acc 0.875\n",
      "2018-05-04T20:38:46.868973: step 23285, loss 0.222019, acc 0.875\n",
      "2018-05-04T20:38:47.942317: step 23286, loss 0.244095, acc 0.90625\n",
      "2018-05-04T20:38:49.052286: step 23287, loss 0.156554, acc 0.953125\n",
      "2018-05-04T20:38:50.108063: step 23288, loss 0.233155, acc 0.90625\n",
      "2018-05-04T20:38:51.222808: step 23289, loss 0.0733553, acc 1\n",
      "2018-05-04T20:38:52.371301: step 23290, loss 0.357639, acc 0.84375\n",
      "2018-05-04T20:38:53.472900: step 23291, loss 0.19797, acc 0.9375\n",
      "2018-05-04T20:38:54.589456: step 23292, loss 0.161961, acc 0.9375\n",
      "2018-05-04T20:38:55.633723: step 23293, loss 0.241564, acc 0.921875\n",
      "2018-05-04T20:38:56.643872: step 23294, loss 0.297431, acc 0.90625\n",
      "2018-05-04T20:38:57.662999: step 23295, loss 0.33376, acc 0.859375\n",
      "2018-05-04T20:38:58.681071: step 23296, loss 0.206034, acc 0.953125\n",
      "2018-05-04T20:38:59.750187: step 23297, loss 0.229321, acc 0.9375\n",
      "2018-05-04T20:39:00.936215: step 23298, loss 0.281735, acc 0.90625\n",
      "2018-05-04T20:39:02.193351: step 23299, loss 0.258178, acc 0.90625\n",
      "2018-05-04T20:39:03.400778: step 23300, loss 0.232532, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T20:39:07.307683: step 23300, loss 0.219193, acc 0.92\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-23300\n",
      "\n",
      "2018-05-04T20:39:08.562111: step 23301, loss 0.3468, acc 0.859375\n",
      "2018-05-04T20:39:09.878392: step 23302, loss 0.22912, acc 0.890625\n",
      "2018-05-04T20:39:11.256855: step 23303, loss 0.208894, acc 0.90625\n",
      "2018-05-04T20:39:12.549608: step 23304, loss 0.152631, acc 0.921875\n",
      "2018-05-04T20:39:13.754311: step 23305, loss 0.197292, acc 0.921875\n",
      "2018-05-04T20:39:14.926228: step 23306, loss 0.332636, acc 0.84375\n",
      "2018-05-04T20:39:16.068339: step 23307, loss 0.225635, acc 0.90625\n",
      "2018-05-04T20:39:17.267583: step 23308, loss 0.464827, acc 0.828125\n",
      "2018-05-04T20:39:18.432193: step 23309, loss 0.379124, acc 0.78125\n",
      "2018-05-04T20:39:19.645594: step 23310, loss 0.126608, acc 0.953125\n",
      "2018-05-04T20:39:20.746670: step 23311, loss 0.240586, acc 0.875\n",
      "2018-05-04T20:39:22.126558: step 23312, loss 0.2345, acc 0.90625\n",
      "2018-05-04T20:39:23.346410: step 23313, loss 0.216854, acc 0.921875\n",
      "2018-05-04T20:39:24.557641: step 23314, loss 0.222808, acc 0.921875\n",
      "2018-05-04T20:39:25.743327: step 23315, loss 0.271141, acc 0.875\n",
      "2018-05-04T20:39:26.932396: step 23316, loss 0.294838, acc 0.859375\n",
      "2018-05-04T20:39:28.162999: step 23317, loss 0.143613, acc 0.953125\n",
      "2018-05-04T20:39:29.350742: step 23318, loss 0.28665, acc 0.84375\n",
      "2018-05-04T20:39:30.472957: step 23319, loss 0.153097, acc 0.9375\n",
      "2018-05-04T20:39:31.776113: step 23320, loss 0.218031, acc 0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T20:39:33.016209: step 23321, loss 0.237393, acc 0.890625\n",
      "2018-05-04T20:39:34.222542: step 23322, loss 0.370021, acc 0.828125\n",
      "2018-05-04T20:39:35.387700: step 23323, loss 0.280998, acc 0.890625\n",
      "2018-05-04T20:39:36.638723: step 23324, loss 0.351573, acc 0.828125\n",
      "2018-05-04T20:39:37.892472: step 23325, loss 0.181791, acc 0.9375\n",
      "2018-05-04T20:39:39.014001: step 23326, loss 0.239123, acc 0.890625\n",
      "2018-05-04T20:39:40.138802: step 23327, loss 0.271157, acc 0.859375\n",
      "2018-05-04T20:39:41.379833: step 23328, loss 0.214725, acc 0.890625\n",
      "2018-05-04T20:39:42.605648: step 23329, loss 0.160558, acc 0.9375\n",
      "2018-05-04T20:39:43.951066: step 23330, loss 0.228636, acc 0.921875\n",
      "2018-05-04T20:39:45.208475: step 23331, loss 0.220689, acc 0.859375\n",
      "2018-05-04T20:39:46.461462: step 23332, loss 0.14288, acc 0.96875\n",
      "2018-05-04T20:39:47.625414: step 23333, loss 0.150662, acc 0.953125\n",
      "2018-05-04T20:39:48.768687: step 23334, loss 0.293604, acc 0.90625\n",
      "2018-05-04T20:39:49.884063: step 23335, loss 0.269758, acc 0.84375\n",
      "2018-05-04T20:39:51.071985: step 23336, loss 0.315616, acc 0.890625\n",
      "2018-05-04T20:39:52.206905: step 23337, loss 0.175807, acc 0.9375\n",
      "2018-05-04T20:39:53.365525: step 23338, loss 0.322737, acc 0.890625\n",
      "2018-05-04T20:39:54.533697: step 23339, loss 0.207742, acc 0.921875\n",
      "2018-05-04T20:39:55.656290: step 23340, loss 0.224301, acc 0.921875\n",
      "2018-05-04T20:39:56.737960: step 23341, loss 0.219416, acc 0.921875\n",
      "2018-05-04T20:39:57.814483: step 23342, loss 0.373628, acc 0.84375\n",
      "2018-05-04T20:39:58.908539: step 23343, loss 0.295384, acc 0.890625\n",
      "2018-05-04T20:40:00.079914: step 23344, loss 0.368921, acc 0.859375\n",
      "2018-05-04T20:40:01.224232: step 23345, loss 0.165092, acc 0.90625\n",
      "2018-05-04T20:40:02.381747: step 23346, loss 0.291642, acc 0.890625\n",
      "2018-05-04T20:40:03.596496: step 23347, loss 0.1844, acc 0.90625\n",
      "2018-05-04T20:40:04.773620: step 23348, loss 0.209225, acc 0.9375\n",
      "2018-05-04T20:40:05.932559: step 23349, loss 0.227181, acc 0.90625\n",
      "2018-05-04T20:40:07.063954: step 23350, loss 0.366631, acc 0.84375\n",
      "2018-05-04T20:40:08.221207: step 23351, loss 0.330762, acc 0.890625\n",
      "2018-05-04T20:40:09.348353: step 23352, loss 0.197993, acc 0.921875\n",
      "2018-05-04T20:40:10.439478: step 23353, loss 0.168113, acc 0.890625\n",
      "2018-05-04T20:40:11.639528: step 23354, loss 0.234938, acc 0.859375\n",
      "2018-05-04T20:40:12.889057: step 23355, loss 0.346259, acc 0.84375\n",
      "2018-05-04T20:40:14.115908: step 23356, loss 0.282656, acc 0.859375\n",
      "2018-05-04T20:40:15.322407: step 23357, loss 0.218316, acc 0.9375\n",
      "2018-05-04T20:40:16.461196: step 23358, loss 0.242564, acc 0.953125\n",
      "2018-05-04T20:40:17.608776: step 23359, loss 0.205401, acc 0.921875\n",
      "2018-05-04T20:40:18.783868: step 23360, loss 0.398002, acc 0.859375\n",
      "2018-05-04T20:40:19.904935: step 23361, loss 0.280566, acc 0.84375\n",
      "2018-05-04T20:40:21.045649: step 23362, loss 0.222825, acc 0.921875\n",
      "2018-05-04T20:40:22.355208: step 23363, loss 0.483572, acc 0.875\n",
      "2018-05-04T20:40:23.521659: step 23364, loss 0.17494, acc 0.921875\n",
      "2018-05-04T20:40:24.658319: step 23365, loss 0.299988, acc 0.90625\n",
      "2018-05-04T20:40:25.766043: step 23366, loss 0.26527, acc 0.890625\n",
      "2018-05-04T20:40:26.923273: step 23367, loss 0.245224, acc 0.90625\n",
      "2018-05-04T20:40:28.051227: step 23368, loss 0.213273, acc 0.90625\n",
      "2018-05-04T20:40:29.097469: step 23369, loss 0.345833, acc 0.859375\n",
      "2018-05-04T20:40:30.162145: step 23370, loss 0.240454, acc 0.921875\n",
      "2018-05-04T20:40:31.304544: step 23371, loss 0.404868, acc 0.78125\n",
      "2018-05-04T20:40:32.511750: step 23372, loss 0.201234, acc 0.921875\n",
      "2018-05-04T20:40:33.749808: step 23373, loss 0.203878, acc 0.921875\n",
      "2018-05-04T20:40:34.935551: step 23374, loss 0.198656, acc 0.890625\n",
      "2018-05-04T20:40:36.144730: step 23375, loss 0.1777, acc 0.921875\n",
      "2018-05-04T20:40:37.447817: step 23376, loss 0.192013, acc 0.9375\n",
      "2018-05-04T20:40:38.659124: step 23377, loss 0.279359, acc 0.890625\n",
      "2018-05-04T20:40:39.848406: step 23378, loss 0.266014, acc 0.921875\n",
      "2018-05-04T20:40:41.000074: step 23379, loss 0.313782, acc 0.828125\n",
      "2018-05-04T20:40:42.317393: step 23380, loss 0.196335, acc 0.90625\n",
      "2018-05-04T20:40:43.456179: step 23381, loss 0.342072, acc 0.875\n",
      "2018-05-04T20:40:44.570270: step 23382, loss 0.223318, acc 0.890625\n",
      "2018-05-04T20:40:45.725863: step 23383, loss 0.153256, acc 0.9375\n",
      "2018-05-04T20:40:47.137212: step 23384, loss 0.215704, acc 0.9375\n",
      "2018-05-04T20:40:48.550957: step 23385, loss 0.333293, acc 0.84375\n",
      "2018-05-04T20:40:50.159604: step 23386, loss 0.214268, acc 0.90625\n",
      "2018-05-04T20:40:51.515036: step 23387, loss 0.20081, acc 0.90625\n",
      "2018-05-04T20:40:52.902710: step 23388, loss 0.228921, acc 0.90625\n",
      "2018-05-04T20:40:54.218528: step 23389, loss 0.219601, acc 0.890625\n",
      "2018-05-04T20:40:55.400971: step 23390, loss 0.264229, acc 0.90625\n",
      "2018-05-04T20:40:56.572439: step 23391, loss 0.220439, acc 0.859375\n",
      "2018-05-04T20:40:57.746221: step 23392, loss 0.434802, acc 0.828125\n",
      "2018-05-04T20:40:58.910602: step 23393, loss 0.14759, acc 0.953125\n",
      "2018-05-04T20:41:00.235008: step 23394, loss 0.283662, acc 0.859375\n",
      "2018-05-04T20:41:01.529245: step 23395, loss 0.364474, acc 0.90625\n",
      "2018-05-04T20:41:02.797526: step 23396, loss 0.128181, acc 0.953125\n",
      "2018-05-04T20:41:04.324460: step 23397, loss 0.280191, acc 0.84375\n",
      "2018-05-04T20:41:05.809378: step 23398, loss 0.22852, acc 0.90625\n",
      "2018-05-04T20:41:07.170994: step 23399, loss 0.233446, acc 0.90625\n",
      "2018-05-04T20:41:08.597832: step 23400, loss 0.23553, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T20:41:13.463802: step 23400, loss 0.220335, acc 0.928\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-23400\n",
      "\n",
      "2018-05-04T20:41:15.180594: step 23401, loss 0.191572, acc 0.921875\n",
      "2018-05-04T20:41:16.591422: step 23402, loss 0.236023, acc 0.859375\n",
      "2018-05-04T20:41:18.146428: step 23403, loss 0.217055, acc 0.875\n",
      "2018-05-04T20:41:19.680094: step 23404, loss 0.255308, acc 0.875\n",
      "2018-05-04T20:41:21.193555: step 23405, loss 0.369762, acc 0.84375\n",
      "2018-05-04T20:41:22.829413: step 23406, loss 0.283931, acc 0.90625\n",
      "2018-05-04T20:41:24.318746: step 23407, loss 0.15362, acc 0.9375\n",
      "2018-05-04T20:41:25.808464: step 23408, loss 0.320376, acc 0.890625\n",
      "2018-05-04T20:41:27.153800: step 23409, loss 0.438162, acc 0.828125\n",
      "2018-05-04T20:41:28.367802: step 23410, loss 0.340471, acc 0.859375\n",
      "2018-05-04T20:41:29.539402: step 23411, loss 0.182191, acc 0.953125\n",
      "2018-05-04T20:41:30.686929: step 23412, loss 0.270106, acc 0.875\n",
      "2018-05-04T20:41:32.083151: step 23413, loss 0.214403, acc 0.890625\n",
      "2018-05-04T20:41:33.477847: step 23414, loss 0.153941, acc 0.96875\n",
      "2018-05-04T20:41:34.788595: step 23415, loss 0.235622, acc 0.90625\n",
      "2018-05-04T20:41:36.016222: step 23416, loss 0.176761, acc 0.921875\n",
      "2018-05-04T20:41:37.370782: step 23417, loss 0.272025, acc 0.921875\n",
      "2018-05-04T20:41:38.689013: step 23418, loss 0.16041, acc 0.9375\n",
      "2018-05-04T20:41:40.072314: step 23419, loss 0.183627, acc 0.90625\n",
      "2018-05-04T20:41:41.424750: step 23420, loss 0.283754, acc 0.90625\n",
      "2018-05-04T20:41:42.744482: step 23421, loss 0.195916, acc 0.921875\n",
      "2018-05-04T20:41:44.032335: step 23422, loss 0.356613, acc 0.828125\n",
      "2018-05-04T20:41:45.425584: step 23423, loss 0.155813, acc 0.953125\n",
      "2018-05-04T20:41:46.854889: step 23424, loss 0.24142, acc 0.90625\n",
      "2018-05-04T20:41:48.146438: step 23425, loss 0.227838, acc 0.921875\n",
      "2018-05-04T20:41:49.473429: step 23426, loss 0.245074, acc 0.921875\n",
      "2018-05-04T20:41:50.705404: step 23427, loss 0.351278, acc 0.890625\n",
      "2018-05-04T20:41:51.970369: step 23428, loss 0.298039, acc 0.859375\n",
      "2018-05-04T20:41:53.402257: step 23429, loss 0.194641, acc 0.9375\n",
      "2018-05-04T20:41:54.602047: step 23430, loss 0.29084, acc 0.859375\n",
      "2018-05-04T20:41:55.813527: step 23431, loss 0.236143, acc 0.890625\n",
      "2018-05-04T20:41:57.020630: step 23432, loss 0.341872, acc 0.875\n",
      "2018-05-04T20:41:58.306620: step 23433, loss 0.210381, acc 0.9375\n",
      "2018-05-04T20:41:59.598022: step 23434, loss 0.222691, acc 0.921875\n",
      "2018-05-04T20:42:00.777614: step 23435, loss 0.260936, acc 0.921875\n",
      "2018-05-04T20:42:01.985714: step 23436, loss 0.288238, acc 0.859375\n",
      "2018-05-04T20:42:03.143146: step 23437, loss 0.366203, acc 0.828125\n",
      "2018-05-04T20:42:04.498649: step 23438, loss 0.257181, acc 0.890625\n",
      "2018-05-04T20:42:05.986240: step 23439, loss 0.139079, acc 0.984375\n",
      "2018-05-04T20:42:07.412165: step 23440, loss 0.224122, acc 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T20:42:08.702442: step 23441, loss 0.300772, acc 0.890625\n",
      "2018-05-04T20:42:10.269352: step 23442, loss 0.37768, acc 0.859375\n",
      "2018-05-04T20:42:11.651736: step 23443, loss 0.317707, acc 0.890625\n",
      "2018-05-04T20:42:13.058622: step 23444, loss 0.227079, acc 0.875\n",
      "2018-05-04T20:42:14.346281: step 23445, loss 0.268155, acc 0.859375\n",
      "2018-05-04T20:42:15.693561: step 23446, loss 0.276639, acc 0.859375\n",
      "2018-05-04T20:42:17.124160: step 23447, loss 0.375299, acc 0.875\n",
      "2018-05-04T20:42:18.376802: step 23448, loss 0.19296, acc 0.9375\n",
      "2018-05-04T20:42:19.632042: step 23449, loss 0.301237, acc 0.921875\n",
      "2018-05-04T20:42:21.176383: step 23450, loss 0.331489, acc 0.828125\n",
      "2018-05-04T20:42:22.521892: step 23451, loss 0.382782, acc 0.796875\n",
      "2018-05-04T20:42:23.737874: step 23452, loss 0.275611, acc 0.875\n",
      "2018-05-04T20:42:25.119072: step 23453, loss 0.223661, acc 0.9375\n",
      "2018-05-04T20:42:26.437280: step 23454, loss 0.265782, acc 0.90625\n",
      "2018-05-04T20:42:27.817449: step 23455, loss 0.196123, acc 0.96875\n",
      "2018-05-04T20:42:29.265681: step 23456, loss 0.204229, acc 0.90625\n",
      "2018-05-04T20:42:30.470341: step 23457, loss 0.288111, acc 0.875\n",
      "2018-05-04T20:42:31.686287: step 23458, loss 0.266681, acc 0.890625\n",
      "2018-05-04T20:42:32.761126: step 23459, loss 0.214216, acc 0.921875\n",
      "2018-05-04T20:42:33.966105: step 23460, loss 0.150477, acc 0.96875\n",
      "2018-05-04T20:42:35.187799: step 23461, loss 0.298318, acc 0.859375\n",
      "2018-05-04T20:42:36.280064: step 23462, loss 0.209535, acc 0.9375\n",
      "2018-05-04T20:42:37.522983: step 23463, loss 0.276741, acc 0.875\n",
      "2018-05-04T20:42:38.904021: step 23464, loss 0.154009, acc 0.921875\n",
      "2018-05-04T20:42:40.080317: step 23465, loss 0.199909, acc 0.90625\n",
      "2018-05-04T20:42:41.186802: step 23466, loss 0.197128, acc 0.921875\n",
      "2018-05-04T20:42:42.356580: step 23467, loss 0.239468, acc 0.890625\n",
      "2018-05-04T20:42:43.417923: step 23468, loss 0.262793, acc 0.875\n",
      "2018-05-04T20:42:44.468233: step 23469, loss 0.265348, acc 0.90625\n",
      "2018-05-04T20:42:45.507448: step 23470, loss 0.261911, acc 0.859375\n",
      "2018-05-04T20:42:46.578429: step 23471, loss 0.160577, acc 0.953125\n",
      "2018-05-04T20:42:47.712751: step 23472, loss 0.251699, acc 0.875\n",
      "2018-05-04T20:42:48.702681: step 23473, loss 0.17998, acc 0.90625\n",
      "2018-05-04T20:42:49.662191: step 23474, loss 0.21214, acc 0.90625\n",
      "2018-05-04T20:42:50.641533: step 23475, loss 0.21596, acc 0.90625\n",
      "2018-05-04T20:42:51.605055: step 23476, loss 0.217644, acc 0.921875\n",
      "2018-05-04T20:42:52.617245: step 23477, loss 0.265795, acc 0.859375\n",
      "2018-05-04T20:42:53.621606: step 23478, loss 0.315236, acc 0.859375\n",
      "2018-05-04T20:42:54.622328: step 23479, loss 0.146568, acc 0.921875\n",
      "2018-05-04T20:42:55.610571: step 23480, loss 0.208564, acc 0.9375\n",
      "2018-05-04T20:42:56.668686: step 23481, loss 0.19848, acc 0.90625\n",
      "2018-05-04T20:42:57.624340: step 23482, loss 0.143951, acc 0.96875\n",
      "2018-05-04T20:42:58.582303: step 23483, loss 0.20103, acc 0.921875\n",
      "2018-05-04T20:42:59.575278: step 23484, loss 0.274451, acc 0.90625\n",
      "2018-05-04T20:43:00.567270: step 23485, loss 0.260887, acc 0.875\n",
      "2018-05-04T20:43:01.521525: step 23486, loss 0.254591, acc 0.859375\n",
      "2018-05-04T20:43:02.551805: step 23487, loss 0.331684, acc 0.875\n",
      "2018-05-04T20:43:03.612898: step 23488, loss 0.242841, acc 0.921875\n",
      "2018-05-04T20:43:04.740310: step 23489, loss 0.422248, acc 0.84375\n",
      "2018-05-04T20:43:05.892244: step 23490, loss 0.199238, acc 0.90625\n",
      "2018-05-04T20:43:06.915586: step 23491, loss 0.257657, acc 0.890625\n",
      "2018-05-04T20:43:07.906000: step 23492, loss 0.244823, acc 0.90625\n",
      "2018-05-04T20:43:08.880865: step 23493, loss 0.335839, acc 0.859375\n",
      "2018-05-04T20:43:09.889452: step 23494, loss 0.17712, acc 0.9375\n",
      "2018-05-04T20:43:10.857282: step 23495, loss 0.211119, acc 0.890625\n",
      "2018-05-04T20:43:11.874046: step 23496, loss 0.169433, acc 0.921875\n",
      "2018-05-04T20:43:12.860022: step 23497, loss 0.200939, acc 0.875\n",
      "2018-05-04T20:43:13.836484: step 23498, loss 0.38577, acc 0.84375\n",
      "2018-05-04T20:43:14.834282: step 23499, loss 0.256343, acc 0.859375\n",
      "2018-05-04T20:43:15.900279: step 23500, loss 0.362768, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T20:43:19.747000: step 23500, loss 0.205792, acc 0.932\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-23500\n",
      "\n",
      "2018-05-04T20:43:20.962795: step 23501, loss 0.32461, acc 0.9375\n",
      "2018-05-04T20:43:22.131073: step 23502, loss 0.279676, acc 0.90625\n",
      "2018-05-04T20:43:23.312591: step 23503, loss 0.248247, acc 0.90625\n",
      "2018-05-04T20:43:24.525037: step 23504, loss 0.147731, acc 0.96875\n",
      "2018-05-04T20:43:25.611915: step 23505, loss 0.329053, acc 0.890625\n",
      "2018-05-04T20:43:26.706827: step 23506, loss 0.471093, acc 0.828125\n",
      "2018-05-04T20:43:27.943241: step 23507, loss 0.174127, acc 0.9375\n",
      "2018-05-04T20:43:29.142745: step 23508, loss 0.25743, acc 0.875\n",
      "2018-05-04T20:43:30.314383: step 23509, loss 0.152974, acc 0.9375\n",
      "2018-05-04T20:43:31.425187: step 23510, loss 0.176245, acc 0.953125\n",
      "2018-05-04T20:43:32.618199: step 23511, loss 0.240647, acc 0.90625\n",
      "2018-05-04T20:43:33.834686: step 23512, loss 0.199214, acc 0.9375\n",
      "2018-05-04T20:43:34.994841: step 23513, loss 0.328456, acc 0.890625\n",
      "2018-05-04T20:43:36.131443: step 23514, loss 0.199431, acc 0.921875\n",
      "2018-05-04T20:43:37.212073: step 23515, loss 0.229402, acc 0.890625\n",
      "2018-05-04T20:43:38.351665: step 23516, loss 0.127058, acc 0.96875\n",
      "2018-05-04T20:43:39.513375: step 23517, loss 0.257194, acc 0.9375\n",
      "2018-05-04T20:43:40.602690: step 23518, loss 0.192778, acc 0.890625\n",
      "2018-05-04T20:43:41.666424: step 23519, loss 0.304994, acc 0.90625\n",
      "2018-05-04T20:43:42.841769: step 23520, loss 0.214407, acc 0.890625\n",
      "2018-05-04T20:43:43.994614: step 23521, loss 0.241429, acc 0.921875\n",
      "2018-05-04T20:43:45.142119: step 23522, loss 0.236753, acc 0.921875\n",
      "2018-05-04T20:43:46.261594: step 23523, loss 0.201424, acc 0.921875\n",
      "2018-05-04T20:43:47.306119: step 23524, loss 0.166402, acc 0.90625\n",
      "2018-05-04T20:43:48.446171: step 23525, loss 0.232376, acc 0.90625\n",
      "2018-05-04T20:43:49.680977: step 23526, loss 0.230956, acc 0.921875\n",
      "2018-05-04T20:43:50.696366: step 23527, loss 0.23017, acc 0.890625\n",
      "2018-05-04T20:43:51.782451: step 23528, loss 0.212248, acc 0.90625\n",
      "2018-05-04T20:43:52.893320: step 23529, loss 0.239914, acc 0.890625\n",
      "2018-05-04T20:43:53.986862: step 23530, loss 0.112386, acc 0.96875\n",
      "2018-05-04T20:43:55.110681: step 23531, loss 0.352023, acc 0.890625\n",
      "2018-05-04T20:43:56.191113: step 23532, loss 0.297469, acc 0.890625\n",
      "2018-05-04T20:43:57.199515: step 23533, loss 0.370055, acc 0.828125\n",
      "2018-05-04T20:43:58.275043: step 23534, loss 0.217888, acc 0.90625\n",
      "2018-05-04T20:43:59.442426: step 23535, loss 0.280648, acc 0.921875\n",
      "2018-05-04T20:44:00.566923: step 23536, loss 0.220387, acc 0.9375\n",
      "2018-05-04T20:44:01.751795: step 23537, loss 0.238219, acc 0.90625\n",
      "2018-05-04T20:44:02.996951: step 23538, loss 0.27055, acc 0.84375\n",
      "2018-05-04T20:44:04.180300: step 23539, loss 0.34579, acc 0.859375\n",
      "2018-05-04T20:44:05.333164: step 23540, loss 0.208393, acc 0.921875\n",
      "2018-05-04T20:44:06.327893: step 23541, loss 0.197024, acc 0.96875\n",
      "2018-05-04T20:44:07.395187: step 23542, loss 0.274078, acc 0.859375\n",
      "2018-05-04T20:44:08.391813: step 23543, loss 0.278915, acc 0.859375\n",
      "2018-05-04T20:44:09.566022: step 23544, loss 0.350852, acc 0.875\n",
      "2018-05-04T20:44:10.632697: step 23545, loss 0.219925, acc 0.90625\n",
      "2018-05-04T20:44:11.791900: step 23546, loss 0.292129, acc 0.890625\n",
      "2018-05-04T20:44:13.027637: step 23547, loss 0.187909, acc 0.9375\n",
      "2018-05-04T20:44:14.174963: step 23548, loss 0.253919, acc 0.859375\n",
      "2018-05-04T20:44:15.214854: step 23549, loss 0.216205, acc 0.90625\n",
      "2018-05-04T20:44:16.205719: step 23550, loss 0.311957, acc 0.921875\n",
      "2018-05-04T20:44:17.160594: step 23551, loss 0.270294, acc 0.90625\n",
      "2018-05-04T20:44:18.121759: step 23552, loss 0.372298, acc 0.8125\n",
      "2018-05-04T20:44:19.090509: step 23553, loss 0.248185, acc 0.921875\n",
      "2018-05-04T20:44:20.068836: step 23554, loss 0.401358, acc 0.8125\n",
      "2018-05-04T20:44:21.101481: step 23555, loss 0.196061, acc 0.875\n",
      "2018-05-04T20:44:22.147589: step 23556, loss 0.427552, acc 0.8125\n",
      "2018-05-04T20:44:23.188357: step 23557, loss 0.270855, acc 0.875\n",
      "2018-05-04T20:44:24.191414: step 23558, loss 0.179409, acc 0.90625\n",
      "2018-05-04T20:44:25.167209: step 23559, loss 0.314802, acc 0.90625\n",
      "2018-05-04T20:44:26.135207: step 23560, loss 0.197174, acc 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T20:44:27.133319: step 23561, loss 0.168127, acc 0.953125\n",
      "2018-05-04T20:44:28.186264: step 23562, loss 0.283952, acc 0.90625\n",
      "2018-05-04T20:44:29.264773: step 23563, loss 0.252569, acc 0.96875\n",
      "2018-05-04T20:44:30.417455: step 23564, loss 0.338352, acc 0.859375\n",
      "2018-05-04T20:44:31.461805: step 23565, loss 0.279855, acc 0.859375\n",
      "2018-05-04T20:44:32.514896: step 23566, loss 0.185745, acc 0.9375\n",
      "2018-05-04T20:44:33.514154: step 23567, loss 0.400721, acc 0.796875\n",
      "2018-05-04T20:44:34.521538: step 23568, loss 0.226521, acc 0.890625\n",
      "2018-05-04T20:44:35.593087: step 23569, loss 0.215649, acc 0.90625\n",
      "2018-05-04T20:44:36.612350: step 23570, loss 0.380264, acc 0.84375\n",
      "2018-05-04T20:44:37.714759: step 23571, loss 0.217978, acc 0.921875\n",
      "2018-05-04T20:44:39.059662: step 23572, loss 0.328048, acc 0.859375\n",
      "2018-05-04T20:44:40.255739: step 23573, loss 0.283688, acc 0.875\n",
      "2018-05-04T20:44:41.289052: step 23574, loss 0.208258, acc 0.890625\n",
      "2018-05-04T20:44:42.389533: step 23575, loss 0.248618, acc 0.859375\n",
      "2018-05-04T20:44:43.412817: step 23576, loss 0.308566, acc 0.84375\n",
      "2018-05-04T20:44:44.457554: step 23577, loss 0.378452, acc 0.921875\n",
      "2018-05-04T20:44:45.465286: step 23578, loss 0.19956, acc 0.9375\n",
      "2018-05-04T20:44:46.493552: step 23579, loss 0.247524, acc 0.90625\n",
      "2018-05-04T20:44:47.441967: step 23580, loss 0.287039, acc 0.90625\n",
      "2018-05-04T20:44:48.414296: step 23581, loss 0.304744, acc 0.90625\n",
      "2018-05-04T20:44:49.409435: step 23582, loss 0.226644, acc 0.921875\n",
      "2018-05-04T20:44:50.425616: step 23583, loss 0.146848, acc 0.96875\n",
      "2018-05-04T20:44:51.543279: step 23584, loss 0.128442, acc 0.953125\n",
      "2018-05-04T20:44:52.535895: step 23585, loss 0.446407, acc 0.78125\n",
      "2018-05-04T20:44:53.517779: step 23586, loss 0.244033, acc 0.890625\n",
      "2018-05-04T20:44:54.547227: step 23587, loss 0.293249, acc 0.890625\n",
      "2018-05-04T20:44:55.561504: step 23588, loss 0.287994, acc 0.875\n",
      "2018-05-04T20:44:56.550924: step 23589, loss 0.397414, acc 0.859375\n",
      "2018-05-04T20:44:57.566261: step 23590, loss 0.259009, acc 0.875\n",
      "2018-05-04T20:44:58.625809: step 23591, loss 0.491187, acc 0.84375\n",
      "2018-05-04T20:44:59.756323: step 23592, loss 0.370465, acc 0.859375\n",
      "2018-05-04T20:45:00.900184: step 23593, loss 0.196164, acc 0.9375\n",
      "2018-05-04T20:45:02.062723: step 23594, loss 0.297276, acc 0.90625\n",
      "2018-05-04T20:45:03.153470: step 23595, loss 0.257528, acc 0.890625\n",
      "2018-05-04T20:45:04.168242: step 23596, loss 0.209816, acc 0.921875\n",
      "2018-05-04T20:45:05.219693: step 23597, loss 0.286345, acc 0.84375\n",
      "2018-05-04T20:45:06.308911: step 23598, loss 0.242388, acc 0.90625\n",
      "2018-05-04T20:45:07.350662: step 23599, loss 0.228853, acc 0.890625\n",
      "2018-05-04T20:45:08.467186: step 23600, loss 0.347328, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T20:45:11.229302: step 23600, loss 0.249781, acc 0.91\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-23600\n",
      "\n",
      "2018-05-04T20:45:12.416997: step 23601, loss 0.314269, acc 0.84375\n",
      "2018-05-04T20:45:13.503536: step 23602, loss 0.333973, acc 0.859375\n",
      "2018-05-04T20:45:14.577339: step 23603, loss 0.287676, acc 0.890625\n",
      "2018-05-04T20:45:15.739110: step 23604, loss 0.174774, acc 0.953125\n",
      "2018-05-04T20:45:16.915594: step 23605, loss 0.254356, acc 0.875\n",
      "2018-05-04T20:45:18.099411: step 23606, loss 0.176652, acc 0.953125\n",
      "2018-05-04T20:45:19.281421: step 23607, loss 0.238162, acc 0.875\n",
      "2018-05-04T20:45:20.450076: step 23608, loss 0.179591, acc 0.953125\n",
      "2018-05-04T20:45:21.655830: step 23609, loss 0.213334, acc 0.875\n",
      "2018-05-04T20:45:22.916191: step 23610, loss 0.199372, acc 0.90625\n",
      "2018-05-04T20:45:24.164177: step 23611, loss 0.14732, acc 0.9375\n",
      "2018-05-04T20:45:25.301999: step 23612, loss 0.392948, acc 0.84375\n",
      "2018-05-04T20:45:26.461929: step 23613, loss 0.293713, acc 0.890625\n",
      "2018-05-04T20:45:27.488087: step 23614, loss 0.170715, acc 0.9375\n",
      "2018-05-04T20:45:28.614448: step 23615, loss 0.393753, acc 0.8125\n",
      "2018-05-04T20:45:29.761724: step 23616, loss 0.291174, acc 0.875\n",
      "2018-05-04T20:45:30.864687: step 23617, loss 0.256931, acc 0.90625\n",
      "2018-05-04T20:45:32.033164: step 23618, loss 0.135027, acc 0.9375\n",
      "2018-05-04T20:45:33.138562: step 23619, loss 0.309478, acc 0.90625\n",
      "2018-05-04T20:45:34.225891: step 23620, loss 0.177639, acc 0.921875\n",
      "2018-05-04T20:45:35.327574: step 23621, loss 0.26905, acc 0.890625\n",
      "2018-05-04T20:45:36.387148: step 23622, loss 0.207215, acc 0.921875\n",
      "2018-05-04T20:45:37.506860: step 23623, loss 0.146787, acc 0.96875\n",
      "2018-05-04T20:45:38.568136: step 23624, loss 0.389787, acc 0.828125\n",
      "2018-05-04T20:45:39.691105: step 23625, loss 0.243334, acc 0.90625\n",
      "2018-05-04T20:45:40.828043: step 23626, loss 0.375776, acc 0.859375\n",
      "2018-05-04T20:45:41.958166: step 23627, loss 0.351207, acc 0.828125\n",
      "2018-05-04T20:45:43.082881: step 23628, loss 0.352108, acc 0.78125\n",
      "2018-05-04T20:45:44.129116: step 23629, loss 0.269543, acc 0.890625\n",
      "2018-05-04T20:45:45.232642: step 23630, loss 0.250262, acc 0.921875\n",
      "2018-05-04T20:45:46.333474: step 23631, loss 0.18208, acc 0.9375\n",
      "2018-05-04T20:45:47.436241: step 23632, loss 0.35598, acc 0.84375\n",
      "2018-05-04T20:45:48.504316: step 23633, loss 0.368646, acc 0.875\n",
      "2018-05-04T20:45:49.567325: step 23634, loss 0.299858, acc 0.84375\n",
      "2018-05-04T20:45:50.606364: step 23635, loss 0.202915, acc 0.9375\n",
      "2018-05-04T20:45:51.890741: step 23636, loss 0.338978, acc 0.859375\n",
      "2018-05-04T20:45:52.972240: step 23637, loss 0.189611, acc 0.9375\n",
      "2018-05-04T20:45:54.169843: step 23638, loss 0.427911, acc 0.8125\n",
      "2018-05-04T20:45:55.299510: step 23639, loss 0.200096, acc 0.90625\n",
      "2018-05-04T20:45:56.434466: step 23640, loss 0.281826, acc 0.90625\n",
      "2018-05-04T20:45:57.557754: step 23641, loss 0.268579, acc 0.890625\n",
      "2018-05-04T20:45:58.665194: step 23642, loss 0.229731, acc 0.921875\n",
      "2018-05-04T20:45:59.731246: step 23643, loss 0.274882, acc 0.890625\n",
      "2018-05-04T20:46:00.812551: step 23644, loss 0.316675, acc 0.859375\n",
      "2018-05-04T20:46:01.936137: step 23645, loss 0.13286, acc 0.9375\n",
      "2018-05-04T20:46:03.012984: step 23646, loss 0.197225, acc 0.9375\n",
      "2018-05-04T20:46:04.060898: step 23647, loss 0.280518, acc 0.859375\n",
      "2018-05-04T20:46:05.183413: step 23648, loss 0.308615, acc 0.859375\n",
      "2018-05-04T20:46:06.388425: step 23649, loss 0.404147, acc 0.8125\n",
      "2018-05-04T20:46:07.708112: step 23650, loss 0.226155, acc 0.921875\n",
      "2018-05-04T20:46:08.756084: step 23651, loss 0.288757, acc 0.90625\n",
      "2018-05-04T20:46:09.755310: step 23652, loss 0.308071, acc 0.875\n",
      "2018-05-04T20:46:10.730988: step 23653, loss 0.217082, acc 0.90625\n",
      "2018-05-04T20:46:11.707751: step 23654, loss 0.274389, acc 0.828125\n",
      "2018-05-04T20:46:12.746170: step 23655, loss 0.188809, acc 0.90625\n",
      "2018-05-04T20:46:13.770985: step 23656, loss 0.332932, acc 0.875\n",
      "2018-05-04T20:46:14.805936: step 23657, loss 0.443194, acc 0.8125\n",
      "2018-05-04T20:46:15.824730: step 23658, loss 0.389205, acc 0.84375\n",
      "2018-05-04T20:46:16.848816: step 23659, loss 0.296723, acc 0.859375\n",
      "2018-05-04T20:46:17.863131: step 23660, loss 0.176767, acc 0.921875\n",
      "2018-05-04T20:46:18.889465: step 23661, loss 0.215498, acc 0.921875\n",
      "2018-05-04T20:46:19.972563: step 23662, loss 0.264866, acc 0.875\n",
      "2018-05-04T20:46:21.061342: step 23663, loss 0.282476, acc 0.90625\n",
      "2018-05-04T20:46:22.163986: step 23664, loss 0.150796, acc 0.953125\n",
      "2018-05-04T20:46:23.497617: step 23665, loss 0.182618, acc 0.953125\n",
      "2018-05-04T20:46:24.840183: step 23666, loss 0.335489, acc 0.890625\n",
      "2018-05-04T20:46:25.914653: step 23667, loss 0.22964, acc 0.90625\n",
      "2018-05-04T20:46:27.026220: step 23668, loss 0.244974, acc 0.890625\n",
      "2018-05-04T20:46:28.180653: step 23669, loss 0.35799, acc 0.84375\n",
      "2018-05-04T20:46:29.279511: step 23670, loss 0.253414, acc 0.90625\n",
      "2018-05-04T20:46:30.371314: step 23671, loss 0.244194, acc 0.875\n",
      "2018-05-04T20:46:31.490951: step 23672, loss 0.304318, acc 0.90625\n",
      "2018-05-04T20:46:32.618525: step 23673, loss 0.224672, acc 0.921875\n",
      "2018-05-04T20:46:33.697998: step 23674, loss 0.163847, acc 0.96875\n",
      "2018-05-04T20:46:34.785237: step 23675, loss 0.253942, acc 0.890625\n",
      "2018-05-04T20:46:35.958567: step 23676, loss 0.307986, acc 0.859375\n",
      "2018-05-04T20:46:37.083284: step 23677, loss 0.273737, acc 0.875\n",
      "2018-05-04T20:46:38.113777: step 23678, loss 0.221003, acc 0.90625\n",
      "2018-05-04T20:46:39.178453: step 23679, loss 0.229163, acc 0.90625\n",
      "2018-05-04T20:46:40.268965: step 23680, loss 0.291843, acc 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T20:46:41.377100: step 23681, loss 0.193752, acc 0.9375\n",
      "2018-05-04T20:46:42.738415: step 23682, loss 0.27812, acc 0.875\n",
      "2018-05-04T20:46:44.131626: step 23683, loss 0.258312, acc 0.875\n",
      "2018-05-04T20:46:45.510951: step 23684, loss 0.233562, acc 0.890625\n",
      "2018-05-04T20:46:46.833692: step 23685, loss 0.193547, acc 0.953125\n",
      "2018-05-04T20:46:48.121987: step 23686, loss 0.173828, acc 0.90625\n",
      "2018-05-04T20:46:49.294875: step 23687, loss 0.170029, acc 0.921875\n",
      "2018-05-04T20:46:50.466335: step 23688, loss 0.18452, acc 0.953125\n",
      "2018-05-04T20:46:51.671344: step 23689, loss 0.145954, acc 0.953125\n",
      "2018-05-04T20:46:52.935842: step 23690, loss 0.230162, acc 0.890625\n",
      "2018-05-04T20:46:54.198050: step 23691, loss 0.217103, acc 0.921875\n",
      "2018-05-04T20:46:55.382571: step 23692, loss 0.168681, acc 0.921875\n",
      "2018-05-04T20:46:56.585821: step 23693, loss 0.197794, acc 0.9375\n",
      "2018-05-04T20:46:57.695516: step 23694, loss 0.129525, acc 0.9375\n",
      "2018-05-04T20:46:58.790406: step 23695, loss 0.188451, acc 0.890625\n",
      "2018-05-04T20:46:59.981641: step 23696, loss 0.211447, acc 0.890625\n",
      "2018-05-04T20:47:01.021601: step 23697, loss 0.160029, acc 0.953125\n",
      "2018-05-04T20:47:02.086622: step 23698, loss 0.37399, acc 0.90625\n",
      "2018-05-04T20:47:03.111808: step 23699, loss 0.494158, acc 0.828125\n",
      "2018-05-04T20:47:04.193934: step 23700, loss 0.229518, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T20:47:07.645066: step 23700, loss 0.204764, acc 0.924\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-23700\n",
      "\n",
      "2018-05-04T20:47:08.903506: step 23701, loss 0.311797, acc 0.875\n",
      "2018-05-04T20:47:10.026946: step 23702, loss 0.236093, acc 0.90625\n",
      "2018-05-04T20:47:11.082168: step 23703, loss 0.156017, acc 0.921875\n",
      "2018-05-04T20:47:12.169976: step 23704, loss 0.208118, acc 0.9375\n",
      "2018-05-04T20:47:13.340159: step 23705, loss 0.216887, acc 0.921875\n",
      "2018-05-04T20:47:14.400862: step 23706, loss 0.212938, acc 0.90625\n",
      "2018-05-04T20:47:15.459751: step 23707, loss 0.235637, acc 0.90625\n",
      "2018-05-04T20:47:16.622244: step 23708, loss 0.237871, acc 0.90625\n",
      "2018-05-04T20:47:17.705962: step 23709, loss 0.1695, acc 0.921875\n",
      "2018-05-04T20:47:18.790082: step 23710, loss 0.139681, acc 0.953125\n",
      "2018-05-04T20:47:19.932020: step 23711, loss 0.269678, acc 0.890625\n",
      "2018-05-04T20:47:21.146543: step 23712, loss 0.136418, acc 0.953125\n",
      "2018-05-04T20:47:22.502147: step 23713, loss 0.201904, acc 0.875\n",
      "2018-05-04T20:47:23.743247: step 23714, loss 0.279714, acc 0.84375\n",
      "2018-05-04T20:47:24.802261: step 23715, loss 0.260976, acc 0.875\n",
      "2018-05-04T20:47:25.925266: step 23716, loss 0.299876, acc 0.890625\n",
      "2018-05-04T20:47:27.073045: step 23717, loss 0.18299, acc 0.9375\n",
      "2018-05-04T20:47:28.170759: step 23718, loss 0.353153, acc 0.828125\n",
      "2018-05-04T20:47:29.266541: step 23719, loss 0.15071, acc 0.921875\n",
      "2018-05-04T20:47:30.456883: step 23720, loss 0.284347, acc 0.953125\n",
      "2018-05-04T20:47:31.642779: step 23721, loss 0.224668, acc 0.890625\n",
      "2018-05-04T20:47:32.638904: step 23722, loss 0.358577, acc 0.90625\n",
      "2018-05-04T20:47:33.776894: step 23723, loss 0.324898, acc 0.875\n",
      "2018-05-04T20:47:34.903010: step 23724, loss 0.294709, acc 0.90625\n",
      "2018-05-04T20:47:36.004733: step 23725, loss 0.192489, acc 0.90625\n",
      "2018-05-04T20:47:37.026455: step 23726, loss 0.271469, acc 0.875\n",
      "2018-05-04T20:47:38.206412: step 23727, loss 0.166644, acc 0.953125\n",
      "2018-05-04T20:47:39.380709: step 23728, loss 0.309062, acc 0.921875\n",
      "2018-05-04T20:47:40.662865: step 23729, loss 0.459115, acc 0.84375\n",
      "2018-05-04T20:47:41.902755: step 23730, loss 0.174117, acc 0.90625\n",
      "2018-05-04T20:47:43.129638: step 23731, loss 0.233445, acc 0.875\n",
      "2018-05-04T20:47:44.249644: step 23732, loss 0.342878, acc 0.890625\n",
      "2018-05-04T20:47:45.290944: step 23733, loss 0.344252, acc 0.875\n",
      "2018-05-04T20:47:46.355306: step 23734, loss 0.189027, acc 0.953125\n",
      "2018-05-04T20:47:47.387511: step 23735, loss 0.225791, acc 0.921875\n",
      "2018-05-04T20:47:48.405782: step 23736, loss 0.240858, acc 0.921875\n",
      "2018-05-04T20:47:49.533742: step 23737, loss 0.340603, acc 0.84375\n",
      "2018-05-04T20:47:50.726917: step 23738, loss 0.15426, acc 0.953125\n",
      "2018-05-04T20:47:51.930201: step 23739, loss 0.359912, acc 0.859375\n",
      "2018-05-04T20:47:53.226477: step 23740, loss 0.267915, acc 0.890625\n",
      "2018-05-04T20:47:54.404392: step 23741, loss 0.208914, acc 0.90625\n",
      "2018-05-04T20:47:55.573211: step 23742, loss 0.350423, acc 0.84375\n",
      "2018-05-04T20:47:56.619156: step 23743, loss 0.30022, acc 0.890625\n",
      "2018-05-04T20:47:57.920065: step 23744, loss 0.215557, acc 0.90625\n",
      "2018-05-04T20:47:59.124342: step 23745, loss 0.177245, acc 0.9375\n",
      "2018-05-04T20:48:00.208560: step 23746, loss 0.282315, acc 0.875\n",
      "2018-05-04T20:48:01.375670: step 23747, loss 0.15704, acc 0.9375\n",
      "2018-05-04T20:48:02.589859: step 23748, loss 0.219179, acc 0.921875\n",
      "2018-05-04T20:48:03.743985: step 23749, loss 0.237274, acc 0.90625\n",
      "2018-05-04T20:48:04.872152: step 23750, loss 0.210948, acc 0.921875\n",
      "2018-05-04T20:48:06.068450: step 23751, loss 0.337356, acc 0.84375\n",
      "2018-05-04T20:48:07.259974: step 23752, loss 0.116289, acc 0.9375\n",
      "2018-05-04T20:48:08.456325: step 23753, loss 0.28508, acc 0.859375\n",
      "2018-05-04T20:48:09.596181: step 23754, loss 0.283027, acc 0.890625\n",
      "2018-05-04T20:48:10.697531: step 23755, loss 0.163006, acc 0.9375\n",
      "2018-05-04T20:48:11.995280: step 23756, loss 0.305371, acc 0.921875\n",
      "2018-05-04T20:48:13.077090: step 23757, loss 0.206061, acc 0.921875\n",
      "2018-05-04T20:48:14.210061: step 23758, loss 0.244703, acc 0.9375\n",
      "2018-05-04T20:48:15.323892: step 23759, loss 0.268777, acc 0.859375\n",
      "2018-05-04T20:48:16.366903: step 23760, loss 0.375418, acc 0.890625\n",
      "2018-05-04T20:48:17.402661: step 23761, loss 0.230561, acc 0.90625\n",
      "2018-05-04T20:48:18.455203: step 23762, loss 0.250113, acc 0.90625\n",
      "2018-05-04T20:48:19.581264: step 23763, loss 0.195312, acc 0.953125\n",
      "2018-05-04T20:48:20.664316: step 23764, loss 0.199956, acc 0.90625\n",
      "2018-05-04T20:48:21.920454: step 23765, loss 0.34376, acc 0.9375\n",
      "2018-05-04T20:48:23.081141: step 23766, loss 0.24802, acc 0.921875\n",
      "2018-05-04T20:48:24.251304: step 23767, loss 0.25146, acc 0.875\n",
      "2018-05-04T20:48:25.353991: step 23768, loss 0.128257, acc 0.953125\n",
      "2018-05-04T20:48:26.414624: step 23769, loss 0.259953, acc 0.859375\n",
      "2018-05-04T20:48:27.507415: step 23770, loss 0.223973, acc 0.890625\n",
      "2018-05-04T20:48:28.788097: step 23771, loss 0.286756, acc 0.875\n",
      "2018-05-04T20:48:29.986055: step 23772, loss 0.228929, acc 0.890625\n",
      "2018-05-04T20:48:31.197662: step 23773, loss 0.196446, acc 0.90625\n",
      "2018-05-04T20:48:32.290152: step 23774, loss 0.275365, acc 0.859375\n",
      "2018-05-04T20:48:33.417567: step 23775, loss 0.229998, acc 0.90625\n",
      "2018-05-04T20:48:34.607061: step 23776, loss 0.205777, acc 0.890625\n",
      "2018-05-04T20:48:35.703141: step 23777, loss 0.217156, acc 0.921875\n",
      "2018-05-04T20:48:36.897780: step 23778, loss 0.23489, acc 0.875\n",
      "2018-05-04T20:48:38.083341: step 23779, loss 0.363422, acc 0.84375\n",
      "2018-05-04T20:48:39.112759: step 23780, loss 0.23192, acc 0.953125\n",
      "2018-05-04T20:48:40.208077: step 23781, loss 0.330025, acc 0.875\n",
      "2018-05-04T20:48:41.412945: step 23782, loss 0.135561, acc 0.9375\n",
      "2018-05-04T20:48:42.534330: step 23783, loss 0.173839, acc 0.921875\n",
      "2018-05-04T20:48:43.691130: step 23784, loss 0.214306, acc 0.890625\n",
      "2018-05-04T20:48:44.848369: step 23785, loss 0.303408, acc 0.875\n",
      "2018-05-04T20:48:46.064194: step 23786, loss 0.195344, acc 0.90625\n",
      "2018-05-04T20:48:47.223007: step 23787, loss 0.150867, acc 0.921875\n",
      "2018-05-04T20:48:48.405875: step 23788, loss 0.181575, acc 0.90625\n",
      "2018-05-04T20:48:49.541219: step 23789, loss 0.354668, acc 0.84375\n",
      "2018-05-04T20:48:50.673763: step 23790, loss 0.127232, acc 0.9375\n",
      "2018-05-04T20:48:51.973443: step 23791, loss 0.371956, acc 0.8125\n",
      "2018-05-04T20:48:53.232666: step 23792, loss 0.140238, acc 0.953125\n",
      "2018-05-04T20:48:54.349608: step 23793, loss 0.209459, acc 0.90625\n",
      "2018-05-04T20:48:55.448301: step 23794, loss 0.268739, acc 0.84375\n",
      "2018-05-04T20:48:56.462306: step 23795, loss 0.187133, acc 0.90625\n",
      "2018-05-04T20:48:57.593074: step 23796, loss 0.259433, acc 0.90625\n",
      "2018-05-04T20:48:58.670783: step 23797, loss 0.278411, acc 0.90625\n",
      "2018-05-04T20:48:59.985505: step 23798, loss 0.141656, acc 0.96875\n",
      "2018-05-04T20:49:01.122251: step 23799, loss 0.12963, acc 0.96875\n",
      "2018-05-04T20:49:02.380468: step 23800, loss 0.217019, acc 0.90625\n",
      "\n",
      "Evaluation:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T20:49:05.494225: step 23800, loss 0.205794, acc 0.93\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-23800\n",
      "\n",
      "2018-05-04T20:49:06.803806: step 23801, loss 0.280376, acc 0.859375\n",
      "2018-05-04T20:49:08.016686: step 23802, loss 0.233544, acc 0.859375\n",
      "2018-05-04T20:49:09.207298: step 23803, loss 0.253962, acc 0.90625\n",
      "2018-05-04T20:49:10.402748: step 23804, loss 0.3842, acc 0.875\n",
      "2018-05-04T20:49:11.653867: step 23805, loss 0.391503, acc 0.859375\n",
      "2018-05-04T20:49:12.812913: step 23806, loss 0.228297, acc 0.921875\n",
      "2018-05-04T20:49:14.003345: step 23807, loss 0.307269, acc 0.859375\n",
      "2018-05-04T20:49:15.141621: step 23808, loss 0.292512, acc 0.875\n",
      "2018-05-04T20:49:16.294356: step 23809, loss 0.236538, acc 0.875\n",
      "2018-05-04T20:49:17.530454: step 23810, loss 0.27119, acc 0.84375\n",
      "2018-05-04T20:49:18.692158: step 23811, loss 0.251761, acc 0.90625\n",
      "2018-05-04T20:49:19.811266: step 23812, loss 0.263775, acc 0.90625\n",
      "2018-05-04T20:49:21.068784: step 23813, loss 0.201226, acc 0.90625\n",
      "2018-05-04T20:49:22.270038: step 23814, loss 0.295072, acc 0.859375\n",
      "2018-05-04T20:49:23.467349: step 23815, loss 0.200901, acc 0.9375\n",
      "2018-05-04T20:49:24.595637: step 23816, loss 0.410127, acc 0.84375\n",
      "2018-05-04T20:49:25.790551: step 23817, loss 0.301189, acc 0.890625\n",
      "2018-05-04T20:49:26.857238: step 23818, loss 0.554346, acc 0.796875\n",
      "2018-05-04T20:49:27.991684: step 23819, loss 0.367735, acc 0.875\n",
      "2018-05-04T20:49:29.280346: step 23820, loss 0.174007, acc 0.921875\n",
      "2018-05-04T20:49:30.628717: step 23821, loss 0.296648, acc 0.921875\n",
      "2018-05-04T20:49:31.880288: step 23822, loss 0.35076, acc 0.859375\n",
      "2018-05-04T20:49:33.124033: step 23823, loss 0.287604, acc 0.90625\n",
      "2018-05-04T20:49:34.364291: step 23824, loss 0.169141, acc 0.9375\n",
      "2018-05-04T20:49:35.608635: step 23825, loss 0.404157, acc 0.84375\n",
      "2018-05-04T20:49:36.775551: step 23826, loss 0.274351, acc 0.890625\n",
      "2018-05-04T20:49:37.918176: step 23827, loss 0.310526, acc 0.90625\n",
      "2018-05-04T20:49:38.966231: step 23828, loss 0.215714, acc 0.921875\n",
      "2018-05-04T20:49:40.065340: step 23829, loss 0.141692, acc 0.9375\n",
      "2018-05-04T20:49:41.105108: step 23830, loss 0.280152, acc 0.90625\n",
      "2018-05-04T20:49:42.217782: step 23831, loss 0.154363, acc 0.96875\n",
      "2018-05-04T20:49:43.624771: step 23832, loss 0.183243, acc 0.90625\n",
      "2018-05-04T20:49:44.985350: step 23833, loss 0.266128, acc 0.859375\n",
      "2018-05-04T20:49:46.230890: step 23834, loss 0.334489, acc 0.84375\n",
      "2018-05-04T20:49:47.436903: step 23835, loss 0.200201, acc 0.921875\n",
      "2018-05-04T20:49:48.558127: step 23836, loss 0.228397, acc 0.90625\n",
      "2018-05-04T20:49:49.739965: step 23837, loss 0.25177, acc 0.90625\n",
      "2018-05-04T20:49:50.818394: step 23838, loss 0.222095, acc 0.921875\n",
      "2018-05-04T20:49:51.919130: step 23839, loss 0.158426, acc 0.96875\n",
      "2018-05-04T20:49:53.062287: step 23840, loss 0.240362, acc 0.921875\n",
      "2018-05-04T20:49:54.236128: step 23841, loss 0.308027, acc 0.90625\n",
      "2018-05-04T20:49:55.393635: step 23842, loss 0.36218, acc 0.796875\n",
      "2018-05-04T20:49:56.621005: step 23843, loss 0.403149, acc 0.859375\n",
      "2018-05-04T20:49:57.722744: step 23844, loss 0.162188, acc 0.921875\n",
      "2018-05-04T20:49:58.890842: step 23845, loss 0.23985, acc 0.90625\n",
      "2018-05-04T20:50:00.112020: step 23846, loss 0.259423, acc 0.875\n",
      "2018-05-04T20:50:01.362353: step 23847, loss 0.244139, acc 0.9375\n",
      "2018-05-04T20:50:02.618196: step 23848, loss 0.205286, acc 0.9375\n",
      "2018-05-04T20:50:03.750565: step 23849, loss 0.192002, acc 0.9375\n",
      "2018-05-04T20:50:04.936261: step 23850, loss 0.17792, acc 0.953125\n",
      "2018-05-04T20:50:06.092230: step 23851, loss 0.184018, acc 0.9375\n",
      "2018-05-04T20:50:07.140438: step 23852, loss 0.196569, acc 0.921875\n",
      "2018-05-04T20:50:08.265364: step 23853, loss 0.261414, acc 0.90625\n",
      "2018-05-04T20:50:09.387996: step 23854, loss 0.221417, acc 0.921875\n",
      "2018-05-04T20:50:10.459670: step 23855, loss 0.244692, acc 0.90625\n",
      "2018-05-04T20:50:11.516156: step 23856, loss 0.298041, acc 0.875\n",
      "2018-05-04T20:50:12.595832: step 23857, loss 0.266683, acc 0.890625\n",
      "2018-05-04T20:50:13.853414: step 23858, loss 0.292833, acc 0.859375\n",
      "2018-05-04T20:50:15.082289: step 23859, loss 0.169118, acc 0.9375\n",
      "2018-05-04T20:50:16.286839: step 23860, loss 0.220829, acc 0.890625\n",
      "2018-05-04T20:50:17.438083: step 23861, loss 0.338579, acc 0.8125\n",
      "2018-05-04T20:50:18.654196: step 23862, loss 0.164261, acc 0.90625\n",
      "2018-05-04T20:50:19.859807: step 23863, loss 0.25338, acc 0.890625\n",
      "2018-05-04T20:50:21.017932: step 23864, loss 0.21094, acc 0.859375\n",
      "2018-05-04T20:50:22.276016: step 23865, loss 0.21794, acc 0.875\n",
      "2018-05-04T20:50:23.388354: step 23866, loss 0.169944, acc 0.921875\n",
      "2018-05-04T20:50:24.491591: step 23867, loss 0.264629, acc 0.875\n",
      "2018-05-04T20:50:25.627838: step 23868, loss 0.223017, acc 0.921875\n",
      "2018-05-04T20:50:26.777246: step 23869, loss 0.17026, acc 0.9375\n",
      "2018-05-04T20:50:27.990908: step 23870, loss 0.305697, acc 0.859375\n",
      "2018-05-04T20:50:29.229152: step 23871, loss 0.195661, acc 0.9375\n",
      "2018-05-04T20:50:30.327479: step 23872, loss 0.248529, acc 0.921875\n",
      "2018-05-04T20:50:31.490365: step 23873, loss 0.416515, acc 0.84375\n",
      "2018-05-04T20:50:32.774580: step 23874, loss 0.198342, acc 0.921875\n",
      "2018-05-04T20:50:33.949650: step 23875, loss 0.349061, acc 0.90625\n",
      "2018-05-04T20:50:35.066738: step 23876, loss 0.237117, acc 0.890625\n",
      "2018-05-04T20:50:36.280833: step 23877, loss 0.337797, acc 0.859375\n",
      "2018-05-04T20:50:37.494128: step 23878, loss 0.3064, acc 0.875\n",
      "2018-05-04T20:50:38.576058: step 23879, loss 0.494577, acc 0.8125\n",
      "2018-05-04T20:50:39.712581: step 23880, loss 0.291233, acc 0.84375\n",
      "2018-05-04T20:50:40.812255: step 23881, loss 0.187138, acc 0.890625\n",
      "2018-05-04T20:50:42.042186: step 23882, loss 0.359905, acc 0.84375\n",
      "2018-05-04T20:50:43.208129: step 23883, loss 0.124754, acc 0.953125\n",
      "2018-05-04T20:50:44.341172: step 23884, loss 0.22732, acc 0.890625\n",
      "2018-05-04T20:50:45.448573: step 23885, loss 0.351114, acc 0.859375\n",
      "2018-05-04T20:50:46.606262: step 23886, loss 0.220959, acc 0.90625\n",
      "2018-05-04T20:50:47.746546: step 23887, loss 0.242149, acc 0.890625\n",
      "2018-05-04T20:50:49.017707: step 23888, loss 0.199895, acc 0.890625\n",
      "2018-05-04T20:50:50.291758: step 23889, loss 0.190301, acc 0.9375\n",
      "2018-05-04T20:50:51.747908: step 23890, loss 0.214974, acc 0.921875\n",
      "2018-05-04T20:50:53.016303: step 23891, loss 0.315194, acc 0.921875\n",
      "2018-05-04T20:50:54.257437: step 23892, loss 0.177829, acc 0.9375\n",
      "2018-05-04T20:50:55.589657: step 23893, loss 0.240614, acc 0.890625\n",
      "2018-05-04T20:50:56.752519: step 23894, loss 0.240362, acc 0.90625\n",
      "2018-05-04T20:50:57.832029: step 23895, loss 0.178493, acc 0.96875\n",
      "2018-05-04T20:50:58.866694: step 23896, loss 0.270561, acc 0.890625\n",
      "2018-05-04T20:50:59.915369: step 23897, loss 0.183174, acc 0.90625\n",
      "2018-05-04T20:51:01.012758: step 23898, loss 0.439878, acc 0.828125\n",
      "2018-05-04T20:51:02.211508: step 23899, loss 0.208904, acc 0.90625\n",
      "2018-05-04T20:51:03.360671: step 23900, loss 0.354785, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T20:51:06.937287: step 23900, loss 0.211019, acc 0.928\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-23900\n",
      "\n",
      "2018-05-04T20:51:08.193654: step 23901, loss 0.217186, acc 0.921875\n",
      "2018-05-04T20:51:09.384391: step 23902, loss 0.292878, acc 0.90625\n",
      "2018-05-04T20:51:10.462586: step 23903, loss 0.238446, acc 0.90625\n",
      "2018-05-04T20:51:11.640753: step 23904, loss 0.258993, acc 0.9375\n",
      "2018-05-04T20:51:12.685575: step 23905, loss 0.233342, acc 0.921875\n",
      "2018-05-04T20:51:13.862321: step 23906, loss 0.312262, acc 0.84375\n",
      "2018-05-04T20:51:15.016784: step 23907, loss 0.162429, acc 0.953125\n",
      "2018-05-04T20:51:16.125200: step 23908, loss 0.338185, acc 0.828125\n",
      "2018-05-04T20:51:17.255478: step 23909, loss 0.198981, acc 0.953125\n",
      "2018-05-04T20:51:18.348632: step 23910, loss 0.274211, acc 0.921875\n",
      "2018-05-04T20:51:19.405956: step 23911, loss 0.325333, acc 0.875\n",
      "2018-05-04T20:51:20.569797: step 23912, loss 0.405083, acc 0.859375\n",
      "2018-05-04T20:51:21.710617: step 23913, loss 0.200652, acc 0.953125\n",
      "2018-05-04T20:51:22.902871: step 23914, loss 0.173379, acc 0.921875\n",
      "2018-05-04T20:51:23.932761: step 23915, loss 0.219215, acc 0.859375\n",
      "2018-05-04T20:51:24.959981: step 23916, loss 0.27274, acc 0.875\n",
      "2018-05-04T20:51:26.075062: step 23917, loss 0.309077, acc 0.875\n",
      "2018-05-04T20:51:27.272164: step 23918, loss 0.356246, acc 0.859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T20:51:28.492126: step 23919, loss 0.372601, acc 0.84375\n",
      "2018-05-04T20:51:29.937082: step 23920, loss 0.290745, acc 0.890625\n",
      "2018-05-04T20:51:31.228576: step 23921, loss 0.190285, acc 0.921875\n",
      "2018-05-04T20:51:32.424670: step 23922, loss 0.131287, acc 0.96875\n",
      "2018-05-04T20:51:33.608031: step 23923, loss 0.369705, acc 0.828125\n",
      "2018-05-04T20:51:34.814179: step 23924, loss 0.253938, acc 0.953125\n",
      "2018-05-04T20:51:35.884805: step 23925, loss 0.315359, acc 0.828125\n",
      "2018-05-04T20:51:36.932879: step 23926, loss 0.351787, acc 0.875\n",
      "2018-05-04T20:51:37.975792: step 23927, loss 0.266909, acc 0.890625\n",
      "2018-05-04T20:51:39.036019: step 23928, loss 0.293658, acc 0.921875\n",
      "2018-05-04T20:51:40.128557: step 23929, loss 0.264423, acc 0.9375\n",
      "2018-05-04T20:51:41.256838: step 23930, loss 0.350992, acc 0.890625\n",
      "2018-05-04T20:51:42.409464: step 23931, loss 0.16186, acc 0.953125\n",
      "2018-05-04T20:51:43.544812: step 23932, loss 0.190302, acc 0.90625\n",
      "2018-05-04T20:51:44.664999: step 23933, loss 0.318474, acc 0.875\n",
      "2018-05-04T20:51:45.941686: step 23934, loss 0.289253, acc 0.890625\n",
      "2018-05-04T20:51:47.291012: step 23935, loss 0.267676, acc 0.90625\n",
      "2018-05-04T20:51:48.485131: step 23936, loss 0.174494, acc 0.921875\n",
      "2018-05-04T20:51:49.714762: step 23937, loss 0.29806, acc 0.875\n",
      "2018-05-04T20:51:50.920865: step 23938, loss 0.314061, acc 0.875\n",
      "2018-05-04T20:51:52.177844: step 23939, loss 0.214599, acc 0.90625\n",
      "2018-05-04T20:51:53.353912: step 23940, loss 0.178296, acc 0.9375\n",
      "2018-05-04T20:51:54.545508: step 23941, loss 0.353611, acc 0.859375\n",
      "2018-05-04T20:51:55.709528: step 23942, loss 0.237507, acc 0.921875\n",
      "2018-05-04T20:51:56.840572: step 23943, loss 0.287955, acc 0.828125\n",
      "2018-05-04T20:51:57.940698: step 23944, loss 0.267597, acc 0.921875\n",
      "2018-05-04T20:51:59.053827: step 23945, loss 0.339986, acc 0.90625\n",
      "2018-05-04T20:52:00.100436: step 23946, loss 0.230984, acc 0.90625\n",
      "2018-05-04T20:52:01.215484: step 23947, loss 0.189278, acc 0.921875\n",
      "2018-05-04T20:52:02.369816: step 23948, loss 0.154993, acc 0.9375\n",
      "2018-05-04T20:52:03.511802: step 23949, loss 0.263404, acc 0.90625\n",
      "2018-05-04T20:52:04.726968: step 23950, loss 0.131575, acc 0.9375\n",
      "2018-05-04T20:52:05.894961: step 23951, loss 0.341153, acc 0.875\n",
      "2018-05-04T20:52:07.099404: step 23952, loss 0.355793, acc 0.828125\n",
      "2018-05-04T20:52:08.156197: step 23953, loss 0.280033, acc 0.859375\n",
      "2018-05-04T20:52:09.311358: step 23954, loss 0.295742, acc 0.90625\n",
      "2018-05-04T20:52:10.520185: step 23955, loss 0.176936, acc 0.9375\n",
      "2018-05-04T20:52:11.745004: step 23956, loss 0.182083, acc 0.921875\n",
      "2018-05-04T20:52:12.921821: step 23957, loss 0.190355, acc 0.921875\n",
      "2018-05-04T20:52:13.963637: step 23958, loss 0.146465, acc 0.9375\n",
      "2018-05-04T20:52:15.257030: step 23959, loss 0.243679, acc 0.921875\n",
      "2018-05-04T20:52:16.565605: step 23960, loss 0.128399, acc 0.9375\n",
      "2018-05-04T20:52:17.608903: step 23961, loss 0.179569, acc 0.9375\n",
      "2018-05-04T20:52:18.711762: step 23962, loss 0.255337, acc 0.9375\n",
      "2018-05-04T20:52:19.708417: step 23963, loss 0.165929, acc 0.921875\n",
      "2018-05-04T20:52:20.792606: step 23964, loss 0.236199, acc 0.890625\n",
      "2018-05-04T20:52:21.954267: step 23965, loss 0.255046, acc 0.859375\n",
      "2018-05-04T20:52:23.048257: step 23966, loss 0.27918, acc 0.875\n",
      "2018-05-04T20:52:24.157681: step 23967, loss 0.259907, acc 0.90625\n",
      "2018-05-04T20:52:25.141117: step 23968, loss 0.267721, acc 0.84375\n",
      "2018-05-04T20:52:26.136604: step 23969, loss 0.33749, acc 0.875\n",
      "2018-05-04T20:52:27.208526: step 23970, loss 0.218934, acc 0.9375\n",
      "2018-05-04T20:52:28.348071: step 23971, loss 0.174179, acc 0.953125\n",
      "2018-05-04T20:52:29.591654: step 23972, loss 0.217791, acc 0.921875\n",
      "2018-05-04T20:52:30.926337: step 23973, loss 0.202876, acc 0.9375\n",
      "2018-05-04T20:52:32.176233: step 23974, loss 0.125237, acc 0.953125\n",
      "2018-05-04T20:52:33.322413: step 23975, loss 0.286628, acc 0.90625\n",
      "2018-05-04T20:52:34.544973: step 23976, loss 0.171322, acc 0.953125\n",
      "2018-05-04T20:52:35.632246: step 23977, loss 0.197597, acc 0.90625\n",
      "2018-05-04T20:52:36.791409: step 23978, loss 0.219791, acc 0.90625\n",
      "2018-05-04T20:52:37.857925: step 23979, loss 0.218016, acc 0.90625\n",
      "2018-05-04T20:52:38.865534: step 23980, loss 0.180291, acc 0.9375\n",
      "2018-05-04T20:52:39.879244: step 23981, loss 0.248016, acc 0.875\n",
      "2018-05-04T20:52:40.892552: step 23982, loss 0.21297, acc 0.9375\n",
      "2018-05-04T20:52:41.986762: step 23983, loss 0.205464, acc 0.890625\n",
      "2018-05-04T20:52:43.185059: step 23984, loss 0.167552, acc 0.9375\n",
      "2018-05-04T20:52:44.255486: step 23985, loss 0.261225, acc 0.859375\n",
      "2018-05-04T20:52:45.353760: step 23986, loss 0.151285, acc 0.953125\n",
      "2018-05-04T20:52:46.407621: step 23987, loss 0.224074, acc 0.921875\n",
      "2018-05-04T20:52:47.483815: step 23988, loss 0.396797, acc 0.890625\n",
      "2018-05-04T20:52:48.745152: step 23989, loss 0.135208, acc 0.921875\n",
      "2018-05-04T20:52:49.989778: step 23990, loss 0.259748, acc 0.890625\n",
      "2018-05-04T20:52:51.195039: step 23991, loss 0.28251, acc 0.859375\n",
      "2018-05-04T20:52:52.350353: step 23992, loss 0.249386, acc 0.890625\n",
      "2018-05-04T20:52:53.458624: step 23993, loss 0.328628, acc 0.875\n",
      "2018-05-04T20:52:54.577985: step 23994, loss 0.0811785, acc 0.984375\n",
      "2018-05-04T20:52:55.701731: step 23995, loss 0.336682, acc 0.875\n",
      "2018-05-04T20:52:56.917782: step 23996, loss 0.26782, acc 0.921875\n",
      "2018-05-04T20:52:58.115253: step 23997, loss 0.216998, acc 0.96875\n",
      "2018-05-04T20:52:59.337423: step 23998, loss 0.366757, acc 0.796875\n",
      "2018-05-04T20:53:00.474583: step 23999, loss 0.352809, acc 0.859375\n",
      "2018-05-04T20:53:01.778581: step 24000, loss 0.226872, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T20:53:05.423017: step 24000, loss 0.239122, acc 0.916\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-24000\n",
      "\n",
      "2018-05-04T20:53:06.759745: step 24001, loss 0.26221, acc 0.875\n",
      "2018-05-04T20:53:08.114706: step 24002, loss 0.242974, acc 0.875\n",
      "2018-05-04T20:53:09.323351: step 24003, loss 0.162167, acc 0.953125\n",
      "2018-05-04T20:53:10.447745: step 24004, loss 0.220752, acc 0.921875\n",
      "2018-05-04T20:53:11.911124: step 24005, loss 0.272957, acc 0.953125\n",
      "2018-05-04T20:53:13.298967: step 24006, loss 0.224126, acc 0.890625\n",
      "2018-05-04T20:53:14.452570: step 24007, loss 0.276958, acc 0.890625\n",
      "2018-05-04T20:53:15.573392: step 24008, loss 0.162283, acc 0.9375\n",
      "2018-05-04T20:53:16.649248: step 24009, loss 0.235964, acc 0.90625\n",
      "2018-05-04T20:53:17.785533: step 24010, loss 0.285058, acc 0.890625\n",
      "2018-05-04T20:53:18.805651: step 24011, loss 0.273702, acc 0.875\n",
      "2018-05-04T20:53:19.916025: step 24012, loss 0.245853, acc 0.90625\n",
      "2018-05-04T20:53:21.139863: step 24013, loss 0.337031, acc 0.921875\n",
      "2018-05-04T20:53:22.530525: step 24014, loss 0.237028, acc 0.953125\n",
      "2018-05-04T20:53:23.860579: step 24015, loss 0.24809, acc 0.921875\n",
      "2018-05-04T20:53:24.993402: step 24016, loss 0.24889, acc 0.96875\n",
      "2018-05-04T20:53:26.064740: step 24017, loss 0.217048, acc 0.921875\n",
      "2018-05-04T20:53:27.247979: step 24018, loss 0.225122, acc 0.90625\n",
      "2018-05-04T20:53:28.521383: step 24019, loss 0.265262, acc 0.859375\n",
      "2018-05-04T20:53:29.850804: step 24020, loss 0.202509, acc 0.890625\n",
      "2018-05-04T20:53:31.156784: step 24021, loss 0.341333, acc 0.828125\n",
      "2018-05-04T20:53:32.412689: step 24022, loss 0.253787, acc 0.90625\n",
      "2018-05-04T20:53:33.540102: step 24023, loss 0.247807, acc 0.890625\n",
      "2018-05-04T20:53:34.712571: step 24024, loss 0.258775, acc 0.890625\n",
      "2018-05-04T20:53:35.820971: step 24025, loss 0.275108, acc 0.90625\n",
      "2018-05-04T20:53:36.998368: step 24026, loss 0.295751, acc 0.84375\n",
      "2018-05-04T20:53:38.272037: step 24027, loss 0.188121, acc 0.90625\n",
      "2018-05-04T20:53:39.538095: step 24028, loss 0.303624, acc 0.828125\n",
      "2018-05-04T20:53:40.783800: step 24029, loss 0.251765, acc 0.890625\n",
      "2018-05-04T20:53:42.045332: step 24030, loss 0.238029, acc 0.890625\n",
      "2018-05-04T20:53:43.222225: step 24031, loss 0.16853, acc 0.9375\n",
      "2018-05-04T20:53:44.359927: step 24032, loss 0.328163, acc 0.875\n",
      "2018-05-04T20:53:45.556075: step 24033, loss 0.211072, acc 0.921875\n",
      "2018-05-04T20:53:46.657004: step 24034, loss 0.201856, acc 0.90625\n",
      "2018-05-04T20:53:47.781056: step 24035, loss 0.253411, acc 0.84375\n",
      "2018-05-04T20:53:49.005736: step 24036, loss 0.184876, acc 0.953125\n",
      "2018-05-04T20:53:50.225761: step 24037, loss 0.303069, acc 0.859375\n",
      "2018-05-04T20:53:51.467787: step 24038, loss 0.159297, acc 0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T20:53:52.730374: step 24039, loss 0.218766, acc 0.875\n",
      "2018-05-04T20:53:53.889316: step 24040, loss 0.207242, acc 0.90625\n",
      "2018-05-04T20:53:55.124813: step 24041, loss 0.325203, acc 0.890625\n",
      "2018-05-04T20:53:56.245180: step 24042, loss 0.287249, acc 0.890625\n",
      "2018-05-04T20:53:57.437545: step 24043, loss 0.171857, acc 0.90625\n",
      "2018-05-04T20:53:58.561926: step 24044, loss 0.297141, acc 0.84375\n",
      "2018-05-04T20:53:59.823694: step 24045, loss 0.301514, acc 0.875\n",
      "2018-05-04T20:54:01.032064: step 24046, loss 0.328468, acc 0.890625\n",
      "2018-05-04T20:54:02.279062: step 24047, loss 0.137691, acc 0.953125\n",
      "2018-05-04T20:54:03.462453: step 24048, loss 0.225633, acc 0.90625\n",
      "2018-05-04T20:54:04.607103: step 24049, loss 0.242405, acc 0.890625\n",
      "2018-05-04T20:54:05.827827: step 24050, loss 0.230192, acc 0.921875\n",
      "2018-05-04T20:54:07.020863: step 24051, loss 0.324203, acc 0.84375\n",
      "2018-05-04T20:54:08.098829: step 24052, loss 0.156723, acc 0.921875\n",
      "2018-05-04T20:54:09.387805: step 24053, loss 0.275427, acc 0.890625\n",
      "2018-05-04T20:54:10.771439: step 24054, loss 0.312655, acc 0.859375\n",
      "2018-05-04T20:54:12.142733: step 24055, loss 0.214912, acc 0.921875\n",
      "2018-05-04T20:54:13.587590: step 24056, loss 0.24427, acc 0.90625\n",
      "2018-05-04T20:54:14.865364: step 24057, loss 0.374905, acc 0.875\n",
      "2018-05-04T20:54:16.338592: step 24058, loss 0.254523, acc 0.921875\n",
      "2018-05-04T20:54:17.509016: step 24059, loss 0.248206, acc 0.875\n",
      "2018-05-04T20:54:18.701469: step 24060, loss 0.25945, acc 0.90625\n",
      "2018-05-04T20:54:19.865028: step 24061, loss 0.277389, acc 0.859375\n",
      "2018-05-04T20:54:21.069615: step 24062, loss 0.347646, acc 0.84375\n",
      "2018-05-04T20:54:22.287000: step 24063, loss 0.15619, acc 0.90625\n",
      "2018-05-04T20:54:23.457486: step 24064, loss 0.295143, acc 0.828125\n",
      "2018-05-04T20:54:24.646642: step 24065, loss 0.250626, acc 0.90625\n",
      "2018-05-04T20:54:25.731830: step 24066, loss 0.155086, acc 0.953125\n",
      "2018-05-04T20:54:26.884678: step 24067, loss 0.406192, acc 0.828125\n",
      "2018-05-04T20:54:28.111629: step 24068, loss 0.15723, acc 0.953125\n",
      "2018-05-04T20:54:29.437791: step 24069, loss 0.178725, acc 0.9375\n",
      "2018-05-04T20:54:30.791832: step 24070, loss 0.243624, acc 0.90625\n",
      "2018-05-04T20:54:32.008010: step 24071, loss 0.222202, acc 0.9375\n",
      "2018-05-04T20:54:33.159405: step 24072, loss 0.235874, acc 0.921875\n",
      "2018-05-04T20:54:34.338488: step 24073, loss 0.219667, acc 0.921875\n",
      "2018-05-04T20:54:35.462502: step 24074, loss 0.218762, acc 0.90625\n",
      "2018-05-04T20:54:36.807051: step 24075, loss 0.152857, acc 0.921875\n",
      "2018-05-04T20:54:38.148124: step 24076, loss 0.339423, acc 0.859375\n",
      "2018-05-04T20:54:39.345653: step 24077, loss 0.406442, acc 0.828125\n",
      "2018-05-04T20:54:40.774188: step 24078, loss 0.227246, acc 0.890625\n",
      "2018-05-04T20:54:42.044063: step 24079, loss 0.246068, acc 0.875\n",
      "2018-05-04T20:54:43.186671: step 24080, loss 0.270355, acc 0.875\n",
      "2018-05-04T20:54:44.246724: step 24081, loss 0.262815, acc 0.875\n",
      "2018-05-04T20:54:45.380294: step 24082, loss 0.30696, acc 0.875\n",
      "2018-05-04T20:54:46.449695: step 24083, loss 0.172356, acc 0.921875\n",
      "2018-05-04T20:54:47.575009: step 24084, loss 0.201042, acc 0.9375\n",
      "2018-05-04T20:54:48.656079: step 24085, loss 0.314521, acc 0.84375\n",
      "2018-05-04T20:54:49.707121: step 24086, loss 0.15802, acc 0.953125\n",
      "2018-05-04T20:54:50.814199: step 24087, loss 0.180134, acc 0.921875\n",
      "2018-05-04T20:54:51.977586: step 24088, loss 0.307917, acc 0.890625\n",
      "2018-05-04T20:54:53.010062: step 24089, loss 0.241505, acc 0.9375\n",
      "2018-05-04T20:54:54.019999: step 24090, loss 0.403357, acc 0.84375\n",
      "2018-05-04T20:54:55.064782: step 24091, loss 0.149925, acc 0.953125\n",
      "2018-05-04T20:54:56.185291: step 24092, loss 0.240836, acc 0.890625\n",
      "2018-05-04T20:54:57.239698: step 24093, loss 0.146559, acc 0.953125\n",
      "2018-05-04T20:54:58.396945: step 24094, loss 0.355621, acc 0.875\n",
      "2018-05-04T20:54:59.514137: step 24095, loss 0.245405, acc 0.90625\n",
      "2018-05-04T20:55:00.636757: step 24096, loss 0.224324, acc 0.921875\n",
      "2018-05-04T20:55:01.955901: step 24097, loss 0.191443, acc 0.921875\n",
      "2018-05-04T20:55:03.094816: step 24098, loss 0.336658, acc 0.8125\n",
      "2018-05-04T20:55:04.159617: step 24099, loss 0.2727, acc 0.890625\n",
      "2018-05-04T20:55:05.359887: step 24100, loss 0.353235, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T20:55:08.903017: step 24100, loss 0.212119, acc 0.928\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-24100\n",
      "\n",
      "2018-05-04T20:55:10.179318: step 24101, loss 0.242765, acc 0.90625\n",
      "2018-05-04T20:55:11.379767: step 24102, loss 0.13685, acc 0.9375\n",
      "2018-05-04T20:55:12.634427: step 24103, loss 0.28183, acc 0.859375\n",
      "2018-05-04T20:55:13.802351: step 24104, loss 0.281512, acc 0.859375\n",
      "2018-05-04T20:55:14.974341: step 24105, loss 0.374353, acc 0.890625\n",
      "2018-05-04T20:55:16.158857: step 24106, loss 0.418027, acc 0.828125\n",
      "2018-05-04T20:55:17.338862: step 24107, loss 0.357301, acc 0.890625\n",
      "2018-05-04T20:55:18.524499: step 24108, loss 0.258676, acc 0.859375\n",
      "2018-05-04T20:55:19.704510: step 24109, loss 0.170311, acc 0.9375\n",
      "2018-05-04T20:55:20.871981: step 24110, loss 0.33924, acc 0.84375\n",
      "2018-05-04T20:55:22.095014: step 24111, loss 0.238922, acc 0.90625\n",
      "2018-05-04T20:55:23.317309: step 24112, loss 0.179822, acc 0.921875\n",
      "2018-05-04T20:55:24.472504: step 24113, loss 0.303272, acc 0.859375\n",
      "2018-05-04T20:55:25.603122: step 24114, loss 0.334803, acc 0.84375\n",
      "2018-05-04T20:55:26.715498: step 24115, loss 0.234468, acc 0.921875\n",
      "2018-05-04T20:55:27.828446: step 24116, loss 0.263148, acc 0.890625\n",
      "2018-05-04T20:55:28.938864: step 24117, loss 0.211621, acc 0.921875\n",
      "2018-05-04T20:55:30.044831: step 24118, loss 0.147603, acc 0.9375\n",
      "2018-05-04T20:55:31.179766: step 24119, loss 0.302171, acc 0.875\n",
      "2018-05-04T20:55:32.243123: step 24120, loss 0.314395, acc 0.828125\n",
      "2018-05-04T20:55:33.373674: step 24121, loss 0.189674, acc 0.921875\n",
      "2018-05-04T20:55:34.508334: step 24122, loss 0.170595, acc 0.9375\n",
      "2018-05-04T20:55:35.641988: step 24123, loss 0.228522, acc 0.9375\n",
      "2018-05-04T20:55:36.816713: step 24124, loss 0.229758, acc 0.875\n",
      "2018-05-04T20:55:37.934781: step 24125, loss 0.205471, acc 0.90625\n",
      "2018-05-04T20:55:39.089833: step 24126, loss 0.21204, acc 0.90625\n",
      "2018-05-04T20:55:40.138148: step 24127, loss 0.149169, acc 0.9375\n",
      "2018-05-04T20:55:41.286016: step 24128, loss 0.338587, acc 0.859375\n",
      "2018-05-04T20:55:42.420354: step 24129, loss 0.389038, acc 0.828125\n",
      "2018-05-04T20:55:43.578927: step 24130, loss 0.163122, acc 0.90625\n",
      "2018-05-04T20:55:44.730912: step 24131, loss 0.322047, acc 0.875\n",
      "2018-05-04T20:55:45.842960: step 24132, loss 0.396587, acc 0.828125\n",
      "2018-05-04T20:55:47.008439: step 24133, loss 0.213524, acc 0.859375\n",
      "2018-05-04T20:55:48.177147: step 24134, loss 0.462985, acc 0.828125\n",
      "2018-05-04T20:55:49.301449: step 24135, loss 0.193057, acc 0.90625\n",
      "2018-05-04T20:55:50.465973: step 24136, loss 0.375532, acc 0.84375\n",
      "2018-05-04T20:55:51.684407: step 24137, loss 0.188422, acc 0.90625\n",
      "2018-05-04T20:55:52.847495: step 24138, loss 0.377501, acc 0.84375\n",
      "2018-05-04T20:55:54.193353: step 24139, loss 0.165958, acc 0.9375\n",
      "2018-05-04T20:55:55.425870: step 24140, loss 0.274358, acc 0.921875\n",
      "2018-05-04T20:55:56.687762: step 24141, loss 0.255583, acc 0.921875\n",
      "2018-05-04T20:55:57.946956: step 24142, loss 0.340674, acc 0.8125\n",
      "2018-05-04T20:55:59.203492: step 24143, loss 0.239873, acc 0.921875\n",
      "2018-05-04T20:56:00.379147: step 24144, loss 0.234166, acc 0.890625\n",
      "2018-05-04T20:56:01.714681: step 24145, loss 0.247418, acc 0.9375\n",
      "2018-05-04T20:56:02.930680: step 24146, loss 0.173842, acc 0.9375\n",
      "2018-05-04T20:56:04.153591: step 24147, loss 0.36618, acc 0.859375\n",
      "2018-05-04T20:56:05.271147: step 24148, loss 0.383046, acc 0.84375\n",
      "2018-05-04T20:56:06.411630: step 24149, loss 0.247004, acc 0.875\n",
      "2018-05-04T20:56:07.470671: step 24150, loss 0.177208, acc 0.9375\n",
      "2018-05-04T20:56:08.612431: step 24151, loss 0.363239, acc 0.875\n",
      "2018-05-04T20:56:09.667259: step 24152, loss 0.161622, acc 0.9375\n",
      "2018-05-04T20:56:10.809885: step 24153, loss 0.283802, acc 0.875\n",
      "2018-05-04T20:56:11.894427: step 24154, loss 0.108775, acc 0.984375\n",
      "2018-05-04T20:56:12.974021: step 24155, loss 0.391631, acc 0.859375\n",
      "2018-05-04T20:56:14.161483: step 24156, loss 0.347575, acc 0.890625\n",
      "2018-05-04T20:56:15.165799: step 24157, loss 0.266696, acc 0.875\n",
      "2018-05-04T20:56:16.273271: step 24158, loss 0.213679, acc 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T20:56:17.388851: step 24159, loss 0.147181, acc 0.96875\n",
      "2018-05-04T20:56:18.490461: step 24160, loss 0.278106, acc 0.890625\n",
      "2018-05-04T20:56:19.669236: step 24161, loss 0.252708, acc 0.90625\n",
      "2018-05-04T20:56:20.787267: step 24162, loss 0.346642, acc 0.859375\n",
      "2018-05-04T20:56:21.920412: step 24163, loss 0.224103, acc 0.90625\n",
      "2018-05-04T20:56:23.053385: step 24164, loss 0.201111, acc 0.921875\n",
      "2018-05-04T20:56:24.175878: step 24165, loss 0.253038, acc 0.875\n",
      "2018-05-04T20:56:25.185686: step 24166, loss 0.177972, acc 0.921875\n",
      "2018-05-04T20:56:26.232023: step 24167, loss 0.287683, acc 0.90625\n",
      "2018-05-04T20:56:27.330472: step 24168, loss 0.201775, acc 0.9375\n",
      "2018-05-04T20:56:28.322280: step 24169, loss 0.235513, acc 0.875\n",
      "2018-05-04T20:56:29.323479: step 24170, loss 0.22588, acc 0.90625\n",
      "2018-05-04T20:56:30.445917: step 24171, loss 0.165458, acc 0.953125\n",
      "2018-05-04T20:56:31.520387: step 24172, loss 0.121631, acc 0.953125\n",
      "2018-05-04T20:56:32.530698: step 24173, loss 0.299532, acc 0.921875\n",
      "2018-05-04T20:56:33.556366: step 24174, loss 0.132091, acc 0.96875\n",
      "2018-05-04T20:56:34.676509: step 24175, loss 0.179882, acc 0.921875\n",
      "2018-05-04T20:56:35.757324: step 24176, loss 0.287521, acc 0.890625\n",
      "2018-05-04T20:56:36.768759: step 24177, loss 0.368051, acc 0.84375\n",
      "2018-05-04T20:56:37.855875: step 24178, loss 0.242709, acc 0.890625\n",
      "2018-05-04T20:56:38.933319: step 24179, loss 0.269428, acc 0.890625\n",
      "2018-05-04T20:56:40.143475: step 24180, loss 0.271949, acc 0.84375\n",
      "2018-05-04T20:56:41.293082: step 24181, loss 0.195247, acc 0.9375\n",
      "2018-05-04T20:56:42.411492: step 24182, loss 0.188314, acc 0.921875\n",
      "2018-05-04T20:56:43.457002: step 24183, loss 0.17903, acc 0.96875\n",
      "2018-05-04T20:56:44.574092: step 24184, loss 0.274902, acc 0.859375\n",
      "2018-05-04T20:56:45.606901: step 24185, loss 0.32726, acc 0.875\n",
      "2018-05-04T20:56:46.704295: step 24186, loss 0.258343, acc 0.84375\n",
      "2018-05-04T20:56:47.798906: step 24187, loss 0.227043, acc 0.890625\n",
      "2018-05-04T20:56:48.989825: step 24188, loss 0.270204, acc 0.875\n",
      "2018-05-04T20:56:50.129535: step 24189, loss 0.330639, acc 0.875\n",
      "2018-05-04T20:56:51.180459: step 24190, loss 0.441478, acc 0.828125\n",
      "2018-05-04T20:56:52.305733: step 24191, loss 0.221367, acc 0.921875\n",
      "2018-05-04T20:56:53.405511: step 24192, loss 0.15344, acc 0.9375\n",
      "2018-05-04T20:56:54.554606: step 24193, loss 0.35993, acc 0.875\n",
      "2018-05-04T20:56:55.697786: step 24194, loss 0.267561, acc 0.890625\n",
      "2018-05-04T20:56:56.882890: step 24195, loss 0.383401, acc 0.859375\n",
      "2018-05-04T20:56:58.180395: step 24196, loss 0.178823, acc 0.921875\n",
      "2018-05-04T20:56:59.418680: step 24197, loss 0.173067, acc 0.921875\n",
      "2018-05-04T20:57:00.497961: step 24198, loss 0.267298, acc 0.875\n",
      "2018-05-04T20:57:01.574717: step 24199, loss 0.246193, acc 0.890625\n",
      "2018-05-04T20:57:02.593376: step 24200, loss 0.225762, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T20:57:05.607129: step 24200, loss 0.212698, acc 0.932\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-24200\n",
      "\n",
      "2018-05-04T20:57:06.852379: step 24201, loss 0.276421, acc 0.859375\n",
      "2018-05-04T20:57:07.909263: step 24202, loss 0.170754, acc 0.9375\n",
      "2018-05-04T20:57:08.968415: step 24203, loss 0.12965, acc 0.984375\n",
      "2018-05-04T20:57:10.170961: step 24204, loss 0.184339, acc 0.90625\n",
      "2018-05-04T20:57:11.304096: step 24205, loss 0.21992, acc 0.921875\n",
      "2018-05-04T20:57:12.498824: step 24206, loss 0.242634, acc 0.921875\n",
      "2018-05-04T20:57:13.608670: step 24207, loss 0.252318, acc 0.921875\n",
      "2018-05-04T20:57:14.753448: step 24208, loss 0.218578, acc 0.890625\n",
      "2018-05-04T20:57:15.973399: step 24209, loss 0.299104, acc 0.875\n",
      "2018-05-04T20:57:17.159389: step 24210, loss 0.294322, acc 0.828125\n",
      "2018-05-04T20:57:18.360814: step 24211, loss 0.154557, acc 0.9375\n",
      "2018-05-04T20:57:19.524193: step 24212, loss 0.147215, acc 0.921875\n",
      "2018-05-04T20:57:20.732072: step 24213, loss 0.198738, acc 0.90625\n",
      "2018-05-04T20:57:21.945982: step 24214, loss 0.221439, acc 0.921875\n",
      "2018-05-04T20:57:23.213424: step 24215, loss 0.145794, acc 0.96875\n",
      "2018-05-04T20:57:24.384674: step 24216, loss 0.399993, acc 0.84375\n",
      "2018-05-04T20:57:25.630192: step 24217, loss 0.225074, acc 0.921875\n",
      "2018-05-04T20:57:26.784045: step 24218, loss 0.280827, acc 0.90625\n",
      "2018-05-04T20:57:27.897629: step 24219, loss 0.322519, acc 0.875\n",
      "2018-05-04T20:57:29.081629: step 24220, loss 0.368522, acc 0.828125\n",
      "2018-05-04T20:57:30.369662: step 24221, loss 0.251438, acc 0.90625\n",
      "2018-05-04T20:57:31.605115: step 24222, loss 0.200369, acc 0.9375\n",
      "2018-05-04T20:57:32.973992: step 24223, loss 0.204915, acc 0.875\n",
      "2018-05-04T20:57:34.102966: step 24224, loss 0.257584, acc 0.890625\n",
      "2018-05-04T20:57:35.233022: step 24225, loss 0.221369, acc 0.90625\n",
      "2018-05-04T20:57:36.384703: step 24226, loss 0.2332, acc 0.90625\n",
      "2018-05-04T20:57:37.793717: step 24227, loss 0.357253, acc 0.859375\n",
      "2018-05-04T20:57:39.854409: step 24228, loss 0.203204, acc 0.90625\n",
      "2018-05-04T20:57:41.403191: step 24229, loss 0.41381, acc 0.859375\n",
      "2018-05-04T20:57:42.887357: step 24230, loss 0.221176, acc 0.9375\n",
      "2018-05-04T20:57:44.269724: step 24231, loss 0.168869, acc 0.953125\n",
      "2018-05-04T20:57:45.456342: step 24232, loss 0.330195, acc 0.84375\n",
      "2018-05-04T20:57:46.835306: step 24233, loss 0.191868, acc 0.890625\n",
      "2018-05-04T20:57:48.065451: step 24234, loss 0.229555, acc 0.90625\n",
      "2018-05-04T20:57:49.457112: step 24235, loss 0.267266, acc 0.921875\n",
      "2018-05-04T20:57:50.734649: step 24236, loss 0.224787, acc 0.9375\n",
      "2018-05-04T20:57:52.055424: step 24237, loss 0.30915, acc 0.875\n",
      "2018-05-04T20:57:53.385999: step 24238, loss 0.275869, acc 0.890625\n",
      "2018-05-04T20:57:54.621747: step 24239, loss 0.368721, acc 0.84375\n",
      "2018-05-04T20:57:55.894530: step 24240, loss 0.299219, acc 0.875\n",
      "2018-05-04T20:57:57.093978: step 24241, loss 0.173183, acc 0.953125\n",
      "2018-05-04T20:57:58.289573: step 24242, loss 0.286139, acc 0.90625\n",
      "2018-05-04T20:57:59.537267: step 24243, loss 0.137352, acc 0.953125\n",
      "2018-05-04T20:58:00.704295: step 24244, loss 0.340032, acc 0.859375\n",
      "2018-05-04T20:58:01.920909: step 24245, loss 0.213339, acc 0.9375\n",
      "2018-05-04T20:58:03.095022: step 24246, loss 0.165405, acc 0.921875\n",
      "2018-05-04T20:58:04.337017: step 24247, loss 0.211722, acc 0.9375\n",
      "2018-05-04T20:58:05.609514: step 24248, loss 0.292116, acc 0.921875\n",
      "2018-05-04T20:58:06.839728: step 24249, loss 0.205338, acc 0.9375\n",
      "2018-05-04T20:58:08.066790: step 24250, loss 0.177104, acc 0.890625\n",
      "2018-05-04T20:58:09.346768: step 24251, loss 0.305627, acc 0.875\n",
      "2018-05-04T20:58:10.478813: step 24252, loss 0.1802, acc 0.9375\n",
      "2018-05-04T20:58:11.752669: step 24253, loss 0.207202, acc 0.90625\n",
      "2018-05-04T20:58:12.997713: step 24254, loss 0.267433, acc 0.859375\n",
      "2018-05-04T20:58:14.327379: step 24255, loss 0.2343, acc 0.890625\n",
      "2018-05-04T20:58:15.589905: step 24256, loss 0.286231, acc 0.921875\n",
      "2018-05-04T20:58:16.827585: step 24257, loss 0.258192, acc 0.875\n",
      "2018-05-04T20:58:18.123426: step 24258, loss 0.302785, acc 0.890625\n",
      "2018-05-04T20:58:19.311038: step 24259, loss 0.281117, acc 0.890625\n",
      "2018-05-04T20:58:20.453356: step 24260, loss 0.144978, acc 0.953125\n",
      "2018-05-04T20:58:21.583901: step 24261, loss 0.252822, acc 0.875\n",
      "2018-05-04T20:58:22.794743: step 24262, loss 0.277537, acc 0.859375\n",
      "2018-05-04T20:58:23.935928: step 24263, loss 0.281802, acc 0.84375\n",
      "2018-05-04T20:58:25.079416: step 24264, loss 0.20868, acc 0.90625\n",
      "2018-05-04T20:58:26.204392: step 24265, loss 0.338714, acc 0.890625\n",
      "2018-05-04T20:58:27.347433: step 24266, loss 0.209818, acc 0.9375\n",
      "2018-05-04T20:58:28.481929: step 24267, loss 0.28931, acc 0.90625\n",
      "2018-05-04T20:58:29.618415: step 24268, loss 0.0945676, acc 1\n",
      "2018-05-04T20:58:30.826832: step 24269, loss 0.303181, acc 0.875\n",
      "2018-05-04T20:58:32.196408: step 24270, loss 0.234253, acc 0.921875\n",
      "2018-05-04T20:58:33.587634: step 24271, loss 0.212733, acc 0.921875\n",
      "2018-05-04T20:58:34.935029: step 24272, loss 0.180654, acc 0.921875\n",
      "2018-05-04T20:58:36.339162: step 24273, loss 0.196619, acc 0.90625\n",
      "2018-05-04T20:58:37.768172: step 24274, loss 0.297551, acc 0.875\n",
      "2018-05-04T20:58:40.054545: step 24275, loss 0.286802, acc 0.84375\n",
      "2018-05-04T20:58:42.036451: step 24276, loss 0.360982, acc 0.859375\n",
      "2018-05-04T20:58:44.023721: step 24277, loss 0.181828, acc 0.921875\n",
      "2018-05-04T20:58:46.157617: step 24278, loss 0.199992, acc 0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T20:58:48.198298: step 24279, loss 0.243245, acc 0.890625\n",
      "2018-05-04T20:58:49.680542: step 24280, loss 0.236471, acc 0.859375\n",
      "2018-05-04T20:58:51.090552: step 24281, loss 0.315409, acc 0.875\n",
      "2018-05-04T20:58:52.462768: step 24282, loss 0.300638, acc 0.859375\n",
      "2018-05-04T20:58:53.926007: step 24283, loss 0.242325, acc 0.921875\n",
      "2018-05-04T20:58:55.304847: step 24284, loss 0.304563, acc 0.859375\n",
      "2018-05-04T20:58:56.633737: step 24285, loss 0.238513, acc 0.90625\n",
      "2018-05-04T20:58:57.985829: step 24286, loss 0.397861, acc 0.8125\n",
      "2018-05-04T20:58:59.336627: step 24287, loss 0.335902, acc 0.828125\n",
      "2018-05-04T20:59:00.721322: step 24288, loss 0.139946, acc 0.96875\n",
      "2018-05-04T20:59:02.287803: step 24289, loss 0.20478, acc 0.890625\n",
      "2018-05-04T20:59:04.465699: step 24290, loss 0.216048, acc 0.921875\n",
      "2018-05-04T20:59:06.457959: step 24291, loss 0.336212, acc 0.859375\n",
      "2018-05-04T20:59:08.472591: step 24292, loss 0.263346, acc 0.9375\n",
      "2018-05-04T20:59:10.520300: step 24293, loss 0.233678, acc 0.90625\n",
      "2018-05-04T20:59:12.262137: step 24294, loss 0.197676, acc 0.9375\n",
      "2018-05-04T20:59:13.691311: step 24295, loss 0.350958, acc 0.84375\n",
      "2018-05-04T20:59:15.035714: step 24296, loss 0.335604, acc 0.875\n",
      "2018-05-04T20:59:16.361001: step 24297, loss 0.304675, acc 0.84375\n",
      "2018-05-04T20:59:17.811714: step 24298, loss 0.170461, acc 0.90625\n",
      "2018-05-04T20:59:19.233603: step 24299, loss 0.270561, acc 0.875\n",
      "2018-05-04T20:59:20.796810: step 24300, loss 0.278189, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T20:59:25.864648: step 24300, loss 0.211067, acc 0.93\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-24300\n",
      "\n",
      "2018-05-04T20:59:27.485743: step 24301, loss 0.181034, acc 0.9375\n",
      "2018-05-04T20:59:28.927756: step 24302, loss 0.227888, acc 0.890625\n",
      "2018-05-04T20:59:30.475110: step 24303, loss 0.241135, acc 0.859375\n",
      "2018-05-04T20:59:32.125065: step 24304, loss 0.302466, acc 0.84375\n",
      "2018-05-04T20:59:33.690876: step 24305, loss 0.310673, acc 0.84375\n",
      "2018-05-04T20:59:35.135912: step 24306, loss 0.361732, acc 0.8125\n",
      "2018-05-04T20:59:36.661916: step 24307, loss 0.253236, acc 0.890625\n",
      "2018-05-04T20:59:38.162648: step 24308, loss 0.163187, acc 0.96875\n",
      "2018-05-04T20:59:39.584435: step 24309, loss 0.292816, acc 0.921875\n",
      "2018-05-04T20:59:40.911214: step 24310, loss 0.156431, acc 0.953125\n",
      "2018-05-04T20:59:42.338175: step 24311, loss 0.134368, acc 0.96875\n",
      "2018-05-04T20:59:43.689737: step 24312, loss 0.247445, acc 0.90625\n",
      "2018-05-04T20:59:45.033084: step 24313, loss 0.264439, acc 0.890625\n",
      "2018-05-04T20:59:46.335403: step 24314, loss 0.238521, acc 0.890625\n",
      "2018-05-04T20:59:47.624406: step 24315, loss 0.305993, acc 0.859375\n",
      "2018-05-04T20:59:48.903547: step 24316, loss 0.198184, acc 0.921875\n",
      "2018-05-04T20:59:50.223313: step 24317, loss 0.223674, acc 0.921875\n",
      "2018-05-04T20:59:51.586472: step 24318, loss 0.256471, acc 0.859375\n",
      "2018-05-04T20:59:52.890907: step 24319, loss 0.420395, acc 0.859375\n",
      "2018-05-04T20:59:54.227294: step 24320, loss 0.19764, acc 0.921875\n",
      "2018-05-04T20:59:55.437783: step 24321, loss 0.209873, acc 0.9375\n",
      "2018-05-04T20:59:56.691755: step 24322, loss 0.12409, acc 0.9375\n",
      "2018-05-04T20:59:57.915493: step 24323, loss 0.231484, acc 0.875\n",
      "2018-05-04T20:59:59.109359: step 24324, loss 0.26188, acc 0.921875\n",
      "2018-05-04T21:00:00.420934: step 24325, loss 0.233864, acc 0.90625\n",
      "2018-05-04T21:00:01.668820: step 24326, loss 0.229351, acc 0.875\n",
      "2018-05-04T21:00:02.918232: step 24327, loss 0.146675, acc 0.953125\n",
      "2018-05-04T21:00:04.259423: step 24328, loss 0.224438, acc 0.875\n",
      "2018-05-04T21:00:05.546014: step 24329, loss 0.250302, acc 0.890625\n",
      "2018-05-04T21:00:06.794768: step 24330, loss 0.210533, acc 0.9375\n",
      "2018-05-04T21:00:08.095913: step 24331, loss 0.166189, acc 0.953125\n",
      "2018-05-04T21:00:09.388709: step 24332, loss 0.236232, acc 0.9375\n",
      "2018-05-04T21:00:10.743242: step 24333, loss 0.335061, acc 0.859375\n",
      "2018-05-04T21:00:12.110121: step 24334, loss 0.215158, acc 0.890625\n",
      "2018-05-04T21:00:13.446410: step 24335, loss 0.202628, acc 0.90625\n",
      "2018-05-04T21:00:14.714455: step 24336, loss 0.265656, acc 0.921875\n",
      "2018-05-04T21:00:15.915428: step 24337, loss 0.171357, acc 0.921875\n",
      "2018-05-04T21:00:17.176591: step 24338, loss 0.228814, acc 0.890625\n",
      "2018-05-04T21:00:18.450376: step 24339, loss 0.261348, acc 0.90625\n",
      "2018-05-04T21:00:19.747053: step 24340, loss 0.16874, acc 0.921875\n",
      "2018-05-04T21:00:21.031445: step 24341, loss 0.382165, acc 0.8125\n",
      "2018-05-04T21:00:22.528009: step 24342, loss 0.297383, acc 0.859375\n",
      "2018-05-04T21:00:23.813895: step 24343, loss 0.148926, acc 0.921875\n",
      "2018-05-04T21:00:25.096789: step 24344, loss 0.274612, acc 0.859375\n",
      "2018-05-04T21:00:26.431474: step 24345, loss 0.159077, acc 0.9375\n",
      "2018-05-04T21:00:27.762004: step 24346, loss 0.284853, acc 0.890625\n",
      "2018-05-04T21:00:29.011841: step 24347, loss 0.255841, acc 0.90625\n",
      "2018-05-04T21:00:30.245880: step 24348, loss 0.220933, acc 0.9375\n",
      "2018-05-04T21:00:31.501984: step 24349, loss 0.295018, acc 0.90625\n",
      "2018-05-04T21:00:32.958096: step 24350, loss 0.219598, acc 0.921875\n",
      "2018-05-04T21:00:34.156422: step 24351, loss 0.307447, acc 0.875\n",
      "2018-05-04T21:00:35.481750: step 24352, loss 0.271331, acc 0.875\n",
      "2018-05-04T21:00:36.785037: step 24353, loss 0.20647, acc 0.90625\n",
      "2018-05-04T21:00:38.037556: step 24354, loss 0.234899, acc 0.890625\n",
      "2018-05-04T21:00:39.348832: step 24355, loss 0.230877, acc 0.890625\n",
      "2018-05-04T21:00:40.722393: step 24356, loss 0.17702, acc 0.953125\n",
      "2018-05-04T21:00:42.042838: step 24357, loss 0.143122, acc 0.9375\n",
      "2018-05-04T21:00:43.231437: step 24358, loss 0.239163, acc 0.921875\n",
      "2018-05-04T21:00:44.365315: step 24359, loss 0.231073, acc 0.9375\n",
      "2018-05-04T21:00:45.449185: step 24360, loss 0.278965, acc 0.90625\n",
      "2018-05-04T21:00:46.550988: step 24361, loss 0.230172, acc 0.890625\n",
      "2018-05-04T21:00:47.689606: step 24362, loss 0.378911, acc 0.765625\n",
      "2018-05-04T21:00:48.759617: step 24363, loss 0.198359, acc 0.921875\n",
      "2018-05-04T21:00:49.881152: step 24364, loss 0.346679, acc 0.890625\n",
      "2018-05-04T21:00:51.059516: step 24365, loss 0.305934, acc 0.890625\n",
      "2018-05-04T21:00:52.132172: step 24366, loss 0.277463, acc 0.921875\n",
      "2018-05-04T21:00:53.296089: step 24367, loss 0.330531, acc 0.84375\n",
      "2018-05-04T21:00:54.421091: step 24368, loss 0.234164, acc 0.890625\n",
      "2018-05-04T21:00:55.623445: step 24369, loss 0.332249, acc 0.9375\n",
      "2018-05-04T21:00:56.789751: step 24370, loss 0.332117, acc 0.875\n",
      "2018-05-04T21:00:57.922737: step 24371, loss 0.297031, acc 0.875\n",
      "2018-05-04T21:00:59.074534: step 24372, loss 0.317368, acc 0.828125\n",
      "2018-05-04T21:01:00.218271: step 24373, loss 0.248724, acc 0.90625\n",
      "2018-05-04T21:01:01.450514: step 24374, loss 0.190908, acc 0.953125\n",
      "2018-05-04T21:01:02.597702: step 24375, loss 0.376105, acc 0.859375\n",
      "2018-05-04T21:01:03.771791: step 24376, loss 0.279942, acc 0.890625\n",
      "2018-05-04T21:01:04.995672: step 24377, loss 0.386611, acc 0.828125\n",
      "2018-05-04T21:01:06.229874: step 24378, loss 0.25, acc 0.90625\n",
      "2018-05-04T21:01:07.558207: step 24379, loss 0.263152, acc 0.90625\n",
      "2018-05-04T21:01:08.578479: step 24380, loss 0.228219, acc 0.90625\n",
      "2018-05-04T21:01:09.624641: step 24381, loss 0.104543, acc 0.984375\n",
      "2018-05-04T21:01:10.662746: step 24382, loss 0.197837, acc 0.96875\n",
      "2018-05-04T21:01:11.760843: step 24383, loss 0.281613, acc 0.828125\n",
      "2018-05-04T21:01:12.842872: step 24384, loss 0.248757, acc 0.921875\n",
      "2018-05-04T21:01:13.865721: step 24385, loss 0.282789, acc 0.921875\n",
      "2018-05-04T21:01:14.913141: step 24386, loss 0.240098, acc 0.921875\n",
      "2018-05-04T21:01:16.026361: step 24387, loss 0.29629, acc 0.875\n",
      "2018-05-04T21:01:17.160755: step 24388, loss 0.199357, acc 0.921875\n",
      "2018-05-04T21:01:18.245809: step 24389, loss 0.350253, acc 0.8125\n",
      "2018-05-04T21:01:19.240518: step 24390, loss 0.331407, acc 0.890625\n",
      "2018-05-04T21:01:20.323010: step 24391, loss 0.217913, acc 0.90625\n",
      "2018-05-04T21:01:21.347577: step 24392, loss 0.254489, acc 0.890625\n",
      "2018-05-04T21:01:22.428499: step 24393, loss 0.26774, acc 0.875\n",
      "2018-05-04T21:01:23.429657: step 24394, loss 0.286011, acc 0.859375\n",
      "2018-05-04T21:01:24.457372: step 24395, loss 0.232997, acc 0.875\n",
      "2018-05-04T21:01:25.459279: step 24396, loss 0.259972, acc 0.90625\n",
      "2018-05-04T21:01:26.441957: step 24397, loss 0.208349, acc 0.90625\n",
      "2018-05-04T21:01:27.408543: step 24398, loss 0.211477, acc 0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T21:01:28.391291: step 24399, loss 0.241749, acc 0.90625\n",
      "2018-05-04T21:01:29.380336: step 24400, loss 0.265074, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T21:01:33.292458: step 24400, loss 0.217922, acc 0.926\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-24400\n",
      "\n",
      "2018-05-04T21:01:34.403450: step 24401, loss 0.256289, acc 0.875\n",
      "2018-05-04T21:01:35.435120: step 24402, loss 0.317182, acc 0.875\n",
      "2018-05-04T21:01:36.481481: step 24403, loss 0.31372, acc 0.90625\n",
      "2018-05-04T21:01:37.534704: step 24404, loss 0.195034, acc 0.890625\n",
      "2018-05-04T21:01:38.567376: step 24405, loss 0.189883, acc 0.96875\n",
      "2018-05-04T21:01:39.609491: step 24406, loss 0.225955, acc 0.875\n",
      "2018-05-04T21:01:40.734668: step 24407, loss 0.354225, acc 0.875\n",
      "2018-05-04T21:01:41.772691: step 24408, loss 0.320816, acc 0.84375\n",
      "2018-05-04T21:01:42.821083: step 24409, loss 0.182603, acc 0.921875\n",
      "2018-05-04T21:01:43.842433: step 24410, loss 0.205005, acc 0.953125\n",
      "2018-05-04T21:01:44.884669: step 24411, loss 0.3119, acc 0.828125\n",
      "2018-05-04T21:01:45.887329: step 24412, loss 0.306625, acc 0.890625\n",
      "2018-05-04T21:01:46.881303: step 24413, loss 0.15952, acc 0.9375\n",
      "2018-05-04T21:01:47.867983: step 24414, loss 0.188587, acc 0.90625\n",
      "2018-05-04T21:01:48.873342: step 24415, loss 0.170713, acc 0.96875\n",
      "2018-05-04T21:01:49.878770: step 24416, loss 0.276062, acc 0.890625\n",
      "2018-05-04T21:01:50.873748: step 24417, loss 0.247957, acc 0.890625\n",
      "2018-05-04T21:01:51.867372: step 24418, loss 0.249844, acc 0.875\n",
      "2018-05-04T21:01:52.825131: step 24419, loss 0.217792, acc 0.875\n",
      "2018-05-04T21:01:53.819609: step 24420, loss 0.145792, acc 0.953125\n",
      "2018-05-04T21:01:54.841790: step 24421, loss 0.18445, acc 0.9375\n",
      "2018-05-04T21:01:55.848793: step 24422, loss 0.399481, acc 0.8125\n",
      "2018-05-04T21:01:56.801308: step 24423, loss 0.35517, acc 0.84375\n",
      "2018-05-04T21:01:57.760666: step 24424, loss 0.253412, acc 0.890625\n",
      "2018-05-04T21:01:58.744425: step 24425, loss 0.284482, acc 0.84375\n",
      "2018-05-04T21:01:59.737907: step 24426, loss 0.242232, acc 0.875\n",
      "2018-05-04T21:02:00.719218: step 24427, loss 0.185339, acc 0.9375\n",
      "2018-05-04T21:02:01.725789: step 24428, loss 0.300076, acc 0.890625\n",
      "2018-05-04T21:02:02.706493: step 24429, loss 0.274554, acc 0.90625\n",
      "2018-05-04T21:02:03.743400: step 24430, loss 0.522586, acc 0.84375\n",
      "2018-05-04T21:02:04.818244: step 24431, loss 0.331041, acc 0.84375\n",
      "2018-05-04T21:02:05.839359: step 24432, loss 0.164465, acc 0.9375\n",
      "2018-05-04T21:02:06.844872: step 24433, loss 0.377449, acc 0.8125\n",
      "2018-05-04T21:02:07.848287: step 24434, loss 0.347282, acc 0.828125\n",
      "2018-05-04T21:02:08.850730: step 24435, loss 0.26566, acc 0.875\n",
      "2018-05-04T21:02:09.955183: step 24436, loss 0.134016, acc 0.953125\n",
      "2018-05-04T21:02:11.067827: step 24437, loss 0.374294, acc 0.84375\n",
      "2018-05-04T21:02:12.269937: step 24438, loss 0.217636, acc 0.921875\n",
      "2018-05-04T21:02:13.372776: step 24439, loss 0.223127, acc 0.9375\n",
      "2018-05-04T21:02:14.388711: step 24440, loss 0.324213, acc 0.9375\n",
      "2018-05-04T21:02:15.433013: step 24441, loss 0.209097, acc 0.9375\n",
      "2018-05-04T21:02:16.595040: step 24442, loss 0.170379, acc 0.953125\n",
      "2018-05-04T21:02:17.656220: step 24443, loss 0.249119, acc 0.890625\n",
      "2018-05-04T21:02:18.682390: step 24444, loss 0.203516, acc 0.921875\n",
      "2018-05-04T21:02:19.742374: step 24445, loss 0.253458, acc 0.84375\n",
      "2018-05-04T21:02:20.873381: step 24446, loss 0.280083, acc 0.875\n",
      "2018-05-04T21:02:22.013067: step 24447, loss 0.190129, acc 0.9375\n",
      "2018-05-04T21:02:23.012920: step 24448, loss 0.184291, acc 0.921875\n",
      "2018-05-04T21:02:23.998601: step 24449, loss 0.278031, acc 0.90625\n",
      "2018-05-04T21:02:24.999916: step 24450, loss 0.159455, acc 0.921875\n",
      "2018-05-04T21:02:26.198085: step 24451, loss 0.143197, acc 0.921875\n",
      "2018-05-04T21:02:27.271982: step 24452, loss 0.220159, acc 0.90625\n",
      "2018-05-04T21:02:28.458786: step 24453, loss 0.330196, acc 0.890625\n",
      "2018-05-04T21:02:29.612961: step 24454, loss 0.298551, acc 0.890625\n",
      "2018-05-04T21:02:30.690046: step 24455, loss 0.312528, acc 0.890625\n",
      "2018-05-04T21:02:31.748425: step 24456, loss 0.213401, acc 0.890625\n",
      "2018-05-04T21:02:32.803971: step 24457, loss 0.243259, acc 0.90625\n",
      "2018-05-04T21:02:33.885977: step 24458, loss 0.217304, acc 0.90625\n",
      "2018-05-04T21:02:35.018524: step 24459, loss 0.230796, acc 0.90625\n",
      "2018-05-04T21:02:36.120815: step 24460, loss 0.211878, acc 0.921875\n",
      "2018-05-04T21:02:37.159900: step 24461, loss 0.276927, acc 0.921875\n",
      "2018-05-04T21:02:38.290144: step 24462, loss 0.293077, acc 0.90625\n",
      "2018-05-04T21:02:39.325538: step 24463, loss 0.262728, acc 0.890625\n",
      "2018-05-04T21:02:40.407225: step 24464, loss 0.225426, acc 0.875\n",
      "2018-05-04T21:02:41.518897: step 24465, loss 0.24857, acc 0.921875\n",
      "2018-05-04T21:02:42.663738: step 24466, loss 0.232198, acc 0.90625\n",
      "2018-05-04T21:02:43.659793: step 24467, loss 0.249511, acc 0.90625\n",
      "2018-05-04T21:02:44.793815: step 24468, loss 0.292539, acc 0.8125\n",
      "2018-05-04T21:02:45.751223: step 24469, loss 0.248451, acc 0.90625\n",
      "2018-05-04T21:02:46.838262: step 24470, loss 0.162935, acc 0.921875\n",
      "2018-05-04T21:02:47.919968: step 24471, loss 0.351549, acc 0.875\n",
      "2018-05-04T21:02:49.096684: step 24472, loss 0.174726, acc 0.9375\n",
      "2018-05-04T21:02:50.181789: step 24473, loss 0.246334, acc 0.90625\n",
      "2018-05-04T21:02:51.291188: step 24474, loss 0.171048, acc 0.953125\n",
      "2018-05-04T21:02:52.395881: step 24475, loss 0.247168, acc 0.921875\n",
      "2018-05-04T21:02:53.443287: step 24476, loss 0.190262, acc 0.890625\n",
      "2018-05-04T21:02:54.466332: step 24477, loss 0.385479, acc 0.859375\n",
      "2018-05-04T21:02:55.513737: step 24478, loss 0.338994, acc 0.859375\n",
      "2018-05-04T21:02:56.649762: step 24479, loss 0.317257, acc 0.8125\n",
      "2018-05-04T21:02:57.717463: step 24480, loss 0.239158, acc 0.9375\n",
      "2018-05-04T21:02:58.877858: step 24481, loss 0.283945, acc 0.90625\n",
      "2018-05-04T21:03:00.023249: step 24482, loss 0.280365, acc 0.859375\n",
      "2018-05-04T21:03:01.165838: step 24483, loss 0.195239, acc 0.921875\n",
      "2018-05-04T21:03:02.327891: step 24484, loss 0.170538, acc 0.953125\n",
      "2018-05-04T21:03:03.543900: step 24485, loss 0.278406, acc 0.890625\n",
      "2018-05-04T21:03:04.697473: step 24486, loss 0.253412, acc 0.859375\n",
      "2018-05-04T21:03:05.783995: step 24487, loss 0.35914, acc 0.875\n",
      "2018-05-04T21:03:06.796231: step 24488, loss 0.335383, acc 0.859375\n",
      "2018-05-04T21:03:07.863163: step 24489, loss 0.161274, acc 0.9375\n",
      "2018-05-04T21:03:08.896770: step 24490, loss 0.285218, acc 0.90625\n",
      "2018-05-04T21:03:09.853922: step 24491, loss 0.267685, acc 0.921875\n",
      "2018-05-04T21:03:10.840315: step 24492, loss 0.415948, acc 0.84375\n",
      "2018-05-04T21:03:11.921292: step 24493, loss 0.256686, acc 0.921875\n",
      "2018-05-04T21:03:12.990296: step 24494, loss 0.25124, acc 0.90625\n",
      "2018-05-04T21:03:14.025407: step 24495, loss 0.376288, acc 0.8125\n",
      "2018-05-04T21:03:15.088686: step 24496, loss 0.382256, acc 0.828125\n",
      "2018-05-04T21:03:16.084757: step 24497, loss 0.192334, acc 0.921875\n",
      "2018-05-04T21:03:17.106279: step 24498, loss 0.264704, acc 0.890625\n",
      "2018-05-04T21:03:18.119687: step 24499, loss 0.228214, acc 0.9375\n",
      "2018-05-04T21:03:19.171529: step 24500, loss 0.253518, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T21:03:22.257770: step 24500, loss 0.221558, acc 0.92\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-24500\n",
      "\n",
      "2018-05-04T21:03:23.564406: step 24501, loss 0.473303, acc 0.765625\n",
      "2018-05-04T21:03:24.803119: step 24502, loss 0.344832, acc 0.859375\n",
      "2018-05-04T21:03:26.049840: step 24503, loss 0.263873, acc 0.90625\n",
      "2018-05-04T21:03:27.504565: step 24504, loss 0.365788, acc 0.90625\n",
      "2018-05-04T21:03:28.985631: step 24505, loss 0.230289, acc 0.921875\n",
      "2018-05-04T21:03:30.322264: step 24506, loss 0.190376, acc 0.9375\n",
      "2018-05-04T21:03:31.723576: step 24507, loss 0.212366, acc 0.9375\n",
      "2018-05-04T21:03:32.870817: step 24508, loss 0.261495, acc 0.9375\n",
      "2018-05-04T21:03:34.041417: step 24509, loss 0.340253, acc 0.8125\n",
      "2018-05-04T21:03:35.226868: step 24510, loss 0.277163, acc 0.890625\n",
      "2018-05-04T21:03:36.477738: step 24511, loss 0.246056, acc 0.890625\n",
      "2018-05-04T21:03:37.671987: step 24512, loss 0.148291, acc 0.96875\n",
      "2018-05-04T21:03:38.885745: step 24513, loss 0.252863, acc 0.890625\n",
      "2018-05-04T21:03:40.075637: step 24514, loss 0.178064, acc 0.921875\n",
      "2018-05-04T21:03:41.225650: step 24515, loss 0.180436, acc 0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T21:03:42.282737: step 24516, loss 0.254146, acc 0.9375\n",
      "2018-05-04T21:03:43.350925: step 24517, loss 0.348197, acc 0.890625\n",
      "2018-05-04T21:03:44.431845: step 24518, loss 0.189198, acc 0.90625\n",
      "2018-05-04T21:03:45.593475: step 24519, loss 0.23724, acc 0.9375\n",
      "2018-05-04T21:03:46.819521: step 24520, loss 0.339496, acc 0.859375\n",
      "2018-05-04T21:03:47.941724: step 24521, loss 0.29648, acc 0.90625\n",
      "2018-05-04T21:03:49.024967: step 24522, loss 0.229716, acc 0.90625\n",
      "2018-05-04T21:03:50.126061: step 24523, loss 0.208807, acc 0.90625\n",
      "2018-05-04T21:03:51.418026: step 24524, loss 0.33613, acc 0.890625\n",
      "2018-05-04T21:03:52.606798: step 24525, loss 0.153804, acc 0.953125\n",
      "2018-05-04T21:03:53.790763: step 24526, loss 0.23895, acc 0.90625\n",
      "2018-05-04T21:03:54.996096: step 24527, loss 0.323273, acc 0.859375\n",
      "2018-05-04T21:03:56.227293: step 24528, loss 0.222992, acc 0.890625\n",
      "2018-05-04T21:03:57.335110: step 24529, loss 0.292251, acc 0.890625\n",
      "2018-05-04T21:03:58.546449: step 24530, loss 0.141496, acc 0.953125\n",
      "2018-05-04T21:03:59.687723: step 24531, loss 0.167321, acc 0.921875\n",
      "2018-05-04T21:04:00.814395: step 24532, loss 0.274656, acc 0.875\n",
      "2018-05-04T21:04:02.012353: step 24533, loss 0.183559, acc 0.921875\n",
      "2018-05-04T21:04:03.246549: step 24534, loss 0.211056, acc 0.9375\n",
      "2018-05-04T21:04:04.449060: step 24535, loss 0.137078, acc 0.9375\n",
      "2018-05-04T21:04:05.812988: step 24536, loss 0.280208, acc 0.875\n",
      "2018-05-04T21:04:07.151898: step 24537, loss 0.161435, acc 0.9375\n",
      "2018-05-04T21:04:08.615304: step 24538, loss 0.260437, acc 0.90625\n",
      "2018-05-04T21:04:10.132005: step 24539, loss 0.154102, acc 0.953125\n",
      "2018-05-04T21:04:11.652987: step 24540, loss 0.3212, acc 0.859375\n",
      "2018-05-04T21:04:13.115186: step 24541, loss 0.234522, acc 0.890625\n",
      "2018-05-04T21:04:14.425782: step 24542, loss 0.258583, acc 0.875\n",
      "2018-05-04T21:04:15.742657: step 24543, loss 0.211424, acc 0.890625\n",
      "2018-05-04T21:04:17.078752: step 24544, loss 0.178279, acc 0.921875\n",
      "2018-05-04T21:04:18.371729: step 24545, loss 0.393283, acc 0.84375\n",
      "2018-05-04T21:04:19.796096: step 24546, loss 0.34057, acc 0.859375\n",
      "2018-05-04T21:04:21.189833: step 24547, loss 0.228011, acc 0.890625\n",
      "2018-05-04T21:04:22.512147: step 24548, loss 0.1119, acc 0.96875\n",
      "2018-05-04T21:04:23.764731: step 24549, loss 0.207093, acc 0.921875\n",
      "2018-05-04T21:04:25.051911: step 24550, loss 0.270581, acc 0.859375\n",
      "2018-05-04T21:04:26.581087: step 24551, loss 0.322587, acc 0.90625\n",
      "2018-05-04T21:04:27.857452: step 24552, loss 0.25453, acc 0.890625\n",
      "2018-05-04T21:04:29.143265: step 24553, loss 0.171965, acc 0.953125\n",
      "2018-05-04T21:04:30.261600: step 24554, loss 0.128657, acc 0.96875\n",
      "2018-05-04T21:04:31.455998: step 24555, loss 0.320857, acc 0.859375\n",
      "2018-05-04T21:04:32.630489: step 24556, loss 0.290396, acc 0.90625\n",
      "2018-05-04T21:04:33.751483: step 24557, loss 0.231456, acc 0.9375\n",
      "2018-05-04T21:04:34.850363: step 24558, loss 0.367109, acc 0.796875\n",
      "2018-05-04T21:04:35.968992: step 24559, loss 0.150146, acc 0.921875\n",
      "2018-05-04T21:04:37.206928: step 24560, loss 0.38022, acc 0.8125\n",
      "2018-05-04T21:04:38.381164: step 24561, loss 0.328722, acc 0.859375\n",
      "2018-05-04T21:04:39.539469: step 24562, loss 0.171207, acc 0.921875\n",
      "2018-05-04T21:04:40.711278: step 24563, loss 0.381031, acc 0.890625\n",
      "2018-05-04T21:04:41.961181: step 24564, loss 0.114746, acc 0.96875\n",
      "2018-05-04T21:04:43.141539: step 24565, loss 0.285527, acc 0.9375\n",
      "2018-05-04T21:04:44.290173: step 24566, loss 0.312938, acc 0.859375\n",
      "2018-05-04T21:04:45.370642: step 24567, loss 0.202087, acc 0.90625\n",
      "2018-05-04T21:04:46.434559: step 24568, loss 0.126762, acc 0.953125\n",
      "2018-05-04T21:04:47.501407: step 24569, loss 0.178456, acc 0.953125\n",
      "2018-05-04T21:04:48.550956: step 24570, loss 0.285854, acc 0.890625\n",
      "2018-05-04T21:04:49.632424: step 24571, loss 0.304447, acc 0.859375\n",
      "2018-05-04T21:04:50.692630: step 24572, loss 0.229359, acc 0.875\n",
      "2018-05-04T21:04:51.787590: step 24573, loss 0.214572, acc 0.90625\n",
      "2018-05-04T21:04:52.924376: step 24574, loss 0.309721, acc 0.890625\n",
      "2018-05-04T21:04:54.056319: step 24575, loss 0.12937, acc 0.9375\n",
      "2018-05-04T21:04:55.135459: step 24576, loss 0.250799, acc 0.890625\n",
      "2018-05-04T21:04:56.204630: step 24577, loss 0.176106, acc 0.953125\n",
      "2018-05-04T21:04:57.389532: step 24578, loss 0.261797, acc 0.921875\n",
      "2018-05-04T21:04:58.642103: step 24579, loss 0.188325, acc 0.921875\n",
      "2018-05-04T21:04:59.999990: step 24580, loss 0.383886, acc 0.84375\n",
      "2018-05-04T21:05:01.238630: step 24581, loss 0.2367, acc 0.890625\n",
      "2018-05-04T21:05:02.432994: step 24582, loss 0.255709, acc 0.875\n",
      "2018-05-04T21:05:03.562303: step 24583, loss 0.164123, acc 0.921875\n",
      "2018-05-04T21:05:04.678133: step 24584, loss 0.364444, acc 0.828125\n",
      "2018-05-04T21:05:05.783222: step 24585, loss 0.236274, acc 0.921875\n",
      "2018-05-04T21:05:06.812474: step 24586, loss 0.359152, acc 0.828125\n",
      "2018-05-04T21:05:07.840058: step 24587, loss 0.348181, acc 0.90625\n",
      "2018-05-04T21:05:08.893669: step 24588, loss 0.133488, acc 0.96875\n",
      "2018-05-04T21:05:09.914569: step 24589, loss 0.277686, acc 0.84375\n",
      "2018-05-04T21:05:10.939151: step 24590, loss 0.234105, acc 0.90625\n",
      "2018-05-04T21:05:11.989868: step 24591, loss 0.340446, acc 0.859375\n",
      "2018-05-04T21:05:13.007682: step 24592, loss 0.15072, acc 0.9375\n",
      "2018-05-04T21:05:14.055235: step 24593, loss 0.302062, acc 0.84375\n",
      "2018-05-04T21:05:15.088291: step 24594, loss 0.220656, acc 0.921875\n",
      "2018-05-04T21:05:16.218918: step 24595, loss 0.239483, acc 0.90625\n",
      "2018-05-04T21:05:17.322070: step 24596, loss 0.279688, acc 0.859375\n",
      "2018-05-04T21:05:18.368005: step 24597, loss 0.299286, acc 0.84375\n",
      "2018-05-04T21:05:19.418279: step 24598, loss 0.254616, acc 0.890625\n",
      "2018-05-04T21:05:20.570127: step 24599, loss 0.286482, acc 0.921875\n",
      "2018-05-04T21:05:21.704325: step 24600, loss 0.285029, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T21:05:25.033631: step 24600, loss 0.233, acc 0.92\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-24600\n",
      "\n",
      "2018-05-04T21:05:26.390791: step 24601, loss 0.332752, acc 0.875\n",
      "2018-05-04T21:05:27.761517: step 24602, loss 0.234557, acc 0.890625\n",
      "2018-05-04T21:05:29.018863: step 24603, loss 0.171787, acc 0.9375\n",
      "2018-05-04T21:05:30.269168: step 24604, loss 0.241591, acc 0.890625\n",
      "2018-05-04T21:05:31.652072: step 24605, loss 0.306807, acc 0.875\n",
      "2018-05-04T21:05:32.820548: step 24606, loss 0.430848, acc 0.828125\n",
      "2018-05-04T21:05:34.010177: step 24607, loss 0.277119, acc 0.875\n",
      "2018-05-04T21:05:35.146292: step 24608, loss 0.196519, acc 0.90625\n",
      "2018-05-04T21:05:36.267338: step 24609, loss 0.227631, acc 0.890625\n",
      "2018-05-04T21:05:37.348281: step 24610, loss 0.317222, acc 0.84375\n",
      "2018-05-04T21:05:38.424227: step 24611, loss 0.24691, acc 0.921875\n",
      "2018-05-04T21:05:39.492440: step 24612, loss 0.218293, acc 0.921875\n",
      "2018-05-04T21:05:40.532317: step 24613, loss 0.277719, acc 0.890625\n",
      "2018-05-04T21:05:41.634098: step 24614, loss 0.232714, acc 0.890625\n",
      "2018-05-04T21:05:42.727814: step 24615, loss 0.173267, acc 0.890625\n",
      "2018-05-04T21:05:43.912914: step 24616, loss 0.38684, acc 0.828125\n",
      "2018-05-04T21:05:45.014758: step 24617, loss 0.267304, acc 0.90625\n",
      "2018-05-04T21:05:46.033916: step 24618, loss 0.251525, acc 0.859375\n",
      "2018-05-04T21:05:47.042765: step 24619, loss 0.239597, acc 0.890625\n",
      "2018-05-04T21:05:48.083580: step 24620, loss 0.270532, acc 0.859375\n",
      "2018-05-04T21:05:49.091820: step 24621, loss 0.189554, acc 0.921875\n",
      "2018-05-04T21:05:50.220707: step 24622, loss 0.227777, acc 0.921875\n",
      "2018-05-04T21:05:51.318382: step 24623, loss 0.325536, acc 0.90625\n",
      "2018-05-04T21:05:52.558465: step 24624, loss 0.234921, acc 0.890625\n",
      "2018-05-04T21:05:53.843593: step 24625, loss 0.21184, acc 0.953125\n",
      "2018-05-04T21:05:55.029259: step 24626, loss 0.252626, acc 0.890625\n",
      "2018-05-04T21:05:56.341438: step 24627, loss 0.166679, acc 0.96875\n",
      "2018-05-04T21:05:57.548375: step 24628, loss 0.27652, acc 0.890625\n",
      "2018-05-04T21:05:58.792883: step 24629, loss 0.161699, acc 0.953125\n",
      "2018-05-04T21:05:59.958355: step 24630, loss 0.300896, acc 0.890625\n",
      "2018-05-04T21:06:01.171638: step 24631, loss 0.366865, acc 0.890625\n",
      "2018-05-04T21:06:02.397400: step 24632, loss 0.416784, acc 0.8125\n",
      "2018-05-04T21:06:03.585324: step 24633, loss 0.255588, acc 0.921875\n",
      "2018-05-04T21:06:04.762611: step 24634, loss 0.133804, acc 0.9375\n",
      "2018-05-04T21:06:05.896432: step 24635, loss 0.211525, acc 0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T21:06:06.996878: step 24636, loss 0.309501, acc 0.859375\n",
      "2018-05-04T21:06:08.237128: step 24637, loss 0.217192, acc 0.96875\n",
      "2018-05-04T21:06:09.322955: step 24638, loss 0.334496, acc 0.84375\n",
      "2018-05-04T21:06:10.370915: step 24639, loss 0.285461, acc 0.875\n",
      "2018-05-04T21:06:11.511264: step 24640, loss 0.217044, acc 0.90625\n",
      "2018-05-04T21:06:12.638596: step 24641, loss 0.29501, acc 0.84375\n",
      "2018-05-04T21:06:13.728408: step 24642, loss 0.333705, acc 0.875\n",
      "2018-05-04T21:06:14.942849: step 24643, loss 0.170844, acc 0.953125\n",
      "2018-05-04T21:06:16.160746: step 24644, loss 0.370003, acc 0.890625\n",
      "2018-05-04T21:06:17.434846: step 24645, loss 0.311629, acc 0.890625\n",
      "2018-05-04T21:06:18.744795: step 24646, loss 0.194881, acc 0.921875\n",
      "2018-05-04T21:06:19.979896: step 24647, loss 0.194393, acc 0.9375\n",
      "2018-05-04T21:06:21.425416: step 24648, loss 0.209828, acc 0.921875\n",
      "2018-05-04T21:06:22.734232: step 24649, loss 0.134591, acc 0.9375\n",
      "2018-05-04T21:06:23.888785: step 24650, loss 0.293458, acc 0.875\n",
      "2018-05-04T21:06:25.059612: step 24651, loss 0.408478, acc 0.828125\n",
      "2018-05-04T21:06:26.279747: step 24652, loss 0.293697, acc 0.875\n",
      "2018-05-04T21:06:27.428394: step 24653, loss 0.214429, acc 0.921875\n",
      "2018-05-04T21:06:28.566189: step 24654, loss 0.151195, acc 0.953125\n",
      "2018-05-04T21:06:29.736784: step 24655, loss 0.272401, acc 0.890625\n",
      "2018-05-04T21:06:30.983853: step 24656, loss 0.129805, acc 0.96875\n",
      "2018-05-04T21:06:32.192961: step 24657, loss 0.290086, acc 0.890625\n",
      "2018-05-04T21:06:33.340417: step 24658, loss 0.173226, acc 0.9375\n",
      "2018-05-04T21:06:34.457384: step 24659, loss 0.211943, acc 0.90625\n",
      "2018-05-04T21:06:35.594393: step 24660, loss 0.207911, acc 0.90625\n",
      "2018-05-04T21:06:36.657204: step 24661, loss 0.197381, acc 0.9375\n",
      "2018-05-04T21:06:37.805842: step 24662, loss 0.334084, acc 0.890625\n",
      "2018-05-04T21:06:38.892456: step 24663, loss 0.304432, acc 0.78125\n",
      "2018-05-04T21:06:39.970100: step 24664, loss 0.192415, acc 0.9375\n",
      "2018-05-04T21:06:41.018606: step 24665, loss 0.17375, acc 0.953125\n",
      "2018-05-04T21:06:42.117175: step 24666, loss 0.337136, acc 0.84375\n",
      "2018-05-04T21:06:43.198313: step 24667, loss 0.247646, acc 0.890625\n",
      "2018-05-04T21:06:44.235714: step 24668, loss 0.239578, acc 0.875\n",
      "2018-05-04T21:06:45.386693: step 24669, loss 0.267913, acc 0.890625\n",
      "2018-05-04T21:06:46.487713: step 24670, loss 0.199792, acc 0.9375\n",
      "2018-05-04T21:06:47.532891: step 24671, loss 0.244293, acc 0.890625\n",
      "2018-05-04T21:06:48.601069: step 24672, loss 0.234151, acc 0.90625\n",
      "2018-05-04T21:06:49.706230: step 24673, loss 0.152422, acc 0.921875\n",
      "2018-05-04T21:06:50.753290: step 24674, loss 0.299633, acc 0.859375\n",
      "2018-05-04T21:06:51.925388: step 24675, loss 0.146396, acc 0.9375\n",
      "2018-05-04T21:06:53.046999: step 24676, loss 0.18652, acc 0.9375\n",
      "2018-05-04T21:06:54.212116: step 24677, loss 0.299972, acc 0.859375\n",
      "2018-05-04T21:06:55.258101: step 24678, loss 0.354362, acc 0.859375\n",
      "2018-05-04T21:06:56.279442: step 24679, loss 0.0850165, acc 1\n",
      "2018-05-04T21:06:57.320316: step 24680, loss 0.229673, acc 0.890625\n",
      "2018-05-04T21:06:58.371647: step 24681, loss 0.163014, acc 0.921875\n",
      "2018-05-04T21:06:59.430502: step 24682, loss 0.206982, acc 0.9375\n",
      "2018-05-04T21:07:00.432136: step 24683, loss 0.292588, acc 0.875\n",
      "2018-05-04T21:07:01.511167: step 24684, loss 0.20462, acc 0.90625\n",
      "2018-05-04T21:07:02.683239: step 24685, loss 0.124013, acc 0.96875\n",
      "2018-05-04T21:07:03.746422: step 24686, loss 0.222625, acc 0.890625\n",
      "2018-05-04T21:07:05.009040: step 24687, loss 0.302708, acc 0.875\n",
      "2018-05-04T21:07:06.156409: step 24688, loss 0.0973179, acc 0.984375\n",
      "2018-05-04T21:07:07.326419: step 24689, loss 0.125117, acc 0.953125\n",
      "2018-05-04T21:07:08.573636: step 24690, loss 0.273886, acc 0.84375\n",
      "2018-05-04T21:07:09.746935: step 24691, loss 0.206057, acc 0.90625\n",
      "2018-05-04T21:07:10.956552: step 24692, loss 0.197923, acc 0.890625\n",
      "2018-05-04T21:07:12.165934: step 24693, loss 0.31499, acc 0.90625\n",
      "2018-05-04T21:07:13.494487: step 24694, loss 0.221855, acc 0.921875\n",
      "2018-05-04T21:07:14.624566: step 24695, loss 0.19928, acc 0.921875\n",
      "2018-05-04T21:07:15.688881: step 24696, loss 0.279594, acc 0.875\n",
      "2018-05-04T21:07:16.763679: step 24697, loss 0.286963, acc 0.859375\n",
      "2018-05-04T21:07:17.909109: step 24698, loss 0.168368, acc 0.9375\n",
      "2018-05-04T21:07:19.022913: step 24699, loss 0.379436, acc 0.875\n",
      "2018-05-04T21:07:20.209272: step 24700, loss 0.339522, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T21:07:23.837001: step 24700, loss 0.207113, acc 0.94\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-24700\n",
      "\n",
      "2018-05-04T21:07:25.285527: step 24701, loss 0.381479, acc 0.84375\n",
      "2018-05-04T21:07:26.691113: step 24702, loss 0.242795, acc 0.875\n",
      "2018-05-04T21:07:28.046125: step 24703, loss 0.262784, acc 0.875\n",
      "2018-05-04T21:07:29.396779: step 24704, loss 0.441903, acc 0.796875\n",
      "2018-05-04T21:07:30.784817: step 24705, loss 0.260499, acc 0.90625\n",
      "2018-05-04T21:07:32.187695: step 24706, loss 0.294903, acc 0.875\n",
      "2018-05-04T21:07:33.557647: step 24707, loss 0.2124, acc 0.9375\n",
      "2018-05-04T21:07:34.878038: step 24708, loss 0.137002, acc 0.953125\n",
      "2018-05-04T21:07:36.043121: step 24709, loss 0.281835, acc 0.90625\n",
      "2018-05-04T21:07:37.140162: step 24710, loss 0.251671, acc 0.90625\n",
      "2018-05-04T21:07:38.246535: step 24711, loss 0.283566, acc 0.859375\n",
      "2018-05-04T21:07:39.297134: step 24712, loss 0.180555, acc 0.953125\n",
      "2018-05-04T21:07:40.336365: step 24713, loss 0.279678, acc 0.84375\n",
      "2018-05-04T21:07:41.431485: step 24714, loss 0.170741, acc 0.953125\n",
      "2018-05-04T21:07:42.461639: step 24715, loss 0.221964, acc 0.90625\n",
      "2018-05-04T21:07:43.517121: step 24716, loss 0.288468, acc 0.90625\n",
      "2018-05-04T21:07:44.605234: step 24717, loss 0.264428, acc 0.921875\n",
      "2018-05-04T21:07:45.628923: step 24718, loss 0.319844, acc 0.890625\n",
      "2018-05-04T21:07:46.651534: step 24719, loss 0.277804, acc 0.921875\n",
      "2018-05-04T21:07:47.666693: step 24720, loss 0.239399, acc 0.90625\n",
      "2018-05-04T21:07:48.701361: step 24721, loss 0.311978, acc 0.875\n",
      "2018-05-04T21:07:49.794228: step 24722, loss 0.248617, acc 0.890625\n",
      "2018-05-04T21:07:50.832364: step 24723, loss 0.225774, acc 0.90625\n",
      "2018-05-04T21:07:51.930848: step 24724, loss 0.270936, acc 0.890625\n",
      "2018-05-04T21:07:52.993866: step 24725, loss 0.135016, acc 0.9375\n",
      "2018-05-04T21:07:54.074005: step 24726, loss 0.0984197, acc 0.984375\n",
      "2018-05-04T21:07:55.153236: step 24727, loss 0.281526, acc 0.90625\n",
      "2018-05-04T21:07:56.257008: step 24728, loss 0.289996, acc 0.875\n",
      "2018-05-04T21:07:57.432526: step 24729, loss 0.297055, acc 0.890625\n",
      "2018-05-04T21:07:58.712536: step 24730, loss 0.122499, acc 0.984375\n",
      "2018-05-04T21:07:59.993553: step 24731, loss 0.143846, acc 0.9375\n",
      "2018-05-04T21:08:01.380790: step 24732, loss 0.244617, acc 0.90625\n",
      "2018-05-04T21:08:02.893448: step 24733, loss 0.242009, acc 0.9375\n",
      "2018-05-04T21:08:04.317569: step 24734, loss 0.127639, acc 0.96875\n",
      "2018-05-04T21:08:05.737612: step 24735, loss 0.392636, acc 0.859375\n",
      "2018-05-04T21:08:07.190620: step 24736, loss 0.166015, acc 0.921875\n",
      "2018-05-04T21:08:08.598041: step 24737, loss 0.2076, acc 0.9375\n",
      "2018-05-04T21:08:09.940260: step 24738, loss 0.233431, acc 0.84375\n",
      "2018-05-04T21:08:11.295313: step 24739, loss 0.316891, acc 0.859375\n",
      "2018-05-04T21:08:12.720084: step 24740, loss 0.130529, acc 0.953125\n",
      "2018-05-04T21:08:13.926212: step 24741, loss 0.292386, acc 0.875\n",
      "2018-05-04T21:08:15.241794: step 24742, loss 0.239212, acc 0.890625\n",
      "2018-05-04T21:08:16.518825: step 24743, loss 0.233331, acc 0.921875\n",
      "2018-05-04T21:08:17.816679: step 24744, loss 0.169389, acc 0.9375\n",
      "2018-05-04T21:08:19.064462: step 24745, loss 0.20191, acc 0.890625\n",
      "2018-05-04T21:08:20.385567: step 24746, loss 0.219493, acc 0.953125\n",
      "2018-05-04T21:08:21.650155: step 24747, loss 0.213716, acc 0.921875\n",
      "2018-05-04T21:08:22.958308: step 24748, loss 0.16324, acc 0.9375\n",
      "2018-05-04T21:08:24.272382: step 24749, loss 0.205018, acc 0.875\n",
      "2018-05-04T21:08:25.578550: step 24750, loss 0.156067, acc 0.921875\n",
      "2018-05-04T21:08:26.867002: step 24751, loss 0.329865, acc 0.859375\n",
      "2018-05-04T21:08:28.204400: step 24752, loss 0.341272, acc 0.890625\n",
      "2018-05-04T21:08:29.433836: step 24753, loss 0.151263, acc 0.9375\n",
      "2018-05-04T21:08:30.625656: step 24754, loss 0.153153, acc 0.96875\n",
      "2018-05-04T21:08:32.067248: step 24755, loss 0.207582, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T21:08:33.278012: step 24756, loss 0.302125, acc 0.859375\n",
      "2018-05-04T21:08:34.585003: step 24757, loss 0.184287, acc 0.90625\n",
      "2018-05-04T21:08:35.895596: step 24758, loss 0.168146, acc 0.9375\n",
      "2018-05-04T21:08:37.231091: step 24759, loss 0.176474, acc 0.90625\n",
      "2018-05-04T21:08:38.411637: step 24760, loss 0.226841, acc 0.90625\n",
      "2018-05-04T21:08:39.550564: step 24761, loss 0.252571, acc 0.859375\n",
      "2018-05-04T21:08:40.682578: step 24762, loss 0.121669, acc 0.96875\n",
      "2018-05-04T21:08:41.926615: step 24763, loss 0.357614, acc 0.84375\n",
      "2018-05-04T21:08:43.257129: step 24764, loss 0.14275, acc 0.96875\n",
      "2018-05-04T21:08:44.492476: step 24765, loss 0.37023, acc 0.875\n",
      "2018-05-04T21:08:45.698824: step 24766, loss 0.173888, acc 0.90625\n",
      "2018-05-04T21:08:46.888179: step 24767, loss 0.252295, acc 0.890625\n",
      "2018-05-04T21:08:48.063713: step 24768, loss 0.272928, acc 0.890625\n",
      "2018-05-04T21:08:49.234011: step 24769, loss 0.236286, acc 0.875\n",
      "2018-05-04T21:08:50.430445: step 24770, loss 0.157362, acc 0.9375\n",
      "2018-05-04T21:08:51.627792: step 24771, loss 0.301707, acc 0.890625\n",
      "2018-05-04T21:08:52.871032: step 24772, loss 0.135445, acc 0.9375\n",
      "2018-05-04T21:08:53.994074: step 24773, loss 0.203726, acc 0.890625\n",
      "2018-05-04T21:08:55.228778: step 24774, loss 0.232598, acc 0.921875\n",
      "2018-05-04T21:08:56.346656: step 24775, loss 0.201589, acc 0.921875\n",
      "2018-05-04T21:08:57.466623: step 24776, loss 0.295981, acc 0.890625\n",
      "2018-05-04T21:08:58.677914: step 24777, loss 0.316551, acc 0.890625\n",
      "2018-05-04T21:08:59.922035: step 24778, loss 0.243656, acc 0.921875\n",
      "2018-05-04T21:09:01.169193: step 24779, loss 0.381026, acc 0.859375\n",
      "2018-05-04T21:09:02.487121: step 24780, loss 0.166637, acc 0.953125\n",
      "2018-05-04T21:09:03.697159: step 24781, loss 0.253626, acc 0.875\n",
      "2018-05-04T21:09:04.978941: step 24782, loss 0.437072, acc 0.8125\n",
      "2018-05-04T21:09:06.113530: step 24783, loss 0.282445, acc 0.84375\n",
      "2018-05-04T21:09:07.214645: step 24784, loss 0.392607, acc 0.859375\n",
      "2018-05-04T21:09:08.383673: step 24785, loss 0.155596, acc 0.9375\n",
      "2018-05-04T21:09:09.583371: step 24786, loss 0.24281, acc 0.890625\n",
      "2018-05-04T21:09:10.892275: step 24787, loss 0.284421, acc 0.859375\n",
      "2018-05-04T21:09:12.095760: step 24788, loss 0.257551, acc 0.890625\n",
      "2018-05-04T21:09:13.336978: step 24789, loss 0.392197, acc 0.8125\n",
      "2018-05-04T21:09:14.722768: step 24790, loss 0.215256, acc 0.890625\n",
      "2018-05-04T21:09:16.127401: step 24791, loss 0.180441, acc 0.875\n",
      "2018-05-04T21:09:17.462064: step 24792, loss 0.182813, acc 0.90625\n",
      "2018-05-04T21:09:18.686542: step 24793, loss 0.301879, acc 0.921875\n",
      "2018-05-04T21:09:19.840142: step 24794, loss 0.330868, acc 0.890625\n",
      "2018-05-04T21:09:21.235042: step 24795, loss 0.300277, acc 0.875\n",
      "2018-05-04T21:09:22.499541: step 24796, loss 0.181949, acc 0.9375\n",
      "2018-05-04T21:09:23.775698: step 24797, loss 0.245756, acc 0.859375\n",
      "2018-05-04T21:09:25.079758: step 24798, loss 0.217666, acc 0.9375\n",
      "2018-05-04T21:09:26.441468: step 24799, loss 0.144799, acc 0.984375\n",
      "2018-05-04T21:09:27.721200: step 24800, loss 0.178073, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T21:09:32.418320: step 24800, loss 0.212807, acc 0.922\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-24800\n",
      "\n",
      "2018-05-04T21:09:33.769546: step 24801, loss 0.224064, acc 0.921875\n",
      "2018-05-04T21:09:35.139335: step 24802, loss 0.396936, acc 0.84375\n",
      "2018-05-04T21:09:36.300022: step 24803, loss 0.205086, acc 0.90625\n",
      "2018-05-04T21:09:37.502574: step 24804, loss 0.281692, acc 0.890625\n",
      "2018-05-04T21:09:38.712502: step 24805, loss 0.293882, acc 0.828125\n",
      "2018-05-04T21:09:39.946193: step 24806, loss 0.270345, acc 0.921875\n",
      "2018-05-04T21:09:41.230855: step 24807, loss 0.113943, acc 0.984375\n",
      "2018-05-04T21:09:42.687008: step 24808, loss 0.216026, acc 0.953125\n",
      "2018-05-04T21:09:43.977548: step 24809, loss 0.412364, acc 0.859375\n",
      "2018-05-04T21:09:45.379484: step 24810, loss 0.306809, acc 0.875\n",
      "2018-05-04T21:09:46.628930: step 24811, loss 0.332191, acc 0.90625\n",
      "2018-05-04T21:09:47.809447: step 24812, loss 0.246784, acc 0.890625\n",
      "2018-05-04T21:09:49.038882: step 24813, loss 0.285862, acc 0.90625\n",
      "2018-05-04T21:09:50.322369: step 24814, loss 0.184896, acc 0.90625\n",
      "2018-05-04T21:09:51.658260: step 24815, loss 0.259352, acc 0.875\n",
      "2018-05-04T21:09:52.820896: step 24816, loss 0.452366, acc 0.8125\n",
      "2018-05-04T21:09:53.970689: step 24817, loss 0.196286, acc 0.921875\n",
      "2018-05-04T21:09:55.172844: step 24818, loss 0.220505, acc 0.921875\n",
      "2018-05-04T21:09:56.458834: step 24819, loss 0.198791, acc 0.90625\n",
      "2018-05-04T21:09:57.662312: step 24820, loss 0.236923, acc 0.875\n",
      "2018-05-04T21:09:58.789388: step 24821, loss 0.219958, acc 0.890625\n",
      "2018-05-04T21:09:59.944326: step 24822, loss 0.22053, acc 0.921875\n",
      "2018-05-04T21:10:01.180884: step 24823, loss 0.233376, acc 0.890625\n",
      "2018-05-04T21:10:02.396089: step 24824, loss 0.119315, acc 0.984375\n",
      "2018-05-04T21:10:03.487414: step 24825, loss 0.354636, acc 0.84375\n",
      "2018-05-04T21:10:04.602149: step 24826, loss 0.226627, acc 0.9375\n",
      "2018-05-04T21:10:05.669375: step 24827, loss 0.247687, acc 0.890625\n",
      "2018-05-04T21:10:06.724370: step 24828, loss 0.232535, acc 0.875\n",
      "2018-05-04T21:10:07.748832: step 24829, loss 0.156819, acc 0.90625\n",
      "2018-05-04T21:10:08.775165: step 24830, loss 0.179199, acc 0.921875\n",
      "2018-05-04T21:10:09.904541: step 24831, loss 0.197263, acc 0.921875\n",
      "2018-05-04T21:10:10.941980: step 24832, loss 0.156977, acc 0.9375\n",
      "2018-05-04T21:10:11.993635: step 24833, loss 0.38729, acc 0.8125\n",
      "2018-05-04T21:10:12.999811: step 24834, loss 0.27234, acc 0.875\n",
      "2018-05-04T21:10:14.043003: step 24835, loss 0.167623, acc 0.953125\n",
      "2018-05-04T21:10:15.098221: step 24836, loss 0.138761, acc 0.9375\n",
      "2018-05-04T21:10:16.125729: step 24837, loss 0.238417, acc 0.9375\n",
      "2018-05-04T21:10:17.110396: step 24838, loss 0.133395, acc 0.9375\n",
      "2018-05-04T21:10:18.223448: step 24839, loss 0.483793, acc 0.84375\n",
      "2018-05-04T21:10:19.240691: step 24840, loss 0.208419, acc 0.90625\n",
      "2018-05-04T21:10:20.266260: step 24841, loss 0.430611, acc 0.765625\n",
      "2018-05-04T21:10:21.325075: step 24842, loss 0.225472, acc 0.90625\n",
      "2018-05-04T21:10:22.334041: step 24843, loss 0.140268, acc 0.953125\n",
      "2018-05-04T21:10:23.347197: step 24844, loss 0.301041, acc 0.859375\n",
      "2018-05-04T21:10:24.366213: step 24845, loss 0.323926, acc 0.84375\n",
      "2018-05-04T21:10:25.458839: step 24846, loss 0.195167, acc 0.90625\n",
      "2018-05-04T21:10:26.472728: step 24847, loss 0.343198, acc 0.84375\n",
      "2018-05-04T21:10:27.482613: step 24848, loss 0.358882, acc 0.828125\n",
      "2018-05-04T21:10:28.468172: step 24849, loss 0.3223, acc 0.875\n",
      "2018-05-04T21:10:29.462880: step 24850, loss 0.218446, acc 0.921875\n",
      "2018-05-04T21:10:30.493939: step 24851, loss 0.227174, acc 0.9375\n",
      "2018-05-04T21:10:31.570995: step 24852, loss 0.343764, acc 0.859375\n",
      "2018-05-04T21:10:32.576308: step 24853, loss 0.380304, acc 0.84375\n",
      "2018-05-04T21:10:33.657062: step 24854, loss 0.343995, acc 0.890625\n",
      "2018-05-04T21:10:34.738381: step 24855, loss 0.321971, acc 0.828125\n",
      "2018-05-04T21:10:35.843893: step 24856, loss 0.264531, acc 0.921875\n",
      "2018-05-04T21:10:36.911716: step 24857, loss 0.24224, acc 0.90625\n",
      "2018-05-04T21:10:37.976594: step 24858, loss 0.356117, acc 0.90625\n",
      "2018-05-04T21:10:39.023293: step 24859, loss 0.255912, acc 0.84375\n",
      "2018-05-04T21:10:40.069081: step 24860, loss 0.232294, acc 0.90625\n",
      "2018-05-04T21:10:41.116048: step 24861, loss 0.145126, acc 0.953125\n",
      "2018-05-04T21:10:42.135927: step 24862, loss 0.272142, acc 0.890625\n",
      "2018-05-04T21:10:43.129893: step 24863, loss 0.22975, acc 0.921875\n",
      "2018-05-04T21:10:44.127588: step 24864, loss 0.230219, acc 0.875\n",
      "2018-05-04T21:10:45.231975: step 24865, loss 0.202669, acc 0.90625\n",
      "2018-05-04T21:10:46.230130: step 24866, loss 0.387557, acc 0.84375\n",
      "2018-05-04T21:10:47.228046: step 24867, loss 0.268288, acc 0.828125\n",
      "2018-05-04T21:10:48.233305: step 24868, loss 0.181375, acc 0.9375\n",
      "2018-05-04T21:10:49.273104: step 24869, loss 0.173637, acc 0.921875\n",
      "2018-05-04T21:10:50.318891: step 24870, loss 0.248708, acc 0.90625\n",
      "2018-05-04T21:10:51.405920: step 24871, loss 0.3168, acc 0.890625\n",
      "2018-05-04T21:10:52.432618: step 24872, loss 0.247187, acc 0.921875\n",
      "2018-05-04T21:10:53.450984: step 24873, loss 0.181284, acc 0.921875\n",
      "2018-05-04T21:10:54.513839: step 24874, loss 0.277049, acc 0.84375\n",
      "2018-05-04T21:10:55.565315: step 24875, loss 0.251531, acc 0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T21:10:56.602990: step 24876, loss 0.250882, acc 0.890625\n",
      "2018-05-04T21:10:57.620270: step 24877, loss 0.281877, acc 0.84375\n",
      "2018-05-04T21:10:58.629469: step 24878, loss 0.283128, acc 0.875\n",
      "2018-05-04T21:10:59.735936: step 24879, loss 0.264149, acc 0.90625\n",
      "2018-05-04T21:11:00.920085: step 24880, loss 0.308795, acc 0.90625\n",
      "2018-05-04T21:11:02.149757: step 24881, loss 0.23233, acc 0.921875\n",
      "2018-05-04T21:11:03.436293: step 24882, loss 0.213567, acc 0.890625\n",
      "2018-05-04T21:11:04.711372: step 24883, loss 0.218471, acc 0.875\n",
      "2018-05-04T21:11:06.218311: step 24884, loss 0.195371, acc 0.921875\n",
      "2018-05-04T21:11:07.557770: step 24885, loss 0.128534, acc 0.984375\n",
      "2018-05-04T21:11:08.806665: step 24886, loss 0.153489, acc 0.921875\n",
      "2018-05-04T21:11:10.069825: step 24887, loss 0.177159, acc 0.9375\n",
      "2018-05-04T21:11:11.239359: step 24888, loss 0.416335, acc 0.8125\n",
      "2018-05-04T21:11:12.340482: step 24889, loss 0.176607, acc 0.921875\n",
      "2018-05-04T21:11:13.492274: step 24890, loss 0.249911, acc 0.90625\n",
      "2018-05-04T21:11:14.717625: step 24891, loss 0.246749, acc 0.875\n",
      "2018-05-04T21:11:16.060293: step 24892, loss 0.211506, acc 0.90625\n",
      "2018-05-04T21:11:17.394428: step 24893, loss 0.246172, acc 0.921875\n",
      "2018-05-04T21:11:18.649610: step 24894, loss 0.185027, acc 0.9375\n",
      "2018-05-04T21:11:19.943906: step 24895, loss 0.228243, acc 0.921875\n",
      "2018-05-04T21:11:21.203887: step 24896, loss 0.344591, acc 0.84375\n",
      "2018-05-04T21:11:22.421853: step 24897, loss 0.196284, acc 0.953125\n",
      "2018-05-04T21:11:23.589181: step 24898, loss 0.278637, acc 0.890625\n",
      "2018-05-04T21:11:24.839802: step 24899, loss 0.237721, acc 0.921875\n",
      "2018-05-04T21:11:26.030816: step 24900, loss 0.267894, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T21:11:30.330658: step 24900, loss 0.215846, acc 0.93\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-24900\n",
      "\n",
      "2018-05-04T21:11:31.722446: step 24901, loss 0.178361, acc 0.90625\n",
      "2018-05-04T21:11:32.969071: step 24902, loss 0.244378, acc 0.90625\n",
      "2018-05-04T21:11:34.150783: step 24903, loss 0.238062, acc 0.890625\n",
      "2018-05-04T21:11:35.373405: step 24904, loss 0.196444, acc 0.921875\n",
      "2018-05-04T21:11:36.480948: step 24905, loss 0.272165, acc 0.859375\n",
      "2018-05-04T21:11:37.616394: step 24906, loss 0.233894, acc 0.921875\n",
      "2018-05-04T21:11:38.906775: step 24907, loss 0.205834, acc 0.921875\n",
      "2018-05-04T21:11:40.169349: step 24908, loss 0.333293, acc 0.875\n",
      "2018-05-04T21:11:41.421950: step 24909, loss 0.13148, acc 0.953125\n",
      "2018-05-04T21:11:42.588882: step 24910, loss 0.267731, acc 0.84375\n",
      "2018-05-04T21:11:43.707558: step 24911, loss 0.315022, acc 0.875\n",
      "2018-05-04T21:11:44.822070: step 24912, loss 0.190704, acc 0.9375\n",
      "2018-05-04T21:11:45.983829: step 24913, loss 0.32923, acc 0.859375\n",
      "2018-05-04T21:11:47.089479: step 24914, loss 0.214828, acc 0.9375\n",
      "2018-05-04T21:11:48.160798: step 24915, loss 0.197781, acc 0.921875\n",
      "2018-05-04T21:11:49.372565: step 24916, loss 0.323572, acc 0.84375\n",
      "2018-05-04T21:11:50.414558: step 24917, loss 0.494247, acc 0.8125\n",
      "2018-05-04T21:11:51.517607: step 24918, loss 0.290365, acc 0.859375\n",
      "2018-05-04T21:11:52.579638: step 24919, loss 0.338245, acc 0.796875\n",
      "2018-05-04T21:11:53.623499: step 24920, loss 0.349115, acc 0.890625\n",
      "2018-05-04T21:11:54.654138: step 24921, loss 0.356286, acc 0.90625\n",
      "2018-05-04T21:11:55.764426: step 24922, loss 0.303591, acc 0.890625\n",
      "2018-05-04T21:11:56.837729: step 24923, loss 0.350484, acc 0.859375\n",
      "2018-05-04T21:11:57.932852: step 24924, loss 0.28576, acc 0.875\n",
      "2018-05-04T21:11:58.994504: step 24925, loss 0.257164, acc 0.90625\n",
      "2018-05-04T21:12:00.183840: step 24926, loss 0.249487, acc 0.90625\n",
      "2018-05-04T21:12:01.301819: step 24927, loss 0.170415, acc 0.953125\n",
      "2018-05-04T21:12:02.345683: step 24928, loss 0.154736, acc 0.9375\n",
      "2018-05-04T21:12:03.390575: step 24929, loss 0.366697, acc 0.890625\n",
      "2018-05-04T21:12:04.581166: step 24930, loss 0.363122, acc 0.84375\n",
      "2018-05-04T21:12:05.697002: step 24931, loss 0.145722, acc 0.953125\n",
      "2018-05-04T21:12:06.730598: step 24932, loss 0.314574, acc 0.875\n",
      "2018-05-04T21:12:07.791719: step 24933, loss 0.154046, acc 0.9375\n",
      "2018-05-04T21:12:08.911736: step 24934, loss 0.175999, acc 0.9375\n",
      "2018-05-04T21:12:09.921169: step 24935, loss 0.280898, acc 0.875\n",
      "2018-05-04T21:12:10.941163: step 24936, loss 0.296101, acc 0.84375\n",
      "2018-05-04T21:12:12.014497: step 24937, loss 0.225209, acc 0.921875\n",
      "2018-05-04T21:12:13.042240: step 24938, loss 0.424394, acc 0.78125\n",
      "2018-05-04T21:12:14.185458: step 24939, loss 0.275574, acc 0.859375\n",
      "2018-05-04T21:12:15.282689: step 24940, loss 0.158773, acc 0.953125\n",
      "2018-05-04T21:12:16.317884: step 24941, loss 0.222452, acc 0.875\n",
      "2018-05-04T21:12:17.468744: step 24942, loss 0.382418, acc 0.8125\n",
      "2018-05-04T21:12:18.517494: step 24943, loss 0.183149, acc 0.9375\n",
      "2018-05-04T21:12:19.549518: step 24944, loss 0.407997, acc 0.84375\n",
      "2018-05-04T21:12:20.666847: step 24945, loss 0.207783, acc 0.90625\n",
      "2018-05-04T21:12:21.770022: step 24946, loss 0.271527, acc 0.90625\n",
      "2018-05-04T21:12:22.909208: step 24947, loss 0.2504, acc 0.921875\n",
      "2018-05-04T21:12:23.995709: step 24948, loss 0.186345, acc 0.890625\n",
      "2018-05-04T21:12:25.081098: step 24949, loss 0.137141, acc 0.96875\n",
      "2018-05-04T21:12:26.177990: step 24950, loss 0.285972, acc 0.890625\n",
      "2018-05-04T21:12:27.255048: step 24951, loss 0.171982, acc 0.9375\n",
      "2018-05-04T21:12:28.390335: step 24952, loss 0.26347, acc 0.875\n",
      "2018-05-04T21:12:29.523902: step 24953, loss 0.331016, acc 0.84375\n",
      "2018-05-04T21:12:30.605273: step 24954, loss 0.14472, acc 0.9375\n",
      "2018-05-04T21:12:31.796137: step 24955, loss 0.208964, acc 0.9375\n",
      "2018-05-04T21:12:33.026679: step 24956, loss 0.210654, acc 0.921875\n",
      "2018-05-04T21:12:34.212562: step 24957, loss 0.235416, acc 0.921875\n",
      "2018-05-04T21:12:35.330857: step 24958, loss 0.144515, acc 0.9375\n",
      "2018-05-04T21:12:36.397495: step 24959, loss 0.195589, acc 0.90625\n",
      "2018-05-04T21:12:37.506743: step 24960, loss 0.207715, acc 0.953125\n",
      "2018-05-04T21:12:38.571882: step 24961, loss 0.240308, acc 0.96875\n",
      "2018-05-04T21:12:39.631464: step 24962, loss 0.31515, acc 0.875\n",
      "2018-05-04T21:12:40.729900: step 24963, loss 0.234725, acc 0.890625\n",
      "2018-05-04T21:12:41.930831: step 24964, loss 0.325183, acc 0.828125\n",
      "2018-05-04T21:12:43.082423: step 24965, loss 0.173659, acc 0.9375\n",
      "2018-05-04T21:12:44.228323: step 24966, loss 0.147768, acc 0.90625\n",
      "2018-05-04T21:12:45.400619: step 24967, loss 0.146783, acc 0.953125\n",
      "2018-05-04T21:12:46.409080: step 24968, loss 0.379408, acc 0.84375\n",
      "2018-05-04T21:12:47.494903: step 24969, loss 0.272976, acc 0.859375\n",
      "2018-05-04T21:12:48.577949: step 24970, loss 0.267228, acc 0.90625\n",
      "2018-05-04T21:12:49.653189: step 24971, loss 0.193799, acc 0.9375\n",
      "2018-05-04T21:12:50.748266: step 24972, loss 0.348986, acc 0.859375\n",
      "2018-05-04T21:12:51.883935: step 24973, loss 0.31896, acc 0.875\n",
      "2018-05-04T21:12:52.971923: step 24974, loss 0.200158, acc 0.921875\n",
      "2018-05-04T21:12:54.204671: step 24975, loss 0.220272, acc 0.921875\n",
      "2018-05-04T21:12:55.279451: step 24976, loss 0.273242, acc 0.890625\n",
      "2018-05-04T21:12:56.414607: step 24977, loss 0.240167, acc 0.921875\n",
      "2018-05-04T21:12:57.486546: step 24978, loss 0.177187, acc 0.9375\n",
      "2018-05-04T21:12:58.495453: step 24979, loss 0.258282, acc 0.875\n",
      "2018-05-04T21:12:59.584448: step 24980, loss 0.259426, acc 0.9375\n",
      "2018-05-04T21:13:00.600081: step 24981, loss 0.271339, acc 0.9375\n",
      "2018-05-04T21:13:01.755136: step 24982, loss 0.263934, acc 0.890625\n",
      "2018-05-04T21:13:02.807861: step 24983, loss 0.30321, acc 0.859375\n",
      "2018-05-04T21:13:03.825308: step 24984, loss 0.188186, acc 0.9375\n",
      "2018-05-04T21:13:04.871294: step 24985, loss 0.296472, acc 0.90625\n",
      "2018-05-04T21:13:05.985359: step 24986, loss 0.23587, acc 0.921875\n",
      "2018-05-04T21:13:07.193265: step 24987, loss 0.281585, acc 0.921875\n",
      "2018-05-04T21:13:08.366793: step 24988, loss 0.290689, acc 0.875\n",
      "2018-05-04T21:13:09.547563: step 24989, loss 0.281615, acc 0.890625\n",
      "2018-05-04T21:13:10.690467: step 24990, loss 0.208246, acc 0.921875\n",
      "2018-05-04T21:13:11.914661: step 24991, loss 0.235349, acc 0.90625\n",
      "2018-05-04T21:13:13.064392: step 24992, loss 0.202463, acc 0.90625\n",
      "2018-05-04T21:13:14.157622: step 24993, loss 0.313761, acc 0.875\n",
      "2018-05-04T21:13:15.325563: step 24994, loss 0.451861, acc 0.859375\n",
      "2018-05-04T21:13:16.529429: step 24995, loss 0.377227, acc 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T21:13:17.717647: step 24996, loss 0.188006, acc 0.921875\n",
      "2018-05-04T21:13:18.891596: step 24997, loss 0.321762, acc 0.875\n",
      "2018-05-04T21:13:20.083525: step 24998, loss 0.41351, acc 0.8125\n",
      "2018-05-04T21:13:21.379193: step 24999, loss 0.184668, acc 0.921875\n",
      "2018-05-04T21:13:22.663488: step 25000, loss 0.180064, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T21:13:25.957027: step 25000, loss 0.221263, acc 0.926\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-25000\n",
      "\n",
      "2018-05-04T21:13:27.213984: step 25001, loss 0.229101, acc 0.890625\n",
      "2018-05-04T21:13:28.362549: step 25002, loss 0.221929, acc 0.890625\n",
      "2018-05-04T21:13:29.540928: step 25003, loss 0.303943, acc 0.84375\n",
      "2018-05-04T21:13:30.701788: step 25004, loss 0.242015, acc 0.90625\n",
      "2018-05-04T21:13:31.920062: step 25005, loss 0.308892, acc 0.875\n",
      "2018-05-04T21:13:33.062666: step 25006, loss 0.279029, acc 0.90625\n",
      "2018-05-04T21:13:34.148728: step 25007, loss 0.191972, acc 0.9375\n",
      "2018-05-04T21:13:35.366264: step 25008, loss 0.303212, acc 0.890625\n",
      "2018-05-04T21:13:36.493358: step 25009, loss 0.256348, acc 0.890625\n",
      "2018-05-04T21:13:37.590910: step 25010, loss 0.234725, acc 0.875\n",
      "2018-05-04T21:13:38.695391: step 25011, loss 0.26653, acc 0.921875\n",
      "2018-05-04T21:13:39.759261: step 25012, loss 0.307982, acc 0.859375\n",
      "2018-05-04T21:13:40.844146: step 25013, loss 0.205121, acc 0.890625\n",
      "2018-05-04T21:13:41.965315: step 25014, loss 0.141379, acc 0.96875\n",
      "2018-05-04T21:13:43.104318: step 25015, loss 0.302757, acc 0.875\n",
      "2018-05-04T21:13:44.239591: step 25016, loss 0.341026, acc 0.90625\n",
      "2018-05-04T21:13:45.329988: step 25017, loss 0.250334, acc 0.875\n",
      "2018-05-04T21:13:46.436442: step 25018, loss 0.214918, acc 0.890625\n",
      "2018-05-04T21:13:47.653641: step 25019, loss 0.220191, acc 0.921875\n",
      "2018-05-04T21:13:48.769988: step 25020, loss 0.17695, acc 0.90625\n",
      "2018-05-04T21:13:49.855034: step 25021, loss 0.406894, acc 0.828125\n",
      "2018-05-04T21:13:50.913830: step 25022, loss 0.381997, acc 0.828125\n",
      "2018-05-04T21:13:52.148564: step 25023, loss 0.219891, acc 0.890625\n",
      "2018-05-04T21:13:53.233329: step 25024, loss 0.300386, acc 0.84375\n",
      "2018-05-04T21:13:54.390162: step 25025, loss 0.246245, acc 0.90625\n",
      "2018-05-04T21:13:55.477865: step 25026, loss 0.528833, acc 0.8125\n",
      "2018-05-04T21:13:56.591770: step 25027, loss 0.153725, acc 0.953125\n",
      "2018-05-04T21:13:57.717234: step 25028, loss 0.158525, acc 0.9375\n",
      "2018-05-04T21:13:58.850046: step 25029, loss 0.206376, acc 0.921875\n",
      "2018-05-04T21:14:00.054464: step 25030, loss 0.228522, acc 0.921875\n",
      "2018-05-04T21:14:01.201479: step 25031, loss 0.140604, acc 0.953125\n",
      "2018-05-04T21:14:02.312094: step 25032, loss 0.318657, acc 0.859375\n",
      "2018-05-04T21:14:03.430703: step 25033, loss 0.22618, acc 0.90625\n",
      "2018-05-04T21:14:04.639934: step 25034, loss 0.217204, acc 0.9375\n",
      "2018-05-04T21:14:05.748155: step 25035, loss 0.151025, acc 0.9375\n",
      "2018-05-04T21:14:06.849262: step 25036, loss 0.238968, acc 0.890625\n",
      "2018-05-04T21:14:07.974103: step 25037, loss 0.215754, acc 0.921875\n",
      "2018-05-04T21:14:09.125030: step 25038, loss 0.198546, acc 0.90625\n",
      "2018-05-04T21:14:10.287554: step 25039, loss 0.316229, acc 0.859375\n",
      "2018-05-04T21:14:11.465376: step 25040, loss 0.144855, acc 0.96875\n",
      "2018-05-04T21:14:12.619303: step 25041, loss 0.193602, acc 0.890625\n",
      "2018-05-04T21:14:13.820700: step 25042, loss 0.157246, acc 0.953125\n",
      "2018-05-04T21:14:14.957693: step 25043, loss 0.19176, acc 0.90625\n",
      "2018-05-04T21:14:16.078963: step 25044, loss 0.175694, acc 0.953125\n",
      "2018-05-04T21:14:17.220891: step 25045, loss 0.213592, acc 0.90625\n",
      "2018-05-04T21:14:18.497630: step 25046, loss 0.203739, acc 0.953125\n",
      "2018-05-04T21:14:19.620868: step 25047, loss 0.303593, acc 0.859375\n",
      "2018-05-04T21:14:20.705973: step 25048, loss 0.246779, acc 0.921875\n",
      "2018-05-04T21:14:21.898367: step 25049, loss 0.180152, acc 0.9375\n",
      "2018-05-04T21:14:23.102488: step 25050, loss 0.401654, acc 0.859375\n",
      "2018-05-04T21:14:24.238040: step 25051, loss 0.220762, acc 0.890625\n",
      "2018-05-04T21:14:25.343674: step 25052, loss 0.255458, acc 0.890625\n",
      "2018-05-04T21:14:26.496054: step 25053, loss 0.304859, acc 0.890625\n",
      "2018-05-04T21:14:27.663910: step 25054, loss 0.313294, acc 0.890625\n",
      "2018-05-04T21:14:28.821273: step 25055, loss 0.400988, acc 0.8125\n",
      "2018-05-04T21:14:29.899427: step 25056, loss 0.200726, acc 0.90625\n",
      "2018-05-04T21:14:31.014520: step 25057, loss 0.487607, acc 0.859375\n",
      "2018-05-04T21:14:32.199639: step 25058, loss 0.209402, acc 0.875\n",
      "2018-05-04T21:14:33.284673: step 25059, loss 0.180535, acc 0.90625\n",
      "2018-05-04T21:14:34.372154: step 25060, loss 0.249237, acc 0.859375\n",
      "2018-05-04T21:14:35.396897: step 25061, loss 0.173991, acc 0.9375\n",
      "2018-05-04T21:14:36.404467: step 25062, loss 0.326773, acc 0.8125\n",
      "2018-05-04T21:14:37.408015: step 25063, loss 0.221443, acc 0.921875\n",
      "2018-05-04T21:14:38.475001: step 25064, loss 0.444439, acc 0.859375\n",
      "2018-05-04T21:14:39.557169: step 25065, loss 0.142655, acc 0.96875\n",
      "2018-05-04T21:14:40.606829: step 25066, loss 0.233358, acc 0.90625\n",
      "2018-05-04T21:14:41.726327: step 25067, loss 0.264015, acc 0.90625\n",
      "2018-05-04T21:14:42.758475: step 25068, loss 0.311501, acc 0.90625\n",
      "2018-05-04T21:14:43.845975: step 25069, loss 0.290067, acc 0.84375\n",
      "2018-05-04T21:14:44.850319: step 25070, loss 0.320418, acc 0.84375\n",
      "2018-05-04T21:14:45.958429: step 25071, loss 0.170491, acc 0.9375\n",
      "2018-05-04T21:14:47.036653: step 25072, loss 0.248658, acc 0.921875\n",
      "2018-05-04T21:14:48.143316: step 25073, loss 0.141448, acc 0.953125\n",
      "2018-05-04T21:14:49.255437: step 25074, loss 0.373337, acc 0.84375\n",
      "2018-05-04T21:14:50.344980: step 25075, loss 0.28334, acc 0.890625\n",
      "2018-05-04T21:14:51.429929: step 25076, loss 0.217391, acc 0.9375\n",
      "2018-05-04T21:14:52.543380: step 25077, loss 0.223898, acc 0.875\n",
      "2018-05-04T21:14:53.588136: step 25078, loss 0.285564, acc 0.859375\n",
      "2018-05-04T21:14:54.622333: step 25079, loss 0.493147, acc 0.796875\n",
      "2018-05-04T21:14:55.764536: step 25080, loss 0.197283, acc 0.875\n",
      "2018-05-04T21:14:56.839195: step 25081, loss 0.169826, acc 0.9375\n",
      "2018-05-04T21:14:57.922662: step 25082, loss 0.361071, acc 0.84375\n",
      "2018-05-04T21:14:58.975224: step 25083, loss 0.170972, acc 0.953125\n",
      "2018-05-04T21:14:59.994052: step 25084, loss 0.185909, acc 0.90625\n",
      "2018-05-04T21:15:01.067280: step 25085, loss 0.201827, acc 0.9375\n",
      "2018-05-04T21:15:02.133392: step 25086, loss 0.232458, acc 0.890625\n",
      "2018-05-04T21:15:03.142074: step 25087, loss 0.199064, acc 0.90625\n",
      "2018-05-04T21:15:04.166479: step 25088, loss 0.37564, acc 0.828125\n",
      "2018-05-04T21:15:05.207581: step 25089, loss 0.32326, acc 0.859375\n",
      "2018-05-04T21:15:06.218103: step 25090, loss 0.206016, acc 0.953125\n",
      "2018-05-04T21:15:07.238568: step 25091, loss 0.176381, acc 0.90625\n",
      "2018-05-04T21:15:08.434744: step 25092, loss 0.340361, acc 0.90625\n",
      "2018-05-04T21:15:09.572195: step 25093, loss 0.274802, acc 0.921875\n",
      "2018-05-04T21:15:10.632772: step 25094, loss 0.280995, acc 0.890625\n",
      "2018-05-04T21:15:11.805113: step 25095, loss 0.182619, acc 0.921875\n",
      "2018-05-04T21:15:12.869324: step 25096, loss 0.18628, acc 0.890625\n",
      "2018-05-04T21:15:13.927080: step 25097, loss 0.223596, acc 0.90625\n",
      "2018-05-04T21:15:15.076552: step 25098, loss 0.167796, acc 0.953125\n",
      "2018-05-04T21:15:16.211311: step 25099, loss 0.243124, acc 0.90625\n",
      "2018-05-04T21:15:17.356799: step 25100, loss 0.342331, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-04T21:15:20.133089: step 25100, loss 0.228969, acc 0.92\n",
      "\n",
      "Saved model checkpoint to /Users/tdual/Workspace/char_level_cnn/runs/1525408577/checkpoints/model-25100\n",
      "\n",
      "2018-05-04T21:15:21.523507: step 25101, loss 0.283326, acc 0.875\n",
      "2018-05-04T21:15:22.777062: step 25102, loss 0.251618, acc 0.859375\n",
      "2018-05-04T21:15:24.125517: step 25103, loss 0.192589, acc 0.921875\n",
      "2018-05-04T21:15:25.384518: step 25104, loss 0.238928, acc 0.953125\n",
      "2018-05-04T21:15:26.637231: step 25105, loss 0.253581, acc 0.859375\n",
      "2018-05-04T21:15:27.881057: step 25106, loss 0.195103, acc 0.90625\n",
      "2018-05-04T21:15:29.122414: step 25107, loss 0.300844, acc 0.890625\n",
      "2018-05-04T21:15:30.370159: step 25108, loss 0.19299, acc 0.953125\n",
      "2018-05-04T21:15:31.691984: step 25109, loss 0.313373, acc 0.890625\n",
      "2018-05-04T21:15:32.866844: step 25110, loss 0.250703, acc 0.890625\n",
      "2018-05-04T21:15:34.072115: step 25111, loss 0.254939, acc 0.890625\n",
      "2018-05-04T21:15:35.268411: step 25112, loss 0.359369, acc 0.84375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04T21:15:36.479995: step 25113, loss 0.288296, acc 0.859375\n",
      "2018-05-04T21:15:37.652737: step 25114, loss 0.226155, acc 0.890625\n",
      "2018-05-04T21:15:38.883233: step 25115, loss 0.131004, acc 0.921875\n",
      "2018-05-04T21:15:40.112764: step 25116, loss 0.175734, acc 0.9375\n",
      "2018-05-04T21:15:41.363654: step 25117, loss 0.244875, acc 0.890625\n",
      "2018-05-04T21:15:42.568466: step 25118, loss 0.288205, acc 0.9375\n",
      "2018-05-04T21:15:43.782499: step 25119, loss 0.194052, acc 0.9375\n",
      "2018-05-04T21:15:44.992977: step 25120, loss 0.213953, acc 0.921875\n",
      "2018-05-04T21:15:46.290843: step 25121, loss 0.239416, acc 0.90625\n",
      "2018-05-04T21:15:47.490114: step 25122, loss 0.20018, acc 0.90625\n",
      "2018-05-04T21:15:48.717566: step 25123, loss 0.374468, acc 0.90625\n",
      "2018-05-04T21:15:49.967454: step 25124, loss 0.14151, acc 0.921875\n",
      "2018-05-04T21:15:51.332798: step 25125, loss 0.175888, acc 0.921875\n",
      "2018-05-04T21:15:52.786114: step 25126, loss 0.25964, acc 0.90625\n",
      "2018-05-04T21:15:54.184159: step 25127, loss 0.290421, acc 0.90625\n",
      "2018-05-04T21:15:55.529500: step 25128, loss 0.226109, acc 0.90625\n",
      "2018-05-04T21:15:56.927669: step 25129, loss 0.152314, acc 0.9375\n",
      "2018-05-04T21:15:58.322812: step 25130, loss 0.39364, acc 0.796875\n",
      "2018-05-04T21:15:59.720315: step 25131, loss 0.463196, acc 0.828125\n",
      "2018-05-04T21:16:01.258266: step 25132, loss 0.205964, acc 0.90625\n",
      "2018-05-04T21:16:02.603254: step 25133, loss 0.276506, acc 0.921875\n",
      "2018-05-04T21:16:03.981599: step 25134, loss 0.276229, acc 0.890625\n",
      "2018-05-04T21:16:05.426841: step 25135, loss 0.23173, acc 0.90625\n",
      "2018-05-04T21:16:06.717269: step 25136, loss 0.339579, acc 0.859375\n",
      "2018-05-04T21:16:07.974420: step 25137, loss 0.278164, acc 0.859375\n",
      "2018-05-04T21:16:09.202148: step 25138, loss 0.187512, acc 0.9375\n",
      "2018-05-04T21:16:10.600407: step 25139, loss 0.227176, acc 0.890625\n",
      "2018-05-04T21:16:12.237379: step 25140, loss 0.394556, acc 0.859375\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    session_conf = tf.ConfigProto(\n",
    "      allow_soft_placement=allow_soft_placement,\n",
    "      log_device_placement=log_device_placement)\n",
    "    sess = tf.Session(config=session_conf)\n",
    "    \n",
    "    with sess.as_default():\n",
    "        \n",
    "        cnn = TextCNN(sequence_length, num_classes, vocab_size, embedding_size, filter_sizes, num_filters, l2_reg_lambda)\n",
    "\n",
    "\n",
    "        global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "        optimizer = tf.train.AdamOptimizer(1e-3)\n",
    "        grads_and_vars = optimizer.compute_gradients(cnn.loss)\n",
    "        train_op = optimizer.apply_gradients(grads_and_vars, global_step=global_step)\n",
    "\n",
    "\n",
    "        grad_summaries = []\n",
    "        for g, v in grads_and_vars:\n",
    "            if g is not None:\n",
    "                grad_hist_summary = tf.summary.histogram(\"{}/grad/hist\".format(v.name), g)\n",
    "                sparsity_summary = tf.summary.scalar(\"{}/grad/sparsity\".format(v.name), tf.nn.zero_fraction(g))\n",
    "                grad_summaries.append(grad_hist_summary)\n",
    "                grad_summaries.append(sparsity_summary)\n",
    "        grad_summaries_merged = tf.summary.merge(grad_summaries)\n",
    "\n",
    "\n",
    "        timestamp = str(int(time.time()))\n",
    "        out_dir = os.path.abspath(os.path.join(os.path.curdir, \"runs\", timestamp))\n",
    "        print(\"Writing to {}\\n\".format(out_dir))\n",
    "\n",
    "\n",
    "        loss_summary = tf.summary.scalar(\"loss\", cnn.loss)\n",
    "        acc_summary = tf.summary.scalar(\"accuracy\", cnn.accuracy)\n",
    "\n",
    "\n",
    "        train_summary_op = tf.summary.merge([loss_summary, acc_summary, grad_summaries_merged])\n",
    "        train_summary_dir = os.path.join(out_dir, \"summaries\", \"train\")\n",
    "        train_summary_writer = tf.summary.FileWriter(train_summary_dir, sess.graph)\n",
    "\n",
    "\n",
    "        dev_summary_op = tf.summary.merge([loss_summary, acc_summary])\n",
    "        dev_summary_dir = os.path.join(out_dir, \"summaries\", \"dev\")\n",
    "        dev_summary_writer = tf.summary.FileWriter(dev_summary_dir, sess.graph)\n",
    "\n",
    "        if save_checkpoint:\n",
    "            checkpoint_dir = os.path.abspath(os.path.join(out_dir, \"checkpoints\"))\n",
    "            checkpoint_prefix = os.path.join(checkpoint_dir, \"model\")\n",
    "            if not os.path.exists(checkpoint_dir):\n",
    "                os.makedirs(checkpoint_dir)\n",
    "            saver = tf.train.Saver(tf.global_variables(), max_to_keep=num_checkpoints)\n",
    "\n",
    "  \n",
    "        vocab_processor.save(os.path.join(out_dir, \"vocab\"))\n",
    "\n",
    "\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        def train_step(x_batch, y_batch):\n",
    "            \"\"\"\n",
    "            A single training step\n",
    "            \"\"\"\n",
    "            feed_dict = {\n",
    "              cnn.input_x: x_batch,\n",
    "              cnn.input_y: y_batch,\n",
    "              cnn.dropout_keep_prob: dropout_keep_prob\n",
    "            }\n",
    "            _, step, summaries, loss, accuracy = sess.run(\n",
    "                [train_op, global_step, train_summary_op, cnn.loss, cnn.accuracy],\n",
    "                feed_dict)\n",
    "            time_str = datetime.datetime.now().isoformat()\n",
    "            print(\"{}: step {}, loss {:g}, acc {:g}\".format(time_str, step, loss, accuracy))\n",
    "            train_summary_writer.add_summary(summaries, step)\n",
    "\n",
    "        def dev_step(x_batch, y_batch, writer=None):\n",
    "            \"\"\"\n",
    "            Evaluates model on a dev set\n",
    "            \"\"\"\n",
    "            feed_dict = {\n",
    "              cnn.input_x: x_batch,\n",
    "              cnn.input_y: y_batch,\n",
    "              cnn.dropout_keep_prob: 1.0\n",
    "            }\n",
    "            step, summaries, loss, accuracy = sess.run(\n",
    "                [global_step, dev_summary_op, cnn.loss, cnn.accuracy],\n",
    "                feed_dict)\n",
    "            time_str = datetime.datetime.now().isoformat()\n",
    "            print(\"{}: step {}, loss {:g}, acc {:g}\".format(time_str, step, loss, accuracy))\n",
    "            if writer:\n",
    "                writer.add_summary(summaries, step)\n",
    "\n",
    "\n",
    "        batches = batch_iter(list(zip(x_train, y_train)), batch_size, num_epochs)\n",
    "        for batch in batches:\n",
    "            x_batch, y_batch = zip(*batch)\n",
    "            train_step(x_batch, y_batch)\n",
    "            current_step = tf.train.global_step(sess, global_step)\n",
    "            \n",
    "            if current_step % evaluate_every == 0:\n",
    "                print(\"\\nEvaluation:\")\n",
    "                dev_step(x_dev, y_dev, writer=dev_summary_writer)\n",
    "                print(\"\")\n",
    "                \n",
    "            if save_checkpoint and current_step % evaluate_every == 0:\n",
    "                path = saver.save(sess, checkpoint_prefix, global_step=current_step)\n",
    "                print(\"Saved model checkpoint to {}\\n\".format(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "char level cnn \n",
    "- 1525408577  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using clean_str  \n",
    "```\n",
    "Evaluation:\n",
    "2018-04-17T10:40:20.162299: step 5000, loss 0.161694, acc 0.942\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.train.get_checkpoint_state('./runs/1523936751/checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(x):\n",
    "    with tf.Graph().as_default():\n",
    "        session_conf = tf.ConfigProto(\n",
    "          allow_soft_placement=allow_soft_placement,\n",
    "          log_device_placement=log_device_placement)\n",
    "        sess = tf.Session(config=session_conf)\n",
    "        with sess.as_default():\n",
    "            cnn = TextCNN(\n",
    "                sequence_length=x_train.shape[1],\n",
    "                num_classes=y_train.shape[1],\n",
    "                vocab_size=len(vocab_processor.vocabulary_),\n",
    "                embedding_size=embedding_dim,\n",
    "                filter_sizes=list(map(int, filter_sizes.split(\",\"))),\n",
    "                num_filters=num_filters,\n",
    "                l2_reg_lambda=l2_reg_lambda)\n",
    "\n",
    "            saver = tf.train.Saver()\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            saver.restore(sess, \"./runs/1523936751/checkpoints/model-77900\")\n",
    "\n",
    "            feed_dict = {\n",
    "                  cnn.input_x: x,\n",
    "                  cnn.dropout_keep_prob: 1.0\n",
    "                }\n",
    "            feature_5, feature_2 = sess.run([cnn.f_h, cnn.scores ], feed_dict=feed_dict)\n",
    "    return feature_5, feature_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = list(open(\"data/amazon/rating_5.txt\", \"r\").readlines())\n",
    "review = [s.strip().split(\"\") for s in review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "x = []\n",
    "for r in review:\n",
    "    l = r.split(\":::::\")\n",
    "    y.append(float(l[0]))\n",
    "    x.append(l[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_processor = preprocessing.VocabularyProcessor.restore(os.path.join(\"runs/1523936751\", \"vocab\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(list(vocab_processor.fit_transform(x)))\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_5 ,feature_2 = get_feature(x[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_5[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_5[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0\n",
    "chunk_size = 100\n",
    "for i in range(chunk_size, len(x)+chunk_size , chunk_size):\n",
    "    feature_5 ,feature_2 = get_feature(x[:i])\n",
    "    for f,r in zip(feature_5, y[:i]):\n",
    "        s  += int(np.argmax(f) == r)\n",
    "    print(s)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(feature_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_2 [0]  #[neg, pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_py3.6)",
   "language": "python",
   "name": "conda_py3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
