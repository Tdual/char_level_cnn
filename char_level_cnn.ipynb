{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset  \n",
    "- amazon review\n",
    "http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Books_5.json.gz\n",
    "\n",
    "- chABSA\n",
    "https://github.com/chakki-works/chABSA-dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/ShopRunner/jupyter-notify\n",
    "```\n",
    "pip install jupyternotify\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "install mecab and neologd if you use Japanese.\n",
    "\n",
    "install mecab on mac\n",
    "```\n",
    "brew install mecab mecab-ipadic  \n",
    "pip install mecab-python3\n",
    "```\n",
    "install neologd\n",
    "```\n",
    "git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git\n",
    "cd mecab-ipadic-neologd\n",
    "./bin/install-mecab-ipadic-neologd -n\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get -q -y install sudo file mecab libmecab-dev mecab-ipadic-utf8 git curl python-mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo yes | mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mecab-python3 tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from tensorflow.contrib.learn import preprocessing\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from numpy.random import choice, randint\n",
    "import MeCab\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext jupyternotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN:\n",
    "\n",
    "    def __init__(\n",
    "        self, sequence_length, num_classes, vocab_size, embedding_size, \n",
    "        filter_sizes, num_filters, l2_reg_lambda=0.0):\n",
    "        print(\"# classes\", num_classes)\n",
    "\n",
    "\n",
    "        self.input_x = tf.placeholder(tf.int32, [None, sequence_length], name=\"input_x\")\n",
    "        self.input_y = tf.placeholder(tf.float32, [None, num_classes], name=\"input_y\")\n",
    "        self.dropout_keep_prob = tf.placeholder(tf.float32, name=\"dropout_keep_prob\")\n",
    "        self.loss_weight = tf.placeholder(tf.float32, name=\"loss_ratio\")\n",
    "\n",
    "        l2_loss = tf.constant(0.0)\n",
    "\n",
    "\n",
    "        with tf.device('/cpu:0'), tf.name_scope(\"embedding\"):\n",
    "            self.W = tf.Variable(tf.random_uniform([vocab_size, embedding_size], -1.0, 1.0), name=\"W\")\n",
    "            self.embedded_chars = tf.nn.embedding_lookup(self.W, self.input_x)\n",
    "            self.embedded_chars_expanded = tf.expand_dims(self.embedded_chars, -1)\n",
    "\n",
    " \n",
    "        pooled_outputs = []\n",
    "        for i, filter_size in enumerate(filter_sizes):\n",
    "            with tf.name_scope(\"conv-maxpool-%s\" % filter_size):\n",
    "                filter_shape = [filter_size, embedding_size, 1, num_filters]\n",
    "                W = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.1), name=\"W\")\n",
    "                b = tf.Variable(tf.constant(0.1, shape=[num_filters]), name=\"b\")\n",
    "                conv = tf.nn.conv2d(self.embedded_chars_expanded,W,strides=[1, 1, 1, 1],padding=\"VALID\", name=\"conv\")\n",
    "                bn_conv = self.batch_normalization(conv) \n",
    "                h = tf.nn.relu(tf.nn.bias_add(bn_conv, b), name=\"relu\")\n",
    "                pooled = tf.nn.max_pool(h, ksize=[1, sequence_length - filter_size + 1, 1, 1],strides=[1, 1, 1, 1],padding='VALID',name=\"pool\")\n",
    "                pooled_outputs.append(pooled)\n",
    "\n",
    "\n",
    "        num_filters_total = num_filters * len(filter_sizes)\n",
    "        self.h_pool = tf.concat(pooled_outputs, 3)\n",
    "        self.h_pool_flat = tf.reshape(self.h_pool, [-1, num_filters_total])\n",
    "        \n",
    "\n",
    "        with tf.name_scope(\"fc-1\"):\n",
    "            W = tf.Variable(tf.truncated_normal([num_filters_total, 1024], stddev=0.01), name=\"W\")\n",
    "            b = tf.Variable(tf.constant(0.1, shape=[1024]), name=\"b\")\n",
    "            l2_loss += tf.nn.l2_loss(W)\n",
    "            l2_loss += tf.nn.l2_loss(b)\n",
    "            fc_1_output = tf.nn.relu(tf.nn.xw_plus_b(self.h_pool_flat, W, b), name=\"fc-1-out\")\n",
    "\n",
    "\n",
    "        with tf.name_scope(\"dropout-1\"):\n",
    "            drop_1 = tf.nn.dropout(fc_1_output, self.dropout_keep_prob)\n",
    "\n",
    "\n",
    "        with tf.name_scope(\"fc-2\"):\n",
    "            W = tf.Variable(tf.truncated_normal([1024,1024], stddev=0.01), name=\"W\")\n",
    "            b = tf.Variable(tf.constant(0.1, shape=[1024]), name=\"b\")\n",
    "            l2_loss += tf.nn.l2_loss(W)\n",
    "            l2_loss += tf.nn.l2_loss(b)\n",
    "            fc_2_output = tf.nn.relu(tf.nn.xw_plus_b(drop_1, W, b), name=\"fc-2-out\")\n",
    "            \n",
    "        with tf.name_scope(\"dropout-2\"):\n",
    "            drop_2 = tf.nn.dropout(fc_2_output, self.dropout_keep_prob)\n",
    "\n",
    "\n",
    "        with tf.name_scope(\"fc-3\"):\n",
    "            W = tf.Variable(tf.truncated_normal([1024, num_classes], stddev=0.01), name=\"W\")\n",
    "            b = tf.Variable(tf.constant(0.1, shape=[num_classes]), name=\"b\")\n",
    "            l2_loss += tf.nn.l2_loss(W)\n",
    "            l2_loss += tf.nn.l2_loss(b)\n",
    "            self.scores = tf.nn.xw_plus_b(drop_2, W, b, name=\"output\")\n",
    "            self.predictions = tf.argmax(self.scores, 1, name=\"predictions\")\n",
    "            \n",
    "            \n",
    "        with tf.name_scope(\"loss\"):\n",
    "      \n",
    "            #　targets * -log(sigmoid(logits)) * pos_weight +　(1 - targets) * -log(1 - sigmoid(logits))\n",
    "            losses = tf.nn.weighted_cross_entropy_with_logits(logits=self.scores, targets=self.input_y, pos_weight=self.loss_weight)\n",
    "            #losses = tf.nn.softmax_cross_entropy_with_logits(logits=self.scores, labels=self.input_y)\n",
    "            self.loss = tf.reduce_mean(losses) + l2_reg_lambda * l2_loss\n",
    "\n",
    "\n",
    "        with tf.name_scope(\"accuracy\"):\n",
    "            correct_predictions = tf.equal(self.predictions, tf.argmax(self.input_y, 1))\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"), name=\"accuracy\") \n",
    "            \n",
    "            \n",
    "    def batch_normalization(self, x):\n",
    "        \"\"\"\n",
    "          x -> γ(x-μ)/√（σ^2-ε）　+ β\n",
    "      \n",
    "          γ : scale\n",
    "          μ: mean (first moment)\n",
    "          σ: variance (second moment)\n",
    "          β: offset\n",
    "          ε: to avoid dividing by 0\n",
    "        \"\"\"\n",
    "        epsilon = 1e-5\n",
    "        dim = x.get_shape()[-1]\n",
    "        scale = tf.Variable(tf.ones([dim]))\n",
    "        offset = tf.Variable(tf.zeros([dim]))\n",
    "        mean, variance = tf.nn.moments(x, [0,1,2])\n",
    "        return tf.nn.batch_normalization(x, mean, variance, offset, scale, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#positive_data_file = \"data/amazon/book_pos.txt\"\n",
    "#negative_data_file = \"data/amazon/book_neg.txt\"\n",
    "\n",
    "#positive_data_file = \"data/chABSA/pos.txt\"\n",
    "#negative_data_file = \"data/chABSA/neg.txt\"\n",
    "\n",
    "positive_data_file = \"data/amazon_ja/pos.txt\"\n",
    "negative_data_file = \"data/amazon_ja/neg.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_dir = \"/usr/lib/mecab/dic/mecab-ipadic-neologd\"\n",
    "#dic_dir = \"/usr/local/lib/mecab/dic/mecab-ipadic-neologd/\"\n",
    "class Tokenizer:\n",
    "    def __init__(self, dic_dir):\n",
    "        mecab = MeCab.Tagger(\"-Ochasen -d {}\".format(dic_dir))\n",
    "        self.parser = mecab.parse\n",
    "            \n",
    "\n",
    "    def tokenize(self, text):\n",
    "        text = text.lower()\n",
    "        l = [line.split(\"\\t\") for line in self.parser(text).split(\"\\n\")]\n",
    "        res = \" \".join([i[2] for i in l if len(i) >=4]) # has POS.)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'認める たい ない もの だ な 。 自分自身 の 若さ故の過ち という もの を 。'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tokenizer(dic_dir).tokenize(\"認めたくないものだな。自分自身の若さ故の過ちというものを。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_and_labels(positive_data_file, negative_data_file, level=\"char\", lang=\"En\", dic_dir=None):\n",
    "       \n",
    "    positive_examples = list(open(positive_data_file, \"r\").readlines())\n",
    "    negative_examples = list(open(negative_data_file, \"r\").readlines())\n",
    "    if level == \"char\":\n",
    "        positive_examples = [s.replace(\" \", \"\").replace(\"\", \" \").lower() for s in positive_examples]\n",
    "        negative_examples = [s.replace(\" \", \"\").replace(\"\", \" \").lower() for s in negative_examples]\n",
    "    elif level == \"word\":\n",
    "        if lang == \"Ja\":\n",
    "            t = Tokenizer(dic_dir)\n",
    "            positive_examples = [t.tokenize(s) for s in positive_examples]\n",
    "            negative_examples = [t.tokenize(s) for s in negative_examples]\n",
    "        else:\n",
    "            positive_examples = [s.strip() for s in positive_examples]\n",
    "            negative_examples = [s.strip() for s in negative_examples]\n",
    "    else:\n",
    "        print(\"invaid value of 'level'. ('char' or 'word') \")\n",
    "        \n",
    "    n_pos = len(positive_examples)\n",
    "    n_neg = len(negative_examples)\n",
    "    ratio = n_pos/n_neg\n",
    "    print(\"# pos: \", n_pos)\n",
    "    print(\"# neg: \", n_neg)\n",
    "    print(\"pos/neg:\", ratio)\n",
    "    x_text = positive_examples + negative_examples\n",
    "\n",
    "    positive_labels = [[0, 1] for _ in positive_examples]\n",
    "    negative_labels = [[1, 0] for _ in negative_examples]\n",
    "    y = np.concatenate([positive_labels, negative_labels], 0)\n",
    "    \n",
    "    return x_text, y, ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_and_labels_multiclass(files, level=\"char\", lang=\"En\", dic_dir=None):\n",
    "    labels = []\n",
    "    x_text = []\n",
    "    n_classes = len(files)\n",
    "    \n",
    "    for i, f in enumerate(files):\n",
    "        positive_examples = list(open(f, \"r\").readlines())\n",
    "        if level == \"char\":\n",
    "            positive_examples = [s.replace(\" \", \"\").replace(\"\", \" \").lower() for s in positive_examples]\n",
    "        elif level == \"word\":\n",
    "            if lang == \"Ja\":\n",
    "                t = Tokenizer(dic_dir=dic_dir)\n",
    "                positive_examples = [t.tokenize(s) for s in positive_examples]\n",
    "            else:\n",
    "                positive_examples = [s.strip() for s in positive_examples]\n",
    "        else:\n",
    "            print(\"invaid value of 'level'. ('char' or 'word') \")\n",
    "        print(len(positive_examples))\n",
    "        x_text += positive_examples\n",
    "        positive_labels = [np.identity(n_classes)[i] for _ in positive_examples]\n",
    "        labels.append(positive_labels)\n",
    "    \n",
    "    y = np.concatenate(labels, 0)\n",
    "    \n",
    "    return x_text, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"data/amazon_ja/r_{}.txt\".format(i) for i in range(1,6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# pos:  62402\n",
      "# neg:  9060\n",
      "pos/neg: 6.887637969094922\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"59c15070-d600-47c0-87bb-335496eaee91\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"59c15070-d600-47c0-87bb-335496eaee91\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify\n",
    "level= \"word\"#\"char\"\n",
    "#x_text, y = load_data_and_labels_multiclass(files, level=level, lang=\"Ja\")\n",
    "x_text, y, ratio = load_data_and_labels(positive_data_file, negative_data_file, level=level, lang=\"Ja\", dic_dir=dic_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_doc = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71462"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'書き込む 、 読み出し 、 転送速度 、 いずれ も 満足 です 。 1600 万 画素 の コンパクトカメラ タイプ の デジカメ に 入れる て 撮影 に 使う 、 撮影後 は カード リーダ に 接続 する て 、 撮影 する た 膨大 だ 量 の 画像 データ を サムネイル 表示 に する たり 、 ピックアップ する た 画像 を コピペ する たり する て いる ます が 、 とくに ストレス を 感じる こと ない 、 快適 に 使える て いる ます 。 【 amazon.co.jp 限定 】 の 個体 は 、 SDカード 本体 が シンプル だ 小さい ボール紙 に 挟む れる て いる だけ 。 梱包 は 超 シンプル です が 、 実 売価 格 が 安い 、 性能 に も 満足 出来る て いる ので 買う て 良い た と 思う て いる ます 。 耐久性 は わかる ます ん 。 そこ は 要 経過 観察 です ね 。'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_list = np.array([len(r)for r in x_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   length\n",
       "0     430\n",
       "1      51\n",
       "2     145\n",
       "3     178\n",
       "4     258"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(length_list, columns=[\"length\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>71462.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>197.877165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>260.944038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>134.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>228.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80%</th>\n",
       "      <td>261.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>374.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>535.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13936.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             length\n",
       "count  71462.000000\n",
       "mean     197.877165\n",
       "std      260.944038\n",
       "min        4.000000\n",
       "50%      134.000000\n",
       "75%      228.000000\n",
       "80%      261.000000\n",
       "90%      374.000000\n",
       "95%      535.000000\n",
       "max    13936.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(percentiles=[0.5,0.75,0.8,0.9,0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.quantile(0.95)[\"length\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f18add98e48>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist(bins=50,figsize=(10,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cut length to  374\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>71462.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>165.509781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>103.387641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>134.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>228.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80%</th>\n",
       "      <td>261.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>374.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>374.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>374.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             length\n",
       "count  71462.000000\n",
       "mean     165.509781\n",
       "std      103.387641\n",
       "min        4.000000\n",
       "50%      134.000000\n",
       "75%      228.000000\n",
       "80%      261.000000\n",
       "90%      374.000000\n",
       "95%      374.000000\n",
       "max      374.000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = int(df.quantile(0.9)[\"length\"]) #1000\n",
    "if long_doc:\n",
    "    print(\"cut length to \", max_length)\n",
    "    x_text = [x[:max_length] if len(x) > max_length else x for x in x_text]\n",
    "length_list = np.array([len(r)for r in x_text])\n",
    "df = pd.DataFrame(length_list, columns=[\"length\"])\n",
    "df.describe(percentiles=[0.5,0.75,0.8,0.9,0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f18ad00a1d0>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist(bins=50,figsize=(10,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-27-0ac02ce7bc00>:1: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n"
     ]
    }
   ],
   "source": [
    "vocab_processor = preprocessing.VocabularyProcessor(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71462"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n"
     ]
    }
   ],
   "source": [
    "%%notify\n",
    "x = np.array(list(vocab_processor.fit_transform(x_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_percentage = 0.05 #0.0010 #0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 53806\n",
      "Train/Test split: 67889/3573\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"408eadd6-469e-46c3-adb2-116cbc22e8cd\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"408eadd6-469e-46c3-adb2-116cbc22e8cd\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify\n",
    "np.random.seed(10)\n",
    "shuffle_indices = np.random.permutation(np.arange(len(y)))\n",
    "x_shuffled = x[shuffle_indices]\n",
    "y_shuffled = y[shuffle_indices]\n",
    "\n",
    "test_sample_index = -1 * int(test_percentage * float(len(y)))\n",
    "x_train, x_test = x_shuffled[:test_sample_index], x_shuffled[test_sample_index:]\n",
    "y_train, y_test = y_shuffled[:test_sample_index], y_shuffled[test_sample_index:]\n",
    "\n",
    "#del x, y, x_shuffled, y_shuffled\n",
    "\n",
    "print(\"Vocabulary Size: {:d}\".format(len(vocab_processor.vocabulary_)))\n",
    "print(\"Train/Test split: {:d}/{:d}\".format(len(y_train), len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67889, 374)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iter(data, batch_size, num_epochs, shuffle=True):\n",
    "    data = np.array(data)\n",
    "    data_size = len(data)\n",
    "    num_batches_per_epoch = int((len(data)-1)/batch_size) + 1\n",
    "    print(\"num of epochs: \", num_epochs)\n",
    "    print(\"num of batches: \", num_batches_per_epoch)\n",
    "    print(\"num of step: \", num_batches_per_epoch*num_epochs)\n",
    "    for epoch in range(num_epochs):\n",
    "        if shuffle:\n",
    "            shuffle_indices = np.random.permutation(np.arange(data_size))\n",
    "            shuffled_data = data[shuffle_indices]\n",
    "        else:\n",
    "            shuffled_data = data\n",
    "        for batch_num in range(num_batches_per_epoch):\n",
    "            start_index = batch_num * batch_size\n",
    "            end_index = min((batch_num + 1) * batch_size, data_size)\n",
    "            yield shuffled_data[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = x_train.shape[1]\n",
    "num_classes = y_train.shape[1]\n",
    "vocab_size = len(vocab_processor.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 128    \n",
    "filter_sizes = [2,3,4,5]    \n",
    "num_filters=128               \n",
    "dropout_keep_prob=0.5 \n",
    "l2_reg_lambda=0.01       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# classes 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.TextCNN at 0x7f18ad63feb8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextCNN(sequence_length, num_classes, vocab_size, embedding_size, filter_sizes, num_filters, l2_reg_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to ./runs/word_cnn_2/2018_07_21_11_53_28/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64                  \n",
    "num_epochs = 30            \n",
    "evaluate_every = 20         \n",
    "num_checkpoints = 5\n",
    "learning_rate = 1e-3\n",
    "\n",
    "allow_soft_placement = True    \n",
    "log_device_placement = False  \n",
    "\n",
    "save_checkpoint = True\n",
    "\n",
    "\n",
    "#timestamp = str(int(time.time()))\n",
    "#timestamp = \"1525609926\"\n",
    "time_path = datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "prefix = \"\"\n",
    "#out_dir = os.path.abspath(os.path.join(os.path.curdir, \"runs\", timestamp, prefix))\n",
    "out_dir = os.path.join(os.path.curdir, \"runs\", \"{}_cnn_{}\".format(level,num_classes), time_path, prefix)\n",
    "print(\"Writing to {}\\n\".format(out_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# classes 2\n",
      "INFO:tensorflow:Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-2/W:0/grad/hist is illegal; using conv-maxpool-2/W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-2/W:0/grad/sparsity is illegal; using conv-maxpool-2/W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-2/b:0/grad/hist is illegal; using conv-maxpool-2/b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-2/b:0/grad/sparsity is illegal; using conv-maxpool-2/b_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-2/Variable:0/grad/hist is illegal; using conv-maxpool-2/Variable_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-2/Variable:0/grad/sparsity is illegal; using conv-maxpool-2/Variable_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-2/Variable_1:0/grad/hist is illegal; using conv-maxpool-2/Variable_1_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-2/Variable_1:0/grad/sparsity is illegal; using conv-maxpool-2/Variable_1_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-3/Variable:0/grad/hist is illegal; using conv-maxpool-3/Variable_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-3/Variable:0/grad/sparsity is illegal; using conv-maxpool-3/Variable_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-3/Variable_1:0/grad/hist is illegal; using conv-maxpool-3/Variable_1_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-3/Variable_1:0/grad/sparsity is illegal; using conv-maxpool-3/Variable_1_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-4/Variable:0/grad/hist is illegal; using conv-maxpool-4/Variable_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-4/Variable:0/grad/sparsity is illegal; using conv-maxpool-4/Variable_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-4/Variable_1:0/grad/hist is illegal; using conv-maxpool-4/Variable_1_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-4/Variable_1:0/grad/sparsity is illegal; using conv-maxpool-4/Variable_1_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-5/Variable:0/grad/hist is illegal; using conv-maxpool-5/Variable_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-5/Variable:0/grad/sparsity is illegal; using conv-maxpool-5/Variable_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-5/Variable_1:0/grad/hist is illegal; using conv-maxpool-5/Variable_1_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-5/Variable_1:0/grad/sparsity is illegal; using conv-maxpool-5/Variable_1_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name fc-1/W:0/grad/hist is illegal; using fc-1/W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name fc-1/W:0/grad/sparsity is illegal; using fc-1/W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name fc-1/b:0/grad/hist is illegal; using fc-1/b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name fc-1/b:0/grad/sparsity is illegal; using fc-1/b_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name fc-2/W:0/grad/hist is illegal; using fc-2/W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name fc-2/W:0/grad/sparsity is illegal; using fc-2/W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name fc-2/b:0/grad/hist is illegal; using fc-2/b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name fc-2/b:0/grad/sparsity is illegal; using fc-2/b_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name fc-3/W:0/grad/hist is illegal; using fc-3/W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name fc-3/W:0/grad/sparsity is illegal; using fc-3/W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name fc-3/b:0/grad/hist is illegal; using fc-3/b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name fc-3/b:0/grad/sparsity is illegal; using fc-3/b_0/grad/sparsity instead.\n",
      "num of epochs:  30\n",
      "num of batches:  1061\n",
      "num of step:  31830\n",
      "2018-07-21T11:53:44.877111: step 20, loss 0.576971, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:53:46.285000: step 20, loss 0.635286, acc 0.873496\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-20\n",
      "\n",
      "2018-07-21T11:53:49.627502: step 40, loss 0.602989, acc 0.828125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:53:50.020510: step 40, loss 0.514456, acc 0.873496\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-40\n",
      "\n",
      "2018-07-21T11:53:53.313850: step 60, loss 0.420099, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:53:53.696259: step 60, loss 0.448958, acc 0.873496\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-60\n",
      "\n",
      "2018-07-21T11:53:57.161383: step 80, loss 0.481636, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:53:57.542618: step 80, loss 0.428364, acc 0.873496\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-80\n",
      "\n",
      "2018-07-21T11:54:00.871637: step 100, loss 0.423941, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:54:01.250373: step 100, loss 0.424076, acc 0.873496\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-100\n",
      "\n",
      "2018-07-21T11:54:04.581514: step 120, loss 0.49064, acc 0.828125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:54:04.956828: step 120, loss 0.391027, acc 0.873496\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-120\n",
      "\n",
      "2018-07-21T11:54:08.344180: step 140, loss 0.377112, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:54:08.724359: step 140, loss 0.386228, acc 0.873496\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-140\n",
      "\n",
      "2018-07-21T11:54:12.167070: step 160, loss 0.387027, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:54:12.551074: step 160, loss 0.369009, acc 0.873496\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-160\n",
      "\n",
      "2018-07-21T11:54:16.014298: step 180, loss 0.338716, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:54:16.395025: step 180, loss 0.390734, acc 0.873496\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-180\n",
      "\n",
      "2018-07-21T11:54:19.788268: step 200, loss 0.449411, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:54:20.174017: step 200, loss 0.352029, acc 0.873496\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-200\n",
      "\n",
      "2018-07-21T11:54:23.545355: step 220, loss 0.36467, acc 0.890625\n",
      "\n",
      "Evaluation:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-07-21T11:54:23.926616: step 220, loss 0.388588, acc 0.873496\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-220\n",
      "\n",
      "2018-07-21T11:54:27.315902: step 240, loss 0.347312, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:54:27.695603: step 240, loss 0.347306, acc 0.873496\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-240\n",
      "\n",
      "2018-07-21T11:54:31.380023: step 260, loss 0.252767, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:54:31.768744: step 260, loss 0.33298, acc 0.873496\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-260\n",
      "\n",
      "2018-07-21T11:54:35.115615: step 280, loss 0.374869, acc 0.8125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:54:35.501872: step 280, loss 0.319458, acc 0.873496\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-280\n",
      "\n",
      "2018-07-21T11:54:38.881582: step 300, loss 0.25337, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:54:39.269237: step 300, loss 0.304657, acc 0.873496\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-300\n",
      "\n",
      "2018-07-21T11:54:42.713137: step 320, loss 0.42908, acc 0.828125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:54:43.102335: step 320, loss 0.296074, acc 0.874895\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-320\n",
      "\n",
      "2018-07-21T11:54:46.610595: step 340, loss 0.387853, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:54:46.988635: step 340, loss 0.296114, acc 0.896725\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-340\n",
      "\n",
      "2018-07-21T11:54:50.412256: step 360, loss 0.338012, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:54:50.791512: step 360, loss 0.290565, acc 0.88553\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-360\n",
      "\n",
      "2018-07-21T11:54:54.185576: step 380, loss 0.338609, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:54:54.567621: step 380, loss 0.285543, acc 0.891408\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-380\n",
      "\n",
      "2018-07-21T11:54:58.029604: step 400, loss 0.353316, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:54:58.412226: step 400, loss 0.279636, acc 0.899244\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-400\n",
      "\n",
      "2018-07-21T11:55:01.886108: step 420, loss 0.276327, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:55:02.269831: step 420, loss 0.262301, acc 0.905402\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-420\n",
      "\n",
      "2018-07-21T11:55:05.559443: step 440, loss 0.244872, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:55:05.942816: step 440, loss 0.269407, acc 0.906521\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-440\n",
      "\n",
      "2018-07-21T11:55:09.297263: step 460, loss 0.333694, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:55:09.675292: step 460, loss 0.267244, acc 0.90876\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-460\n",
      "\n",
      "2018-07-21T11:55:13.006082: step 480, loss 0.182324, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:55:13.383098: step 480, loss 0.330302, acc 0.878813\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-480\n",
      "\n",
      "2018-07-21T11:55:16.936709: step 500, loss 0.282647, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:55:17.327251: step 500, loss 0.261778, acc 0.907921\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-500\n",
      "\n",
      "2018-07-21T11:55:20.681971: step 520, loss 0.300031, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:55:21.064855: step 520, loss 0.259667, acc 0.9082\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-520\n",
      "\n",
      "2018-07-21T11:55:24.456817: step 540, loss 0.350591, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:55:24.835770: step 540, loss 0.249184, acc 0.912958\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-540\n",
      "\n",
      "2018-07-21T11:55:28.272990: step 560, loss 0.33164, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:55:28.654556: step 560, loss 0.256113, acc 0.90876\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-560\n",
      "\n",
      "2018-07-21T11:55:32.167493: step 580, loss 0.31064, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:55:32.578191: step 580, loss 0.343054, acc 0.888609\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-580\n",
      "\n",
      "2018-07-21T11:55:36.009428: step 600, loss 0.233303, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:55:36.396399: step 600, loss 0.24588, acc 0.916597\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-600\n",
      "\n",
      "2018-07-21T11:55:39.852299: step 620, loss 0.316719, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:55:40.235575: step 620, loss 0.27266, acc 0.907641\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-620\n",
      "\n",
      "2018-07-21T11:55:43.667108: step 640, loss 0.216611, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:55:44.046447: step 640, loss 0.239151, acc 0.920795\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-640\n",
      "\n",
      "2018-07-21T11:55:47.365994: step 660, loss 0.25975, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:55:47.753670: step 660, loss 0.24513, acc 0.912119\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-660\n",
      "\n",
      "2018-07-21T11:55:51.113814: step 680, loss 0.235792, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:55:51.491568: step 680, loss 0.234506, acc 0.922474\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-680\n",
      "\n",
      "2018-07-21T11:55:54.978854: step 700, loss 0.303343, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:55:55.360403: step 700, loss 0.275641, acc 0.907361\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-700\n",
      "\n",
      "2018-07-21T11:55:58.764367: step 720, loss 0.264411, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:55:59.149296: step 720, loss 0.23627, acc 0.922194\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-720\n",
      "\n",
      "2018-07-21T11:56:02.623856: step 740, loss 0.226875, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:56:03.018824: step 740, loss 0.227135, acc 0.925553\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-740\n",
      "\n",
      "2018-07-21T11:56:06.565755: step 760, loss 0.197963, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:56:06.949369: step 760, loss 0.225083, acc 0.928911\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-760\n",
      "\n",
      "2018-07-21T11:56:10.308703: step 780, loss 0.285886, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:56:10.691369: step 780, loss 0.226659, acc 0.927232\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-780\n",
      "\n",
      "2018-07-21T11:56:13.952312: step 800, loss 0.235709, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:56:14.333642: step 800, loss 0.238543, acc 0.916597\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-800\n",
      "\n",
      "2018-07-21T11:56:17.719008: step 820, loss 0.266096, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:56:18.109097: step 820, loss 0.241776, acc 0.922474\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-820\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-07-21T11:56:21.564129: step 840, loss 0.303863, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:56:21.943306: step 840, loss 0.281309, acc 0.90904\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-840\n",
      "\n",
      "2018-07-21T11:56:25.334176: step 860, loss 0.225688, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:56:25.718537: step 860, loss 0.229729, acc 0.925833\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-860\n",
      "\n",
      "2018-07-21T11:56:29.167174: step 880, loss 0.215864, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:56:29.580547: step 880, loss 0.216436, acc 0.93115\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-880\n",
      "\n",
      "2018-07-21T11:56:32.926176: step 900, loss 0.264937, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:56:33.305602: step 900, loss 0.233783, acc 0.922754\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-900\n",
      "\n",
      "2018-07-21T11:56:36.944950: step 920, loss 0.256868, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:56:37.320714: step 920, loss 0.224318, acc 0.926952\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-920\n",
      "\n",
      "2018-07-21T11:56:40.691491: step 940, loss 0.281536, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:56:41.070171: step 940, loss 0.219408, acc 0.924993\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-940\n",
      "\n",
      "2018-07-21T11:56:44.405603: step 960, loss 0.237287, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:56:44.782210: step 960, loss 0.206702, acc 0.93199\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-960\n",
      "\n",
      "2018-07-21T11:56:48.237438: step 980, loss 0.280811, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:56:48.632100: step 980, loss 0.20865, acc 0.933669\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-980\n",
      "\n",
      "2018-07-21T11:56:52.122193: step 1000, loss 0.366171, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:56:52.501902: step 1000, loss 0.229879, acc 0.916317\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1000\n",
      "\n",
      "2018-07-21T11:56:55.929530: step 1020, loss 0.283658, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:56:56.309440: step 1020, loss 0.205493, acc 0.934789\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1020\n",
      "\n",
      "2018-07-21T11:56:59.798451: step 1040, loss 0.215963, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:57:00.176427: step 1040, loss 0.201801, acc 0.935908\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1040\n",
      "\n",
      "2018-07-21T11:57:03.649629: step 1060, loss 0.251227, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:57:04.031626: step 1060, loss 0.228253, acc 0.925273\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1060\n",
      "\n",
      "2018-07-21T11:57:07.749238: step 1080, loss 0.180366, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:57:08.136431: step 1080, loss 0.21509, acc 0.933949\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1080\n",
      "\n",
      "2018-07-21T11:57:11.475968: step 1100, loss 0.132974, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:57:11.853427: step 1100, loss 0.208454, acc 0.934509\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1100\n",
      "\n",
      "2018-07-21T11:57:15.218145: step 1120, loss 0.176812, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:57:15.639660: step 1120, loss 0.207609, acc 0.936188\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1120\n",
      "\n",
      "2018-07-21T11:57:19.024140: step 1140, loss 0.191237, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:57:19.399266: step 1140, loss 0.21825, acc 0.93255\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1140\n",
      "\n",
      "2018-07-21T11:57:22.869562: step 1160, loss 0.256053, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:57:23.249080: step 1160, loss 0.200989, acc 0.935628\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1160\n",
      "\n",
      "2018-07-21T11:57:26.564823: step 1180, loss 0.183851, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:57:26.952981: step 1180, loss 0.201815, acc 0.93171\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1180\n",
      "\n",
      "2018-07-21T11:57:30.284625: step 1200, loss 0.340111, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:57:30.669896: step 1200, loss 0.202485, acc 0.937867\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1200\n",
      "\n",
      "2018-07-21T11:57:34.103329: step 1220, loss 0.174051, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:57:34.499326: step 1220, loss 0.206741, acc 0.935348\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1220\n",
      "\n",
      "2018-07-21T11:57:37.844000: step 1240, loss 0.105644, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:57:38.224068: step 1240, loss 0.203035, acc 0.938707\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1240\n",
      "\n",
      "2018-07-21T11:57:41.693814: step 1260, loss 0.175783, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:57:42.071977: step 1260, loss 0.237336, acc 0.918276\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1260\n",
      "\n",
      "2018-07-21T11:57:45.473571: step 1280, loss 0.113448, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:57:45.854269: step 1280, loss 0.206586, acc 0.938147\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1280\n",
      "\n",
      "2018-07-21T11:57:49.154136: step 1300, loss 0.217389, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:57:49.532807: step 1300, loss 0.197591, acc 0.938147\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1300\n",
      "\n",
      "2018-07-21T11:57:52.861373: step 1320, loss 0.129263, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:57:53.245520: step 1320, loss 0.216397, acc 0.935908\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1320\n",
      "\n",
      "2018-07-21T11:57:56.669635: step 1340, loss 0.172852, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:57:57.077216: step 1340, loss 0.198716, acc 0.935069\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1340\n",
      "\n",
      "2018-07-21T11:58:00.338806: step 1360, loss 0.149446, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:58:00.751904: step 1360, loss 0.21162, acc 0.923314\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1360\n",
      "\n",
      "2018-07-21T11:58:04.058403: step 1380, loss 0.216263, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:58:04.437721: step 1380, loss 0.227243, acc 0.937308\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1380\n",
      "\n",
      "2018-07-21T11:58:07.861749: step 1400, loss 0.173318, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:58:08.239185: step 1400, loss 0.217818, acc 0.922474\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1400\n",
      "\n",
      "2018-07-21T11:58:11.533557: step 1420, loss 0.189777, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:58:11.949004: step 1420, loss 0.199205, acc 0.937308\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1420\n",
      "\n",
      "2018-07-21T11:58:15.374236: step 1440, loss 0.123063, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:58:15.783729: step 1440, loss 0.19228, acc 0.938707\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1440\n",
      "\n",
      "2018-07-21T11:58:19.166832: step 1460, loss 0.205018, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:58:19.555438: step 1460, loss 0.234023, acc 0.929751\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1460\n",
      "\n",
      "2018-07-21T11:58:22.935117: step 1480, loss 0.134138, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:58:23.313401: step 1480, loss 0.192122, acc 0.941786\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1480\n",
      "\n",
      "2018-07-21T11:58:26.815666: step 1500, loss 0.355975, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:58:27.196220: step 1500, loss 0.188276, acc 0.940946\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1500\n",
      "\n",
      "2018-07-21T11:58:30.519965: step 1520, loss 0.154983, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:58:30.932324: step 1520, loss 0.198369, acc 0.939547\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1520\n",
      "\n",
      "2018-07-21T11:58:34.250858: step 1540, loss 0.291502, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:58:34.633818: step 1540, loss 0.193533, acc 0.942065\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1540\n",
      "\n",
      "2018-07-21T11:58:38.085486: step 1560, loss 0.289814, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:58:38.465650: step 1560, loss 0.215997, acc 0.934229\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1560\n",
      "\n",
      "2018-07-21T11:58:41.944001: step 1580, loss 0.137472, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:58:42.324193: step 1580, loss 0.205485, acc 0.941226\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1580\n",
      "\n",
      "2018-07-21T11:58:45.703222: step 1600, loss 0.246856, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:58:46.083431: step 1600, loss 0.19179, acc 0.942065\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1600\n",
      "\n",
      "2018-07-21T11:58:49.336562: step 1620, loss 0.07142, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:58:49.717500: step 1620, loss 0.22698, acc 0.930031\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1620\n",
      "\n",
      "2018-07-21T11:58:52.988871: step 1640, loss 0.183464, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:58:53.369531: step 1640, loss 0.185011, acc 0.943745\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1640\n",
      "\n",
      "2018-07-21T11:58:56.994085: step 1660, loss 0.0947685, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:58:57.381754: step 1660, loss 0.201303, acc 0.940666\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1660\n",
      "\n",
      "2018-07-21T11:59:00.784630: step 1680, loss 0.167381, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:59:01.166249: step 1680, loss 0.190747, acc 0.942345\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1680\n",
      "\n",
      "2018-07-21T11:59:04.429185: step 1700, loss 0.227953, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:59:04.821261: step 1700, loss 0.204068, acc 0.944025\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1700\n",
      "\n",
      "2018-07-21T11:59:08.333352: step 1720, loss 0.187804, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:59:08.743879: step 1720, loss 0.206147, acc 0.938707\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1720\n",
      "\n",
      "2018-07-21T11:59:12.101173: step 1740, loss 0.147819, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:59:12.486748: step 1740, loss 0.209093, acc 0.924993\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1740\n",
      "\n",
      "2018-07-21T11:59:16.103906: step 1760, loss 0.282771, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:59:16.482261: step 1760, loss 0.193945, acc 0.940946\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1760\n",
      "\n",
      "2018-07-21T11:59:19.792264: step 1780, loss 0.20428, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:59:20.205669: step 1780, loss 0.187699, acc 0.940666\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1780\n",
      "\n",
      "2018-07-21T11:59:23.529051: step 1800, loss 0.169769, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:59:23.912899: step 1800, loss 0.186498, acc 0.942905\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1800\n",
      "\n",
      "2018-07-21T11:59:27.176119: step 1820, loss 0.270045, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:59:27.553549: step 1820, loss 0.185066, acc 0.941786\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1820\n",
      "\n",
      "2018-07-21T11:59:31.096444: step 1840, loss 0.182678, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:59:31.482930: step 1840, loss 0.18502, acc 0.938987\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1840\n",
      "\n",
      "2018-07-21T11:59:34.766841: step 1860, loss 0.210368, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:59:35.148831: step 1860, loss 0.185774, acc 0.943185\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1860\n",
      "\n",
      "2018-07-21T11:59:38.484464: step 1880, loss 0.242397, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:59:38.863671: step 1880, loss 0.204426, acc 0.927232\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1880\n",
      "\n",
      "2018-07-21T11:59:42.187416: step 1900, loss 0.134123, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:59:42.565976: step 1900, loss 0.19216, acc 0.945424\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1900\n",
      "\n",
      "2018-07-21T11:59:46.137838: step 1920, loss 0.229546, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:59:46.517353: step 1920, loss 0.184429, acc 0.944584\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1920\n",
      "\n",
      "2018-07-21T11:59:49.723962: step 1940, loss 0.127837, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:59:50.116583: step 1940, loss 0.195705, acc 0.945704\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1940\n",
      "\n",
      "2018-07-21T11:59:53.430704: step 1960, loss 0.146974, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:59:53.810560: step 1960, loss 0.182662, acc 0.944025\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1960\n",
      "\n",
      "2018-07-21T11:59:57.178727: step 1980, loss 0.189844, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T11:59:57.558106: step 1980, loss 0.185599, acc 0.941786\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-1980\n",
      "\n",
      "2018-07-21T12:00:01.003231: step 2000, loss 0.15427, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:00:01.387710: step 2000, loss 0.214843, acc 0.939267\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2000\n",
      "\n",
      "2018-07-21T12:00:04.759943: step 2020, loss 0.122248, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:00:05.147787: step 2020, loss 0.18194, acc 0.941226\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2020\n",
      "\n",
      "2018-07-21T12:00:08.472477: step 2040, loss 0.138347, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:00:08.849450: step 2040, loss 0.181984, acc 0.942345\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2040\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-07-21T12:00:12.095001: step 2060, loss 0.119646, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:00:12.472152: step 2060, loss 0.18774, acc 0.944025\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2060\n",
      "\n",
      "2018-07-21T12:00:15.786271: step 2080, loss 0.155227, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:00:16.165663: step 2080, loss 0.179707, acc 0.942625\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2080\n",
      "\n",
      "2018-07-21T12:00:19.674665: step 2100, loss 0.136006, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:00:20.053822: step 2100, loss 0.17925, acc 0.943745\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2100\n",
      "\n",
      "2018-07-21T12:00:23.342470: step 2120, loss 0.133957, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:00:23.719153: step 2120, loss 0.196488, acc 0.945984\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2120\n",
      "\n",
      "2018-07-21T12:00:26.949425: step 2140, loss 0.100263, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:00:27.329857: step 2140, loss 0.18502, acc 0.939547\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2140\n",
      "\n",
      "2018-07-21T12:00:30.555406: step 2160, loss 0.37938, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:00:30.939019: step 2160, loss 0.22119, acc 0.940946\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2160\n",
      "\n",
      "2018-07-21T12:00:34.213176: step 2180, loss 0.096837, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:00:34.605226: step 2180, loss 0.192117, acc 0.942065\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2180\n",
      "\n",
      "2018-07-21T12:00:37.947543: step 2200, loss 0.14943, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:00:38.327127: step 2200, loss 0.197363, acc 0.948503\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2200\n",
      "\n",
      "2018-07-21T12:00:41.643434: step 2220, loss 0.186715, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:00:42.021329: step 2220, loss 0.205236, acc 0.945984\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2220\n",
      "\n",
      "2018-07-21T12:00:45.242162: step 2240, loss 0.136232, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:00:45.616448: step 2240, loss 0.201671, acc 0.941786\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2240\n",
      "\n",
      "2018-07-21T12:00:48.881899: step 2260, loss 0.0990695, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:00:49.306000: step 2260, loss 0.188187, acc 0.947103\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2260\n",
      "\n",
      "2018-07-21T12:00:52.800778: step 2280, loss 0.157776, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:00:53.181081: step 2280, loss 0.184286, acc 0.945984\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2280\n",
      "\n",
      "2018-07-21T12:00:56.524665: step 2300, loss 0.155474, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:00:56.901333: step 2300, loss 0.205811, acc 0.944864\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2300\n",
      "\n",
      "2018-07-21T12:01:00.192239: step 2320, loss 0.216979, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:01:00.608595: step 2320, loss 0.182417, acc 0.944864\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2320\n",
      "\n",
      "2018-07-21T12:01:04.034466: step 2340, loss 0.092713, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:01:04.430825: step 2340, loss 0.180698, acc 0.945144\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2340\n",
      "\n",
      "2018-07-21T12:01:07.660411: step 2360, loss 0.141961, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:01:08.038914: step 2360, loss 0.18736, acc 0.944864\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2360\n",
      "\n",
      "2018-07-21T12:01:11.265898: step 2380, loss 0.158923, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:01:11.642658: step 2380, loss 0.190688, acc 0.939826\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2380\n",
      "\n",
      "2018-07-21T12:01:15.167835: step 2400, loss 0.12572, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:01:15.584668: step 2400, loss 0.198461, acc 0.942345\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2400\n",
      "\n",
      "2018-07-21T12:01:18.951955: step 2420, loss 0.228355, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:01:19.340764: step 2420, loss 0.184028, acc 0.944025\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2420\n",
      "\n",
      "2018-07-21T12:01:22.831011: step 2440, loss 0.129681, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:01:23.210625: step 2440, loss 0.195237, acc 0.943185\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2440\n",
      "\n",
      "2018-07-21T12:01:26.466319: step 2460, loss 0.0864255, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:01:26.842379: step 2460, loss 0.19287, acc 0.943745\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2460\n",
      "\n",
      "2018-07-21T12:01:30.057578: step 2480, loss 0.198535, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:01:30.434401: step 2480, loss 0.194037, acc 0.941506\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2480\n",
      "\n",
      "2018-07-21T12:01:33.748191: step 2500, loss 0.124221, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:01:34.163570: step 2500, loss 0.199592, acc 0.942065\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2500\n",
      "\n",
      "2018-07-21T12:01:37.625354: step 2520, loss 0.0911499, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:01:38.009425: step 2520, loss 0.180555, acc 0.943745\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2520\n",
      "\n",
      "2018-07-21T12:01:41.339072: step 2540, loss 0.114643, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:01:41.714411: step 2540, loss 0.18173, acc 0.947383\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2540\n",
      "\n",
      "2018-07-21T12:01:44.964050: step 2560, loss 0.125137, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:01:45.344783: step 2560, loss 0.208024, acc 0.941226\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2560\n",
      "\n",
      "2018-07-21T12:01:48.622458: step 2580, loss 0.0858724, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:01:48.999213: step 2580, loss 0.186459, acc 0.945704\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2580\n",
      "\n",
      "2018-07-21T12:01:52.578521: step 2600, loss 0.142291, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:01:52.957267: step 2600, loss 0.20192, acc 0.926392\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2600\n",
      "\n",
      "2018-07-21T12:01:56.364678: step 2620, loss 0.165816, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:01:56.746934: step 2620, loss 0.195843, acc 0.947103\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2620\n",
      "\n",
      "2018-07-21T12:02:00.136107: step 2640, loss 0.0780338, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:02:00.513982: step 2640, loss 0.186127, acc 0.938707\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2640\n",
      "\n",
      "2018-07-21T12:02:03.828153: step 2660, loss 0.0602908, acc 1\n",
      "\n",
      "Evaluation:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-07-21T12:02:04.219925: step 2660, loss 0.18922, acc 0.939267\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2660\n",
      "\n",
      "2018-07-21T12:02:07.474285: step 2680, loss 0.102024, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:02:07.852823: step 2680, loss 0.180276, acc 0.943185\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2680\n",
      "\n",
      "2018-07-21T12:02:11.188004: step 2700, loss 0.0976054, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:02:11.568227: step 2700, loss 0.180879, acc 0.947383\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2700\n",
      "\n",
      "2018-07-21T12:02:14.920454: step 2720, loss 0.141954, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:02:15.325163: step 2720, loss 0.186758, acc 0.949342\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2720\n",
      "\n",
      "2018-07-21T12:02:18.594098: step 2740, loss 0.127112, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:02:18.965765: step 2740, loss 0.185067, acc 0.942065\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2740\n",
      "\n",
      "2018-07-21T12:02:22.096060: step 2760, loss 0.10034, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:02:22.467166: step 2760, loss 0.175163, acc 0.947943\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2760\n",
      "\n",
      "2018-07-21T12:02:25.641496: step 2780, loss 0.0991295, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:02:26.013457: step 2780, loss 0.181815, acc 0.947383\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2780\n",
      "\n",
      "2018-07-21T12:02:29.221848: step 2800, loss 0.0940773, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:02:29.594626: step 2800, loss 0.180503, acc 0.943745\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2800\n",
      "\n",
      "2018-07-21T12:02:32.735365: step 2820, loss 0.0942408, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:02:33.108783: step 2820, loss 0.186675, acc 0.946823\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2820\n",
      "\n",
      "2018-07-21T12:02:36.293834: step 2840, loss 0.123848, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:02:36.672016: step 2840, loss 0.180085, acc 0.944864\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2840\n",
      "\n",
      "2018-07-21T12:02:40.060598: step 2860, loss 0.122656, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:02:40.429073: step 2860, loss 0.187481, acc 0.945424\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2860\n",
      "\n",
      "2018-07-21T12:02:43.560491: step 2880, loss 0.318606, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:02:43.934224: step 2880, loss 0.174629, acc 0.949062\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2880\n",
      "\n",
      "2018-07-21T12:02:47.054381: step 2900, loss 0.0881694, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:02:47.426764: step 2900, loss 0.24699, acc 0.936468\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2900\n",
      "\n",
      "2018-07-21T12:02:50.601670: step 2920, loss 0.0550901, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:02:50.982079: step 2920, loss 0.19845, acc 0.949902\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2920\n",
      "\n",
      "2018-07-21T12:02:54.151805: step 2940, loss 0.251594, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:02:54.528128: step 2940, loss 0.194638, acc 0.930311\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2940\n",
      "\n",
      "2018-07-21T12:02:57.836211: step 2960, loss 0.245414, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:02:58.216434: step 2960, loss 0.177057, acc 0.944305\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2960\n",
      "\n",
      "2018-07-21T12:03:01.440692: step 2980, loss 0.127042, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:03:01.815105: step 2980, loss 0.180627, acc 0.950182\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-2980\n",
      "\n",
      "2018-07-21T12:03:05.003182: step 3000, loss 0.110526, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:03:05.373275: step 3000, loss 0.205519, acc 0.946264\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3000\n",
      "\n",
      "2018-07-21T12:03:08.524667: step 3020, loss 0.0838537, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:03:08.901384: step 3020, loss 0.19579, acc 0.946264\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3020\n",
      "\n",
      "2018-07-21T12:03:12.244788: step 3040, loss 0.0826183, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:03:12.617667: step 3040, loss 0.194149, acc 0.948783\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3040\n",
      "\n",
      "2018-07-21T12:03:15.743257: step 3060, loss 0.0867856, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:03:16.115124: step 3060, loss 0.178236, acc 0.949902\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3060\n",
      "\n",
      "2018-07-21T12:03:19.289667: step 3080, loss 0.182727, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:03:19.662042: step 3080, loss 0.183601, acc 0.949902\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3080\n",
      "\n",
      "2018-07-21T12:03:22.832022: step 3100, loss 0.107356, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:03:23.204957: step 3100, loss 0.179536, acc 0.948223\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3100\n",
      "\n",
      "2018-07-21T12:03:26.391109: step 3120, loss 0.105638, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:03:26.769920: step 3120, loss 0.183759, acc 0.940386\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3120\n",
      "\n",
      "2018-07-21T12:03:29.909573: step 3140, loss 0.407619, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:03:30.281830: step 3140, loss 0.198993, acc 0.935348\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3140\n",
      "\n",
      "2018-07-21T12:03:33.407478: step 3160, loss 0.111439, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:03:33.780262: step 3160, loss 0.182004, acc 0.947663\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3160\n",
      "\n",
      "2018-07-21T12:03:36.951305: step 3180, loss 0.106331, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:03:37.325913: step 3180, loss 0.189132, acc 0.949062\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3180\n",
      "\n",
      "2018-07-21T12:03:40.471879: step 3200, loss 0.152591, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:03:40.840368: step 3200, loss 0.22953, acc 0.947383\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3200\n",
      "\n",
      "2018-07-21T12:03:44.247058: step 3220, loss 0.0727552, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:03:44.614756: step 3220, loss 0.196862, acc 0.941226\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3220\n",
      "\n",
      "2018-07-21T12:03:47.749499: step 3240, loss 0.0555054, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:03:48.119887: step 3240, loss 0.255257, acc 0.947103\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3240\n",
      "\n",
      "2018-07-21T12:03:51.270798: step 3260, loss 0.0497456, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:03:51.641853: step 3260, loss 0.213202, acc 0.946823\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3260\n",
      "\n",
      "2018-07-21T12:03:54.832933: step 3280, loss 0.0980972, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:03:55.207979: step 3280, loss 0.190942, acc 0.940666\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3280\n",
      "\n",
      "2018-07-21T12:03:58.383220: step 3300, loss 0.0582038, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:03:58.759097: step 3300, loss 0.234273, acc 0.946264\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3300\n",
      "\n",
      "2018-07-21T12:04:02.047780: step 3320, loss 0.0970833, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:04:02.422051: step 3320, loss 0.204829, acc 0.942625\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3320\n",
      "\n",
      "2018-07-21T12:04:05.587043: step 3340, loss 0.237788, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:04:05.960633: step 3340, loss 0.222467, acc 0.947103\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3340\n",
      "\n",
      "2018-07-21T12:04:09.126549: step 3360, loss 0.0848527, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:04:09.500860: step 3360, loss 0.205976, acc 0.946544\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3360\n",
      "\n",
      "2018-07-21T12:04:12.630251: step 3380, loss 0.0562911, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:04:13.008233: step 3380, loss 0.204996, acc 0.942625\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3380\n",
      "\n",
      "2018-07-21T12:04:16.275722: step 3400, loss 0.0473937, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:04:16.646964: step 3400, loss 0.201763, acc 0.944025\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3400\n",
      "\n",
      "2018-07-21T12:04:19.800646: step 3420, loss 0.15406, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:04:20.173066: step 3420, loss 0.20812, acc 0.937587\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3420\n",
      "\n",
      "2018-07-21T12:04:23.333110: step 3440, loss 0.0913375, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:04:23.729409: step 3440, loss 0.205992, acc 0.945984\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3440\n",
      "\n",
      "2018-07-21T12:04:26.851831: step 3460, loss 0.0877918, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:04:27.225380: step 3460, loss 0.195688, acc 0.947103\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3460\n",
      "\n",
      "2018-07-21T12:04:30.416318: step 3480, loss 0.068482, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:04:30.789791: step 3480, loss 0.20911, acc 0.947383\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3480\n",
      "\n",
      "2018-07-21T12:04:34.077852: step 3500, loss 0.082385, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:04:34.450516: step 3500, loss 0.206754, acc 0.947383\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3500\n",
      "\n",
      "2018-07-21T12:04:37.589331: step 3520, loss 0.0745579, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:04:37.965628: step 3520, loss 0.207539, acc 0.934229\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3520\n",
      "\n",
      "2018-07-21T12:04:41.132355: step 3540, loss 0.0909597, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:04:41.501663: step 3540, loss 0.208834, acc 0.941506\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3540\n",
      "\n",
      "2018-07-21T12:04:44.663873: step 3560, loss 0.0706095, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:04:45.035082: step 3560, loss 0.210739, acc 0.944305\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3560\n",
      "\n",
      "2018-07-21T12:04:48.193691: step 3580, loss 0.0501814, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:04:48.566554: step 3580, loss 0.230744, acc 0.946544\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3580\n",
      "\n",
      "2018-07-21T12:04:51.795545: step 3600, loss 0.0853229, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:04:52.168704: step 3600, loss 0.1963, acc 0.944025\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3600\n",
      "\n",
      "2018-07-21T12:04:55.320063: step 3620, loss 0.237722, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:04:55.694926: step 3620, loss 0.192642, acc 0.943465\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3620\n",
      "\n",
      "2018-07-21T12:04:58.849014: step 3640, loss 0.127918, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:04:59.222221: step 3640, loss 0.207645, acc 0.945704\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3640\n",
      "\n",
      "2018-07-21T12:05:02.377837: step 3660, loss 0.17978, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:05:02.752363: step 3660, loss 0.224345, acc 0.947383\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3660\n",
      "\n",
      "2018-07-21T12:05:05.897907: step 3680, loss 0.0625229, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:05:06.267071: step 3680, loss 0.198245, acc 0.944584\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3680\n",
      "\n",
      "2018-07-21T12:05:09.424419: step 3700, loss 0.069334, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:05:09.806485: step 3700, loss 0.214274, acc 0.948503\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3700\n",
      "\n",
      "2018-07-21T12:05:13.050385: step 3720, loss 0.0639822, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:05:13.425230: step 3720, loss 0.202979, acc 0.947943\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3720\n",
      "\n",
      "2018-07-21T12:05:16.760204: step 3740, loss 0.0963119, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:05:17.141495: step 3740, loss 0.204514, acc 0.934789\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3740\n",
      "\n",
      "2018-07-21T12:05:21.604330: step 3760, loss 0.0543848, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:05:22.247150: step 3760, loss 0.198246, acc 0.937867\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3760\n",
      "\n",
      "2018-07-21T12:05:27.650838: step 3780, loss 0.0931945, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:05:28.284452: step 3780, loss 0.206029, acc 0.940946\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3780\n",
      "\n",
      "2018-07-21T12:05:36.545832: step 3800, loss 0.103232, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:05:37.041259: step 3800, loss 0.202575, acc 0.941226\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3800\n",
      "\n",
      "2018-07-21T12:05:46.623906: step 3820, loss 0.0766211, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:05:50.796942: step 3820, loss 0.222513, acc 0.947103\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3820\n",
      "\n",
      "2018-07-21T12:05:54.198525: step 3840, loss 0.0810466, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:05:54.782698: step 3840, loss 0.209264, acc 0.947663\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3840\n",
      "\n",
      "2018-07-21T12:06:02.277861: step 3860, loss 0.0730673, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:06:02.909082: step 3860, loss 0.198216, acc 0.948223\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3860\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-07-21T12:06:07.401917: step 3880, loss 0.227594, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:06:15.710425: step 3880, loss 0.213301, acc 0.948783\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3880\n",
      "\n",
      "2018-07-21T12:06:19.272398: step 3900, loss 0.0635935, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:06:19.697184: step 3900, loss 0.199961, acc 0.940946\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3900\n",
      "\n",
      "2018-07-21T12:06:22.881137: step 3920, loss 0.104896, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:06:23.302076: step 3920, loss 0.249873, acc 0.944025\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3920\n",
      "\n",
      "2018-07-21T12:06:26.686836: step 3940, loss 0.0762946, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:06:27.110136: step 3940, loss 0.19822, acc 0.948223\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3940\n",
      "\n",
      "2018-07-21T12:06:30.303746: step 3960, loss 0.0877286, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:06:30.734506: step 3960, loss 0.206157, acc 0.948503\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3960\n",
      "\n",
      "2018-07-21T12:06:33.898926: step 3980, loss 0.0970112, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:06:34.318013: step 3980, loss 0.1952, acc 0.946544\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-3980\n",
      "\n",
      "2018-07-21T12:06:37.592287: step 4000, loss 0.0795357, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:06:38.019873: step 4000, loss 0.2153, acc 0.949062\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4000\n",
      "\n",
      "2018-07-21T12:06:41.176713: step 4020, loss 0.156675, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:06:41.610951: step 4020, loss 0.252676, acc 0.914358\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4020\n",
      "\n",
      "2018-07-21T12:06:44.817887: step 4040, loss 0.123737, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:06:45.263787: step 4040, loss 0.186688, acc 0.949622\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4040\n",
      "\n",
      "2018-07-21T12:06:48.433828: step 4060, loss 0.0460058, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:06:48.854813: step 4060, loss 0.209663, acc 0.947943\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4060\n",
      "\n",
      "2018-07-21T12:06:52.047426: step 4080, loss 0.10669, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:06:52.477635: step 4080, loss 0.21379, acc 0.945984\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4080\n",
      "\n",
      "2018-07-21T12:06:55.658168: step 4100, loss 0.0780357, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:06:56.086954: step 4100, loss 0.191947, acc 0.938707\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4100\n",
      "\n",
      "2018-07-21T12:06:59.257707: step 4120, loss 0.0593076, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:06:59.669989: step 4120, loss 0.182923, acc 0.948223\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4120\n",
      "\n",
      "2018-07-21T12:07:02.790373: step 4140, loss 0.125748, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:07:04.985370: step 4140, loss 0.209138, acc 0.947103\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4140\n",
      "\n",
      "2018-07-21T12:07:08.471760: step 4160, loss 0.0956505, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:07:08.903669: step 4160, loss 0.202831, acc 0.942905\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4160\n",
      "\n",
      "2018-07-21T12:07:12.074591: step 4180, loss 0.104265, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:07:12.490005: step 4180, loss 0.194945, acc 0.947943\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4180\n",
      "\n",
      "2018-07-21T12:07:15.910142: step 4200, loss 0.118121, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:07:16.291477: step 4200, loss 0.180568, acc 0.948223\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4200\n",
      "\n",
      "2018-07-21T12:07:19.568607: step 4220, loss 0.0481884, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:07:19.949885: step 4220, loss 0.254872, acc 0.939826\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4220\n",
      "\n",
      "2018-07-21T12:07:23.176172: step 4240, loss 0.168089, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:07:23.613847: step 4240, loss 0.189531, acc 0.939267\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4240\n",
      "\n",
      "2018-07-21T12:07:27.008093: step 4260, loss 0.0730466, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:07:27.456583: step 4260, loss 0.219873, acc 0.948503\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4260\n",
      "\n",
      "2018-07-21T12:07:30.651544: step 4280, loss 0.0968727, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:07:31.085922: step 4280, loss 0.232775, acc 0.949902\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4280\n",
      "\n",
      "2018-07-21T12:07:34.279711: step 4300, loss 0.0559339, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:07:34.701649: step 4300, loss 0.210549, acc 0.948503\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4300\n",
      "\n",
      "2018-07-21T12:07:37.886142: step 4320, loss 0.0429963, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:07:38.318703: step 4320, loss 0.213654, acc 0.947943\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4320\n",
      "\n",
      "2018-07-21T12:07:41.624179: step 4340, loss 0.115204, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:07:42.051623: step 4340, loss 0.222375, acc 0.950182\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4340\n",
      "\n",
      "2018-07-21T12:07:45.243244: step 4360, loss 0.0595765, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:07:45.677300: step 4360, loss 0.197729, acc 0.944864\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4360\n",
      "\n",
      "2018-07-21T12:07:48.907489: step 4380, loss 0.0508784, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:07:49.340333: step 4380, loss 0.204281, acc 0.948223\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4380\n",
      "\n",
      "2018-07-21T12:07:52.581938: step 4400, loss 0.0563039, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:07:52.966995: step 4400, loss 0.208823, acc 0.950462\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4400\n",
      "\n",
      "2018-07-21T12:07:56.455676: step 4420, loss 0.0597542, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:07:56.895429: step 4420, loss 0.21402, acc 0.949062\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4420\n",
      "\n",
      "2018-07-21T12:08:00.083038: step 4440, loss 0.0648384, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:08:00.511793: step 4440, loss 0.224799, acc 0.948783\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4440\n",
      "\n",
      "2018-07-21T12:08:03.655536: step 4460, loss 0.104937, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:08:04.077551: step 4460, loss 0.235652, acc 0.947943\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4460\n",
      "\n",
      "2018-07-21T12:08:07.265857: step 4480, loss 0.0443454, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:08:07.697276: step 4480, loss 0.209185, acc 0.949342\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4480\n",
      "\n",
      "2018-07-21T12:08:11.033575: step 4500, loss 0.0499641, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:08:11.458068: step 4500, loss 0.212456, acc 0.947943\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4500\n",
      "\n",
      "2018-07-21T12:08:15.100198: step 4520, loss 0.0635145, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:08:15.547025: step 4520, loss 0.213329, acc 0.945144\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4520\n",
      "\n",
      "2018-07-21T12:08:19.007825: step 4540, loss 0.058038, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:08:19.436957: step 4540, loss 0.203045, acc 0.947943\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4540\n",
      "\n",
      "2018-07-21T12:08:23.094265: step 4560, loss 0.0472292, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:08:23.520061: step 4560, loss 0.218508, acc 0.944025\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4560\n",
      "\n",
      "2018-07-21T12:08:27.264784: step 4580, loss 0.0420673, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:08:27.707033: step 4580, loss 0.252917, acc 0.947943\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4580\n",
      "\n",
      "2018-07-21T12:08:31.239047: step 4600, loss 0.0409701, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:08:31.617422: step 4600, loss 0.219012, acc 0.949902\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4600\n",
      "\n",
      "2018-07-21T12:08:35.034291: step 4620, loss 0.0488916, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:08:35.466835: step 4620, loss 0.204759, acc 0.942065\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4620\n",
      "\n",
      "2018-07-21T12:08:38.863899: step 4640, loss 0.0654047, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:08:39.301775: step 4640, loss 0.272957, acc 0.947383\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4640\n",
      "\n",
      "2018-07-21T12:08:42.787188: step 4660, loss 0.0617515, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:08:43.209103: step 4660, loss 0.19995, acc 0.948783\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4660\n",
      "\n",
      "2018-07-21T12:08:46.740448: step 4680, loss 0.237389, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:08:47.170372: step 4680, loss 0.220456, acc 0.941786\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4680\n",
      "\n",
      "2018-07-21T12:08:50.742247: step 4700, loss 0.0695546, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:08:51.124429: step 4700, loss 0.217694, acc 0.948783\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4700\n",
      "\n",
      "2018-07-21T12:08:54.480262: step 4720, loss 0.0437712, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:08:54.912764: step 4720, loss 0.222085, acc 0.949342\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4720\n",
      "\n",
      "2018-07-21T12:08:58.409925: step 4740, loss 0.0930243, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:08:58.853238: step 4740, loss 0.205553, acc 0.951301\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4740\n",
      "\n",
      "2018-07-21T12:09:02.407795: step 4760, loss 0.0438903, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:09:02.859022: step 4760, loss 0.215421, acc 0.949902\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4760\n",
      "\n",
      "2018-07-21T12:09:06.178449: step 4780, loss 0.0658678, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:09:06.605675: step 4780, loss 0.217133, acc 0.938707\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4780\n",
      "\n",
      "2018-07-21T12:09:09.905754: step 4800, loss 0.112442, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:09:10.358858: step 4800, loss 0.20876, acc 0.950742\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4800\n",
      "\n",
      "2018-07-21T12:09:13.838796: step 4820, loss 0.115029, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:09:14.272498: step 4820, loss 0.209141, acc 0.946823\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4820\n",
      "\n",
      "2018-07-21T12:09:17.925253: step 4840, loss 0.0992488, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:09:18.363894: step 4840, loss 0.197384, acc 0.947943\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4840\n",
      "\n",
      "2018-07-21T12:09:21.694029: step 4860, loss 0.0840065, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:09:22.077782: step 4860, loss 0.204272, acc 0.949902\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4860\n",
      "\n",
      "2018-07-21T12:09:25.242069: step 4880, loss 0.0482969, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:09:25.671135: step 4880, loss 0.204549, acc 0.948503\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4880\n",
      "\n",
      "2018-07-21T12:09:28.848325: step 4900, loss 0.0437789, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:09:29.224844: step 4900, loss 0.207702, acc 0.947943\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4900\n",
      "\n",
      "2018-07-21T12:09:32.690626: step 4920, loss 0.0479066, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:09:33.121174: step 4920, loss 0.198009, acc 0.947663\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4920\n",
      "\n",
      "2018-07-21T12:09:36.373997: step 4940, loss 0.0701944, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:09:36.805528: step 4940, loss 0.197721, acc 0.947663\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4940\n",
      "\n",
      "2018-07-21T12:09:40.327206: step 4960, loss 0.0582742, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:09:40.754704: step 4960, loss 0.229327, acc 0.952421\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4960\n",
      "\n",
      "2018-07-21T12:09:44.069567: step 4980, loss 0.0535844, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:09:44.507822: step 4980, loss 0.238279, acc 0.952141\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-4980\n",
      "\n",
      "2018-07-21T12:09:48.061032: step 5000, loss 0.0759665, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:09:48.516510: step 5000, loss 0.238492, acc 0.951581\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-5000\n",
      "\n",
      "2018-07-21T12:09:51.808447: step 5020, loss 0.117095, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:09:52.237815: step 5020, loss 0.209422, acc 0.935908\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-5020\n",
      "\n",
      "2018-07-21T12:09:55.584814: step 5040, loss 0.0593958, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:09:56.015492: step 5040, loss 0.214072, acc 0.95382\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-5040\n",
      "\n",
      "2018-07-21T12:09:59.398736: step 5060, loss 0.0400759, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:09:59.836058: step 5060, loss 0.21809, acc 0.952141\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-5060\n",
      "\n",
      "2018-07-21T12:10:03.301294: step 5080, loss 0.0423084, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:10:03.752896: step 5080, loss 0.216713, acc 0.951022\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-5080\n",
      "\n",
      "2018-07-21T12:10:07.142528: step 5100, loss 0.065942, acc 0.984375\n",
      "\n",
      "Evaluation:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-07-21T12:10:07.573667: step 5100, loss 0.211546, acc 0.951861\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-5100\n",
      "\n",
      "2018-07-21T12:10:10.972024: step 5120, loss 0.149619, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:10:11.401097: step 5120, loss 0.197219, acc 0.951022\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-5120\n",
      "\n",
      "2018-07-21T12:10:14.722975: step 5140, loss 0.0509599, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-07-21T12:10:15.167757: step 5140, loss 0.20517, acc 0.946823\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/Workspace/char_level_cnn/runs/word_cnn_2/2018_07_21_11_53_28/checkpoints/model-5140\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-9f50c2b1b433>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0mcurrent_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-9f50c2b1b433>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(x_batch, y_batch)\u001b[0m\n\u001b[1;32m     58\u001b[0m               \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_weight\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;31m#ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             }\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_summary_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mtime_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misoformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    session_conf = tf.ConfigProto(\n",
    "      allow_soft_placement=allow_soft_placement,\n",
    "      log_device_placement=log_device_placement)\n",
    "    sess = tf.Session(config=session_conf)\n",
    "    \n",
    "    with sess.as_default():\n",
    "        \n",
    "        cnn = TextCNN(sequence_length, num_classes, vocab_size, embedding_size, filter_sizes, num_filters, l2_reg_lambda)\n",
    "\n",
    "\n",
    "        global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "        grads_and_vars = optimizer.compute_gradients(cnn.loss)\n",
    "        train_op = optimizer.apply_gradients(grads_and_vars, global_step=global_step)\n",
    "\n",
    "\n",
    "        grad_summaries = []\n",
    "        for g, v in grads_and_vars:\n",
    "            if g is not None:\n",
    "                grad_hist_summary = tf.summary.histogram(\"{}/grad/hist\".format(v.name), g)\n",
    "                sparsity_summary = tf.summary.scalar(\"{}/grad/sparsity\".format(v.name), tf.nn.zero_fraction(g))\n",
    "                grad_summaries.append(grad_hist_summary)\n",
    "                grad_summaries.append(sparsity_summary)\n",
    "        grad_summaries_merged = tf.summary.merge(grad_summaries)\n",
    "\n",
    "\n",
    "        loss_summary = tf.summary.scalar(\"loss\", cnn.loss)\n",
    "        acc_summary = tf.summary.scalar(\"accuracy\", cnn.accuracy)\n",
    "\n",
    "        train_summary_op = tf.summary.merge([loss_summary, acc_summary, grad_summaries_merged])\n",
    "        \n",
    "        train_summary_dir = os.path.join(out_dir, \"summaries\", \"train\")\n",
    "        train_summary_writer = tf.summary.FileWriter(train_summary_dir, sess.graph)\n",
    "\n",
    "        test_summary_op = tf.summary.merge([loss_summary, acc_summary])\n",
    "        test_summary_dir = os.path.join(out_dir, \"summaries\", \"test\")\n",
    "        test_summary_writer = tf.summary.FileWriter(test_summary_dir, sess.graph)\n",
    "\n",
    "        if save_checkpoint:\n",
    "            checkpoint_dir = os.path.abspath(os.path.join(out_dir, \"checkpoints\"))\n",
    "            checkpoint_prefix = os.path.join(checkpoint_dir, \"model\")\n",
    "            if not os.path.exists(checkpoint_dir):\n",
    "                os.makedirs(checkpoint_dir)\n",
    "            saver = tf.train.Saver(tf.global_variables(), max_to_keep=num_checkpoints)\n",
    "\n",
    "  \n",
    "        vocab_processor.save(os.path.join(out_dir, \"vocab\"))\n",
    "\n",
    "\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        def train_step(x_batch, y_batch):\n",
    "            feed_dict = {\n",
    "              cnn.input_x: x_batch,\n",
    "              cnn.input_y: y_batch,\n",
    "              cnn.dropout_keep_prob: dropout_keep_prob,\n",
    "              cnn.loss_weight: 1.0#ratio\n",
    "            }\n",
    "            _, step, summaries, loss, accuracy = sess.run([train_op, global_step, train_summary_op, cnn.loss, cnn.accuracy], feed_dict)\n",
    "            \n",
    "            time_str = datetime.datetime.now().isoformat()\n",
    "            if step % 20 == 0:\n",
    "                print(\"{}: step {}, loss {:g}, acc {:g}\".format(time_str, step, loss, accuracy))\n",
    "            train_summary_writer.add_summary(summaries, step)\n",
    "\n",
    "        def test_step(x_batch, y_batch, writer=None):\n",
    "            feed_dict = {\n",
    "              cnn.input_x: x_batch,\n",
    "              cnn.input_y: y_batch,\n",
    "              cnn.dropout_keep_prob: 1.0,\n",
    "              cnn.loss_weight: 1.0\n",
    "            }\n",
    "            step, summaries, loss, accuracy = sess.run([global_step, test_summary_op, cnn.loss, cnn.accuracy], feed_dict)\n",
    "            time_str = datetime.datetime.now().isoformat()\n",
    "            print(\"{}: step {}, loss {:g}, acc {:g}\".format(time_str, step, loss, accuracy))\n",
    "            if writer:\n",
    "                writer.add_summary(summaries, step)\n",
    "\n",
    "        batches = batch_iter(list(zip(x_train, y_train)), batch_size, num_epochs)\n",
    "        for batch in batches:\n",
    "            x_batch, y_batch = zip(*batch)\n",
    "            train_step(x_batch, y_batch)\n",
    "            current_step = tf.train.global_step(sess, global_step)\n",
    "            \n",
    "            if current_step % evaluate_every == 0:\n",
    "                print(\"\\nEvaluation:\")\n",
    "                test_step(x_test, y_test, writer=test_summary_writer)\n",
    "                print(\"\")\n",
    "                \n",
    "            if save_checkpoint and current_step % evaluate_every == 0:\n",
    "                path = saver.save(sess, checkpoint_prefix, global_step=current_step)\n",
    "                print(\"Saved model checkpoint to {}\\n\".format(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##char level cnn \n",
    "- 1525408577  \n",
    "- 1526189751 chABSA  good\n",
    "- 1523936751 amazon good\n",
    "- 2018_05_17_12_10_17 chABSA max_length 300\n",
    "- 2018_07_07_10_13_49 amazon_ja\n",
    "\n",
    "##word level cnn \n",
    "- 2018_05_17_12_46_51chABSA\n",
    "- 2018_07_07_13_04_25 amazon_ja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out_dir = os.path.join(os.path.curdir, \"runs\", \"2018_05_17_12_10_17\", prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = os.path.join(out_dir, \"checkpoints\" )\n",
    "latest_ckpt = tf.train.get_checkpoint_state(ckpt_dir).model_checkpoint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_neg_posi(text):\n",
    "    with tf.Graph().as_default():\n",
    "        session_conf = tf.ConfigProto(\n",
    "              allow_soft_placement=allow_soft_placement,\n",
    "              log_device_placement=log_device_placement)\n",
    "        sess = tf.Session(config=session_conf)\n",
    "        vocab_processor = preprocessing.VocabularyProcessor.restore(os.path.join(out_dir, \"vocab\"))\n",
    "        with sess.as_default():\n",
    "            cnn = TextCNN(\n",
    "                sequence_length=max_length,\n",
    "                num_classes=2,\n",
    "                vocab_size=vocab_size,\n",
    "                embedding_size=embedding_size,\n",
    "                filter_sizes=filter_sizes,\n",
    "                num_filters=num_filters,\n",
    "                l2_reg_lambda=l2_reg_lambda)\n",
    "            saver = tf.train.Saver()\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            saver.restore(sess, latest_ckpt)\n",
    "        \n",
    "            text = [s.replace(\" \", \"\").replace(\"\", \" \").lower() for s in [text]]\n",
    "            x = np.array(list(vocab_processor.fit_transform(text)))\n",
    "            feed_dict = {\n",
    "                  cnn.input_x: x,\n",
    "                  cnn.dropout_keep_prob: 1.0\n",
    "                }\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            feature_2 = sess.run(cnn.scores, feed_dict=feed_dict)\n",
    "    print(feature_2[0])\n",
    "    if np.argmax(feature_2[0]):\n",
    "        print(\"positive\")\n",
    "    else:\n",
    "        print(\"negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_neg_posi(\"当四半期連結累計期間の営業利益は、前年同期比5,184億円増加し、7,127億円となりました。この大幅な増益は、主に半導体分野の大幅な損益改善及び前年同期に映画分野の営業権の減損損失を計上していたことによるものです。 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_neg_posi(\"伸び率は減少傾向にありました。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_neg_posi(\"伸び率は加向にありました。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_neg_posi(\"伸び率は減向にありました。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_acc(x, y, max_length):\n",
    "    with tf.Graph().as_default():\n",
    "        with tf.Session() as sess:\n",
    "            cnn = TextCNN(\n",
    "                sequence_length=max_length,\n",
    "                num_classes=2,\n",
    "                vocab_size=vocab_size,\n",
    "                embedding_size=embedding_size,\n",
    "                filter_sizes=filter_sizes,\n",
    "                num_filters=num_filters,\n",
    "                l2_reg_lambda=l2_reg_lambda)\n",
    "            \n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            saver = tf.train.Saver()\n",
    "            \n",
    "            saver.restore(sess, latest_ckpt)\n",
    "        \n",
    "            feed_dict = {\n",
    "              cnn.input_x: x,\n",
    "              cnn.input_y: y,\n",
    "              cnn.dropout_keep_prob: 1.0\n",
    "            }\n",
    "            acc, scores = sess.run([cnn.accuracy, cnn.scores], feed_dict=feed_dict)\n",
    "    return acc, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_char(x_test ,n):\n",
    "    drop_x_test = []\n",
    "    for x in  x_test:\n",
    "        x_c = x.copy()\n",
    "        for i in choice(range(max_length), n,replace=False):\n",
    "            x_c[i] = randint(max_length)\n",
    "        drop_x_test.append(x_c)\n",
    "    return drop_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,s = eval_acc(x_test, y_test, max_length=max_length)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,s = eval_acc(drop_char(x_test, 100), y_test, max_length=max_length)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = []\n",
    "for i in tqdm(range(max_length)):\n",
    "    a,s = eval_acc(drop_char(x_test, i), y_test, max_length=max_length)\n",
    "    print(a)\n",
    "    r.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(max_length), r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_drop_doc(positive_data_file, negative_data_file, n):\n",
    "       \n",
    "    positive_examples = list(open(positive_data_file, \"r\").readlines())\n",
    "    negative_examples = list(open(negative_data_file, \"r\").readlines())\n",
    "    po = []\n",
    "    ne = []\n",
    "    t = Tokenizer()\n",
    "    for e in positive_examples:\n",
    "        if len(e) < n:\n",
    "            e_ = \"\"\n",
    "            for _ in  range(len(e)):\n",
    "                e_ += chr(randint(12354, 20000)) + \" \"\n",
    "            e = e_\n",
    "        else:\n",
    "            max_n = n\n",
    "            for i in choice(range(len(e)), max_n, replace=False):\n",
    "                e = e.replace(e[i], chr(randint(12354, 20000)))\n",
    "        po.append(t.tokenize(e))\n",
    "        \n",
    "    for e in negative_examples:\n",
    "        if len(e) < n:\n",
    "            e = \"{} \".format(chr(randint(12354, 20000))) * len(e)\n",
    "        else:\n",
    "            max_n = n\n",
    "            for i in choice(range(len(e)), max_n, replace=False):\n",
    "                e = e.replace(e[i], chr(randint(12354, 20000)))\n",
    "        ne.append(t.tokenize(e))\n",
    "\n",
    "   \n",
    "    positive_examples = po\n",
    "    negative_examples = ne\n",
    "        \n",
    "    x_text = positive_examples + negative_examples\n",
    "\n",
    "    positive_labels = [[0, 1] for _ in positive_examples]\n",
    "    negative_labels = [[1, 0] for _ in negative_examples]\n",
    "    y = np.concatenate([positive_labels, negative_labels], 0)\n",
    "    \n",
    "    #return po, y\n",
    "    return x_text, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_, y_ = create_drop_doc(positive_data_file, negative_data_file, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(list(vocab_processor.fit_transform(x_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[shuffle_indices][test_sample_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,s = eval_acc(x_test, y_test, max_length=max_length)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,s = eval_acc(x, y_test, max_length=max_length)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = []\n",
    "for i in tqdm(range(max_length)):\n",
    "    x_, y_ = create_drop_doc(positive_data_file, negative_data_file, i)\n",
    "    x = np.array(list(vocab_processor.fit_transform(x_)))\n",
    "    x = x[shuffle_indices][test_sample_index:]\n",
    "    a,s = eval_acc(x, y_test,max_length=max_length)\n",
    "    print(a)\n",
    "    r.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(max_length), r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,s = eval_acc(drop_char(), y_test, max_length=max_length)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out_dir=\"runs/1523936751\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Graph().as_default():\n",
    "    session_conf = tf.ConfigProto(\n",
    "          allow_soft_placement=allow_soft_placement,\n",
    "          log_device_placement=log_device_placement)\n",
    "    sess = tf.Session(config=session_conf)\n",
    "    vocab_processor = preprocessing.VocabularyProcessor.restore(os.path.join(out_dir, \"vocab\"))\n",
    "    with sess.as_default():\n",
    "        cnn = TextCNN(\n",
    "                sequence_length=x_train.shape[1],\n",
    "                num_classes=y_train.shape[1],\n",
    "                vocab_size=len(vocab_processor.vocabulary_),\n",
    "                embedding_size=embedding_size,\n",
    "                filter_sizes=filter_sizes,\n",
    "                num_filters=num_filters,\n",
    "                l2_reg_lambda=l2_reg_lambda)\n",
    "        saver = tf.train.Saver()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        saver.restore(sess, latest_ckpt)\n",
    "        #sess.run(tf.global_variables_initializer())\n",
    "        w = sess.run(cnn.W, feed_dict={cnn.input_x: x_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('embedding_tensor.tsv','w') as f:\n",
    "    for char_vec in w:\n",
    "        for weight in char_vec:\n",
    "            f.write(str(weight)+ \"\\t\")\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab_dict = vocab_processor.vocabulary_._mapping\n",
    "vocab_dict = vocab_processor.vocabulary_._reverse_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with  open('embedding_metadata.tsv' ,'w') as f:\n",
    "    f.write('Titles\\tGenres\\n')\n",
    "    for i,v in enumerate(w):\n",
    "        f.write(\"%s\\t%s\\n\" % (vocab_dict[i], vocab_dict[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(x):\n",
    "    with tf.Graph().as_default():\n",
    "        session_conf = tf.ConfigProto(\n",
    "          allow_soft_placement=allow_soft_placement,\n",
    "          log_device_placement=log_device_placement)\n",
    "        sess = tf.Session(config=session_conf)\n",
    "        with sess.as_default():\n",
    "            cnn = TextCNN(\n",
    "                sequence_length=x_train.shape[1],\n",
    "                num_classes=y_train.shape[1],\n",
    "                vocab_size=len(vocab_processor.vocabulary_),\n",
    "                embedding_size=embedding_dim,\n",
    "                filter_sizes=list(map(int, filter_sizes.split(\",\"))),\n",
    "                num_filters=num_filters,\n",
    "                l2_reg_lambda=l2_reg_lambda)\n",
    "\n",
    "            saver = tf.train.Saver()\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            saver.restore(sess, latest_ckpt)\n",
    "\n",
    "            feed_dict = {\n",
    "                  cnn.input_x: x,\n",
    "                  cnn.dropout_keep_prob: 1.0\n",
    "                }\n",
    "            feature_5, feature_2 = sess.run([cnn.f_h, cnn.scores ], feed_dict=feed_dict)\n",
    "    return feature_5, feature_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = list(open(\"data/amazon/rating_5.txt\", \"r\").readlines())\n",
    "review = [s.strip() for s in review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "x = []\n",
    "for r in review:\n",
    "    l = r.split(\":::::\")\n",
    "    y.append(float(l[0]))\n",
    "    x.append(l[1].replace(\" \", \"\").replace(\"\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_processor = preprocessing.VocabularyProcessor.restore(os.path.join(\"runs/1525408577\", \"vocab\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(list(vocab_processor.fit_transform(x)))\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_5 ,feature_2 = get_feature(x[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_5[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_5[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0\n",
    "chunk_size = 100\n",
    "for i in range(0, len(x) , chunk_size):\n",
    "    feature_5 ,feature_2 = get_feature(x[i:i+chunk_size])\n",
    "    for f, r in zip(feature_5, y[i:i+chunk_size]):\n",
    "        s  += int(np.argmax(f) == r)\n",
    "    print(s/(i+chunk_size))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(feature_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_2 [0]  #[neg, pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(list(vocab_processor.fit_transform(x_text)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
