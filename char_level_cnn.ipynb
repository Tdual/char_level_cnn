{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset  \n",
    "- amazon review\n",
    "http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Books_5.json.gz\n",
    "\n",
    "- chABSA\n",
    "https://github.com/chakki-works/chABSA-dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/ShopRunner/jupyter-notify\n",
    "```\n",
    "pip install jupyternotify\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The jupyternotify extension is already loaded. To reload it, use:\n",
      "  %reload_ext jupyternotify\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from tensorflow.contrib.learn import preprocessing\n",
    "import pickle\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "%load_ext jupyternotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN:\n",
    "\n",
    "    def __init__(\n",
    "      self, sequence_length, num_classes, vocab_size, embedding_size, filter_sizes, num_filters, l2_reg_lambda=0.0):\n",
    "\n",
    "\n",
    "        self.input_x = tf.placeholder(tf.int32, [None, sequence_length], name=\"input_x\")\n",
    "        self.input_y = tf.placeholder(tf.float32, [None, num_classes], name=\"input_y\")\n",
    "        self.dropout_keep_prob = tf.placeholder(tf.float32, name=\"dropout_keep_prob\")\n",
    "\n",
    "        l2_loss = tf.constant(0.0)\n",
    "\n",
    "\n",
    "        with tf.device('/cpu:0'), tf.name_scope(\"embedding\"):\n",
    "            self.W = tf.Variable(tf.random_uniform([vocab_size, embedding_size], -1.0, 1.0), name=\"W\")\n",
    "            self.embedded_chars = tf.nn.embedding_lookup(self.W, self.input_x)\n",
    "            self.embedded_chars_expanded = tf.expand_dims(self.embedded_chars, -1)\n",
    "\n",
    " \n",
    "        pooled_outputs = []\n",
    "        for i, filter_size in enumerate(filter_sizes):\n",
    "            with tf.name_scope(\"conv-maxpool-%s\" % filter_size):\n",
    "                filter_shape = [filter_size, embedding_size, 1, num_filters]\n",
    "                W = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.1), name=\"W\")\n",
    "                b = tf.Variable(tf.constant(0.1, shape=[num_filters]), name=\"b\")\n",
    "                conv = tf.nn.conv2d(self.embedded_chars_expanded,W,strides=[1, 1, 1, 1],padding=\"VALID\", name=\"conv\")\n",
    "                h = tf.nn.relu(tf.nn.bias_add(conv, b), name=\"relu\")\n",
    "                pooled = tf.nn.max_pool(h, ksize=[1, sequence_length - filter_size + 1, 1, 1],strides=[1, 1, 1, 1],padding='VALID',name=\"pool\")\n",
    "                pooled_outputs.append(pooled)\n",
    "\n",
    "\n",
    "        num_filters_total = num_filters * len(filter_sizes)\n",
    "        self.h_pool = tf.concat(pooled_outputs, 3)\n",
    "        self.h_pool_flat = tf.reshape(self.h_pool, [-1, num_filters_total])\n",
    "        \n",
    "\n",
    "        with tf.name_scope(\"fc-1\"):\n",
    "            W = tf.Variable(tf.truncated_normal([num_filters_total, 1024], stddev=0.1), name=\"W\")\n",
    "            b = tf.Variable(tf.constant(0.1, shape=[1024]), name=\"b\")\n",
    "            l2_loss += tf.nn.l2_loss(W)\n",
    "            l2_loss += tf.nn.l2_loss(b)\n",
    "            fc_1_output = tf.nn.relu(tf.nn.xw_plus_b(self.h_pool_flat, W, b), name=\"fc-1-out\")\n",
    "\n",
    "\n",
    "        with tf.name_scope(\"dropout-1\"):\n",
    "            drop_1 = tf.nn.dropout(fc_1_output, self.dropout_keep_prob)\n",
    "\n",
    "\n",
    "        with tf.name_scope(\"fc-2\"):\n",
    "            W = tf.Variable(tf.truncated_normal([1024,1024], stddev=0.1), name=\"W\")\n",
    "            b = tf.Variable(tf.constant(0.1, shape=[1024]), name=\"b\")\n",
    "            l2_loss += tf.nn.l2_loss(W)\n",
    "            l2_loss += tf.nn.l2_loss(b)\n",
    "            fc_2_output = tf.nn.relu(tf.nn.xw_plus_b(drop_1, W, b), name=\"fc-2-out\")\n",
    "            \n",
    "        with tf.name_scope(\"dropout-2\"):\n",
    "            drop_2 = tf.nn.dropout(fc_2_output, self.dropout_keep_prob)\n",
    "\n",
    "\n",
    "        with tf.name_scope(\"fc-3\"):\n",
    "            W = tf.Variable(tf.truncated_normal([1024, num_classes], stddev=0.1), name=\"W\")\n",
    "            b = tf.Variable(tf.constant(0.1, shape=[num_classes]), name=\"b\")\n",
    "            l2_loss += tf.nn.l2_loss(W)\n",
    "            l2_loss += tf.nn.l2_loss(b)\n",
    "            self.scores = tf.nn.xw_plus_b(drop_2, W, b, name=\"output\")\n",
    "            self.predictions = tf.argmax(self.scores, 1, name=\"predictions\")\n",
    "            \n",
    "            \n",
    "        with tf.name_scope(\"loss\"):\n",
    "            losses = tf.nn.softmax_cross_entropy_with_logits(logits=self.scores, labels=self.input_y)\n",
    "            self.loss = tf.reduce_mean(losses) + l2_reg_lambda * l2_loss\n",
    "\n",
    "\n",
    "        with tf.name_scope(\"accuracy\"):\n",
    "            correct_predictions = tf.equal(self.predictions, tf.argmax(self.input_y, 1))\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"), name=\"accuracy\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#positive_data_file = \"data/amazon/book_pos.txt\"\n",
    "#negative_data_file = \"data/amazon/book_neg.txt\"\n",
    "positive_data_file = \"data/chABSA/pos.txt\"\n",
    "negative_data_file = \"data/chABSA/neg.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_and_labels(positive_data_file, negative_data_file, level=\"char\"):\n",
    "       \n",
    "    positive_examples = list(open(positive_data_file, \"r\").readlines())\n",
    "    negative_examples = list(open(negative_data_file, \"r\").readlines())\n",
    "    if level == \"char\":\n",
    "        positive_examples = [s.replace(\" \", \"\").replace(\"\", \" \").lower() for s in positive_examples]\n",
    "        negative_examples = [s.replace(\" \", \"\").replace(\"\", \" \").lower() for s in negative_examples]\n",
    "    elif level == \"word\":\n",
    "        positive_examples = [s.strip() for s in positive_examples]\n",
    "        negative_examples = [s.strip() for s in negative_examples]\n",
    "    else:\n",
    "        print(\"invaid value of 'level'. ('char' or 'word') \")\n",
    "        \n",
    "    x_text = positive_examples + negative_examples\n",
    "\n",
    "    positive_labels = [[0, 1] for _ in positive_examples]\n",
    "    negative_labels = [[1, 0] for _ in negative_examples]\n",
    "    y = np.concatenate([positive_labels, negative_labels], 0)\n",
    "    \n",
    "    return x_text, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"4bd05be7-31bb-49c8-9fce-c90e61b113cc\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"4bd05be7-31bb-49c8-9fce-c90e61b113cc\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify\n",
    "x_text, y = load_data_and_labels(positive_data_file, negative_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2830"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 当 連 結 会 計 年 度 の 世 界 経 済 は 、 米 国 を 中 心 に 景 気 は 概 ね 堅 調 に 推 移 し ま し た が 、 英 国 の e u 離 脱 問 題 に よ る 影 響 の ほ か 、 中 国 を は じ め と す る 新 興 国 経 済 の 減 速 懸 念 や 米 国 新 政 権 の 政 策 動 向 の 不 確 実 性 な ど 、 景 気 の 先 行 き は 不 透 明 な 状 況 が 続 き ま し た \\n '"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_list = np.array([len(r)for r in x_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   length\n",
       "0     225\n",
       "1     107\n",
       "2     131\n",
       "3     137\n",
       "4     137"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(length_list, columns=[\"length\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2830.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>162.599293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>77.631221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>149.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>201.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80%</th>\n",
       "      <td>217.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>265.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>805.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            length\n",
       "count  2830.000000\n",
       "mean    162.599293\n",
       "std      77.631221\n",
       "min       5.000000\n",
       "50%     149.000000\n",
       "75%     201.000000\n",
       "80%     217.000000\n",
       "90%     265.000000\n",
       "max     805.000000"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(percentiles=[0.5,0.75,0.8,0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "length    265.0\n",
       "Name: 0.9, dtype: float64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.quantile(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x1221f9a20>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlkAAAEICAYAAABswuGIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAGJVJREFUeJzt3X+Q3PV93/Hn22BjzLkIAr6RJdWHxwqFoCLDDcYl09wZJ+ZHEzkzOANDbJHQkaeDJ3arjiPiTmw3pVHaYBKnDrUSXBPH4UxsUxQgP4jMjcedYowwIIFMkc0VDogUjBA+TJkIv/vHfmQ24qRb6fZzu3vf52NmZ/f7+X72u5/3/ji99Pl+97uRmUiSJKm7XtPrAUiSJC1GhixJkqQKDFmSJEkVGLIkSZIqMGRJkiRVYMiSJEmqwJAlqe9ExFREvHuBH3MkIjIijl7Ix5W0eBmyJDVSL4KcpGYxZEmSJFVgyJLUtyLiNRGxISK+GxHfj4ibI+LEsm7/7r21EfF4RDwTER9ru++xEXFjROyJiB0R8dGImC7rvgD8U+AvImImIj7a9rCXz7Y9STpchixJ/ezXgPcCPwO8GdgDfOaAPj8NnAqcD/xmRJxW2j8OjABvBX4W+OX9d8jM9wOPAz+fmUOZ+V862J4kHRZDlqR+9kHgY5k5nZkvAZ8ALjng4PRPZuaLmfkA8ABwZmn/JeA/Z+aezJwGPt3hYx5se5J0WPwWjaR+9hbgloj4UVvby8Bw2/Lftd3+ITBUbr8ZeKJtXfvtQznY9iTpsDiTJamfPQFcmJlL2i6vz8wnO7jv08DytuUVB6zPro1SkmZhyJLUz/47cE1EvAUgIk6OiDUd3vdm4OqIOCEilgEfOmD9LlrHa0lSFYYsSf3s94HNwN9ExA+Au4F3dHjf/whMA48Bfwt8GXipbf1vA/8hIp6LiH/fvSFLUktkOmMuafGLiH8DXJqZP9PrsUhqBmeyJC1KEbE0Is4r59o6FVgP3NLrcUlqDr9dKGmxeh3wWeAU4DlgAvjDno5IUqO4u1CSJKkCdxdKkiRV0Be7C0866aQcGRnp+nZfeOEFjjvuuK5vd1A0uf4m1w7Nrt/am1k7NLv+JtcOC1//1q1bn8nMk+fq1xcha2RkhHvvvbfr252cnGRsbKzr2x0UTa6/ybVDs+u39rFeD6Nnmlx/k2uHha8/Iv5vJ/3cXShJklSBIUuSJKmCOUNWRLw+Iu6JiAci4qGI+GRpPyUivhkRj0bElyLidaX9mLK8s6wfqVuCJElS/+lkJusl4F2ZeSawGrggIs4Ffge4LjNXAnuAK0v/K4E9mfk24LrST5IkqVHmDFnZMlMWX1suCbyL1m+BAdwIvLfcXlOWKevPj4jo2oglSZIGQEcnI42Io4CtwNuAzwD/Fbi7zFYRESuAv8zMMyJiO3BBZk6Xdd8F3pGZzxywzXXAOoDh4eGzJyYmuldVMTMzw9DQUNe3OyiaXH+Ta4dm12/tzawdml1/k2uHha9/fHx8a2aOztWvo1M4ZObLwOqIWELrt79Om61buZ5t1upVSS4zNwGbAEZHR7PGVy/9Smtz629y7dDs+q19rNfD6Jkm19/k2qF/6z+sbxdm5nPAJHAusCQi9oe05cBT5fY0sAKgrD8eeLYbg5UkSRoUnXy78OQyg0VEHAu8G9gB3AVcUrqtBW4ttzeXZcr6r6U/kChJkhqmk92FS4Eby3FZrwFuzszbIuJhYCIi/hPwbeCG0v8G4AsRsZPWDNalFcatLhvZcHtH/aY2Xlx5JJIkLQ5zhqzMfBB4+yzt3wPOmaX9/wHv68roJEmSBpRnfJckSarAkCVJklSBIUuSJKkCQ5YkSVIFhixJkqQKDFmSJEkVGLIkSZIqMGRJkiRVYMiSJEmqwJAlSZJUgSFLkiSpAkOWJElSBYYsSZKkCgxZkiRJFRiyJEmSKjBkSZIkVWDIkiRJquDoXg9Ag2Vkw+0d9ZvaeHHlkUiS1N+cyZIkSarAkCVJklSBIUuSJKkCj8laxLY9uZcrOjyGSpIkdZchS1V4gLwkqencXShJklSBIUuSJKkCQ5YkSVIFc4asiFgREXdFxI6IeCgiPlzaPxERT0bE/eVyUdt9ro6InRHxSES8p2YBkiRJ/aiTA9/3Aesz876IeCOwNSLuLOuuy8zfbe8cEacDlwI/BbwZ+NuI+MnMfLmbA5ckSepnc85kZebTmXlfuf0DYAew7BB3WQNMZOZLmfkYsBM4pxuDlSRJGhSRmZ13jhgBvg6cAfw74ArgeeBeWrNdeyLivwF3Z+aflvvcAPxlZn75gG2tA9YBDA8Pnz0xMTHfWl5lZmaGoaGhrm93UOx+di+7Xuz1KA5t1bLjq2y36a99k+u39mbWDs2uv8m1w8LXPz4+vjUzR+fq1/F5siJiCPgK8JHMfD4irgd+C8hyfS3wq0DMcvdXJbnM3ARsAhgdHc2xsbFOh9KxyclJamx3UPzBF2/l2m39fSq0qcvHqmy36a99k+u39rFeD6Nnmlx/k2uH/q2/o28XRsRraQWsL2bmVwEyc1dmvpyZPwL+iFd2CU4DK9ruvhx4qntDliRJ6n+dfLswgBuAHZn5qbb2pW3dfhHYXm5vBi6NiGMi4hRgJXBP94YsSZLU/zrZl3Qe8H5gW0TcX9p+A7gsIlbT2hU4BXwQIDMfioibgYdpfTPxKr9ZKEmSmmbOkJWZ32D246zuOMR9rgGumce4dAid/i7g+lWVByJJkg7KM75LkiRVYMiSJEmqwJAlSZJUgSFLkiSpAkOWJElSBYYsSZKkCgxZkiRJFRiyJEmSKjBkSZIkVWDIkiRJqsCQJUmSVIEhS5IkqQJDliRJUgVH93oAaraRDbd31G9q48WVRyJJUnc5kyVJklSBIUuSJKkCQ5YkSVIFhixJkqQKDFmSJEkVGLIkSZIqMGRJkiRVYMiSJEmqwJAlSZJUgWd87yOdnv1ckiT1P2eyJEmSKjBkSZIkVTBnyIqIFRFxV0TsiIiHIuLDpf3EiLgzIh4t1yeU9oiIT0fEzoh4MCLOql2EJElSv+lkJmsfsD4zTwPOBa6KiNOBDcCWzFwJbCnLABcCK8tlHXB910ctSZLU5+YMWZn5dGbeV27/ANgBLAPWADeWbjcC7y231wB/ki13A0siYmnXRy5JktTHIjM77xwxAnwdOAN4PDOXtK3bk5knRMRtwMbM/EZp3wL8embee8C21tGa6WJ4ePjsiYmJeZbyajMzMwwNDXV9u7Vse3JvV7c3fCzserGrm+yZVcuOP6z+g/bad1uT67f2ZtYOza6/ybXDwtc/Pj6+NTNH5+rX8SkcImII+Arwkcx8PiIO2nWWtlcluczcBGwCGB0dzbGxsU6H0rHJyUlqbLeWK7p8Cof1q/Zx7bbFcZaOqcvHDqv/oL323dbk+q19rNfD6Jkm19/k2qF/6+/o24UR8VpaAeuLmfnV0rxr/27Acr27tE8DK9ruvhx4qjvDlSRJGgydfLswgBuAHZn5qbZVm4G15fZa4Na29g+UbxmeC+zNzKe7OGZJkqS+18m+pPOA9wPbIuL+0vYbwEbg5oi4EngceF9ZdwdwEbAT+CHwK10dsSRJ0gCYM2SVA9gPdgDW+bP0T+CqeY5LkiRpoHnGd0mSpAoMWZIkSRUYsiRJkipYHCdR0qI30uE5xKY2Xlx5JJIkdcaZLEmSpAoMWZIkSRUYsiRJkiowZEmSJFVgyJIkSarAkCVJklSBIUuSJKkCQ5YkSVIFhixJkqQKDFmSJEkVGLIkSZIqMGRJkiRVYMiSJEmqwJAlSZJUgSFLkiSpAkOWJElSBYYsSZKkCgxZkiRJFRiyJEmSKjBkSZIkVWDIkiRJqsCQJUmSVMGcISsiPhcRuyNie1vbJyLiyYi4v1wualt3dUTsjIhHIuI9tQYuSZLUzzqZyfo8cMEs7ddl5upyuQMgIk4HLgV+qtznDyPiqG4NVpIkaVDMGbIy8+vAsx1ubw0wkZkvZeZjwE7gnHmMT5IkaSDN55isD0XEg2V34gmlbRnwRFuf6dImSZLUKJGZc3eKGAFuy8wzyvIw8AyQwG8BSzPzVyPiM8D/zsw/Lf1uAO7IzK/Mss11wDqA4eHhsycmJrpSULuZmRmGhoa6vt1atj25t6vbGz4Wdr3Y1U32vVXLjgcG77XvtibXb+3NrB2aXX+Ta4eFr398fHxrZo7O1e/oI9l4Zu7afzsi/gi4rSxOAyvaui4HnjrINjYBmwBGR0dzbGzsSIZySJOTk9TYbi1XbLi9q9tbv2of1247opd4YE1dPgYM3mvfbU2u39rHej2Mnmly/U2uHfq3/iPaXRgRS9sWfxHY/83DzcClEXFMRJwCrATumd8QJUmSBs+c0xwRcRMwBpwUEdPAx4GxiFhNa3fhFPBBgMx8KCJuBh4G9gFXZebLdYYuSZLUv+YMWZl52SzNNxyi/zXANfMZlCRJ0qDzjO+SJEkVGLIkSZIqMGRJkiRVYMiSJEmqwJAlSZJUgSFLkiSpgmadDlyL3kg5a/76VfsOeQb9qY0XL9SQJEkN5UyWJElSBYYsSZKkCgxZkiRJFRiyJEmSKvDAdzXSyCEOij+QB8lLko6EM1mSJEkVGLIkSZIqMGRJkiRVYMiSJEmqwJAlSZJUgSFLkiSpAkOWJElSBYYsSZKkCgxZkiRJFRiyJEmSKjBkSZIkVWDIkiRJqsCQJUmSVIEhS5IkqYI5Q1ZEfC4idkfE9ra2EyPizoh4tFyfUNojIj4dETsj4sGIOKvm4CVJkvpVJzNZnwcuOKBtA7AlM1cCW8oywIXAynJZB1zfnWFKkiQNljlDVmZ+HXj2gOY1wI3l9o3Ae9va/yRb7gaWRMTSbg1WkiRpUBzpMVnDmfk0QLl+U2lfBjzR1m+6tEmSJDVKZObcnSJGgNsy84yy/FxmLmlbvyczT4iI24HfzsxvlPYtwEczc+ss21xHa5ciw8PDZ09MTHShnH9sZmaGoaGhrm+3lm1P7u3q9oaPhV0vdnWTA6Obta9adnx3NrSABu29303W3szaodn1N7l2WPj6x8fHt2bm6Fz9jj7C7e+KiKWZ+XTZHbi7tE8DK9r6LQeemm0DmbkJ2AQwOjqaY2NjRziUg5ucnKTGdmu5YsPtXd3e+lX7uHbbkb7Eg62rtW97oaNuUxsv7s7jdcGgvfe7ydrHej2Mnmly/U2uHfq3/iPdXbgZWFturwVubWv/QPmW4bnA3v27FSVJkppkzv/qR8RNwBhwUkRMAx8HNgI3R8SVwOPA+0r3O4CLgJ3AD4FfqTBmSZKkvjdnyMrMyw6y6vxZ+iZw1XwHJUmSNOiaecCOVMFIh8fU9dOxW5KkevxZHUmSpAqcyVoAnc5wSJKkxcOZLEmSpAoMWZIkSRUYsiRJkiowZEmSJFVgyJIkSarAkCVJklSBIUuSJKkCQ5YkSVIFhixJkqQKDFmSJEkVGLIkSZIqMGRJkiRVYMiSJEmqwJAlSZJUgSFLkiSpgqN7PQCpaUY23N5Rv6mNF1ceiSSpJmeyJEmSKjBkSZIkVWDIkiRJqsCQJUmSVIEhS5IkqQJDliRJUgWGLEmSpAoMWZIkSRXM62SkETEF/AB4GdiXmaMRcSLwJWAEmAJ+KTP3zG+YkiRJg6UbM1njmbk6M0fL8gZgS2auBLaUZUmSpEap8bM6a4CxcvtGYBL49QqPIy1q/vyOJA22yMwjv3PEY8AeIIHPZuamiHguM5e09dmTmSfMct91wDqA4eHhsycmJo54HAczMzPD0NBQ17d7uLY9ubcnjzt8LOx6sScP3XNNqn3VsuNf1dYv7/1esPZm1g7Nrr/JtcPC1z8+Pr61bQ/eQc13Juu8zHwqIt4E3BkR3+n0jpm5CdgEMDo6mmNjY/McyqtNTk5SY7uH64oOZyS6bf2qfVy7rZm/Ad6k2qcuH3tVW7+893vB2sd6PYyeaXL9Ta4d+rf+eR2TlZlPlevdwC3AOcCuiFgKUK53z3eQkiRJg+aIQ1ZEHBcRb9x/G/g5YDuwGVhbuq0Fbp3vICVJkgbNfPanDAO3RMT+7fxZZv5VRHwLuDkirgQeB943/2FKkiQNliMOWZn5PeDMWdq/D5w/n0FJkiQNOs/4LkmSVIEhS5IkqQJDliRJUgWGLEmSpAqacbZGSR3r9Od8wJ/0kaRDcSZLkiSpAmeypAE328zT+lX7XvVzTs46SdLCciZLkiSpAmeypIY4nGOtJEnz50yWJElSBc5kzYMzA5Ik6WAMWZKOWKf/0fCge0lN5O5CSZKkCgxZkiRJFRiyJEmSKjBkSZIkVWDIkiRJqsCQJUmSVIEhS5IkqQJDliRJUgWejFRSdZ60VFITOZMlSZJUQaNmsvzftLQ4HOqzvH7VPq4o6/0sS+qlRoUsSf3NH12XtJi4u1CSJKkCZ7Jm4f+mpcWh259ldz9KOhzVQlZEXAD8PnAU8MeZubHWY0lSv+nVMaAeeyr1jyohKyKOAj4D/CwwDXwrIjZn5sM1Hk+SFkIvZ7k7eez1q/bR6Z91w5hUX62ZrHOAnZn5PYCImADWAIYsSWq4fg94NcbX7zUPgkH8VnFkZvc3GnEJcEFm/uuy/H7gHZn5obY+64B1ZfFU4JGuDwROAp6psN1B0eT6m1w7NLt+a2+uJtff5Nph4et/S2aePFenWjNZMUvbP0pzmbkJ2FTp8VuDiLg3M0drPkY/a3L9Ta4dml2/tTezdmh2/U2uHfq3/lqncJgGVrQtLweeqvRYkiRJfadWyPoWsDIiTomI1wGXApsrPZYkSVLfqbK7MDP3RcSHgL+mdQqHz2XmQzUeaw5Vd0cOgCbX3+Taodn1W3tzNbn+JtcOfVp/lQPfJUmSms6f1ZEkSarAkCVJklTBog1ZEXFBRDwSETsjYkOvx9NtEfG5iNgdEdvb2k6MiDsj4tFyfUJpj4j4dHkuHoyIs3o38u6IiBURcVdE7IiIhyLiw6V90T8HEfH6iLgnIh4otX+ytJ8SEd8stX+pfOmEiDimLO8s60d6Of5uiIijIuLbEXFbWW5S7VMRsS0i7o+Ie0vbon/fA0TEkoj4ckR8p3z239mg2k8tr/n+y/MR8ZEG1f9vy9+77RFxU/k72Pef+0UZsuKVn/W5EDgduCwiTu/tqLru88AFB7RtALZk5kpgS1mG1vOwslzWAdcv0Bhr2gesz8zTgHOBq8pr3ITn4CXgXZl5JrAauCAizgV+B7iu1L4HuLL0vxLYk5lvA64r/Qbdh4EdbctNqh1gPDNXt50XqAnve2j9Hu5fZeY/A86k9R5oRO2Z+Uh5zVcDZwM/BG6hAfVHxDLg14DRzDyD1hfqLmUQPveZueguwDuBv25bvhq4utfjqlDnCLC9bfkRYGm5vRR4pNz+LHDZbP0WywW4ldZvZTbqOQDeANwHvIPW2Y6PLu0//gzQ+pbvO8vto0u/6PXY51Hzclr/mLwLuI3WyY8bUXupYwo46YC2Rf++B/4J8NiBr18Tap/lufg54H81pX5gGfAEcGL5HN8GvGcQPveLciaLV16Q/aZL22I3nJlPA5TrN5X2Rf18lKngtwPfpCHPQdlddj+wG7gT+C7wXGbuK13a6/tx7WX9XuAnFnbEXfV7wEeBH5Xln6A5tUPr1zP+JiK2RuvnyaAZ7/u3An8P/I+yq/iPI+I4mlH7gS4Fbiq3F339mfkk8LvA48DTtD7HWxmAz/1iDVlz/qxPwyza5yMihoCvAB/JzOcP1XWWtoF9DjLz5WztNlhO6wfZT5utW7leNLVHxL8Cdmfm1vbmWbouutrbnJeZZ9HaHXRVRPzLQ/RdTPUfDZwFXJ+Zbwde4JVdY7NZTLX/WDnu6BeAP5+r6yxtA1l/Oc5sDXAK8GbgOFrv/wP13ed+sYaspv6sz66IWApQrneX9kX5fETEa2kFrC9m5ldLc6Oeg8x8DpikdVzakojYf4Lh9vp+XHtZfzzw7MKOtGvOA34hIqaACVq7DH+PZtQOQGY+Va530zom5xya8b6fBqYz85tl+cu0QlcTam93IXBfZu4qy02o/93AY5n595n5D8BXgX/BAHzuF2vIaurP+mwG1pbba2kdp7S//QPl2ybnAnv3Ty8PqogI4AZgR2Z+qm3Von8OIuLkiFhSbh9L6w/QDuAu4JLS7cDa9z8nlwBfy3KwwqDJzKszc3lmjtD6XH8tMy+nAbUDRMRxEfHG/bdpHZuznQa87zPz74AnIuLU0nQ+8DANqP0Al/HKrkJoRv2PA+dGxBvK3/79r33/f+57fUBbrQtwEfB/aB2r8rFej6dCfTfR2jf9D7RS+5W09jlvAR4t1yeWvkHr25bfBbbR+oZGz2uYZ/0/TWv690Hg/nK5qAnPAfDPgW+X2rcDv1na3wrcA+yktSvhmNL++rK8s6x/a69r6NLzMAbc1qTaS50PlMtD+/+2NeF9X+pZDdxb3vv/EzihKbWXmt4AfB84vq2tEfUDnwS+U/7mfQE4ZhA+9/6sjiRJUgWLdXehJElSTxmyJEmSKjBkSZIkVWDIkiRJqsCQJUmSVIEhS5IkqQJDliRJUgX/HyNCq7WduUJTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1221f93c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist(bins=50,figsize=(10,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_doc = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2830.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>162.599293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>77.631221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>107.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>149.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>201.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>805.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            length\n",
       "count  2830.000000\n",
       "mean    162.599293\n",
       "std      77.631221\n",
       "min       5.000000\n",
       "25%     107.000000\n",
       "50%     149.000000\n",
       "75%     201.000000\n",
       "max     805.000000"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if long_doc:\n",
    "    x_text = [x[:2000] if len(x) > 2000 else x for x in x_text]\n",
    "length_list = np.array([len(r)for r in x_text])\n",
    "df = pd.DataFrame(length_list, columns=[\"length\"])\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x11c62c978>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c62c710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist(bins=50,figsize=(10,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "level = \"char\" #\"word\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max document length 805\n"
     ]
    }
   ],
   "source": [
    "if level == \"word\":\n",
    "    max_document_length = max([len(x.split(\" \")) for x in x_text])\n",
    "elif level == \"char\":\n",
    "    max_document_length = max([len(x) for x in x_text])\n",
    "print(\"max document length\", max_document_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_processor = preprocessing.VocabularyProcessor(max_document_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"732245c1-f4a2-4316-a16d-ecd61dc4b012\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"732245c1-f4a2-4316-a16d-ecd61dc4b012\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify\n",
    "x = np.array(list(vocab_processor.fit_transform(x_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_percentage = 0.1#0.0010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 1517\n",
      "Train/Test split: 2547/283\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"c0190394-c419-4292-adc8-d1f8461a3b79\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"c0190394-c419-4292-adc8-d1f8461a3b79\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify\n",
    "np.random.seed(10)\n",
    "shuffle_indices = np.random.permutation(np.arange(len(y)))\n",
    "x_shuffled = x[shuffle_indices]\n",
    "y_shuffled = y[shuffle_indices]\n",
    "\n",
    "test_sample_index = -1 * int(test_percentage * float(len(y)))\n",
    "x_train, x_test = x_shuffled[:test_sample_index], x_shuffled[test_sample_index:]\n",
    "y_train, y_test = y_shuffled[:test_sample_index], y_shuffled[test_sample_index:]\n",
    "\n",
    "#del x, y, x_shuffled, y_shuffled\n",
    "\n",
    "print(\"Vocabulary Size: {:d}\".format(len(vocab_processor.vocabulary_)))\n",
    "print(\"Train/Test split: {:d}/{:d}\".format(len(y_train), len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2547, 805)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle():\n",
    "    chunk_size =  int(len(x_train)/10)\n",
    "    print(chunk_size)\n",
    "    for i in range(0, len(x_train), chunck_size):\n",
    "        print(i)\n",
    "        end = i+chunck_size\n",
    "        if end < len(x_train):\n",
    "            chunk = x_train[i:  end]\n",
    "        else:\n",
    "            chunk = x_train[i:]\n",
    "            end = len(x_train)\n",
    "        with open(\"data/x_train_{}.pkl\".format(end), \"wb\") as f:\n",
    "            pickle.dump(chunk, f, protocol = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_x_train():\n",
    "    all_size = 999000\n",
    "    chunk_size = 99900\n",
    "    x_train =[]\n",
    "    for i in range(0, all_size, chunck_size):\n",
    "        print(i)\n",
    "        end = i+chunk_size\n",
    "        if end > len(reviews):\n",
    "            end = all_size\n",
    "        with open(\"data/x_train_{}.pkl\".format(end), \"rb\") as f:\n",
    "            x_train += pickle.load(f)\n",
    "        return x_train\n",
    "#x_train = load_x_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iter(data, batch_size, num_epochs, shuffle=True):\n",
    "    data = np.array(data)\n",
    "    data_size = len(data)\n",
    "    num_batches_per_epoch = int((len(data)-1)/batch_size) + 1\n",
    "    print(\"num of epochs: \", num_epochs)\n",
    "    print(\"num of batches: \", num_batches_per_epoch)\n",
    "    print(\"num of step: \", num_batches_per_epoch*num_epochs)\n",
    "    for epoch in range(num_epochs):\n",
    "        if shuffle:\n",
    "            shuffle_indices = np.random.permutation(np.arange(data_size))\n",
    "            shuffled_data = data[shuffle_indices]\n",
    "        else:\n",
    "            shuffled_data = data\n",
    "        for batch_num in range(num_batches_per_epoch):\n",
    "            start_index = batch_num * batch_size\n",
    "            end_index = min((batch_num + 1) * batch_size, data_size)\n",
    "            yield shuffled_data[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = x_train.shape[1]\n",
    "num_classes = y_train.shape[1]\n",
    "vocab_size = len(vocab_processor.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 32     \n",
    "filter_sizes = [2,3,4,5]    \n",
    "num_filters=128               \n",
    "dropout_keep_prob=0.5 \n",
    "l2_reg_lambda=0.0       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.TextCNN at 0x1214c7f60>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextCNN(sequence_length, num_classes, vocab_size, embedding_size, filter_sizes, num_filters, l2_reg_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to ./runs/1526271055/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "timestamp = str(int(time.time()))\n",
    "#timestamp = \"1525609926\"\n",
    "prefix = \"\"\n",
    "#out_dir = os.path.abspath(os.path.join(os.path.curdir, \"runs\", timestamp, prefix))\n",
    "out_dir = os.path.join(os.path.curdir, \"runs\", timestamp, prefix)\n",
    "print(\"Writing to {}\\n\".format(out_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64                  \n",
    "num_epochs = 20#200            \n",
    "evaluate_every = 20         \n",
    "num_checkpoints = 5\n",
    "learning_rate = 1e-3\n",
    "\n",
    "allow_soft_placement = True    \n",
    "log_device_placement = False  \n",
    "\n",
    "save_checkpoint = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-2/W:0/grad/hist is illegal; using conv-maxpool-2/W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-2/W:0/grad/sparsity is illegal; using conv-maxpool-2/W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-2/b:0/grad/hist is illegal; using conv-maxpool-2/b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-2/b:0/grad/sparsity is illegal; using conv-maxpool-2/b_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name fc-1/W:0/grad/hist is illegal; using fc-1/W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name fc-1/W:0/grad/sparsity is illegal; using fc-1/W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name fc-1/b:0/grad/hist is illegal; using fc-1/b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name fc-1/b:0/grad/sparsity is illegal; using fc-1/b_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name fc-2/W:0/grad/hist is illegal; using fc-2/W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name fc-2/W:0/grad/sparsity is illegal; using fc-2/W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name fc-2/b:0/grad/hist is illegal; using fc-2/b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name fc-2/b:0/grad/sparsity is illegal; using fc-2/b_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name fc-3/W:0/grad/hist is illegal; using fc-3/W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name fc-3/W:0/grad/sparsity is illegal; using fc-3/W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name fc-3/b:0/grad/hist is illegal; using fc-3/b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name fc-3/b:0/grad/sparsity is illegal; using fc-3/b_0/grad/sparsity instead.\n",
      "num of epochs:  20\n",
      "num of batches:  40\n",
      "num of step:  800\n",
      "2018-05-14T13:11:01.350170: step 1, loss 9.52218, acc 0.53125\n",
      "2018-05-14T13:11:01.869680: step 2, loss 19.9094, acc 0.5625\n",
      "2018-05-14T13:11:02.282094: step 3, loss 12.7582, acc 0.390625\n",
      "2018-05-14T13:11:02.746881: step 4, loss 13.1349, acc 0.40625\n",
      "2018-05-14T13:11:03.225770: step 5, loss 11.9935, acc 0.578125\n",
      "2018-05-14T13:11:03.618021: step 6, loss 14.374, acc 0.53125\n",
      "2018-05-14T13:11:03.968269: step 7, loss 11.819, acc 0.53125\n",
      "2018-05-14T13:11:04.376392: step 8, loss 8.55033, acc 0.46875\n",
      "2018-05-14T13:11:04.793887: step 9, loss 11.369, acc 0.484375\n",
      "2018-05-14T13:11:05.140025: step 10, loss 12.1289, acc 0.546875\n",
      "2018-05-14T13:11:05.526372: step 11, loss 6.87571, acc 0.484375\n",
      "2018-05-14T13:11:06.006247: step 12, loss 9.65781, acc 0.453125\n",
      "2018-05-14T13:11:06.479794: step 13, loss 9.41122, acc 0.578125\n",
      "2018-05-14T13:11:06.914595: step 14, loss 7.76983, acc 0.578125\n",
      "2018-05-14T13:11:07.298018: step 15, loss 6.6261, acc 0.546875\n",
      "2018-05-14T13:11:07.670710: step 16, loss 7.54809, acc 0.359375\n",
      "2018-05-14T13:11:08.105890: step 17, loss 8.98961, acc 0.40625\n",
      "2018-05-14T13:11:08.463346: step 18, loss 7.55893, acc 0.46875\n",
      "2018-05-14T13:11:08.851670: step 19, loss 5.84134, acc 0.46875\n",
      "2018-05-14T13:11:09.222191: step 20, loss 4.72608, acc 0.671875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-14T13:11:10.003457: step 20, loss 3.24158, acc 0.625442\n",
      "\n",
      "Saved model checkpoint to /Users/tamoto.yoshifumi/Workspace/Python/char_level_cnn/runs/1526271055/checkpoints/model-20\n",
      "\n",
      "2018-05-14T13:11:10.551858: step 21, loss 5.651, acc 0.5625\n",
      "2018-05-14T13:11:10.904261: step 22, loss 5.35494, acc 0.625\n",
      "2018-05-14T13:11:11.246027: step 23, loss 5.33795, acc 0.59375\n",
      "2018-05-14T13:11:11.588679: step 24, loss 3.64255, acc 0.640625\n",
      "2018-05-14T13:11:11.923337: step 25, loss 5.60157, acc 0.5\n",
      "2018-05-14T13:11:12.256160: step 26, loss 6.39208, acc 0.421875\n",
      "2018-05-14T13:11:12.595919: step 27, loss 3.41292, acc 0.625\n",
      "2018-05-14T13:11:12.939827: step 28, loss 3.36377, acc 0.625\n",
      "2018-05-14T13:11:13.294134: step 29, loss 3.47684, acc 0.546875\n",
      "2018-05-14T13:11:13.633053: step 30, loss 2.55048, acc 0.6875\n",
      "2018-05-14T13:11:13.972334: step 31, loss 3.0703, acc 0.59375\n",
      "2018-05-14T13:11:14.329372: step 32, loss 4.23363, acc 0.484375\n",
      "2018-05-14T13:11:14.674883: step 33, loss 3.45126, acc 0.578125\n",
      "2018-05-14T13:11:15.014779: step 34, loss 2.97749, acc 0.546875\n",
      "2018-05-14T13:11:15.412992: step 35, loss 3.75657, acc 0.5625\n",
      "2018-05-14T13:11:15.757615: step 36, loss 4.01059, acc 0.5\n",
      "2018-05-14T13:11:16.095289: step 37, loss 4.6853, acc 0.453125\n",
      "2018-05-14T13:11:16.436526: step 38, loss 3.85354, acc 0.4375\n",
      "2018-05-14T13:11:16.768608: step 39, loss 4.20238, acc 0.5\n",
      "2018-05-14T13:11:17.041822: step 40, loss 2.86951, acc 0.509804\n",
      "\n",
      "Evaluation:\n",
      "2018-05-14T13:11:17.630288: step 40, loss 1.47396, acc 0.625442\n",
      "\n",
      "Saved model checkpoint to /Users/tamoto.yoshifumi/Workspace/Python/char_level_cnn/runs/1526271055/checkpoints/model-40\n",
      "\n",
      "2018-05-14T13:11:18.188814: step 41, loss 2.6665, acc 0.5\n",
      "2018-05-14T13:11:18.551793: step 42, loss 3.05815, acc 0.53125\n",
      "2018-05-14T13:11:18.975361: step 43, loss 2.19033, acc 0.46875\n",
      "2018-05-14T13:11:19.364969: step 44, loss 3.35879, acc 0.53125\n",
      "2018-05-14T13:11:19.760192: step 45, loss 3.03232, acc 0.546875\n",
      "2018-05-14T13:11:20.103061: step 46, loss 2.62023, acc 0.453125\n",
      "2018-05-14T13:11:20.602104: step 47, loss 1.80985, acc 0.640625\n",
      "2018-05-14T13:11:20.999778: step 48, loss 2.01927, acc 0.59375\n",
      "2018-05-14T13:11:21.346118: step 49, loss 3.34608, acc 0.5625\n",
      "2018-05-14T13:11:21.694909: step 50, loss 1.7892, acc 0.671875\n",
      "2018-05-14T13:11:22.030091: step 51, loss 2.37678, acc 0.453125\n",
      "2018-05-14T13:11:22.389192: step 52, loss 2.40249, acc 0.53125\n",
      "2018-05-14T13:11:22.871849: step 53, loss 2.81888, acc 0.53125\n",
      "2018-05-14T13:11:23.399272: step 54, loss 2.3915, acc 0.546875\n",
      "2018-05-14T13:11:23.857074: step 55, loss 1.28215, acc 0.65625\n",
      "2018-05-14T13:11:24.292237: step 56, loss 1.64218, acc 0.5\n",
      "2018-05-14T13:11:24.704053: step 57, loss 1.12528, acc 0.71875\n",
      "2018-05-14T13:11:25.108092: step 58, loss 2.09967, acc 0.65625\n",
      "2018-05-14T13:11:25.493431: step 59, loss 2.11064, acc 0.625\n",
      "2018-05-14T13:11:25.873609: step 60, loss 2.08174, acc 0.53125\n",
      "\n",
      "Evaluation:\n",
      "2018-05-14T13:11:26.839892: step 60, loss 0.704664, acc 0.65371\n",
      "\n",
      "Saved model checkpoint to /Users/tamoto.yoshifumi/Workspace/Python/char_level_cnn/runs/1526271055/checkpoints/model-60\n",
      "\n",
      "2018-05-14T13:11:27.408551: step 61, loss 1.32316, acc 0.515625\n",
      "2018-05-14T13:11:27.766147: step 62, loss 1.73587, acc 0.578125\n",
      "2018-05-14T13:11:28.165332: step 63, loss 2.19118, acc 0.484375\n",
      "2018-05-14T13:11:28.588589: step 64, loss 1.64621, acc 0.5\n",
      "2018-05-14T13:11:29.033552: step 65, loss 1.22812, acc 0.65625\n",
      "2018-05-14T13:11:29.480612: step 66, loss 2.13394, acc 0.5\n",
      "2018-05-14T13:11:29.897342: step 67, loss 1.60118, acc 0.5625\n",
      "2018-05-14T13:11:30.388564: step 68, loss 1.47487, acc 0.59375\n",
      "2018-05-14T13:11:30.816591: step 69, loss 1.47334, acc 0.53125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-14T13:11:31.187044: step 70, loss 1.80864, acc 0.46875\n",
      "2018-05-14T13:11:31.518569: step 71, loss 1.59018, acc 0.5625\n",
      "2018-05-14T13:11:31.857794: step 72, loss 1.4546, acc 0.53125\n",
      "2018-05-14T13:11:32.197292: step 73, loss 1.12823, acc 0.71875\n",
      "2018-05-14T13:11:32.549874: step 74, loss 1.15161, acc 0.65625\n",
      "2018-05-14T13:11:32.890185: step 75, loss 1.22194, acc 0.671875\n",
      "2018-05-14T13:11:33.232213: step 76, loss 1.09945, acc 0.671875\n",
      "2018-05-14T13:11:33.571958: step 77, loss 1.01891, acc 0.703125\n",
      "2018-05-14T13:11:33.906641: step 78, loss 0.892965, acc 0.65625\n",
      "2018-05-14T13:11:34.250388: step 79, loss 1.08629, acc 0.609375\n",
      "2018-05-14T13:11:34.524914: step 80, loss 0.98826, acc 0.647059\n",
      "\n",
      "Evaluation:\n",
      "2018-05-14T13:11:35.149493: step 80, loss 0.56008, acc 0.717314\n",
      "\n",
      "Saved model checkpoint to /Users/tamoto.yoshifumi/Workspace/Python/char_level_cnn/runs/1526271055/checkpoints/model-80\n",
      "\n",
      "2018-05-14T13:11:35.675805: step 81, loss 1.36983, acc 0.453125\n",
      "2018-05-14T13:11:36.089074: step 82, loss 0.805929, acc 0.640625\n",
      "2018-05-14T13:11:36.490012: step 83, loss 0.831258, acc 0.71875\n",
      "2018-05-14T13:11:36.865389: step 84, loss 1.32769, acc 0.515625\n",
      "2018-05-14T13:11:37.222272: step 85, loss 1.00537, acc 0.640625\n",
      "2018-05-14T13:11:37.595631: step 86, loss 1.27253, acc 0.640625\n",
      "2018-05-14T13:11:37.978544: step 87, loss 1.11046, acc 0.65625\n",
      "2018-05-14T13:11:38.356717: step 88, loss 1.03149, acc 0.6875\n",
      "2018-05-14T13:11:38.715968: step 89, loss 1.21854, acc 0.578125\n",
      "2018-05-14T13:11:39.077572: step 90, loss 1.05869, acc 0.59375\n",
      "2018-05-14T13:11:39.422067: step 91, loss 0.887942, acc 0.609375\n",
      "2018-05-14T13:11:39.778767: step 92, loss 0.990273, acc 0.5625\n",
      "2018-05-14T13:11:40.137950: step 93, loss 0.8889, acc 0.671875\n",
      "2018-05-14T13:11:40.501441: step 94, loss 1.24183, acc 0.5625\n",
      "2018-05-14T13:11:40.920868: step 95, loss 0.997944, acc 0.578125\n",
      "2018-05-14T13:11:41.356570: step 96, loss 1.03608, acc 0.578125\n",
      "2018-05-14T13:11:41.708180: step 97, loss 1.04761, acc 0.546875\n",
      "2018-05-14T13:11:42.064270: step 98, loss 0.732985, acc 0.65625\n",
      "2018-05-14T13:11:42.430076: step 99, loss 0.847105, acc 0.609375\n",
      "2018-05-14T13:11:42.791560: step 100, loss 0.90403, acc 0.53125\n",
      "\n",
      "Evaluation:\n",
      "2018-05-14T13:11:43.402242: step 100, loss 0.510987, acc 0.756184\n",
      "\n",
      "Saved model checkpoint to /Users/tamoto.yoshifumi/Workspace/Python/char_level_cnn/runs/1526271055/checkpoints/model-100\n",
      "\n",
      "2018-05-14T13:11:43.950235: step 101, loss 0.946461, acc 0.5\n",
      "2018-05-14T13:11:44.354489: step 102, loss 0.786734, acc 0.578125\n",
      "2018-05-14T13:11:44.765839: step 103, loss 0.85622, acc 0.609375\n",
      "2018-05-14T13:11:45.166437: step 104, loss 0.907829, acc 0.546875\n",
      "2018-05-14T13:11:45.663058: step 105, loss 0.702571, acc 0.640625\n",
      "2018-05-14T13:11:46.105128: step 106, loss 0.655989, acc 0.640625\n",
      "2018-05-14T13:11:46.506238: step 107, loss 0.683546, acc 0.65625\n",
      "2018-05-14T13:11:46.884862: step 108, loss 0.992275, acc 0.53125\n",
      "2018-05-14T13:11:47.283631: step 109, loss 0.770373, acc 0.65625\n",
      "2018-05-14T13:11:47.720320: step 110, loss 0.705616, acc 0.59375\n",
      "2018-05-14T13:11:48.215755: step 111, loss 0.712702, acc 0.625\n",
      "2018-05-14T13:11:48.708049: step 112, loss 0.658732, acc 0.625\n",
      "2018-05-14T13:11:49.156411: step 113, loss 0.734298, acc 0.609375\n",
      "2018-05-14T13:11:49.524098: step 114, loss 0.646531, acc 0.703125\n",
      "2018-05-14T13:11:49.855956: step 115, loss 0.72059, acc 0.59375\n",
      "2018-05-14T13:11:50.196602: step 116, loss 0.623929, acc 0.625\n",
      "2018-05-14T13:11:50.540692: step 117, loss 0.649898, acc 0.671875\n",
      "2018-05-14T13:11:50.944689: step 118, loss 0.533476, acc 0.671875\n",
      "2018-05-14T13:11:51.298210: step 119, loss 0.50932, acc 0.75\n",
      "2018-05-14T13:11:51.578093: step 120, loss 0.702084, acc 0.607843\n",
      "\n",
      "Evaluation:\n",
      "2018-05-14T13:11:52.131316: step 120, loss 0.506994, acc 0.766784\n",
      "\n",
      "Saved model checkpoint to /Users/tamoto.yoshifumi/Workspace/Python/char_level_cnn/runs/1526271055/checkpoints/model-120\n",
      "\n",
      "2018-05-14T13:11:52.685702: step 121, loss 0.586338, acc 0.765625\n",
      "2018-05-14T13:11:53.054694: step 122, loss 0.580767, acc 0.71875\n",
      "2018-05-14T13:11:53.427781: step 123, loss 0.640442, acc 0.59375\n",
      "2018-05-14T13:11:53.802919: step 124, loss 0.578809, acc 0.71875\n",
      "2018-05-14T13:11:54.156152: step 125, loss 0.615666, acc 0.703125\n",
      "2018-05-14T13:11:54.495862: step 126, loss 0.686817, acc 0.65625\n",
      "2018-05-14T13:11:54.853830: step 127, loss 0.415379, acc 0.796875\n",
      "2018-05-14T13:11:55.212467: step 128, loss 0.653655, acc 0.71875\n",
      "2018-05-14T13:11:55.569061: step 129, loss 0.492993, acc 0.734375\n",
      "2018-05-14T13:11:55.942445: step 130, loss 0.561984, acc 0.78125\n",
      "2018-05-14T13:11:56.300501: step 131, loss 0.505301, acc 0.6875\n",
      "2018-05-14T13:11:56.636940: step 132, loss 0.567208, acc 0.734375\n",
      "2018-05-14T13:11:56.978070: step 133, loss 0.531464, acc 0.6875\n",
      "2018-05-14T13:11:57.314035: step 134, loss 0.629798, acc 0.6875\n",
      "2018-05-14T13:11:57.662516: step 135, loss 0.685294, acc 0.71875\n",
      "2018-05-14T13:11:58.024794: step 136, loss 0.543814, acc 0.75\n",
      "2018-05-14T13:11:58.374387: step 137, loss 0.774821, acc 0.59375\n",
      "2018-05-14T13:11:58.757491: step 138, loss 0.520964, acc 0.765625\n",
      "2018-05-14T13:11:59.107036: step 139, loss 0.79655, acc 0.578125\n",
      "2018-05-14T13:11:59.538500: step 140, loss 0.660085, acc 0.671875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-14T13:12:00.156357: step 140, loss 0.493389, acc 0.766784\n",
      "\n",
      "Saved model checkpoint to /Users/tamoto.yoshifumi/Workspace/Python/char_level_cnn/runs/1526271055/checkpoints/model-140\n",
      "\n",
      "2018-05-14T13:12:00.718842: step 141, loss 0.600629, acc 0.6875\n",
      "2018-05-14T13:12:01.056477: step 142, loss 0.704533, acc 0.59375\n",
      "2018-05-14T13:12:01.401472: step 143, loss 0.636501, acc 0.6875\n",
      "2018-05-14T13:12:01.737110: step 144, loss 0.545018, acc 0.703125\n",
      "2018-05-14T13:12:02.169556: step 145, loss 0.769132, acc 0.65625\n",
      "2018-05-14T13:12:02.534056: step 146, loss 0.514409, acc 0.734375\n",
      "2018-05-14T13:12:02.939009: step 147, loss 0.631072, acc 0.65625\n",
      "2018-05-14T13:12:03.298809: step 148, loss 0.595601, acc 0.6875\n",
      "2018-05-14T13:12:03.650382: step 149, loss 0.54535, acc 0.75\n",
      "2018-05-14T13:12:04.000823: step 150, loss 0.718231, acc 0.65625\n",
      "2018-05-14T13:12:04.345498: step 151, loss 0.594005, acc 0.734375\n",
      "2018-05-14T13:12:04.722513: step 152, loss 0.502255, acc 0.734375\n",
      "2018-05-14T13:12:05.088203: step 153, loss 0.566005, acc 0.765625\n",
      "2018-05-14T13:12:05.481025: step 154, loss 0.554076, acc 0.71875\n",
      "2018-05-14T13:12:05.824529: step 155, loss 0.553576, acc 0.734375\n",
      "2018-05-14T13:12:06.202457: step 156, loss 0.513905, acc 0.734375\n",
      "2018-05-14T13:12:06.547134: step 157, loss 0.678928, acc 0.640625\n",
      "2018-05-14T13:12:06.958144: step 158, loss 0.61549, acc 0.75\n",
      "2018-05-14T13:12:07.305051: step 159, loss 0.49249, acc 0.75\n",
      "2018-05-14T13:12:07.612274: step 160, loss 0.603162, acc 0.784314\n",
      "\n",
      "Evaluation:\n",
      "2018-05-14T13:12:08.102677: step 160, loss 0.525251, acc 0.738516\n",
      "\n",
      "Saved model checkpoint to /Users/tamoto.yoshifumi/Workspace/Python/char_level_cnn/runs/1526271055/checkpoints/model-160\n",
      "\n",
      "2018-05-14T13:12:08.656917: step 161, loss 0.563858, acc 0.71875\n",
      "2018-05-14T13:12:09.020541: step 162, loss 0.659724, acc 0.765625\n",
      "2018-05-14T13:12:09.365598: step 163, loss 0.621895, acc 0.65625\n",
      "2018-05-14T13:12:09.723557: step 164, loss 0.605325, acc 0.703125\n",
      "2018-05-14T13:12:10.093870: step 165, loss 0.507686, acc 0.75\n",
      "2018-05-14T13:12:10.492126: step 166, loss 0.635128, acc 0.65625\n",
      "2018-05-14T13:12:11.021162: step 167, loss 0.471476, acc 0.75\n",
      "2018-05-14T13:12:11.469020: step 168, loss 0.47155, acc 0.8125\n",
      "2018-05-14T13:12:11.935733: step 169, loss 0.483771, acc 0.765625\n",
      "2018-05-14T13:12:12.385303: step 170, loss 0.512218, acc 0.71875\n",
      "2018-05-14T13:12:12.761354: step 171, loss 0.560149, acc 0.6875\n",
      "2018-05-14T13:12:13.123976: step 172, loss 0.614101, acc 0.6875\n",
      "2018-05-14T13:12:13.525160: step 173, loss 0.579922, acc 0.75\n",
      "2018-05-14T13:12:13.873952: step 174, loss 0.688432, acc 0.609375\n",
      "2018-05-14T13:12:14.214534: step 175, loss 0.570183, acc 0.75\n",
      "2018-05-14T13:12:14.592947: step 176, loss 0.589702, acc 0.734375\n",
      "2018-05-14T13:12:14.955403: step 177, loss 0.521618, acc 0.734375\n",
      "2018-05-14T13:12:15.346844: step 178, loss 0.543125, acc 0.765625\n",
      "2018-05-14T13:12:15.682227: step 179, loss 0.469795, acc 0.765625\n",
      "2018-05-14T13:12:16.002893: step 180, loss 0.491072, acc 0.765625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-14T13:12:16.600656: step 180, loss 0.399726, acc 0.833922\n",
      "\n",
      "Saved model checkpoint to /Users/tamoto.yoshifumi/Workspace/Python/char_level_cnn/runs/1526271055/checkpoints/model-180\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-14T13:12:17.145530: step 181, loss 0.483708, acc 0.796875\n",
      "2018-05-14T13:12:17.486463: step 182, loss 0.516477, acc 0.75\n",
      "2018-05-14T13:12:17.836343: step 183, loss 0.571847, acc 0.765625\n",
      "2018-05-14T13:12:18.205581: step 184, loss 0.534263, acc 0.671875\n",
      "2018-05-14T13:12:18.556321: step 185, loss 0.387738, acc 0.8125\n",
      "2018-05-14T13:12:18.896336: step 186, loss 0.471033, acc 0.796875\n",
      "2018-05-14T13:12:19.288088: step 187, loss 0.485586, acc 0.71875\n",
      "2018-05-14T13:12:19.720150: step 188, loss 0.496811, acc 0.765625\n",
      "2018-05-14T13:12:20.129215: step 189, loss 0.50899, acc 0.796875\n",
      "2018-05-14T13:12:20.611843: step 190, loss 0.451931, acc 0.75\n",
      "2018-05-14T13:12:21.021570: step 191, loss 0.468328, acc 0.78125\n",
      "2018-05-14T13:12:21.401931: step 192, loss 0.42376, acc 0.828125\n",
      "2018-05-14T13:12:21.732735: step 193, loss 0.528886, acc 0.734375\n",
      "2018-05-14T13:12:22.082146: step 194, loss 0.583652, acc 0.75\n",
      "2018-05-14T13:12:22.480631: step 195, loss 0.53793, acc 0.703125\n",
      "2018-05-14T13:12:22.816689: step 196, loss 0.538858, acc 0.734375\n",
      "2018-05-14T13:12:23.176055: step 197, loss 0.485957, acc 0.78125\n",
      "2018-05-14T13:12:23.508222: step 198, loss 0.472334, acc 0.796875\n",
      "2018-05-14T13:12:23.912942: step 199, loss 0.536758, acc 0.765625\n",
      "2018-05-14T13:12:24.194686: step 200, loss 0.467102, acc 0.72549\n",
      "\n",
      "Evaluation:\n",
      "2018-05-14T13:12:24.785071: step 200, loss 0.368945, acc 0.830389\n",
      "\n",
      "Saved model checkpoint to /Users/tamoto.yoshifumi/Workspace/Python/char_level_cnn/runs/1526271055/checkpoints/model-200\n",
      "\n",
      "2018-05-14T13:12:25.353856: step 201, loss 0.347086, acc 0.828125\n",
      "2018-05-14T13:12:25.732406: step 202, loss 0.308934, acc 0.90625\n",
      "2018-05-14T13:12:26.063931: step 203, loss 0.488121, acc 0.78125\n",
      "2018-05-14T13:12:26.410172: step 204, loss 0.327631, acc 0.875\n",
      "2018-05-14T13:12:26.739835: step 205, loss 0.519126, acc 0.75\n",
      "2018-05-14T13:12:27.069968: step 206, loss 0.440878, acc 0.875\n",
      "2018-05-14T13:12:27.417384: step 207, loss 0.45648, acc 0.75\n",
      "2018-05-14T13:12:27.788720: step 208, loss 0.463769, acc 0.75\n",
      "2018-05-14T13:12:28.127875: step 209, loss 0.364086, acc 0.859375\n",
      "2018-05-14T13:12:28.470361: step 210, loss 0.46153, acc 0.765625\n",
      "2018-05-14T13:12:28.794575: step 211, loss 0.373065, acc 0.84375\n",
      "2018-05-14T13:12:29.137352: step 212, loss 0.356445, acc 0.875\n",
      "2018-05-14T13:12:29.512033: step 213, loss 0.445629, acc 0.75\n",
      "2018-05-14T13:12:29.906068: step 214, loss 0.419873, acc 0.84375\n",
      "2018-05-14T13:12:30.255004: step 215, loss 0.39855, acc 0.796875\n",
      "2018-05-14T13:12:30.612935: step 216, loss 0.430846, acc 0.796875\n",
      "2018-05-14T13:12:30.947915: step 217, loss 0.470267, acc 0.796875\n",
      "2018-05-14T13:12:31.314039: step 218, loss 0.397444, acc 0.78125\n",
      "2018-05-14T13:12:31.653358: step 219, loss 0.460489, acc 0.78125\n",
      "2018-05-14T13:12:31.996615: step 220, loss 0.510243, acc 0.734375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-14T13:12:32.509375: step 220, loss 0.37907, acc 0.848057\n",
      "\n",
      "Saved model checkpoint to /Users/tamoto.yoshifumi/Workspace/Python/char_level_cnn/runs/1526271055/checkpoints/model-220\n",
      "\n",
      "2018-05-14T13:12:33.015782: step 221, loss 0.519219, acc 0.8125\n",
      "2018-05-14T13:12:33.359971: step 222, loss 0.445758, acc 0.796875\n",
      "2018-05-14T13:12:33.738178: step 223, loss 0.414147, acc 0.765625\n",
      "2018-05-14T13:12:34.075868: step 224, loss 0.410002, acc 0.828125\n",
      "2018-05-14T13:12:34.434639: step 225, loss 0.365039, acc 0.84375\n",
      "2018-05-14T13:12:34.838804: step 226, loss 0.502074, acc 0.796875\n",
      "2018-05-14T13:12:35.200416: step 227, loss 0.44834, acc 0.78125\n",
      "2018-05-14T13:12:35.570125: step 228, loss 0.359959, acc 0.890625\n",
      "2018-05-14T13:12:35.943177: step 229, loss 0.44666, acc 0.875\n",
      "2018-05-14T13:12:36.354226: step 230, loss 0.522129, acc 0.71875\n",
      "2018-05-14T13:12:36.705522: step 231, loss 0.439188, acc 0.78125\n",
      "2018-05-14T13:12:37.029138: step 232, loss 0.333714, acc 0.859375\n",
      "2018-05-14T13:12:37.368261: step 233, loss 0.722317, acc 0.6875\n",
      "2018-05-14T13:12:37.733611: step 234, loss 0.563078, acc 0.765625\n",
      "2018-05-14T13:12:38.103299: step 235, loss 0.498584, acc 0.8125\n",
      "2018-05-14T13:12:38.470309: step 236, loss 0.373531, acc 0.828125\n",
      "2018-05-14T13:12:38.852082: step 237, loss 0.321865, acc 0.84375\n",
      "2018-05-14T13:12:39.279310: step 238, loss 0.373488, acc 0.859375\n",
      "2018-05-14T13:12:39.620606: step 239, loss 0.448945, acc 0.765625\n",
      "2018-05-14T13:12:39.888445: step 240, loss 0.689545, acc 0.72549\n",
      "\n",
      "Evaluation:\n",
      "2018-05-14T13:12:40.403084: step 240, loss 0.404768, acc 0.80212\n",
      "\n",
      "Saved model checkpoint to /Users/tamoto.yoshifumi/Workspace/Python/char_level_cnn/runs/1526271055/checkpoints/model-240\n",
      "\n",
      "2018-05-14T13:12:40.926023: step 241, loss 0.406931, acc 0.71875\n",
      "2018-05-14T13:12:41.266005: step 242, loss 0.618632, acc 0.6875\n",
      "2018-05-14T13:12:41.671873: step 243, loss 0.538748, acc 0.71875\n",
      "2018-05-14T13:12:42.008682: step 244, loss 0.437076, acc 0.78125\n",
      "2018-05-14T13:12:42.366597: step 245, loss 0.321384, acc 0.875\n",
      "2018-05-14T13:12:42.733014: step 246, loss 0.504043, acc 0.78125\n",
      "2018-05-14T13:12:43.077335: step 247, loss 0.410229, acc 0.78125\n",
      "2018-05-14T13:12:43.434460: step 248, loss 0.455958, acc 0.78125\n",
      "2018-05-14T13:12:43.784848: step 249, loss 0.459648, acc 0.78125\n",
      "2018-05-14T13:12:44.141172: step 250, loss 0.398393, acc 0.796875\n",
      "2018-05-14T13:12:44.565875: step 251, loss 0.334098, acc 0.890625\n",
      "2018-05-14T13:12:44.945739: step 252, loss 0.282158, acc 0.890625\n",
      "2018-05-14T13:12:45.322734: step 253, loss 0.689194, acc 0.71875\n",
      "2018-05-14T13:12:45.679099: step 254, loss 0.505546, acc 0.765625\n",
      "2018-05-14T13:12:46.026185: step 255, loss 0.446029, acc 0.78125\n",
      "2018-05-14T13:12:46.365911: step 256, loss 0.377117, acc 0.78125\n",
      "2018-05-14T13:12:46.715101: step 257, loss 0.465217, acc 0.828125\n",
      "2018-05-14T13:12:47.089790: step 258, loss 0.364632, acc 0.84375\n",
      "2018-05-14T13:12:47.461939: step 259, loss 0.439357, acc 0.734375\n",
      "2018-05-14T13:12:47.904493: step 260, loss 0.346096, acc 0.796875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-14T13:12:48.526386: step 260, loss 0.346012, acc 0.855124\n",
      "\n",
      "Saved model checkpoint to /Users/tamoto.yoshifumi/Workspace/Python/char_level_cnn/runs/1526271055/checkpoints/model-260\n",
      "\n",
      "2018-05-14T13:12:49.115739: step 261, loss 0.42687, acc 0.78125\n",
      "2018-05-14T13:12:49.481022: step 262, loss 0.429527, acc 0.796875\n",
      "2018-05-14T13:12:49.863680: step 263, loss 0.399776, acc 0.828125\n",
      "2018-05-14T13:12:50.251237: step 264, loss 0.464998, acc 0.765625\n",
      "2018-05-14T13:12:50.648958: step 265, loss 0.430776, acc 0.78125\n",
      "2018-05-14T13:12:51.102377: step 266, loss 0.350168, acc 0.84375\n",
      "2018-05-14T13:12:51.465740: step 267, loss 0.331716, acc 0.828125\n",
      "2018-05-14T13:12:51.875368: step 268, loss 0.39649, acc 0.828125\n",
      "2018-05-14T13:12:52.280242: step 269, loss 0.472493, acc 0.796875\n",
      "2018-05-14T13:12:52.662183: step 270, loss 0.44277, acc 0.84375\n",
      "2018-05-14T13:12:53.054233: step 271, loss 0.336569, acc 0.875\n",
      "2018-05-14T13:12:53.412083: step 272, loss 0.344398, acc 0.890625\n",
      "2018-05-14T13:12:53.758359: step 273, loss 0.448093, acc 0.8125\n",
      "2018-05-14T13:12:54.107928: step 274, loss 0.467835, acc 0.765625\n",
      "2018-05-14T13:12:54.460049: step 275, loss 0.317234, acc 0.828125\n",
      "2018-05-14T13:12:54.800386: step 276, loss 0.434535, acc 0.84375\n",
      "2018-05-14T13:12:55.174543: step 277, loss 0.341709, acc 0.8125\n",
      "2018-05-14T13:12:55.521420: step 278, loss 0.316093, acc 0.859375\n",
      "2018-05-14T13:12:55.920225: step 279, loss 0.514744, acc 0.703125\n",
      "2018-05-14T13:12:56.189508: step 280, loss 0.40579, acc 0.862745\n",
      "\n",
      "Evaluation:\n",
      "2018-05-14T13:12:56.662468: step 280, loss 0.384602, acc 0.85159\n",
      "\n",
      "Saved model checkpoint to /Users/tamoto.yoshifumi/Workspace/Python/char_level_cnn/runs/1526271055/checkpoints/model-280\n",
      "\n",
      "2018-05-14T13:12:57.245012: step 281, loss 0.439515, acc 0.84375\n",
      "2018-05-14T13:12:57.625698: step 282, loss 0.380147, acc 0.859375\n",
      "2018-05-14T13:12:57.997675: step 283, loss 0.257243, acc 0.890625\n",
      "2018-05-14T13:12:58.355971: step 284, loss 0.695581, acc 0.734375\n",
      "2018-05-14T13:12:58.814276: step 285, loss 0.478428, acc 0.828125\n",
      "2018-05-14T13:12:59.155414: step 286, loss 0.261793, acc 0.875\n",
      "2018-05-14T13:12:59.556058: step 287, loss 0.438239, acc 0.796875\n",
      "2018-05-14T13:12:59.923402: step 288, loss 0.810444, acc 0.78125\n",
      "2018-05-14T13:13:00.291289: step 289, loss 0.425778, acc 0.796875\n",
      "2018-05-14T13:13:00.632038: step 290, loss 0.242992, acc 0.921875\n",
      "2018-05-14T13:13:00.970994: step 291, loss 0.327343, acc 0.828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-14T13:13:01.333855: step 292, loss 0.288694, acc 0.890625\n",
      "2018-05-14T13:13:01.701344: step 293, loss 0.436656, acc 0.8125\n",
      "2018-05-14T13:13:02.037305: step 294, loss 0.311906, acc 0.859375\n",
      "2018-05-14T13:13:02.383828: step 295, loss 0.372027, acc 0.828125\n",
      "2018-05-14T13:13:02.790880: step 296, loss 0.370055, acc 0.828125\n",
      "2018-05-14T13:13:03.177080: step 297, loss 0.366143, acc 0.84375\n",
      "2018-05-14T13:13:03.525223: step 298, loss 0.749527, acc 0.765625\n",
      "2018-05-14T13:13:03.873410: step 299, loss 0.392304, acc 0.796875\n",
      "2018-05-14T13:13:04.225642: step 300, loss 0.492338, acc 0.75\n",
      "\n",
      "Evaluation:\n",
      "2018-05-14T13:13:04.802061: step 300, loss 0.422221, acc 0.816254\n",
      "\n",
      "Saved model checkpoint to /Users/tamoto.yoshifumi/Workspace/Python/char_level_cnn/runs/1526271055/checkpoints/model-300\n",
      "\n",
      "2018-05-14T13:13:05.474137: step 301, loss 0.428253, acc 0.75\n",
      "2018-05-14T13:13:05.891130: step 302, loss 0.324788, acc 0.84375\n",
      "2018-05-14T13:13:06.339149: step 303, loss 0.325984, acc 0.90625\n",
      "2018-05-14T13:13:06.837840: step 304, loss 0.352989, acc 0.84375\n",
      "2018-05-14T13:13:07.357151: step 305, loss 0.563597, acc 0.71875\n",
      "2018-05-14T13:13:07.845539: step 306, loss 0.366937, acc 0.84375\n",
      "2018-05-14T13:13:08.316793: step 307, loss 0.334352, acc 0.84375\n",
      "2018-05-14T13:13:08.708123: step 308, loss 0.277204, acc 0.9375\n",
      "2018-05-14T13:13:09.165738: step 309, loss 0.388479, acc 0.8125\n",
      "2018-05-14T13:13:09.625044: step 310, loss 0.339552, acc 0.8125\n",
      "2018-05-14T13:13:09.998807: step 311, loss 0.330783, acc 0.875\n",
      "2018-05-14T13:13:10.406205: step 312, loss 0.264808, acc 0.859375\n",
      "2018-05-14T13:13:10.814972: step 313, loss 0.352292, acc 0.84375\n",
      "2018-05-14T13:13:11.203477: step 314, loss 0.41052, acc 0.828125\n",
      "2018-05-14T13:13:11.581046: step 315, loss 0.344244, acc 0.875\n",
      "2018-05-14T13:13:11.932279: step 316, loss 0.355907, acc 0.875\n",
      "2018-05-14T13:13:12.307306: step 317, loss 0.330805, acc 0.890625\n",
      "2018-05-14T13:13:12.652804: step 318, loss 0.43795, acc 0.8125\n",
      "2018-05-14T13:13:13.009038: step 319, loss 0.268743, acc 0.890625\n",
      "2018-05-14T13:13:13.319037: step 320, loss 0.318528, acc 0.843137\n",
      "\n",
      "Evaluation:\n",
      "2018-05-14T13:13:13.910952: step 320, loss 0.387476, acc 0.830389\n",
      "\n",
      "Saved model checkpoint to /Users/tamoto.yoshifumi/Workspace/Python/char_level_cnn/runs/1526271055/checkpoints/model-320\n",
      "\n",
      "2018-05-14T13:13:14.446409: step 321, loss 0.262204, acc 0.921875\n",
      "2018-05-14T13:13:14.884500: step 322, loss 0.30111, acc 0.875\n",
      "2018-05-14T13:13:15.257775: step 323, loss 0.393303, acc 0.828125\n",
      "2018-05-14T13:13:15.642318: step 324, loss 0.442485, acc 0.859375\n",
      "2018-05-14T13:13:15.987841: step 325, loss 0.388878, acc 0.890625\n",
      "2018-05-14T13:13:16.350785: step 326, loss 0.425419, acc 0.84375\n",
      "2018-05-14T13:13:16.680446: step 327, loss 0.229023, acc 0.90625\n",
      "2018-05-14T13:13:17.056799: step 328, loss 0.351644, acc 0.875\n",
      "2018-05-14T13:13:17.412115: step 329, loss 0.234389, acc 0.90625\n",
      "2018-05-14T13:13:17.830884: step 330, loss 0.29554, acc 0.875\n",
      "2018-05-14T13:13:18.202777: step 331, loss 0.200283, acc 0.953125\n",
      "2018-05-14T13:13:18.549179: step 332, loss 0.333846, acc 0.84375\n",
      "2018-05-14T13:13:18.907267: step 333, loss 0.215179, acc 0.921875\n",
      "2018-05-14T13:13:19.263720: step 334, loss 0.313474, acc 0.921875\n",
      "2018-05-14T13:13:19.599602: step 335, loss 0.406515, acc 0.796875\n",
      "2018-05-14T13:13:19.937318: step 336, loss 0.397471, acc 0.859375\n",
      "2018-05-14T13:13:20.292310: step 337, loss 0.32088, acc 0.84375\n",
      "2018-05-14T13:13:20.618785: step 338, loss 0.361765, acc 0.890625\n",
      "2018-05-14T13:13:20.945806: step 339, loss 0.40225, acc 0.8125\n",
      "2018-05-14T13:13:21.274744: step 340, loss 0.221352, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-14T13:13:21.723875: step 340, loss 0.319217, acc 0.865724\n",
      "\n",
      "Saved model checkpoint to /Users/tamoto.yoshifumi/Workspace/Python/char_level_cnn/runs/1526271055/checkpoints/model-340\n",
      "\n",
      "2018-05-14T13:13:22.229556: step 341, loss 0.311478, acc 0.875\n",
      "2018-05-14T13:13:22.565320: step 342, loss 0.364194, acc 0.84375\n",
      "2018-05-14T13:13:23.094853: step 343, loss 0.221333, acc 0.9375\n",
      "2018-05-14T13:13:23.423161: step 344, loss 0.348152, acc 0.828125\n",
      "2018-05-14T13:13:23.774183: step 345, loss 0.228382, acc 0.890625\n",
      "2018-05-14T13:13:24.128127: step 346, loss 0.239346, acc 0.921875\n",
      "2018-05-14T13:13:24.472593: step 347, loss 0.206651, acc 0.921875\n",
      "2018-05-14T13:13:24.806488: step 348, loss 0.270634, acc 0.921875\n",
      "2018-05-14T13:13:25.142140: step 349, loss 0.342101, acc 0.84375\n",
      "2018-05-14T13:13:25.475342: step 350, loss 0.377608, acc 0.796875\n",
      "2018-05-14T13:13:25.823604: step 351, loss 0.306467, acc 0.859375\n",
      "2018-05-14T13:13:26.161050: step 352, loss 0.369473, acc 0.875\n",
      "2018-05-14T13:13:26.492918: step 353, loss 0.455129, acc 0.828125\n",
      "2018-05-14T13:13:26.829012: step 354, loss 0.314213, acc 0.859375\n",
      "2018-05-14T13:13:27.154936: step 355, loss 0.39468, acc 0.875\n",
      "2018-05-14T13:13:27.498187: step 356, loss 0.314775, acc 0.859375\n",
      "2018-05-14T13:13:27.849415: step 357, loss 0.4126, acc 0.8125\n",
      "2018-05-14T13:13:28.348673: step 358, loss 0.159307, acc 0.9375\n",
      "2018-05-14T13:13:28.683867: step 359, loss 0.388747, acc 0.84375\n",
      "2018-05-14T13:13:28.948851: step 360, loss 0.300351, acc 0.882353\n",
      "\n",
      "Evaluation:\n",
      "2018-05-14T13:13:29.516263: step 360, loss 0.348027, acc 0.848057\n",
      "\n",
      "Saved model checkpoint to /Users/tamoto.yoshifumi/Workspace/Python/char_level_cnn/runs/1526271055/checkpoints/model-360\n",
      "\n",
      "2018-05-14T13:13:30.019157: step 361, loss 0.174376, acc 0.9375\n",
      "2018-05-14T13:13:30.370436: step 362, loss 0.355696, acc 0.859375\n",
      "2018-05-14T13:13:30.702750: step 363, loss 0.486103, acc 0.8125\n",
      "2018-05-14T13:13:31.104699: step 364, loss 0.31982, acc 0.84375\n",
      "2018-05-14T13:13:31.450241: step 365, loss 0.450446, acc 0.8125\n",
      "2018-05-14T13:13:31.803038: step 366, loss 0.427448, acc 0.859375\n",
      "2018-05-14T13:13:32.144029: step 367, loss 0.274684, acc 0.875\n",
      "2018-05-14T13:13:32.496443: step 368, loss 0.299035, acc 0.890625\n",
      "2018-05-14T13:13:32.837878: step 369, loss 0.374225, acc 0.84375\n",
      "2018-05-14T13:13:33.222189: step 370, loss 0.169244, acc 0.9375\n",
      "2018-05-14T13:13:33.576125: step 371, loss 0.24127, acc 0.90625\n",
      "2018-05-14T13:13:33.935640: step 372, loss 0.405821, acc 0.8125\n",
      "2018-05-14T13:13:34.283987: step 373, loss 0.361551, acc 0.828125\n",
      "2018-05-14T13:13:34.628495: step 374, loss 0.260825, acc 0.875\n",
      "2018-05-14T13:13:35.009469: step 375, loss 0.273423, acc 0.859375\n",
      "2018-05-14T13:13:35.368078: step 376, loss 0.332927, acc 0.90625\n",
      "2018-05-14T13:13:35.733679: step 377, loss 0.346917, acc 0.828125\n",
      "2018-05-14T13:13:36.169466: step 378, loss 0.194749, acc 0.921875\n",
      "2018-05-14T13:13:36.648843: step 379, loss 0.257893, acc 0.875\n",
      "2018-05-14T13:13:37.030779: step 380, loss 0.338059, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-14T13:13:37.652062: step 380, loss 0.365771, acc 0.840989\n",
      "\n",
      "Saved model checkpoint to /Users/tamoto.yoshifumi/Workspace/Python/char_level_cnn/runs/1526271055/checkpoints/model-380\n",
      "\n",
      "2018-05-14T13:13:38.327153: step 381, loss 0.381245, acc 0.875\n",
      "2018-05-14T13:13:38.848237: step 382, loss 0.325047, acc 0.828125\n",
      "2018-05-14T13:13:39.294967: step 383, loss 0.389342, acc 0.84375\n",
      "2018-05-14T13:13:39.735702: step 384, loss 0.275751, acc 0.9375\n",
      "2018-05-14T13:13:40.144312: step 385, loss 0.188614, acc 0.984375\n",
      "2018-05-14T13:13:40.567406: step 386, loss 0.312043, acc 0.828125\n",
      "2018-05-14T13:13:40.992155: step 387, loss 0.191826, acc 0.921875\n",
      "2018-05-14T13:13:41.453304: step 388, loss 0.314478, acc 0.859375\n",
      "2018-05-14T13:13:41.932516: step 389, loss 0.246882, acc 0.890625\n",
      "2018-05-14T13:13:42.411592: step 390, loss 0.345118, acc 0.8125\n",
      "2018-05-14T13:13:42.958015: step 391, loss 0.3776, acc 0.84375\n",
      "2018-05-14T13:13:43.310604: step 392, loss 0.288458, acc 0.890625\n",
      "2018-05-14T13:13:43.700509: step 393, loss 0.281366, acc 0.921875\n",
      "2018-05-14T13:13:44.136701: step 394, loss 0.322897, acc 0.828125\n",
      "2018-05-14T13:13:44.485691: step 395, loss 0.321281, acc 0.875\n",
      "2018-05-14T13:13:44.875570: step 396, loss 0.268886, acc 0.890625\n",
      "2018-05-14T13:13:45.250667: step 397, loss 0.342399, acc 0.796875\n",
      "2018-05-14T13:13:45.712920: step 398, loss 0.245112, acc 0.921875\n",
      "2018-05-14T13:13:46.059028: step 399, loss 0.212077, acc 0.90625\n",
      "2018-05-14T13:13:46.405035: step 400, loss 0.252839, acc 0.901961\n",
      "\n",
      "Evaluation:\n",
      "2018-05-14T13:13:47.117254: step 400, loss 0.302429, acc 0.869258\n",
      "\n",
      "Saved model checkpoint to /Users/tamoto.yoshifumi/Workspace/Python/char_level_cnn/runs/1526271055/checkpoints/model-400\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-14T13:13:47.759277: step 401, loss 0.231518, acc 0.890625\n",
      "2018-05-14T13:13:48.127168: step 402, loss 0.252986, acc 0.9375\n",
      "2018-05-14T13:13:48.607824: step 403, loss 0.174823, acc 0.9375\n",
      "2018-05-14T13:13:48.985921: step 404, loss 0.280952, acc 0.90625\n",
      "2018-05-14T13:13:49.425774: step 405, loss 0.476631, acc 0.796875\n",
      "2018-05-14T13:13:49.847585: step 406, loss 0.305765, acc 0.84375\n",
      "2018-05-14T13:13:50.290387: step 407, loss 0.23577, acc 0.90625\n",
      "2018-05-14T13:13:50.734726: step 408, loss 0.243668, acc 0.890625\n",
      "2018-05-14T13:13:51.126617: step 409, loss 0.223384, acc 0.921875\n",
      "2018-05-14T13:13:51.528172: step 410, loss 0.386394, acc 0.828125\n",
      "2018-05-14T13:13:51.935417: step 411, loss 0.27293, acc 0.875\n",
      "2018-05-14T13:13:52.306999: step 412, loss 0.217053, acc 0.9375\n",
      "2018-05-14T13:13:52.653872: step 413, loss 0.403311, acc 0.796875\n",
      "2018-05-14T13:13:53.009916: step 414, loss 0.238336, acc 0.90625\n",
      "2018-05-14T13:13:53.376942: step 415, loss 0.326826, acc 0.890625\n",
      "2018-05-14T13:13:53.704639: step 416, loss 0.445593, acc 0.890625\n",
      "2018-05-14T13:13:54.062705: step 417, loss 0.298469, acc 0.8125\n",
      "2018-05-14T13:13:54.450606: step 418, loss 0.266073, acc 0.875\n",
      "2018-05-14T13:13:54.887665: step 419, loss 0.30777, acc 0.875\n",
      "2018-05-14T13:13:55.239306: step 420, loss 0.229568, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-14T13:13:55.680857: step 420, loss 0.316114, acc 0.862191\n",
      "\n",
      "Saved model checkpoint to /Users/tamoto.yoshifumi/Workspace/Python/char_level_cnn/runs/1526271055/checkpoints/model-420\n",
      "\n",
      "2018-05-14T13:13:56.237929: step 421, loss 0.3048, acc 0.9375\n",
      "2018-05-14T13:13:56.604239: step 422, loss 0.261731, acc 0.890625\n",
      "2018-05-14T13:13:56.955828: step 423, loss 0.331409, acc 0.84375\n",
      "2018-05-14T13:13:57.312979: step 424, loss 0.380057, acc 0.84375\n",
      "2018-05-14T13:13:57.769227: step 425, loss 0.272608, acc 0.921875\n",
      "2018-05-14T13:13:58.137460: step 426, loss 0.300149, acc 0.890625\n",
      "2018-05-14T13:13:58.513182: step 427, loss 0.178896, acc 0.9375\n",
      "2018-05-14T13:13:58.906880: step 428, loss 0.31753, acc 0.84375\n",
      "2018-05-14T13:13:59.257362: step 429, loss 0.208714, acc 0.890625\n",
      "2018-05-14T13:13:59.628567: step 430, loss 0.243304, acc 0.90625\n",
      "2018-05-14T13:14:00.044872: step 431, loss 0.388904, acc 0.84375\n",
      "2018-05-14T13:14:00.383699: step 432, loss 0.251984, acc 0.859375\n",
      "2018-05-14T13:14:00.739336: step 433, loss 0.184663, acc 0.9375\n",
      "2018-05-14T13:14:01.080552: step 434, loss 0.233479, acc 0.90625\n",
      "2018-05-14T13:14:01.514044: step 435, loss 0.260027, acc 0.84375\n",
      "2018-05-14T13:14:01.863789: step 436, loss 0.362597, acc 0.796875\n",
      "2018-05-14T13:14:02.262572: step 437, loss 0.173983, acc 0.921875\n",
      "2018-05-14T13:14:02.637139: step 438, loss 0.283929, acc 0.890625\n",
      "2018-05-14T13:14:02.983690: step 439, loss 0.285212, acc 0.921875\n",
      "2018-05-14T13:14:03.279154: step 440, loss 0.281088, acc 0.882353\n",
      "\n",
      "Evaluation:\n",
      "2018-05-14T13:14:03.844468: step 440, loss 0.327421, acc 0.855124\n",
      "\n",
      "Saved model checkpoint to /Users/tamoto.yoshifumi/Workspace/Python/char_level_cnn/runs/1526271055/checkpoints/model-440\n",
      "\n",
      "2018-05-14T13:14:04.373663: step 441, loss 0.156613, acc 0.90625\n",
      "2018-05-14T13:14:04.722229: step 442, loss 0.182995, acc 0.921875\n",
      "2018-05-14T13:14:05.070972: step 443, loss 0.169259, acc 0.921875\n",
      "2018-05-14T13:14:05.404354: step 444, loss 0.219264, acc 0.890625\n",
      "2018-05-14T13:14:05.738596: step 445, loss 0.348861, acc 0.84375\n",
      "2018-05-14T13:14:06.082018: step 446, loss 0.232097, acc 0.890625\n",
      "2018-05-14T13:14:06.446847: step 447, loss 0.315206, acc 0.859375\n",
      "2018-05-14T13:14:06.806015: step 448, loss 0.21293, acc 0.90625\n",
      "2018-05-14T13:14:07.156945: step 449, loss 0.210819, acc 0.921875\n",
      "2018-05-14T13:14:07.581283: step 450, loss 0.17954, acc 0.921875\n",
      "2018-05-14T13:14:08.076311: step 451, loss 0.249537, acc 0.890625\n",
      "2018-05-14T13:14:08.583873: step 452, loss 0.279389, acc 0.84375\n",
      "2018-05-14T13:14:09.081978: step 453, loss 0.30952, acc 0.84375\n",
      "2018-05-14T13:14:09.505953: step 454, loss 0.226668, acc 0.90625\n",
      "2018-05-14T13:14:09.889147: step 455, loss 0.233853, acc 0.90625\n",
      "2018-05-14T13:14:10.235175: step 456, loss 0.165389, acc 0.9375\n",
      "2018-05-14T13:14:10.574748: step 457, loss 0.231637, acc 0.875\n",
      "2018-05-14T13:14:10.987286: step 458, loss 0.233942, acc 0.921875\n",
      "2018-05-14T13:14:11.349084: step 459, loss 0.203756, acc 0.890625\n",
      "2018-05-14T13:14:11.674808: step 460, loss 0.262045, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-14T13:14:12.268706: step 460, loss 0.318918, acc 0.865724\n",
      "\n",
      "Saved model checkpoint to /Users/tamoto.yoshifumi/Workspace/Python/char_level_cnn/runs/1526271055/checkpoints/model-460\n",
      "\n",
      "2018-05-14T13:14:12.789172: step 461, loss 0.186039, acc 0.953125\n",
      "2018-05-14T13:14:13.135090: step 462, loss 0.279756, acc 0.890625\n",
      "2018-05-14T13:14:13.464334: step 463, loss 0.39043, acc 0.8125\n",
      "2018-05-14T13:14:13.796760: step 464, loss 0.261484, acc 0.875\n",
      "2018-05-14T13:14:14.126109: step 465, loss 0.221238, acc 0.890625\n",
      "2018-05-14T13:14:14.463540: step 466, loss 0.254307, acc 0.890625\n",
      "2018-05-14T13:14:14.829612: step 467, loss 0.182121, acc 0.921875\n",
      "2018-05-14T13:14:15.177027: step 468, loss 0.273068, acc 0.90625\n",
      "2018-05-14T13:14:15.535718: step 469, loss 0.22383, acc 0.90625\n",
      "2018-05-14T13:14:15.859548: step 470, loss 0.342705, acc 0.890625\n",
      "2018-05-14T13:14:16.223663: step 471, loss 0.196053, acc 0.921875\n",
      "2018-05-14T13:14:16.575616: step 472, loss 0.173831, acc 0.921875\n",
      "2018-05-14T13:14:16.924130: step 473, loss 0.331319, acc 0.84375\n",
      "2018-05-14T13:14:17.283743: step 474, loss 0.201231, acc 0.90625\n",
      "2018-05-14T13:14:17.671092: step 475, loss 0.304113, acc 0.890625\n",
      "2018-05-14T13:14:18.055847: step 476, loss 0.213168, acc 0.890625\n",
      "2018-05-14T13:14:18.466266: step 477, loss 0.226907, acc 0.875\n",
      "2018-05-14T13:14:18.835244: step 478, loss 0.154047, acc 0.9375\n",
      "2018-05-14T13:14:19.177830: step 479, loss 0.210925, acc 0.9375\n",
      "2018-05-14T13:14:19.458531: step 480, loss 0.379955, acc 0.803922\n",
      "\n",
      "Evaluation:\n",
      "2018-05-14T13:14:19.996717: step 480, loss 0.395661, acc 0.833922\n",
      "\n",
      "Saved model checkpoint to /Users/tamoto.yoshifumi/Workspace/Python/char_level_cnn/runs/1526271055/checkpoints/model-480\n",
      "\n",
      "2018-05-14T13:14:20.590388: step 481, loss 0.260501, acc 0.90625\n",
      "2018-05-14T13:14:20.943687: step 482, loss 0.30135, acc 0.875\n",
      "2018-05-14T13:14:21.293971: step 483, loss 0.154856, acc 0.953125\n",
      "2018-05-14T13:14:21.645200: step 484, loss 0.202209, acc 0.921875\n",
      "2018-05-14T13:14:22.011802: step 485, loss 0.446461, acc 0.75\n",
      "2018-05-14T13:14:22.410658: step 486, loss 0.22181, acc 0.875\n",
      "2018-05-14T13:14:22.829336: step 487, loss 0.193361, acc 0.890625\n",
      "2018-05-14T13:14:23.240287: step 488, loss 0.181447, acc 0.90625\n",
      "2018-05-14T13:14:23.695918: step 489, loss 0.350087, acc 0.828125\n",
      "2018-05-14T13:14:24.129009: step 490, loss 0.281112, acc 0.890625\n",
      "2018-05-14T13:14:24.534163: step 491, loss 0.22963, acc 0.9375\n",
      "2018-05-14T13:14:24.931455: step 492, loss 0.189265, acc 0.90625\n",
      "2018-05-14T13:14:25.296714: step 493, loss 0.163145, acc 0.953125\n",
      "2018-05-14T13:14:25.653306: step 494, loss 0.216761, acc 0.90625\n",
      "2018-05-14T13:14:25.991794: step 495, loss 0.241075, acc 0.890625\n",
      "2018-05-14T13:14:26.350986: step 496, loss 0.138988, acc 0.9375\n",
      "2018-05-14T13:14:26.710644: step 497, loss 0.165426, acc 0.9375\n",
      "2018-05-14T13:14:27.067709: step 498, loss 0.272486, acc 0.875\n",
      "2018-05-14T13:14:27.438634: step 499, loss 0.288656, acc 0.84375\n",
      "2018-05-14T13:14:27.821831: step 500, loss 0.286038, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-05-14T13:14:28.512719: step 500, loss 0.324205, acc 0.865724\n",
      "\n",
      "Saved model checkpoint to /Users/tamoto.yoshifumi/Workspace/Python/char_level_cnn/runs/1526271055/checkpoints/model-500\n",
      "\n",
      "2018-05-14T13:14:29.065087: step 501, loss 0.236443, acc 0.921875\n",
      "2018-05-14T13:14:29.407446: step 502, loss 0.144198, acc 0.9375\n",
      "2018-05-14T13:14:29.739253: step 503, loss 0.122476, acc 0.96875\n",
      "2018-05-14T13:14:30.079402: step 504, loss 0.202219, acc 0.921875\n",
      "2018-05-14T13:14:30.421394: step 505, loss 0.23051, acc 0.921875\n",
      "2018-05-14T13:14:30.750992: step 506, loss 0.161321, acc 0.953125\n",
      "2018-05-14T13:14:31.102688: step 507, loss 0.304978, acc 0.8125\n",
      "2018-05-14T13:14:31.546759: step 508, loss 0.203015, acc 0.921875\n",
      "2018-05-14T13:14:31.932769: step 509, loss 0.25858, acc 0.921875\n",
      "2018-05-14T13:14:32.341126: step 510, loss 0.216275, acc 0.921875\n",
      "2018-05-14T13:14:32.734125: step 511, loss 0.355013, acc 0.84375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-14T13:14:33.124649: step 512, loss 0.230895, acc 0.90625\n",
      "2018-05-14T13:14:33.564104: step 513, loss 0.166046, acc 0.921875\n",
      "2018-05-14T13:14:33.917363: step 514, loss 0.265323, acc 0.90625\n",
      "2018-05-14T13:14:34.248968: step 515, loss 0.310854, acc 0.90625\n",
      "2018-05-14T13:14:34.574365: step 516, loss 0.398682, acc 0.84375\n",
      "2018-05-14T13:14:34.908305: step 517, loss 0.239728, acc 0.90625\n",
      "2018-05-14T13:14:35.251357: step 518, loss 0.230155, acc 0.921875\n",
      "2018-05-14T13:14:35.677944: step 519, loss 0.284451, acc 0.859375\n",
      "2018-05-14T13:14:35.946727: step 520, loss 0.104576, acc 0.941176\n",
      "\n",
      "Evaluation:\n",
      "2018-05-14T13:14:36.482458: step 520, loss 0.318005, acc 0.848057\n",
      "\n",
      "Saved model checkpoint to /Users/tamoto.yoshifumi/Workspace/Python/char_level_cnn/runs/1526271055/checkpoints/model-520\n",
      "\n",
      "2018-05-14T13:14:37.087334: step 521, loss 0.235562, acc 0.875\n",
      "2018-05-14T13:14:37.534191: step 522, loss 0.149291, acc 0.953125\n",
      "2018-05-14T13:14:37.992309: step 523, loss 0.230315, acc 0.875\n",
      "2018-05-14T13:14:38.365173: step 524, loss 0.273508, acc 0.890625\n",
      "2018-05-14T13:14:38.689741: step 525, loss 0.197016, acc 0.90625\n",
      "2018-05-14T13:14:39.019317: step 526, loss 0.187312, acc 0.921875\n",
      "2018-05-14T13:14:39.339536: step 527, loss 0.255236, acc 0.90625\n",
      "2018-05-14T13:14:39.660962: step 528, loss 0.212714, acc 0.90625\n",
      "2018-05-14T13:14:39.979195: step 529, loss 0.196506, acc 0.921875\n",
      "2018-05-14T13:14:40.310308: step 530, loss 0.263222, acc 0.890625\n",
      "2018-05-14T13:14:40.634119: step 531, loss 0.266327, acc 0.890625\n",
      "2018-05-14T13:14:40.963400: step 532, loss 0.189266, acc 0.9375\n",
      "2018-05-14T13:14:41.296121: step 533, loss 0.155484, acc 0.953125\n",
      "2018-05-14T13:14:41.645511: step 534, loss 0.30135, acc 0.84375\n",
      "2018-05-14T13:14:41.961722: step 535, loss 0.129623, acc 0.96875\n",
      "2018-05-14T13:14:42.307816: step 536, loss 0.171073, acc 0.9375\n",
      "2018-05-14T13:14:42.627255: step 537, loss 0.229347, acc 0.875\n",
      "2018-05-14T13:14:42.942230: step 538, loss 0.256856, acc 0.90625\n",
      "2018-05-14T13:14:43.271035: step 539, loss 0.231926, acc 0.90625\n",
      "2018-05-14T13:14:43.596733: step 540, loss 0.184006, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-05-14T13:14:44.043668: step 540, loss 0.332273, acc 0.865724\n",
      "\n",
      "Saved model checkpoint to /Users/tamoto.yoshifumi/Workspace/Python/char_level_cnn/runs/1526271055/checkpoints/model-540\n",
      "\n",
      "2018-05-14T13:14:44.541425: step 541, loss 0.0909661, acc 0.96875\n",
      "2018-05-14T13:14:44.870330: step 542, loss 0.200073, acc 0.890625\n",
      "2018-05-14T13:14:45.194298: step 543, loss 0.194635, acc 0.890625\n",
      "2018-05-14T13:14:45.547075: step 544, loss 0.251073, acc 0.90625\n",
      "2018-05-14T13:14:45.895034: step 545, loss 0.22639, acc 0.90625\n",
      "2018-05-14T13:14:46.241336: step 546, loss 0.182266, acc 0.9375\n",
      "2018-05-14T13:14:46.573338: step 547, loss 0.177507, acc 0.9375\n",
      "2018-05-14T13:14:46.906102: step 548, loss 0.337119, acc 0.84375\n",
      "2018-05-14T13:14:47.233598: step 549, loss 0.219306, acc 0.90625\n",
      "2018-05-14T13:14:47.584610: step 550, loss 0.238381, acc 0.90625\n",
      "2018-05-14T13:14:47.958762: step 551, loss 0.258547, acc 0.90625\n",
      "2018-05-14T13:14:48.304561: step 552, loss 0.266628, acc 0.890625\n",
      "2018-05-14T13:14:48.630995: step 553, loss 0.174647, acc 0.953125\n",
      "2018-05-14T13:14:48.946538: step 554, loss 0.283206, acc 0.90625\n",
      "2018-05-14T13:14:49.271364: step 555, loss 0.192025, acc 0.953125\n",
      "2018-05-14T13:14:49.596720: step 556, loss 0.265005, acc 0.859375\n",
      "2018-05-14T13:14:49.922282: step 557, loss 0.270303, acc 0.890625\n",
      "2018-05-14T13:14:50.262377: step 558, loss 0.265059, acc 0.90625\n",
      "2018-05-14T13:14:50.577990: step 559, loss 0.289372, acc 0.875\n",
      "2018-05-14T13:14:50.832877: step 560, loss 0.295004, acc 0.862745\n",
      "\n",
      "Evaluation:\n",
      "2018-05-14T13:14:51.277979: step 560, loss 0.289066, acc 0.869258\n",
      "\n",
      "Saved model checkpoint to /Users/tamoto.yoshifumi/Workspace/Python/char_level_cnn/runs/1526271055/checkpoints/model-560\n",
      "\n",
      "2018-05-14T13:14:51.776297: step 561, loss 0.143024, acc 0.953125\n",
      "2018-05-14T13:14:52.116116: step 562, loss 0.220821, acc 0.90625\n",
      "2018-05-14T13:14:52.520638: step 563, loss 0.277806, acc 0.875\n",
      "2018-05-14T13:14:52.863917: step 564, loss 0.246505, acc 0.921875\n",
      "2018-05-14T13:14:53.208034: step 565, loss 0.190799, acc 0.9375\n",
      "2018-05-14T13:14:53.538142: step 566, loss 0.148932, acc 0.96875\n",
      "2018-05-14T13:14:53.868145: step 567, loss 0.247476, acc 0.921875\n",
      "2018-05-14T13:14:54.193561: step 568, loss 0.224003, acc 0.9375\n",
      "2018-05-14T13:14:54.516905: step 569, loss 0.278524, acc 0.875\n",
      "2018-05-14T13:14:54.840235: step 570, loss 0.177705, acc 0.953125\n",
      "2018-05-14T13:14:55.196912: step 571, loss 0.134708, acc 0.953125\n",
      "2018-05-14T13:14:55.533700: step 572, loss 0.160124, acc 0.96875\n",
      "2018-05-14T13:14:55.871787: step 573, loss 0.2727, acc 0.90625\n",
      "2018-05-14T13:14:56.213574: step 574, loss 0.14209, acc 0.9375\n",
      "2018-05-14T13:14:56.549074: step 575, loss 0.18848, acc 0.90625\n",
      "2018-05-14T13:14:56.904487: step 576, loss 0.138431, acc 0.953125\n",
      "2018-05-14T13:14:57.244299: step 577, loss 0.316281, acc 0.828125\n",
      "2018-05-14T13:14:57.580894: step 578, loss 0.183878, acc 0.921875\n",
      "2018-05-14T13:14:57.944901: step 579, loss 0.15736, acc 0.96875\n",
      "2018-05-14T13:14:58.306931: step 580, loss 0.115088, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-14T13:14:58.810071: step 580, loss 0.299996, acc 0.865724\n",
      "\n",
      "Saved model checkpoint to /Users/tamoto.yoshifumi/Workspace/Python/char_level_cnn/runs/1526271055/checkpoints/model-580\n",
      "\n",
      "2018-05-14T13:14:59.338378: step 581, loss 0.161631, acc 0.921875\n",
      "2018-05-14T13:14:59.673212: step 582, loss 0.101008, acc 0.96875\n",
      "2018-05-14T13:15:00.000035: step 583, loss 0.214128, acc 0.890625\n",
      "2018-05-14T13:15:00.345763: step 584, loss 0.108218, acc 0.9375\n",
      "2018-05-14T13:15:00.678638: step 585, loss 0.107359, acc 0.96875\n",
      "2018-05-14T13:15:00.999046: step 586, loss 0.139869, acc 0.9375\n",
      "2018-05-14T13:15:01.340103: step 587, loss 0.247125, acc 0.921875\n",
      "2018-05-14T13:15:01.690767: step 588, loss 0.186977, acc 0.953125\n",
      "2018-05-14T13:15:02.031936: step 589, loss 0.343715, acc 0.84375\n",
      "2018-05-14T13:15:02.371294: step 590, loss 0.182828, acc 0.890625\n",
      "2018-05-14T13:15:02.710191: step 591, loss 0.100131, acc 0.953125\n",
      "2018-05-14T13:15:03.094105: step 592, loss 0.244662, acc 0.90625\n",
      "2018-05-14T13:15:03.430608: step 593, loss 0.264417, acc 0.875\n",
      "2018-05-14T13:15:03.812561: step 594, loss 0.186294, acc 0.90625\n",
      "2018-05-14T13:15:04.155028: step 595, loss 0.214681, acc 0.90625\n",
      "2018-05-14T13:15:04.499151: step 596, loss 0.321754, acc 0.875\n",
      "2018-05-14T13:15:04.850154: step 597, loss 0.244488, acc 0.921875\n",
      "2018-05-14T13:15:05.194015: step 598, loss 0.269181, acc 0.890625\n",
      "2018-05-14T13:15:05.548736: step 599, loss 0.238953, acc 0.90625\n",
      "2018-05-14T13:15:05.835348: step 600, loss 0.154142, acc 0.921569\n",
      "\n",
      "Evaluation:\n",
      "2018-05-14T13:15:06.389796: step 600, loss 0.342151, acc 0.869258\n",
      "\n",
      "Saved model checkpoint to /Users/tamoto.yoshifumi/Workspace/Python/char_level_cnn/runs/1526271055/checkpoints/model-600\n",
      "\n",
      "2018-05-14T13:15:06.886867: step 601, loss 0.129385, acc 0.953125\n",
      "2018-05-14T13:15:07.217237: step 602, loss 0.311269, acc 0.859375\n",
      "2018-05-14T13:15:07.567551: step 603, loss 0.210541, acc 0.890625\n",
      "2018-05-14T13:15:07.940290: step 604, loss 0.217895, acc 0.90625\n",
      "2018-05-14T13:15:08.283732: step 605, loss 0.188007, acc 0.921875\n",
      "2018-05-14T13:15:08.611298: step 606, loss 0.147564, acc 0.9375\n",
      "2018-05-14T13:15:08.992465: step 607, loss 0.140346, acc 0.953125\n",
      "2018-05-14T13:15:09.364645: step 608, loss 0.234303, acc 0.875\n",
      "2018-05-14T13:15:09.723868: step 609, loss 0.23547, acc 0.921875\n",
      "2018-05-14T13:15:10.061543: step 610, loss 0.193928, acc 0.921875\n",
      "2018-05-14T13:15:10.451857: step 611, loss 0.118684, acc 0.953125\n",
      "2018-05-14T13:15:10.847597: step 612, loss 0.197631, acc 0.953125\n",
      "2018-05-14T13:15:11.212372: step 613, loss 0.25886, acc 0.890625\n",
      "2018-05-14T13:15:11.551245: step 614, loss 0.120874, acc 0.953125\n",
      "2018-05-14T13:15:11.944429: step 615, loss 0.286314, acc 0.84375\n",
      "2018-05-14T13:15:12.390912: step 616, loss 0.0384001, acc 0.984375\n",
      "2018-05-14T13:15:12.842073: step 617, loss 0.315125, acc 0.890625\n",
      "2018-05-14T13:15:13.302239: step 618, loss 0.160144, acc 0.90625\n",
      "2018-05-14T13:15:13.788085: step 619, loss 0.215733, acc 0.953125\n",
      "2018-05-14T13:15:14.141809: step 620, loss 0.273492, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2018-05-14T13:15:14.861224: step 620, loss 0.342355, acc 0.862191\n",
      "\n",
      "Saved model checkpoint to /Users/tamoto.yoshifumi/Workspace/Python/char_level_cnn/runs/1526271055/checkpoints/model-620\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-14T13:15:15.496880: step 621, loss 0.236848, acc 0.921875\n",
      "2018-05-14T13:15:15.894425: step 622, loss 0.177893, acc 0.90625\n",
      "2018-05-14T13:15:16.247472: step 623, loss 0.227657, acc 0.890625\n",
      "2018-05-14T13:15:16.673323: step 624, loss 0.119948, acc 0.9375\n",
      "2018-05-14T13:15:17.178143: step 625, loss 0.114456, acc 0.9375\n",
      "2018-05-14T13:15:17.623912: step 626, loss 0.240889, acc 0.859375\n",
      "2018-05-14T13:15:18.099145: step 627, loss 0.0985414, acc 0.953125\n",
      "2018-05-14T13:15:18.491371: step 628, loss 0.206886, acc 0.9375\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-9f67fc291220>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0mcurrent_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-96-9f67fc291220>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(x_batch, y_batch)\u001b[0m\n\u001b[1;32m     57\u001b[0m               \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_keep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdropout_keep_prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             }\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_summary_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mtime_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misoformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[0mrun_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m         \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_DeleteBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetch_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0mmake_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \"\"\"Returns a Python callable that runs a particular step.\n\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBaseSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NODEDEF_NAME_RE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m       \u001b[0mnode_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m         \u001b[0mnode_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'partial_run() requires empty target_list.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1312\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m       return tf_session.TF_SessionPRun_wrapper(\n\u001b[1;32m   1419\u001b[0m           self._session, handle, feed_dict, fetch_list)\n\u001b[0;32m-> 1420\u001b[0;31m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1421\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m         return tf_session.TF_PRun(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    session_conf = tf.ConfigProto(\n",
    "      allow_soft_placement=allow_soft_placement,\n",
    "      log_device_placement=log_device_placement)\n",
    "    sess = tf.Session(config=session_conf)\n",
    "    \n",
    "    with sess.as_default():\n",
    "        \n",
    "        cnn = TextCNN(sequence_length, num_classes, vocab_size, embedding_size, filter_sizes, num_filters, l2_reg_lambda)\n",
    "\n",
    "\n",
    "        global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "        grads_and_vars = optimizer.compute_gradients(cnn.loss)\n",
    "        train_op = optimizer.apply_gradients(grads_and_vars, global_step=global_step)\n",
    "\n",
    "\n",
    "        grad_summaries = []\n",
    "        for g, v in grads_and_vars:\n",
    "            if g is not None:\n",
    "                grad_hist_summary = tf.summary.histogram(\"{}/grad/hist\".format(v.name), g)\n",
    "                sparsity_summary = tf.summary.scalar(\"{}/grad/sparsity\".format(v.name), tf.nn.zero_fraction(g))\n",
    "                grad_summaries.append(grad_hist_summary)\n",
    "                grad_summaries.append(sparsity_summary)\n",
    "        grad_summaries_merged = tf.summary.merge(grad_summaries)\n",
    "\n",
    "\n",
    "        loss_summary = tf.summary.scalar(\"loss\", cnn.loss)\n",
    "        acc_summary = tf.summary.scalar(\"accuracy\", cnn.accuracy)\n",
    "\n",
    "        train_summary_op = tf.summary.merge([loss_summary, acc_summary, grad_summaries_merged])\n",
    "        \n",
    "        train_summary_dir = os.path.join(out_dir, \"summaries\", \"train\")\n",
    "        train_summary_writer = tf.summary.FileWriter(train_summary_dir, sess.graph)\n",
    "\n",
    "        test_summary_op = tf.summary.merge([loss_summary, acc_summary])\n",
    "        test_summary_dir = os.path.join(out_dir, \"summaries\", \"test\")\n",
    "        test_summary_writer = tf.summary.FileWriter(test_summary_dir, sess.graph)\n",
    "\n",
    "        if save_checkpoint:\n",
    "            checkpoint_dir = os.path.abspath(os.path.join(out_dir, \"checkpoints\"))\n",
    "            checkpoint_prefix = os.path.join(checkpoint_dir, \"model\")\n",
    "            if not os.path.exists(checkpoint_dir):\n",
    "                os.makedirs(checkpoint_dir)\n",
    "            saver = tf.train.Saver(tf.global_variables(), max_to_keep=num_checkpoints)\n",
    "\n",
    "  \n",
    "        vocab_processor.save(os.path.join(out_dir, \"vocab\"))\n",
    "\n",
    "\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        def train_step(x_batch, y_batch):\n",
    "            feed_dict = {\n",
    "              cnn.input_x: x_batch,\n",
    "              cnn.input_y: y_batch,\n",
    "              cnn.dropout_keep_prob: dropout_keep_prob\n",
    "            }\n",
    "            _, step, summaries, loss, accuracy = sess.run([train_op, global_step, train_summary_op, cnn.loss, cnn.accuracy], feed_dict)\n",
    "            \n",
    "            time_str = datetime.datetime.now().isoformat()\n",
    "            print(\"{}: step {}, loss {:g}, acc {:g}\".format(time_str, step, loss, accuracy))\n",
    "            train_summary_writer.add_summary(summaries, step)\n",
    "\n",
    "        def test_step(x_batch, y_batch, writer=None):\n",
    "            feed_dict = {\n",
    "              cnn.input_x: x_batch,\n",
    "              cnn.input_y: y_batch,\n",
    "              cnn.dropout_keep_prob: 1.0\n",
    "            }\n",
    "            step, summaries, loss, accuracy = sess.run([global_step, test_summary_op, cnn.loss, cnn.accuracy], feed_dict)\n",
    "            time_str = datetime.datetime.now().isoformat()\n",
    "            print(\"{}: step {}, loss {:g}, acc {:g}\".format(time_str, step, loss, accuracy))\n",
    "            if writer:\n",
    "                writer.add_summary(summaries, step)\n",
    "\n",
    "        batches = batch_iter(list(zip(x_train, y_train)), batch_size, num_epochs)\n",
    "        for batch in batches:\n",
    "            x_batch, y_batch = zip(*batch)\n",
    "            train_step(x_batch, y_batch)\n",
    "            current_step = tf.train.global_step(sess, global_step)\n",
    "            \n",
    "            if current_step % evaluate_every == 0:\n",
    "                print(\"\\nEvaluation:\")\n",
    "                test_step(x_test, y_test, writer=test_summary_writer)\n",
    "                print(\"\")\n",
    "                \n",
    "            if save_checkpoint and current_step % evaluate_every == 0:\n",
    "                path = saver.save(sess, checkpoint_prefix, global_step=current_step)\n",
    "                print(\"Saved model checkpoint to {}\\n\".format(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "char level cnn \n",
    "- 1525408577  \n",
    "- 1526189751   good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_neg_posi(text):\n",
    "    text = [s.replace(\" \", \"\").replace(\"\", \" \").lower() for s in [text]]\n",
    "    x = np.array(list(vocab_processor.fit_transform(text)))\n",
    "    feed_dict = {\n",
    "                  cnn.input_x: x,\n",
    "                  cnn.dropout_keep_prob: 1.0\n",
    "                }\n",
    "    feature_2 = sess.run(cnn.scores, feed_dict=feed_dict)\n",
    "    print(feature_2[0])\n",
    "    if np.argmax(feature_2[0]):\n",
    "        print(\"positive\")\n",
    "    else:\n",
    "        print(\"negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.4666646  3.9447124]\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "check_neg_posi(\"伸び率は増加傾向にありました。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.8813882 -1.8911232]\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "check_neg_posi(\"伸び率は減少傾向にありました。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9804301  1.8085191]\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "check_neg_posi(\"伸び率は加向にありました。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.6227853 -1.3544416]\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "check_neg_posi(\"伸び率は減向にありました。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = os.path.join(out_dir, \"checkpoints\" )\n",
    "latest_ckpt = tf.train.get_checkpoint_state(ckpt_dir).model_checkpoint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(x):\n",
    "    with tf.Graph().as_default():\n",
    "        session_conf = tf.ConfigProto(\n",
    "          allow_soft_placement=allow_soft_placement,\n",
    "          log_device_placement=log_device_placement)\n",
    "        sess = tf.Session(config=session_conf)\n",
    "        with sess.as_default():\n",
    "            cnn = TextCNN(\n",
    "                sequence_length=x_train.shape[1],\n",
    "                num_classes=y_train.shape[1],\n",
    "                vocab_size=len(vocab_processor.vocabulary_),\n",
    "                embedding_size=embedding_dim,\n",
    "                filter_sizes=list(map(int, filter_sizes.split(\",\"))),\n",
    "                num_filters=num_filters,\n",
    "                l2_reg_lambda=l2_reg_lambda)\n",
    "\n",
    "            saver = tf.train.Saver()\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            saver.restore(sess, latest_ckpt)\n",
    "\n",
    "            feed_dict = {\n",
    "                  cnn.input_x: x,\n",
    "                  cnn.dropout_keep_prob: 1.0\n",
    "                }\n",
    "            feature_5, feature_2 = sess.run([cnn.f_h, cnn.scores ], feed_dict=feed_dict)\n",
    "    return feature_5, feature_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = list(open(\"data/amazon/rating_5.txt\", \"r\").readlines())\n",
    "review = [s.strip() for s in review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "x = []\n",
    "for r in review:\n",
    "    l = r.split(\":::::\")\n",
    "    y.append(float(l[0]))\n",
    "    x.append(l[1].replace(\" \", \"\").replace(\"\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_processor = preprocessing.VocabularyProcessor.restore(os.path.join(\"runs/1525408577\", \"vocab\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(list(vocab_processor.fit_transform(x)))\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_5 ,feature_2 = get_feature(x[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_5[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_5[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0\n",
    "chunk_size = 100\n",
    "for i in range(0, len(x) , chunk_size):\n",
    "    feature_5 ,feature_2 = get_feature(x[i:i+chunk_size])\n",
    "    for f, r in zip(feature_5, y[i:i+chunk_size]):\n",
    "        s  += int(np.argmax(f) == r)\n",
    "    print(s/(i+chunk_size))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(feature_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_2 [0]  #[neg, pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_py36)",
   "language": "python",
   "name": "conda_py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
